
@BOOK{Wallach20091,
author={Wallach, W. and Allen, C.},
title={Moral Machines: Teaching Robots Right from Wrong},
journal={Moral Machines: Teaching Robots Right from Wrong},
year={2009},
pages={1-288},
doi={10.1093/acprof:oso/9780195374049.001.0001},
note={cited By 428},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921546917&doi=10.1093%2facprof%3aoso%2f9780195374049.001.0001&partnerID=40&md5=7adb067dab5a0be05681866c26d99de9},
abstract={The human-built environment is increasingly being populated by artificial agents that, through artificial intelligence (AI), are capable of acting autonomously. The software controlling these autonomous systems is, to-date, "ethically blind" in the sense that the decision-making capabilities of such systems does not involve any explicit moral reasoning. The title Moral Machines: Teaching Robots Right from Wrong refers to the need for these increasingly autonomous systems (robots and software bots) to become capable of factoring ethical and moral considerations into their decision making. The new field of inquiry directed at the development of artificial moral agents is referred to by a number of names including machine morality, machine ethics, roboethics, or artificial morality. Engineers exploring design strategies for systems sensitive to moral considerations in their choices and actions will need to determine what role ethical theory should play in defining control architectures for such systems. © 2009 by Oxford University Press, Inc. All rights reserved.},
author_keywords={Artificial intelligence;  Artificial moral agents;  Autonomous systems;  Decision-making;  Ethics;  Machine ethics;  Machine morality;  Moral agent;  Moral reasoning;  Robot},
references={Adams, B., Breazeal, C., Brooks, R.A., Scassellati, B., Humanoid Robots: A New Kind of Tool (2000) IEEE Intelligent Systems, 15, pp. 25-31; Aleksander, I., (2007) The World in My Mind, My Mind in the World: Key Mechanisms of Consciousness in People, Animals and Machines, , Thorverton, UK: Imprint Academic; Aleksander, I., Dunmall, B., Axioms and Test for the Presence of Minimal Consciousness in Agents (2003) Machine Consciousness, pp. 7-18. , O. Holland (Ed.), Thorverton, UK: Imprint Academic; Aleksander, I., Lanhnstein, M., Rabinder, L., (2005) Will and Emotions: A Machine Model That Shuns Illusions, , Paper presented at the Symposium on Next Generation Approaches to Machine Consciousness, Hatfield, UK; Allen, C., (2002) Calculated Morality: Ethical Computing in the Limit, , Paper presented at the 14th International Conference on Systems Research, Informatics and Cybernetics, Baden-Baden, Germany; Allen, C., Smit, I., Wallach, W., Artificial Morality: Top-Down, Bottom-Up and Hybrid Approaches (2006) Ethics and New Information Technology, 7, pp. 149-155; Allen, C., Varner, G., Zinser, J., Prolegomena to Any Future Artificial Moral Agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12, pp. 251-261; Allen, C., Wallach, W., Smit, I., Why Machine Ethics? (2006) IEEE Intelligent Systems, 21 (4), pp. 12-17; Allhoff, F., Lin, P., (2007) Nanoethics: The Ethical and Social Implications of Nanotechnology, , Hoboken, NJ: Wiley-Interscience; Anderson, M., Anderson, S.L., Machine Ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 10-11; Anderson, M., Anderson, S.L., (2006) MedEthEx: A Prototype Medical Ethics Advisor, , Paper presented at the Eighteenth Conference on Innovative Applications of Artificial Intelligence, Boston; Anderson, M., Anderson, S.L., (2008) Ethical Healthcare Agents. Advanced Computational Intelligence Paradigms in Healthcare-3, pp. 233-257. , L. C. Jain. Berlin, Springer; Anderson, M., Anderson, S.L., Armen, C., An Approach to Computing Ethics (2006) IEEE Intelligent Systems, pp. 56-63; Anderson, M., Anderson, S.L., Armen, C., (2005) Towards Machine Ethics: Implementing Two Action-Based Ethical Theories, , Paper presented at the American Association for Artificial Intelligence 2005 Fall Symposium on Machine Ethics, Arlington, VA; Anderson, M., Anderson, S.L., EthEl: Towards a principled ethical eldercare robot (2008), March, ACM/IEEE Human-Robot Interaction Conference, Amsterdam; Anderson, S.L., (2005) Asimov's "Three Laws of Robotics" and Machine Metaethics, , Paper presented at the American Association for Artificial Intelligence 2005 Fall Symposium on Machine Ethics, Arlington, VA; Antunes, L., Coelho, H., Decisions Based upon Multiple Values:The BVG Agent Architecture (1999) Ninth Portuguese Conference on Artificial Intelligence, pp. 297-311. , P. Barahona & J. J. O. Alferes (Eds.), Springer; Appiah, K.A., (2008) Experiments in Ethics, , Cambridge: Harvard University Press; Aristotle, (1908) Nichomachean Ethics, , (W. D. Ross, Trans.). Oxford:Clarendon Press; Arkin, R., (2004) Bombs, Bonding, and Bondage: Human-Robot Interaction and Related Ethical Issues, , Paper presented at the First International Conference on Roboethics, San Remo, Italy; Arkin, R., (2007) Governing Lethal Behavior: Embedding Ethics in a Hybrid Deliberative/Reactive Robot Architecture, , Technical Report, College of Computing, Georgia Institute of Technology; Arkin, R., Robot Ethics: From the Battlefield to the Bedroom, Robots of the Future Raise Ethical Concerns (2007) Research Horizons, pp. 14-15. , Winter-Spring; Arkoudas, K., Bringsjord, S., (2004) Metareasoning for Multi-Agent Epistemic Logics, , Paper presented at the Fifth International Conference on Computational Logic in Multi-Agent Systems, Lisbon, Portugal; Arkoudas, K., Bringsjord, S., (2005) Toward Ethical Robots via Mechanized Deontic Logic, , Paper presented at the American Association for Artificial Intelligence 2005 Fall Symposium on Machine Ethics, Arlington, VA; Asaro, P., What Should We Want from a Robot Ethic? (2006) International Review of Information Ethics, 6, pp. 10-16; Ashley, K.D., (1990) Modeling Legal Arguments: Reasoning with Cases and Hypotheticals (Artificial Intelligence and Legal Reasoning), , Cambridge, MA:MIT Press; Asimov, I., Runaround (1942) Astounding Science Fiction, pp. 94-103. , March; Asimov, I., (1950) I, Robot, , New York: Gnome Press; Asimov, I., (1985) Robots and Empire, , Garden City, NY: Doubleday; Axelrod, R., Hamilton, W., The Evolution of Cooperation (1981) Science, 211, pp. 1390-1396; Baars, B., (1997) In the Theater of Consciousness: The Workspace of the Mind, , Oxford: Oxford University Press; Baars, B.J., (1988) A Cognitive Theory of Consciousness, , Cambridge, UK:Cambridge University Press; Baars, B.J., The Conscious Access Hypothesis: Origins and Recent Evidence (2002) Trends in Cognitive Science, 6, pp. 47-52; Baars, B.J., Franklin, S., How Conscious Experience and Working Memory Interact (2003) Trends in Cognitive Science, 7, pp. 166-172; Baddeley, A.D., Consciousness and Working Memory (1992) Consciousness and Cognition, 1, pp. 3-6; Baddeley, A.D., Conway, M., Aggleton, J., (2001) Episodic Memory, , Oxford:Oxford University Press; Baddeley, A.D., Hitch, G.J., Working Memory (1974) The Psychology of Learning and Motivation, pp. 47-89. , G. A. Bower (Ed.), New York: Academic Press; Bainbridge, W.S., (2006) God from the Machine: Artificial Intelligence Models of Religious Cognition, , Lanham, MD: AltaMira Press; Barad, J., Robertson, E., (2000) The Ethics of Star Trek, , New York:HarperCollins; Barrett, M., Eells, E., Fitelson, B., Sober, E., Models and Reality-A Review of Brian Skyrms's (1999) Evolution of the Social Contract. Philosophy and Phenomenological Research, 59 (1), pp. 237-241; Barsalou, L.W., Perceptual Symbol Systems (1999) Behavioral and Brain Sciences, 22, pp. 577-609; Bartneck, C., (2002) Integrating the Ortony/Clore/Collins Model of Emotion in Embodied Characters, , Paper presented at the workshop Virtual Conversational Characters: Applications, Methods, and Research Challenges, Melbourne, AU; Bates, J., The Role of Emotion in Believable Agents (1994) Communications of the ACM, 37, pp. 122-125; Baum, E., (2004) What Is Thought?, , Cambridge, MA: MIT Press; Beauchamp, T.L., Childress, J.F., (2001) Principles of Biomedical Ethics, , (5th ed.). Oxford: Oxford University Press; Bechtel, W., Abrahamsen, A., (2007) Mental Mechanisms, Autonomous Systems, and Moral Agency, , Paper presented at the annual meeting of the Cognitive Science Society, Nashville, TN; Bennett, D., Robo-Justice: Do We Have the Technology to Build Better Legal Systems? (2005) Boston Globe, , September 11; Bentham, J., (1780) An Introduction to the Principles of Morals and Legislation, , Oxford: Clarendon Press; Berne, E., (1964) Games People Play: The Basic Hand Book of Transactional Analysis, , New York: Ballantine Books; Billings, L., Rise of Roboethics (2007) Seed, , July 16; Birrer, F., Applying Ethical and Moral Concepts and Theories to IT Contexts: Some Key Problems and Challenges (2001) Readings in Cybernetics, pp. 91-97. , R. A. Spinello & H. T. Tavani (Eds.), Sudbury, MA: Jones & Bartlett; Blackmore, S., Consciousness in Meme Machines (2003) Machine Consciousness, pp. 19-30. , O. Holland (Ed.), Thorverton, UK: Imprint Academic; Boden, M.A., Artificial Intelligence as a Humanizing Force (1983) Proceedings of the Eighth International Joint Conferences on Artificial Intelligence, pp. 1197-1198. , A. Bundy (Ed.); Boden, M.A., Could a Robot Be Creative-How Would We Know? (1995) Android Epistemology, pp. 51-72. , K. Ford, C. Glymour, & P. Hayes (Eds.), Menlo Park, CA: AAAI Press; Boden, M.A., Ethical issues in AI and biotechnology (2005) Creative Creatures: Values and Ethical Issues in Theology, Science and Technology, pp. 123-134. , U. Görman, W.B. Drees, & M. Meisinger (Eds.), London: T & T Clark; Boella, G., van der Torre, L., Verhagen, H., (2005) Introduction to Normative Multiagent Systems, , Paper presented at the Artificial Intelligence and the Simulation of Behavior '05 Convention, Social Intelligence and Interaction in Animals, Robots and Agents: Symposium on Normative Multi-Agent Systems, Hatfield, UK; Bostrom, N., How Long before Superintelligence? (1998) International Journal of Future Studies, 2, pp. 1-13; Bostrom, N., Are You Living in a Computer Simulation? (2003) Philosophical Quarterly, 53 (211), pp. 243-255; Bostrom, N., The Ethics of Superintelligent Machines (2003) Fifteenth International Conference on Systems Research, Informatics and Cybernetics: Symposium on Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, 2, pp. 12-18. , I. Smit, W. Wallach, & G. Lasker (Eds.), Windsor, Ontario, Canada: International Institute for Advanced Studies in Systems Research and Cybernetics; Bostrom, N., When Machines Outsmart Humans (2003) Futures, 35 (7), pp. 759-764; Bratman, M., (1987) Intention, Plans, and Practical Reason, , Cambridge, MA:Harvard University Press; Breazeal, C., (2002) Designing Sociable Robots, , Cambridge, MA: MIT Press; Breazeal, C., Emotion and Sociable Humanoid Robots (2003) International Journal of Human-Computer Studies, 59, pp. 119-155; Breazeal, C., Scassellati, B., Challenges in Building Robots That Imitate People (2001) Imitation in Animals and Artifacts, pp. 363-390. , K. Dautenhahn & C. Nehaniv (Eds.), Cambridge, MA: MIT Press; Bringsjord, S., Arkoudas, K., Bello, P., Toward a General Logicist Methodology for Engineering Ethically Correct Robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44; Bringsjord, S., Ferucci, D., Logic and Artificial Intelligence: Divorced, Still Married, Separated...? (1998) Minds and Machines, 8 (2), pp. 273-308; Brooks, R., A Robust Layered Control System for a Mobile Robot (1986) IEEE Journal of Robotics and Automation, RA-2 (1), pp. 14-23; Brooks, R., (2002) Flesh and Machines, , New York: Pantheon Books; Brooks, R.A., A Robot That Walks: Emergent Behavior from a Carefully Evolved Network (1989) Neural Computation, 1, pp. 253-262; Brooks, R.A., How to Build Complete Creatures Rather Than Isolated Cognitive Simulators (1991) Architectures for Intelligence, pp. 225-239. , K. van Lehn (Ed.), Hillsdale, NJ: Erlbaum; Brooks, R.A., Intelligence without Representation (1991) Artificial Intelligence, 47 (1-3), pp. 139-159; Brooks, R.A., The Cog Project (1997) Journal of the Robotics Society of Japan, 15, pp. 968-970; Brooks, R.A., Steps towards Living Machines (2001) The International Symposium on Evolutionary Robotics From Intelligent Robotics to Artificial Life, pp. 72-93. , T. Gomi (Ed.), Tokyo: Springer-Verlag; Brosnan, S., de Waal, F.B.M., Monkeys Reject Unequal Pay (2003) Nature, 425, pp. 297-299; Brown, J.S., Don't Count Society Out: A Response to Bill Joy (2001) Societal Implications of Nanoscience and Nanotechnology, pp. 37-46. , M.C. Roco & W.S. Bainbridge (Eds.), New York: Springer; Bryson, J., Kime, P., (1998) Just Another Artifact: Ethics and the Empirical Experience of AI, , Paper presented at the Fifteenth International Congress on Cybernetics, Namur, Belgium; Bynum, T.W., (1985) Computers and Ethics, , Malden, MA: Blackwell; Bynum, T.W., A Very Short History of Computer Ethics (2000) American Philosophical Association Newsletter on Philosophy and Computing, 99 (2), pp. 163-165; Bynum, T.W., Computer Ethics: Its Birth and Its Future (2001) Ethics and Information Technology, 3 (2), pp. 109-112; Calverley, D., (2005) Towards a Method for Determining the Legal Status of a Conscious Machine, , Paper presented at the Artificial Intelligence and the Simulation of Behavior '05: Social Intelligence and Interaction in Animals, Robots and Agents: Symposium on Next Generation Approaches to Machine Consciousness, Hatfield, UK; Campbell, M., An Enjoyable Game: How HAL Plays Chess (1997) HAL's Legacy: 2001's Computer as Dream and Reality, pp. 75-98. , D. Stork (Ed.), Cambridge, MA: MIT Press; Campbell, M., Hoane, A.J., Hsu, F., Deep Blue (2002) Artificial Intelligence, 134, pp. 57-83; Canamero, L.D., Emotion Understanding from the Perspective of Autonomous Robots Research (2005) Neural Networks, 18, pp. 445-455; Capek, K., (1920) Rossum's Universal Robots, , New York: Simon and Schuster; Carpenter, J., Eliot, M., Schultheis, D., (2006) Machine or Friend: Understanding Users' Preferences for and Expectations of a Humanoid Robot Companion, , September, Paper presented at the Fifteenth Conference on Design and Emotion, Gothenburg, Sweden; Carsten Stahl, B., Information, Ethics, and Computers: The Problem of Autonomous Agents (2004) Minds and Machines, 14 (1), pp. 67-83; Casebeer, W., (2003) Natural Ethical Facts: Evolution, Connectionism, and Moral Cognition, , Cambridge, MA: MIT Press; Chalmers, D.J., (1996) The Conscious Mind, , Oxford: Oxford University Press; Chaput, H.H., Kuipers, B., Miikkulainen, R., Constructivist Learning: A Neural Implementation of the Schema Mechanism (2003), September, Paper presented at the Workshop for Self-Organizing Maps '03, Kitakyushu, Japan; Chomsky, N., (1965) Aspects of the Theory of Syntax, , Cambridge, MA: MIT Press; Chomsky, N., (1985) Syntactic Structures, , Berlin: Mouton; Chopra, S., White, L., Artificial Agents-Personhood in Law and Philosophy (2004) European Conference on Artificial Intelligence, 16, pp. 635-639; Churchland, P.M., (1989) A Neurocomputational Perspective: The Nature of Mind and the Structure of Science, , Cambridge, MA: MIT Press; Churchland, P.M., (1995) The Engine of Reason, The Seat of the Soul: A Philosophical Journey into the Brain, , Cambridge, MA: MIT Press; Churchland, P.M., The Neural Representation of the Social World (1996) Mind and Morals: Essays on Cognitive Science and Ethics, pp. 91-108. , L. May, M. Friedman & A. Clark (Eds.), Cambridge, MA: MIT Press; Clark, A., Connectionism, Moral Cognition, and Collaborative Problem Solving (1996) Mind and Morals: Essays on Cognitive Science and Ethics, pp. 109-127. , L. May, M. Friedman, & A. Clark (Eds.), Cambridge, MA: MIT Press; Clark, A., (1998) Being There: Putting Brain, Body, and World Together Again, , Cambridge, MA: MIT Press; Clark, A., (2003) Natural-Born Cyborgs: Minds, Technologies, and the Future of Human Intelligence, , Cambridge, MA: MIT Press; Clark, J., (2002) Paris Says "Oui" to Driverless Trains, , http://tube.tfl.gov.uk/content/metro/02/0207/11/Default.asp,http://web.archive.org/web/20040211000716/http://tube.tfl.gov.uk/content/metro/02/0207/11/Default.asp, Transport for London website. Originally retrieved from and now archived at The Internet Archive at; Clarke, R., Asimov's Laws of Robotics: Implications for Information Technology (1) (1993) IEEE Computer, 26 (12), pp. 53-61; Clarke, R., Asimov's Laws of Robotics: Implications for Information Technology (2) (1994) IEEE Computer, 27 (1), pp. 57-66; Coleman, K.G., Android Arete: Towards a Virtue Ethic for Computational Agents (2001) Ethics and Information Technology, 3 (4), pp. 247-265; Comte-Sponville, A., (2001) A Small Treatise on Great Virtues; The Uses of Philosophy in Everyday Life, , (C. Temerson, Trans.). New York: Metropolitan Books; Conway, M.A., Sensory-Perceptual Episodic Memory and Its Context:Autobiographical Memory (2002) Episodic Memory, pp. 53-70. , A. D. Baddeley, M. Conway, & J. Aggleton (Eds.), Oxford: Oxford University Press; Coopersmith, J., The Role of the Pornography Industry in the Development of Videotape and the Internet (1999) IEEE International Symposium on Technology and Society-Women and Technology: Historical, Societal, and Professional Perspectives, pp. 175-182. , New Brunswick, NJ; Cotterill, R.M.J., CyberChild: A Simulation Test-Bed for Consciousness Studies (2003) Journal of Consciousness Studies, 10, pp. 31-45; D'Mello, S.K., Ramamurthy, U., Franklin, S., (2005) Encoding and Retrieval Efficiency of Episodic Data in a Modified Sparse Distributed Memory System, , Paper presented at the Twenty-seventh Annual Conference of the Cognitive Science Society, Strassa, Italy; D'Mello, S.K., Ramamurthy, U., Negatu, A., Franklin, S., A Procedural Learning Mechanism for Novel Skill Acquisition (2006) Adaptation in Artificial and Biological Systems, AISB '06, 1, pp. 184-185. , T. Kovacs & J. A. R. Marshall (Eds.), Bristol, UK: Society for the Study of Artificial Intelligence and the Simulation of Behaviour; Damasio, A., (1994) Descartes' Error: Emotion, Reason, and the Human Brain, , New York: Putnam; Damasio, A., (1999) The Feeling of What Happens: Body and Emotion in the Making of Consciousness, , New York: Harcourt Brace; Dancy, J., (1993) Moral Reasons, , Malden, MA: Blackwell; Dancy, J., (1998) Can a Particularist Learn the Difference between Right and Wrong?, , Paper presented at the Twentieth World Congress of Philosophy, Boston; Dancy, J., Moral Particularism. (2005) The Stanford Encyclopedia of Philosophy (Summer 2005 Edition), , http://plato.stanford.edu/archives/sum2005/entries/moral-particularism, E. N. Zalta (Ed.); Danielson, P., (1992) Artificial Morality: Virtuous Robots for Virtual Games, , New York: Routledge; Danielson, P., (1998) Modeling Rationality, Morality and Evolution, , Oxford:Oxford University Press; Danielson, P., (2003) Modeling Complex Ethical Agents, , Paper presented at the conference on Computational Modeling in the Social Sciences, Seattle, Washington; Danielson, P., (2006) From Artificial Morality to NERD: Models, Experiments, & Robust Reflective Equilibrium, , Paper presented at the EthicALife Workshop of the ALifeX Conference, Bloomington, Indiana; Darley, J.M., Batson, C.D., From Jerusalem to Jericho: A Study of Situational and Dispositional Variables in Helping Behavior (1973) Journal of Personality and Social Psychology, 27, pp. 100-108; Darwin, C., (1860) Origin of Species, 11. , (Harvard Classics). New York:Bartleby Press; Darwin, C., (1872) The Expression of Emotions in Man and Animals, , London:John Murray; Darwin, C., (1871) The Descent of Man, , New York: Penguin; Das, P., Kemp, A.H., Liddell, B.J., Brown, K.J., Olivieri, G., Peduto, A., Gordon, E., Williams, L.M., Pathways for Fear Perception:Modulation of Amygdala Activity by Thalamo-Cortical Systems (2005) NeuroImage, 26, pp. 141-148; Dautenhahn, K., (2002) Socially Intelligent Agents: Creating Relationships with Computers and Robots, , New York: Springer; Davachi, L., Mitchell, J.P., Wagner, A.D., Multiple Routes to Memory: Distinct Medial Temporal Lobe Processes Build Item and Source Memories (2003) Proceedings of the National Academy of Sciences, 100, pp. 2157-2162; Davidson, R.J., Maxwell, J.S., Shackma, A.J., The Privileged Status of Emotion in the Brain (2004) Proceedings of the National Academy of Sciences, 101, pp. 11915-11916; Dawkins, R., (1989) The Selfish Gene, , Oxford: Oxford University Press; de Garis, H., The Twenty-first-century Artilect: Moral Dilemmas Concerning the Ultra-intelligent Machine (1990) Revue Internationale de Philosophie, 44, pp. 131-138; de Garis, H., (2005) The Artilect War: Cosmists vs. Terrans: A Bitter Controversy Concerning Whether Humanity Should Build Godlike Massively Intelligent Machines, , Palm Springs, CA: ETC; de Martino, B., Kumaran, D., Seymour, B., Dolan, R.J., Frames, Biases, and Rational Decision-Making in the Human Brain (2006) Science, 313, pp. 684-687; de Sousa, R., (1987) The Rationality of Emotion, , Cambridge, MA: MIT Press; de Waal, F.B.M., (2006) Primates and Philosophers: How Morality Evolved, , Princeton, NJ: Princeton University Press; Dehaene, S., (2002) The Cognitive Neuroscience of Consciousness, , Cambridge, MA: MIT Press; Dehaene, S., Changeux, J., Naccache, L., Sackur, J., Sergent, C., Conscious, Preconscious, and Subliminal Processing: A Testable Taxonomy (2006) Trends in Cognitive Sciences, 10, pp. 204-211; DeMoss, D., Aristotle, Connectionism, and the Morally Excellent Brain. The Paideia project on-line (1998) Proceedings of the Twentieth World Congress of Philosophy, , www.bu.edu/wcp/Papers/Cogn/CognDemo.htm, American Organizing Committee Inc., Boston; Dennett, D.C., Cog: Steps towards Consciousness in Robots (1995) Conscious Experience, pp. 471-487. , T. Metzinger (Ed.), Thorverton, UK: Imprint Academic; Dennett, D.C., When Hal Kills, Who's to Blame? (1996) Hal's Legacy, pp. 351-365. , D. Stork (Ed.), Cambridge, MA: MIT Press; Dennett, D.C., Cog as a Thought Experiment (1997) Robotics and Autonomous Systems, 20 (2-4), pp. 251-256; Dennett, D.C., Consciousness in Human and Robot Minds (1997) Proceedings of the IIAS Symposium on Cognition, Computation, and Consciousness, pp. 17-30. , M. Ito, Y. Miyashita, & E. T. Rolls (Eds), New York: Oxford University Press; Dennett, D.C., (2003) Freedom Evolves, , New York: Viking; Descartes, R., (1978) The Philosophical Works of Descartes, , (E. S. Haldane & G. R. T. Ross, Trans.). Cambridge, UK: Cambridge University Press; Diamond, D., The Love Machine (2003) Wired, 11 (12). , www.wired.com/wired/archive/11.12/love.html, December; Dietrich, E., After the Humans Are Gone (2007) Journal of Experimental and Theoretical Artificial Intelligence, 19 (1), pp. 55-67; Doris, J.M., (2002) Lack of Character: Personality and Moral Behavior, , Cambridge, UK: Cambridge University Press; Drescher, G.L., (1991) Made-Up Minds: A Constructivist Approach to Artificial Intelligence, , Cambridge, MA: MIT Press; Dreyfus, H., (1979) What Computers Can't Do: The Limits of Artificial Intelligence, , New York: Harper Colophon Books; Dreyfus, H., Dreyfus, S., What Is Morality? A Phenomenological Account of the Development of Ethical Expertise (1990) Universalism vs. Communitarianism: Contemporary Debates in Ethics, pp. 237-264. , D. Rasmussen (Ed.), Cambridge, MA: MIT Press; Duffy, B.R., Joue, G., The Paradox of Social Robotics: A Discussion (2005) Machine Ethics: Papers From The AAAI Fall Symposium, , M. Anderson, S.L. Anderson, & C. Armen (Cochairs), Arlington, VA: AAAI Press; Edelman, G.M., (1987) Neural Darwinism, , New York: Basic Books; Ekman, P., Facial Expression of Emotion (1993) American Psychologist, 48, pp. 384-392; Engelberger, J.F., (1989) Robotics in Service, , Cambridge, MA: MIT Press; Epstein, R., (1996) The Case of the Killer Robot: Stories about the Professional, Ethical, and Societal Dimensions of Computing, , New York:Wiley; Estes, W.K., (1993) Classification and Cognition, , Oxford: Oxford University Press; Ferbinteanu, J., Shapiro, M.L., Prospective and Retrospective Memory Coding in the Hippocampus (2003) Neuron, 40, pp. 1227-1239; Flack, J., de Waal, F.B.M., 'Any Animal Whatever': Darwinian Building Blocks of Morality in Monkeys and Apes (2000) Evolutionary Origins of Morality, pp. 1-30. , L. Katz (Ed.), Thorverton, UK: Imprint Academic; Flavell, J.H., Metacognition and Cognitive Monitoring: A New Area of Cognitive-Developmental Inquiry (1979) American Psychologist, 34, pp. 906-911; Floridi, L., Sanders, J.W., Artificial Evil and the Foundation of Computer Ethics (2001) Ethics and Information Technology, 3 (1), pp. 55-66; Floridi, L., Sanders, J.W., On the Morality of Artificial Agents (2004) Minds and Machines, 14 (3), pp. 349-379; Foerst, A., (2005) God in the Machine: What Robots Teach Us about Humanity and God, , New York: Plume; Fogg, B.J., Nass, C., Silicon Sycophants: The Effects of Computers That Flatter (1997) Journal of Human-Computer Studies, 46, pp. 551-561; Foot, P., The Problem of Abortion and the Doctrine of Double Effect (1967) Oxford Review, 5, pp. 5-15; Foot, P., Moral Beliefs (1967) Theories of Ethics, pp. 83-100. , P. Foot (Ed.), Oxford: Oxford University Press; Ford, K., Glymour, C., Hayes, P., (1995) Android Epistemology, , Menlo Park, CA: AAAI Press; Ford, K., Glymour, C., Hayes, P., (2006) Thinking about Android Epistemology, , Cambridge, MA: MIT Press; Franklin, S., Deliberation and Voluntary Action in "Conscious" Software Agents (2000) Neural Network World, 10, pp. 505-521; Franklin, S., A "Consciousness" Based Architecture for a Functioning Mind (2001) Visions Of Mind, pp. 149-175. , D. Davis, (Ed.), Hershey, PA: IDEA Group, Inc; Franklin, S., Conscious Software: A Computational View of Mind (2001) Soft Computing Agents: New Trends for Designing Autonomous Systems, pp. 1-46. , V. Loia & S. Sessa (Eds.), Berlin, GE: Springer (Physica-Verlag); Franklin, S., IDA: A Conscious Artifact? (2003) Journal of Consciousness Studies, 10, pp. 47-66; Franklin, S., Cognitive Robots: Perceptual Associative Memory and Learning (2005) Proceedings of the Fourteenth Annual International Workshop on Robot and Human Interactive Communication (RO-MAN 2005), pp. 427-433. , Paper presented at; Franklin, S., Evolutionary Pressures and a Stable World for Animals and Robots: A Commentary on Merker (2005) Consciousness and Cognition, 14, pp. 115-118; Franklin, S., (2005) Perceptual Memory and Learning: Recognizing, Categorizing, and Relating, , March, Paper presented at American Association for Artificial Intelligence Symposium on Developmental Robotics, Palo Alto, CA; Franklin, S., Baars, B.J., Ramamurthy, U., Ventura, M., The Role of Consciousness in Memory (2005) Brains, Minds and Media, 1, pp. 1-38; Franklin, S., Graesser, A.C., Is It an Agent, or Just a Program? A Taxonomy for Autonomous Agents (1997) Intelligent Agents III, pp. 21-35. , J. Muller, M. Woolridge, & N.R. Jennings (Eds.), Berlin: Springer Verlag; Franklin, S., McCauley, L., Feelings and Emotions as Motivators and Learning Facilitators (2004) Architectures for Modeling Emotion: Cross-Disciplinary Foundations, AAAI 2004 Spring Symposium Series, pp. 48-51. , E. Hudlicka & L. Cañamero (Co-chairs), Technical Report, Palo Alto, CA:AAAI Press; Franklin, S., Ramamurthy, U., Motivations, Values and Emotions:Three Sides of the Same Coin (2006) Proceedings of the Sixth International Workshop on Epigenetic Robotics, 128, pp. 41-48. , Paris: Lund University Cognitive Studies; Freeman, W.J., (1999) How Brains Make Up Their Minds, , London: Weidenfeld and Nicolson; Freeman, W.J., The Wave Packet: An Action Potential for the Twentyfirst Century (2003) Journal of Integrative Neuroscience, 2, pp. 3-30; Friedman, B., (1995) It's the Computer's Fault: Reasoning about Computers as Moral Agents, , Paper presented at the Conference on Human Factors in Computing Systems, Denver, Colorado; Friedman, B., Kahn, P., Human Agency and Responsible Computing:Implications for Computer System Design (1992) Journal of Systems and Software, 17, pp. 7-14; Friedman, B., Nissenbaum, H., Bias in Computer Systems (1996) ACM Transactions on Information Systems, 14 (3), pp. 330-347; Gadanho, S.C., Learning Behavior-Selection by Emotions and Cognition in a Multi-Goal Robot Task (2003) Journal of Machine Learning Research, 4, pp. 385-412; Gardner, A., (1987) An Artificial Approach to Legal Reasoning, , Cambridge, MA: MIT Press; Garreau, J., Bots on the Ground: In the Field of Battle (Or Even above It), Robots Are a Soldier's Best Friend (2007) Washington Post, , May 6; Gazzaniga, M.S., The Believing Brain (2005) The Ethical Brain, pp. 145-162. , New York: Dana Press; Georges, T.M., (2003) Digital Soul: Intelligent Machines and Human Values, , Cambridge, MA: Westview Press; Gert, B., (1988) Morality, , Oxford: Oxford University Press; Gertner, R., Lawyers Are Turning to Old Websites for Evidence (2005) Lawyer's Weekly USA, , August 15; Gibson, J.J., (1979) The Ecological Approach to Visual Perception, , Mahwah, NJ: Erlbaum; Gigerenzer, G., Selten, R., (2002) Bounded Rationality: The Adaptive Toolbox, , Cambridge, MA: MIT Press; Gigerenzer, G., Todd, P., Group, T.A.R., (1999) Simple Heuristics That Make Us Smart, , Oxford: Oxford University Press; Gilligan, C., (1982) In a Different Voice: Psychological Theory and Women's Development, , Cambridge, MA: Harvard University Press; Gips, J., Towards the Ethical Robot (1991) Android Epistemology, pp. 243-252. , K. G. Ford, C. Glymour, & P.J. Hayes (Eds.), Cambridge, MA: MIT Press; Gips, J., Creating Ethical Robots: A Grand Challenge (2005) AAAI Fall 2005 Symposium on Machine Ethics, pp. 1-7. , M. Anderson, S.L. Anderson, & Armen, C. (Co-chairs), Alexandria, VA: AAAI Press; Glenberg, A.M., What Memory Is For (1997) Behavioral and Brain Sciences, 20, pp. 1-19; Goertzel, B., Thoughts on AI Morality (2002) Dynamic Psychology, , www.goertzel.org/dynapsyc/2002/AIMorality.htm, May; Goertzel, B., (2008) An Integrative Methodology for Teaching Embodied Non-Linguistic Agents, Applied to Virtual Animals in Second Life, , Paper presented at First Conference on Artificial General Intelligence (AGI-08), Memphis, TN; Goertzel, B., Pennachin, C., (2007) Artificial General Intelligence, , Berlin:Springer; Goertzel, B., Pennachin, C., Bugaj, S.V., The Novamente AGI Engine: An Artificial General Intelligence in the Making (2002), http://inteligenesiscorp.com/agiriorg/article.htm, March; Goldin, I.M., Ashley, K.D., Pinkus, R.L., (2001) Introducing PETE:Computer Support for Teaching Ethics, , Paper presented at the Eighth International Conference on Artificial Intelligence and Law, St. Louis, Missouri; Goleman, D., (1995) Emotional Intelligence, , New York: Bantam Books; Good, I.J., (1982) Ethical Machines, , Paper presented at the Tenth Machine Intelligence Workshop, Cleveland, Ohio; Goodale, M.A., Milner, D., (2004) Sight Unseen, , Oxford: Oxford University Press; Grau, C., There Is No "I" in "Robots": Robots and Utilitarianism (2006) IEEE Intelligent Systems, 21 (4), pp. 52-55; Greene, J., Haidt, J., How (and Where) Does Moral Judgment Work? (2002) Trends in Cognitive Sciences, 6 (12), pp. 517-523; Greene, J.D., Nystrom, L.E., Engell, A.D., Darley, J.M., Cohen, J.D., The Neural Bases of Cognitive Conflict and Control in Moral Judgment (2004) Neuron, 44, pp. 389-400; Greene, J.D., Sommerville, R.B., Nystrom, L.E., Darley, J.M., Cohen, J.D., An fMRI Investigation of Emotional Engagement in Moral Judgment (2001) Science, 293, pp. 2105-2108; Gross, M., It's My (Virtual) World. (2006) New York Times, , November 3; Guarini, M., Particularism and Classification and Reclassification of Moral Cases (2006) IEEE Intelligent Systems, 21 (4), pp. 22-28; Guth, W., Schmittberger, R., Schwarze, B., An Experimental Analysis of Ultimatum Bargaining (1982) Journal of Economic Behavior and Organization, 3 (4), pp. 367-388; Hahn, C.S., Fley, B., Florian, M., (2005) A Framework for the Design of Self-Regulation of Open Agent-Based Electronic Marketplace, , Paper presented at the Artificial Intelligence and the Simulation of Behavior '05 Convention, Social Intelligence and Interaction in Animals, Robots and Agents: Symposium on Normative Multi-Agent Systems, Hatfield, UK; Haidt, J., The Emotional Dog and Its Rational Tail: A Social Intuitionist Approach to Moral Judgment (2001) Psychology Review, 108, pp. 814-834; Haidt, J., The Moral Emotions (2003) Handbook of Affective Sciences, pp. 852-870. , R. J. Davidson, K. R. Scherer, & H. H. Goldsmith (Eds.), Oxford:Oxford University Press; Haidt, J., The New Synthesis in Moral Psychology (2007) Science, 316, pp. 998-1002; Hall, J.S., (2000) Ethics for Machines, , http://autogeny.org/ethics.html; Hall, J.S., (2007) Beyond AI: Creating the Conscience of the Machine, , Amherst, NY: Prometheus Books; Hambling, D., Armed Robots Go into Action (2007) Wired Blog Network, , http://blog.wired.com/defense/2007/09/robosoldiers-hi.html, September 10; Hamilton, E., Cairns, H., (1961) The Collected Dialogues of Plato, Including the Letters, , (Cooper, L., Trans.). Princeton, NJ: Princeton University Press; Hare, R., (1981) Moral Thinking: Its Levels, Methods, and Point, , Oxford:Oxford University Press; Harms, W., Biological Altruism in Hostile Environments (1999) Complexity, 5 (2), pp. 23-28; Harms, W., The Evolution of Altruism in Hostile Environments (2000) Evolutionary Origins of Morality, pp. 308-312. , L.D. Katz (Ed.), Exeter, UK: Imprint Academic; Harnad, S., Can a Machine Be Conscious? How? (2003) Journal of Consciousness Studies, 10 (4-5), pp. 69-75; Hauser, M.D., (2000) Wild Minds, , New York: Holt; Hauser, M.D., (2006) Moral Minds: How Nature Designed Our Universal Sense of Right and Wrong, , New York: Ecco; Hauser, M.D., Cushman, F., Young, L., Jin, R.K., Mikhail, J., A Dissociation between Moral Judgment and Justification (2007) Mind and Language, 22 (1), pp. 1-21; Heilman, K.M., The Neurobiology of Emotional Experience (1997) Journal of Neuropsychiatry and Clinical Neuroscience, 9, pp. 439-448; Henig, R.M., The Real Transformers (2007) New York Times Magazine, , July 29; Hexmoor, H., Castelfranchi, C., Falcone, R., (2003) Agent Autonomy, , New York: Springer; Hibbard, B., Super-Intelligent Machines (2000) Computer Graphics, 35 (1), pp. 11-13; Hibbard, B., (2003) Critique of the SIAI Guidelines on Friendly AI, , www.ssec.wisc.edu/billh/g/SIAI_critique.html; Hill, R.J., The Automation of Railways (1983) Physics in Technology, 14, pp. 37-47; Hodges, A., (1992) Alan Turing: The Enigma, , New York: Simon and Schuster; Hoffman, M., (2000) Empathy and Moral Development: Implications for Caring and Justice, , Cambridge, UK: Cambridge University Press; Hofstadter, D.R., Mitchell, M., The Copycat Project: A Model of Mental Fluidity and Analogy-Making (1995) Advances in Connectionist and Neural Computation Theory, Vol. 2: Logical Connections, pp. 205-267. , K. J. Holyoak & J. Barnden (Eds.), Norwood, NJ: Ablex; Holland, J.H., Outline for a Logical Theory of Adaptive Systems (1962) Journal of the Association for Computing Machinery, 9, pp. 297-314; Holland, J.H., (1975) Adaptation in Natural and Artificial Systems, , Ann Arbor:University of Michigan; Holland, J.H., Genetic Algorithms (1992) Scientific American, 267 (1), pp. 66-72; Holland, O., Special issue on Machine Consciousness (2003) Journal of Consciousness Studies, 10 (4-5); Holland, O., (2003) Machine Consciousness, , Thorverton, UK: Imprint Academic; Holland, O., Goodman, R., Robots with Internal Models: A Route to Machine Consciousness (2003) Machine Consciousness, pp. 77-110. , O. Holland (Ed.), Thorverton, UK: Imprint Academic; Howell, S.R., (1999) Neural Networks and Philosopy: Why Aristotle was a Connectionist, , www.psychology.mcmaster.ca/beckerlab/showell/aristotle.pdf; Hume, D., (1739) A Treatise on Human Nature, , 40, Oxford: Oxford University Press; Irrgang, B., Ethical Acts in Robotics (2006) Ubiguity, 7 (34), pp. 241-250; Isen, A.M., Levin, P.F., The Effect of Feeling Good on Helping:Cookies and Kindness (1972) Personality and Social Psychology, 21, pp. 382-388; Ishiguro, H., (2005) Android Science: Towards a New Cross-Disciplinary Framework, , July, Paper presented at the CogSci-2005 Workshop: Towards Social Mechanisms of Android Science, Stresa, Italy; ISO Robot Safety Standards, Standard No. 10218-1: 2006 (2006), International Organization for Standardization; Jablonka, E., Lamb, M., (2005) Evolution in Four Dimensions:Genetic, Epigenetic, Behavioral, and Symbolic Variation in the History of Life, , Cambridge, MA: MIT Press; Jackson, J.V., Idea for a Mind (1987) ACM Siggart Bulletin, 101, pp. 23-26; James, W., (1890) The Principles of Psychology, , Cambridge, MA: Harvard University Press; John, D., (1993) Moral Reasons, , Oxford: Blackwell; Johnson, D., (1985) Computer Ethics, , New York: Prentice-Hall; Johnson, M., (1993) Moral Imagination: Implications of Cognitive Science for Ethics, , Chicago: University of Chicago Press; Johnston, V.S., (1999) Why We Feel: The Science of Human Emotions, , Reading, MA: Perseus Books; Jonsen, A.R., Toulmin, S., (1988) The Abuse of Casuistry: A History of Moral Reasoning, , Berkeley: University of California Press; Joy, B., Why the Future Doesn't Need Us (2000) Wired, 8 (4). , www.wired.com/wired/archive/8.04/joy_pr.html, April; Kaelbling, L.P., Littman, M.L., Moore, A.W., Reinforcement Learning: A Survey (1996) Journal of Artificial Intelligence Research, 4, pp. 237-285; Kahn, A.F.U., The Ethics of Autonomous Learning Systems (1995) Android Epistemology, pp. 243-252. , K. Ford, C. Glymour, & P. Hayes (Eds.), Cambridge, MA: MIT Press; Kahneman, D., Slovic, P., Tversky, A., (1982) Judgment under Uncertainty:Heuristics and Biases, , Cambridge, MA: Cambridge University Press; Kanerva, P., (1988) Sparse Distributed Memory, , Cambridge, MA: MIT Press; Kant, E., (1785) Groundwork of the Metaphysics of Morals, , Cambridge, UK: Cambridge University Press; Kara, D., (2005) Sizing and Seizing the Robotics Opportunity., , www.robnexus.com/roboticsmarket.htm; Kassan, P., A.I. Gone Awry: The Futile Quest for Artificial Intelligence (2006) Skeptic, 12 (2), pp. 30-39; Katz, L., (2000) Evolutionary Origins of Morality: Cross-Disciplinary Perspectives, , Thorverton, UK: Imprint Academic; Kennedy, C., Agents for Trustworthy Ethical Assistance (2004) Sixteenth International Conference on Systems Research, Informatics and Cybernetics: Symposium on Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, 3, pp. 15-20. , I. Smit, W. Wallach, & G. Lasker (Eds.), Windsor, Ontario, Canada: International Institute for Advanced Studies in Systems Research and Cybernetics; Kennedy, C.M., (2000) Reducing Indifference: Steps towards Autonomous Agents with Human Concerns, , Paper presented at the Convention of the Society for Artificial Intelligence and Simulated Behavior, Symposium on AI, Ethics and (Quasi-) Human Rights, Birmingham, UK; Knutton, M., The Future Lies in Driverless Metros (2002) International Railway Journal, , http://findarticles.com/p/articles/mi_m0BQQ/is_6_42/88099079, June; Kohlberg, L., Stage and Sequence: The Cognitive-Developmental Approach to Socialization (1969) Handbook of Socialization Theory and Research, pp. 347-480. , D. A. Gosli (Ed.), Chicago: Rand-McNally; Kohlberg, L., (1981) Essays on Moral Development, Vol. 1: The Philosophy of Moral Development, , San Francisco: Harper & Row; Kohlberg, L., (1984) Essays on Moral Development, Vol. 2: The Psychology of Moral Development, , San Francisco: Harper & Row; Kolcaba, R., Angelic Machines: A Philosophical Dialogue (2001) Ethics and Information Technology, 2 (1), pp. 11-17; Kraus, S., (2001) Strategic Negotiation in Multiagent Environments, , Cambridge, MA: MIT Press; Krazit, T., My Friend the Robot (2006) CNET News, , May 24; Kuflik, A., Computers in Control: Rational Transfer of Authority or Irresponsible Abdication of Autonomy? (2001) Ethics and Information Technology, 1 (3), pp. 173-184; Kurzweil, R., (1999) The Age of Spiritual Machines: When Computers Exceed Human Intelligence, , New York: Viking Press; Kurzweil, R., Promise and Peril (2000) Interactive Week, , October 23; Kurzweil, R., (2005) The Singularity Is Near: When Humans Transcend Biology, , New York: Viking; LaChat, M.R., Moral Stages in the Evolution of the Artificial Superego:A Cost-Benefits Trajectory (2003) Fifteenth International Conference on Systems Research, Informatics and Cybernetics: Symposium on Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, 2, pp. 18-24. , I. Smit, W. Wallach, & G. Lasker (Eds.), Windsor, Ontario, Canada: International Institute for Advanced Studies in Systems Research and Cybernetics; LaChat, M.R., "Playing God" and the Construction of Artificial Persons (2004) Sixteenth International Conference on Systems Research, Informatics and Cybernetics, 3, pp. 39-44. , I. Smit, W. Wallach, & G. Lasker (Eds.), Windsor, Ontario, Canada: International Institute for Advanced Studies in Systems Research and Cybernetics; Lakoff, G., (1987) Women, Fire, and Dangerous Things-What Categories Reveal about the Mind, , Chicago: University of Chicago Press; Lakoff, G., Metaphor, Morality, and Politics, Or, Why Conservatives Have Left Liberals in the Dust (1995) Social Research, 62 (2), pp. 177-214; Lakoff, G., Johnson, M., (1980) Metaphors We Live By, , Chicago: University of Chicago Press; Lang, C., (2002) Ethics for Artificial Intelligences, , Paper presented at Wisconsin State-Wide Technology Symposium "Promise or Peril? Reflecting on Computer Technology: Educational, Psychological, and Ethical Implications," Madison, Wisconsin; Latané, B.D., Darley, J.M., (1970) The Unresponsive Bystander: Why Doesn't He Help?, , New York: Appleton-Century Crofts; Lazarus, R., (1991) Emotion and Adaptation, , Oxford: Oxford University Press; LeDoux, J., (1996) The Emotional Brain: The Mysterious Underpinnings of Emotional Life, , New York: Simon & Schuster; Lehman-Wilzig, S., Frankenstein Unbound: Towards a Legal Definition of Artificial Intelligence (1981) Futures, pp. 442-457. , December; Lenggenhager, B., Tadi, T., Metzinger, T., Blanke, O., Video Ergo Sum (2007) Science, 317, pp. 1096-1099; Levy, D., (2007) Love and Sex with Robots: The Evolution of Human-Robot Relationships, , New York: HarperCollins; Lewis, J., Robots of Arabia (2005) Wired, 13 (11), pp. 188-195; Libet, B., Do We Have Free Will? (1999) Journal of Consciousness Studies, 6, pp. 47-57; Libet, B., Gleason, C.A., Wright, E.W., Pearl, D.K., Time of Conscious Intention to Act in Relation to Onset of Cerebral Activity (Readiness-Potential): The Unconscioous Initiation of a Freely Voluntary Act (1983) Brain, 106, pp. 623-642; Lisetti, C., Developing Multimodal Intelligent Affective Interfaces for Tele-Home Health Care (2003) International Journal of Human-Computer Studies, 59 (1-2), pp. 245-255; Logical Endings: Computers May Soon Be Better Than Kin at Predicting the Wishes of the Dying (2007) Economist, , p. 63; Longnian, L., Neural Encoding of the Concept of Nest in the Mouse Brain (2007) Proceedings of the National Academy of Sciences, 10, p. 1073; Looks, M., Goertzel, B., Pennachin, C., Novamente: An Integrative Architecture for General Intelligence (2004) AAAI Symposium: "Achieving Human-Level Intelligence via Integrated Systems and Research.", , N. Cassimatis & P. Winston (Co-chairs), Alexandria, VA: AAAI Press; Lorenz, E., Predictability: Does the Flap of a Butterfly' Wings in Brazil Set Off a Tornado in Texas? (1972), December, Paper presented to the American Association for the Advancement of Science. Washington, DC; MacDorman, K.F., (2006) Subjective Ratings of Robot Video Clips for Human Likeness, Familiarity, and Eeriness: An Exploration of the Uncanny Valley, , Paper presented at the International Conference of the Cognitive Science/CogSci-2006 Long Symposium: Toward Social Mechanisms of Android Science, Vancouver, Canada; Maes, P., How to Do the Right Thing (1989) Connection Science, 1, pp. 291-323; Maes, P., A Bottom-Up Mechanism for Behavior Selection in an Artificial Creature (1991) Proceedings of the First International Conference on Simulation of Adaptive Behavior: From Animals to Animats, pp. 238-246. , J. Meyer & S. W. Wilson (Eds.), Cambridge, MA: MIT Press; Malinowski, B., (1944) A Scientific Theory of Culture, , Raleigh: University of North Carolina Press; Maner, W., Heuristic Methods for Computer Ethics (2002) Cyberphilosophy: The Intersection of Philosophy and Computing, pp. 339-365. , J. H. Moor & T. W. Bynum (Eds.), Malden, MA: Blackwell; Markowitsch, H.J., Neuroanatomy of Memory (2000) The Oxford Handbook of Memory, pp. 465-484. , E. Tulving & F. I. M. Craik (Eds.), Oxford: Oxford University Press; Marks, P., Robot Infantry Get Ready for the Battlefield (2006) New Scientist, , September 21; Marshall, J., (2002) Metacat: A Self-Watching Cognitive Architecture for Analogy-Making, , August, Paper presented at the twenty-fourth annual conference of the Cognitive Science Society, Fairfax, VA; Martin, J., (2000) After the Internet: Alien Intelligence, , Washington, DC:Capital Press; Massimini, M., Ferrarelli, F., Huber, R., Esser, S.K., Singh, H., Tononi, G., Breakdown of Cortical Effective Connectivity during Sleep (2005) Science, 309, pp. 2228-2232; Maturana, H.R., Varela, F.J., (1980) Autopoiesis and Cognition: The Realization of the Living, , New York: Springer; May, L., Freidman, M., Clark, A., (1996) Mind and Morals: Essays on Ethics and Cognitive Science, , Cambridge, MA: MIT Press; McCarthy, J., (1995) Making Robots Conscious of Their Mental States, , www.formal.stanford.edu/jmc/consciousness/consciousness.html; McCauley, L., Franklin, S., A Large-Scale Multi-Agent System for Navy Personnel Distribution (2002) Connection Science, 14, pp. 371-385; McDermott, D., We've Been Framed: Or, Why AI Is Innocent of the Frame Problem (1988) The Robot' Dilemma: The Frame Problem in Artificial Intelligence, pp. 113-122. , Z. W. Pylyshyn (Ed.), Norwood, NJ: Ablex; McDermott, D., Why Ethics is a High Hurdle for AI (2008) 2008 North American Conference on Computing and Philosophy, , Paper presented at Bloomington, Indiana; McGinn, C., (1999) The Mysterious Flame: Conscious Minds in a Material World, , New York: Basic Books; McKeever, S., Ridge, M., The Many Moral Particularisms (2005) Canadian Journal of Philosophy, 35 (1), pp. 83-106; McLaren, B., Extensionally Defining Principles of Machine Ethics: An AI Model (2003) Artificial Intelligence Journal, 150, pp. 145-181; McLaren, B., Computational Models of Ethical Reasoning: Challenges, Initial Steps, and Future Directions (2006) IEEE Intelligent Systems, 21 (4), pp. 29-37; McLaren, B., Ashley, K.D., Case-Based Comparative Evaluation in Truth-Teller (1995) Seventeenth Annual Conference of the Cognitive Science Society, pp. 72-77. , E. Lawrence (Ed.), San Diego, CA; McNally, P., Inayatullah, S., Robots: Technology, Culture and Law in the Twenty-first Century (1988), Metafuture.org/Articles/TheRightsofRobots.htm; Meador, K.J., Ray, P.G., Echauz, J.R., Loring, D.W., Vachtsevanos, G.J., Gamma Coherence and Conscious Perception (2002) Neurology, 59, pp. 847-854; Merker, B., The Liabilities of Mobility: A Selection Pressure for the Transition to Consciousness in Animal Evolution (2005) Consciousness and Cognition, 14, pp. 89-114; Metzinger, T., (2004) Being No One: The Self-Model Theory of Subjectivity, , Cambridge, MA: MIT Press; Mikhail, J., (2000) Rawls' Linguistic Analogy: A Study of the "Generative Grammar" Model of Moral Theory Described by John Rawls in "A Theory of Justice.", , Ithaca, NY: Cornell University Press; Mikhail, J., Sorentino, C., Spelke, E., (1998) Toward a Universal Moral Grammar, , Paper presented at the twentieth annual conference of the Cognitive Science Society, Mahwah, NJ; Mill, J.S., (1864) Utilitarianism, , Oxford: Oxford University Press; Miller, G., The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information (1956) Psychology Review, 63 (2), pp. 81-97; Minsky, M., (1985) The Society of Mind, , New York: Simon & Schuster; Minsky, M., (2006) The Emotion Machine, , New York: Simon & Schuster; Mitchell, T., (1997) Machine Learning, , Boston: McGraw-Hill; Moor, J.H., Are There Decisions Computers Should Never Make? (1979) Nature and System, 1 (4), pp. 217-229; Moor, J.H., Is Ethics Computable? (1995) Metaphilosophy, 26 (1-2), pp. 1-21; Moor, J.H., The Future of Computer Ethics: You Ain't Seen Nothing Yet! (2001) Ethics and Information Technology, 3 (2); Moor, J.H., The Status and Future of the Turing Test (2001) Minds and Machines, 11, pp. 77-93; Moor, J.H., The Nature, Importance, and Difficulty of Machine Ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Moravec, H., (1988) Mind Children: The Future of Robot and Human Intelligence, , Cambridge, MA: Harvard University Press; Moravec, H., (2000) Robot: Mere Machine to Transcendent Mind, , Oxford:Oxford University Press; More, M., (2000) Embrace, Don't Relinquish, the Future, , www.kurzweilai.net/articles/art0106.html?printable=1; Morgenstern, O., von Neumann, J., (1944) Theory of Games and Economic Behavior, , New York: Wiley; Mori, M., Bukimi no tani (The Uncanny Valley) (1970) Energy, 7 (4), pp. 33-35; Mowbray, M., Ethics for Bots (2002) Sixteenth International Conference on Systems Research, Informatics and Cybernetics:Symposium on Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, 1, pp. 24-28. , I. Smit & G. Lasker (Eds.), Windsor, Ontario, Canada: International Institute for Advanced Studies in Systems Research and Cybernetics; Mulcahy, N.J., Call, J., Apes Save Tools for Future Use (2006) Science, 312, pp. 1038-1040; Murakami, Y., (2004) Utilitarian Deontic Logic, , Paper presented at Advances in Modal Logic Fifth International Conference, Manchester, UK; Muramatsu, R., Hanoch, Y., Emotions as a Mechanism for Boundedly Rational Agents: The Fast and Frugal Way (2004) Journal of Economic Psychology, 26 (2), pp. 201-221; Nadel, L., Multiple Memory Systems: What and Why (1992) Journal of Cognitive Neuroscience, 4, pp. 179-188; Nadel, L., Moscovitch, M., Memory Consolidation, Retrograde Amnesia and the Hippocampal Complex (1997) Current Opinions in Neurobiology, 7, pp. 217-227; Nagel, T., What Is It Like to Be a Bat? (1974) Philosophical Review, 83 (4), pp. 435-450; (1996) The NSPE Code of Ethics, , www.onlineethics.diamax.com/CMS/profpractice/ethcodes/13411/9972.aspx; Negatu, A., D'Mello, S.K., Franklin, S., Cognitively Inspired Anticipatory Adaptation and Associated Learning Mechanisms for Autonomous Agents (2007) ABiALS-2006-Anticipatory Behavior in Adaptive Learning Systems, pp. 108-127. , M. V. Butz, O. Sigaud, G. Pezzulo, & G. Baldassarre (Eds.), Rome: Springer; Negatu, A., Franklin, S., An Action Selection Mechanism for "Conscious" Software Agents (2002) Cognitive Science Quarterly, 2, pp. 363-386; Negatu, A., McCauley, T.L., Franklin, S., Automatization for Software Agents (In Review); Nehaniv, C.L., Dautenhahn, K., (2007) Imitation and Social Learning in Robots, Humans and Animals: Behavioral, Social and Communicative Dimensions, , Cambridge, UK: Cambridge University Press; Newell, A., Simon, H.A., Computer Science as Empirical Inquiry:Symbols and Search (1976) Communications of the ACM, 19 (3), pp. 113-126; Newman, S.D., Carpenter, P.A., Varma, S., Just, M.A., Frontal and Parietal Participation in Problem Solving in the Tower of London:fMRI and Computational Modeling of Planning and High-Level Perception (2003) Neuropsychologia, 41, pp. 1668-1682; Nichols, S., (2004) Sentimental Rules: On the Natural Foundations of Moral Judgment, , Oxford: Oxford University Press; Nissenbaum, H., Accountability in a Computerized Society (1996) Science and Engineering Ethics, 2, pp. 25-42; Nissenbaum, H., How Computer Systems Embody Values (2001) Computer, 34 (3), pp. 118-119; Nolfi, N., Floreano, D., (2000) Evolutionary Robotics: The Biology, Intelligence, and Technology of Self-Organizing Machines, , Cambridge, MA:MIT Press; Norman, D., (2004) Emotional Design, , New York: Basic Books; Norvig, P., (2007) The History and Future of Technological Change, , Transcript of a talk presented at the Singularity Summit 2007: AI and the Future of Humanity. San Francisco, CA; Ornstein, R., (1986) Multimind, , Boston: Houghton Mifflin; Ortony, A., Clore, G., Collins, A., (1988) The Cognitive Structure of Emotions, , Cambridge, UK: Cambridge University Press; Oyama, S., (1985) The Ontology of Information, , Cambridge, UK: Cambridge University Press; Panksepp, J., (1998) Affective Neuroscience: The Foundations of Human and Animal Emotions, , Oxford: Oxford University Press; Pascal, B., (1670) Pensées, , Whitefish, MT: Kessinger; Penrose, R., (1989) The Emperor' New Mind: Concerning Computers, Minds, and the Laws of Physics, , Oxford: Oxford University Press; Perkowitz, S., (2005) Digital People: From Bionic Humans to Androids, , Washington, DC: Joseph Henry Press; Pettit, P., Akrasia, Collective and Individual (2003) Weakness of Will and Practical Irrationality, pp. 68-97. , S. Stroud & C. Tappolet (Eds.), Oxford:Oxford University Press; Piaget, J., (1932) The Moral Judgment of the Child, , London: Routledge & Kegan Paul; Piaget, J., (1972) Judgment and Reasoning in the Child, , Totowa, NJ: Littlefield, Adams; Picard, R., (1997) Affective Computing, , Cambridge, MA: MIT Press; Picard, R.W., Klein, J., Computers that Recognise and Respond to User Emotion: Theoretical and Practical Implications (2002) Interacting with Computers, 14 (2), pp. 141-169; Pickering, J., (2000) Agents and Ethics, , Paper presented at the Convention of the Society for Artificial Intelligence and Simulated Behavior, Symposium on AI, Ethics and (Quasi-) Human Rights, Birmingham, UK; Pollack, J.B., Ethics for the Robot Age: Should Bots Carry Weapons? Should They Win Patents? Questions We Must Answer as Automation Advances (2005) Wired, 13 (1). , www.wired.com/wired/archive/13.01/view.html; Pollack, J.B., Mindless Intelligence (2006) IEEE Intelligent Systems, 21 (3), pp. 50-56; Powers, T., Prospects for a Kantian Machine (2006) IEEE Intelligent Systems, 21 (4), pp. 46-51; Premack, D.W., Woodruff, G., Does the Chimpanzee Have a Theory of Mind? (1978) Behavioral and Brain Science, 1, pp. 515-526; Prinz, J., (2004) Gut Reactions: A Perceptual Theory of Emotions, , Oxford:Oxford University Press; Pinz, J., The Emotional Basis of Moral Judgments (2006) Philosophical Explorations, 9 (1); Ramamurthy, U., D'Mello, S.K., Franklin, S., (2004) 2004 Institute of Electrical Engineers International Conference on Systems, Man and Cybernetics, 6, pp. 5858-5863. , The Hague: Institute of Electrical Electronics Engineers; Ramamurthy, U., D'Mello, S.K., Franklin, S., (2005) Role of Consciousness in Episodic Memory Processes, , Poster presented at the ninth conference of the Association for the Scientific Study of Consciousness. Pasadena, CA; Rao, R.P.N., Fuentes, O., Hierarchical Learning of Navigational Behaviors in an Autonomous Robot Using a Predictive Sparse Distributed Memory (1998) Machine Learning, 31 (1-3), pp. 87-113; Rawls, J., (1999) A Theory of Justice, , Cambridge, MA: Harvard University Press; Ray, T., An Approach to the Synthesis of Life (1991) Artificial Life II, pp. 371-408. , C. G. Langton, C. Taylor, J. D. Farmer, & S. Rasmussen (Eds.), Santa Fe, NM: Westview Press; Ray, T., Kurzweil' Turing Fallacy (2002) Are We Spiritual Machines? Ray Kurzweil vs. the Critics of Strong A.I., pp. 116-127. , J. Richards & G. Gilder (Eds.), Seattle: Discovery Institute; Richards, J.W., Gilder, G., (2002) Are We Spiritual Machines? Ray Kurzweil vs. the Critics of Strong A.I., , Seattle: Discovery Institute; Reeves, B., Nass, C., (1996) The Media Equation: How People Treat Computers, Television, and New Media, , Cambridge, MA: Cambridge University Press; Reynolds, C., Picard, R., (2004) Affective sensors, privacy, and ethical contracts, , Paper presented at Conference on Human Factors in Computing Systems. Vienna, Austria; Robbins, R.W., Wallace, W.A., Decision Support for Ethical Problem Solving: A Multi-Agent Approach (2007) Decision Support Systems, 43 (4), pp. 1571-1587; Roco, M., Bainbridge, W., (2002) Conference report Converging Technologies for Improving Human Performance-Nanotechnology, Biotechnology, Information Technology, and Cognitive Science, , Arlington, VA:NSF/DoC; Rose, J., Turkett, W., (2002) Emergent Planning with Philosophical Agents, , Paper presented at the Third International Workshop on Planning and Scheduling for Space, Houston, TX; Ross, W.D., (1930) The Right and the Good, , Oxford: Clarendon Press; Rothstein, J., Soldiers Bond with Battlefield Robots: Lessons Learned in Iraq May Show Up in Future Homeland "Avatars." MSNBC/Reuters (2006), www.msnbc.msn.com/id/12939612,http://web.archive.org/web/20060613225745/http://www.msnbc.msn.com/id/12939612, May 23, Originally retrieved from, archived at; Rothstein, J., Soldiers Bond with iRobot Machine (2006), www.boston.com/news/nation/articles/2006/05/23/soldiers_bond_with_irobot_machine_ceo_dreams_big/?rss_id=Boston.com+%2F+News, May 23, Reuters, San Diego; Rozin, P., Haidt, J., McCauley, C., Disgust (2000) Handbook of Emotions, pp. 637-653. , M. Lewis & J. M.Haviland-Jones (Eds.), (2nd ed.), New York: Guilford Press; Russell, S., Norvig, P., (1995) Artificial Intelligence: A Modern Approach, , Upper Saddle River, NJ: Prentice Hall; Rzepka, R., Araki, K., What Could Statistics Do for Ethics? The Idea of Common Sense Processing Based Safety Value (2005) Machine Ethics: Papers From The AAAI Fall Symposium, pp. 85-87. , M. Anderson, S. L. Anderson, & C. Armen (Cochairs),. Arlington, VA: AAAI Press; Saletan, W., Chess Bump: The Triumphant Teamwork of Humans and Computers (2007) Slate, , www.slate.com/id/2166000, May 11; Salovey, P., Mayer, J.D., Emotional Intelligence (1990) Imagination, Cognition, and Personality, 9, pp. 185-211; Satpute, A.B., Lieberman, M.D., Integrating Automatic and Controlled Processes into Neurocognitive Models of Social Cognition (2006) Brain Research, 1079, pp. 86-97; Sawyer, R.J., Robot Ethics (2007) Science, 318, p. 1037; Scassellati, B., (2001) Foundations for a Theory of Mind for a Humanoid Robot, , Ph. D. Thesis submitted to the Department of Electrical Engineering and Computer Science. MIT, Cambridge, Massachusetts; Schactman, N., Armed Robots Pushed to Police (2007) Wired Blog Network, , http://blog.wired.com/defense/2007/08/armed-robots-so.html, August 16; Schactman, N., Robot Cannon Kills 9, Wounds 14 (2007) Wired Blog Network, , http://blog.wired.com/defense/2007/10/robotcannon-ki.html, Ocotober 18; Schactman, N., Roomba-Maker Unveils Kill-Bot (2007) Wired Blog Network, , http://blog.wired.com/defense/2007/10/roomba-makerun.html, October 17; Scheutz, M., Useful Roles of Emotions in Artificial Agents: A Case Study from Artificial Life (2004) Proceedings of AAAI 2004, pp. 42-48. , San Jose, CA: AAAI Press; Scheutz, M.C., Crowell, C., (2007) The Burden of Embodied Autonomy: Some Reflections on the Social and Ethical Implications of Autonomous Robots, , Paper presented at the Workshop on Roboethics at the International Conference on Robotics and Automation, Rome; Scholl, B., Tremoulet, P., Perceptual Causality and Animacy (2000) Trends in Cognitive Science, 4 (8), pp. 299-309; Searing, D., (1998) HARPS Ethical Analysis Methodology, , www.cs.bgsu.edu/maner/heuristics/-1998Searing.htm; Searle, J.R., Minds, Brains, and Programs (1980) Behavioral and Brain Sciences, 3 (3), pp. 417-458; Seville, H., Field, D.G., (2000) What Can AI Do for Ethics?, , Paper presented at the convention for The Society for the Study of Artificial Intelligence and the Simulation of Behavior 2000, Birmingham, UK; Shalowitz, D.I., Garrett-Myer, E., Wendler, D., How Should Treatment Decisions Be Made for Incapacitated Patients, and Why? (2007) Public Library of Science Medicine, 4 (3), p. e35; Shanahan, M., (2005) Consciousness, Emotion, and Imagination: A Brain-Inspired Architecture for Conscious Robots, , Paper presented at the Artificial Intelligence and the Simulation of Behavior '05 Convention, Social Intelligence and Interaction in Animals, Robots and Agents: Symposium on Next Generation Approaches to Machine Consciousness, Hatfield, UK; Shanahan, M., (2007) Is There an Ethics of Artificial Consciousness?, , Paper presented at the Hungary Cognitive Science Foundation conference, Towards a Science of Consciousness, Budapest; Shanahan, M.P., Consciousness, Emotion, and Imagination: A Brain-Inspired Architecture for Cognitive Robotics (2005) Proceedings of the Artificial Intelligence and the Simulation of Behavior 2005 Symposium on Next Generation Approaches to Machine Consciousness, pp. 26-35. , www.aisb.org.uk/publications/proceedings/aisb05/7_MachConsc_Final.pdf; Shanahan, M.P., A Cognitive Architecture that Combines Internal Simulation with a Global Workspace (2006) Consciousness and Cognition, 15, pp. 433-449; Shanahan, M.S., A Spiking Neuron Model of Cortical Broadcast and Competition (2007) Consciousness and Cognition, 17 (1), pp. 288-303; Shnayerson, M., The Code Warrior (2004) Vanity Fair, , January 1; Sidgwick, H., (1874) The Methods of Ethics, , London: Macmillan; Sieghart, P., Dawson, J., Computer-aided medical ethics (1987) Journal of Medical Ethics, 13 (4), pp. 185-188; Sigman, M., Dehaene, S., Dynamics of the Central Bottleneck: Dual-Task and Task Uncertainty (2006) Public Library of Science Biology, 4 (7), p. e220; Simon, H.A., Motivation and emotional controls of cognition (1967) Psychological Review, 74, pp. 29-39; Simon, H.A., (1982) Models of Bounded Rationality, , Cambridge, MA: MIT Press; Singh, S., Thayer, S., (2001) ARMS (Autonomous Robots for Military Systems): A Survey of Collaborative Robotics Core Technologies and Their Military Applications, , Pittsburgh, PA: Robotics Institute, Carnegie Mellon University; (2001) SIAI Guidelines on Friendly AI, , www.singinst.org/ourresearch/publications/guidelines.html; Skyrms, B., (1996) Evolution of the Social Contract, , Cambridge, UK:Cambridge University Press; Skyrms, B., Game Theory, Rationality and Evolution of the Social Contract (2000) Evolutionary Origins of Morality, pp. 269-285. , L. Katz (Ed.), Thorverton, UK: Imprint Academic; Skyrms, B., (2003) The Stag Hunt and the Evolution of the Social Contract, , Cambridge, UK: Cambridge University Press; Sloman, A., Damasio, Descartes, Alarms and Meta-Management (1998) Proceedings of the Symposium on Cognitive Agents: Modeling Human Cognition, , San Diego, CA: Institute of Electrical Electronics Engineers; Sloman, A., What Sort of Architecture Is Required for a Human-like Agent? (1999) Foundations of Rational Agency, pp. 35-52. , M. Wooldridge & A. S. Rao (Eds.), New York: Springer; Sloman, A., Chrisley, R., Virtual Machines and Consciousness (2003) Machine Consciousness, pp. 133-172. , O. Holland (Ed.), Thorverton, UK: Imprint Academic; Sloman, A.R., Chrisley, R., Scheutz, M., The Architectural Basis of Affective States and Processes (2005) Who Needs Emotions? The Brain Meets the Robot, pp. 203-244. , J. M. Fellous & Arbib, M. A. (Eds.), Oxford: Oxford University Press; Slovic, P., Perception of Risk (1987) Science, 236, pp. 280-285; Smit, I., Equations, Emotions, and Ethics: A Journey Between Theory and Practice (2002) Fourteenth International Conference on Systems Research, Informatics and Cybernetics: Symposium on Cognitive, Emotive and Ethical Aspects of Decision Making and Human Action, 1, pp. 1-6. , I. Smit & G. Lasker (Eds.), Windsor, Ontario, Canada: International Institute for Advanced Studies in Systems Research and Cybernetics; Smit, I., Robots, Quo Vadis? (2003) Fifteenth International Conference on Systems Research, Informatics and Cybernetics: Symposium on Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, 2, pp. 6-11. , I. Smit, W. Wallach, & G. Lasker (Eds.), Windsor, Ontario, Canada: International Institute for Advanced Studies in Systems Research and Cybernetics; Smith, J.D., Washburn, D.A., Uncertainty Monitoring and Metacognition by Animals (2005) Current Directions in Psychological Science, 14, pp. 19-24; Snapper, J.W., Responsibility for Computer-Based Errors (1985) Metaphilosophy, 16, pp. 289-295; Soskis, B., Man and the Machines (2005) Legal Affairs, , www.legalaffairs.org/issues/January-February-2005/feature_sokis_janfeb05.msp, January/February; Sousa, R., (1987) The Rationality of Emotion, , Cambridge, MA: MIT Press; Sparrow, R., The March of the Robot Dogs (2002) Ethics and Information Technology, 4 (4), pp. 305-318; Sparrow, R., In the Hands of Machines? The Future of Aged Care (2006) Minds and Machines, 16, pp. 141-161; Sparrow, R., Killer Robots (2007) Applied Philosophy, 24 (1), pp. 62-77; Stahl, B.C., Can a Computer Adhere to the Categorical Imperative? A Contemplation of the Limits of Transcendental Ethics in IT (2002) Fourteenth International Conference on Systems Research, Informatics and Cybernetics: Symposium on Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, 1, pp. 13-18. , I. Smit & G. Lasker (Eds.), Windsor, Ontario, Canada: International Institute for Advanced Studies in Systems Research and Cybernetics; Stahl, B.C., Information, Ethics, and Computers: The Problem of Autonomous Moral Agents (2004) Minds and Machines, 14 (1), pp. 67-83; Stickgold, R., Walker, M.P., Memory Consolidation and Reconsolidation: What Is the Role of Sleep? (2005) Trends in Neuroscience, 28, pp. 408-415; Stiehl, D., Lieberman, J., Breazeal, C., Basel, L., Lalla, L., Wolf, M., The Design of the Huggable: A Therapeutic Robotic Companion for Relational, Affective Touch (2005) AAAI Fall Symposium in Caring Machines: AI in Eldercare, , T. Bickmore (Ed.), Washington, DC: AAAI Press; Stross, C., (2006) Accelerando, , New York: Ace; Stuart, S., Artificial Intelligence and Artificial Life-Should Artificial Systems Have Rights? (1994), www.gla.ac.uk/departments/philosophy/Personnel/susan/NewNightmares.pdf, slightly rev; Tarsitano, M., Route Selection by a Jumping Spider (Portia Labiata) during the Locomotory Phase of a Detour (2006) Animal Behavior, 72, pp. 1437-1442; Taylor, C., (1989) Sources of the Self, , Cambridge, MA: Harvard University Press; (2004) Central Line facts, , http://tube.tfl.gov.uk/content/faq/lines/central.asp10/18/2004;http://web.archive.org/web/*hh_/tube.tfl.gov.uk/content/faq/lines/central.asp, Original web page retrieved from; Thompson, H.S., Computational Systems, Responsibility and Moral Sensibility (1999) Technology in Society, 21 (4), pp. 409-415; Torrance, S., (2000) Towards an Ethics for Epersons, , Paper presented at the Symposium on AI, Ethics and (Quasi-) Human Rights, Birmingham, UK; Torrance, S., Artificial Intelligence and Artificial Consciousness:Continuum or Divide? (2003) Fifteenth International Conference on Systems Research, Informatics and Cybernetics:Symposium on Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, 2, pp. 25-30. , I. Smit, W. Wallach, & G. Lasker (Eds.), Windsor, Ontario, Canada: International Institute for Advanced Studies in Systems Research and Cybernetics; Torrance, S., Us and Them: Living with Self-Aware Systems (2004) Sixteenth International Conference on Systems Research, Informatics and Cybernetics: Symposium on Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, 3, pp. 7-14. , I. Smit, W. Wallach, & G. Lasker (Eds.), Windsor, Ontario, Canada: International Institute for Advanced Studies in Systems Research and Cybernetics; Tulving, E., (1983) Elements of Episodic Memory, , Oxford: Clarendon Press; Turing, A., Computing Machinery and Intelligence (1950) Mind and Language, 59, pp. 434-460; Turkle, S., (1984) The Second Self: Computers and the Human Spirit, , New York: Simon & Schuster; Tversky, A., Kahneman, D., Judgment under Uncertainty: Heuristics and Biases (1974) Science, 185, pp. 1124-1131; Tyrell, T., An Evaluation of Maes's Bottom-Up Mechanism for Behavior Selection (1994) Adaptive Behavior, 2 (4), pp. 307-348; Uchida, N., Kepecs, A., Mainen, Z.F., Seeing at a Glance, Smelling in a Whiff: Rapid Forms of Perceptual Decision Making (2006) Nature Reviews Neuroscience, 7, pp. 485-491; (2005) BBC News, , January 23; van den Hoven, J., Lokhorst, G., Deontic Logic and Computer-Supported Computer Ethics (2002) Cyberphilosophy: The Intersection of Computing and Philosophy, pp. 280-289. , J. H. Moor & T. W. Bynum (Eds.), Malden, MA: Blackwell; van der Loos, H.F.M., (2007) Ethics by Design: A Conceptual Approach to Personal and Service Robot Systems, , Paper presented at the Institute of Electrical Electronics Engineers '07 Workshop on Roboethics, Rome; van der Loos, H.F.M., Lees, D.S., Leifer, L.J., (1992) Safety Considerations for Rehabilitative and Human-Service Robot Systems, , Paper presented at the Fifteenth Annual Conference of the Rehabilitation Engeneering and Assistive Technology Society of North America, Toronto; Varela, F.J., Thompson, E., Rosch, E., (1991) The Embodied Mind, , Cambridge, MA: MIT Press; Vauclair, J., Fagot, J., Hopkins, W.D., Rotation of Mental Images in Baboons When the Visual Input Is Directed to the Left Cerebral Hemisphere (1993) Psychological Science, 4, pp. 99-103; Veruggio, G., The Birth of Roboethics (2005), April, Paper presented at the Institute of Electrical and Electronics Engineers International Conference on Robotics and Automation 2005 Workshop on Roboethics, Barcelona; Veruggio, G., (2006) EURON Roboethics Roadmap, , Paper presented at the EURON Roboethics Atelier, Genoa; Veruggio, G., Operto, F., Roboethics: A Bottom-Up Interdisciplinary Discourse in the Field of Applied Ethics in Robotics (2006) International Review of Information Ethics, 6, pp. 2-8; Vidnyánszky, Z., Sohn, W., Attentional Learning: Learning to bias Sensory Competition [Abstract] (2003) Journal of Vision, 3, p. 174a; Vinge, V., First Word (1983) OMNI, , January; Vinge, V., The Coming Technological Singularity: How to Survive in the Post-Human Era (1993) Whole Earth Review, p. 77. , Winter; von Foerster, H., Ethics and Second-Order Cybernetics (1992) Cybernetics and Human Knowing, 1 (1), pp. 40-46; Wallach, W., Robot Morals and Human Ethics (2003) Fifteenth International Conference on Systems Research, Informatics and Cybernetics: Symposium on Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, 2, pp. 1-5. , I. Smit, W. Wallach, & G. Lasker (Eds.), Windsor, Ontario, Canada: International Institute for Advanced Studies in Systems Research and Cybernetics; Wallach, W., Artificial Morality: Bounded Rationality, Bounded Morality and Emotions (2004) Sixteenth International Conference on Systems Research, Informatics and Cybernetics:Symposium on Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, 3, pp. 1-6. , I. Smit, W. Wallach, & G. Lasker (Eds.), Windsor, Ontario, Canada: International Institute for Advanced Studies in Systems Research and Cybernetics; Wallach, W., (2007) The Road to Singularity: Comedic Complexity, Technological Thresholds, and Bioethical Broad Jumps, , Transcript of a presentation at the Singularity Summit 2007: AI and the Future of Humanity. San Francisco; Wallach, W., Implementing Moral Decision Making Faculties in Computers and Robots (2008) AI and Society, 22 (4), pp. 463-475; Wallach, W., Allen, C., Smit, I., Machine Morality: Bottom-Up and Top-Down Approaches for Modelling Human Moral Faculties (2008) AI and Society, 22 (4), pp. 565-582; Warwick, K., Cyborg Morals, Cyborg Values, Cyborg Ethics (2003) Ethics and Information Technology, 5, pp. 131-137; Warwick, K., (2004) I Cyborg, , London: Century; Watt, D.F., Affect and the Limbic System: Some Hard Problems (1998) Journal of Neuropsychiatry and Clinical Neuroscience, 10, pp. 113-116; Weckert, J., Intelligent Machines, Dehumanisation and Professional Responsibility (1997) Computer Ethics: Philosophical Enquiry, pp. 179-192. , J. van den Hoven (Ed.), Rotterdam: Erasmus University Press; Weckert, J., Trusting Agents (2005) Ethics of New Information Technology: Proceedings of the Sixth International Conference of Computer Ethics: Philosophical Enquiry, pp. 407-412. , P. Brey, F. Grodzinsky, & L. Introna (Eds.), Enschede, The Netherlands: Center for Telematics and Information Technology; Weiner, T., New Model Army Soldier Rolls Closer to Battle (2005) New York Times, , February 16; Weinman, J., (2001) Autonomous Agents: Motivations, Ethics, and Responsibility, , www.weinman.cc/ethics.phtml,http://web.archive.org/web/*/http://www.weinman.cc/ethics.phtml, Manuscript originally retrieved from archived at; Werdenich, D., Huber, L., A Case of Quick Problem Solving in Birds: String Pulling in Keas, Nestor Notabilis (2006) Animal Behaviour, 71, pp. 855-863; Wertheim, M., (1999) The Pearly Gates of Cyberspace, , New York: Norton; Whitbeck, C., Teaching Ethics to Scientists and Engineers: Moral Agents and Moral Problems (1995) Science and Engineering Ethics, 1 (3), pp. 299-308; Whitby, B.R., (1990) Problems in the Computer Representation of Moral Reasoning, , Paper presented at the Second National Conference on Law, Computers and Artificial Intelligence. Exeter University, UK; Whitby, B.R., AI and the Law: Proceed with Caution (1991) Law, Computer Science and Artificial Intelligence, pp. 1-14. , M. Bennun (Ed.), New York:Ellis Horwood; Whitby, B.R., (1996) Reflections on Artificial Intelligence: The Social, Legal, and Moral Dimensions, , Exeter, UK: Intellect Books; Whitby, B.R., Oliver, K., (2000) How to Avoid a Robot Takeover: Political and Ethical Choices in the Design and Introduction of Intelligent Artifacts, , Paper presented at the Convention of the Society for Artificial Intelligence and Simulated Behavior, Symposium on AI, Ethics and (Quasi-) Human Rights. Birmingham, UK; Wiegel, V., van den Hoven, J., Lokhorst, G., Privacy, Deontic Epistemic Action Logic and Software Agents (2005) Sixth International Conference on Computer Ethics: Ethics of New Information Technology, pp. 419-434. , Enschede, The Netherlands: Center for Telematics and Information Technology; Wilcox, S., Jackson, R., Jumping Spider Tricksters: Deceit, Predation, and Cognition (2002) The Cognitive Animal, pp. 27-33. , M. Bekoff, C. Allen, & G. M. Burghardt (Eds.), Cambridge, MA: MIT Press; Williams, B., (1985) Ethics and the Limits of Philosophy, , Cambridge, MA:Harvard University Press; Willis, J., Todorov, A., First Impressions: Making Up Your Mind after a 100-Ms Exposure to a Face (2006) Psychological Science, 17, pp. 592-599; Wilson, E.O., (1975) Sociobiology: The New Synthesis, , Cambridge, MA:Harvard University Press; (2002) Injury: A leading cause of the global burden of disease, 2000, , Geneva: World Health Organisation; Wu, X., Chen, X., Li, Z., Han, S., Zhang, D., Binding of Verbal and Spatial Information in Human Working Memory Involves Large-Scale Neural Synchronization at Theta Frequency (2007) Neuroimage, 35 (4), pp. 1654-1662; Yaeger, L., Sporns, O., Evolution of Neural Structure and Complexity in a Computational Ecology (2006) Artificial Life X, , Bloomington, IN: MIT Press; Yudkowsky, E., (2001) What Is Friendly AI?, , www.kurzweilai.net/meme/frame.html?main=/articles/art0172.html; Yudkowsky, E., (2001) Creating Friendly AI, , www.singinst.org/upload/CFAI.html; Yudkowsky, E., Artificial Intelligence as a Positive and Negative Factor in Global Risk Global Catastrophic Risks, , (Forthcoming), M. Rees, N. Bostrom, & M. Cirkovic (Eds.), Oxford: Oxford University Press; Zhang, Z., Dasgupta, D., Franklin, S., Metacognition in Software Agents Using Classifier Systems (1998) Proceedings of the Fifteenth National Conference on Artificial Intelligence, pp. 83-88. , Menlo Park, CA:AAAI Press; Zhu, J., Thagard, P., Emotion and Action (2002) Philosophical Psychology, 15, pp. 19-36},
document_type={Book},
source={Scopus},
}

@ARTICLE{Moor200618,
author={Moor, J.H.},
title={The nature, importance, and difficulty of machine ethics},
journal={IEEE Intelligent Systems},
year={2006},
volume={21},
number={4},
pages={18-21},
doi={10.1109/MIS.2006.80},
art_number={1667948},
note={cited By 193},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33747228513&doi=10.1109%2fMIS.2006.80&partnerID=40&md5=478997c34e1c591a448b980210e5b0e9},
abstract={The importance and difficulty of machine ethics, which is an emerging concept that allows autonomous machines to make decision in a more practical way, are discussed. Computing technology often has important ethical impact. Machine ethics can be incorporated into a computer by constraining the machine's actions to avoid unethical outcomes. Machine's capability to be implicit ethical agents illustrates an important sense of machine ethics. Software engineers must routinely consider machine ethics in this sense during software development. Machines that are explicit ethical agents can be the best ethical agents to have in situations such as disaster relief. A full ethical agent can make explicit ethical judgments and generally is a competent to reasonably justify them. The limited understanding of a proper ethical theory and conflicting ethical intuitions and beliefs are posing challenge in incorporating machine ethics to autonomous systems.},
keywords={Autonomous systems;  Ethical agents;  Ethical theory;  Machine ethics, Computer software;  Constraint theory;  Decision making;  Learning systems;  Software engineering, Autonomous agents},
references={Simon, H., (1999) Re: Dartmouth Seminar 1956, , (email to J. Berleur), Herbert A. Simon Collection, Carnegie Mellon Univ. Archives, 20 Nov; Lewis, J., Robots of Arabia (2005) Wired, 13 (11), pp. 188-195. , www.wired.com/wired/archive/13.11/camel.html?pg=1&topic= camel&topic_set=; Moor, J.H., Is ethics computable? (1995) Metaphilosophy, 26 (1-2), pp. 1-21.4; Wallach, W., Allen, C., Smit, I., Machine morality: Bottom-up and top-down approaches for modeling human moral faculties (2005) Machine Ethics, pp. 94-102. , M. Anderson, S.L. Anderson, and C. Armen, eds., AAAI Press; Van Den Hoven, J., Lokhorst, G.-J., Deontic logic and computer-supported computer ethics (2002) Cyberphilosophy: the Intersection of Computing and Philosophy, pp. 280-289. , J.H. Moor and T.W. Bynum, eds., Blackwell; Wiegel, V., Van Den Hoven, J., Lokhorst, G.-J., Privacy, deontic epistemic action logic and software agents (2005) Ethics of New Information Technology, Proc. 6th Int'l Conf. Computer Ethics: Philosophical Enquiry (CEPE 05), pp. 419-434. , Center for Telematics and Information Technology, Univ. of Twente; Anderson, M., Anderson, S.L., Armen, C., Towards machine ethics: Implementing two action-based ethical theories (2005) Machine Ethics, pp. 1-7. , M. Anderson, S.L. Anderson, and C. Armen, eds., AAAI Press; Gips, J., Creating ethical robots: A grand challenge AAAI Fall 2005 Symposium on Machine Ethics, , www.cs.be.edu/~gips/EthicalRobotsGrandChallenge.pdf; Moor, J.H., Are there decisions computers should never make? (1979) Nature and System, 1 (4), pp. 217-229; Searle, J.R., Minds, brains, and programs (1980) Behavioral and Brain Sciences, 3 (3), pp. 417-457},
document_type={Review},
source={Scopus},
}

@ARTICLE{Anderson200715,
author={Anderson, M. and Anderson, S.L.},
title={Machine ethics: Creating an ethical intelligent agent},
journal={AI Magazine},
year={2007},
volume={28},
number={4},
pages={15-26},
note={cited By 137},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-39049109150&partnerID=40&md5=43b1810358f719b47f32f7a08b693f4d},
abstract={The newly emerging field of machine ethics (Anderson and Anderson 2006) is concerned with adding an ethical dimension to machines. Unlike computer ethics - which has traditionally focused on ethical issues surrounding humans' use of machines - machine ethics is concerned with ensuring that the behavior of machines toward human users, and perhaps other machines as well, is ethically acceptable. In this article we discuss the importance of machine ethics, the need for machines that represent ethical principles explicitly, and the challenges facing those working on machine ethics. We also give an example of current research in the field that shows that it is possible, at least in a limited domain, for a machine to abstract an ethical principle from examples of correct ethical judgments and use that principle to guide its own behavior. Copyright © 2007, American Association for Artificial Intelligence. All rights reserved.},
keywords={Artificial intelligence;  Human computer interaction;  Information technology, Ethical intelligent agent;  Machine ethics, Intelligent agents},
references={Allen, C., Varner, G., Zinser, J., Prolegomena to Any Future Artificial Moral Agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12, pp. 251-261; Special Issue on Machine Ethics (2006) IEEE Intelligent Systems, 21 (4). , Anderson, M, and Anderson, S, eds, July/August; Machine Ethics: Papers from the AAAI Fall Symposium (2005), Anderson, M, Anderson, S, and Armen, C, eds, Technical Report FS-05-06, Association for the Advancement of Artificial Intelligence, Menlo Park, CA; Anderson, M., Anderson, S., Armen, C., Toward Machine Ethics: Implementing Two Action-Based Ethical Theories. In Machine Ethics: Papers from the AAAI Fall Symposium (2005), Technical Report FS-05-06, Association for the Advancement of Artificial Intelligence, Menlo Park, CA; Anderson, M., Anderson, S., Armen, C., An Approach to Computing Ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 56-63; Anderson, M., Anderson, S., Armen, C., MedEthEx: A Prototype Medical Ethics Advisor (2006) Proceedings of the Eighteenth Conference on Innovative Applications of Artificial Intelligence, , Menlo Park, CA: AAAI Press; Anderson, S.L., Being Morally Responsible for an Action Versus Acting Responsibly or Irresponsibly (1995) Journal of Philosophical Research, 20, pp. 453-462; Asimov, I. 1976. The Bicentennial Man. In Stellar Science Fiction 2, ed. J.-L. del Rey. New York: Ballatine Books; Baral, C., (2003) Knowledge Representation, Reasoning, and Declarative Problem Solving, , Cambridge, UK: Cambridge University Press; Beauchamp, T.L., Childress, J.F., (1979) Principles of Biomedical Ethics, , Oxford, UK: Oxford University Press; Bentham, J., (1907) An Introduction to the Principles and Morals of Legislation, , Oxford: Clarendon Press; Bringsjord, S., Arkoudas, K., Bello, P., Toward a General Logicist Methodology for Engineering Ethically Correct Robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44; Brody, B., (1988) Life and Death Decision Making, , New York: Oxford University Press; Buchanan, A.E., Brock, D.W., (1989) Deciding for Others: The Ethics of Surrogate Decision Making, pp. 48-57. , Cambridge, UK: Cambridge University Press; Capek, K. 1921. R.U.R. In Philosophy and Science Fiction, ed. M. Phillips. Amherst, NY: Prometheus Books; Clarke, A.C., (1968) 2001: A Space Odyssey, , New York: Putnam; Damasio, A.R., (1994) Descartes' Error: Emotion, Reason, and the Human Brain, , New York: G. P. Putnam; Dennett, D., Computers as Prostheses for the Imagination. Invited talk (2006) International Computers and Philosophy Conference, , presented at the, Laval, France, May 3; Dietrich, E., After the Humans Are Gone. Keynote address (2006) 2006 North American Computing and Philosophy Conference, , presented at the, RPI, Troy, NY, August 12; Ganascia, J.G., Using Non-Monotonic Logics to Model Machine Ethics (2007) Seventh International Computer Ethics Conference, , Paper presented at the, San Diego, CA, July 12-14; Gazzaniga, M., (2006) The Ethical Brain: The Science of Our Moral Dilemmas, , New York: Harper Perennial; Guarini, M., Particularism and the Classification and Reclassification of Moral Cases (2006) IEEE Intelligent Systems, 21 (4), pp. 22-28; Horty, J., (2001) Agency and Deontic Logic, , New York: Oxford University Press},
document_type={Article},
source={Scopus},
}

@ARTICLE{Awad201859,
author={Awad, E. and Dsouza, S. and Kim, R. and Schulz, J. and Henrich, J. and Shariff, A. and Bonnefon, J.-F. and Rahwan, I.},
title={The Moral Machine experiment},
journal={Nature},
year={2018},
volume={563},
number={7729},
pages={59-64},
doi={10.1038/s41586-018-0637-6},
note={cited By 128},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055831155&doi=10.1038%2fs41586-018-0637-6&partnerID=40&md5=de8fa111ffddea46578f643a6f47529c},
abstract={With the rapid development of artificial intelligence have come concerns about how machines will make moral decisions, and the major challenge of quantifying societal expectations about the ethical principles that should guide machine behaviour. To address this challenge, we deployed the Moral Machine, an online experimental platform designed to explore the moral dilemmas faced by autonomous vehicles. This platform gathered 40 million decisions in ten languages from millions of people in 233 countries and territories. Here we describe the results of this experiment. First, we summarize global moral preferences. Second, we document individual variations in preferences, based on respondents’ demographics. Third, we report cross-cultural ethical variation, and uncover three major clusters of countries. Fourth, we show that these differences correlate with modern institutions and deep cultural traits. We discuss how these preferences can contribute to developing global, socially acceptable principles for machine ethics. All data used in this article are publicly available. © 2018, Springer Nature Limited.},
keywords={adult;  article;  ethics;  human;  language;  machine;  morality;  artificial intelligence;  decision making;  ethics;  female;  harm reduction;  information processing;  international cooperation;  Internet;  male;  motor vehicle;  pedestrian;  procedures;  public opinion;  robotics;  traffic accident;  translating (language), Accidents, Traffic;  Artificial Intelligence;  Data Collection;  Decision Making;  Female;  Harm Reduction;  Humans;  Internationality;  Internet;  Male;  Morals;  Motor Vehicles;  Pedestrians;  Public Opinion;  Robotics;  Translating},
references={Greene, J., (2013) Moral Tribes: Emotion, Reason and the Gap between Us and Them, , Atlantic Books, London; Tomasello, M.A., (2014) Natural History of Human Thinking, , Harvard Univ. Press, Cambridge; Cushman, F., Young, L., The psychology of dilemmas and the philosophy of morality (2009) Ethical Theory Moral Pract., 12, pp. 9-24; Asimov, I.I., (1950) Robot, , Doubleday, New York; Bryson, J., Winfield, A., Standardizing ethical design for artificial intelligence and autonomous systems (2017) Computer, 50, pp. 116-119; Wiener, N., Some moral and technical consequences of automation (1960) Science, 131, pp. 1355-1358. , COI: 1:STN:280:DC%2BC3cvmtFSqtw%3D%3D; Wallach, W., Allen, C., (2008) Moral Machines: Teaching Robots Right from Wrong, , Oxford Univ. Press, Oxford; Responsible autonomy (2017) Proc. 26Th International Joint Conference on Artificial Intelligence 4698–4704 (IJCAI; Dadich, S., (2016) Barack Obama, Neural Nets, Self-Driving Cars, and the Future of the World, , https://www.wired.com/2016/10/president-obama-mit-joi-ito-interview/, Wired; Shariff, A., Bonnefon, J.-F., Rahwan, I., Psychological roadblocks to the adoption of self-driving vehicles (2017) Nat. Hum. Behav., 1, pp. 694-696; Conitzer, V., Brill, M., Freeman, R., Crowdsourcing societal tradeoffs (2015) Proc. 2015 International Conference on Autonomous Agents and Multiagent Systems, pp. 1213-1217. , IFAAMAS; Bonnefon, J.-F., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2016) Science, 352, pp. 1573-1576. , COI: 1:CAS:528:DC%2BC28XhtVaitLzK; Hauser, M., Cushman, F., Young, L., Jin, K.-X.R., Mikhail, J., A dissociation between moral judgments and justifications (2007) Mind Lang., 22, pp. 1-21; Carlsson, F., Daruvala, D., Jaldell, H., Preferences for lives, injuries, and age: a stated preference survey (2010) Accid. Anal. Prev., 42, pp. 1814-1821; Johansson-Stenman, O., Martinsson, P., Are some lives more valuable? An ethical preferences approach (2008) J. Health Econ., 27, pp. 739-752; Johansson-Stenman, O., Mahmud, M., Martinsson, P., Saving lives versus life-years in rural Bangladesh: an ethical preferences approach (2011) Health Econ., 20, pp. 723-736; Graham, J., Meindl, P., Beall, E., Johnson, K.M., Zhang, L., Cultural differences in moral judgment and behavior, across and within societies (2016) Current Opinion in Psychology, 8, pp. 125-130; Hainmueller, J., Hopkins, D.J., Yamamoto, T., Causal inference in conjoint analysis: understanding multidimensional choices via stated preference experiments (2014) Polit. Anal., 22, pp. 1-30; Luetge, C., The German Ethics Code for automated and connected driving (2017) Philos. Technol., 30, pp. 547-558; Müllner, D., (2011) Modern Hierarchical, Agglomerative Clustering Algorithms, , https://arxiv.org/abs/1109.2378, Preprint at; Inglehart, R., Welzel, C., (2005) Modernization, Cultural Change, and Democracy: The Human Development Sequence, , Cambridge Univ. Press, Cambridge; Muthukrishna, M., (2018) Beyond WEIRD Psychology: Measuring and Mapping Scales of Cultural and Psychological Distance, , https://ssrn.com/abstract=3259613, Preprint at; Hofstede, G., (2003) Culture’s Consequences: Comparing Values, Behaviors, Institutions and Organizations across Nations, , Sage, Thousand Oaks; (2017) World Economic Outlook Database, , https://www.imf.org/external/pubs/ft/weo/2017/01/weodata/index.aspx; Kaufmann, D., Kraay, A., Mastruzzi, M., The worldwide governance indicators: methodology and analytical issues (2011) Hague J. Rule Law, 3, pp. 220-246; Gächter, S., Schulz, J.F., Intrinsic honesty and the prevalence of rule violations across societies (2016) Nature, 531, pp. 496-499; O’Neil, C., (2016) Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy, , Penguin, London; Henrich, J., In search of Homo Economicus: behavioral experiments in 15 small-scale societies (2001) Am. Econ. Rev., 91, pp. 73-78; (2017) Future of Life Institute. Asilomar AI Principles, , https://futureoflife.org/ai-principles/; Haidt, J., (2012) The Righteous Mind: Why Good People are Divided by Politics and Religion, , Knopf Doubleday, New York; Gastil, J., Braman, D., Kahan, D., Slovic, P., The cultural orientation of mass political opinion (2011) PS Polit. Sci. Polit., 44, pp. 711-714; Nishi, A., Christakis, N.A., Rand, D.G., Cooperation, decision time, and culture: online experiments with American and Indian participants (2017) PLoS One, 12},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bagloee2016284,
author={Bagloee, S.A. and Tavana, M. and Asadi, M. and Oliver, T.},
title={Autonomous vehicles: challenges, opportunities, and future implications for transportation policies},
journal={Journal of Modern Transportation},
year={2016},
volume={24},
number={4},
pages={284-303},
doi={10.1007/s40534-016-0117-3},
note={cited By 115},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995738131&doi=10.1007%2fs40534-016-0117-3&partnerID=40&md5=8a0be300957ca145d040ee4f29652382},
abstract={This study investigates the challenges and opportunities pertaining to transportation policies that may arise as a result of emerging autonomous vehicle (AV) technologies. AV technologies can decrease the transportation cost and increase accessibility to low-income households and persons with mobility issues. This emerging technology also has far-reaching applications and implications beyond all current expectations. This paper provides a comprehensive review of the relevant literature and explores a broad spectrum of issues from safety to machine ethics. An indispensable part of a prospective AV development is communication over cars and infrastructure (connected vehicles). A major knowledge gap exists in AV technology with respect to routing behaviors. Connected-vehicle technology provides a great opportunity to implement an efficient and intelligent routing system. To this end, we propose a conceptual navigation model based on a fleet of AVs that are centrally dispatched over a network seeking system optimization. This study contributes to the literature on two fronts: (i) it attempts to shed light on future opportunities as well as possible hurdles associated with AV technology; and (ii) it conceptualizes a navigation model for the AV which leads to highly efficient traffic circulations. © 2016, The Author(s).},
author_keywords={Autonomous vehicle;  Connected vehicle;  Intelligent transportation system;  System optimality;  Vehicle navigation},
references={Fagnant, D.J., Kockelman, K., Preparing a nation for autonomous vehicles: opportunities, barriers and policy recommendations (2015) Transp Res Part A, 77, pp. 167-181; Guizzo, E., How google’s self-driving car works. IEEE Spectrum Online (2011) October, p. 18; Markoff, J., Google cars drive themselves, in Traffic (2010) New York Times, p. 9; The automobile industry pocket guide (2015) European Automobile Manufacturers Association, , http://www.acea.be/uploads/publications/POCKET_GUIDE_2015-2016.pdf; Nieuwenhuijsen, J., (2015) Diffusion of automated vehicles: a quantitative method to model the diffusion of automated vehicles with system dynamics, , Delft University of Technology, TU Delft; Hong, D., Kimmel, S., Boehling, R., Camoriano, N., Cardwell, W., Jannaman, G., Purcell, A., Russel, E., Development of a semi-autonomous vehicle operable by the visually-impaired (2008) IEEE International Conference on multisensor fusion and integration for intelligent systems, 2008. MFI, 2008, pp. 539-544; Anderson, J.M., Nidhi, K., Stanley, K.D., Sorensen, P., Samaras, C., (2014) Oluwatola OA, , Autonomous vehicle technology: A guide for policymakers. Rand Corporation; Folsom, T.C., (2011) Social ramifications of autonomous urban land vehicles, , In: IEEE International Symposium on Technology and Society; Piao, J., McDonald, M., Advanced driver assistance systems from autonomous to cooperative approach (2008) Transp Rev, 28, pp. 659-684; Manyika, J., Chui, M., Bughin, J., Dobbs, R., Bisson, P., Marrs, A., Disruptive technologies: advances that will transform life, business, and the global economy (2013) McKinsey Global Institute New York; Petit, J., Shladover, S.E., Potential cyberattacks on automated vehicles (2015) IEEE Trans Intell Transp Syst, 16, pp. 546-556; Knight, W., Driverless cars are further away than you think (2013) MIT Technology Review, , https://www.technologyreview.com/s/520431/driverless-cars-are-further-away-than-you-think/; Litman, T., Autonomous vehicle implementation predictions (2015) Victoria Transport Policy Institute, p. 28; Maddox, J., Sweatman, P., Sayer, J., Intelligent vehicles + infrastructure to address transportation problems–a strategic approach (2015) In: 24th international technical conference on the enhanced safety of vehicles (ESV); Schoettle, B., Sivak, M., A survey of public opinion about connected vehicles in the US, the UK, and Australia (2014) In: 2014 International Conference on Connected Vehicles and Expo (ICCVE); Kan, Z., Qiang, Z., Haojun, Y., Long, Z., Lu, H., Chatzimisios, P., Reliable and efficient autonomous driving: the need for heterogeneous vehicular networks (2015) Commun Mag IEEE, 53, pp. 72-79; Patriksson, P., The traffic assignment problem: models and methods, VSP BV, The Netherlands (1994) Facsimile reproduction published in 2014 by Dover Publications, , Inc., Mineola; Sheffi, Y., (1985) Urban transportation networks: equilibrium analysis with mathematical programming methods, , Prentice-Hall Inc, Englewood Cliffs; Weber, M., Where to? (2014) a history of autonomous vehicles, , http://www.computerhistory.org/atchm/where-to-a-history-of-autonomous-vehicles; Fenton, R.E., Mayhan, R.J., Automated highway studies at the ohio state university-an overview (1991) IEEE Trans Vehicular Technol, 40, pp. 100-113; Ioannou, P., (2013) Automated highway systems, , Springer Science &, Business Media; Lantos, B., (2010) Nonlinear control of vehicles and robots, , Springer Science &, Business Media; Blasch, E.P., Lakhotia, A., Seetharaman, G., Unmanned vehicles come of age: The DARPA grand challenge (2006) Computer, 39, pp. 26-29; http://static.googleusercontent.com/media/www.google.com/en//selfdrivingcar/files/reports/report-0615.pdf, Google (2015) Google Self-Driving Car Project; Muir, H., Google self-driving car caught on video colliding with bus (2016) In: (ed.) The Guardian, , https://www.theguardian.com/technology/2016/mar/09/google-self-driving-car-crash-video-accident-bus; http://www.nhtsa.gov/About±NHTSA/Press+Releases/U.S.+Department+of+Transportation+Releases+Policy+on+Automated+Vehicle+Development, NHTSA (2013); Behere, S., Törngren, M., A functional architecture for autonomous driving. In: Proceedings of the first international workshop on automotive software architecture. ACM, pp (2015) 3–10; DiClemente, J., (2014) Mogos S, , Wang R, Autonomous car policy report; Siciliano, B., Khatib, O., (2008) Springer handbook of robotics, , Springer Science & Business Media, Berlin; Farhadi, A., Endres, I., Hoiem, D., Forsyth, D., Describing objects by their attributes (2009) IEEE Conference on Computer vision and pattern recognition, 2009. CVPR, 2009, pp. 1778-1785; Savasturk, D., Froehlich, B., Schneider, N., Enzweiler, M., Franke, U., A comparison study on vehicle detection in far infrared and regular images (2015) IEEE 18th international conference on intelligent transportation systems (ITSC), IEEE, 2015, pp. 1595-1600; Chen, W., Vehicular communications and networks: Architectures, protocols, operation and deployment (2015) Elsevier; Sivaraman, S., Learning, modeling (2013) and understanding vehicle surround using multi-modal sensing; Wei, J., Snider, J.M., Kim, J., Dolan, J.M., Rajkumar, R., Litkouhi, B., Towards a viable autonomous driving research platform (2013) Intelligent vehicles symposium (IV), IEEE, 2013, pp. 763-770; Link, H., Nash, C., Ricci, A., Shires, J., A generalised approach for measuring the marginal social costs of road transport in Europe. Int J Sustain Transp (2014) null-null; Parry, I.W., Walls, M., Harrington, W., Automobile externalities and policies (2007) J Econom Lit, 45, pp. 373-399; Blincoe, L., Miller, T.R., Zaloshnja, E., (2010) Lawrence BA, 2015. , The economic and societal impact of motor vehicle crashes, Revised; NHTSA (2012) 2010 motor vehicle crashes: overview. US Department of Transportation, Washington, DC, Research Note DOT HS 811, 552; report, S., New estimates of benefits of crash avoidance features on passenger vehicles (2010) Insurance Institute for Highway Safety, pp. 4-5; Jermakian, J.S., Crash avoidance potential of four passenger vehicle technologies (2011) Accid Anal Prev, 43, pp. 732-740; Farmer, C.M., Crash avoidance potential of five vehicle technologies (2008) Traffic Injury Prevention; Maddox, J., Improving driving safety through automation, congressional robotics caucus (2012) National Highway Traffic Safety Administration; Davidson, P., Spinoulas, A., Autonomous vehicles-what could this mean for the future of transport? (2015) AITPM 2015 National Conference; Greenblatt, J.B., Shaheen, S., Automated vehicles, on-demand mobility, and environmental Impacts (2015) Curr Sustain Renew Energy Rep, 2, pp. 74-81; Templeton, B., Where robot cars (robocars) can really take us. Brad Templeton Robocar Blog (2012) Np, , http://www.templetons.com/brad/robocars/; Dresner, K., Stone, P., Multiagent traffic management: a reservation-based intersection control mechanism (2004) Proceedings of the Third international joint conference on autonomous agents and multiagent systems, 2004. AAMAS, 2004, pp. 530-537; Dresner, K.M., Stone, P., Sharing the Road: autonomous vehicles meet human drivers (2007) IJCAI, pp. 1263-1268; Fajardo, D., Au, T.-C., Waller, S., Stone, P., Yang, D., Automated intersection control: Performance of future innovation versus current traffic signal control (2011) Transp Res Rec, 1, pp. 223-232; Martin, E.W., Shaheen, S., Greenhouse gas emission impacts of carsharing in North America (2011) IEEE Trans Intell Transp Syst, 12, pp. 1074-1086; Schoettle B, Sivak M (2015) Potential impact of self-driving vehicles on household vehicle demand and usage; Melis, W.J., The future of electrical vehicles (2014) Autonomous Vehicles: Intelligent Transport Systems and Smart Technologies, pp. 509-530; Kang, N., Feinberg, F.M., Papalambros, P.Y., Autonomous electric vehicle sharing system design. In: ASME 2015 international design engineering technical conferences and computers and information in engineering conference. American Society of Mechanical Engineers, pp (2015) V02AT03A034–V002AT003A034; Chen, T.D., Management of a shared, autonomous, electric vehicle fleet: vehicle choice (2015) charging infrastructure & pricing strategies; Ploeg, J., Serrarens, A.F.A., Heijenk, G.J., Connect & drive: design and evaluation of cooperative adaptive cruise control for congestion reduction (2011) J Mod Transp, 19, pp. 207-213; Fernandes, P., Nunes, U., Platooning with IVC-enabled autonomous vehicles: strategies to mitigate communication delays, improve safety and traffic flow (2012) IEEE Trans Intell Transp Syst, 13, pp. 91-106; Milakis, D., Snelder, M., Van Arem, B., Van Wee G Homem de Almeida Correia G (2015) Development of automated vehicles in the Netherlands: scenarios for 2030 and; Hensher, D.A., Bliemer, M.C., What type of road pricing scheme might appeal to politicians? Viewpoints on the challenge in gaining the citizen and public servant vote by staging reform (2014) Transp Res Part A, 61, pp. 227-237; Shoup, D.C., (2005) The high cost of free parking, , Planners Press, Chicago; Sridhar, K.S., Sridhar, V., Telecommunications infrastructure and economic growth: evidence from developing countries (2007) Appl Econom Int Dev, p. 7; Alson, J., Hula, A., Bunker, A., Light-duty automotive technology, carbon dioxide emissions, and fuel economy trends: 1975 through 2013. Appendix F (2014) US Environmental Protection Agency, , http://www.epa.gov/oms/fetrends.htm#report, Ann Arbor, Michigan; Hidden costs of energy: unpriced consequences of energy production and use. National Academies Press (2010) doi: 10.17226/12794; Atiyeh, C., Predicting traffic patterns, one Honda at a time. MSN Auto (2012) June, p. 25; Folsom, T., Energy and autonomous urban land vehicles (2012) IEEE Technol Soc Mag, 2, pp. 28-38; Lu, X.-Y., Shladover, S.E., Automated truck platoon control and field test, road vehicle automation (2014) Springer, pp. 247-261; Brooker, A.D., Ward, J., Wang, L., Light weighting impacts on fuel economy, cost, and component losses (2013) SAE Technical Paper; Report on the first quadrennial technology review (2011) In: US Department of Energy, , http://energy.gov/sites/prod/files/QTR_report.pdf; Light-duty automotive technology, carbon dioxide emissions (2013) and fuel economy trends: 1975 through 2012, , http://www.epa.gov/fueleconomy/fetrends/1975-2012/420r13001.pdf, In: Agency UEP (ed.) Transportation and climate division, office of transportation and air quality; Bansal, P., Kockelman, K.M., Forecasting Americans' long-term adoption of connected and autonomous vehicle technologies. In: Transportation research board 95th annual meeting, no (2016) 16-1871; Laslau, C., Holman, M., Saenko, M., See, K., Zhang, Z., Set autopilot for profits: Capitalizing on the $87 billion self-driving car opportunity (2014) In:, , http://www.giiresearch.com/report/lux301508-set-autopilot-profits-capitalizing-on-87-billion.html; Kesting, A., Treiber, M., Helbing, D., Enhanced intelligent driver model to access the impact of driving strategies on traffic capacity (2010) Philos Trans R Soc Lond A, 368, pp. 4585-4605; Levin, M.W., Boyles, S.D., A multiclass cell transmission model for shared human and autonomous vehicle roads (2016) Transp Res Part C, 62, pp. 103-116; Marsden, G., McDonald, M., Brackstone, M., Towards an understanding of adaptive cruise control (2001) Transp Res Part C, 9, pp. 33-51; Van Arem, B., Van Driel, C.J., Visser, R., The impact of cooperative adaptive cruise control on traffic-flow characteristics (2006) IEEE Trans Intell Transp Syst, 7, pp. 429-436; Carlino, D., Depinet, M., Khandelwal, P., Stone, P., Approximately orchestrated routing and transportation analyzer: Large-scale traffic simulation for autonomous vehicles (2012) 15th international IEEE conference on intelligent transportation systems (ITSC), IEEE, 2012, pp. 334-339; Levin, M.W., Boyles, S.D., Intersection auctions and reservation-based control in dynamic traffic assignment (2015) Transportation Research Record, 1, pp. 35-44; Bagloee, S.A., Ceder, A., Tavana, M., Bozic, C., A heuristic methodology to tackle the Braess Paradox detecting problem tailored for real road networks (2013) Transp A, 10, pp. 437-456; Roughgarden, T., Tardos, É., How bad is selfish routing? (2002) J ACM (JACM), 49, pp. 236-259; Bennett, L.D., The existence of equivalent mathematical programs for certain mixed equilibrium traffic assignment problems (1993) Eur J Oper Res, 71, pp. 177-187; Harker, P.T., Multiple equilibrium behaviors on networks (1988) Transp Sci, 22, pp. 39-46; Yang, H., Multiple equilibrium behaviors and advanced traveler information systems with endogenous market penetration (1998) Transp Res Part B, 32, pp. 205-218; Bagloee, S.A., Ceder, A., Bozic, C., Effectiveness of en route traffic information in developing countries using conventional discrete choice and neural-network models (2014) J Adv Transp, 48, pp. 486-506; Bagloee, S.A., Kermanshah, M., Bozic, C., Assessment of public-private partnership in traveler information provision (2013) Transp Res Rec, 2394, pp. 19-29; van Essen, M., Thomas, T., van Berkum, E., Chorus, C., From user equilibrium to system optimum: a literature review on the role of travel information, bounded rationality and non-selfish behaviour at the network and individual levels (2016) Transp Rev, pp. 1-22; Aashtiani, H.Z., The multi-modal traffic assignment problem. PhD dissertation (1979) Massachusetts Institute of Technology; Bar-Gera, H., Boyce D (1999) Route flow entropy maximization in origin-based traffic assignment 14th international symposium on transportation and traffic theory. Elsevier Science, Oxford, U.K., pp. 397-415. , Jerusalem: Israel; Boyce, D., Network equilibrium models for urban transport (2014) Handbook of regional science, pp. 759-786. , Fischer MM, Nijkamp P, (eds), Springer, Berlin; Chen, B.Y., Lam, W.H.K., Sumalee, A., Shao, H., An efficient solution algorithm for solving multi-class reliability-based traffic assignment problem (2011) Math Comput Model, 54, pp. 1428-1439; Dafermos, S.C., The traffic assignment problem for multiclass-user transportation networks (1972) Transp Sci, 6, pp. 73-87; Florian, M., Morosan, C.D., On uniqueness and proportionality in multi-class equilibrium assignment (2014) Transp Res Part B, 70, pp. 173-185; Nagurney, A., A multiclass, multicriteria traffic network equilibrium model (2000) Math Comput Model, 32, pp. 393-411; Nagurney, A., Dong, J., A multiclass, multicriteria traffic network equilibrium model with elastic demand (2002) Transp Res Part B, 36, pp. 445-469; Xie, J., Xie, C., An improved TAPAS algorithm for the traffic assignment problem (2014) 17th international conference on intelligent transportation systems (ITSC), IEEE, 2014, pp. 2336-2341; Xie J, Xie C (2015) Origin-based algorithms for traffic assignment: algorithmic structure, complexity analysis, and convergence performance. In; Transportation Research Board 94th annual meeting; Zhang, G., Chen, J., Solving multi-class traffic assignment problem with genetic algorithm. In: Computational intelligence and natural computing proceedings (CINC), 2010 second international conference on. IEEE, pp (2010) 229–232; Braess, D., Über ein Paradoxon aus der Verkehrsplanung (1968) Unternehmensforschung, 12, pp. 258-268; (2014) GAMS Development Corporation, , GAMS Development Corporation, Washington DC; Chowdhury, M., Dey, K., Intelligent transportation systems-a frontier for breaking boundaries of traditional academic engineering disciplines [Education] (2016) IEEE Intell Transp Syst Mag, 8, pp. 4-8; Sonka, M., (2014) Hlavac, 5. , Boyle R: Image processing, analysis, and machine vision. Cengage Learning; Olson, P.L., Dewar, R., Farber, E., (2010) Forensic aspects of driver perception and response, , Lawyers & Judges Publishing Company, Tucson; Wan, Y., Huang, Y., Buckles, B., Camera calibration and vehicle tracking: highway traffic video analytics (2014) Transp Res Part C, 44, pp. 202-213; Lillesand, T., Kiefer, R.W., Chipman, J., (2014) Remote sensing and image interpretation, , Wiley, New York; Alismail, H., Browning, B., Automatic calibration of spinning actuated lidar internal parameters (2014) J Field Robot, 32, pp. 723-747; Shang, E., An, X., Wu, T., Hu, T., Yuan, Q., He, H., LiDAR based negative obstacle detection for field autonomous land vehicles (2015) J Field Robot; Bengler, K., Dietmayer, K., Farber, B., Maurer, M., Stiller, C., Winner, H., Three decades of driver assistance systems: review and future perspectives (2014) IEEE Intell Transp Syst Mag, 6, pp. 6-22; Fleming, B., Recent advancement in automotive radar systems [Automotive Electronics] (2012) Vehicular Technol Mag IEEE, 7, pp. 4-9; Ilas, C., (2013) Electronic sensing technologies for autonomous ground vehicles: A review 2013 8th international symposium on advanced topics in electrical engineering, pp. 1-6. , ATEE: IEEE; Alonso, L., Milanés, V., Torre-Ferrero, C., Godoy, J., Oria, J.P., De Pedro, T., Ultrasonic sensors in urban traffic driving-aid systems (2011) Sensors, 11, pp. 661-673; Paromtchik, I.E., Laugier, C., Motion generation and control for parking an autonomous vehicle (1996) Proceedings 1996 IEEE International conference on robotics and automation, IEEE, 1996, pp. 3117-3122; Wang, W., Song, Y., Zhang, J., Deng, H., Automatic parking of vehicles: a review of literatures (2014) Int J Automot Technol, 15, pp. 967-978; As of August 19 (2011) 2016:, , http://www.digikey.com/us/en/techzone/sensors/resources/articles/the-burgeoning-use-of-sensors.html; John, V., Mita, S., Liu, Z., Qi, B., Pedestrian detection in thermal images using adaptive fuzzy C-means clustering and convolutional neural networks. In: 2015 14th IAPR international conference on. IEEE machine vision applications (MVA), pp (2015) 246–249; Miura, S., Kamijo, S., Gps error correction by multipath adaptation (2015) Int J Intell Transp Syst Res, 13, pp. 1-8; Dupuis, Y., Merriaux, P., Subirats, P., Boutteau, R., Savatier, X., Vasseur, P., GPS-based preliminary map estimation for autonomous vehicle mission preparation (2014) IEEE/RSJ international conference on intelligent robots and systems (IROS 2014), IEEE, 2014, pp. 4241-4246; Tao, Z., Bonnifait, P., Tightly coupling GPS with lane markings for autonomous vehicle navigation. In IEEE 17th international conference on intelligent transportation systems (ITSC) (2014) IEEE, 2014, pp. 439-444; Britting, K.R., (2010) Inertial navigation systems analysis, , Wiley, New York; Velaskar, P., Vargas-Clara, A., Jameel, O., Redkar, S., Guided navigation control of an unmanned ground vehicle using global positioning systems and inertial navigation systems (2014) Int J Electr Comput Eng (IJECE), 4, pp. 329-342; Yang, X., Liu, J., Vaidya, N.H., Zhao F (2004) A vehicle-to-vehicle communication protocol for cooperative collision warning (2004) networking and services, 2004, pp. 114-123. , MOBIQUITOUS: The First Annual International Conference on. IEEE; Gozálvez, J., Sepulcre, M., Bauza, R., IEEE 802.11 p vehicle to infrastructure communications in urban environments (2012) Commun Mag IEEE, 50, pp. 176-183; Kenney, J.B., Dedicated short-range communications (DSRC) standards in the United States (2011) Proc IEEE, 99, pp. 1162-1182; Kumfer, W., Analysis of the effects of demographic and driver behavior variables on traffic safety and crash prediction (2015) Texas Tech University; Kumfer, W., Burgess, R., Investigation into the Role of Rational Ethics in Autonomous Vehicle Crashes (2015) Transportation Research Board 94th Annual Meeting; Pătraşcu, A., Simion, E., vehicles, A., Cyber security evaluation of critical infrastructures systems (2014) N., B., L., D., N.M., T, pp. 185-205. , Nova Science Publishers: Inc; Hussain, M., Security in connected cars. In: Proceedings of the European Automotive Congress EAEC-ESFA 2015. Springer, pp (2016) 267–275; Schellekens, M., Car hacking: navigating the regulatory landscape (2016) Comput Law Secur Rev, 32, pp. 307-315; IEC 61508, Functional safety of electrical/electronic/programmable electronic safety-related systems, parts 1–7, Ed. 2.0 (2010) IEC Std; Schoitsch, E., Schmittner, C., Ma, Z., Gruber, T., The need for safety and cyber-security co-engineering and standardization for highly automated automotive vehicles. In: Advanced microsystems for automotive applications 2015. Springer, pp (2016) 251–261; ISO 26262 (2011) International Standard 26262 Road vehicles—Functional safety; Davidson P, Spinoulas A (2015b) Autonomous vehicles-what could this mean for the future of transport?},
document_type={Article},
source={Scopus},
}

@ARTICLE{Allen200612,
author={Allen, C. and Wallach, W. and Smit, I.},
title={Why machine ethics?},
journal={IEEE Intelligent Systems},
year={2006},
volume={21},
number={4},
pages={12-17},
doi={10.1109/MIS.2006.83},
art_number={1667947},
note={cited By 104},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33747238879&doi=10.1109%2fMIS.2006.83&partnerID=40&md5=f104149f0af4314546277832ee5ebe6a},
abstract={Machine ethics, which is an emerging field that seeks to implement moral decision making faculties in computers and robots, is discussed. The rapid developments in increasingly complex autonomous software agents and robots have necessitated ethical decision making by the machines. The machine ethics helps an autonomous system recognize possible harmful consequences of an autonomous action thereby minimize harm by selecting its actions accordingly. Artificial moral agents (AMA) need to be incorporated in new autonomous technologies to manage their complexity. Implementing AMA involved a broad range of engineering, ethical, and legal considerations. Robotics and ethical laboratories are taking interest in studying applicability of decision making in artificial systems and the ethical validity of those decisions. Designing artificial systems that function convincingly and autonomously in real physical and social environments required logical representation of relevant facts.},
keywords={Artificial moral agents (AMA);  Artificial systems;  Machine ethics;  Social environments, Artificial intelligence;  Computational complexity;  Decision making;  Robotics;  Social aspects, Autonomous agents},
references={Foot, P., The problem of abortion and the doctrine of double effect (1967) Oxford Rev., 5, pp. 5-15; Nissenbaum, H., How computer systems embody values (2001) Computer, 34 (3), p. 120; Gips, J., Towards the ethical robot (1995) Android Epistemology, pp. 243-252. , K. Ford. C. Glymour, and P. Hayes, eds.. MIT Press; Alien, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2006) Ethics and Information Technology, 7, pp. 149-155. , to be published; Kurzweil, R., (2005) The Singularity Is Near: When Humans Transcend Biology, , Viking Adult; Moravec, H., (2000) Robot: Mere Machine to Transcendent Mind, , Oxford Univ. Press; Searle, J.R., Minds, brains, and programs (1980) Behavioral and Brain Sciences, 3 (3), pp. 417-457; Danielson, P., (1992) Artificial Morality: Virtuous Robots for Virtual Games, , Routledge; Machine ethics (2005) AAAI Fall Symp., , M. Anderson, S.L. Anderson, and C. Armen, eds., tech report FS-05-06, AAA1 Press; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) J. Experimental and Theoretical Artificial Intelligence, 12 (3), pp. 251-261; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds and Machines, 14 (3), pp. 349-379; Damasio, A., (1994) Descartes'Error, , Avon},
document_type={Review},
source={Scopus},
}

@CONFERENCE{Malle2015117,
author={Malle, B.F. and Scheutz, M. and Arnold, T. and Voiklis, J. and Cusimano, C.},
title={Sacrifice One for the Good of Many?: People Apply Different Moral Norms to Human and Robot Agents},
journal={ACM/IEEE International Conference on Human-Robot Interaction},
year={2015},
volume={2015-March},
pages={117-124},
doi={10.1145/2696454.2696458},
note={cited By 77},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943572774&doi=10.1145%2f2696454.2696458&partnerID=40&md5=a0dce5863fd4fbba2bbab8b0bf83d573},
abstract={Moral norms play an essential role in regulating human interaction. With the growing sophistication and proliferation of robots, it is important to understand how ordinary people apply moral norms to robot agents and make moral judgments about their behavior. We report the first comparison of people's moral judgments (of permissibility, wrongness, and blame) about human and robot agents. Two online experiments (total N = 316) found that robots, compared with human agents, were more strongly expected to take an action that sacrifices one person for the good of many (a "utilitarian" choice), and they were blamed more than their human counterparts when they did not make that choice. Though the utilitarian sacrifice was generally seen as permissible for human agents, they were blamed more for choosing this option than for doing nothing. These results provide a first step toward a new field of Moral HRI, which is well placed to help guide the design of social robots. © 2015 ACM.},
author_keywords={human-robot interaction;  machine morality;  moral psychology;  robot ethics},
keywords={Machine design;  Man machine systems;  Robots, Human agent;  Human interactions;  Moral judgment;  moral psychology;  On-line experiments;  Ordinary people;  Robot ethics;  Social robots, Human robot interaction},
references={Bicchieri, C., (2006) The Grammar of Society: The Nature and Dynamics of Social Norms, , New York NY: Cambridge University Press; Joyce, R., (2006) The Evolution of Morality, , MIT Press; Boyd, R., Richerson, P.J., (2005) The Origin and Evolution of Cultures, , New York NY: Oxford University Press; De Waal, F.B.M., (2006) Primates and Philosophers: How Morality Evolved, , Princeton NJ: Princeton University Press; Kohlberg, L., (1981) Essays on Moral Development, , San Francisco CA Harper & Row; Cushman, F., Young, L., Hauser, M., The role of conscious reasoning and intuition in moral judgment (2006) Psychological Science, 17, pp. 1082-1089; Greene, J.D., Sommerville, R.B., Nystrom, L.E., Darley, J.M., Cohen, J.D., An fmri investigation of emotional engagement in moral judgment (2001) Science, 293, pp. 2105-2108; Hauser, M., Cushman, F., Young, L., Kang-Xing Jin, R., Mikhail, J., A dissociation between moral judgments and justifications (2007) Mind & Language, 22, pp. 1-21; Mikhail, J., Moral cognition and computational theory (2008) Moral Psychology Vol. 3: The Neuroscience of Morality, pp. 81-92. , W. Sinnott-Armstrong, Ed. Cambridge, MA MIT Press; Lin, P., The Ethics of Autonomous Cars the Atlantic, , http://www.theatlantic.com/technology/archive/2013/10/theethics-of-Autonomous-cars/280360, 08-Oct2013. [Online]. Available/. [Accessed: 30-Sep2014]; Millar, J., An ethical dilemma: When robot cars must kill who should pick the victim? | Robohub Robohub.Org, , http://robohub.org/an-ethicaldilemma-when-robot-cars-must-kill-who-should-pick-thevictim, Jun2014. [Online]. Available/. [Accessed: 28-Sep-2014]; My (Autonomous) Car, My Safety: Results from Our Reader Poll, , Open Roboethics Initiative, 30-Jun-2014; If death by autonomous car is unavoidable, who should die? Reader Poll Results, , Open Roboethics Initiative, 23-Jun2014; Van De Poel, I., Verbeek, P.-P., Editorial: Ethics and engineering design (2006) Science, Technology, & Human Values, 31, pp. 223-236; Van Der Loos, H.F.M., Ethics by design: A conceptual approach to personal and service robot systems (2007) ICRA Roboethics Workshop, , Rome, Italy IEEE; Crnkovic, G.D., Çürüklü, B., Robots: Ethical by design (2012) Ethics and Information Technology, 14, pp. 61-71; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental & Theoretical Artificial Intelligence, 12, pp. 251-261; Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge University Press; Capurro, R., Nagenborg, M., (2009) Ethics and Robotics, , Heidelberg; [Amsterdam]: AKA ; IOS Press; Lin, P., Abney, K., Bekey, G.A., (2012) Robot Ethics the Ethical and Social Implications of Robotics, , Cambridge MA MIT Press; Malle, B.F., Scheutz, M., Moral competence in social robots (2014) IEEE International Symposium on Ethics in Engineering, Science, and Technology, , Chicago, IL; Sullins, J.P., Introduction: Open questions in roboethics (2011) Philosophy & Technology, 24, p. 233; Wallach, W., Allen, C., (2008) Moral Machines: Teaching Robots Right from Wrong, , New York NY: Oxford University Press; Scheutz, M., Crowell, C., The burden of embodied autonomy: Some reflections on the social and ethical implications of autonomous robots (2007) Proceedings of Workshop on Roboethics at ICRA 2007, , Rome, Italy; Briggs, G., Scheutz, M., How robots can affect human behavior: Investigating the effects of robotic displays of protest and distress (2014) International Journal of Social Robotics, 6, pp. 1-13; Scheutz, M., Malle, B.F., Think and do the right thing" a plea for morally competent autonomous robots (2014) Presented at the 2014 IEEE Ethics Conference, , Chicago, IL; Scheutz, M., The need for moral competency in autonomous agent architectures (2014) Fundamental Issues of Artificial Intelligence, , V. C. Müller, Ed. Berlin Springer; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) Intelligent Systems IEEE, 21, pp. 38-44; Sun, R., Moral judgment human motivation, and neural networks (2013) Cognitive Computation, 5, pp. 566-579; Wallach, W., Franklin, S., Allen, C., A conceptual and computational model of moral decision making in human and artificial agents (2010) Topics in Cognitive Science, 2, pp. 454-485; Kahn, P.H., Jr., Kanda, T., Ishiguro, H., Gill, B.T., Ruckert, J.H., Shen, S., Gary, H.E., Severson, R.L., Do people hold a humanoid robot morally accountable for the harm it causes?, in proceedings of the seventh annual acm/ (2012) IEEE International Conference on Human-Robot Interaction, pp. 33-40. , New York, NY; Monroe, A.E., Dillon, K.D., Malle, B.F., Bringing free will down to earth: People's psychological concept of free will and its role in moral judgment (2014) Consciousness and Cognition, 27, pp. 100-108; Midden, C., Ham, J., The illusion of agency: The influence of the agency of an artificial agent on its persuasive power (2012) Persuasive Technology. Design for Health and Safety, pp. 90-99. , Springer; Strait, M., Canning, C., Scheutz, M., Let me tell you! Investigating the effects of robot communication strategies in advice-giving situations based on robot appearance, interaction modality and distance (2014) Proceedings of the 2014 ACM/IEEE International Conference on Human-robot Interaction, pp. 479-486; Monin, B., Pizarro, D.A., Beer, J.S., Deciding versus reacting: Conceptions of moral judgment and the reason-Affect debate (2007) Review of General Psychology, 11, pp. 99-111; Malle, B.F., Guglielmo, S., Monroe, A.E., A theory of blame (2014) Psychological Inquiry, 25, pp. 147-186; Cushman, F., Crime and punishment: Distinguishing the roles of causal and intentional analyses in moral judgment (2008) Cognition, 108, pp. 353-380; Scanlon, T.C., (2008) Moral Dimensions: Permissibility, Meaning, Blame, , Cambridge, MA Belknap Press; Williston, B., Blaming agents in moral dilemmas (2006) Ethical Theory and Moral Practice, 9, pp. 563-576; Haidt, J., The emotional dog and its rational tail: A social intuitionist approach to moral judgment (2001) Psychological Review, 108, pp. 814-834; Jonathan, H., Björklund, F., Murphy, S., (2000) Moral Dumbfounding: When Intuition Finds No Reason, , University of Virginia, Charlottesville, VA, Unpublished manuscript; Crump, M.J.C., McDonnell, J.V., Gureckis, T.M., Evaluating amazon's mechanical turk as a tool for experimental behavioral research (2013) PLoS ONE, 8, p. e57410; Mason, W., Suri, S., Conducting behavioral research on amazon's mechanical turk (2012) Behavior Research Methods, 44, pp. 1-23; Paolacci, G., Chandler, J., Ipeirotis, P.G., Running experiments on amazon mechanical turk (2010) Judgment and Decision Making, 5, pp. 411-419; Foot, P., The problem of abortion and the doctrine of double effect (1967) Oxford Review, 5, pp. 5-15; Thomson, J.J., The trolley problem (1985) The Yale Law Journal, 94, pp. 1395-1415; Mikhail, J.M., (2011) Elements of Moral Cognition: Rawls' Linguistic Analogy and the Cognitive Science of Moral and Legal Judgment, , New York NY: Cambridge University Press; Bless, H., Schwarz, N., Mental construal and the emergence of assimilation and contrast effects: The inclusion/exclusion model (2010) Advances in Experimental Social Psychology, 42, pp. 319-373. , M. P. Zanna, Ed. San Diego, CA Academic Press},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{KahnJr.2007363,
author={Kahn Jr., P.H. and Ishiguro, H. and Friedman, B. and Kanda, T. and Freier, N.G. and Severson, R.L. and Miller, J.},
title={What is a human? Toward psychological benchmarks in the field of human-robot interaction},
journal={Interaction Studies},
year={2007},
volume={8},
number={3},
pages={363-390},
doi={10.1075/is.8.3.04kah},
note={cited By 76},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-39049138001&doi=10.1075%2fis.8.3.04kah&partnerID=40&md5=76c22a15fb5f40b16efa58360de6c09d},
abstract={In this paper, we move toward offering psychological benchmarks to measure success in building increasingly humanlike robots. By psychological benchmarks we mean categories of interaction that capture conceptually fundamental aspects of human life, specified abstractly enough to resist their identity as a mere psychological instrument, but capable of being translated into testable empirical propositions. Nine possible benchmarks are considered: autonomy, imitation, intrinsic moral value, moral accountability, privacy, reciprocity, conventionality, creativity, and authenticity of relation. Finally, we discuss how getting the right group of benchmarks in human-robot interaction will, in future years, help inform on the foundational question of what constitutes essential features of being human. © John Benjamins Publishing Company.},
author_keywords={Authenticity of relation;  Autonomy;  Creativity;  Human-robot interaction;  Imitation;  Morality;  Privacy;  Psychological benchmarks;  Reciprocity;  Robot ethics},
references={Akiwa, Y., Sugi, Y., Ogata, T., Sugano, S., Imitation based human-robot interaction: - Roles of joint attention and motion prediction (2004) Proceedings of the 14th International Workshop on Robot and Human Interactive Communication, pp. 283-288. , New York: Association for Computing Machinery; Alissandrakis, A., Nehaniv, C.L., Dautenhahn, K., Saunders, J., Evaluation of robot imitation attempts: Comparison of the system's and the human's perspectives (2006) Proceedings of the 1st Annual Conference on Human-Robot Interaction, pp. 134-141. , New York: Association for Computing Machinery; Aylett, R., (2002) Robots: Bringing intelligent machines to life, , Hauppauge, NY: Barron; Baldwin, J.M., (1973) Social and ethical interpretations in mental development, , New York: Arno, Original work published 1897; Bartneck, C., Nomura, T., Kanda, T., Suzuki, T., Kato, K., A cross-cultural study on attitudes towards robots (2005) Proceedings 11th International Conference on Human-Computer Interaction (HCI International 2005), , July 22-27, Las Vegas, USA; Boden, M.A., (2004) The creative mind: Myths and mechanisms, , 2nd edition, New York: Routledge; Breazeal, C.L., (2002) Designing sociable robots: Intelligent robotics and autonomous agents, , Cambridge, MA: MIT Press; Breazeal, C., Buchsbaum, D., Gray, J., Gatenby, D., Blumberg, B., Learning from and about others: Towards using imitation to bootstrap the social understanding of others by robots (2005) Artificial Life, 11, pp. 31-62; Breazeal, C., Scassellati, B., Robots that imitate humans (2002) Trend's in Cognitive Sciences, 6, pp. 481-487; Buber, M., (1996) I and thou, , M. Kaufmann, Trans, New York: Touchstone, Original work published 1970; Buchsbaum, D., Blumberg, B., Breazeal, C., Meltzoff, A.N., A simulation-theory inspired social learning system for interactive characters (2005) Proceedings of the 14th International Workshop on Robot and Human Interactive Communication, pp. 85-90. , Piscataway, NJ: IEEE; Dautenhahn, K., Roles of robots in human society - Implications from research in autism therapy (2003) Robotica, 21, pp. 443-452; (2002) Imitation in animals and artifacts, , Dautenhahn, K, & Nehaniv, C. L, Eds, Cambridge, MA: MIT Press; Dawkins, R., (1976) The selfish gene, , New York: Oxford University Press; Dworkin, R., (1978) Taking rights seriously, , Cambridge: Harvard University Press; Fein, G.G., Pretend play in childhood: An integrative review (1981) Child Development, 52, pp. 1095-1118; Fong, T., Nourbakhsh, I., Dautenhahn, K., A survey of socially interactive robots (2003) Robotics and Autonomous Systems, 42, pp. 143-166; Freier, N.G., Towards an interactional model of children's relationships to personified adaptive systems (2006) Proceedings of the 5th International Conference on Cognitive Science (ICCS 2006), pp. 91-92. , Vancouver, B.C, Canada; Freier, N.G., Children distinguish conventional from moral violations in interactions with a personified agent (2007) Extended Abstracts of the Conference on Human Factors in Computing (CHI'07), pp. 2195-2200. , New York: Association for Computing Machinery; Friedman, B., Kahn Jr., P.H., Human agency and responsible computing: Implications for computer system design (1992) Journal of Systems Software, 17, pp. 7-14; Friedman, B., Kahn Jr., P.H., Human values, ethics, and design (2003) The Human-computer interaction handbook, pp. 1177-1201. , J. A. Jacko & A. Sears Eds, Mahwah, NJ: Erlbaum; Friedman, B., Kahn Jr., P.H., Hagman, J., Hardware companions? What online AIBO discussion forums reveal about the hurnan-robotic relationship (2003) Proceedings of the CHI 2003 Conference on Human Factors in Computing Systems, pp. 273-280. , New York: Association for Computing Machinery; Friedman, B., Lin, P., Miller, J.K., Informed consent by design (2005) Designing Secure Systems that People Can Use, pp. 495-521. , L. Cranor & S. Garfinkel Eds, Cambridge, MA: O'Reilly and Associates; Friedman, B., Millet, L., It's the computer's fault: Reasoning about computers as moral agents (1995) Proceedings of the Conference on Human Factors in Computing Systems, pp. 226-227. , New York: Association for Computing Machinery; Gopnik, A., Meltzoff, A.N., (1998) Words, thoughts, and theories, , Cambridge, MA: MIT Press; Helwig, C.C., Tisak, M., Turiel, E., Children's social reasoning in context (1990) Child Development, 61, pp. 2068-2078; (1981) The mind's I, , Hofstadter, D. R, & Dennett, D. C, Eds, New York: Basic Books; Ishiguro, H., Toward interactive humanoid robots: A constructive approach to developing intelligent robots (2004) Proceedings of the third International Joint Conference on Autonomous Agents and Multi-Agent Systems (AAMAS 2004), pp. 621-622. , New York: Association for Computing Machinery; Ishiguro, H., Android science: Toward a new cross - disciplinary framework (2005) Cogsci- 2005 workshop: Toward social mechanisms of android sciences, pp. 1-6. , Stresa, Italy; John-Steiner, V., (2000) Creative Collaboration, , New York: Oxford University Press; Kahn Jr., P.H., Children's obligatory and discretionary moral judgments (1992) Child Development, 63, pp. 416-430; Kahn Jr., P.H., (1999) The human relationship with nature: Development and culture, , Cambridge, MA: MIT Press; Kahn Jr., P.H., Freier, N.G., Friedman, B., Severson, R.L., Feldman, E., Social and moral relationships with robotic others? (2004) Proceedings of the 13th International Workshop on Robot and Human Interactive Communication (RO-MAN'04), pp. 545-550. , Piscataway, NJ: IEEE; Kahn Jr., P.H., Friedman, B., Perez-Granados, D.R., Freier, N.G., Robotic pets in the lives of preschool children (2006) Interaction Studies: Social Behavior and Communication in Biological and Artificial Systems, 7, pp. 405-436; Kanda, T., Hirano, T., Eaton, D., Ishiguro, H., Interactive robots as social partners and peer tutors for children: A field trial (2004) Human Computer Interaction, 19, pp. 61-84; Kanda, T., Ishiguro, H., Imai, M., Ono, T., Development and evaluation of interactive humanoid robots (1839) Proceedings of the IEEE (Special issue on Human interactive robot for psychological enrichment), , 2004; Kaplan, F., Artificial attachment: Will a robot ever pass Ainsworth's strange situation test? (2001) Proceedings of Humanoids 2001: IEEE-RAS International Conference on Humanoid Robots, pp. 99-106. , S. Hashimoto Ed, Piscataway, NJ: IEEE; Kiesler, S., Goetz, J., Mental models of robotic assistants (2002) Extended Abstracts of the Conference on Human Factors in Computing Systems (CHI '02), pp. 576-577. , New York: Association for Computing Machinery; Kohlberg, L., Stage and sequence: The cognitive-developmental approach to socialization (1969) Handbook of socialization theory and research, pp. 347-480. , D. A. Goslin Ed, New York: Rand McNally; Kohlberg, L. (1984). Essays in moral development: II. The psychology of moral development. San Francisco: Harper & Row; MacDorman, K.F., Androids as an experimental apparatus: Why is there an uncanny valley and can we exploit it? (2005) CogSci-2005 Workshop: Toward Social Mechanisms of Android Science, pp. 106-118. , Stresa, Italy; MacDorman, K.F., Ishiguro, H., The uncanny advantage of using androids in cognitive and social science research (2006) Interaction Studies: Social Behavior and Communication in Biological and Artificial Systems, 7, pp. 297-337; Mei, Y.P., Mo Tzu (1972) The Encyclopedia of Philosophy, 5, pp. 409-410. , P. Edwards Ed, New York: Macmillan; Melson, G.F., Kahn Jr., P.H., Beck, A.M., Friedman, B., Roberts, T., Garrett, E., Robots as dogs? - Children's interactions with the robotic dog AIBO and a live Australian Shepherd (2005) Extended Abstracts of the Conference on Human Factors in Computing Systems (CHI'05), pp. 1649-1652. , New York: Association for Computing Machinery; Meltzoff, A.N., Understanding the intentions of others: Re-enactment of intended acts by 18-month-old children (1995) Developmental Psychology, 31, pp. 838-850; Minato, T., Shimada, M., Ishiguro, H., Itakura, S., Development of an android robot for studying human-robot interaction (2004) Proceedings of the 17th International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems, pp. 424-434. , New York: Association for Computing Machinery; Myers, B., Hollan, J., Cruz, I., Bryson, S., Bulterman, D., Catarci, T., Citrin, W., Ioannidis, Y., Strategic directions in human-computer interaction (1996) ACM Computing Surveys, 28, pp. 794-809; Nourbakhsh, R.I., A roadmap for technology literacy and a vehicle for getting there: Educational robotics and the TeRK project. Plenary (2006) The 15th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN '06), , presented at, September 6-8, University of Hertfordshire, Hatfield, Hertfordshire, UK; (2004) Oxford English Dictionary, , http://dictionary.oed.com, Oxford University Press, Oxford, England. Retrieved May 24, 2004 from; Piaget, J., (1969) The moral judgment of the child, , Glencoe, IL: Free Press, Original work published 1932; Piaget, J., (1970) Structuralism, , New York: Harper and Row; Piaget, J. (1983). Piaget's theory. In W. Kessen (Ed.), P. H. Mussen (Series Ed.), Handbook of child psychology: 1. History, theory, and methods (4th ed., pp. 103-128). New York: Wiley; Povinelli, D.J., (2000) Folk physics for apes: The chimpanzee's theory of how the world works, , New York: Oxford University Press; Searle, J.R., Is the brain's mind a computer program? (1990) Scientific American, 262 (1), pp. 26-31; Severson, R.L., Kahn Jr., P.H., Social and moral judgments about pesticides and the natural environment: A developmental study with farm worker children (2005) biennial meeting of the Society for Research in Child Development, , April, Paper presented at the, Atlanta, GA; Skinner, B.F., (1974) About behaviorism, , New York: Knopf; Smetana, J.G., Morality in context: Abstractions, ambiguities and applications (1995) Annals of Child Development, 10, pp. 83-130. , R. Vasta Ed, London: Jessica Kingsley; Smetana, J., Parenting and the development of social knowledge reconceptualized: A social domain analysis (1997) Handbook of parenting and the transmission of values, pp. 162-192. , J. E. Grusec & L. Kuczynski Eds, New York: Wiley; Steinfeld, A., Fong, T., Kaber, D., Lewis, M., Scholtz, J., Schultz, A., Goodrich, M., Common metrics for human-robot interaction (2006) Proceedings of the 1st Annual Conference on Human-Robot Interaction (HRI'06), pp. 33-40. , New York: Association for Computing Machinery; Sternberg, R. J. (2005). Creativity or creativities? In E. A. Edmonds & L. Candy (Eds.), Special Issue on Computer support for creativity. International Journal Human-Computer Studies, 63, 370-382; Sternberg, R.J., The nature of creativity (2006) Creativity Research Journal, 18, pp. 87-98; Sternberg, R.J., Lubart, T.I., An investment theory of creativity and its development (1991) Human Development, 34, pp. 1-31; Tisak, M.S., Domains of social reasoning and beyond (1995) Annals of Child Development, 11, pp. 95-130. , R. Vasta Ed, London: Jessica Kingsley; Tomasello, M., (2000) The cultural origins of human cognition, , Cambridge, MA: Harvard University Press; Turiel, E., (1983) The development of social knowledge, , Cambridge, England: Cambridge University Press; Turiel, E. (1998). Moral development. In W. Damon (Ed.), Handbook of child psychology. (5th ed.). 3: N. Eisenberg (Ed.), Social, emotional, and personality development (pp. 863-932). New York: Wiley; Turiel, E., Davidson, P., Heterogeneity, inconsistency, and asynchrony in the development of cognitive structures (1986) Stage and structure: Reopening the debate, pp. 106-143. , I. Levin Ed, Norwood, NJ: Ablex; Turiel, E., Killen, M., Helwig, C.C., Morality: Its structure, functions and vagaries (1987) The emergence of morality in young children, pp. 155-244. , J. Kagan and S. Lamb Eds, Chicago: University of Chicago Press; Yamamoto, D., Doi, M., Matsuhira, N., Ueda, H., Kidode, M., Behavior fusion in a robotic interface for practicality and familiarity: Approach by simultaneous imitations (2004) Proceedings of the 14th International Workshop on Robot and Human Interactive Communication (HRI'04), pp. 114-119. , New York: Association for Computing Machinery},
document_type={Article},
source={Scopus},
}

@ARTICLE{Arkin2012571,
author={Arkin, R.C. and Ulam, P. and Wagner, A.R.},
title={Moral decision making in autonomous systems: Enforcement, moral emotions, dignity, trust, and deception},
journal={Proceedings of the IEEE},
year={2012},
volume={100},
number={3},
pages={571-589},
doi={10.1109/JPROC.2011.2173265},
art_number={6099675},
note={cited By 69},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857370423&doi=10.1109%2fJPROC.2011.2173265&partnerID=40&md5=953e85b9bc4cd5dea58e71546047bf01},
abstract={As humans are being progressively pushed further downstream in the decision-making process of autonomous systems, the need arises to ensure that moral standards, however defined, are adhered to by these robotic artifacts. While meaningful inroads have been made in this area regarding the use of ethical lethal military robots, including work by our laboratory, these needs transcend the warfighting domain and are pervasive, extending to eldercare, robot nannies, and other forms of service and entertainment robotic platforms. This paper presents an overview of the spectrum and specter of ethical issues raised by the advent of these systems, and various technical results obtained to date by our research group, geared towards managing ethical behavior in autonomous robots in relation to humanity. This includes: 1) the use of an ethical governor capable of restricting robotic behavior to predefined social norms; 2) an ethical adaptor which draws upon the moral emotions to allow a system to constructively and proactively modify its behavior based on the consequences of its actions; 3) the development of models of robotic trust in humans and its dual, deception, drawing on psychological models of interdependence theory; and 4) concluding with an approach towards the maintenance of dignity in human-robot relationships. © 2011 IEEE.},
author_keywords={Autonomous robots;  robot ethics;  unmanned systems},
keywords={Decision making;  Decision support systems;  Philosophical aspects;  Robotics, Autonomous systems;  Decision making process;  Entertainment robotics;  Ethical behavior;  Psychological model;  Robot ethics;  Robotic behavior;  Unmanned system, Robots},
references={Adams, J., US defends unmanned drone attacks after harsh un Report (2010) Christian Science Monitor, , http://www.csmonitor.com/World/terrorism-security/2010/0603/ US-defends-unmanned-drone-attacks-after-harsh-UN-report, Jun. 5 [Online]. Available; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) IEEE Intell. Syst., 21 (4), pp. 12-17. , Jul./Aug; Amodio, D., Devine, P., Harmon-Jones, E., A dynamic model of guilt (2007) Psychol. Sci., 18 (6), pp. 524-530; Anderson, M., Anderson, S., Armen, C., An approach to computing ethics (2006) IEEE Intell. Syst., 21 (4), pp. 56-63. , Jul./Aug; Arkin, R.C., (1998) "ehavior-Based Robotics, , Cambridge, MA: MIT Press; Arkin, R.C., Moving up the food chain: Motivation and emotion in behavior-based robots (2005) Who Needs Emotions: The Brain Meets the Robot, , J. Fellous and M. Arbib, Eds. Oxford, U.K.: Oxford Univ. Press; Arkin, R.C., (2009) Governing Lethal Behavior in Autonomous Systems, , London U.K.: Taylor & Francis; Arkin, R.C., The case for ethical autonomy in unmanned systems (2010) J. Military Ethics, 9 (4), pp. 332-341; Arkin, R., Fujita, M., Takagi, T., Hasegawa, R., An ethological and emotional basis for human-robot interaction (2003) Robot. Autonom. Syst., 42 (3-4), pp. 191-201. , Mar; Arkin, R.C., Ulam, P., An ethical adaptor: Behavioral modification derived from moral emotions (2009) Proc. IEEE Int. Symp. Comput. Intell. Robot. Autom, pp. 381-387. , Daejeon, Korea, Dec; Arkin, R.C., Wagner, A., Duncan, B., Responsibility and lethality for unmanned systems: Ethical pre-mission responsibility advisement (2009) Proc. IEEE Workshop Roboethics, pp. 1-8. , Kobe, Japan May; Arkoudas, K., Bringsjord, S., Bello, P., Toward ethical robots via mechanized deontic logic (2005) AAAI Tech. Rep. FS-05-06, , AAAI Fall Symposium on Machine Ethics; Baldor, L., (2006) Military Declined to Bomb Group of Taliban at Funeral, , Washington DC: Associated Press, Sep. 14; Bond, C.F., Robinson, M., The evolution of deception (1988) J. Nonverbal Behav., 12 (4), pp. 295-307; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intell. Syst., 21 (4), pp. 38-44. , Jul./Aug; Brosnan, S.F., Nonhuman species' reactions to inequity and their implications for fairness (2006) Social Justice Research, 19 (2), pp. 153-185. , DOI 10.1007/s11211-006-0002-z; Cervellati, M., Esteban, J., Kranich, L., Moral values, self-regulatory emotions, and redistribution Inst. Econ. Anal, , "arcelona, Spain working paper, May 2007; Cheney, D., Seyfarth, R., (2007) "aboon Metaphysics, , Chicago, IL: Univ. Chicago Press; Conway, F., Siegelman, T., Dark hero of the information age (2006) Search of Norbert Wiener the Father of Cybernetics, , New York: Basic Books; De Melo, C., Zheng, L., Gratch, J., Expression of moral emotions in cooperating agents (2009) Proc. Int. Conf. Intell. Virtual Agents, , Amsterdam, The Netherlands DOI: 10.1007/978-3-642-04380-2-32; Ettinger, D., Jehiel, P., Towards a theory of deception (2009) ESRC Centre for Economic Learning and Social Evolution, 181. , London, U.K., ELSE Working Papers; (2007) EURON Roboethics Roadmap, , Version 2.0; Fellous, J., Arbib Eds, M., (2005) Who Needs Emotions: The Brain Meets the Robot, pp. 245-270. , Oxford U.K.: Oxford Univ. Press; Filkins, D., (2010) Operators of Drones Are Faulted in Afghan Deaths, , http://www.nytimes.com/2010/05/30/world/asia/30drone.html, New York Times May 29 [Online]. Available; Gazzaniga, M.S., (2005) The Ethical Brain, , New York: Dana Press; Gerwehr, S., Glenn, R.W., (2000) The Art of Darkness: Deception and Urban Operations, , Rand Corporation, Santa Monica, CA; Haidt, J., The moral emotions (2003) Handbook of Affective Sciences, , R. J. Davidson, K. R. Scherer, and H. Hill Goldsmith, Eds. Oxford, U.K.: Oxford Univ. Press; Horty, J., (2001) Agency and Deontic Logic, , Oxford U.K.: Oxford Univ Press; Ikuta, K., Nokata, M., Ishii, H., Safety evaluation method of human-care robot control (2000) Proc. Int. Symp. Micromechatron. Human Sci., pp. 119-127; Joy, W., Why the future doesn't need us (2000) Wired, 804. , http://www.wired.com/wired/archive/8.04/joy.html, Apr. [Online]. Available; Kelley, H.H., Holmes, J.G., Kerr, N.L., Reis, H.T., Rusbult, C.E., Lange, P.A.M.V., (2003) An Atlas of Interpersonal Situations, , New York: Cambridge Univ. Press; Kelley, H.H., Thibaut, J.W., (1978) Interpersonal Relations: A Theory of Interdependence, , New York: Wiley; MacKenzie, D., Arkin, R.C., Cameron, J., Multiagent mission specification and execution (1997) Autonom. Robots, 4 (1), pp. 29-57. , Jan; Marchant, G., Allenby, B., Arkin, R., Barrett, E., Borenstein, J., Gaudet, L., Kittrie, O., Silberman, J., International governance of autonomous military robots (2011) Columbia Sci. Technol. Law Rev., , http://www.stlr.org/volumes/volume-xii-2010-2011/marchant/, [Online]. Available; Moor, J., The nature, importance, and difficulty of machine ethics (2006) IEEE Intell. Syst., 21 (4), pp. 18-21. , Jul./Aug; Moravec, H., Children, M., (1990) The future of robot and human intelligence, , Cambridge MA: Harvard Univ. Press; Moshkina, L., Arkin, R.C., Lee, J., Jung, H., Time varying affective response for humanoid robots (2009) Proc. Int. Conf. Social Robot, , Seoul, Korea Aug. DOI: 10.1.1.149.9375; Norderflet, L., Dignity and the care of the elderly (2003) Med. Health Care Philosophy, 6, pp. 103-110; Norman, R., (1995) Ethics Killing and War, , Cambridge U.K.: Cambridge Univ. Press; Norman, D., Some observations on mental models (1983) Mental Models, , D. Gentner and A. Stevens, Eds. Hillsdale, NJ: Lawrence Erlbaum; Osborne, M.J., Rubinstein, A., (1994) A Course in Game Theory, , Cambridge MA: MIT Press; Pfaff, D., (2007) The Neuroscience of Fair Play, , New York: Dana Press; Powers, A., Kiesler, S., The advisor robot: Tracing people's mental model from a robot's physical attributes (2006) HRI 2006: Proceedings of the 2006 ACM Conference on Human-Robot Interaction, 2006, pp. 218-225. , HRI 2006: Proceedings of the 2006 ACM Conference on Human-Robot Interaction - Toward Human Robot Collaboration; Rizzolati, G., Sinigaglia, C., (2008) Mirrors in the Brain: How Our Minds Share Actions and Emotions, , Oxford U.K.: Oxford Univ. Press; Sharkey, N., The ethical frontiers of robotics (2008) Science, 322, pp. 1800-1801. , Dec. 12; Smits, D.J.M., De Boeck, P., A componential IRT model for guilt (2003) Multivariate Behavioral Research, 38 (2), pp. 161-188; Spenko, M., Yu, H., Dubowsky, S., Robotic personal aids for mobility and monitoring for the elderly (2006) IEEE Transactions on Neural Systems and Rehabilitation Engineering, 14 (3), pp. 344-351. , DOI 10.1109/TNSRE.2006.881534; Sullivan, R., (2010) Drone Crew Blamed in Afghan Civilian Deaths, , Washington DC: Associated Press, May 5; Tangney, J., Stuewig, J., Mashek, D., Moral emotions and moral behavior (2007) Annu. Rev. Psychol., 58, pp. 345-372; Veruggio, G., The birth of roboethics (2005) Proc. IEEE Int. Conf. Robot. Autom. Workshop Robo-Ethics, "arcelona, pp. 2-4. , Spain Apr. 18; Wagner, A., (2009) The Role of Trust and Relationships in Human-robot Interaction, , Ph.D. dissertation Schl. Interactive Comput., Georgia Inst. Technol., Atlanta, GA Dec; Wagner, A., Arkin, R.C., Analyzing social situations for human-robot interaction (2008) Interaction Studies, 9 (2), pp. 277-300; Wagner, A., Arkin, R.C., Acting deceptively: Providing robots with the capacity for deception (2011) Int. J. Social Robot., 3 (1), pp. 5-26; Walzer, M., (1977) Just and Unjust Wars, , 4th ed New York: Basic Books; Wells, D., (1996) An Encyclopedia of War and Ethics, , Ed Westport, CT: Greenwood Press; Wiegel, V., Hoven Den M.Van, Lokhorst, G., Privacy, deontic epistemic action logic and software agents (2005) Ethics Inf. Technol., 7, pp. 251-264; Zinn, M., Khatib, O., Roth, B., Salisbury, K., Playing it safe: A new concept for human-friendly robot design (2004) IEEE Robot. Autom. Mag., 11 (2), pp. 13-21. , Jun},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Powers200646,
author={Powers, T.M.},
title={Prospects for a kantian machine},
journal={IEEE Intelligent Systems},
year={2006},
volume={21},
number={4},
pages={46-51},
doi={10.1109/MIS.2006.77},
art_number={1667953},
note={cited By 68},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33747293847&doi=10.1109%2fMIS.2006.77&partnerID=40&md5=4d0d4b565d9f6cdc66adf17d60e57b55},
abstract={Rule-based ethical theories like Immanuel Kant's appear to be promising for machine ethics because they offer a computational structure for judgment. The utilitarian tradition holds that it is essentially arithmetic that reaches the right ethical conclusion by calculating the prospective utility for all individuals who will be affected by a set of possible actions and then choosing the action that promises to maximize total utility. The deontological tradition holds that some actions ought or ought not to be performed, irrespective of how they might affect others. Deontology emphasizes complex reasoning about actions and their logical implications and focuses on rules for action. Human practical reasoning primarily concerns the transformation between the consideration of facts and ensuing actions which resembles a machine's state changes when it goes from a set of declarative units in a database to an output.},
keywords={Deontology;  Human practical reasoning;  Kantian machine, Computational methods;  Database systems;  Formal logic;  Mathematical transformations;  Set theory, Learning systems},
references={Kant, I., (1981) Grounding for the Metaphysics of Morals, , translated by J. Ellington, Hackett; Kant, I., (1991) Bemerkungen in Den "Beobachtungen Über das Gefühl des Schönen und Erhabenen", , [Unpublished Notes on "Observations on the Feeling of the Beautiful and the Sublime"], Felix-Meiner Verlag, (in German, translated by the author); Neill, O., (1989) Constructions of Reason, , Cambridge University Press; Horty, J., (2001) Agency and Deontic Logic, , Oxford Univ. Press; Silber, J., Procedural formalism in kant"s ethics (1974) Review of Metaphysics, 28, pp. 197-236; Rawls, J., Kantian Constructivism in moral theory (1980) J. Philosophy, 77 (9), pp. 515-572; Reiter, R., A logic for default reasoning (1980) Artificial Intelligence, 13, pp. 81-132; Poole, D., Default logic (1994) Handbook of Logic in Artificial Intelligence and Logic Programming, , D. Gabbay, C. Hogger, and J. Robinson, eds., Oxford, Univ. Press; Gärdenfors, P., (1988) Knowledge in Flux: Modeling the Dynamics of Epistemic States, , MIT Press},
document_type={Review},
source={Scopus},
}

@ARTICLE{Lin2011942,
author={Lin, P. and Abney, K. and Bekey, G.},
title={Robot ethics: Mapping the issues for a mechanized world},
journal={Artificial Intelligence},
year={2011},
volume={175},
number={5-6},
pages={942-949},
doi={10.1016/j.artint.2010.11.026},
note={cited By 62},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79953218320&doi=10.1016%2fj.artint.2010.11.026&partnerID=40&md5=07b6f1022e38ff11de8655f62b516d7a},
abstract={As with other emerging technologies, advanced robotics brings with it new ethical and policy challenges. This paper will describe the flourishing role of robots in society-from security to sex-and survey the numerous ethical and social issues, which we locate in three broad categories: safety & errors, law & ethics, and social impact. We discuss many of these issues in greater detail in our forthcoming edited volume on robot ethics from MIT Press. © 2011 Elsevier B.V. All rights reserved.},
author_keywords={Error;  Ethics;  Law;  Philosophy;  Policy;  Psychology;  Robot;  Robotics;  Safety;  Society},
keywords={Accident prevention;  Errors;  Philosophical aspects;  Public policy;  Robotics;  Robots, Emerging technologies;  Ethics;  Philosophy;  Psychology;  Robot ethics;  Social impact;  Social issues;  Society, Economic and social effects},
references={Abramson, J., Arms Control Association: The Ottawa Convention at A Glance, , http://www.armscontrol.org/factsheets/ottawa; Agarwal, A., Desai, N.R., Makker, K., Varghese, A., Mouradi, R., Sabanegh, E., Sharma, R., Effects of radiofrequency electromagnetic waves (RF-EMW) from cellular phones on human ejaculated semen: An in vitro pilot study (2009) Fertility and Sterility, 92 (4), pp. 1318-1325; Allhoff, F., Lin, P., Moore, D., (2010) What Is Nanotechnology and Why Does It Matter?: From Science to Ethics, , Wiley-Blackwell Hoboken, NJ; Arkin, R.C., Governing Lethal Behavior: Embedding Ethics in A Hybrid Deliberative/hybrid Robot Architecture, , http://www.cc.gatech.edu/ai/robot-lab/online-publications/ formalizationv35.pdf; Asimov, I., (1950) I, Robot, , 2004 edition Bantam Dell New York, NY; Asimov, I., (1957) The Naked Sun, , Doubleday New York, NY; Asimov, I., My own view (1978) The Encyclopedia of Science Fiction; Asimov, I., (1985) Robots and Empire, , Doubleday New York, NY; Bekey, G., (2005) Autonomous Robots: From Biological Inspiration to Implementation and Control, , MIT Press Cambridge, MA; Benner, S.A., Q&A: Life, synthetic biology, and risk (2010) BMC Biology, 8, p. 77; Elisabeth Bumiller, The New York Times: Navy Drone Violated Washington Airspace (Aug. 25, 2010); Ryan Calo Robots, M., Robots and Privacy, , http://ssrn.com/abstract=1599189; Čapek, K., (1921) Rossums Universal Robots, , 2004 edition Penguin Group New York, NY; Davidson, K., How a butterflys wing can bring down Goliath (2003) San Francisco Chronicle; Karrar-Irans New Jet-powered Recce and Attack Drone, , http://defense-update.com/products/k/karrar_jet_powered_drone_24082010. html; Dick, P.K., (1968) Do Androids Dream of Electric Sheep?, , Del Rey Books New York, NY; Fulbright, Y., Meet Roxxxy, the 'Woman' of Your Dreams, , http://www.foxnews.com/story/0,2933,583314,00.html; Gates, B., A robot in every home (2007) Scientific American, pp. 58-65; Geipel, G., Global Aging and the Global Workforce, A Hudson Institute Article, , http://www.hudson.org/index.cfm?fuseaction=publication_details&id= 2740; Gorman, C., Danger in the diet pills? (1997) Time Magazine, , http://www.time.com/time/magazine/article/0,9171,986725,00.html; Guizzo, E., IEEE Spectrum: World Robot Population Reaches 8.6 Million, , http://spectrum.ieee.org/automaton/robotics/industrial-robots/ 041410-world-robot-population; Hsu, J., Real soldiers love their robot brethren (2009) Live Science, , http://www.livescience.com/technology/090521-terminator-war.html; Kiska, T., Death on the job: Jury awards $10 million to heirs of man killed by robot at auto plant (1983) Philadelphia Inquirer, p. 10; Lear, L., (1997) Rachel Carson: Witness for Nature, , Henry Hoyten New York, NY; Levy, D., (2007) Love and Sex with Robots: The Evolution of Human-Robot Relationships, , Harper Collins Publishers New York, NY; Lin, P., Bekey, G., Abney, K., Autonomous Military Robots: Risk, Ethics, and Design, , http://ethics.calpoly.edu/ONR_report.pdf; Lin, P., Bekey, G., Abney, K., Robots in war: Issues of risk and ethics (2009) Ethics and Robotics; Lin, P., Abney, K., Bekey, G., Robot Ethics: The Ethical and Social Implications of Robotics, , MIT Press, Cambridge, MA (forthcoming); Madrigal, A., Market data firm spots the tracks of bizarre robot traders (2010) The Atlantic; Moor, J.H., (1985) Metaphilosophy: What Is Computer Ethics?, 16 (4), pp. 266-275; Odonoghue, A.J., E-waste is a growing issue for states (2010) Deseret News, , http://www.deseretnews.com/article/700059360/E-waste-is-a-growing-issue- for-states.html?pg=1; Japan Hopes to Employ Robots by 2025, , http://www.redorbit.com/news/technology/1332274/ japan_hopes_to_employ_robots_by_2025/, RedOrbit; Rosenberg, M., The surprising benefits of robots in the DC (2009) Supply & Demand Chain Executive; Schactman, N., Robot cannon kills 9, wounds 14 (2007) Wired, , http://blog.wired.com/defense/2007/10/robot-cannon-ki.html; Schoenberger, C., Japans shrinking workforce (2008) Forbes, , http://www.forbes.com/2008/05/25/immigration-labor-visa-oped- cx_crs_outsourcing08_0529japan.html; Sharkey, N., 2084: Big Robot Is Watching You, A Commissioned Report, , http://www.dcs.shef.ac.uk/~noel/; Sharma, V.P., Kumar, N.R., Changes in honeybee behaviour and biology under the influence of cellphone radiations (2010) Current Science, 98 (10), pp. 1376-1378; Singer, P.W., (2009) Wired for War: The Robotics Revolution and Conflict in the 21st Century, , Penguin Press New York, NY; Singer, P.W., Robots at war: The new battlefield (2009) Wilson Quarterly, , http://www.wilsonquarterly.com/article.cfm?aid=1313; The Convention on Certain Conventional Weapons, , http://www.armscontrol.org/factsheets/CCW, United Nations; Asbestos Ban and Phase Out, , http://www.epa.gov/asbestos/pubs/ban.html, US Environmental Protection Agency; (2006) EURON Roboethics Roadmap, EURON Roboethics Atelier, , http://www.roboethics.org/atelier2006/docs/ROBOETHICS%20ROADMAP%20Rel2.1. 1.pdf, Gianmarco Veruggio, EURON Genoa, Italy; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press New York; Warwick, K., Implications and consequences of robots with biological brains (2010) Ethics & Information Technology, 12 (1); Wilson, D.H., (2005) How to Survive A Robot Uprising: Tips on Defending Yourself Against the Coming Rebellion, , Bloomsbury Publishing New York, NY; Zucchino, D., War zone drone crashes add up (2010) Los Angeles Times},
document_type={Review},
source={Scopus},
}

@ARTICLE{Torrance2008495,
author={Torrance, S.},
title={Ethics and consciousness in artificial agents},
journal={AI and Society},
year={2008},
volume={22},
number={4},
pages={495-521},
doi={10.1007/s00146-007-0091-8},
note={cited By 53},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547231992&doi=10.1007%2fs00146-007-0091-8&partnerID=40&md5=fdc07f667d85156fead3081214e70d2d},
abstract={In what ways should we include future humanoid robots, and other kinds of artificial agents, in our moral universe? We consider the Organic view, which maintains that artificial humanoid agents, based on current computational technologies, could not count as full-blooded moral agents, nor as appropriate targets of intrinsic moral concern. On this view, artificial humanoids lack certain key properties of biological organisms, which preclude them from having full moral status. Computationally controlled systems, however advanced in their cognitive or informational capacities, are, it is proposed, unlikely to possess sentience and hence will fail to be able to exercise the kind of empathic rationality that is a prerequisite for being a moral agent. The organic view also argues that sentience and teleology require biologically based forms of self-organization and autonomous self-maintenance. The organic view may not be correct, but at least it needs to be taken seriously in the future development of the field of Machine Ethics. © Springer-Verlag London Limited 2007.},
keywords={Artificial agents;  Biological organisms;  Computational technology;  Controlled system;  Humanoid agents;  Moral concerns;  Self organizations;  Self-maintenance, Anthropomorphic robots;  Behavioral research, Philosophical aspects},
references={Anderson, M., Anderson, S.L., Armen, C., (2005) Machine Ethics. Papers from the AAAI Fall Symposium, , Anderson M, Anderson SL, Armen C (eds) Technical report FS-05-06. AAAI Press, Menlo Park, CA; Calverley, D., Towards a method for determining the legal status of a conscious machine (2005) Next Generation Approaches to Machine Consciousness: Imagination, Development, Intersubjectivity, and Embodiment (Proceedings of an AISB05 Symposium), pp. 75-84. , In: Chrisley R, Clowes R, Torrance S (eds) University of Hertfordshire, Hertfordshire, UK; Calverley, D., Android science and the animals rights movement: Are there analogies? Toward social mechanisms of android science (2005) Proceedings of CogSci-2005 Workshop, Cognitive Science Society, Stresa, Italy, pp. 127-136; Di Paolo, E., Organismically-inspired robotics: Homeostatic adaptation and natural teleology beyond the closed sensorimotor loop (2003) Dynamical Systems Approach to Embodiment and Sociality. Advanced Knowledge International, Adelaide, pp. 19-42. , In: Murase K, Asakura T (eds); Di Paolo, E., Autopoiesis, adaptivity, teleology, agency (2005) Phenomenol Cogn Sci, 4 (4), pp. 429-452; Floridi, L., Sanders, J., On the morality of artificial agents (2004) Mind Mach, 14 (3), pp. 349-379; Franklin, S., IDA: A conscious artefact? (2003) J Conscious Stud, 10 (4-5), pp. 47-66; (2003) Machine Consciousness, , Holland O (ed) Imprint Academic, Exeter (also published as special issue of J Conscious Stud 10(4-5)); Jonas, H., (1966) The Phenomenon of Life: Towards a Philosophical Biology, , Northwestern U.P., Evanston, IL, USA; Letelier, J., Marin, G., Mpodozis, J., Autopoietic and (M, R) systems (2003) J Theor Biol, 222 (2), pp. 261-272; Maturana, H., Varela, F., (1980) Autopoiesis and Cognition: The Realization of the Living, , D. Reidel, Dordrecht, Holland; Picard, R., (1997) Affective Computing, , MIT, Cambridge, MA; Strawson, P.F., Freedom and resentment (1974) Freedom and Resentment and Other Essays, , In: Strawson PF (ed) Methuen, London; Thompson, E., Life and mind: From autopoiesis to neurophenomenology, a tribute to Francisco Varela (2004) Phenomenol Cogn Sci, 3 (4), pp. 381-398; Thompson, E., Sensorimotor subjectivity and the enactive approach to experience (2005) Phenomenol Cogn Sci, 4 (4), pp. 407-427; Thompson, E., (2007) Mind in Life: Biology, Phenomenology, and the Sciences of Mind, , Harvard University Press; Torrance, S.B., Ethics, mind and artifice (1986) AI for Society, pp. 55-72. , In: Gill KS (ed) John, Chichester; Torrance, S.B., Producing mind (2000) J Exp Theor Artif Intell Xxxx; Torrance, S.B., Us and them: Living with self-aware systems (2004) Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, 3, pp. 7-14. , In: Smit I, Wallach W, Lasker G (eds) IIAS, Windsor, ON; Torrance, S.B., Two conceptions of machine phenomenality (2007) J Conscious Stud, , forthcoming; (1948) U.N. Universal Declaration of Human Rights, , http://www.unhchr.ch/udhr/index.htm, United Nations; Varela, F., Thompson, E., Rosch, E., (1991) The Embodied Mind: Cognitive Science and Human Experience, , MIT, Cambridge, MA; Weber, A., Varela, F., Life after kant: Natural purposes and the autopoietic foundations of biological individuality (2002) Phenomenol Cogn Sci, 1 (2), pp. 97-125},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wallach2010454,
author={Wallach, W. and Franklin, S. and Allen, C.},
title={A conceptual and computational model of moral decision making in human and artificial agents},
journal={Topics in Cognitive Science},
year={2010},
volume={2},
number={3},
pages={454-485},
doi={10.1111/j.1756-8765.2010.01095.x},
note={cited By 52},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957657605&doi=10.1111%2fj.1756-8765.2010.01095.x&partnerID=40&md5=443a09b939c52bbb66c0b8ff740b019e},
abstract={Recently, there has been a resurgence of interest in general, comprehensive models of human cognition. Such models aim to explain higher-order cognitive faculties, such as deliberation and planning. Given a computational representation, the validity of these models can be tested in computer simulations such as software agents or embodied robots. The push to implement computational models of this kind has created the field of artificial general intelligence (AGI). Moral decision making is arguably one of the most challenging tasks for computational approaches to higher-order cognition. The need for increasingly autonomous artificial agents to factor moral considerations into their choices and actions has given rise to another new field of inquiry variously known as Machine Morality, Machine Ethics, Roboethics, or Friendly AI. In this study, we discuss how LIDA, an AGI model of human cognition, can be adapted to model both affective and rational features of moral decision making. Using the LIDA model, we will demonstrate how moral decisions can be made in many domains using the same mechanisms that enable general decision making. Comprehensive models of human cognition typically aim for compatibility with recent research in the cognitive and neural sciences. Global workspace theory, proposed by the neuropsychologist Bernard Baars (1988), is a highly regarded model of human cognition that is currently being computationally instantiated in several software implementations. LIDA (Franklin, Baars, Ramamurthy, & Ventura, 2005) is one such computational implementation. LIDA is both a set of computational tools and an underlying model of human cognition, which provides mechanisms that are capable of explaining how an agent's selection of its next action arises from bottom-up collection of sensory data and top-down processes for making sense of its current situation. We will describe how the LIDA model helps integrate emotions into the human decision-making process, and we will elucidate a process whereby an agent can work through an ethical problem to reach a solution that takes account of ethically relevant factors. © 2010 Cognitive Science Society, Inc.},
author_keywords={Artificial general intelligence;  Artificial intelligence;  Global workspace theory;  Machine ethics;  Machine morality;  Moral decision making},
keywords={artificial intelligence;  cognition;  computer simulation;  decision making;  ethics;  human;  morality;  psychological model, Artificial Intelligence;  Cognition;  Computer Simulation;  Decision Making;  Humans;  Models, Psychological;  Morals},
references={Allen, C., Calculated morality: Ethical computing in the limit (2002) Cognitive, emotive and ethical aspects of decision making and human action, 1, pp. 19-23. , In I. Smit & G. Lasker (Eds.), Windsor, ON: IIAS; Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up and hybrid approaches (2006) Ethics of New Information Technology, 7, pp. 149-155; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12, pp. 251-261; Anderson, J.R., (1990) The adaptive character of thought, , Hillsdale, NJ: Erlbaum; Anderson, M., Anderson, S., Machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 10-11. , (Guest Editors) ; Anderson, M., Anderson, S., Armen, C., Towards machine ethics: Implementing two action-based ethical theories (2005) Machine ethics, pp. 1-16. , In M. Anderson, S. Anderson, amp; C. Armen (Eds.) Technical Report FS-05-06. Menlo Park, CA: AAAI Press; Anderson, M., Anderson, S., Armen, C., An approach to computing ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 56-63; Baars, B.J., (1988) A cognitive theory of consciousness, , Cambridge, England: Cambridge University Press; Baars, B.J., The conscious access hypothesis: Origins and recent evidence (2002) Trends in Cognitive Sciences, 6, pp. 47-52; Baars, B.J., Franklin, S., How conscious experience and working memory interact (2003) Trends in Cognitive Sciences, 7, pp. 166-172; Baddeley, A., Consciousness and working memory (1992) Consciousness and Cognition, 1, pp. 3-6; Baddeley, A., Conway, M., Aggleton, J., (2001) Episodic memory, , Oxford, England: Oxford University Press; Baddeley, A.D., Hitch, G.J., Working memory (1974) The psychology of learning and motivation, pp. 47-89. , In G. A. Bower (Ed.) New York: Academic Press; Barsalou, L.W., Perceptual symbol systems (1999) Behavioral and Brain Sciences, 22, pp. 577-660; Berne, E., (1964) Games people play: The basic handbook of transactional analysis, , New York: Ballantine Books; Breazeal, C., (2002) Designing sociable robots, , Cambridge, MA: MIT Press; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44; Brooks, R.A., (2002) Flesh and machines, , New York: Pantheon Books; Canamero, L.D., Designing emotions for activity selection in autonomous agents (2003) Emotions in humans and artifacts, pp. 115-148. , In R. Trappl, P. Petta, amp; S. Payr (Eds.) Cambridge, MA: MIT Press; Clarke, R., Asimov's Laws of Robotics: Implications for Information Technology (1) (1993) IEEE Computer, 26 (12), pp. 53-61; Clarke, R., Asimov's Laws of Robotics: Implications for Information Technology (1) (1994) IEEE Computer, 27 (1), pp. 57-66; Conway, M.A., Sensory-perceptual episodic memory and its context: Autobiographical memory (2001) Philos Trans R Soc London 13, 356, pp. 1375-1384; Danielson, P., (1992) Artificial morality: Virtuous robots for virtual games, , New York: Routledge; Das, P., Kemp, A.H., Liddell, B.J., Brown, K.J., Olivieri, G., Peduto, A., Gordon, E., Williams, L.A., Pathways for fear perception: Modulation of amygdala activity by thalamo-cortical systems (2005) NeuroImage, 26, pp. 141-148; Dehaene, S., Sergent, C., Changeux, J.-P., A neuronal network model linking subjective reports and objective physiological data during conscious perception (2003) Proceedings of the National Academy of Sciences of the United States of America, 1001, pp. 8520-8525; DeMoss, D., (1998), Aristotle, connectionism, and the morally excellent brain. Proceedings of the 20th world congress of philosophy, The Paideia Archive. Available at: Accessed March 1, 2010; D'Mello, S.K., Ramamurthy, U., Negatu, A., Franklin, S., A procedural learning mechanism for novel skill acquisition (2006) Workshop on motor development: Proceeding of adaptation in artificial and biological systems, AISB'06, 1, pp. 184-185. , In T. Kovacs & J. A. R. Marshall (Eds.), Bristol, England: Society for the Study of Artificial Intelligence and the Simulation of Behaviour; Drescher, G.L., (1991) Made-up minds: A constructivist approach to artificial intelligence, , Cambridge, MA: MIT Press; Edelman, G.M., (1987) Neural Darwinism, , New York: Basic Books; Ericsson, K.A., Kintsch, W., Long-term working memory (1995) Psychological Review, 102, pp. 211-245; Estes, W.K., (1993) Classification and cognition, , Oxford, England: Oxford University Press; Flavell, J.H., Metacognition and cognitive monitoring: A new area of cognitive-developmental inquiry (1979) American Psychologist, 34, pp. 906-911; Franklin, S., (2000), A "consciousness" based architecture for a functioning mind. Paper presented at the Symposium on Designing a Functioning Mind: Artificial Intelligence and the Simulation of Behaviour, April 2000, Birmingham, England; Franklin, S., Deliberation and voluntary action in 'conscious' software agents (2000) Neural Network World, 10, pp. 505-521; Franklin, S., IDA: A conscious artifact? (2003) Journal of Consciousness Studies, 10, pp. 47-66; Franklin, S., (2005), pp. 427-433. , Cognitive robots: Perceptual associative memory and learning. Proceedings of the 14th Annual International Workshop on Robot and Human Interactive Communication (RO-MAN 2005) Nashville, TN; Franklin, S., Evolutionary pressures and a stable world for animals and robots: A commentary on Merker (2005) Consciousness and Cognition, 14, pp. 115-118; Franklin, S., Perceptual memory and learning: Recognizing, categorizing, and relating (2005) Symposium on developmental robotics: American Association for Artificial Intelligence (AAAI), , Palo Alto, CA: Stanford University; Franklin, S., Baars, B.J., Ramamurthy, U., Ventura, M., The role of consciousness in memory (2005) Brains, Minds and Media, 1, pp. 1-38; Franklin, S., Graesser, A.C., Is it an agent, or just a program?: A taxonomy for autonomous agents (1997) Proceedings of the third international workshop on agent theories, architectures, and languages, intelligent agents III, pp. 21-35. , Berlin: Springer-Verlag; Franklin, S., Kelemen, A., McCauley, L., IDA: A cognitive agent architecture (1998) IEEE conference on systems, man and cybernetics, pp. 2646-2651. , IEEE Press; Franklin, S., McCauley, L., Interacting with IDA (2003) Agent autonomy, pp. 159-186. , In H. Hexmoor, C. Castelfranchi, amp; R. Falcone (Eds.) Dordrecht, The Netherlands: Kluwer; Franklin, S., Patterson Jr., F.G., The LIDA architecture: Adding new modes of learning to an intelligent, autonomous, software agent (2006) IDPT-2006 Proceedings (Integrated Design and Process Technology), , San Diego, CA: Society for Design and Process Science; Franklin, S., Ramamurthy, U., Motivations, values and emotions: Three sides of the same coin (2006) Proceedings of the sixth international workshop on epigenetic robotics, 1, pp. 41-48. , In Paris: Lund University Cognitive Studies; Franklin, S., Ramamurthy, U., D'Mello, S.K., McCauley, L., Negatu, A., Silva, R.L., Datla, V., (2007), (, November 9-11). LIDA: A computational model of global workspace theory and developmental learning. Paper presented at the AAAI fall symposium on AI and consciousness: Theoretical foundations and current approaches, Arlington, VA; Freeman, W.J., (1999) How brains make up their minds, , London: Weidenfeld and Nicolson General; Friedlander, D., Franklin, S., LIDA and a theory of mind (2008) Artificial general intelligence 2008, pp. 137-148. , In P. Wang, B. Goertzel, amp; S. Franklin (Eds.) Amsterdam: IOS Press; Gadanho, S.C., Learning behavior-selection by emotions and cognition in a multi-goal robot task (2003) Journal of Machine Learning Research, 4, pp. 385-412; Gibson, J.J., (1979) The ecological approach to visual perception, , Mahwah, NJ: Lawrence Erlbaum Associates; Gips, J., Towards the ethical robot (1991) Android epistemology, pp. 243-252. , In K. Ford, C. Glymour, amp; P. Hayes (Eds.) Cambridge, MA: MIT Press; Glenberg, A.M., What memory is for (1997) Behavioral and Brain Sciences, 20, pp. 1-19; Goodale, M.A., Milner, D., (2004) Sight unseen, , Oxford, England: Oxford University Press; Grau, C., There is no 'I' in 'robot': Robots and utilitarianism (2006) IEEE Intelligent Systems, 21 (4), pp. 52-55; Guarini, M., Particularism and classification and reclassification of moral cases (2006) IEEE Intelligent Systems, 21 (4), pp. 22-28; Heilman, K.M., The neurobiology of emotional experience (1997) Journal of Neuropsychiatry and Clinical Neurosciences, 9, pp. 439-448; Hofstadter, D.R., Mitchell, M., The copycat project: A model of mental fluidity and analogy-making (1995) Advances in connectionist and neural computation theory, Vol. 2: Logical connections, pp. 205-267. , In K. J. Holyoak & J. Barnden (Eds.) New York: Basic Books; (2003) Machine consciousness, , Holland, O. (Ed.) New York: Imprint Academic; Jackson, J.V., Idea for a mind (1987) ACM SIGART Bulletin, 191, pp. 23-26; James, W., (1890) The principles of psychology, , Cambridge, MA: Harvard University Press; Johnston, V.S., (1999) Why we feel: The science of human emotions, , Reading, MA: Perseus Books; Kaelbling, L.P., Littman, M.L., Moore, A.W., Reinforcement learning: A survey (1996) Journal of Artificial Intelligence Research, 4, pp. 237-285; Kanerva, P., (1988) Sparse distributed memory, , Cambridge, MA: MIT Press; Kruschke, J.K., Attention in learning (2003) Current Directions in Psychological Science, 12 (5), pp. 171-175; Laird, J.E., Newell, A., Rosenbloom, P.S., SOAR: An architecture for general intelligence (1987) Artificial Intelligence, 33, pp. 1-64; Massimini, M., Ferrarelli, F., Huber, R., Esser, S.K., Singh, H., Tononi, G., Breakdown of cortical effective connectivity during sleep (2005) Science, 309, pp. 2228-2232; McLaren, B., Computational models of ethical reasoning: Challenges, initial steps, and future directions (2006) IEEE Intelligent Systems, 21 (4), pp. 29-37; Merker, B., The liabilities of mobility: A selection pressure for the transition to consciousness in animal evolution (2005) Consciousness and Cognition, 14, pp. 89-114; Minsky, M., (1985) The society of mind, , New York: Simon and Schuster; Mulcahy, N.J., Call, J., Apes save tools for future use (2006) Science, 312, pp. 1038-1040; Nadel, L., Multiple memory systems: What and why (1992) Journal of Cognitive Neuroscience, 4, pp. 179-188; Nadel, L., Moscovitch, M., Memory consolidation, retrograde amnesia and the hippocampal complex (1997) Current Opinion in Neurobiology, 7, pp. 217-227; Negatu, A., D'Mello, S.K., Franklin, S., Cognitively inspired anticipation and anticipatory learning mechanisms for autonomous agents (2007) Proceedings of the third workshop on Anticipatory Behavior in Adaptive Learning Systems (ABiALS 2006), pp. 108-127. , In M. V. Butz, O. Sigaud, G. Pezzulo, amp; G. O. Baldassarre (Eds.) Rome: Springer-Verlag; Negatu, A., Franklin, S., An action selection mechanism for 'conscious' software agents (2002) Cognitive Science Quarterly, 2, pp. 363-386; Ornstein, R., (1986) Multimind, , Boston: Houghton Mifflin; Picard, R., (1997) Affective computing, , Cambridge, MA: MIT Press; Powers, T., Prospects for a Kantian machine (2006) IEEE Intelligent Systems, 21 (4), pp. 46-51; Ramamurthy, U., Baars, B.J., D'Mello, S.K., Franklin, S., LIDA: A working model of cognition (2006) Proceedings of the 7th international conference on cognitive modeling, pp. 244-249. , In D. Fum, F. Del Missier, amp; A. Stocco (Eds.) Trieste: Edizioni Goliardiche; Ramamurthy, U., D'Mello, S.K., Franklin, S., (2004), Modified sparse distributed memory as transient episodic memory for cognitive software agents. IEEE international conference on Systems, Man and Cybernetics-SMC2004, The Hague, The Netherlands; Ramamurthy, U., D'Mello, S.K., Franklin, S., (2005), Role of consciousness in episodic memory processes: Poster. Ninth conference of the Association for the Scientific Study of Consciousness-ASSC9, Pasadena, CA; Scassellati, B.M., (2001) Foundations for a theory of mind for a humanoid robot, , PhD thesis, Department of Electrical Engineering and Computer Science, MIT. Available at: Accessed March 1, 2010; Shanahan, M., A cognitive architecture that combines internal simulation with a global workspace (2006) Consciousness and Cognition, 15, pp. 433-449; Sigman, M., Dehaene, S., Dynamics of the central bottleneck: Dual-task and task uncertainty (2006) PLoS Biology, 4 (7), pp. e220; Sloman, A., Damasio, Descartes, alarms and meta-management (1998) Proceedings symposium on cognitive agents: Modeling human cognition, , San Diego, CA: IEEE; Sloman, A., What sort of architecture is required for a human-like agent? (1999) Foundations of rational agency, pp. 35-52. , In M. Wooldridge & A. S. Rao (Eds.) Dordrecht, The Netherlands: Kluwer Academic Publishers; Smith, J.D., Washburn, D.A., Uncertainty monitoring and metacognition by animals (2005) Current Directions in Psychological Science, 14, pp. 19-24; Stahl, B.C., Can a computer adhere to the categorical imperative? A contemplation of the limits of transcendental ethics in IT (2002) Cognitive, emotive and ethical aspects of decision making in humans and in artificial intelligence, 1, pp. 13-18. , In I. Smit & G. Lasker (Eds.), Windsor, ON: IIAS; Stickgold, R., Walker, M.P., Memory consolidation and reconsolidation: What is the role of sleep? (2005) Trends in Neuroscience, 28, pp. 408-415; Sun, R., The importance of cognitive architectures: An analysis based on CLARION (2007) Journal of Experimental and Theoretical Artificial Intelligence, 19 (2), pp. 159-193; Tarsitano, M., Route selection by a jumping spider (Portia labiata) during the locomotory phase of a detour (2006) Animal Behavior, 72, pp. 1437-1442; Tulving, E., (1983) Elements of episodic memory, , Oxford, England: Clarendon Press; Uchida, N., Kepecs, A., Mainen, Z.F., Seeing at a glance, smelling in a whiff: Rapid forms of perceptual decision making (2006) Nature Reviews Neuroscience, 7, pp. 485-491; Varela, F.J., Thompson, E., Rosch, E., (1991) The embodied mind, , Cambridge, MA: MIT Press; Vidnyánszky, Z., Sohn, W., Attentional learning: Learning to bias sensory competition (2003) Journal of Vision, 3, pp. 174a. , [abstract]; Wallach, W., Allen, C., (2009) Moral machines: Teaching robots right from wrong, , New York: Oxford University Press; Wallach, W., Allen, C., Smit, I., Machine morality: Bottom-up and top-down approaches for modelling human moral faculties (2008) AI and Society, 22 (4), pp. 565-582; Wang, P., Goertzel, B., Franklin, S., (2008) Artificial general intelligence 2008, , Amsterdam: IOS Press; Watt, D.F., Affect and the limbic system: Some hard problems (1998) Journal of Neuropsychiatry and Clinical Neurosciences, 10, pp. 113-116; Werdenich, D., Huber, L., A case of quick problem solving in birds: String pulling in keas, Nestor notabilis (2006) Animal Behaviour, 71, pp. 855-863; Wilcox, S., Jackson, R., Jumping spider tricksters: Deceit, predation, and cognition (2002) The cognitive animal, pp. 27-33. , In M. Bekoff, C. Allen, amp; G. M. Burghardt (Eds.) Cambridge, MA: MIT Press; Willis, J., Todorov, A., First impressions: Making up your mind after a 100-ms exposure to a face (2006) Psychological Science, 17, pp. 592-599; Yoshida, H., Smith, L.B., Known and novel noun extensions: Attention at two levels of abstraction (2003) Child Development, 76 (2), pp. 564-577; Yudkowsky, E., (2001), What is friendly AI? Available at: Accessed March 1, 2010; Zacks, J.M., Speer, N.K., Swallow, K.M., Braver, T.S., Reynolds, J.R., Event perception: A mind-brain perspective (2007) Psychological Bulletin, 133 (2), pp. 273-293; Zhu, J., Thagard, P., Emotion and action (2002) Philosophical Psychology, 15, pp. 19-36},
document_type={Article},
source={Scopus},
}

@ARTICLE{Winfield201485,
author={Winfield, A.F.T. and Blum, C. and Liu, W.},
title={Towards an ethical robot: Internal models, consequences and ethical action selection},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2014},
volume={8717 LNAI},
pages={85-96},
doi={10.1007/978-3-319-10401-0_8},
note={cited By 48},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906761955&doi=10.1007%2f978-3-319-10401-0_8&partnerID=40&md5=f19cd3296e85289e91bf323f352aa24a},
abstract={If robots are to be trusted, especially when interacting with humans, then they will need to be more than just safe. This paper explores the potential of robots capable of modelling and therefore predicting the consequences of both their own actions, and the actions of other dynamic actors in their environment. We show that with the addition of an 'ethical' action selection mechanism a robot can sometimes choose actions that compromise its own safety in order to prevent a second robot from coming to harm. An implementation with e-puck mobile robots provides a proof of principle by showing that a simple robot can, in real time, model and act upon the consequences of both its own and another robot's actions. We argue that this work moves us towards robots that are ethical, as well as safe. © 2014 Springer International Publishing.},
author_keywords={Human-Robot Interaction;  Internal Model;  Machine Ethics;  Safety},
keywords={Accident prevention;  Philosophical aspects;  Robotics, Action selection;  Action selection mechanism;  Internal modeling;  Internal models;  Proof of principles;  Real time, Robots},
references={Asimov, I., (1950) I, ROBOT, , Gnome Press; Bongard, J., Zykov, V., Lipson, H., Resilient machines through continuous self-modeling (2006) Science, 314 (5802), pp. 1118-1121; Braitenberg, V., (1984) Vehicles: Experiments in Synthetic Psychology, , MIT Press; Holland, J., (1992) Complex Adaptive Systems, , Daedalus; Holland, O., (2003) Machine Consciousness, , Imprint Academic; Isidori, A., Marconi, L., Serrani, A., Fundamentals of internal-model-based control theory (2003) Robust Autonomous Guidance. Advances in Industrial Control, pp. 1-58. , Springer, London; Liu, W., Winfield, A.F.T., Open-hardware e-puck Linux extension board for experimental swarm robotics research (2011) Microprocessors and Microsystems, 35 (1); Marques, H., Holland, O., Architectures for functional imagination (2009) Neurocomputing, 72 (4-6), pp. 743-759; Michel, O., Webots: Professional mobile robot simulation (2004) International Journal of Advanced Robotic Systems, 1 (1), pp. 39-42; Mondada, F., Bonani, M., Raemy, X., Pugh, J., Cianci, C., Klaptocz, A., Magnenat, S., Martinoli, A., The e-puck, a robot designed for education in engineering (2009) Proc. 9th Conference on Autonomous Robot Systems and Competitions, pp. 59-65; O'Dowd, P.J., Winfield, A.F.T., Studley, M., The distributed co-evolution of an embodied simulator and controller for swarm robot behaviours (2011) Proc. IEEE/RSJ Int. Conf. on Intelligent Robots and Systems (IROS), pp. 4995-5000; Stepney, S., Welch, P., Andrews, P., (2011) CoSMoS 2011: Proc. 2011 Workshop on Complex Systems Modelling and Simulation, , Luniver Press; Vaughan, R., Massively multi-robot simulation in stage (2008) Swarm Intelligence, 2 (2-4), pp. 189-208; Vaughan, R.T., Gerkey, B.P., Really reused robot code from the player/stage project (2007) Software Engineering for Experimental Robotics, pp. 267-289. , Brugali, D. (ed.) Springer; Vaughan, R.T., Zuluaga, M., Use your illusion: Sensorimotor self-simulation allows complex agents to plan with incomplete self-knowledge (2006) Proc. International Conference on Simulation of Adaptive Behaviour (SAB), pp. 298-309; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press, Oxford; Zagal, J.C., Delpiano, J., Ruiz-del Solar, J., Self-modeling in humanoid soccer robots (2009) Robot. Auton. Syst., 57 (8), pp. 819-827},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Anderson20051,
author={Anderson, M. and Anderson, S.L. and Armen, C.},
title={Towards machine ethics: Implementing two action-based ethical theories},
journal={AAAI Fall Symposium - Technical Report},
year={2005},
volume={FS-05-06},
pages={1-7},
note={cited By 46},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646148468&partnerID=40&md5=5a9c515b3e33833c7b6fd353ee95a6c3},
abstract={Machine ethics, in contrast to computer ethics, is concerned with the behavior of machines towards human users and other machines. It involves adding an ethical dimension to machines. Our increasing reliance on machine intelligence that effects change in the world can be dangerous without some restraint. We explore the implementation of two action-based ethical theories that might serve as a foundation for machine ethics and present details of prototype systems based upon them.},
keywords={Computer ethics;  Ethical dimension;  Ethical theories;  Machine intelligence, Artificial intelligence;  Computer science;  Software prototyping;  Systems analysis;  Theorem proving;  User interfaces, Machine design},
references={Anderson, S.L., We are our values (2000) Questioning Matters, an Introduction to Philosophical Inquiry, 606 (8). , edited by D. Kolak, Mayfield Publishing Company, Mountain View, California; Asimov, I., (1950) I, Robot, , Gnome Press; Bratko, I., Refining complete hypotheses in ILP. Inductive logic programming (1999) LNAI, 1634. , (S. Dzeroski and N. Lavrac, eds.), Springer; Bentham, J., (1799) An Introduction to the Principles and Morals of Legislation, , Oxford; Beauchamp, T.L., Childress, J.F., (1979) Principles of Biomedical Ethics, , Oxford University Press; Ford, K., Glymour, C., Hayes, P.J., (1991) Android Epistemology, , MIT Press; Gips, J., (1991) Towards an Ethical Robot, , [Ford et al, 1991]; Kahn, A.F.U., (1991) The Ethics of Autonomous Learning Systems, , [Ford et al, 1991]; Lavrac, N., Dzeroski, S., (1997) Inductive Logic Programming: Techniques and Applications, , Ellis Harwood; Mill, J.S., (1974) Utilitarianism, in Utilitarianism and Other Writings, 253. , edited by M. Warnock, New American Library, New York; Rawls, J., Outline for a decision procedure for ethics (1951) Philosophical Review, 60; Ross, W.D., (1930) The Right and the Good, , Clarendon Press, Oxford},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Arkin2008121,
author={Arkin, R.C.},
title={Governing lethal behavior: Embedding ethics in a hybrid deliberative/reactive robot architecture - Part I: Motivation and philosophy},
journal={HRI 2008 - Proceedings of the 3rd ACM/IEEE International Conference on Human-Robot Interaction: Living with Robots},
year={2008},
pages={121-128},
doi={10.1145/1349822.1349839},
note={cited By 45},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-72849113732&doi=10.1145%2f1349822.1349839&partnerID=40&md5=b7dff023d83dc84a0123660c266e6063},
abstract={This paper provides the motivation and philosophy underlying the design of an ethical control and reasoning system potentially suitable for constraining lethal actions in an autonomous robotic system, so that its behavior will fall within the bounds prescribed by the Laws of War and Rules of Engagement. This research, funded by the U.S. Army Research Office, is intended to ensure that robots do not behave illegally or unethically in the battlefield. Reasons are provided for the necessity of developing such a system at this time, as well as arguments for and against its creation. Copyright 2008 ACM.},
author_keywords={Autonomous robots;  Battlefield robots;  Human-Robot interaction;  Robot ethics;  Unmanned systems},
keywords={Autonomous robot;  Autonomous robotic systems;  Autonomous robots;  Human robot interactions;  Reasoning system;  Robot architecture;  Rules of engagements;  U.S. Army;  Unmanned system, Human computer interaction;  Man machine systems;  Motivation;  Ontology;  Philosophical aspects, Human robot interaction},
references={Arkin, R.C., Governing Ethical Behavior: Embedding an Ethical Controller in a Hybrid Deliberative-Reactive Robot Architecture - Part II: Formalization for Ethical Control (2008) Proc. 1st Conference on Artificial General Intelligence, , Memphis, TN, March; Arkin, R.C., Governing Lethal Behavior: Embedding Ethics in a Hybrid Deliberative/Reactive Robot Architecture - Part III: Representational and Architectural Considerations (2008) Proc. Technology in Wartime Conference, , Stanford, CA, Jan; Arkin, R.C., Governing Ethical Behavior: Embedding an Ethical Controller in a Hybrid Deliberative-Reactive Robot Architecture (2007) GVU Technical Report, , GIT-GVU-07-11, College of Computing, Georgia Tech; May, L., Rovie, E., Viner, S., (2005) The Morality of War: Classical and Contemporary Readings, , Pearson-Prentice Hall; Clausewitz, C.V., On the Art of War (1832) The Morality of War: Classical and Contemporary Readings, pp. 115-121. , Eds. L. May, E. Rovie, and S. Viner, Pearson-Prentice Hall, pp; Cook, M., The Moral Warrior: Ethics and Service in the U.S. Military, State University of New York Press, 2004; (1996) An Encyclopedia of War and Ethics, , Wells, D, Ed, Greenwood Press; Walzer, M., (1977) Just and Unjust Wars, , 4th Ed, Basic Books; Fieser, J., Dowden, B., Just War Theory (2007) The Internet Encyclopedia of Philosophy; Dictionary of Military and Associated Terms (2001) Amended through, , Department of Defense Joint Publication 1-02, April, June; Hartle, A., (2004) Moral Issues in Military Decision Making, , 2nd Ed, Revised, University Press of Kansas; (2007) Laws of War, , http://en.wikipedia.org/wiki/Laws-of-war; Yoder, J.H., When War is Unjust: Being Honest in Just-War Thinking (1984) The Morality of War: Classical and Contemporary Readings, pp. 153-159. , Eds. L. May, et al, Pearson-Prentice Hall, pp; (2007) Unmanned Systems Safety Guide for DOD Acquisition, p. 96. , Department of Defense, 1st Edition, Version, Jan; Argy, P., Ethics Dilemma in Killer Bots (2007) Australian IT News, , June 14; (2007) Samsung Techwin, , http://www.samsungtechwin.com/product/features/dep/SSsystem-e/SSsystem.html; Kumagai, J., A Robotic Sentry for Korea's Demilitarized Zone (2007) IEEE Spectrum, , March; Jewell, M., Taser, iRobot team up to arm robots (2007) AP News Wire, , June; (2007) Products & Service: TALON Military Robots, EOD, SWORDS, and Hazmat Robots, , http://www.foster-miller.com/lemming.htm, Foster-Miller Inc; Opall-Rome, B., Israel Wants Robotic Guns, Missiles to Guard Gaza (2007), Defensenews.com; Lockheed-Martin, M., (2007) ARV-A(L), Fact Sheet; Air Force, Reaper moniker given to MQ-9 Unmanned Aerial Vehicle, Official Website of the United States Air Force, 2006; Erwin, S., For the First Time, Navy will Launch Weapons from Surveillance Drones (2007) National Defense, , June; U.S. Army SBIR Solicitation 07.2, Topic A07-032 Multi-Agent Based Small Unit Effects Planning and Collaborative Engagement with Unmanned Systems, pp. Army 57-68, 2007; (2007) Programmatic / Design / Operational Safety Precepts Rev F, , Joint Government/Industry Unmanned Systems Safety Initiatives; Sagan, S., Rules of Engagement (1991) Avoiding War: Problems of Crisis Management, , Ed. A. George, Westview Press; Mental Health Advisory Team (MHAT) IV Operation Iraqi Freedom 05-07 (2006), Surgeon General's Office, Final Report, Nov. 17; (2000) Law of War Workshop Deskbook, , Bill, B, Ed, International and Operational Law Department, Judge Advocate General's School, June; Sparrow, R., Killer Robots (2006) Journal of Applied Philosophy, 24 (1); Sparrow, R., (2007), Personal Communication, July 2; Asaro, P., What Should We Want From a Robot Ethic? (2006) International Review of Information Ethics, 6, pp. 9-16. , Dec; Perri, Ethics, Regulation and the New Artificial Intelligence, Part II: Autonomy and Liability (2001) Information, Communication and Society, 4, pp. 3-434,406. , 6; Sullins, J., When is a Robot a Moral Agent? (2006) International Journal of information Ethics, 6, p. 12; Dennett, D., When HAL Kills, Who's to Blame? (1996) HAL's Legacy: 2001's Computer as Dream and Reality, , Ed. D. Stork, MIT Press; Himma, K., Artificial Agency, Consciousness, and the Criteria for Moral Agency: What Properties Must an Artificial Agent Have to be a Moral Agent? (2007) 7th International Computer Ethics Conference, , San Diego, CA, July; Asaro, P., How Just Could a Robot War Be? (2007) presentation at 5th European Computing and Philosophy Conference, Twente, NL, June; Canning, J., Riggs, G., Holland, O., Blakelock, C., A Concept for the Operation of Armed Autonomous Systems on the Battlefield (2004) Proc. AUVSI 2004, , Anaheim, CA, Aug; Woodruff, P., Justification or Excuse: Saving Soldiers at the Expense of Civilians (1982) The Morality of War: Classical and Contemporary Readings, pp. 281-291. , Eds. L. May, E. Rovie, and S. Viner, Pearson-Prentice Hall, pp; Anderson, K., The Ethics of Robot Soldiers? (2007) Kenneth Anderson's Law of Jaw and Just War Theory Blog, , July 4; Likhachev, M., Kaess, M., Arkin, R.C., Learning Behavioral Parameterization Using Spatio-Temporal Casebased Reasoning (2002) 2002 IEEE International Conference on Robotics and Automation, , Washington, D.C, May; Ram, A., Arkin, R.C., Moorman, K., and Clark, R.J., Casebased Reactive Navigation: A case-based method for online selection and adaptation of reactive control parameters in autonomous robotic systems, IEEE Transactions on Systems, Man, and Cybernetics, 27, Part B, No. 3, June 1997, pp. 376-394; Walzer, M., (2004) Arguing About War, , Yale Univ. Press; Bring, O., International Humanitarian Law After Kosovo: Is Lex Lata Sufficient? (2002) Legal and Ethical Lessons of NATO's Kosovo Campaign, International Law Studies, 78, pp. 257-272. , Ed. A. Wall, Naval War College; Asimov, I., (1950) I, Robot, , New York: Doubleday & Co; Asimov, I., (1985) Robots and Empire, , New York: Doubleday & Company; Anderson, S., Asimov's 'Three Laws of Robotics' and Machine Metaethics (2007) AI and Society, , Springer, published online March},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Sullins2012398,
author={Sullins, J.P.},
title={Robots, love, and sex: The ethics of building a love machine},
journal={IEEE Transactions on Affective Computing},
year={2012},
volume={3},
number={4},
pages={398-409},
doi={10.1109/T-AFFC.2012.31},
art_number={6313590},
note={cited By 44},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872242148&doi=10.1109%2fT-AFFC.2012.31&partnerID=40&md5=240262abb116833a9a54f3e038144a79},
abstract={This paper will explore the ethical impacts of the use of affective computing by engineers and roboticists who program their machines to mimic and manipulate human emotions in order to evoke loving or amorous reactions from their human users. We will see that it does seem plausible that some people might buy a love machine if it were created, but it is argued here that principles from machine ethics have a role to play in the design of these machines. This is best achieved by applying what is known about the philosophy of love, the ethics of loving relationships, and the philosophical value of the erotic in the early design stage of building robust artificial companions. The paper concludes by proposing certain ethical limits on the manipulation of human psychology when it comes to building sex robots and in the simulation of love in such machines. In addition, the paper argues that the attainment of erotic wisdom is an ethically sound goal and that it provides more to loving relationships than only satisfying physical desire. This fact may limit the possibility of creating a machine that can fulfill all that one should want out of erotic love unless a machine can be built that would help its user attain this kind of love. © 2010-2012 IEEE.},
author_keywords={Affective computing;  Artificial companions;  Artificial emotions;  Robotics},
keywords={Affective Computing;  Artificial companions;  Artificial emotions;  Early design stages;  Human emotion;  Human psychology;  Human users, Robotics, Philosophical aspects},
references={Levy, D., (2007) Love and Sex with Robots: The Evolution of Human-Robot Relationships, , Harper Collins; Cowie, R., Companionship is an emotional business (2010) Close Engagements with Artificial Companions: Key Social, Psychological, Ethical and Design Issues, , http://site.ebrary.com/lib/sonoma/Doc?id=10383970&ppg=192, Y. Wilks ed., John Benjamins Publishing Company; Duffy, B., Anthropomorphism and the social robot (2003) Robotics and Automation Systems, 42, pp. 177-190; Breazeal, C., Brooks, A., Gray, J., Hoffman, G., Kidd, C., Lee, H., Lieberman, J., Mulanda, D., (2004) Humanoid Robots As Cooperative Partners for People, , http://web.media.mit.edu/~cynthiab/Papers/Breazeal-etal-ijhr04.pdf; Samani, H.A., Cheok, A.D., Tharakan, M.J., Koh, J., Fernando, N., A design process for lovotics (2011) Proc. Third Int'l Conf. Human-Robot Personal Relationships, pp. 118-125; Sullins, J.P., Friends by design: A design philosophy for personal robotics technology (2008) Philosophy and Design: From Eng. to Architecture, pp. 143-158. , P. Vermaas, P. Kroes, A. Light, and S. Moore, eds., Springer; Kanda, T., Ishiguro, H., (2005) Communication Robots for Elementary Schools, , http://www.irc.atr.jp/~kanda/pdf/kandaaisb2005.pdf; Kanda, T., Ishiguro, H., Ishida, T., Psychological analysis on human-robot interaction (2001) Proceedings - IEEE International Conference on Robotics and Automation, 4, pp. 4166-4173; Kanda, T., Sato, R., Saiwaki, N., Ishiguro, H., Friendly social robot that understands human's friendly relationships (2004) 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 3, pp. 2215-2222. , FP1-F3, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); (2012) First Androids, , http://www.andydroid.com; (2012) True Companions, , http://www.truecompanion.com/; Meston, C.M., Buss, D.M., Why humans have sex (2007) Archives of Sexual Behavior, 36 (4), pp. 477-507. , DOI 10.1007/s10508-007-9175-2; Snell, J., Sexbots: An editorial (2005) Psychology and Education: An Interdisciplinary J., 42 (1), pp. 49-50; Turkle, S., (2011) Alone Together: Why We Expect More from Technology and Less from Each Other, , Basic Books; Coeckelbergh, M., Personal robots, appearance, and human good: A methodological reflection on roboethics (2009) Int'l J. Social Robotics, 1 (3), pp. 217-221; Sullins, J., Friends by design: A design philosophy for personal robotics technology (2008) Philosophy and Design: From Eng. to Architecture, pp. 143-158. , P. Vermaas, P. Kroes, A. Light, and S. Moore, eds., Springer; Turing, A., Computing machinery and intelligence (1950) Mind, 59 (236), pp. 433-460; Fehr, B., Prototype based assessment of laypeople's views of love (1994) Personal Relationships, 1, pp. 301-331; Fehr, B., Russel, J.A., The concept of love viewed from a prototype perspective (1991) J. Personality and Social Psychology, 60, pp. 424-438; Gilbert, D.T., Jones, E.E., Perceiver-induced constraint: Interpretations of self-generated reality" (1986) J. Personality and Social Psychology, 50, pp. 269-280; Aron, A., Aron, E.N., Love and expansion of the self: The state of the model (1996) Personal Relationships, 3 (1), pp. 45-58; Aron, A., Aron, E.N., Smollan, D., Inclusion of other in the self scale and the structure of interpersonal closeness (1992) J. Personality and Social Psychology, 63, pp. 596-612; Aron, A., Aron, E.N., Tudor, M., Nelson, G., Close relationships as including other in the self (1991) J. Personality and Social Psychology, 60, pp. 241-253; Aron, A., Fraley, B., Relationship closeness as including other in the self: Cognitive underpinnings and measures (1999) Social Cognition, 17, pp. 140-160; (2012), http://www.haverford.edu/psych/ble/continuous_ios/index.html, About the Continuous IOS; Susan, F., Lazurus, R.S., Coping as a mediator of emotion (1988) J. Personality and Social Psychology, 54, pp. 466-475; Ortigue, S., Bianchi-Demicheli, F., Why is your spouse so predictable? connecting mirror neuron system and self-expansion model of love (2008) Medical Hypotheses, 71 (6), pp. 941-944; Buck, R., The genetics and biology of true love: Prosocial biological affects and the left hemisphere (2002) Psychological Rev., 109 (4), pp. 739-744. , Oct; Buck, R., Ginsburg, B.E., Emotional communication and altruism: The cognitive gene hypothesis (1991) Altruism: Rev. of Personality and Social Psychology, 12, pp. 149-175; Buck, R., Ginsburg, B.E., Communicative genes and the evolution of empathy (1997) Empathetic Accuracy, pp. 17-43. , W. Ickes, ed., Guilford Press; Davis, M., Kraus, L., Personality and empathic accuracy (1997) Empathic Accuracy, pp. 144-168. , W. Ickes ed., Guilford Press; (2001) Plato Symposium, , The Univ.of Chicago Press; Singer, I., (2001) Explorations in Love and Sex, , Rowman and Littlefield; (2012), http://hooman.lovotics.com/, Information Retrieved From; Samani, H.A., Cheok, A.D., Probability of love between robots and humans (2010) Proc. IEEE/RSJ Int'l Conf. Intelligent Robots and Systems; Samani, H.A., Towards a formulation of love in human- robot interaction (2010) Proc. 19th IEEE Int'l Symp. Robot and Human Interactive Comm.; Samani, H.A., A design process for lovotics (2011) Proc. Int'l Conf. Human-Robot Personal Relationships, pp. 118-125; (2012), http://www.is.sys.es.osaka-u.ac.jp/index.en.html, Intelligent Robotics Laboratory; (2012), http://www.geminoid.jp/en/index.html, Hiroshi Ishiguro Laboratory, ATR; Mori, M., The uncanny valley (1970) Energy, 7 (4), pp. 33-35; Mori, M., (1981) The Buddha in the Robot: A Robot Engineer's Thoughts on Science and Religion, , Kosei Publishing; Breazeal, C.A., Robot in society: Friend or appliance?" (1999) Proc. Autonomous Agents Workshop Emotion-Based Agent Architectures, pp. 18-26; Breazeal, C.A., (2002) Designing Sociable Robots, , MIT Press; Breazeal, C.A., Brooks, R.A., Gray, J., Hoffman, G., Kidd, C., Lee, H., Lieberman, J., Mulanda, D., (2004) Humanoid Robots As Cooperative Partners for People, , http://robotic.media.mit.edu/Papers/Breazeal-etal-ijhr04.pdf; Brooks, R.A., (2002) Flesh and Machines, , Pantheon Books; Gaudin, S., NASA: Humanoid robot slated to live on space station (2010) Computerworld, , www.computerworld.com, Apr; Kanda, T., Ishiguro, H., (2005) Communication Robots for Elementary Schools, , http://www.irc.atr.jp/~kanda/pdf/kandaaisb2005.pdf; Kanda, T., Ishiguro, H., Ishida, T., Psychological analysis on human-robot interaction (2001) Proceedings - IEEE International Conference on Robotics and Automation, 4, pp. 4166-4173; Kanda, T., Sato, R., Saiwaki, N., Ishiguro, H., Friendly social robot that understands human's friendly relationships (2004) 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 3, pp. 2215-2222. , FP1-F3, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Scheutz, M., Schermerhorn, P., Kramer, J., Middendorff, C., The utility of affect expression in natural language interactions in joint human-robot tasks (2006) HRI 2006: Proceedings of the 2006 ACM Conference on Human-Robot Interaction, 2006, pp. 226-233. , HRI 2006: Proceedings of the 2006 ACM Conference on Human-Robot Interaction - Toward Human Robot Collaboration; Duffy, B., Anthropomorphism and the social robot (2003) Robotics and Automation Systems, 42, pp. 177-190; Menzel, P., D'Aluisio, F., (2000) Robosapiens: Evolution of A New Species, , MIT Press; Sullins, J.P., Friends by design: A design philosophy for personal robotics technology (2008) Philosophy and Design: From Eng. to Architecture, pp. 143-158. , P. Vermaas, P. Kroes, A. Light, and S. Moore, eds., Springer; Scheutz, M., The inherent dangers of unidirectional emotional bonds (2009) Proc. IEEE Int'l Conf. Robotics and Automation; Cook, S.D.N., Design and responsibility: The interdependence of natural, artifactural, and human systems (2008) Philosophy and Design: From Eng. to Architecture, pp. 259-269. , P. Vermaas, P. Kroes, A. Light, and S. Moore eds., Springer},
document_type={Article},
source={Scopus},
}

@ARTICLE{Borenstein2010277,
author={Borenstein, J. and Pearson, Y.},
title={Robot caregivers: Harbingers of expanded freedom for all?},
journal={Ethics and Information Technology},
year={2010},
volume={12},
number={3},
pages={277-288},
doi={10.1007/s10676-010-9236-4},
note={cited By 44},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955549794&doi=10.1007%2fs10676-010-9236-4&partnerID=40&md5=1a37b40f258469a31c3a26e25505efb2},
abstract={As we near a time when robots may serve a vital function by becoming caregivers, it is important to examine the ethical implications of this development. By applying the capabilities approach as a guide to both the design and use of robot caregivers, we hope that this will maximize opportunities to preserve or expand freedom for care recipients. We think the use of the capabilities approach will be especially valuable for improving the ability of impaired persons to interface more effectively with their physical and social environments. © 2010 Springer Science+Business Media B.V.},
author_keywords={Capabilities approach;  Human flourishing;  Robot caregivers;  Robot ethics},
keywords={Capabilities approach;  Ethical implications;  Human flourishing;  Robot ethics;  Social environment, Handicapped persons;  Robots, Machine design},
references={Alkire, S., (2005) Capability and functionings: Definition and justification, , http://www.capabilityapproach.com/pubs/HDCA_Briefing_Concepts.pdf, Accessed March 20, 2010; Banks, M.R., Willoughby, L.M., Banks, W.A., Animal-assisted therapy and loneliness in nursing homes: Use of robotic versus living dogs (2008) Journal of the American Medical Directors Association, 9 (3), pp. 173-177; Bringsjord, S., Ethical robots: The future can heed us (2008) AI & Society, 22, pp. 539-550; Bynum, T.W., Flourishing ethics (2006) Ethics and Information Technology, 8, pp. 157-173; Castelfranchi, C., Artificial liars: Why computers will (necessarily) deceive us and each other (2000) Ethics and Information Technology, 2, pp. 113-119; Coeckelbergh, M., Personal robots, appearance, and human good: A methodological reflection on roboethics (2009) International Journal of Social Robotics, 1, pp. 217-221; Coeckelbergh, M., Health care, capabilities, and ai assistive technologies (2010) Ethical Theory and Moral Practice, 13 (2), pp. 181-190; Cooper, C., Selwood, A., Blanchard, M., Walker, Z., Blizard, R., Livingston, G., Abuse of people with dementia by family carers: Representative cross sectional survey (2009) British Medical Journal, 338, pp. 583-586; Cowan, R.S., (1983) More Work for Mother: The Ironies of Household Technology from the Open Hearth to the Microwave, , London: Basic Books, Inc; Datteri, E., Laschi, C., Salvini, P., Tamburrini, G., Veruggio, G., Warwick, K., (2006) ETHICBOTS: Emerging Technoethics of Human Interaction with Communication, Bionic and Robotic Systems, , http://ethicbots.na.infn.it/restricted/doc/EthicBotsD1.zip, April 2006, Accessed December 4, 2009; Decker, M., Caregiving robots and ethical reflection: The perspective of interdisciplinary technology assessment (2008) AI & Society, 22, pp. 315-330; (2008) Techno-ethical case-studies in robotics, bionics, and related ai agent technologies, , http://ethicbots.na.infn.it/documents.php, ETHICBOTS (D5), R. Capurro, G. Tamburrini, & J. Weber (Eds.), (accessed January 2, 2010); Ezer, N., Fisk, A.D., Rogers, W.A., More than a servant: Self-reported willingness of younger and older adults to having a robot perform interactive and critical tasks in the home (2009) Proceedings of the Human Factors and Ergonomics Society 53rd Annual Meeting-2009, , http://www.hfes.org/web/Newsroom/HFES09-Ezer-RobotsInHome.pdf, Accessed December 2, 2009; Faucounau, V., Wu, Y.H., Boulay, M., Maestrutti, M., Rigaud, A.S., Caregivers' requirements for in-home robotic agent for supporting community-living elderly subjects with cognitive impairment (2009) Technology and Health Care, 17 (1), pp. 33-40; Garreau, J., (2007) Bots on the ground, , http://www.washingtonpost.com/wp-dyn/content/article/2007/05/05/AR2007050501009_pf.html, The Washington Post. May 6, 2007, Accessed July 13, 2009; Graf, B., Hans, M., Kubacki, J., Schraft, R., Robotic home assistant care-o-bot II (2002) Proceedings of the Second Joint Meeting of the IEEE Engineering in Medicine and Biology Society and the Biomedical Engineering Society, , http://www.care-o-bot.de/Papers/2002_RoboticHomeAssistant_Care-O-bot_II_IEEE_Texas.pdf, Accessed July 13, 2009; Hansson, S.O., The ethics of enabling technology (2007) Cambridge Quarterly of Healthcare Ethics, 16, pp. 257-267; Hardwig, J., Is there a duty to die? (1997) Hastings Center Report, 27 (2), pp. 34-42; Johnstone, J., Technology as empowerment: A capability approach to computer ethics (2007) Ethics and Information Technology, 9, pp. 73-87; North, A.C., Tarrant, M., Hargreaves, D.J., The effects of music on helping behavior (2004) Environment and Behavior, 36 (2), pp. 266-275; Nussbaum, M.C., (2000) Women and Human Development, , New York: Cambridge University Press; Nussbaum, M.C., (2006) Frontiers of Justice, , Cambridge, Massachusetts: Belknap Press; Nussbaum, M.C., O'Neill, O., Justice, gender, and international boundaries (1993) The Quality of Life, pp. 324-335. , C. Nussbaum and A. Sen (Eds.), Oxford: Clarendon Press; Onishi, N., (2006) In a wired South Korea, robots will feel right at home, , http://www.nytimes.com/2006/04/02/world/asia/02robot.html, The New York Times, April 2, 2006, Accessed July 2, 2009; Oosterlaken, I., Design for development: A capability approach (2009) Design Issues, 25 (4), pp. 91-102; Pear, R., (2008) Violations reported at 94% of nursing homes, , http://www.nytimes.com/2008/09/30/us/30nursing.html, The New York Times. September 29, 2008, Accessed July 7, 2009; Reidy, K., Crozier, K.S., Refusing treatment during rehabilitation-A model for conflict resolution, In rehabilitation medicine-adding life to years [special issue] (1991) The Western Journal of Medicine, 154, pp. 622-623; Robeyns, I., The capability approach in practice (2006) The Journal of Political Philosphy, 14 (3), pp. 351-376; Robins, B., Dautenhahn, K., Te Boekhorst, R., Billard, A., Robotic assistants in therapy and education of children with autism: Can a small humanoid robot help encourage social interaction skills? (2005) Universal Access in the Information Society, 4, pp. 105-120; Scassellati, B., How social robots will help us to diagnose, treat, and understand autism (2007) Robotics Research, pp. 552-563. , S. Thrun, R. Brooks, and H. Durrant-Whyte (Eds.), Berlin: Springer; Sen, A., Capability and well-being (1993) The Quality of Life, pp. 31-53. , M. Nussbaum and A. Sen (Eds.), Oxford: Clarendon Press; Sen, A., (1999) Development as Freedom, , New York: Alfred A. Knopf; Shaw-Garlock, G., Looking forward to sociable robots (2009) International Journal of Social Robotics, 1, pp. 249-260; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Minds and Machines, 16, pp. 141-161; Steckenfinger, S.A., Ghazanfar, A.A., Monkey visual behavior falls into the uncanny valley (2009) PNAS, 106 (43), pp. 18362-18366; Sung, J.Y., Guo, L., Grinter, R.E., Christensen, H.I., My Roomba is Rambo: Intimate home appliances (2007) UbiComp 2007: Ubiquitous Computing, pp. 145-162. , J. Krumm, G. D. Abowd, A. Seneviratne, and T. Strang (Eds.), Berlin: Springer; Terzi, L., A capability perspective on impairment, disability, and special needs (2005) Theory and Research in Education, 3 (2), pp. 197-223; Tucker, A., (2009) Robot babies. Smithsonian Magazine, pp. 56-65. , http://www.smithsonianmag.com/science-nature/Birth-of-a-Robot.html, July 2009, Accessed July 13, 2009; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , New York: Oxford University Press, Inc},
document_type={Article},
source={Scopus},
}

@ARTICLE{Whitby2008326,
author={Whitby, B.},
title={Sometimes it's hard to be a robot: A call for action on the ethics of abusing artificial agents},
journal={Interacting with Computers},
year={2008},
volume={20},
number={3},
pages={326-333},
doi={10.1016/j.intcom.2008.02.002},
note={cited By 42},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-43049172266&doi=10.1016%2fj.intcom.2008.02.002&partnerID=40&md5=fd07a31d2cf35a40936c87773f820098},
abstract={This is a call for informed debate on the ethical issues raised by the forthcoming widespread use of robots, particularly in domestic settings. Research shows that humans can sometimes become very abusive towards computers and robots particularly when they are seen as human-like and this raises important ethical issues. The designers of robotic systems need to take an ethical stance on at least three specific questions. Firstly is it acceptable to treat artefacts - particularly human-like artefacts - in ways that we would consider it morally unacceptable to treat humans? Second, if so, just how much sexual or violent 'abuse' of an artificial agent should we allow before we censure the behaviour of the abuser? Thirdly is it ethical for designers to attempt to 'design out' abusive behaviour by users? Conclusions on these and related issues should be used to modify professional codes as a matter of urgency. © 2008 Elsevier B.V. All rights reserved.},
author_keywords={Abusive interaction;  Ethical design;  Robot ethics},
keywords={Codes (standards);  Intelligent agents;  Man machine systems;  Product design;  Professional aspects;  Robots, Abusive interaction;  Ethical design;  Robot ethics, Artificial intelligence},
references={Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12, pp. 251-261; Anderson, C.A., Bushman, B.J., Effects of violent video games on aggressive behaviour, aggressive cognition, aggressive affect, psychological arousal, and prosocial behaviour: a meta-analytic review of the scientific literature (2001) Psychological Science, 12 (5), pp. 353-359; Aristotle, (1968) The Poetics, , Aristotle, OUP; Boden, M.A., (2006) Mind as Machine. A History of Cognitive Science, , Oxford University Press pp. 1094-1095; De Angeli, A., Brahnam, S., Wallis, P., 2006. Misuse and abuse of interactive technologies, In: Proceedings of CHI'06, pp. 1647-1650; du Boulay, B., Luckin, R., del Soldato, T., The plausibility problem: human teaching tactics in the 'hands' of a machine (1999) Artificial Intelligence in Education: Open Learning Environments: New Computational Technologies to Support Learning, Exploration and Collaboration. Proceedings of the International Conference of the AI-ED Society on Artificial Intelligence and Education, pp. 225-232. , Lajoie S.P., and Vivet M. (Eds), IOS Press, Le Mans France; Fogg, B.J., Tseng, H., 1999. The Elements of Computer Credibility, Proceedings of CHI'99, pp. 80-87; Frude, N., (1983) The Intimate Machine: Close Encounters with New Computers, , Century, London; Garreau, J., 2007. Bots on the ground: in the field of battle (or even above it), Robots are a soldier's best friend, Washington Post, May 6th, 2007; Gates, B., 2007. Scientific American Magazine, January, pp. 58-65; Hobbes, T., 1651. Leviathan, XIV, pp. 25; Kant, I., 1788. Critique of Practical Reason. 8, pp. 287; LaChat, M.R., Artificial intelligence and ethics: an exercise in the moral imagination (1986) AI Magazine, 7 (2), pp. 70-79; Lovgren, S., 2006. A Robot in Every Home by 2010, South Korea Says, National Geographic News, 6th September, 2006; Mill, J.S., 1859. On Liberty, reprinted in John Stuart Mill, A Selection of his Works. Robson, J.M. (Ed.), (1966) Macmillan, Toronto, pp. 14; Picard, R., (1998) Affective Computing, , MIT Press, Cambridge, MA; Singer, P., (1979) Practical Ethics, , Cambridge University Press pp. 1; Torrance, S., Towards an ethics for epersons (2000) Proceedings of the AISB 2000 Symposium on Artificial Intelligence, Ethics and (Quasi-) Human Rights, pp. 47-52. , Barnden J. (Ed), University of Birmingham; Turing, A.M., 1950. Computing machinery and intelligence, Mind, vol. LIX, No. 236; Weizenbaum, J., (1984) Computer Power and Human Reason, , Penguin, Harmondsworth; Whitby, B.R., (1988) Artificial Intelligence: A Handbook of Professionalism, , Ellis Horwood, Chichester pp. 152-158; Whitby, B.R., 1993. The virtual sky is not the limit - the ethical implications of virtual reality. Intelligent Tutoring Media vol. 3, No. 2; Whitby, B.R., (1996) Reflections on Artificial Intelligence: The Legal, Moral, and Ethical Dimensions, , Intellect, Exeter pp. 93-105},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bynum2006157,
author={Bynum, T.W.},
title={Flourishing ethics},
journal={Ethics and Information Technology},
year={2006},
volume={8},
number={4},
pages={157-173},
doi={10.1007/s10676-006-9107-1},
note={cited By 42},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750995722&doi=10.1007%2fs10676-006-9107-1&partnerID=40&md5=3e23d46a69b9d6aa186699cd6a16a532},
abstract={This essay describes a new ethical theory that has begun to coalesce from the works of several scholars in the international computer ethics community. I call the new theory Flourishing Ethics because of its Aristotelian roots, though it also includes ideas suggestive of Taoism and Buddhism. In spite of its roots in ancient ethical theories, Flourishing Ethics is informed and grounded by recent scientific insights into the nature of living things, human nature and the fundamental nature of the universe-ideas from today's information theory, astrophysics and genetics. Flourishing Ethics can be divided conveniently into two parts. The first part, which I call Human-Centered FE, is focused exclusively upon human beings - their actions, values and characters. The second part, which I call General FE, applies to every physical entity in the universe, including humans. Rather than replacing traditional great ethical theories, Flourishing Ethics is likely to deepen and broaden our understanding of them. © Springer Science+Business Media B.V. 2006.},
author_keywords={Aristotelian ethics;  Computer ethics;  Cybernetics;  Cyborg ethics;  Entropy;  Good and evil;  Information ethics;  Infosphere;  Just consequentialism;  Robot ethics},
keywords={Aristotelian ethics;  Computer ethics;  Good and evil;  Information ethics;  Infosphere;  Just consequentialism;  Robot ethics, Astrophysics;  Cybernetics;  Entropy, Philosophical aspects},
references={On the Movement of Animals; On the Soul; Nicomachean Ethics; and Eudemian Ethics, , Aristotle; Baumrin, B.H., Applying Philosophy (1988) Applying Philosophy, pp. 1-10. , I n T.W. Bynum and W. Vitek, editors Blackwell (A monograph of the Metaphilosophy Foundation); Bekenstein, J.D., Information in the Holographic Universe (2003) Scientific American, , August; Bynum, T.W., (1986) Aristotle's Theory of Human Action, , UMI; Bynum, T.W., The Foundation of Computer Ethics (2000) Computers and Society, , June 6-13; Bynum, T.W., Ethical Challenges to Citizens of "The Automatic Age": Norbert Wiener on the Information Society (2004) Journal of Information, Communication and Ethics in Society, 2 (2), pp. 65-74; Bynum, T.W., The Impact of the "Automatic Age" on Our Moral Lives (2005) The Impact of the Internet on Our Moral Lives, pp. 11-25. , In R. Cavalier, editor State University of New York Press; Bynum, T.W., Norbert Wiener and the Rise of Information Ethics (2007) Moral Philosophy and Information Technology, , In W.J. van den Hoven and J. Weckert, editors Cambridge University Press (forthcoming); Chang, K., Intelligent Beings in Space! (2006) New York Times, pp. F4. , May 30, F1; Conway, F., Siegelman, J., (2005) Dark Hero of the Information Age: In Search of Norbert Wiener, the Father of Cybernetics, , Basic Books; Cooper, J.M., (1975) Reason and Human Good in Aristotle, , Harvard University Press; Floridi, L., Information Ethics: On the Theoretical Foundations of Computer Ethics (1999) Ethics and Information Technology, 1 (1), pp. 37-56; Floridi, L., On the Intrinsic Value of Information Objects and the Infosphere (2003) Ethics and Information Technology, 4 (4), pp. 287-304; Floridi, L., Information Ethics: Its Nature and Scope (2006) Moral Philosophy and Information Technology, , In W.J. van den Hoven and J. Weckert, editors Cambridge University Press; Floridi, L., Global Information Ethics: The Importance of Being Environmentally Earnest, , (a forthcoming article); Floridi, L., Sanders, J.W., The Foundationalist Debate in Computer Ethics (2004) Readings in CyberEthics, pp. 81-95. , In R.A. Spinello and H.T. Tavani, editors 2nd edition Jones and Bartlett; Floridi, L., Sanders, J.W., On the Morality of Artificial Agents (2004) Minds and Machines, 14 (3), pp. 349-379; Gert, B., (1998) Morality: Its Nature and Justification, , Oxford University Press; Kuhn, T.H., (1962) The Structure of Scientific Revolutions, , University of Chicago Press; Lloyd, S., (2006) Programming the Universe, , Knopf; Maner, W., (1980) Starter Kit on Teaching Computer Ethics, , Helvetia Press (originally self published in 1978); Markoff, J., Brainy Robots Start Stepping into Daily Life (2006) New York Times, pp. A1. , July 18 C4; Moor, J.H., What Is Computer Ethics? (1985) Computers and Ethics, pp. 263-275. , In T.W. Bynum, editor Blackwell [Published as the October 1985 special issue of Metaphilosophy. ]; Moor, J.H., Reason, Relativity and Responsibility in Computer Ethics (1998) Computers and Society, 28, p. 1; Moor, J.H., Just Consequentialism and Computing (1999) Ethics and Information Technology, 1, pp. 65-69; Moor, J.H., An Interview with James Moor (2006) Ethics for the Information Age, pp. 103-105. , In M.J. Quinn, editor 2nd edition Addison Wesley; Ryle, G., (1949) The Concept of Mind, , University of Chicago Press; Wheeler, J., (1990) Information, Physics, Quantum: The Search for Links, , Westview; Wiener, N., (1948) Cybernetics: Or Control and Communication in the Animal and the Machine, , Technology Press; Wiener, N., (1950) The Human Use of Human Beings: Cybernetics and Society, , Houghton Mifflin (Second Edition Revised, Doubleday Anchor, 1954); Wiener, N., (1964) God & Golem, Inc. A Comment on Certain Points Where Cybernetics Impinges on Religion, , MIT Press},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Hellström201399,
author={Hellström, T.},
title={On the moral responsibility of military robots},
journal={Ethics and Information Technology},
year={2013},
volume={15},
number={2},
pages={99-107},
doi={10.1007/s10676-012-9301-2},
note={cited By 40},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879780209&doi=10.1007%2fs10676-012-9301-2&partnerID=40&md5=ea02a70402342e41bd8eb7df8b61df60},
abstract={This article discusses mechanisms and principles for assignment of moral responsibility to intelligent robots, with special focus on military robots. We introduce the concept autonomous power as a new concept, and use it to identify the type of robots that call for moral considerations. It is furthermore argued that autonomous power, and in particular the ability to learn, is decisive for assignment of moral responsibility to robots. As technological development will lead to robots with increasing autonomous power, we should be prepared for a future when people blame robots for their actions. It is important to, already today, investigate the mechanisms that control human behavior in this respect. The results may be used when designing future military robots, to control unwanted tendencies to assign responsibility to the robots. Independent of the responsibility issue, the moral quality of robots' behavior should be seen as one of many performance measures by which we evaluate robots. How to design ethics based control systems should be carefully investigated already now. From a consequentialist view, it would indeed be highly immoral to develop robots capable of performing acts involving life and death, without including some kind of moral framework. © 2012 Springer Science+Business Media B.V.},
author_keywords={Autonomy;  Military robots;  Moral responsibility;  Robot ethics;  Robots},
keywords={Assign responsibilities;  Autonomy;  Human behaviors;  Military robots;  Moral responsibility;  Performance measure;  Robot ethics;  Technological development, Quality control, Robots},
references={(2011) Military robot markets to exceed $8 billion in 2016., , http://www.abiresearch.com/press/3616-Military+Robot+Markets+to+Exceed+%248+Billion+in+2016, ABIresearch Retrieved June 15, 2012, from; Allen, C., Wallach, W., Smit, I., (2006) Why machine ethics?, pp. 12-17. , IEEE Intelligent Systems, July/August; (1985) The Nicomachean Ethics (Terence Irwin, Trans.), , Aristotle Hackett Publishing Co, 1985; Arkin, R.C., (2009) Governing Lethal Behavior in Autonomous Robots, , London: Chapman & Hall/CRC; Arkin, R.C., Ethical robots in warfare (2009) IEEE Technology and Society Magazine, 28 (1), pp. 30-33; Asaro, P.M., (2006) What should we want from a robot ethic? IRIE International Review of Information Ethics, 6. , 12/2006; Bechtel, W., Attributing responsibility to computer systems (1985) Metaphilosophy, 16 (4), pp. 296-306; Bone, E., Bolkcom, C., (2003) Unmanned aerial vehicles: Background and issues for congress, , https://www.policyarchive.org/handle/10207/1698, Retrieved January 3, 2012, from; Connolly, W., (1974) The Terms of Political Discourse, , Princeton: Princeton University Press; Dennett, D.C., Mechanism and responsibility (1973) Essays on Freedom of Action, , T. Honderich (Ed.), Boston: Routledge & Keegan Paul; Dennett, D.C., When HAL kills, who's to blame? computer ethics (1997) HAL's Legacy: 2001′S Computer as Dream and Reality, , D. G. Stork (Ed.), Cambridge: MIT Press; Dodig-Crnkovic, G., Persson, D., Sharing moral responsibility with robots: A pragmatic approach (2008) 10h Scandinavian Conference on Artificial Intelligence SCAI 2008 (Vol. 173). Frontiers in Artificial Intelligence and Applications, , In A. Holst, P. Kreuger, & P. Funk (Eds.); Eshleman, A., (2009) Moral responsibility, the stanford encyclopedia of philosophy (Winter 2009 Edition), , http://plato.stanford.edu/archives/win2009/entries/moral-responsibility/, In E. N. Zalta (Ed.), Retrieved January 21, 2012, from; Franklin, S., Graesser, A., (1997) Is It an Agent, Or Just a Program?: A Taxonomy for Autonomous Agents, pp. 21-35. , Berlin: Intelligent Agents III; Friedman, B., Moral responsibility and computer technology (1990) Erin document reproduction services; Friedman, B., Millett, L., It's the computer's fault-reasoning about computers as moral agents (1995) In Conference companion of the conference on human factors in computing systems, pp. 226-227. , Denver, CO; Friedman, B., Millett, L., (1997) Reasoning about computers as moral agents: A research note, in human values and the design of computer technology, , In B. Friedman (Ed.), Stanford/New York: CSLI Publications/Cambridge University Press; (2012) TALON small mobile robot, , http://www.globalsecurity.org/military/systems/ground/talon.htm, GlobalSecurity. Retrieved January 22, 2012, from; Grossman, N., Rehabilitation or revenge: Prosecuting child soldiers for human rights violations (2007) Georgetown Journal of International Law, 38, pp. 323-362; Hertzberg, J., Chatila, R., AI easoning methods for robotics (2008) Springer handbook of robotics, pp. 207-223; Hildebrand, A., (2009) Samsung Techwin's latest: A killing robot, info4 4 SECURITY, , http://www.info4security.com/story.asp?storycode=4121852, March. Retrieved January 21, 2012, from; Hinds, P., Roberts, T., Jones, H., Whose job is it anyway? A study of human-robot interaction in a collaborative task (2004) Human-Computer Interaction, 19, pp. 151-181; (2012), http://www.irobot.com/gi/ground, iRobot. Retrieved January 22, 2012, from; Johnson, D.G., Computer systems: Moral entities but not moral agents (2006) Ethics and Information Technology, 8, pp. 195-204; Kim, T., Hinds, P.J., Who should i blame? Effects of autonomy and transparency on attributions in human-robot interaction (2006) Proceedings of RO-MAN'06, pp. 80-85; Lin, P., Bekey, G., Abney, K., (2008) Autonomous military robotics: Risk, ethics, and design, a US department of defense office of naval research-funded report, , http://ethics.calpoly.edu/ONR_report.pdf, Retrieved June 16, 2012, from; Matarić, M.J., Michaud, F., Behavior-based systems (2008) Springer handbook of eobotics, pp. 891-909. , In B. Siciliano, & O. Khatib (Eds.). Springer; Matthias, A., The responsibility gap: Ascribing responsibility for the actions of learning automata (2004) Ethics and Information Technology, 6 (3), pp. 175-183; Miller, K.W., Moral responsibility for computing artifacts: "The rules" (2011) IT Professional, 13 (3), pp. 57-59; Moon, Y., Nass, C., Are computers scapegoats? Attributions of responsibility in human-computer interaction (1998) International Journal of Human-Computer Studies, 49 (1), pp. 79-94; Parasuraman, R., Sheridan, T.B., Wickens, C.D., A model for types and levels of human interaction with automation (2000) IEEE Transactions on Systems, Man, & Cybernetics, 30 (3), pp. 286-297; Qinetic, Q., (2012) MAARS-Modular Advanced Armed Robotic System, , http://www.qinetiq-na.com/products/unmanned-systems/maars/, Retrieved January 22, 2012, from; (2009) News release, , http://www.raytheon.ca/rtnwcm/groups/rcl/documents/content/rcl_archive_phalanx_release.pdf, Raytheon. Retrieved January 22, 2012, from; Riedel, F.W., Hall, S.M., Barton, J.D., Christ, J.P., Funk, B.K., Milnes, T.D., Guidance and navigation in the global engagement department (2010) Johns Hopkins APL Technical Digest, 29 (2); (2012) SGR-1, , http://www.samsungtechwin.com/product/product_01_02.asp, Samsung. Retrieved January 22, 2012, from; Sheridan, T.B., (1992) Telerobotics, Automation, and Human Supervisory Control, , USA: MIT Press; Singer, P.W., (2009) Wired for war-The robotics revolution and 21st Century conflict, , Penguin; Singer, P.W., Military robots and the laws of war (2009) The New Atlantis, , Winter 2009; Singer, P.W., Wired for war? Robots and military doctrine (2009) JFQ: Joint Force Quarterly, 2009 1st Quarter, 1 (52), pp. 104-110; Sofge, E., (2009) America's Robot Army: Are Unmanned Fighters Ready for Combat?, , http://www.popularmechanics.com/technology/military/robots/4252643, Retrieved January 3, 2012, from; Sparrow, R., Killer robots (2007) Journal of Applied Philosophy, 24 (1), pp. 62-77; Stahl, B.C., (2004) Responsible Management of Information Systems, , Hershey: Idea-Group Publishing; Strawson, P.F., (1974) Freedom and Resentment, in Freedom and Resentment and Other Essays, , London: Methuen; Sutton, R.S., Barto, A.G., (1998) Reinforcement Learning: An Introduction, , Cambridge: MIT Press; Thorndike, E.L., (1911) Animal Intelligence, , 2nd edn., New York: Hafner. Transaction Publishers, 2000; 'Reaper' moniker given to MQ-9 unmanned aerial vehicle (2006) The official Web site of U. S. Air Force, , http://www.af.mil/news/story.asp?storyID=123027012&page=2, U. S. Air Force. Retrieved January 3, 2012, from; (2009) Unmanned Aircraft Systems Flight Plan 2009-2047, , http://www.globalsecurity.org/military/library/policy/usaf/usaf-uas-flight-plan_2009-2047.pdf, U. S. Air Force. Retrieved January 3, 2012, from; (2011) MK 15-Phalanx Close-In Weapons System (CIWS), United States Navy Fact File, , http://www.navy.mil/navydata/fact_display.asp?cid=2100&tid=487&ct=2, U. S. Navy. Retrieved June 14, 2012, from; Walzer, M., Just and unjust wars: A moral argument with historical illustrations (2006) Basic Books; Wezeman, S., (2007) UAVS and UCAVS: Developments in the European Union, , http://www.europarl.europa.eu/activities/committees/studies/download.do?file=19483, European Parliament, October, 2007. Retrieved January 3, 2012, from; Yamauchi, B., PackBot: A Versatile platform for military robotics (2004) Proceedings of SPIE Vol. 5422: Unmanned ground vehicle technology VI, , Orlando, FL; Yamauchi, B., Pook, P., Gruber, A., Bloodhound: A semi-autonomous battlefield medical robot (2002) Proceedings of the 23rd Army Science Conference, , U. S. Army, Orlando, FL; Young, I.M., Responsibility and global labor justice (2010) Responsibility in context: Perspectives, , In G. Ognjenovic (Ed.). Springer},
document_type={Article},
source={Scopus},
}

@ARTICLE{Tonkens2009421,
author={Tonkens, R.},
title={A challenge for machine ethics},
journal={Minds and Machines},
year={2009},
volume={19},
number={3},
pages={421-438},
doi={10.1007/s11023-009-9159-1},
note={cited By 40},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-71149115886&doi=10.1007%2fs11023-009-9159-1&partnerID=40&md5=7696f6acb9f1a3d8b07dae4b5ea9d18c},
abstract={That the successful development of fully autonomous artificial moral agents (AMAs) is imminent is becoming the received view within artificial intelligence research and robotics. The discipline of Machines Ethics, whose mandate is to create such ethical robots, is consequently gaining momentum. Although it is often asked whether a given moral framework can be implemented into machines, it is never asked whether it should be. This paper articulates a pressing challenge for Machine Ethics: To identify an ethical framework that is both implementable into machines and whose tenets permit the creation of such AMAs in the first place. Without consistency between ethics and engineering, the resulting AMAs would not be genuine ethical robots, and hence the discipline of Machine Ethics would be a failure in this regard. Here this challenge is articulated through a critical analysis of the development of Kantian AMAs, as one of the leading contenders for being the ethic that can be implemented into machines. In the end, however, the development of Kantian artificial moral machines is found to be anti-Kantian. The upshot of all this is that machine ethicists need to look elsewhere for an ethic to implement into their machines. © 2009 Springer Science+Business Media B.V.},
author_keywords={Artificial moral agents;  Ethical consistency;  Kantian morality;  Machine Ethics},
keywords={Artificial intelligence research;  Critical analysis;  Gaining momentum;  Moral agents, Artificial intelligence;  Robots, Autonomous agents},
references={Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics and Information Technology, 7 (3), pp. 149-155. , DOI 10.1007/s10676-006-0004-4, Ethics of New Information Technology Papers from CEPE 2005; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12 (3), pp. 251-261. , 1008.68092 10.1080/09528130050111428; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) IEEE Intelligent Systems, 21 (4), pp. 12-17. , DOI 10.1109/MIS.2006.83, 1667947; Anderson, M., Anderson, S.L., Machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 10-11. , DOI 10.1109/MIS.2006.70, 1667946; Anderson, M., Anderson, S.L., The status of machine ethics: A report from the AAAI Symposium (2007) Minds and Machines, 17 (1), pp. 1-10. , DOI 10.1007/s11023-007-9053-7; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 26 (4), pp. 15-26; (1994) Dimensions of Creativity, , M.A. Boden (eds). MIT Press Cambridge; Brooks, R.A., Intelligence without representation (1991) Artificial Intelligence, 47, pp. 139-159. , 10.1016/0004-3702(91)90053-M; Calverley, D.J., Imagining a non-biological machine as a legal person (2008) AI & SOCIETY, 22 (4), pp. 523-537. , 10.1007/s00146-007-0092-7; Floridi, L., Sanders, J.W., On the morality of artificial agents (2007) Minds and Machines, 14 (3), pp. 349-379. , 10.1023/B:MIND.0000035461.63578.9d; Gips, J., Towards the ethical robot (1995) Android Epistemology, pp. 243-252. , K. Ford C. Glymour P. Hayes (eds). MIT Press Cambridge; Gips, J., Creating ethical robots: A grand challenge (2005) AAAI Symposium on Machine Ethics, , Washington, DC; Grau, C., There is no "I" in "Robot": Robots and utilitarianism (2006) IEEE Intelligent Systems, 21 (4), pp. 52-55. , DOI 10.1109/MIS.2006.81, 1667954; Guarini, M., Particularism and the classification and reclassification of moral cases (2006) IEEE Intelligent Systems, 21 (4), pp. 22-28. , DOI 10.1109/MIS.2006.76, 1667949; Johnson, D.G., Computer systems: Moral entities but not moral agents (2006) Ethics and Information Technology, 8 (4), pp. 195-204. , DOI 10.1007/s10676-006-9111-5; Kant, I., (1785) Fundamental Principles of the Metaphysic of Morals (T. K. Abbott, Trans.), , New York: Prometheus Books; Kant, I., (1797) The Metaphysics of Morals (M. Gregor, Trans.), , Cambridge: Cambridge University Press; Kant, I., (1997) Lectures on Ethics (P. Heath, Trans.), , Cambridge: Cambridge University Press; McCarthy, J., Free will-even for robots (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12 (3), pp. 341-352. , 1008.68136 10.1080/09528130050111473 1737527; McLaren, B.M., Computational models of ethical reasoning: Challenges, initial steps, and future directions (2006) IEEE Intelligent Systems, 21 (4), pp. 29-37. , DOI 10.1109/MIS.2006.67, 1667950; Mill, J.S., (1871) Utilitarianism, , New York: Broadview; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21. , DOI 10.1109/MIS.2006.80, 1667948; Nadeau, J.E., Only androids can be ethical (2006) Thinking about Android Epistemology, pp. 241-248. , K. Ford C. Glymour P.J. Hayes (eds). MIT Press Cambridge; O'Neill, O., (1989) Constructions of Reason: Explorations of Kant's Practical Philosophy, , Cambridge University Press New York; Picard, R.W., (1997) Affective Computing, , MIT Press Cambridge; Powers, T.M., Prospects for a kantian machine (2006) IEEE Intelligent Systems, 21 (4), pp. 46-51. , DOI 10.1109/MIS.2006.77, 1667953; Rawls, J., (2000) Lectures on the History of Moral Philosophy, , Harvard University Press Cambridge; Sparrow, R., Killer robots (2007) Journal of Applied Philosophy, 24 (1), pp. 62-77. , 10.1111/j.1468-5930.2007.00346.x; www.cbo.gov/ftpdoc.cfm?index=7122, The U.S. Army Future Combat Systems Program. (2006). Retrieved July 31, 2008, from; Torrance, S., Ethics and consciousness in artificial agents (2008) AI & SOCIETY, 22 (4), pp. 495-521. , 10.1007/s00146-007-0091-8; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford: Oxford University Press (forthcoming); Wallach, W., Allen, C., Smit, I., Machine morality: Bottom-up and top-down approaches for modelling human moral faculties (2008) AI & SOCIETY, 22, pp. 565-582. , 10.1007/s00146-007-0099-0},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sharkey2016283,
author={Sharkey, A.J.C.},
title={Should we welcome robot teachers?},
journal={Ethics and Information Technology},
year={2016},
volume={18},
number={4},
pages={283-297},
doi={10.1007/s10676-016-9387-z},
note={cited By 39},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957692645&doi=10.1007%2fs10676-016-9387-z&partnerID=40&md5=d2ed188eeec2c453f8895656c2333758},
abstract={Current uses of robots in classrooms are reviewed and used to characterise four scenarios: (s1) Robot as Classroom Teacher; (s2) Robot as Companion and Peer; (s3) Robot as Care-eliciting Companion; and (s4) Telepresence Robot Teacher. The main ethical concerns associated with robot teachers are identified as: privacy; attachment, deception, and loss of human contact; and control and accountability. These are discussed in terms of the four identified scenarios. It is argued that classroom robots are likely to impact children’s’ privacy, especially when they masquerade as their friends and companions, when sensors are used to measure children’s responses, and when records are kept. Social robots designed to appear as if they understand and care for humans necessarily involve some deception (itself a complex notion), and could increase the risk of reduced human contact. Children could form attachments to robot companions (s2 and s3), or robot teachers (s1) and this could have a deleterious effect on their social development. There are also concerns about the ability, and use of robots to control or make decisions about children’s behaviour in the classroom. It is concluded that there are good reasons not to welcome fully fledged robot teachers (s1), and that robot companions (s2 and 3) should be given a cautious welcome at best. The limited circumstances in which robots could be used in the classroom to improve the human condition by offering otherwise unavailable educational experiences are discussed. © 2016, The Author(s).},
author_keywords={Attachment;  Classroom;  Deception;  Privacy;  Robot companion;  Robot ethics;  Robot teacher},
keywords={Data privacy;  Education;  Philosophical aspects;  Robots;  Teaching;  Visual communication, Attachment;  Classroom;  Deception;  Robot companion;  Robot ethics, Economic and social effects},
references={Ainsworth, M.D.S., The development of infant–mother attachment (1973) Review of child development research, pp. 1-94. , Caldwell B, Ricciuti H, (eds), 3, University of Chicago Press, Chicago; Arkin, R., Governing lethal behavior in autonomous robots. Chapman-Hall review (2009) Computers and Education, 58 (3), pp. 978-988; Asaro, P., A body to kick, but still no soul to damn: Legal perspectives on robotics (2012) Robot ethics: The ethical and social implications of robotics, pp. 169-186. , Lin P, Abney K, Bekey GA, (eds), MIT Press, London; Bartneck, C., Hu, J., Exploring the abuse of robots (2008) Interaction Studies: Social Behaviour and Communication in Biological and Artificial Systems, 9, pp. 415-433; Benitti, F.B.V., Exploring the educational potential of robotics in schools: A systematic review (2012) Computers and Education, 58 (3), pp. 978-988; Bergin, C., Bergin, D., Attachment in the classroom (2009) Education Psychology Review, 21, pp. 141-170; Borenstein, J., Pearson, Y., Companion robots and the emotional development of children (2013) Law, Innovation and Technology, 5 (2), pp. 172-189; Bowlby, J., (1969) Attachment and loss: Volume 1: Attachment, , Hogarth Press, London; Brščić, D., Kidokoro, H., Suehiro, Y., Kanda, T., Escaping from children’s abuse of social robots (2015) In Proceedings of ACM/IEEE international conference on human-robot interaction, pp. 59-66; Calo, M.R., Robots and privacy (2012) Robot ethics: The ethical and social implications of robotics, pp. 187-202. , Lin P, Abney K, Bekey GA, (eds), The MIT Press, London; Carr, N., (2015) The glass cage: Where automation is taking us, , Bodley Head, London; Churchland, P.S., (2011) Braintrust: What neuroscience tells us about morality, , Princeton University Press, Oxford; Coeckelbergh, M., Health care, capabilities, and AI assistive technologies (2010) Ethical Theory and Moral Practice, 13 (2), pp. 181-190; Damiano, L., Dumoouchel, P., Lehmann, H., Artificial empathy: An interdisciplinary investigation (2014) International Journal of Social Robotics, 7 (1), pp. 3-5; Dietvorst, B., Simmons, J., Massey, C., Algorithm aversion: People erroneously avoid algorithms after seeing them err (2015) Journal of Experimental Psychology: General, 144 (1), pp. 114-126; Epley, N., Akalis, S., Waytz, A., Cacioppo, J.T., Creating social connection through inferential reproduction: Loneliness and perceived agency in gadgets, gods, and greyhounds (2008) Psychological Science, 19, pp. 114-120; Epley, N., Waytz, A., Caciopo, J.T., On seeing human: A three factor theory of anthropomorphism (2007) Psychological Review, 114 (4), pp. 864-886; (2012) Public attitudes towards robots, , Bussels: European Commission; Friedman, B., Kahn, P.H., Human agency and responsible computing: Implications for computer system design (1992) Journal of Systems and Software, 17 (1), pp. 7-14; Friedman, B., Nissenbaum, H., Bias in computer systems (1996) ACM Transaction on Information Systems (TOIS), 14 (3), pp. 330-347; (2005) Proceedings of the 14th IEEE International Workshop on Robot and Human Interactive Communication (RO-MAN 2005), , Han, J., Jo, M., Park, S., & Kim, S., The educational use of home robots for children. (pp. 378–383). Piscataway, NJ: IEEE; Han, J., Emerging technologies: Robot assisted language learning (2012) Language Learning and Technology, 16 (3), pp. 1-9; Hashimoto, T., Kato, N., Kobayashi, H., Development of educational system with the android robot SAYA and evaluation (2011) International Journal Advanced Robotic Systems, 8 (3), pp. 51-61. , (Special issues assistive robotics); An experimental study on user conformation to the iCub’s answers, , Gaudiello, I., Zibetti, E., Lefort, S., Chetouani, M., & Ivaldi, S. (submitted). Trust as indicator of robot functional and social acceptance. arXiv:1510.03678[cs.RO]; Heyns, C., Report of the Special Rapporteur on extrajudicial, summary or arbitrary executions (2013) A/HRC/23/47; (2015) HRI ’15, , Hood, D., Lemaignan, S., & Dillenbourg, P., When children teach a robot to write: an autonomous teachable humanoid which uses simulated handwriting, March 02–05 2015, Portland, OR, USA; Jung, C., The development of personality, Collected Works of C.G. Jung (1953) volume 17, , Princeton: N.J. Princeton University Press; Kanda, T., Hirano, T., Eaton, D., Ishiguro, H., Interactive robots as social partners and peer tutors for children: A field trial (2004) Human Computer Interaction, 9, pp. 61-84; Kanda, T., Sato, R., Saiwaki, N., Ishiguro, H., A two-month field trial in an elementary school for long-term human–robot interaction (2007) IEEE Transactions on Robotics, 23 (5), pp. 962-971; Kline, M.A., How to learn about teaching: An evolutionary framework for the study of teaching behavior in humans and other animals (2015) Behavioural and Brain Sciences, 38, pp. 1-17; Koenig, M., Sabbagh, M.A., Selective social learning: New perspectives on learning from others (2013) Developmental Psychology, 49, pp. 399-403; (2014) Proceedings of the second international conference on human–agent interaction, , Komatsubara, T., Shiomi, M., Kanda, T., Ishiguro, H., and Hagita, N., Can a social robot help children’s understanding of science in classrooms? (pp. 83–90); Levy, D., (2007) Love + sex with robots: The evolution of human–robot relationships, , Gerald Duckworth and Co., Ltd; Lin, P., Abney, K., Bekey, G.A., (2012) Robot ethics: The ethical and social implications of robotics, , MIT Press, London; Meah, L.F.S., Moore, R.K., The uncanny valley: A focus on misaligned cues. In M. Beetz, B. Johnston, M. Williams (Eds.), Social Robotics (vol. 8755, pp. 256–265) (2014) LNAI; (2009) Proceedings of 2009 international conference on human robot interaction (HRI2009), , Movellan, J., Eckhart, M., Virnes, M., & Rodriguez, A., Sociable robot improves toddler vocabulary skills; Mubin, O., Stevens, C.J., Shahid, S., Al Mahmud, A., Dong, J.J., A review of the applicability of robots in education (2013) Technology for Education and Learning, 1, pp. 1-7; Mutlu, B., Szafir, D., Pay Attention! Designing adaptive agents that monitor and improve user engagement (2012) In Proceedings of Human Factors in Computing (CHI, p. 2012; (2011) Proceedings of workshop on advanced robotics and its social impacts, , http://www.arso2011.org/papers, Park, S., Han, J., Kang, B., & Shin, K., Teaching assistant robot, ROBOSEM, in English class and practical issues for its diffusion; Pelissier, C., The anthropology of teaching and learning (1991) Annual Review of Anthropology, 20, pp. 75-95; Rostanti, S., Can a robot teach? University of Sheffield (2015) Department of Computer Science undergraduate dissertation; Sabbagh, M.A., Shafman, D., How children block learning from ignorant speakers (2009) Cognition, 112, pp. 415-422; Sharkey, A., Robots and human dignity: The effects of robot care on the dignity of older people (2014) Ethics and Information Technology, 16 (1), pp. 53-75; Sharkey, A., Robot teachers: The very idea! (2015) Behavioural and Brain Sciences, 38, pp. 46-47; Sharkey, N., Sharkey, A., Artificial intelligence and natural magic (2006) Artificial Intelligence Review, 25, pp. 9-19; Sharkey, N.E., Sharkey, A.J.C., The crying shame of robot nannies: An ethical appraisal (2010) Interaction Studies, 11 (2), pp. 161-190; Sharkey, A., Sharkey, N., Children, the elderly, and interactive robots (2011) IEEE Robotics and Automation Magazine, 18 (1), pp. 32-38; Sharkey, A.J.C., Sharkey, N.E., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics and Information Technology, 14 (1), pp. 27-40; Sparrow, R., The march of the robot dogs (2002) Ethics and Information Technology, 4, pp. 305-318; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Mind and Machine, 16, pp. 141-161; Takayama, L., Ju, W., Nass, C., (2008) Beyond dirty, dangerous and dull: What every day people think robots should do (2008) In Proceedings of Human Robot Interaction, 12-15, pp. 25-32. , March; Tanaka, F., Cicourel, A., Movellan, J.R., Socialization between toddlers and robots at an early childhood education center (2007) Proceedings of the National Academy of Science, 194 (46), pp. 17954-17958; Tanaka, F., Kimura, T., The use of robots in early education: a scenario based on ethical consideration (2009) In Proceedings of the 18th IEEE international symposium on robot and human interactive communication (RO-MAN, 2009, pp. 558-560; Tanaka, F., Matsuzoe, S., Children teach a care-receiving robot to promote their learning: Field experiments in a classroom for vocabulary learning (2012) Journal of Human-Robot Interaction, 1 (1), pp. 78-95; Tanaka, F., Takahashi, T., Matsuzoe, S., Tazawa, & Morita, M (2013) Child-operated telepresence robot: A field trial connecting classrooms between Australia and Japan. In Proceedings of IEEE/RSJ international conference on intelligent robots and systems (IROS 2013), Tokyo, Japan, November, 2013, pp. 5896-5901; Van Wynsberghe, A., Designing care robots for care: Care centered value-sensitive design (2013) Journal of Science and Engineering Ethics, 19 (2), pp. 407-433; Wallach, W., Allen, C., (2009) Moral machines: Teaching robots right from wrong, , Oxford University Press, New York; (2014) Advances in autonomous robotics systems: Proceedings of the 15th annual conference, TAROS 2014, , Winfield, A.F., Blum, C., and Liu, W., Towards an ethical robot: Internal models, consequences and ethical action selection. In M. Mistry, A. Leonardis, M. Witkowski, & C. Melhuish (Eds) (pp 85–96). Birmingham, UK, 1–3 September; Yamaoka, F., Kanda, T., Ishiguro, H., Hagita, N., Interacting with a human or a humanoid robot? (2007) In Proceeding of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS, p. 2007; Yun, S., Shin, J., Kim, D., Kim, C.G., Kim, M., Choi, M.T., Engkey: Tele-education robot. In B. Mutlu, et al. (Eds.) Social robotics: Proceedings of the third international conference on social robotics, LNAI 7072, pp (2011) 142–152; Zhang, J., Sharkey, A., It’s not all written on the robot’s face (2012) Robotics and Autonomous Systems, 60 (11), pp. 1449-1456},
document_type={Article},
source={Scopus},
}

@ARTICLE{Levy2009209,
author={Levy, D.},
title={The ethical treatment of artificially conscious robots},
journal={International Journal of Social Robotics},
year={2009},
volume={1},
number={3},
pages={209-216},
doi={10.1007/s12369-009-0022-6},
note={cited By 39},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-78249257568&doi=10.1007%2fs12369-009-0022-6&partnerID=40&md5=dcb9ab2b826b80fa8bed16a95c097c06},
abstract={The ethical aspects of robotics have recently gained sufficient importance to be debated in international forums and to be endowed with their own collective nametag-roboethics. Almost all of the discussion within the roboethics community and elsewhere has thus far centered on questions of the form: "Is it ethical to develop and use robots for such-and-such a purpose?", questions based upon doubts about the effect that a particular type of robot is likely to have, both on society in general and on those with whom the robots will interact in particular. What has usually been missing from the debate is the complementary question: "Is it ethical to treat robots in such-and-such a way?" Here we attempt to redress the balance, having first reviewed some of the relevant literature. © The Author 2009.},
author_keywords={Machine consciousness;  Roboethics;  Robot consciousness;  Robot ethics;  Robot rights},
keywords={Ethical aspects;  Machine consciousness;  Roboethics, Philosophical aspects, Robots},
references={Aleksander, I., Artificial neuroconsciousness: An update (1995) IWANN, , http://www.ee.ic.ac.uk/research/neural/publications.iwann.html; Arkin, R., Lethality and autonomous robots: An ethical stance (2007) ICRA'07: IEEE International Conference On Robotics and Automation, , Rome; Billings, L., (2007) Rise of Roboethics. Grappling With the Implications of An Artificially Intelligent Culture, , www.seedmagazine.com/news/2007/07/rise_of_roboethics.php?; Calverley, D., Toward a method for determining the legal status of a conscious machine (2005) Proceedings of the AISB 2005 Symposium On Next Generation Approaches to Machine Consciousness: Imagination, Development, Intersubjectivity, and Embodiment, , Chrisley R, Clowes R, Torrance S, University of Hertfordshire; Calverley, D., Android science and the animal rights movement: Are there analogies? (2005) Cognitive Sciences Society Workshop, pp. 127-136. , Stresa, Italy; (2007) Ethical Code For Robots In Works, South Korea Says, , www.cbc.ca/technology/story/2007/03/07/tech-robot-ethics.html, CBC; Chella, A., Manzotti, R., (2007) Artificial Consciousness, , Imprint Academic, Exter; Clark, R., Squire, L., Classical conditioning and brain systems: The role of awareness (1998) Science, 280 (3), pp. 77-81; Clark, R., Squire, L., Human eyeblink classical conditioning: Effects of manipulating awareness of the stimulus contingencies (1999) Psychol Sci, 10, pp. 14-18; Clowes, R., Torrance, S., Chrsley, R., Machine consciousness: Embodiment and imagination (2007) J Conscious Stud, 14 (7). , Special issue; de Quincey, C., Switched-on consciousness: Clarifying what it means (2006) J Conscious Stud, 13 (4), pp. 7-12; Robot wars (2007) The Economist, , http://www.economist.com/science/tq/displaystory.cfm?story_id=9028041, Economist, April 17th 2007; Freitas, R., The legal rights of robots (1985) Stud Lawyer, 13, pp. 54-56. , http://www.freitas.com/Astro/LegalRightsOfRobots.html, A later draft is available at; Freud, S., New introductory lectures on psychoanalysis (1933) In-ternationaler Psychoanalytischer, , Leipzig; Gallup, G., Self-recognition in primates: A comparative approach to the bidirectional properties of consciousness (1977) Am Psy-chol, pp. 329-338; (2003) Machine Consciousness, , Holland O, Imprint Academic, Exeter; Kant, I., (1996) Lectures On Ethics, , Heath P, Schneewind J, Cambridge University Press, New York; Koch, C., (2004) The Quest For Consciousness: A Neurobiological Approach, , Roberts and Company, Englewood; Lehman-Wilzig, S., Frankenstein unbound: Towards a legal definition of artificial intelligence (1981) Futures, pp. 442-457; Levy, D., (2006) Robots Unlimited, , AK Peters, Wellesley; Levy, D., (2007) Intimate Relationships With Artificial Partners, , Ph.D. Dissertation, Maastricht University, Maastricht, The Netherlands; Levy, D., (2007) Love and Sex With Robots, , Harper Collins, New York; Owen, J., Osley, R., (2007) Bill of Rights For Abused Robots: Experts Draw Up An Ethical Charter to Prevent Humans Exploiting Machines, , The Independent, April 1st; Pinker, S., (1997) Could a Computer Ever Be Conscious?, , http://pinker.wjh.harvard.edu/articles/media/1997_08_18_usnewsworldreport.html; Ramey, C., 'For the sake of others': The 'personal ethics' of human-android interaction (2005) Proceedings of COGSCI Workshop: Toward Social Mechanisms of Android Science, pp. 137-148. , Stresa, Italy, July 25-26; Sloman, A., (1996) A Systematic Approach to Consciousness, , http://www.cs.bham.ac.uk/~axs/misc/consciousness.rsa.text, How to avoid talking nonsense?, Summary of a lecture presented by Aaron Sloman at the Royal Society of Arts, 26 February 1996; Solum, L., Legal personhood for artificial intelligences (1992) North Carol Law Rev, 70, pp. 1231-1287; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Minds Mach, 16 (2), pp. 141-161; Stone, C., Should trees have standing? Toward legal rights for natural objects (1972) South Calif Law Rev, 45, pp. 450-457; Stone, C., (1997) 'Should Trees Have Standing?' and Other Essays On Law, Morals and The Environment, , Kaufmann, Los Altos; Takeno, J., Inaba, K., Suzuki, T., Experiments and examination of mirror image cognition using a small robot (2005) The 6th IEEE International Symposium On Computational Intelligence In Robotics and Automation (CIRA 2005), pp. 493-498. , http://ieeeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=1554325; Torrance, S., Could we, should we, create conscious robots? (2004) J Health Soc Econ Issues, 4 (2), pp. 43-46; Torrance, S., Ethics and consciousness in artificial agents (2008) Artif Intell Soc, 22 (4); Turing, A., Computing machinery and intelligence (1950) Mind Q Rev Psychol Philos LIX, (236), pp. 433-460; Veruggio, G., (2006) EURON Roboethics Roadmap, , http://www.roboethics.org/site/modules/tinycontent/index.php?id=14, Genoa, Scuola di Robotica},
document_type={Article},
source={Scopus},
}

@ARTICLE{Anderson2008477,
author={Anderson, S.L.},
title={Asimov's "Three Laws of Robotics" and machine metaethics},
journal={AI and Society},
year={2008},
volume={22},
number={4},
pages={477-493},
doi={10.1007/s00146-007-0094-5},
note={cited By 37},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-41549163350&doi=10.1007%2fs00146-007-0094-5&partnerID=40&md5=da313baaf58b9eb581934cf136a65f84},
abstract={Using Asimov's "Bicentennial Man" as a springboard, a number of metaethical issues concerning the emerging field of machine ethics are discussed. Although the ultimate goal of machine ethics is to create autonomous ethical machines, this presents a number of challenges. A good way to begin the task of making ethics computable is to create a program that enables a machine to act an ethical advisor to human beings. This project, unlike creating an autonomous ethical machine, will not require that we make a judgment about the ethical status of the machine itself, a judgment that will be particularly difficult to make. Finally, it is argued that Asimov's "three laws of robotics" are an unsatisfactory basis for machine ethics, regardless of the status of the machine. © Springer-Verlag London Limited 2007.},
keywords={Human being, Robotics, Philosophical aspects},
references={Anderson, S., Being morally responsible for an action versus acting responsibly or irresponsibly (1995) J Philos Res, 20, pp. 451-462; Anderson, M., Anderson, S., Armen, C., MedEthEx: Towards a medical ethics advisor (2005) Proceedings of the AAAI Fall Symposium on Caring Machines: AI and Eldercare, , In: Menlo Park. AAAI, California; Asimov, I., (1976) 'The Bicentennial Man' in I. Asimov, The Bicentennial Man and Other Stories, , Doubleday, New York, 1984; Asimov, I., Silverberg, R., (1992) The Positronic Man, , Doubleday, New York; Bentham, J., (1799) An Introduction to the Principles of Morals and Legislation, , chapter 17. Burns J, Hart H (eds). Clarendon Press, Oxford, 1969; Columbus, C., (1999) Bicentennial Man, , (Director) [movie based on Asimov and Silverberg (1993), The positronic man]. Columbia Tristar Pictures Distributors International; Kant, I., Our duties to animals (1780) Lectures on Ethics, pp. 239-241. , In: Infield L (trans.). Harper & Row, New York; Kant, I., (1785) The Groundwork of the Metaphysic of Morals, , Paton HJ (trans.). Barnes and Noble, New York, 1948; Machan, T., Do animals have rights? (1991) Public Affairs Q, 5 (2), pp. 163-173; McLaren, B.M., Extensionally defining principles and cases in ethics: An AI model (2003) Artif Intell, 150, pp. 145-181; Mill, J.S., (1863) Utilitarianism, , Parker, Son and Bourn, London; Ross, W.D., (1930) The Right and the Good, , Oxford University Press, Oxford; Singer, P., All animals are equal (1975) Animal Liberation: A New Ethics for Our Treatment of Animals New York, pp. 1-22. , In: New York review, Distributed by Random House; Tooley, M., Abortion and infanticide (1972) Philos Public Affairs, 2, pp. 47-66; Warren, M.A., On the moral and legal status of abortion (1997) Ethics in Practice, , In: LaFollette H (ed) Blackwell, Oxford},
document_type={Article},
source={Scopus},
}

@ARTICLE{Etzioni2017403,
author={Etzioni, A. and Etzioni, O.},
title={Incorporating Ethics into Artificial Intelligence},
journal={Journal of Ethics},
year={2017},
volume={21},
number={4},
pages={403-418},
doi={10.1007/s10892-017-9252-2},
note={cited By 36},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014561079&doi=10.1007%2fs10892-017-9252-2&partnerID=40&md5=d8c451dffac1a000134917ae3308b163},
abstract={This article reviews the reasons scholars hold that driverless cars and many other AI equipped machines must be able to make ethical decisions, and the difficulties this approach faces. It then shows that cars have no moral agency, and that the term ‘autonomous’, commonly applied to these machines, is misleading, and leads to invalid conclusions about the ways these machines can be kept ethical. The article’s most important claim is that a significant part of the challenge posed by AI-equipped machines can be addressed by the kind of ethical choices made by human beings for millennia. Ergo, there is little need to teach machines ethics even if this could be done in the first place. Finally, the article points out that it is a grievous error to draw on extreme outlier scenarios—such as the Trolley narratives—as a basis for conceptualizing the ethical issues at hand. © 2017, Springer Science+Business Media Dordrecht.},
author_keywords={Artificial intelligence;  Autonomy;  Ethics;  Self-driving cars;  Trolley problem},
references={Anderson, M., Anderson, S.L., (2011) Machine ethics, , eds), Cambridge University Press, Cambridge; Batavia, P.H., Pomerleau, D.A., Thorpe, C.E., (1996) Applying advanced learning algorithms to ALVINN, , http://www.ri.cmu.edu/pub_files/pub1/batavia_parag_1996_1/batavia_parag_1996_1.pdf, Carnegie Mellon University, The Robotics Institute; Benartzi, S., Thaler, R.H., Behavioral economics and the retirement savings crisis (2013) Science, 339, pp. 1152-1153; Beshears, J., Choi, J.J., Laibson, D., Madrian, B.C., The importance of default options for retirement saving outcomes: evidence from the United States (2009) Social security policy in a changing environment, pp. 167-195. , Wise David A, Liebman Jeffrey B, (eds), University of Chicago Press, Chicago; Bojarski, M., Testa, D.D., Dworakowski, D., Firner, B., Flepp, B., Goyal, P., Jackel, L.D., End to end learning for self-driving cars (2016) arXiv, , https://arxiv.org/abs/1604.07316; Bonnefon, J.-F., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2016) Science, 352, pp. 1573-1576; Constant, B., Des réactions politiques (1797) Oeuvres complètes, 1, pp. 1774-1799; Dmello, A., Rise of the humans: intelligence amplification will make us as smart as the machines (2015) The Conversation, , http://theconversation.com/rise-of-the-humans-intelligence-amplification-will-make-us-as-smart-as-the-machines-44767; Domingos, P., (2015) The master algorithm: How the quest for the ultimate learning machine will remake our world, , Basic Books, New York; Etzioni, A., Etzioni, O., AI assisted ethics (2016) Ethics and Information Technology, 18, pp. 149-156; Etzioni, A., Etzioni, O., Keeping AI legal (2016) Vanderbilt Journal of Entertainment and Technology Law, 19, pp. 133-146; Frankfurt, H.G., Alternate possibilities and moral responsibility (1969) The Journal of Philosophy, 66, pp. 829-839; Fried, B.H., What does matter? The case for killing the trolley problem (or letting it die) (2012) The Philosophical Quarterly, 62, pp. 505-529; Gibbs, S., (2015) What’s it like to drive with Tesla’s autopilot and how does it work? The Guardian, , https://www.theguardian.com/technology/2016/jul/01/tesla-autopilot-model-s-crash-how-does-it-work; Goodall, N., Ethical decision making during automated vehicle crashes (2014) Transportation research record: journal of the transportation research board, 2424, pp. 58-65; Harris, M., (2015) New pedestrian detector from Google could make self-driving cars cheaper, , http://spectrum.ieee.org/cars-that-think/transportation/self-driving/new-pedestrian-detector-from-google-could-make-selfdriving-cars-cheaper, IEEE Spectrum; Harris, S., (2011) The moral landscape: How science can determine human values, , Simon and Schuster, New York; Hsu, J., (2016) Deep learning makes driverless cars better at spotting pedestrians, , http://spectrum.ieee.org/cars-that-think/transportation/advanced-cars/deep-learning-makes-driverless-cars-better-at-spotting-pedestrians, IEEE Spectrum; Johnson, E.J., Goldstein, D., Do defaults save lives? (2003) Science, 302, pp. 1338-1339; Joy, B., (2000) Why the future doesn’t need us, , http://www.wired.com/2000/04/joy-2/, WIRED; Levin, S., Woolf, N., (2016) Tesla driver killed while using autopilot was watching Harry Potter, witness says, , https://www.theguardian.com/technology/2016/jul/01/tesla-driver-killed-autopilot-self-driving-car-harry-potter, The Guardian, and; Lohr, S., (2015) Homes try to reach smart switch, , http://www.nytimes.com/2015/04/23/business/energy-environment/homes-try-to-reach-smart-switch.html?_r=0, New York Times; Luban, D., Liberalism, torture, and the ticking bomb (2005) Virginia Law Review, 91, pp. 1425-1461; Lucas, G.R., Jr., Engineering, ethics and industry: the moral challenges of lethal autonomy (2013) Killing by remote control: the ethics of an unmanned military, pp. 211-228. , Strawser Bradley Jay, (ed), Oxford University Press, New York; Markoff, J., (2015) Machines of loving grace: the quest for common ground between humans and robots, , ECCO, New York; McDermott, D., What matters to a machine (2011) Machine ethics, pp. 88-114. , Anderson Michael, Anderson Susan Leigh, (eds), Cambridge University Press, Cambridge; Metz, C., (2016) Self-driving cars will teach themselves to save lives—but also take them, , http://www.wired.com/2016/06/self-driving-cars-will-power-kill-wont-conscience/, WIRED; Mill, J.S., (2008) On liberty and other essays, , Oxford University Press, Oxford; Millar, J., (2014) You should have a say in your robot car’s code of ethics, , http://www.wired.com/2014/09/set-the-ethics-robot-car/, WIRED; (2013) Traffic safety facts 2013: A compilation of motor vehicle crash data from the fatality analysis reporting system and the general estimates system, , https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812139, US Department of Transportation; O’Connor, J., The trolley method of moral philosophy (2012) Essays in Philosophy, 13, pp. 242-255; Rozenfield, M., (2016) The next step for artificial intelligence is machines that get smarter on their own, , http://theinstitute.ieee.org/technology-topics/artificial-intelligence/the-next-step-for-artificial-intelligence-is-machines-that-get-smarter-on-their-own, The Institute; Shah, R.C., Sandvig, C., Software defaults as de facto regulation the case of the wireless Internet (2008) Information, Community and Society, 11, pp. 25-46; Sharkey, A., Sharkey, N., Granny and the robots: ethical issues in robot care for the elderly (2012) Ethics and Information Technology, 14, pp. 27-40; Sharkey, N., Sharkey, A., The crying shame of robot nannies: an ethical appraisal (2010) Interaction Studies, 11, pp. 161-190; Spice, B., (2016) Carnegie Mellon transparency reports make AI decision-making accountable, , http://www.cs.cmu.edu/news/carnegie-mellon-transparency-reports-make-ai-decision-making-accountable, Carnegie Mellon Computer University School of Computer Science; Van Inwagen, P., Fischer on moral responsibility (1997) The Philosophical Quarterly, 47, pp. 373-381; Wallach, W., Allen, C., (2009) Moral machines: teaching robots right from wrong, , Oxford University Press, New York; Waymo, , https://waymo.com/journey/, Accessed 14 Feb 2017; Wood, A., (2007) Kantian ethics, , Cambridge University Press, Cambridge},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Andersora20061759,
author={Andersora, M. and Anderson, S.L. and Armera, C.},
title={MedEthEx: A prototype medical ethics advisor},
journal={Proceedings of the National Conference on Artificial Intelligence},
year={2006},
volume={2},
pages={1759-1765},
note={cited By 36},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750734653&partnerID=40&md5=901bd484e9409d6fe16ab4c6f8d68bf7},
abstract={As part of a larger Machine Ethics Project, we are developing an ethical advisor that provides guidance to health care workers faced with ethical dilemmas. MedEthEx is 'an implementation of Beauchamp's and Childress' Principles of Biomedical Ethics that harnesses machine learning techniques to abstract decision principles from cases in a particular type of dilemma with conflicting prima facie duties and uses these principles to determine the correct course of action in similar and new cases. We believe that accomplishing this will be a useful first step towards creating machines that can interact with those in need of health care in a way that is sensitive to ethical issues that may arise. Copyright © 2006, American Association for Artificial Intelligence (www.aaai.org). All rights reserved.},
keywords={Decision principles;  Medical ethics, Artificial intelligence;  Decision theory;  Learning systems;  Professional aspects, Health care},
references={Andersen, M., Andersen, S., Armen, C., Toward machine ethics: Implementing two action-based ethical theories (2005) Proceedings of the AAAI 2005 Fall Symposium on Machine Ethics, , Crystal City, VA; Andersen, M., Andersen, S., Armen, C., Toward machine ethics (2004) Proceedings of AAAI 2004 Workshop on Agent Organizations: Theory and Practice, , San Jose, CA; Andersen, S., We are our values (1999) Questioning Matters, p. 599. , Kolak, D. (ed.), Mayfield Publishing Company; Buchanan, A.E., Brock, D.W., (1989) Deciding for Others: The Ethics of Surrogate Decision Making, pp. 48-57. , Cambridge University Press; Bratko, I., Refining complete hypotheses in ILP (1999) Inductive Logic Programming, , LNAI 1634, Springer; Beauchamp, T.L., Childress, J.F., (1979) Principles of Biomedical Ethics, , Oxford University Press; Ford, K., Glymour, C., Hayes, P.J., (1991) Android Epistemology, , MIT Press; Lavrac, N., Dzeroski, S., (1997) Inductive Logic Programming: Techniques and Applications, , Ellis Harwood; Mappes, T.A., DeGrazia, D., (2001) Biomedical Ethics, 5 th Edtion, pp. 39-42. , McGraw-Hill, New York; McLaren, B.M., Extensionally defining principles and cases in ethics: An AI model (2003) Artificial Intelligence, 150, pp. 145-181. , November; Rawls, J., Outline for a decision procedure for ethics (1951) Philosophical Review, 60; Ross, W.D., (1930) The Right and the Good, , Clarendon Press, Oxford},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Wallach2010243,
author={Wallach, W.},
title={Robot minds and human ethics: The need for a comprehensive model of moral decision making},
journal={Ethics and Information Technology},
year={2010},
volume={12},
number={3},
pages={243-250},
doi={10.1007/s10676-010-9232-8},
note={cited By 35},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955559970&doi=10.1007%2fs10676-010-9232-8&partnerID=40&md5=8cbf8a8e61b162dbba0f00f5a82c2945},
abstract={Building artificial moral agents (AMAs) underscores the fragmentary character of presently available models of human ethical behavior. It is a distinctly different enterprise from either the attempt by moral philosophers to illuminate the "ought" of ethics or the research by cognitive scientists directed at revealing the mechanisms that influence moral psychology, and yet it draws on both. Philosophers and cognitive scientists have tended to stress the importance of particular cognitive mechanisms, e.g., reasoning, moral sentiments, heuristics, intuitions, or a moral grammar, in the making of moral decisions. However, assembling a system from the bottom-up which is capable of accommodating moral considerations draws attention to the importance of a much wider array of mechanisms in honing moral intelligence. Moral machines need not emulate human cognitive faculties in order to function satisfactorily in responding to morally significant situations. But working through methods for building AMAs will have a profound effect in deepening an appreciation for the many mechanisms that contribute to a moral acumen, and the manner in which these mechanisms work together. Building AMAs highlights the need for a comprehensive model of how humans arrive at satisfactory moral judgments. © 2010 Springer Science+Business Media B.V.},
author_keywords={Computers;  Decision making;  Emotions;  Machine ethics;  Moral agent;  Moral judgment;  Moral philosophy;  Moral psychology;  Robots;  Virtues},
keywords={Emotions;  Moral agents;  Moral judgment;  Moral philosophy;  Moral psychology;  Virtues, Computers;  Decision making;  Philosophical aspects;  Robots, Behavioral research},
references={Allen, C., Calculated morality: Ethical computing in the limit (2002) Cognitive, Emotive and Ethical Aspects of Decision Making and Human Action, Vol I, , I. Smit and G. Lasker (Eds.), Germany/Windsor, Ontario: Baden Baden/IIAS; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12, pp. 251-261; Anderson, M., Anderson, S., Machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 10-11; Anderson, M., Anderson, S., Armen, C., An approach to computing ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 56-63; Axelrod, R., Hamilton, W., The evolution of cooperation (1981) Science, 211, pp. 1390-1396; Danielson, P., (1992) Artificial Morality: Virtuous Robots for Virtual Games, , New York: Routledge; Darley, J., Batson, D., From Jerusalem to Jericho: A study of situational and dispositional variables in helping behavior (1973) Journal of Personality and Social Psychology, 27, pp. 100-108; de Waal, F., (1996) Good Natured: The Evolution of Right & Wrong in Humans and Other Animals, , Cambridge, MA: Harvard University Press; Franklin, S., IDA: A conscious artifact? (2003) Journal of Consciousness Studies, 10, pp. 47-66; Greenwald, A., Banaji, M., Implicit social cognition: Attitudes, self-esteem, and stereotypes (1995) Psychological Review, 102, pp. 4-27; Haidt, J., The emotional dog and its rational tail: A social intuitionist approach to moral judgment (2001) Psychological Review, 108 (4), pp. 814-834; Haidt, J., The moral emotions (2003) Handbook of Affective Sciences, pp. 852-870. , R. J. Davidson, K. R. Scherer, and H. H. Goldsmith (Eds.), Oxford: Oxford University Press; Hamilton, W., The general evolution of social behavior I (1964) Journal of Theoretical Biology, 7, pp. 1-16; Hamilton, W., The general evolution of social behavior II (1964) Journal of Theoretical Biology, 7, pp. 17-52; Hauser, M., (2006) Moral Minds: How Nature Designed Our Universal Sense of Right and Wrong, , New York: Ecco; Isen, A., Levin, P.F., Effect of feeling good on helping: Cookies and kindness (1972) Journal of Personality and Social Psychology, 21, pp. 384-388; Kohlberg, L., (1981) Essays on Moral Development, Vol. I: The Philosophy of Moral Development, , San Francisco: Harper & Row; Kohlberg, L., (1984) Essays on Moral Development, Vol 2: The Psychology of Moral Development, , San Francisco: Harper & Row; (2004) Moral Development, Self, and Identity, , D. Lapsley and D. Narvaez (Eds.), Mahwah, New Jersey: Lawrence Erlbaum Associates; Miller, G., The magical number seven, plus or minus two: Some limits on our capacity for processing information (1956) The Psychological Review, 63 (2), pp. 81-97; Nucci, L., Narvaez, D., (2008) Handbook of Moral and Character Education, , New York: Routledge; Piaget, J., (1972) Judgment and Reasoning in the Child, , Totowa, NJ: Littlefield, Adams and Company; Searle, J., Minds, brains, and programs (1980) Behavioral and Brain Sciences, 3 (3), pp. 417-458; Simon, H., (1957) A Behavioral Model of Rational Choice, in Models of Man, Social and Rational: Mathematical Essays on Rational Human Behavior in a Social Setting, , New York: Wiley; Simon, H., (1982) Models of Bounded Rationality, Vols. 1 and 2, , Cambridge, MA: MIT Press; Singer, P., (1990) Animal Liberation, , New York: New York Review Books; Torrance, S., Ethics and consciousness in artificial agents (2008) Artificial Intelligence and Society, 22 (4), p. 34; Tversky, A., Kahneman, D., Judgment under uncertainty: Heuristics and biases (1974) Science, 185, pp. 1124-1131; (1989) Unintended Thought, , J. Uleman and J. Bargh (Eds.), New York: Guilford; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , New York: Oxford University Press; Wallach, W., Allen, C., Smit, I., Machine morality: Bottom-up and top-down approaches for modelling human moral faculties (2008) AI and Society, 22 (4), pp. 565-582; Wilson, E., (1975) Sociobiology: The New Synthesis, , Cambridge, MA: Harvard University Press; Yudkowsky, E., (2001) What is Friendly AI?, , http://singinst.org/ourresearch/publications/what-is-friendly-ai.html, Available online at},
document_type={Article},
source={Scopus},
}

@ARTICLE{Winfield2018,
author={Winfield, A.F.T. and Jirotka, M.},
title={Ethical governance is essential to building trust in robotics and artificial intelligence systems},
journal={Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
year={2018},
volume={376},
number={2133},
doi={10.1098/rsta.2018.0085},
art_number={0085},
note={cited By 34},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055077256&doi=10.1098%2frsta.2018.0085&partnerID=40&md5=aef519d16033220c75f39dcec0a0252a},
abstract={This paper explores the question of ethical governance for robotics and artificial intelligence (AI) systems. We outline a roadmap-which links a number of elements, including ethics, standards, regulation, responsible research and innovation, and public engagement-as a framework to guide ethical governance in robotics and AI. We argue that ethical governance is essential to building public trust in robotics and AI, and conclude by proposing five pillars of good ethical governance. This article is part of the theme issue 'Governing artificial intelligence: ethical, legal, and technical opportunities and challenges'. © 2018 The Author(s) Published by the Royal Society. All rights reserved.},
author_keywords={Artificial intelligence ethics;  Governance;  Responsible innovation;  Robot ethics;  Standards;  Trust},
keywords={Artificial intelligence;  Intelligent robots;  Robotics;  Standards, Artificial intelligence systems;  Governance;  Public engagement;  Public trust;  Roadmap;  Robot ethics;  Trust, Philosophical aspects},
references={(2012) Public Attitudes Towards Robots, , http://ec.europa.eu/COMMFrontOffice/PublicOpinion/index.cfm/ResultDoc/download/DocumentKy/56814, European Commission, Special Eurobarometer 382, September 2012; (2015) Autonomous Systems, , http://ec.europa.eu/public_opinion/archives/ebs/ebs_427_en.pdf, European Commission, Special Eurobarometer 427, June 2015; Brynjolfsson, E., McAfee, A., (2014) The Second Machine Age: Work, Progress, and Prosperity in A Time of Brilliant Technologies, , Cambridge, MA: MIT Press; Robinette, P., Wagner, A.R., Howard, A.M., Building and maintaining trust between humans and guidance robots in an emergency (2013) Trust and Autonomous Systems: 2013 AAAI Spring Symp., Stanford, CA, 25-27 March, pp. 78-83. , https://www.aaai.org/ocs/index.php/SSS/SSS13/paper/download/5755/6007, Palo Alto, CA: AAAI Press; (2016) Robotics and Artificial Intelligence, , http://www.publications.parliament.uk/pa/cm201617/cmselect/cmsctech/145/145.pdf, House of Commons, Science and Technology Committee, HC 145; Mulgan, G., (2016) A Machine Intelligence Commission for the UK: How to Grow Informed Public Trust and Maximise the Positive Impact of Smart Machines, , https://www.nesta.org.uk/documents/692/a_machine_intelligence_commission_for_the_uk_-_geoff_mulgan.pdf, February 2016. London, UK: Nesta; Rainey, S., Goujon, P., Toward a normative ethical governance of technology. Contextual pragmatism and ethical governance (2011) Towards Responsible Research and Innovation in the Information and Communication Technologies and Security Technologies Fields, , http://dx.doi.org/10.2139/ssrn.2436399, ed. R von Schomberg. Report of the European Commission, DG Research and Innovation; Eden, G., Jirotka, M., Stahl, B., Responsible research and innovation: Critical reflection into the potential social consequences of ICT (2013) Proc. IEEE 7th Int. Conf. on Research Challenges in Information Science (RCIS 2013) Paris, France, 29-31 May, 12p. , New York, NY: IEEE; Broekaert, K., Espinel, V.A., (2018) How Can Policy Keep Pace with the Fourth Industrial Revolution?, , https://www.weforum.org/agenda/2018/02/can-policy-keep-pace-withfourth-industrial-revolution/; Schwab, K., (2017) The Fourth Industrial Revolution, , New York, NY: Portfolio Penguin; (2018) Agile Governance: Reimagining Policy-making in the Fourth Industrial Revolution, , http://www3.weforum.org/docs/WEF_Agile_Governance_Reimagining_Policy-making_4IR_report.pdf, World Economic Forum. White paper; (2013) Robots and Robotic Devices: Safety Requirements for Personal Care Robots, , http://www.iso.org/iso/catalogue_detail.htm?csnumber=53820, International Standards Organisation ISO 13482:2013; Veruggio, G., (2006) EURON Roboethics Roadmap, , http://www.roboethics.org/atelier2006/docs/ROBOETHICS%20ROADMAP%20Rel2.1.1.pdf; Boden, M., Principles of robotics (2017) Connect. Sci., 29, pp. 124-129; Winfield, A.F., (2017) A Round Up of Robotics and AI Ethics: Part 1 Principles, , http://alanwinfield.blogspot.com/2017/12/a-round-up-of-robotics-and-ai-ethics.html; Murphy, R., Woods, D.D., Beyond Asimov: The three laws of responsible robotics (2009) IEEE Intell. Syst., 24, pp. 14-20; (2017) Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems, Version 2, , https://ethicsinaction.ieee.org/, IEEE, IEEE Standards Association; (2016) Robots and Robotic Devices: Guide to the Ethical Design and Application of Robots and Robotic Systems, , British Standards Institution BS 8611:2016. London, UK: BSI; Stilgoe, J., Owen, R., Macnaghten, P., Developing a framework for responsible innovation (2013) Res. Policy, 42, pp. 1568-1580; Grand, A., Wilkinson, C., Bultitude, K., Winfield, A.F., Open science: A new 'trust technology'? (2012) Sci. Commun., 34, pp. 679-689; Dillmann, R., (2004) Benchmarks for Robotics Research. EURON, , https://www.researchgate.net/publication/250861011_KA_110_Benchmarks_for_Robotics_Research; Italian presidency of the council of the European union (2014) Rome Declaration on Responsible Research and Innovation in Europe, , http://ec.europa.eu/newsroom/dae/document.cfm?doc_id=8196; (2016) Framework for Responsible Innovation, , https://www.epsrc.ac.uk/research/framework/, EPSRC. AREA framework; Van Wynsberghe, A., Sharkey, N., (2016) Foundation for Responsible Robotics, , http://responsiblerobotics.org/; Grimpe, B., Hartswood, M., Jirotka, M., Towards a closer dialogue between policy and practice: Responsible design in HCI (2014) Proc. SIGHCI Conf. On Human Factors in Computing Systems Toronto, Canada, 26 April-1 May, pp. 2965-2974. , New York, NY: ACM; Jirotka, M., Grimpe, B., Stahl, B., Eden, G., Hartswood, M., Responsible research and innovation in the digital age (2017) Commun ACM, 60, pp. 62-68; Winfield, A.F.T., Jirotka, M., The case for an ethical black box (2017) Towards Autonomous Robotic Systems, pp. 262-273. , eds Y Gao, S Fallah, Y Jin, C Lekakou. Lecture Notes in Artificial Intelligence 10454. Cham, Switzerland: Springer; Wilsdon, J., Willis, R., (2004) See-through Science: Why Public Engagement Needs to Move Upstream, , Project Report. London, UK: Demos; Wilkinson, C., Weitkamp, E., (2016) Creative Research Communication: Theory and Practice, , Manchester, UK: Manchester University Press; Bonnefon, J.-F., Shariff, A., Rahwam, I., The social dilemma of autonomous vehicles (2016) Science, 352, pp. 1573-1576; Billings, D.R., Schaefer, K.E., Chen, J.Y.C., Hancock, P.A., Human-robot interaction: Developing trust in robots (2012) Proc. 7th Annual ACM/IEEE Int. Conf. on Human-Robot Interaction Boston, MA, 5-8 March, pp. 109-110. , New York, NY: ACM; Coeckelbergh, M., Can we trust robots? (2012) Ethics Inf. Technol., 14, pp. 53-60; Harper, R.H.R., (2014) Trust, Computing, and Society, , Cambridge, UK: Cambridge University Press; Koene, A., Perez, E., Carter, C.J., Statache, R., Adolphs, S., O'Malley, C., Rodden, T., McAuley, D., Research ethics and public trust, preconditions for continued growth of internet mediated research (2015) Int. Conf. on Information Systems Security and Privacy (ICISSP 2015), Angers, France, 9-11 February, pp. 163-168. , https://www.computer.org/csdl/proceedings/icissp/2015/135/00/07509947-abs.html, New York, NY: IEEE Computer Society; (2016) The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems, , http://standards.ieee.org/develop/indconn/ec/autonomous_systems.html, IEEE Standards Association; Bryson, J., Winfield, A., Standardizing ethical design for artificial intelligence and autonomous systems (2017) IEEE Comput., 50, pp. 116-119; Palmerini, E., (2014) D6.2-Guidelines on Regulating Robotics, , http://www.robolaw.eu/RoboLaw_files/documents/robolaw_d6.2_guidelinesregulatingrobotics_20140922.pdf, RoboLaw project; Winfield, A.F., (2012) Robotics: A Very Short Introduction, , Oxford, UK: Oxford University Press; Webster, M., Dixon, C., Fisher, M., Salem, M., Saunders, J., Koay, K.-L., Dautenhahn, K., Saez-Pons, J., Toward reliable autonomous robotic assistants through formal verification: A case study (2016) IEEE Trans. Human-Mach. Syst., 46, pp. 186-196; Campolo, A., Sanfilippo, M., Whittaker, M., Crawford, K., (2017) AI Now 2017 Report, , https://ainowinstitute.org/AI_Now_2017_Report.pdf, New York, NY: AI Now Institute, New York University; Theodorou, A., Wortham, R.H., Bryson, J.J., Designing and implementing transparency for real time inspection of autonomous robots (2017) Connect. Sci., 29, pp. 230-241; Wortham, R.H., Theodorou, A., Robot transparency, trust and utility (2017) Connect. Sci., 29, pp. 242-248; Edwards, L., Veale, M., Slave to the algorithm?Why a 'right to an explanation' is probably not the remedy you are looking for (2017) Duke Law Technol. Rev., 16, p. 18; Wachter, S., Mittelstadt, B., Russell, C., Counterfactual explanations without opening the black box: Automated decisions and the GDPR (2018) Harvard J. Law Technol., 31 (2); Ananny, M., Crawford, K., Seeing without knowing: Limitations of the transparency ideal and its application to algorithmic accountability (2016) New Media Soc., 20, pp. 973-989; Stilgoe, J., Machine learning, social learning and the governance of self-driving cars (2018) Social Stud. Sci., 48, pp. 25-56; Stilgoe, J., Winfield, A.F., Self-driving car companies should not be allowed to investigate their own crashes (2018) The Guardian, , 13 April 2018; (2017) P7001 Transparency of Autonomous Systems, , https://standards.ieee.org/develop/project/7001.html, IEEE Standards Association; Caliskan-Islam, A., Bryson, J., Narayanan, A., Semantics derived automatically from language corpora contain human-like biases (2017) Science, 356, pp. 183-186; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intell. Syst., 21, pp. 18-21; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intell. Syst., 21, pp. 38-44; Fisher, M., List, C., Slavkovik, M., Winfield, A.F., Engineering moral machines. Forum/Dagstuhl Manifesto (2016) Informatik-Spektrum, 39 (6), pp. 467-472; Malle, B.F., Integrating robot ethics and machine morality: The study and design of moral competence in robots (2016) Ethics Inf. Technol., 18, pp. 243-256; Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics Inf. Technol., 7, pp. 149-155; Anderson, M., Anderson, S.L., GenEth: A general ethical dilemma analyzer (2014) Proc. 28th AAAI Conf. on Artificial Intelligence, Quebec, Canada, 27-31 July, pp. 253-261. , https://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/view/8308/8428, Palo Alto, CA: AAAI Press; Arkin, R.C., Ulam, P., Wagner, A.R., Moral decision making in autonomous systems: Enforcement, moral emotions, dignity, trust, and deception (2012) Proc. IEEE, 100, pp. 571-589; Winfield, A.F., Blum, C., Liu, W., Towards an ethical robot: Internal models, consequences and ethical action selection (2014) Advances in Autonomous Robotics Systems. Lecture Notes in Artificial Intelligence, 8717, pp. 85-96. , eds M Mistry, A Leonardis, M Witkowski, C Melhuish. Cham, Switzerland: Springer; Dennis, L.A., Fisher, M., Slavkovik, M., Webster, M., Formal verification of ethical choices in autonomous systems (2016) Rob. Auton. Syst., 77, pp. 1-14; Vanderelst, D., Winfield, A.F., The dark side of ethical robots (2018) Proc. AAAI/ ACM Conf. on Artificial Intelligence, Ethics and Society, , http://www.aies-conference.com/wp-content/papers/main/AIES_2018_paper_98.pdf, New Orleans; (2018) ACM Code of Ethics and Professional Conduct, , https://www.acm.org/code-of-ethics, ACM. 2018 ACM; Boddington, P., (2017) Towards A Code of Ethics for Artificial Intelligence, , Cham, Switzerland: Springer; O'Donovan, C., Google employees are organizing to protest the company's secret, censored search engine for China (2018) BuzzFeed News, , https://www.buzzfeednews.com/article/carolineodonovan/google-dragonfly-maven-employee-protestdemands, 16 August 2018},
document_type={Article},
source={Scopus},
}

@ARTICLE{Yampolskiy2013389,
author={Yampolskiy, R.V.},
title={Artificial intelligence safety engineering: Why machine ethics is a wrong approach},
journal={Studies in Applied Philosophy, Epistemology and Rational Ethics},
year={2013},
volume={5},
pages={389-396},
doi={10.1007/978-3-642-31674-6_29},
note={cited By 34},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903298299&doi=10.1007%2f978-3-642-31674-6_29&partnerID=40&md5=7a766efc3e57f6129eceff156bf824db},
abstract={Machine ethics and robot rights are quickly becoming hot topics in artificial intelligence/robotics communities. We will argue that the attempts to allow machines to make ethical decisions or to have rights are misguided. Instead we propose a new science of safety engineering for intelligent artificial agents. In particular we issue a challenge to the scientific community to develop intelligent systems capable of proving that they are in fact safe even under recursive selfimprovement. © Springer-Verlag Berlin Heidelberg 2013.},
author_keywords={AI confinement;  Machine ethics;  Robot rights},
references={Ajina, S., Yampolskiy, R.V., Amara, N.E.B., SVM Classification of Avatar Facial Recognition (2011) 8Th International Symposium on Neural Networks (ISNN2011), , Guilin, China, May 29- June 1; Ali, N., Hindi, M., Yampolskiy, R.V., Evaluation of Authorship Attribution Software on a Chat Bot Corpus (2011) 23Rd International Symposium on Information, Communication and Automation Technologies (ICAT2011), , Sarajevo, Bosnia and Herzegovina, October 27-29; Allen, C., Smit, I., Wallach, W., Artificial Morality: Top-down. Bottom-up, and Hybrid Approaches Ethics and Information Technology, 7 (3); Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12, pp. 251-261; Allen, C., Wallach, W., Smit, I., Why Machine Ethics? (2006) IEEE Intelligent Systems, 21 (4), pp. 12-17; Erson, M., Erson, S.L., Machine Ethics: Creating an Ethical Intelligent Agent (2007) AI Magazine, 28 (4), pp. 15-26; (2011), http://singinst.org/riskintro/index.html, Reducing Long-term Catastrophic Risks from Artificial Intelligence The Singularity Institute for Artificial Intelligence; Bishop, M., Why Computers Can’t Feel Pain (2009) Minds and Machines, 19 (4), pp. 507-516; Bostrom, N., (2008), http://lesswrong.com/lw/qv/the_rhythm_of_disagreement/, Oracle AI; Bouhhris, M., Beck, M., Mahamed, A., Amara, N.E.B., D’Souza, D., Yampolskiy, R.V., Artificial Human-Face Recognition via Daubechies Wavelet Transform and SVM (2011) 16Th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational & Serious Games, pp. 18-25. , Louisville, KY, USA, July 27 - 30; Butler, S., (1863) Darwin among the Machines, , To the Editor of Press, Christchurch, New Zealand, June 13; Chalmers, D., The Singularity: A Philosophical Analysis (2010) Journal of Consciousness Studies, 17, pp. 7-65; Dennett, D.C., Why You Can’t Make a Computer That Feels Pain (1978) Synthese, 38 (3), pp. 415-456; Drexler, E., (1986) Engines of Creation, , Anchor Press; Epstein, R.G., (1997), http://www.cs.wcupa.edu/~epstein/comppsy.htm, Computer Psychologists Command Big Bucks; Gavrilova, M., Yampolskiy, R., Applying Biometric Principles to Avatar Recognition (2010) International Conference on Cyberworlds (CW 2010), , Singapore, October 20-22; Gordon-Spears, D., Assuring the behavior of adaptive agents (2004) Agent Technology from a Formal Perspective, pp. 227-259. , Rouff, C.A., et al. (eds.), Kluwer; Gordon-Spears, D.F., Asimov’s Laws: Current Progress (2003) FAABS 2002. LNCS (LNAI), 2699, pp. 257-259. , Hinchey, M.G., Rash, J.L., Truszkowski, W.F., Rouff, C.A., Gordon-Spears, D.F. (eds.), Springer, Heidelberg; Gordon, D.F., Well-Behaved Borgs, Bolos, and Berserkers (1998) 15Th International Conference on Machine Learning (ICML 1998), , San Francisco, CA; Grau, C., There Is No “I” in “Robot”: Robots and Utilitarianism (2006) IEEE Intelligent Systems, 21 (4), pp. 52-55; Guo, S., Zhang, G., Robot Rights (2009) Science, 323, p. 876; Hall, J.S., (2000) Ethics for Machines, , http://autogeny.org/ethics.html; Hall, J.S., Self-Improving AI: An Analysis (2007) Minds and Machines, 17 (3), pp. 249-259; Hanson, R., (2009) Prefer Law to Values, , http://www.overcomingbias.com/2009/10/prefer-law-to-values.html, October 10; Joy, B., Why the Future Doesn’t Need Us (2000) Wired Magazine, 8 (4). , April; Kaczynski, T., Industrial Society and Its Future (1995) The New York Times, , (September 19; Lin, P., Abney, K., Bekey, G., Robot Ethics: Mapping the Issues for a Mechanized World (2011) Artificial Intelligence; Margaret, A., Henry, J., Computer Ethics: The Role of Personal, Informal, and Formal Codes Journal of Business Ethics, 15 (4), p. 425; McDermott, D., Why Ethics is a High Hurdle for AI (2008) In: North American Conference on Computers and Philosophy (NACAP 2008), , http://cs-www.cs.yale.edu/homes/dvm/papers/ethical-machine.pdf, Bloomington, Indiana (July; Mohamed, A., Baili, N., D’Souza, D., Yampolskiy, R.V., Avatar Face Recognition Using Wavelet Transform and Hierarchical Multi-scale LBP (2011) The Tenth International Conference on Machine Learning and Applications (ICMLA 2011), , Honolulu, USA, December 18-21; Mohamed, A., Yampolskiy, R.V., An Improved LBP Algorithm for Avatar Face Recognition (2011) 23Rd International Symposium on Information, Communication and Automation Technologies (ICAT 2011), pp. 27-29. , Sarajevo, Bosnia and Herzegovina; Moor, J.H., The Nature, Importance, and Difficulty of Machine Ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Powers, T.M., Prospects for a Kantian Machine (2006) IEEE Intelligent Systems, 21 (4), pp. 46-51; Rappaport, Z.H., Robotics and artificial intelligence: Jewish ethical perspectives (2006) Acta Neurochir, 98, pp. 9-12; Roh, D., (2009), http://www.wired.com/culture/culturereviews/magazine/17-02/st_essay, Do Humanlike Machines Deserve Human Rights? Wired (January 19; Ruvinsky, A.I., Computational Ethics (2007) Encyclopedia of Information Ethics and Security, pp. 76-73. , Quigley, M. (ed.); Sawyer, R.J., (2007) Robot Ethics. Science, 318, p. 1037; Sharkey, N., The Ethical Frontiers of Robotics (2008) Science, 322, pp. 1800-1801; Sparrow, R., Killer Robots (2007) Journal of Applied Philosophy, 24 (1), pp. 62-77; Tonkens, R., A Challenge for Machine Ethics (2009) Minds & Machines, 19 (3), pp. 421-438; Veruggio, G., Roboethics (2010) IEEE Robotics & Automation Magazine, 17 (2); Wallach, W., Allen, C., EthicALife: A new field of inquiry (2006) Analifex Workshop, , USA; Warwick, K., Cyborg Morals, Cyborg Values, Cyborg Ethics (2003) Ethics and Information Technology, 5, pp. 131-137; Wendell, W., Colin, A., (2008) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press; Yampolskiy, R.V., Behavioral Biometrics for Verification and Recognition of AI Programs (2007) 20Th Annual Computer Science and Engineering Graduate Conference, , (GradConf 2007), Buffalo, NY; Yampolskiy, R.V., Leakproofing Singularity - Artificial Intelligence Confinement Problem (2012) Journal of Consciousness Studies (JCS), 19 (1-2); Yampolskiy, R.V., Cho, G., Rosenthal, R., Gavrilova, M.L., Evaluation of Face Detection and Recognition Algorithms on Avatar Face Datasets (2011) International Conference on Cyberworlds (CW 2011), , Banff, Alberta, Canada, October 4-6; Yampolskiy, R.V., Govindaraju, V., Behavioral Biometrics for Recognition and Verification of Game Bots (2007) The 8Th Annual European Game-On Conference on Simulation and AI in Computer Games (GAMEON 2007), , Bologna, Italy, November 20- 22; Yampolskiy, R.V., Govindaraju, V., Behavioral Biometrics for Verification and Recognition of Malicious Software Agents, Sensors, and Command, Control, Communications, and Intelligence (C3I) Technologies for Homeland Security and Homeland Defense VII (2008) SPIE Defense and Security Symposium, , Orlando, Florida, March 16-20},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Gunkel2014113,
author={Gunkel, D.J.},
title={A vindication of the rights of machines},
journal={Philosophy and Technology},
year={2014},
volume={27},
number={1},
pages={113-132},
doi={10.1007/s13347-013-0121-z},
note={cited By 33},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899485037&doi=10.1007%2fs13347-013-0121-z&partnerID=40&md5=9d501378a0bcb612d3691690f59d6216},
abstract={This essay responds to the machine question in the affirmative, arguing that artifacts, like robots, AI, and other autonomous systems, can no longer be legitimately excluded from moral consideration. The demonstration of this thesis proceeds in four parts or movements. The first and second parts approach the subject by investigating the two constitutive components of the ethical relationship - moral agency and patiency. In the process, they each demonstrate failure. This occurs not because the machine is somehow unable to achieve what is considered necessary and sufficient to be a moral agent or patient but because the characterization of agency and patiency already fail to accommodate others. The third and fourth parts respond to this problem by considering two recent alternatives - the all-encompassing ontocentric approach of Luciano Floridi's information ethics and Emmanuel Levinas's eccentric ethics of otherness. Both alternatives, despite considerable promise to reconfigure the scope ofmoral thinking by addressing previously excluded others, like the machine, also fail but for other reasons. Consequently, the essay concludes not by accommodating the alterity of the machine to the requirements of moral philosophy but by questioning the systemic limitations of moral reasoning, requiring not just an extension of rights to machines, but a thorough examination of the way moral standing has been configured in the first place.},
author_keywords={Animal ethics;  Artificial intelligence;  Ethics;  Information ethics;  Machine ethics},
references={Anderson, S., Asimovs three laws of robotics and machine metaethics (2008) AI & Society, 22 (4), pp. 477-493; Atterton, P., Calarco, M., (2010) Radicalizing Levinas, , Albany, NY: SUNY Press; Bates, J., The role of emotion in believable agents (1994) Communications of the ACM, 37, pp. 122-125; Benford, G., Malartre, E., (2007) Beyond Human: Living with Robots and Cyborgs, , New York: Tom Doherty; Benso, S., (2000) The Face of Things: A Different Side of Ethics, , Albany, NY: SUNY Press; Bentham, J., (2005) An Introduction to the Principles of Morals and Legislation, , J. H. Burns and H. L. Hart (Eds.) Oxford: Oxford University Press; Birch, T., Moral considerability and universal consideration (1993) Environmental Ethics, 15, pp. 313-332; Birch, T., The incarnation of wilderness: Wilderness areas as prisons (1995) Postmodern Environmental Ethics, pp. 137-162. , M. Oelschlaeger (Ed.) Albany, NY: State University of New York Press; Blumberg, B., Todd, P., Maes, M., No bad dogs: Ethological lessons for learning (1996) Proceedings of the 4th International Conference on Simulation of Adaptive Behavior, pp. 295-304. , Cambridge, MA: MIT Press; Breazeal, C., Brooks, R., Robot emotion: A functional perspective (2004) Who Needs Emotions: The Brain Meets the Robot, pp. 271-310. , J M. Fellous & M. Arbib (Eds.), Oxford: Oxford University Press; Calarco, M., (2008) Zoographies: The Question of the Animal from Heidegger to Derrida, , New York: Columbia University Press; Churchland, P.M., (1999) Matter and Consciousness, , Cambridge, MA: MIT Press; Coeckelbergh, M., (2012) Growing Moral Relations: Critique of Moral Status Ascription, , New York: Palgrave Macmillan; Cohen, R.A., (2001) Ethics, Exegesis and Philosophy: Interpretation after Levinas, , Cambridge: Cambridge University Press; Dawkins, M.S., The science of animal suffering (2008) Ethology, 114 (10), pp. 937-945; Dennett, D., (1998) Brainstorms: Philosophical Essays on Mind and Psychology, , Cambridge, MA: MIT Press; Dennett, D., (1996) Kinds of Minds: Toward An Understanding of Consciousness, , New York: Basic Books; Derrida, J., (1978) Writing and Difference, , Trans. by Alan Bass. Chicago: University of Chicago Press; Derrida, J., (2005) Paper Machine, , Trans. by Rachel Bowlby. Stanford, CA: Stanford University Press; Derrida, J., (2008) The Animal That Therefore i Am, , Trans. by DavidWills. New York: Fordham University Press; Descartes, R., (1988) Selected Philosophical Writings, , Trans. by J. Cottingham, R. Stoothoff, and D. Murdoch. Cambridge: Cambridge University Press; Ess, C., The political computer: Democracy, cmc, and habermas (1996) Philosophical Perspectives on Computer-Mediated Communication, pp. 196-230. , C. Ess (Ed.) Albany, NY: SUNY Press; Floridi, L., Information ethics: On the philosophical foundation of computer ethics (1999) Ethics and Information Technology, 1 (1), pp. 37-56; Floridi, L., On the intrinsic value of information objects and the infosphere (2002) Ethics and Information Technology, 4, pp. 287-304; Floridi, L., Information ethics, its nature and scope (2008) Information Technology and Moral Philosophy, pp. 40-65. , J. van den Hoven & J. Weckert (Eds.) Cambridge: Cambridge University Press; Floridi, L., (2013) The Ethics of Information, , Oxford: Oxford University Press; French, P., The corporation as a moral person (1979) American Philosophical Quarterly, 16 (3), pp. 207-215; Gunkel, D.J., (2007) Thinking Otherwise: Philosophy, Communication, Technology, , West Lafayette, IN: Purdue University Press; Gunkel, D.J., (2012) The Machine Question: Critical Perspectives on AI, Robots and Ethics, , Cambridge, MA: MIT Press; Güzeldere, G., The many faces of consciousness: A field guide (1997) The Nature of Consciousness: Philosophical Debates, pp. 1-68. , N. Block, O. Flanagan, & G. Güzeldere (Eds.) Cambridge, MA: MIT Press; Hajdin, M., (1994) The Boundaries of Moral Discourse, , Chicago: Loyola University Press; Heidegger, M., (1962) Being and Time, , Trans. by J. Macquarrie and E. Robinson. New York: Harper and Row Publishers; Himma, K.E., Theres something about mary: The moral value of things qua information objects (2004) Ethics and Information Technology, 6 (3), pp. 145-195; Himma, K.E., Artificial agency (2009) Consciousness, and the Criteria for Moral Agency: What Properties Must An Artificial Agent Have to Be A Moral Agent? Ethics and Information Technology, 11 (1), pp. 19-29; (2009), http://www.kokoro-dreams.co.jp; Kurzweil, R., (2005) The Singularity Is Near: When Humans Transcend Biology, , New York: Viking; Levinas, E., (1969) Totality and Infinity: An Essay on Exteriority, , Trans. by A. Lingis. Pittsburgh, PA: Duquesne University Press; Levinas, E., (1981) Otherwise Than Being or beyond Essence, , Trans. by Alphonso Lingis. Hague: Martinus Nijhoff Publishers; Levinas, E., (1987) Collected Philosophical Papers, , Trans. by A. Lingis. Dordrecht: Martinus Nijhoff Publishers; Levinas, E., (2003) Humanism of the Other, , Trans. by Nidra Poller. Urbana: University of Illinois Press; Llewelyn, J., (1995) Emmanuel Levinas: The Genealogy of Ethics, , London: Routledge; Locke, J., (1996) An Essay Concerning Human Understanding, , Indianapolis, IN: Hackett; Mauss, M., A category of the human mind: The notion of person; The notion of self (1985) The Category of the Person, pp. 1-25. , Trans. by W. D. Halls M. Carrithers, S. Collins, and S. Lukes (Eds.) Cambridge: Cambridge University Press; Nealon, J., (1998) Alterity Politics: Ethics and Performative Subjectivity, , Durham, NC: Duke University Press; Nietzsche, F., (1974) The Gay Science, , Trans. by W. Kaufmann. New York: Vintage Books; Scott, G.E., (1990) Moral Personhood: An Essay in the Philosophy of Moral Psychology, , Albany, NY: SUNY Press; Scott, R.L., On viewing rhetoric as epistemic (1967) Central States Speech Journal, 18, pp. 9-17; Singer, P., (1975) Animal Liberation: A New Ethics for Our Treatment of Animals, , New York: New York Review of Books; Singer, P., All animals are equal (1989) Animal Rights and Human Obligations, pp. 148-162. , T. Regan & P. Singer (Eds.) New York: Prentice Hall; Singer, P., (1999) Practical Ethics, , Cambridge: Cambridge University Press; Smith, C., (2010) What Is A Person? Rethinking Humanity, Social Life, and the Moral Good from the Person Up, , Chicago: University of Chicago Press; Torrence, S., Ethics and consciousness in artificial agents (2008) AI & Society, 22, pp. 495-521; Velmans, M., (2000) Understanding Consciousness, , New York: Routledge; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford: Oxford University Press; Žižek, S., (2006) The Parallax View, , Cambridge, MA: MIT Press},
document_type={Article},
source={Scopus},
}

@ARTICLE{DodigCrnkovic201261,
author={Dodig Crnkovic, G. and Çürüklü, B.},
title={Robots: Ethical by design},
journal={Ethics and Information Technology},
year={2012},
volume={14},
number={1},
pages={61-71},
doi={10.1007/s10676-011-9278-2},
note={cited By 30},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860417495&doi=10.1007%2fs10676-011-9278-2&partnerID=40&md5=157f0e5b0bd47fa7f894e55ab3ef3417},
abstract={Among ethicists and engineers within robotics there is an ongoing discussion as to whether ethical robots are possible or even desirable. We answer both of these questions in the positive, based on an extensive literature study of existing arguments. Our contribution consists in bringing together and reinterpreting pieces of information from a variety of sources. One of the conclusions drawn is that artifactual morality must come in degrees and depend on the level of agency, autonomy and intelligence of the machine. Moral concerns for agents such as intelligent search machines are relatively simple, while highly intelligent and autonomous artifacts with significant impact and complex modes of agency must be equipped with more advanced ethical capabilities. Systems like cognitive robots are being developed that are expected to become part of our everyday lives in future decades. Thus, it is necessary to ensure that their behaviour is adequate. In an analogy with artificial intelligence, which is the ability of a machine to perform activities that would require intelligence in humans, artificial morality is considered to be the ability of a machine to perform activities that would require morality in humans. The capacity for artificial (artifactual) morality, such as artifactual agency, artifactual responsibility, artificial intentions, artificial (synthetic) emotions, etc., come in varying degrees and depend on the type of agent. As an illustration, we address the assurance of safety in modern High Reliability Organizations through responsibility distribution. In the same way that the concept of agency is generalized in the case of artificial agents, the concept of moral agency, including responsibility, is generalized too. We propose to look at artificial moral agents as having functional responsibilities within a network of distributed responsibilities in a socio-technological system. This does not take away the responsibilities of the other stakeholders in the system, but facilitates an understanding and regulation of such networks. It should be pointed out that the process of development must assume an evolutionary form with a number of iterations because the emergent properties of artifacts must be tested in real world situations with agents of increasing intelligence and moral competence. We see this paper as a contribution to the macro-level Requirement Engineering through discussion and analysis of general requirements for design of ethical robots. © 2011 Springer Science+Business Media B.V.},
author_keywords={Artifactual responsibility;  Artificial morality;  Autonomous agents;  Functional responsibility;  Machine ethics;  Machine morality;  Roboethics},
references={Adam, A., Delegating and distributing morality: Can we inscribe privacy protection in a machine? (2005) Ethics and Information Technology, 7, pp. 233-242; Adam, A., Ethics for things (2008) Ethics and Information Technology, 10 (2-3), pp. 149-154; Akan, B., Çürüklü, B., Spampinato, G., Asplund, L., Towards Robust Human Robot Collaboration in Industrial Environments (2010) In Proceedings 5th ACM/IEEE International Conference on Human-Robot Interaction, pp. 71-72; Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics and Information Technology, 7, pp. 149-155; Allen, C., Smit, I., Wallach, W., (2006) Why machine ethics? IEEE Intelligent Systems, pp. 12-17. , July/August 2006; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental & Theoretical Artificial Intelligence, 12 (3), pp. 251-261; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-25; Arkin, R.C., (1998) Behavior-Based Robotics, , Cambridge: MIT Press; Asaro, P.M., Robots and responsibility from a legal perspective (2007) Proceedings of the IEEE 2007 International Conference on Robotics and Automation, , Workshop on RoboEthics, Rome; Aurum, A., Wohlin, C., The fundamental nature of requirements engineering activities as a decision-making process (2003) Information and Software Technology, 45 (14), pp. 945-954; Beavers, A., Moral machines and the threat of ethical nihilism (2011) Robot Ethics: The Ethical and Social Implication of Robotics, , PatrickLin, GeorgeBekey, and KeithAbney (Eds.), Cambridge, MA: MIT Press; Becker, B., Social robots-emotional agents: Some remarks on naturalizing man-machine interaction (2006) International Review of Information Ethics (IRIE), 6, pp. 37-45; Brey, P., Freedom and privacy in ambient intelligence (2006) Ethics and Information Technology, 7 (3), pp. 157-166; Brey, P., Technological design as an evolutionary process (2008) Philosophy and Design, 1, pp. 61-75; (2004) Computer Ethics and Professional Responsibility, pp. 98-106. , T. W. Bynum and S. Rogerson (Eds.), Kundli, India: Blackwell; (2009) Ethics and Robotics, , R. Capurro and M. Nagenborg (Eds.), Amsterdam: IOS Press; Clark, A., (2003) Natural-Born Cyborgs: Minds, Technologies, and the Future of Human Intelligence, , Oxford: Oxford University Press; Coeckelbergh, M., Virtual moral agency, virtual moral responsibility: On the moral significance of the appearance, perception, and performance of artificial agents (2009) AI & Society, 24, pp. 188-189; Coeckelbergh, M., Moral appearances: Emotions, robots, and human morality (2010) Ethics and Information Technology, , published on-line ISSN 1388-1957, 18 March 2010; Coleman, K.G., Computing and moral responsibility (2008) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/fall2008/entries/computing-responsibility/, In E. N. Zalta (Ed.),Fall 2008 Edition; Crutzen, C.K.M., Invisibility and the meaning of ambient intelligence (2006) International Journal of Information Ethics, 6 (6), pp. 52-60. , Ethics in Robotics; Çürüklü, B., Dodig-Crnkovic, G., Akan, B., Towards industrial robots with human like moral responsibilities (2010) Proceedings 5th ACM/IEEE International Conference on Human-Robot Interaction, pp. 85-86; Danielson, P., (1992) Artificial Morality Virtuous Robots for Virtual Games, , London: Routledge; Davis, M., Ain't no one here but us social forces: Constructing the professional responsibility of engineers (2010) Science and Engineering Ethics, pp. 1-22. , Issn: 1353-3452; Dennett, D.C., Mechanism and responsibility (1973) Essays on Freedom of Action, , T. Honderich (Ed.), Boston: Routledge & Keegan Paul; Dennett, D.C., The myth of original intentionality (1994) Thinking Computers and Virtual Persons: Essays on the Intentionality of Machines, pp. 91-107. , E. Dietrich (Ed.), San Diego, CA and London: Academic Press; Dodig-Crnkovic, G., (1999) ABB atom's criticality safety handbook, ICNC'99 Sixth International Conference on Nuclear Criticality Safety, , Versailles, France; Dodig-Crnkovic, G., On the importance of teaching professional ethics to computer science students, computing and philosophy conference, E-CAP 2004, Pavia, Italy (2005) Computing and philosophy, , In L. Magnani (Ed.),Associated International Academic Publishers; Dodig-Crnkovic, G., Professional ethics in computing and intelligent systems (2006) Proceedings of the Ninth Scandinavian Conference on Artificial Intelligence (SCAI 2006, , Espoo, Finland, Oct 25-27; Dodig-Crnkovic, G., Persson, D., Sharing moral responsibility with robots: A pragmatic approach (2008) Tenth Scandinavian Conference on Artificial Intelligence SCAI 2008, 173. , In A. Holst, P. Kreuger & P. Funk (Eds.),Frontiers in Artificial Intelligence and Applications; Edgar, S.L., (1997) Morality and Machines: Perspectives on Computer Ethics, , Sudbury, MA: Jones and Bartlett Publishers; Eshleman, A., Moral responsibility (2009) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/win2009/entries/moral-responsibility/, In Edward N. Zalta (Ed.),Winter 2009 Edition; (2005) Who Needs Emotions?: The Brain Meets the Robot, , J.-M. Fellous and M. A. Arbib (Eds.), Oxford: Oxford University Press; Floridi, L., Distributed morality in multiagent systems (2007) Paper Presented at CEPE 2007, , http://cepe2007.sandiego.edu/abstractDetail.asp?ID=40, San Diego; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds and Machines, 14 (3), pp. 349-379; Gates, B., A robot in every home (2007) Scientific American, 296, pp. 58-65; Grodzinsky, F.S., Miller, K.W., Wolf, M.J., The ethics of designing artificial agents (2008) Ethics and Information Technology, 11 (1), pp. 115-121; Grodzinsky, F., Miller, K., Wolf, M., Developing artificial agents worthy of trust: "Would you buy a used car from this artificial agent?" (2011) Ethics and Information Technology, 13 (1), pp. 17-27; Hansson, S.O., The limits of precaution (1997) Foundations of Science, 2, pp. 293-306; Hansson, S.O., Adjusting scientific practices to the precautionary principle (1999) Human and Ecological Risk Assessment, 5, pp. 909-921; Huff, C., Unintentional power in the design of computing systems (2004) Computer Ethics and Professional Responsibility, pp. 98-106. , T. W. Bynum and S. Rogerson (Eds.), Kundli, India: Blackwell Publishing; Huff, C., (2010) Why a sociotechnical system?, , http://computingcases.org/general_tools/sia/socio_tech_system.html; Järvik, M., How to understand moral responsibility? (2003) Trames, (3), pp. 147-163. , Teaduste Akadeemia Kirjastus; Johnson, D.G., (1994) Computer Ethics, , Upper Saddle River, NJ: Prentice-Hall, Inc; Johnson, D.G., Computer systems: Moral entities but not moral agents (2006) Ethics and Information Technology, 8, pp. 195-204; Johnson, D.G., Miller, K.W., A dialogue on responsibility, moral agency, and IT systems (2006) Proceedings of the 2006 ACM symposium on Applied computing table of content, pp. 272-276. , Dijon, France; Johnson, D.G., Powers, T.M., Computer systems and responsibility: A normative look at technological complexity (2005) Ethics and Information Technology, 7, pp. 99-107; Larsson, M., (2004) Predicting quality attributes in component-based software systems, , PhD Thesis. Sweden: Mälardalen University Press. ISBN: 91-88834-33-6; Latour, B., Where are the missing masses, sociology of a few mundane artefacts, originally (1992) Shaping Technology-Building Society. Studies in Sociotechnical Change, pp. 225-259. , WiebeBijker and JohnLaw (Eds.), Cambridge, Mass: MIT Press; Levy, D.N.L., (2006) Robots Unlimited: Life in a Virtual Age, , Natick, Massachusetts: A K Peters, Ltd; Lin, P., Bekey, G., Abney, K., (2008) Autonomous military robotics: Risk, ethics, and design, , http://ethics.calpoly.edu/ONR_report.pdf; Lin, P., Bekey, G., Abney, K., Robots in war: Issues of risk and ethics (2009) Ethics and Robotics, , RafaelCapurro and MichaelNagenborg (Eds.), Heidelberg, Germany: AKA Verlag/IOS Press; Magnani, L., (2007) Distributed morality and technological artifacts. 4th International Conference on Human being in Contemporary Philosophy, , http://volgograd2007.goldenideashome.com/2%20Papers/Magnani%20Lorenzo%20p.pdf, Volgograd; Marino, D., Tamburrini, G., Learning robots and human responsibility (2006) International Review of Information Ethics (IRIE), 6, pp. 46-51; Matthias, A., The responsibility gap: Ascribing responsibility for the actions of learning automata (2004) Ethics and Information Technology, 6, pp. 175-183; McKenna, M., Compatibilism (2009) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/win2009/entries/compatibilism/, In: Edward N. Zalta (Ed,Winter 2009 Edition; Miller, K.W., Moral responsibility for computing artifacts: The rules (2011) IT Professional, 13 (3), pp. 57-59; Minsky, M., (2006) The Emotion Machine: Commonsense Thinking, Artificial Intelligence, and the Future of the Human Mind, , NY: Simon & Schuster, Inc; Mitcham, C., Computers, information and ethics: A review of issues and literature (1995) Science and Engineering Ethics, 1 (2), pp. 113-132; Montague, P., (1998) The precautionary principle, Rachel's environment and health weekly, (586). , http://www.biotech-info.net/rachels_586.html; Moor, J., What is computer ethics? (1985) Metaphilosophy, 16 (4), pp. 266-275; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE intelligent systems, IEEE computer society, pp. 18-21; Moravec, H., (1999) Robot: Mere Machine to Transcendent Mind, , Oxford, New York: Oxford University Press; Nagenborg, M., Artificial moral agents: An intercultural perspective (2007) International Review of Information Ethics, 7 (9), pp. 129-133; Nissenbaum, H., Computing and accountability (1994) Communications of the ACM, 37 (1), pp. 73-80; Nobre, F.S., Tobias, A.M., Walker, D.S., Organizational and technological implications of cognitive machines: Designing future information management systems (2009) IGI Global, pp. 1-338. , doi: 10. 4018/978-1-60566-302-9; (1999) Handbook of Industrial Robotics, , 2nd edn., S. Y. Nof (Ed.), Hoboken, New Jersey: Wiley; Nuseibeh, B., Easterbrook, S., Requirements engineering: A roadmap (2000) Proceedings of InternationalConference on Software Engineering (ICSE-2000, pp. 4-11. , ACM Press: Limerick, Ireland; Pimple, K.D., Surrounded by machines (2011) Communications of the ACM, 54 (3), pp. 29-31; Russell, S., Norvig, P., (2003) Artificial Intelligence-A Modern Approach, , Upper Saddle River, NJ: Pearson Education; Scheutz, M., (2002) Computationalism New Directions, pp. 1-223. , Cambridge, Mass: MIT Press; Shrader-Frechette, K., Technology and ethics (2003) Philosophy of Technology-The Technological Condition, pp. 187-190. , R. C. Scharff and V. Dusek (Eds.), Padstow, United Kingdom: Blackwell Publishing; Silver, D.A., Strawsonian defense of corporate moral responsibility (2005) American Philosophical Quarterly, 42, pp. 279-295; Siponen, M., A pragmatic evaluation of the theory of information ethics (2004) Ethics and Information Technology, 6 (4), pp. 279-290; Som, C., Hilty, L.M., Ruddy, T.F., The precautionary principle in the information society (2004) Human and Ecological Risk Assessment, 10 (5), pp. 787-799; Sommerville, I., Models for responsibility assignment (2007) Responsibility and Dependable Systems, , 1846286255, G. Dewsbury and J. Dobson (Eds.), Kluwer: Springer; Stahl, B.C., Information, ethics, and computers: The problem of autonomous moral agents (2004) Minds and Machines, 14, pp. 67-83; Strawson, P.F., (1974) Freedom and Resentment, in Freedom and Resentment and Other Essays, , London: Methuen; Sullins, J.P., When is a robot a moral agent? (2006) International Review of Information Ethics, 6 (12), pp. 23-30; Vallverdú, J., Casacuberta, D., Handbook of research on synthetic emotions and sociable robotics: New applications in affective computing and artificial intelligence (2009) IGI Global, , doi: 10. 4018/978-1-60566-354-8; van de Poel, I.R., Verbeek, P.P., Special issue on ethics and engineering design (2006) Science, Technology and Human Values, 31 (3), pp. 223-380; Verbeek, P.-P., Morality in design: Design ethics and the morality of technological artifacts (2008) Philosophy and Design, pp. 91-103. , P. E. Vermaas, P. A. Kroes, A. Light, and S. Moore (Eds.), Berlin, Germany: Springer; Veruggio, G., (2006) The EURON Roboethics Roadmap, Humanoids'06, , December 6, 2006, Genoa, Italy; Veruggio, G., Operto, F., (2008) Roboethics, Chapter 64 in Springer Handbook of Robotics, , Berlin, Heidelberg: Springer; Wallach, C., Allen, W., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford: Oxford University Press; Warwick, K., (2009) Today it's a cute friend. Tomorrow it could be the dominant life form, , http://www.timesonline.co.uk/tol/comment/columnists/guest_contributors/article5798625.ece, Times of London 2009-02-25},
document_type={Article},
source={Scopus},
}

@ARTICLE{deGraaf2016589,
author={de Graaf, M.M.A.},
title={An Ethical Evaluation of Human–Robot Relationships},
journal={International Journal of Social Robotics},
year={2016},
volume={8},
number={4},
pages={589-598},
doi={10.1007/s12369-016-0368-5},
note={cited By 29},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985911042&doi=10.1007%2fs12369-016-0368-5&partnerID=40&md5=8e1983f6141313103cfa9c2e2dbd4b0b},
abstract={When people interact with socially interactive robots on a regular basis, it could be that people start developing some kind of relationship with such robots. People are able to get attached to several objects in our everyday world. However, the relationships we build with regular objects differ significantly from those we may build with socially interactive robots. In contrast to common nonhuman objects, socially interactive robots act autonomously, which increases people’s expectations about its capacities. Moreover, human–robot interactions are constructed according to the rules of human–human interaction, inviting users to interact socially with robots. This paper fosters a discussion on the ethical considerations of human–robot relationships and discusses whether these bonds between humans and robots could contribute to the good life. Research on people’s interactions with and social reactions towards socially interactive robots is necessary to shape the ethical, societal and legal perspectives on these issues, and facilitates the design of responsible robotics and the successful introduction of robots into our society. © 2016, The Author(s).},
author_keywords={Human–robot relationships;  Psychological well-being;  Robot ethics;  Socially interactive robots},
keywords={Machine design;  Philosophical aspects;  Robot learning;  Robots, Ethical considerations;  Good life;  Human interactions;  Interactive robot;  Psychological well-being;  Robot ethics;  Robot interactions, Human robot interaction},
references={Aboujaoude, E., (2011) Virtually you: the dangerous powers of the e-personality, , Norton, New York; Akrich, M., The description of technological objects (1992) Shaping technology, , Bijker W, Law J, (eds), MIT Press, Cambridge, MA, USA; Ethica Nichomachea, , Aristotle: 384–322 BC; Ascione, F.R., Arkow, P., (1999) Child abuse, domestic violence, and animal abuse: linking the circles of compassion for prevention and intervention, , Purdue University Press, West Lafayette; Badhwar, N.K., Friends as ends in themselves (1987) Philos Phenomenol Res, 48, pp. 1-23; Bartneck, C., van der Hoek, M., Mubin, O., Al Mahmud, A., (2007) “Daisy, Daisy, Give me your answer do!”: switching off a robot. In: International conference on human–robot interaction, , Arlington, VA: USA; Baumeister, R.F., Leary, M.R., The need to belong: desire for interpersonal attachments as a fundamental human motivation (1995) Psychol Bull, 117, pp. 497-529; Baumgaertner, B., Weiss, A., Do emotions matter in the ethics of human–robot interaction? Artificial empathy and companion robots (2014) In, , International symposium on new frontiers in human–robot interaction, London, UK; Belk, R.W., Possessions and the extended self (1988) J Consum Res, 15, pp. 139-168; Belk, R.W., Extended self in a digital world (2013) J Consum Behav, 40, pp. 477-500; Berscheid, E., Peplau, L.A., The emerging science of relationships (1983) Close relationships, , Kelly HH, (ed), WH Freeman, New York; Bernstein, D., Crowley, K., Searching for signs of intelligent life: an investigation of young children’s beliefs about robot intelligence (2008) J Learn Sci, 17, pp. 225-247; Bickmore, T.W., Friendship and intimacy in the digital age (1998) Online report retrieved from, , http://www.media.mit.edu/Bbickmore/Mas714/finalReport.html; Breazeal, C.L., (2004) Designing sociable robots, , MIT Press, Cambridge; Brey, P., Well-being in philosophy, psychology, and economics (2012) The good life in a technological age, pp. 15-34. , Brey P, Briggle A, Spence E, (eds), Routledge, New York; Broadbent, E., Stafford, R., MacDonald, B., Acceptance of healthcare robots for the older population: review and future directions (2009) Int J Soc Robot, 1, pp. 319-330; Cacioppo, J.T., Patrick, B., (2008) Loneliness: human nature and the need for social connection, , Norton, New York; Cerulo, K.A., Nonhumans in social interaction (2009) Annu Rev Sociol, 35 (531), p. 552; Cayton, H., From childhood to childhood? Autonomy and dependence through the ages of life (2006) Dementia: mind, meaning, and the person, , Hughes JC, Louw SJ, Sabat SR, (eds), Oxford University Press, Oxford; Coeckelbergh, M., Personal robots, appearance, and human good: a methodological reflection on roboethics (2009) Int J Soc Robot, 1, pp. 217-221; Coeckelbergh, M., Care robots, virtual virtue, and the best possible life (2012) The good life in a technological age, , Brey P, Briggle A, Spence E, (eds), Routledge, New York; Dewey, J., (1980) Art as experience, , Perigee Books, New York; van Dijk, J.A.G.M., (2012) The network society, , Sage, London; Feil-Seifer, D., Mataric, M.J., Socially assistive robotics (2011) IEEE Robot Autom Mag, 18, pp. 24-31; Fischinger, D., Einramhof, P., Wohlkinger, W., Papoutsakis, K., Mayer, P., Panek, P., Koertner, T., Gisinger, C., Hobbit: the mutual care (workshop paper) (2013) In: International conference on intelligent robots and systems, , Tokyo, Japan; Fong, T., Nourbakhsh, I., Dautenhahn, K., A survey of socially interactive robots (2003) Robot Auton Syst, 42, pp. 143-166; Gates, B., A robot in every home (2007) Sci Am, 296, pp. 58-65; Gnepp, J., Hess, D.L.R., Children’s understanding of verbal and facial display rules (1986) Dev Psychol, 22, pp. 103-108; Goffman, E., (1956) The presentation of self in everyday life, , Doubleday, New York; Interaction studies special issue: new frontiers in human–robot interaction, , de Graaf MMA, Ben Allouch S, van Dijk JAGM (forthcoming) Long-term evaluation of a social robot in real homes. In:; de Graaf, M.M.A., Ben Allouch, S., van Dijk, J.A.G.M., Long-term acceptance of social robots in domestic environments: insights from a user’s perspective (2016) In: AAAI 2016 Spring symposium on “Enabling computing research in socially intelligent human–robot interaction: a community-driven modular research platform”, , Palo Alto, CA: USA; de Graaf, M.M.A., Ben Allouch, S., van Dijk, J.A.G.M., What makes robots social? A user’s perspective on characteristicsfor social human–robot interaction (2015) In: International conference on social robotics, , Paris: France; de Graaf, M.M.A., Ben Allouch, S., Klamer, T., Sharing a life with Harvey: exploring the acceptance of and relationship building with a social robot (2015) Comput Hum Behav, 43, pp. 1-14; Heider, F., (1958) The psychology of interpersonal relations, , Wiley, New York; Inagaki, K., Hatano, G., Young children’s conception of the biological world (2006) Curr Dir Psychol Sci, 15, pp. 177-181; Jipson, J., Gelman, S.A., Robots and rodents: children’s inferences about living and nonliving kinds (2007) Child Dev, 78, pp. 1675-1688; Jones, E.E., Davis, K.E., From acts to dispositions: the attribution process in person perception (1965) Advances in experimental social psychology, , Berkowitz L, (ed), Erlbaum, Hillsdale, NJ; Josephs, E., Display rule behavior and understanding in preschool children (1994) J Nonverbal Behav, 18, pp. 301-326; Kahn, P.H., Gary, H.E., Shen, S., Children’s social relationships with current and near-future robots (2013) Child Dev Perspect, 7, pp. 32-37; Kelley, H.H., Attribution theory in social psychology (1967) Nebraska symposium on motivation, , Levine D, (ed), University of Nebraska Press, Lincoln; Kerepesi, A., Kubinyi, E., Jonsson, G.K., Magnusson, M.S., Miklosi, A., Behavioural comparison of human–animal (dog) and human–robot (AIBO) interactions (2006) Behav Process, 73, pp. 92-99; Kiesler, S., Hinds, P., Introduction to the special issue on human–robot interaction (2004) Hum Comput Interact, 19, pp. 1-8; Krämer, N.C., Eimler, S.N., Pütten, A.M., Payr, S., Theory of companion: what can theoretical model contribute to applications and understanding of human–robot interaction? (2011) Appl Artif Intell, 25, pp. 474-502; Lammer, L., Huber, A., Weiss, A., Vincze, M., Mutual care: how older adults react when they should helptheir care robot (2014) In, , AISB workshop on new frontier in human–robot interaction, London, UK; Latour, B., On technical mediation: philosophy, sociology, genealogy (1994) Common Knowl, 3, pp. 29-64; Lee, K.M., Presence, explicated (2004) Commun Theory, 14, pp. 27-50; Lee, K., Park, N., Song, H., Can a robot be perceived as a developing creature? Effects of a robot’s long-term cognitive developments on its social presence and people’s social responses toward it (2005) Hum Commun Res, 31, pp. 538-563; Lee, K.M., Jung, Y., Kim, J., Kim, S.R., Are physically embodied social agents better than disembodied social agents? The effects of physical embodiment, tactile interaction, and people’s loneliness in human–robot interaction (2006) Int J Hum Comput Stud, 64, pp. 962-973; Levy, D., The ethical treatment of artificial conscious robots (2009) Int J Soc Robot, 1, pp. 209-216; Lin, P., Abney, K., Bekey, G., Robot ethics: mapping the issues for a mechanized world (2011) Artif Intell, 175, pp. 942-949; MacDorman, K.F., Cowley, S.J., Long-term relationships as a benchmark for robotpersonhood (2006) In, , International symposium on robot and human interactive communication, Hatfield, UK; Malle, B.F., Scheutz, M., Arnold, T., Voiklis, J., Cusimano, C., Sacrifice one for the good of many? People apply different moral norms to human and robot agents (2015) In: International conference on human–robot interaction, , Portland, OR: USA; Mead, G.H., (1934) Mind, self, an society, , University of Chicago Press, Chicago; Nicholson, N.R., A review of social isolation: an important but underassessed condition in older adults (2012) J Prim Prev, 33, pp. 137-152; Nourbakhsh, I.R., (2013) Robot futures, , MIT Press, Cambridge; Reeves, B., Nass, C., (1996) The media equation: how people treat computers, television, and new media like real people and places, , CSLI, New York; Ritzer, G., The McDonaldization of society (1983) J Am Cult, 6, pp. 100-107; Rook, D., The ritual dimensions of consumer behavior (1985) J Consum Res, 12, pp. 231-246; Royakkers, L., van Est, R., A literature review on new robotics: automation from love to war (2015) J Soc Robot, 7, pp. 549-570; Sanders, C.E., Field, T.M., Diego, M., Kaplam, M., The relationship of internet use to depression and social isolation among adolescents (2000) Adolescence, 35, pp. 2242-2387; Scheutz, M., The inherent dangers of unidirectional emotional bonds between humans and socially interactive robots (2012) Robot ethics: the ethical and social implications of robotics, , Lin P, Abney K, Bekey GA, (eds), MIT Press, Cambridge; Scheutz, M., Schermerhorn, J., Kramer, J., Anderson, D., First steps toward natural human-like HRI (2007) Auton Robots, 22, pp. 411-423; Seligman, M., (2002) Authentic happiness: using the new positive psychology to realize your potential for lasing fulfillment, , Free Press, New York; Seligman, M., Csikszentmihalyi, M., Positive psychology: an introduction (2000) Am Psychol, 55, pp. 5-14; Severson, R.L., Carlson, S.M., Behaving as or behaving as if? Children’s conceptions of personified robots and the emergence of a new ontological category (2010) Neural Netw, 23, pp. 1099-1103; Sharkey, N.E., Computer science: the ethical frontiers of robotics (2008) Science, 322, pp. 1800-1801; Sharkey, A.J.C., Sharkey, N.E., The crying shame of robot nannies: an ethical appraisal (2010) Interact Stud, 11, pp. 161-190; Sherman, N., Aristotle on friendship and the good life (1987) Philos Phenomenol Res, 47, pp. 589-613; Silverstone, R., Haddon, L., Design and the domestication of ICTs: technical change and everyday life (1996) Communication by design. The politics of information and communication technologies, pp. 44-74. , Silverstone R, Mansell R, (eds), Oxford Press, Oxford; Simmons, R., Makatchev, M., Kirby, R., Lee, M.K., Fanaswala, I., Browning, B., Forlizzi, J., Sakr, M., Believable robot characters (2011) AI Mag, 32, pp. 39-52; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Mind Mach, 16, pp. 141-161; Turkle, S., (2011) Alone together: why we expect more from technology and less from each other, , Basic Books, New York; Twenge, J., (2009) The narcissism epidemic: living in the age of entitlement, , Free Press, New York; Vasalou, A., Joinson, A.N., Me, myself and I: the role of interactional context on self-presentation through avatars (2009) Comput Hum Behav, 25, pp. 510-520; Verbeek, P.P.C.C., Materializing morality: design ethics and technological mediation (2006) Sci Technol Hum Values, 31, pp. 361-380; Verbeek, P.P.C.C., Morality in design: design ethics and technological mediation (2008) Philosophy and design: from engineering to architecture, pp. 91-102. , Vermaas P, Kroes P, Light A, Moore S, (eds), Springer, Berlin; Veruggio, G., Operto, F., Roboethics: a bottom-up interdisciplinary discourse in the field of applied ethics in robotics (2006) Ethics and robotics, pp. 3-8. , Capurro R, Nagenborg M, (eds), OIS Press, Amsterdam; Wada, K., Shibata, T., Living with seal robots: its sociopsychological and physiological influences on the elderly at a care house (2007) IEEE Trans Robot, 23, pp. 972-980; Wallach, W., Allen, C., (2008) Moral machines: teaching robots right from wrong, , Oxford University Press, Oxford; Walters, M.L., Dautenhahn, K., Woods, S.N., (2007) Koay KL, , Robot etiquette. In: International conference of human–robot interaction, Arlington, VA, USA; Wang, E., Lignos, C., Vatsal, A., Scassellati, B., Effects head movement on perceptions of humanoid robot behavior (2006) In: International conference of human–robot interaction, , Salt Lake City, UT: USA; Williams, R., Edge, D., The social shaping of technology (1996) Res Policy, 25, pp. 865-899; Wong, P.T.P., Positive psychology 2.0: towards a balanced interactive model of the good life (2011) Can Psychol, 52, pp. 69-81; van Wynsberghe, A.M., Designing robots for care: care centered value-sensitive design (2012) Sci Eng Ethics, 19, pp. 40-433; Young, J.E., Hawkins, R., Sharlin, E., Igarashi, T., Towards acceptable domestic robots: applying insights from social psychology (2007) Int J Soc Robot, 1, pp. 95-108; Young, J.E., Sung, J.Y., Voida, A., Sharlin, E., Igarashi, T., Christensen, H.I., Grinter, R.E., Evaluating human–robot interaction (2011) Int J Soc Robot, 3, pp. 53-67},
document_type={Article},
source={Scopus},
}

@ARTICLE{Deng201524,
author={Deng, B.},
title={Machine ethics: The robot's dilemma},
journal={Nature},
year={2015},
volume={523},
number={7558},
pages={24-26},
doi={10.1038/523024a},
note={cited By 29},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938497034&doi=10.1038%2f523024a&partnerID=40&md5=a4976d6346091ea75e3c97fb702fcacc},
keywords={algorithm;  artificial intelligence;  decision support system;  ethics;  robotics;  trends, Algorithms;  Artificial Intelligence;  Decision Making, Computer-Assisted;  Robotics},
document_type={Note},
source={Scopus},
}

@ARTICLE{Briggs2014343,
author={Briggs, G. and Scheutz, M.},
title={How Robots Can Affect Human Behavior: Investigating the Effects of Robotic Displays of Protest and Distress},
journal={International Journal of Social Robotics},
year={2014},
volume={6},
number={3},
pages={343-355},
doi={10.1007/s12369-014-0235-1},
note={cited By 29},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905487423&doi=10.1007%2fs12369-014-0235-1&partnerID=40&md5=dfde5684b87fe183a9ba5c810da47128},
abstract={The rise of military drones and other robots deployed in ethically-sensitive contexts has fueled interest in developing autonomous agents that behave ethically. The ability for autonomous agents to independently reason about situational ethics will inevitably lead to confrontations between robots and human operators regarding the morality of issued commands. Ideally, a robot would be able to successfully convince a human operator to abandon a potentially unethical course of action. To investigate this issue, we conducted an experiment to measure how successfully a humanoid robot could dissuade a person from performing a task using verbal refusals and affective displays that conveyed distress. The results demonstrate a significant behavioral effect on task-completion as well as significant effects on subjective metrics such as how comfortable subjects felt ordering the robot to complete the task. We discuss the potential relationship between the level of perceived agency of the robot and the sensitivity of subjects to robotic confrontation. Additionally, the possible ethical pitfalls of utilizing robotic displays of affect to shape human behavior are also discussed. © 2014 Springer Science+Business Media Dordrecht.},
author_keywords={Affective display;  Human-robot interaction;  Robot ethics;  Robotic protest},
keywords={Anthropomorphic robots;  Autonomous agents;  Philosophical aspects;  Social sciences, Behavioral effects;  Course of action;  Human behaviors;  Human operator;  Humanoid robot;  Robot ethics, Robotics},
references={Arkin, R., Governing lethal behavior: embedding ethics in a hybrid deliberative/reactive robot architecture (2009) Tech. Rep. GIT-GVU-07-11, Georgia Institute of Technology; Bartneck, C., van der Hoek, M., Mubin, O., Mahmud, A.A., Daisy, daisy, give me your answer do!': Switching off a robot (2007) In: Proceedings of the ACM/IEEE International Conference on Human-Robot, Interaction, ACM, pp. 217-222; Bartneck, C., Verbunt, M., Mubin, O., Mahmud, A.A., To kill a mockingbird robot (2007) In: Proceedings of the ACM/IEEE international conference on human-robot, interaction, ACM, pp. 81-87; Bridewell, W., Isaac, A., Recognizing deception: A model of dynamic belief attribution (2011) Advances in cognitive systems: Papers from the 2011 AAAI fall symposium, pp. 50-57; Briggs, G., Machine ethics, the frame problem, and theory of mind (2012) In: Proceedings of the AISB/IACAP World Congress; Briggs, G., Scheutz, M., Investigating the effects of robotic displays of protest and distress (2012) Social Robotics, pp. 238-247. , S. S. Ge, H. Li, J. J. Cabibihan, and Y. K. Tan (Eds.), Dordrech: Springer; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intell Syst, 21 (5), pp. 38-44; Bringsjord, S., Taylor, J., (2009) Introducing divine-command robot ethics, , Tech. Rep. 062310, Rensselaer Polytechnic Institute; Call, J., Tomasello, M., Does the chimpanzee have a theory of mind? 30 years later (2008) Trends Cogn Sci, 12 (5), pp. 187-192; Crowelly, C., Villanoy, M., Scheutzz, M., Schermerhornz, P., Gendered voice and robot entities: perceptions and reactions of male and female subjects (2009) In: Intelligent robots and systems, 2009, pp. 3735-3741. , IROS 2009. IEEE/RSJ International Conference on, IEEE; Dennett, D., Intentional systems (1971) J Philos, 68 (4), pp. 87-106; Dougherty, E.G., Scharfe, H., Initial formation of trust: designing an interaction with geminoid-dk to promote a positive attitude for cooperation (2011) Social Robotics, pp. 95-103. , S. S. Ge, H. Li, J. J. Cabibihan, and Y. K. Tan (Eds.), Dordrecht: Springer; Epley, N., Akalis, S., Waytz, A., Cacioppo, J.T., Creating social connection through inferential reproduction loneliness and perceived agency in gadgets, gods, and greyhounds (2008) Psychol Sci, 19 (2), pp. 114-120; Guarini, M., Particularism and the classification and reclassification of moral cases (2006) IEEE Intell Syst, 21 (4), pp. 22-28; Kahn, P., Ishiguro, H., Gill, B., Kanda, T., Freier, N., Severson, R., Ruckert, J., Shen, S., Robovie, you'll have to go into the closet now: children's social and moral relationships with a humanoid robot (2012) Dev Psychol, 48, pp. 303-314; Krach, S., Hegel, F., Wrede, B., Sagerer, G., Binkofski, F., Kircher, T., Can machines think? interaction and perspective taking with robots investigated via fmri (2008) PLoS One, 3 (7), pp. e2597; MacDorman, K.F., Coram, J.A., Ho, C.C., Patel, H., Gender differences in the impact of presentational factors in human character animation on decisions in ethical dilemmas (2010) Presence: Teleoper Virtual Environ, 19 (3), pp. 213-229; Nass, C., Etiquette equality: exhibitions and expectations of computer politeness (2004) Commun ACM, 47 (4), pp. 35-37; Nass, C., Moon, Y., Machines and mindlessness: social responses to computers (2000) J Soc Issues, 56 (1), pp. 81-103; Ogawa, K., Bartneck, C., Sakamoto, D., Kanda, T., Ono, T., Ishiguro, H., Can an android persuade you? (2009) In: Proceedings of the 18th IEEE international symposium on robot and human interactive, communication, IEEE, pp. 516-521; Pfeiffer, U.J., Timmermans, B., Bente, G., Vogeley, K., Schilbach, L., A non-verbal turing test: differentiating mind from machine in gaze-based social interaction (2011) PloS One, 6 (11), pp. 27-591; Riek, L.D., Rabinowitch, T.C., Chakrabarti, B., Robinson, P., Empathizing with robots: Fellow feeling along the anthropomorphic spectrum (2009) In: Affective computing and intelligent interaction and workshops, pp. 1-6. , 2009. ACII 2009. 3rd international conference on, IEEE; Rose, R., Scheutz, M., Schermerhorn, P., Towards a conceptual and methodological framework for determining robot believability (2010) Interact Stud, 11 (2), pp. 314-335; Scheutz, M., The affect dilemma for artificial agents: should we develop affective artificial agents? (2012) IEEE Trans Affect Comput, 3, pp. 424-433; Scheutz, M., The inherent dangers of unidirectional emotional bonds between humans and social robots (2012) Anthol on Robo-Ethics, , P. Lin, G. Bekey, and K. Abney (Eds.), Cambridge: MIT Press; Siegel, M., Breazeal, C., Norton, M., Persuasive robotics: The influence of robot gender on human behavior (2009) In: Proceedings of the IEEE/RSJ international conference on intelligent robots and systems, IEEE, pp. 2563-2568; Sparrow, R., The turing triage test (2004) Ethics Inf Technol, 6 (4), pp. 203-213; Sung, J.Y., Guo, L., Grinter, R., Christensen, H., My roomba is rambo': Intimate home applicances (2007) In: Proceedings of the 9th international conference on ubiquitous computing, UbiCompi, pp. 145-162; Takayama, L., Groom, V., Nass, C., I'm sorry, dave: I'm afraid i won't do that: Social aspect of human-agent conflict (2009) In: Proceedings of the 27th international conference on human factors in computing systems, pp. 2099-2107. , ACM SIGCHI, New York; Turkle, S., Relational artifacts/children/elders: The complexities of cybercompanions (2005) In: Toward social mechanisms of android science, pp. 62-73. , Cognitive Science Society; Wallach, W., Robot minds and human ethics: the need for a comprehensive model of moral decision making (2010) Ethics Inf Technol, 12, pp. 243-250},
document_type={Article},
source={Scopus},
}

@ARTICLE{Boden2017124,
author={Boden, M. and Bryson, J. and Caldwell, D. and Dautenhahn, K. and Edwards, L. and Kember, S. and Newman, P. and Parry, V. and Pegman, G. and Rodden, T. and Sorrell, T. and Wallis, M. and Whitby, B. and Winfield, A.},
title={Principles of robotics: regulating robots in the real world},
journal={Connection Science},
year={2017},
volume={29},
number={2},
pages={124-129},
doi={10.1080/09540091.2016.1271400},
note={cited By 28},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018635423&doi=10.1080%2f09540091.2016.1271400&partnerID=40&md5=d6360be27d60eec68d8076d3fa06a367},
abstract={This paper proposes a set of five ethical principles, together with seven high-level messages, as a basis for responsible robotics. The Principles of Robotics were drafted in 2010 and published online in 2011. Since then the principles have influenced, and continue to influence, a number of initiatives in robot ethics but have not, to date, been formally published. This paper remedies that omission. © 2017 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={principles of robotics;  responsible innovation;  Robot ethics},
keywords={Philosophical aspects;  Robots, Ethical principles;  Real-world;  Robot ethics, Robotics},
references={Asimov, I., (1950), I, Robot. New York: Gnome Press; Boden, M., Bryson, J., Caldwell, D., Dautenhahn, K., Edwards, L., Kember, S., Winfield, A., (2011) Principles of robotics, , http://www.epsrc.ac.uk/research/ourportfolio/themes/engineering/activities/principlesofrobotics/, Swindon, UK: Engineering and Physical Sciences Research Council, Retrieved from. Accessed 16 August 2016; (2016) Robots and robotic devices: Guide to the ethical design and application of robots and robotic systems, , London: British Standards Institution; Russell, S., Dewey, D., Tegmark, M., Research priorities for robust and beneficial artificial intelligence (2015) AI Magazine, 36 (4), pp. 105-114. , Association for the Advancement of Artificial Intelligence; (2016), http://en.wikipedia.org/wiki/Three_Laws_of_Robotics, Three laws of robotics. Retrieved from. Accessed 16 August 2016; Winfield, A., Roboethics–for humans (2011) New Scientist, 210 (2811), pp. 32-33. , 7 May 2011},
document_type={Article},
source={Scopus},
}

@ARTICLE{Warwick2010223,
author={Warwick, K.},
title={Implications and consequences of robots with biological brains},
journal={Ethics and Information Technology},
year={2010},
volume={12},
number={3},
pages={223-234},
doi={10.1007/s10676-010-9218-6},
note={cited By 27},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955551798&doi=10.1007%2fs10676-010-9218-6&partnerID=40&md5=2abc12ea5740dc16a9fe1261c28c4d8e},
abstract={In this paper a look is taken at the relatively new area of culturing neural tissue and embodying it in a mobile robot platform-essentially giving a robot a biological brain. Present technology and practice is discussed. New trends and the potential effects of and in this area are also indicated. This has a potential major impact with regard to society and ethical issues and hence some initial observations are made. Some initial issues are also considered with regard to the potential consciousness of such a brain. © 2010 Springer Science+Business Media B.V.},
author_keywords={Autonomy;  Consciousness;  Human ethics;  Robot ethics;  Robot rights;  Robotics},
keywords={Autonomy;  Consciousness;  Ethical issues;  Human ethics;  Neural tissue;  Potential effects;  Robot ethics, Philosophical aspects;  Robotics, Robots},
references={Arkin, R., (2009) Governing Lethal Behaviour in Autonomous Robots, , London: Chapman and Hall; Asaro, P., Information and regulation in robots, perception and consciousness: Ashby's Embodied minds (2009) International Journal of General Systems, 38 (2), pp. 111-128; Brueckner, A., Brains in a vat (1986) Journal of Philosophy, 83 (3), pp. 148-167; Cotterill, R., On the mechanism of consciousness (1997) Journal of Consciousness Studies, 4 (3), pp. 231-247; Hebb, D., (1949) The Organisation of Behaviour, , New York: Wiley; Lewicki, M., A review of methods for spike sorting: The detection and classification of neural action potentials (1998) Network: Computation in Neural Systems., 9 (4), pp. R53-R78; Minsky, M., (1975) The Psychology of Computer Vision, , New York: McGraw-Hill; Potter, S., Lukina, N., Longmuir, K., Wu, Y., Multi-site two-photon imaging of neurons on multi-electrode arrays (2001) In SPIE Proceedings, 4262, pp. 104-110; Thomas, C., Springer, P., Loeb, G., Berwald-Netter, Y., Okun, L., A miniature microelectrode array to monitor the bioelectric activity of cultured cells (1972) Experimental Cell Research, 74, pp. 61-66; },
document_type={Article},
source={Scopus},
}

@ARTICLE{vanWynsberghe2016311,
author={van Wynsberghe, A.},
title={Service robots, care ethics, and design},
journal={Ethics and Information Technology},
year={2016},
volume={18},
number={4},
pages={311-321},
doi={10.1007/s10676-016-9409-x},
note={cited By 26},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983233456&doi=10.1007%2fs10676-016-9409-x&partnerID=40&md5=31cd43fbd2e7e7a4e32b7d99988377bb},
abstract={It should not be a surprise in the near future to encounter either a personal or a professional service robot in our homes and/or our work places: according to the International Federation for Robots, there will be approx 35 million service robots at work by 2018. Given that individuals will interact and even cooperate with these service robots, their design and development demand ethical attention. With this in mind I suggest the use of an approach for incorporating ethics into the design process of robots known as Care Centered Value Sensitive Design (CCVSD). Although this approach was originally and intentionally designed for the healthcare domain, the aim of this paper is to present a preliminary study of how personal and professional service robots might also be evaluated using the CCVSD approach. The normative foundations for CCVSD come from its reliance on the care ethics tradition and in particular the use of care practices for: (1) structuring the analysis and, (2) determining the values of ethical import. To apply CCVSD outside of healthcare one must show that the robot has been integrated into a care practice. Accordingly, the practice into which the robot is to be used must be assessed and shown to meet the conditions of a care practice. By investigating the foundations of the approach I hope to show why it may be applicable for service robots and further to give examples of current robot prototypes that can and cannot be evaluated using CCVSD. © 2016, The Author(s).},
author_keywords={Applied ethics;  Care ethics;  Robot ethics;  Service robots;  Value-sensitive design},
keywords={Design;  Health care;  Mobile robots;  Philosophical aspects;  Robots, Applied ethics;  Care ethics;  Robot ethics;  Service robots;  Value sensitive design, Machine design},
references={Allen, C., Wallach, W., Moral machines: contradition in terms of abdication of human responsibility? (2011) Robot ethics: The ethical and social implications of robotics, pp. 55-68. , Lin P, Abney K, Bekey GA, (eds), MIT Press, Cambridge; Asaro, P., What should we want from a robot ethic? (2006) International Review of Information Ethics, 6, pp. 8-16; Asaro, P., A body to kick, but still no soul to damn: Legal perspectives on robotics (2011) Robot ethics: The ethical and social implications of robotics, pp. 169-186. , Lin P, Abney K, Bekey GA, (eds), MIT Press, Cambridge; Calo, R., Robots and Privacy (2011) Robot ethics: the ethical and social implications of robotics, pp. 187-202. , Lin P, Abney K, Bekey GA, (eds), MIT Press, Cambridge; Capurro, R., Ethics and robotics (2009) Ethics and robotics, pp. 117-123. , Capurro R, Nagenborg M, (eds), IOS Press, Amsterdam; Denning, T., Matuszek, C., Koscher, K., Smith, J.R., Kohno, T., A spotlight on security and privacy risks with future household robots: attacks and lessons (2009) In Proceedings of the 11th international conference on ubiquitous computing, pp. 105-114. , ACM, New York; Driessen, C., Heutinck, L., Cows desiring to be milked? Milking robots and the co-evolution of ethics and technology on Dutch dairy farms (2015) Agriculture and Human Values, 32 (1), pp. 3-20; Engelberger, J.F., (1989) Robotics in service, , MIT Press, Cambridge; Evert, F.K., A mobile field robot with vision-based detection of volunteer potato plants in a corn crop (2006) Weed Technology, 20 (4), pp. 853-861; Friedman, B., Value-sensitive design (1996) Interactions, 3 (6), pp. 16-23; Friedman, B., Hendry, D., Huldtgren, A., Jonker, C., van den Hoven, J., van Wynsberghe, A., Charting the next decade for value sensitive design (2015) Aarhus Series on Human Centered Computing, 1 (1), p. 4; Friedman, B., Kahn, P., Jacko, J., Sears, A., Human values, ethics, and design (2003) The human-computer interaction handbook, pp. 1177-1201. , http://dl.acm.org/citation.cfm?id=772072.772147, Hillsdale, NJ, L. Erlbaum. Retrieved from; Friedman, B., Kahn, P., Borning, A., Value sensitive design: Theory and methods (pp. 2–12) (2002) University of Washington technical report; (2003) Proceedings of the SIGCHI conference on human factors in computing systems, , Friedman, B., Kahn, P., & Hagman, J., Hardware Companions?: What Online AIBO discussion forums reveal about the human-robotic relationship. (pp. 273–280). New York, NY: ACM; Lin, P., Abney, K., Bekey, G.A., (2011) Robot ethics: The ethical and social implications of robotics, , MIT Press, Cambridge; Little, M.O., Care: From theory to orientation and back (1998) Journal of Medicine and Philosophy, 23 (2), pp. 190-209; Lokhorst, G.-J., van den Hoven, J., Responsibility for Military Robots (2011) Robot ethics: The ethical and social implications of robotics, pp. 145-155. , Lin P, Abney K, Bekey GA, (eds), MIT Press, Cambridge; Manders-Huits, N., What values in design? The challenge of incorporating moral values into design (2011) Science and Engineering Ethics, 17 (2), pp. 271-287; Maslow, A.H., (1970) Motivation and personality, , Harper & Row, New York; (2013) Robots cook dumplings, noodles and wait tables at restaurant in China, , http://www.dailymail.co.uk/news/article-2261767/Robot-Restaurant-Robots-cook-food-wait-tables-Harbin.html, (Jan 13), Mail Online, Retrieved from; Mol, A., Moser, I., Pols, J., Care in practice: On tinkering in clinics, homes and farms (2010) Bielefeld, , Piscataway, NJ: Transcript; Distributed in North America by Transaction Publishers; News, F., Dec 4) (2014) This restaurant replaced humans with robot waiters, , http://nypost.com/2014/12/04/this-restaurant-replaced-waiters-with-robots/, New York Post, Retrieved from; Noddings, N., (2002) Educating moral people: A caring alternative to character education, , http://eric.ed.gov/?id=ED468125, Teachers College Press, P.O. Box 20, Williston, VT 05495-0020 paperback, $21.95; cloth, Tel: 800-575-6566 (Toll Free); Fax: 802-864-7626; Web site: http://www.tcpress.com/index.html. Retrieved from; Pedersen, S.M., Fountas, S., Have, H., Blackmore, B.S., Agricultural robots—System analysis and economic feasibility (2006) Precision Agriculture, 7 (4), pp. 295-308; December 29) (2009) Retrieved from, , http://www.gizmag.com/robovie-ii-robotic-shopping-assistant/13664/; Sharkey, A., Robots and human dignity: A consideration of the effects of robot care on the dignity of older people (2014) Ethics and Information Technology, 16 (1), pp. 63-75; Sharkey, A., Should we welcome robot teachers? (2016) Ethics and Information Technology, pp. 1-15; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics and Information Technology, 14 (1), pp. 27-40; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Minds and Machines, 16 (2), pp. 141-161; Spiekermann, S., (2015) Ethical IT Innovation: A value-based system design approach, , CRC Press, Boca Raton; Sullins, J., (2011) Machine ethics, , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Tronto, J.C., (1993) Moral boundaries: A political argument for an ethic of care, , Psychology Press, Abingdon; Tronto, J.C., Creating caring institutions: Politics, plurality, and purpose (2010) Ethics and Social Welfare, 4 (2), pp. 158-171; Vallor, S., Carebots and caregivers: Sustaining the ethical ideal of care in the twenty-first century (2011) Philosophy and Technology, 24 (3), pp. 251-268; van Wynsberghe, A., Designing robots for care: Care centered value-sensitive design (2012) Science and Engineering Ethics, 19 (2), pp. 407-433; van Wynsberghe, A., A method for integrating ethics into the design of robots (2013) Industrial Robot: An International Journal, 40 (5), pp. 433-440; van Wynsberghe, A., (2015) Healthcare robots: Ethics, design and implementation, , Ashgate Publishing Ltd, Farnham; Vanlaere, L., Gastmans, C., A personalist approach to care ethics (2011) Nursing Ethics, 18 (2), pp. 161-173; Verkerk, M.A., The care perspective and autonomy (2001) Medicine, Health Care and Philosophy, 4 (3), pp. 289-294; Veruggio, G., Operto, F., Roboethics: A bottom-up interdisciplinary discourse in the field of applied ethics in robotics (2006) International Review of Information Ethics, 6, pp. 2-8; Wallach, W., Robot minds and human ethics: The need for a comprehensive model of moral decision making (2010) Ethics and Information Technology, 12 (3), pp. 243-250; Wallach, W., Allen, C., (2008) Moral Machines: Teaching robots right from wrong, , Oxford University Press, Oxford},
document_type={Article},
source={Scopus},
}

@BOOK{Yampolskiy20151,
author={Yampolskiy, R.V.},
title={Artificial superintelligence: A futuristic approachroman},
journal={Artificial Superintelligence: A Futuristic Approachroman},
year={2015},
pages={1-192},
doi={10.1201/b18612},
note={cited By 25},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053992299&doi=10.1201%2fb18612&partnerID=40&md5=8aa895ea48613d5893343cc5fb2fe6d9},
abstract={A day does not go by without a news article reporting some amazing breakthrough in artificial intelligence (AI). Many philosophers, futurists, and AI researchers have conjectured that human-level AI will be developed in the next 20 to 200 years. If these predictions are correct, it raises new and sinister issues related to our future in the age of intelligent machines. Artificial Superintelligence: A Futuristic Approach directly addresses these issues and consolidates research aimed at making sure that emerging superintelligence is beneficial to humanity. While specific predictions regarding the consequences of superintelligent AI vary from potential economic hardship to the complete extinction of humankind, many researchers agree that the issue is of utmost importance and needs to be seriously addressed. Artificial Superintelligence: A Futuristic Approachdiscusses key topics such as: AI-Completeness theory and how it can be used to see if an artificial intelligent agent has attained human level intelligence Methods for safeguarding the invention of a superintelligent system that could theoretically be worth trillions of dollars Self-improving AI systems: definition, types, and limits The science of AI safety engineering, including machine ethics and robot rights Solutions for ensuring safe and secure confinement of superintelligent systems The future of superintelligence and why long-term prospects for humanity to remain as the dominant species on Earth are not great Artificial Superintelligence: A Futuristic Approach is designed to become a foundational text for the new science of AI safety engineering. AI researchers and students, computer security researchers, futurists, and philosophers should find this an invaluable resource. © 2016 by Taylor & Francis Group, LLC.},
keywords={Artificial intelligence;  Formal logic;  Intelligent robots;  Philosophical aspects;  Security of data, Artificial intelligent;  Completeness theory;  Dominant species;  Human level intelligence;  Human levels;  Intelligent machine;  News articles;  Superintelligence, Safety engineering},
references={Von Ahn, L., Games with a purpose (2006) IEEE Computer Magazine, pp. 96-98. , June; Von Ahn, L., Blum, M., Hopper, N., Langford, J., CAPTCHA: Using Hard AI Problems for Security (2003) Paper Read at Eurocrypt. Advances in Cryptology — EUROCRYPT 2003, 2656 (2003), pp. 294-311. , International Conference on the Theory and Applications of Cryptographic Techniques, Warsaw, Poland, May 4-8, 2003. Published in Lecture Notes in Computer Science; (2011), http://en.wikipedia.org/wiki/AI-complete, Accessed January 7; Andrich, C., Novosel, L., Hrnkas, B., Common Sense Knowledge (2009) Exercise Paper—Information Search and Retrieval, , http://www.iicm.tu-graz.ac.at/cguetl/courses/isr/uearchive/uews2009/Ue06-CommonSenseKnowledge.pdf; Anusuya, M.A., Katti, S.K., Speech recognition by machine: A review (2009) International Journal of Computer Science and Information Security (IJCSIS) No, 6 (3), pp. 181-205; Bajaj, V., (2010) Spammers Pay Others to Answer Security Tests, , April 25, New York Times; Bergmair, R., Natural Language Steganography and an ‘AI-Complete” Security Primitive (2004) 21St Chaos Communication Congress, , December, Berlin; Bishop, M., Why computers can’t feel pain (2009) Minds and Machines, 19 (4), pp. 507-516; Bradford, P.G., Wollowski, M., A formalization of the Turing Test (1995) Sigartbulletin, 6 (4), pp. 3-10; Chan, T.-Y., Using a text-to-speech synthesizer to generate a reverse Turing test (2003) Paper Presented at the 15Th IEEE International Conference on Tools with Artificial Intelligence (ICTAI’03), pp. 3-5. , Washington, DC, November; Chen, J., Liu, J., Wei, Y., Peng, W., Combining Lexical Stability and Improved Lexical Chain for Unsupervised Word Sense Disambiguation (2009) Paper Presented at the Second International Symposium on Knowledge Acquisition and Modeling (KAM’09), , November 30, Wuhan, China; Demasi, P., Szwarcfiter, J.L., Cruz, A.J.O., A Theoretical Framework to Formalize AGI-Hard Problems (2010) Paper Presented at the Third Conference on Artificial General Intelligence, , March 5-8, Lugano, Switzerland; Dennett, D.C., Why you can’t make a computer that feels pain (1978) Synthese, 38 (3), pp. 415-456. , July; Dimmock, N., Maddison, I., Peer-to-peer collaborative spam detection (2004) Crossroads, 11 (2), pp. 17-25. , December; Dreyfus, H.L., (1972) What Computers Cant Do: A Critique of Artificial Reason, , New York: Harper & Row; Gentry, C., Ramzan, Z., Stubblebine, S., Secure Distributed Human Computation (2005) Paper Presented at the 6Th ACM Conference on Electronic Commerce, , June 5-8, Vancouver, BC, Canada; Hendler, J., We’ve come a long way, maybe… (2008) IEEE Intelligent Systems, 23 (5), pp. 2-3. , September; Hirschman, L., Gaizauskas, R., Natural language question answering. The view from here (2001) Natural Language Engineering, 7 (4), pp. 275-300; Horvitz, E., Reflections on challenges and promises of mixed-initiative interaction (2007) AI Magazine—Special Issue on Mixed-Initiative Assistants, 28 (2), pp. 11-18; Horvitz, E., Paek, T., Complementary computing: Policies for transferring callers from dialog systems to human receptionists (2007) User Modeling and User Adapted Interaction, 17 (1), pp. 159-182; Ide, N., Véronis, J., Introduction to the special issue on word sense disambiguation: The state of the art (1998) Computational Linguistics, 24 (1), pp. 1-40; Kapoor, A., Tan, D., Shenoy, P., Horvitz, E., Complementary Computing for Visual Tasks: Meshing Computer Vision with Human Visual Processing (2008) Paper Presented at the IEEE International Conference on Automatic Face and Gesture Recognition, , September 17-19, Amsterdam; Karp, R.M., Reducibility among combinatorial problems (1972) Complexity of Computer Computations, pp. 85-103. , edited by R. E. Miller and J. W. Thatcher, New York: Plenum; Leahu, L., Sengers, P., Mateas, M., Interactionist AI and the Promise of ubicomp, or, How to Put Your Box in the World Without Putting the World in Your Box (2008) Paper Presented at the Tenth International Conference on Ubiquitous Computing, , September 21-24, Seoul, South Korea; Legg, S., Machine Super Intelligence (2008) Phd Thesis, , http://www.vetta.org/documents/Machine_Super_Intelligence.pdf, June, University of Lugano, Switzerland; Legg, S., Hutter, M., Universal intelligence: A definition of machine intelligence (2007) Minds and Machines, 17 (4), pp. 391-444. , December; Mallery, J.C., Thinking about Foreign Policy: Finding an Appropriate Role for Artificial Intelligence Computers (1988) Ph.D. Dissertation, , MIT Political Science Department, Cambridge, MA; Ideas on Authenticating Humanness in Collaborative Systems Using AI-Hard Problems in Perception and Cognition (2009) Paper Presented at the IEEE National Aerospace and Electronics Conference (NAECON), , McIntire, John P., Paul R. Havig, and Lindsey K. McIntire, July 21-23, Dayton, OH; McIntire, J.P., McIntire, L.K., Havig, P.R., A Variety of Automated Turing tests for Network Security: Using AI-Hard Problems in Perception and Cognition to Ensure Secure Collaborations (2009) Paper Presented at the International Symposium on Collaborative Technologies and Systems (CTS’09), , May 18-22, Baltimore; Mert, E., Dalkilic, C., Word Sense Disambiguation for Turkish (2009) Paper Presented at the 24Th International Symposium on Computer and Information Sciences (ISCIS 2009), , September 14-16, Guzelyurt, Turkey; Morgan, N., Baron, D., Bhagat, S., Carvey, H., Dhillon, R., Edwards, J., Gelbart, D., Wooters, C., Meetings about Meetings: Research at ICSI on Speech in Multiparty Conversations (2003) Paper Presented at the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP’03), , April 6-10, Hong Kong; Mueller, E.T., Daydreaming and Computation (1987) Phd Dissertation, , March, University of California, Los Angeles; Navigli, R., Velardi, P., Structural semantic interconnections: A knowledge-based approach to word sense disambiguation (2005) IEEE Transactions on Pattern Analysis and Machine Intelligence, 27 (7), pp. 1075-1086. , July; Nejad, A.S., A Framework for Analyzing Changes in Health Care Lexicons and Nomenclatures (2010) Phd Dissertation, , April, Concordia University, Montreal, QC, Canada; Nicolelis, M.A.L., Wessberg, J., Stambaugh, C.R., Kralik, J.D., Beck, P.D., Laubach, M., Chapin, J.K., Kim, J., Real-time prediction of hand trajectory by ensembles of cortical neurons in primates (2000) Nature, 408 (6810), p. 361; Pepitone, J., (2011) IBM’s Jeopardy Supercomputer Beats Humans in Practice Bout, , http://money.cnn.com/2011/01/13/technology/ibm_jeopardy_watson, CNNMoney, Accessed January 13; Phillips, P.J., Ross Beveridge, J., An Introduction to Biometric-Completeness: The Equivalence of Matching and Quality (2009) Paper Presented at the IEEE 3Rd International Conference on Biometrics: Theory, Applications, and Systems (BTAS’09), , September 28-30, Washington, DC; Raymond, E.S., (1991), http://catb.org/esr/jargon/oldversions/jarg282.txt, March 22, Jargon File Version 2.8.1; Salloum, W., A Question Answering System Based on Conceptual Graph Formalism (2009) Paper Presented at the 2Nd International Symposium on Knowledge Acquisition and Modeling (KAM 2009), , November 30, Wuhan, China; Sandberg, A., Boström, N., (2008) Whole Brain Emulation: A Roadmap, , http://www.fhi.ox.ac.uk/Reports/2008-3.pdf, Technical Report 2008-3. Future of Humanity Institute, Oxford University; Searle, J., Minds, brains and programs (1980) Behavioral and Brain Sciences, 3 (3), pp. 417-457; Shahaf, D., Amir, E., Towards a Theory of AI Completeness (2007) Paper Presented at the 8Th International Symposium on Logical Formalizations of Commonsense Reasoning (Commonsense 2007), , March 26-28, Stanford University, Stanford, CA; Shahaf, D., Horvitz, E., Generalized Task Markets for Human and Machine Computation (2010) Paper Presented at the Twenty-Fourth AAAI Conference on Artificial Intelligence, , July, Atlanta, GA; Shapiro, S.C., Artificial Intelligence (1992) Encyclopedia of Artificial Intelligence, pp. 54-57. , edited by Stuart C. Shapiro, New York: Wiley; Shieber, S.M., Does the Turing Test Demonstrate Intelligence or Not? (2006) Paper Presented at the Twenty-First National Conference on Artificial Intelligence (AAAI-06), , July 16-20, Boston; Shieber, S.M., The Turing test as interactive proof (2007) Nous, 41 (4), pp. 686-713. , December; Surowiecki, J., (2004) The Wisdom of Crowds: Why the Many are Smarter than the Few and How Collective Wisdom Shapes Business, Economies, Societies and Nations, , New York: Little, Brown; Takagi, H., Interactive evolutionary computation: Fusion of the capacities of EC optimization and human evaluation (2001) Proceedings of the IEEE, 89 (9), pp. 1275-1296; Talwar, S.K., Shaohua, X., Hawley, E.S., Weiss, S.A., Moxon, K.A., Chapin, J.K., Behavioural neuroscience: Rat navigation guided by remote control (2002) Nature, 417, pp. 37-38. , May 2; Taylor, P., Black, A., Speech Synthesis by Phonological Structure Matching (1999) Paper Presented at Eurospeech99, , Budapest, Hungary; Turing, A., Computing machinery and intelligence (1950) Mind, 59 (236), pp. 433-460; Turing, A.M., On computable numbers, with an application to the Entscheidungs problem (1936) Proceedings of the London Mathematical Society, 42, pp. 230-265; Vaas, L., Striptease used to recruit help in cracking sites (2007) PC Magazine, , http://www.pcmag.com/article2/0,2817,2210671,00.asp, December 1; Vidal, J.J., Toward direct brain-computer communication (1973) Annual Review of Biophysics and Bioengineering, 2, pp. 157-180; Yampolskiy, R.V., AI-Complete CAPTCHAs as zero knowledge proofs of access to an artificially intelligent system (2011) ISRN Artificial Intelligence; Yampolskiy, R.V., Embedded CAPTCHA for Online Poker (2007) Paper Presented at the 20Th Annual CSE Graduate Conference (Grad-Conf2007), , April 13, Buffalo, NY; Yampolskiy, R.V., Graphical CAPTCHA Embedded in Cards (2007) Paper Presented at the Western New York Image Processing Workshop (WNYIPW)-IEEE Signal Processing Society, , September 28, Rochester, NY; Yampolskiy, R.V., Artificial Intelligence Safety Engineering: Why Machine Ethics Is a Wrong Approach (2011) Paper Presented at Philosophy and Theory of Artificial Intelligence (PT-AI2011), , October 3-4, Thessaloniki, Greece; Yampolskiy, R.V., What to Do with the Singularity Paradox? (2011) Paper Presented at Philosophy and Theory of Artificial Intelligence (PT-AI2011), , October 3-4, Thessaloniki, Greece; Yampolskiy, R.V., AI-Complete, AI-Hard, or AI-Easy—Classification of Problems in AI (2012) Paper Presented at the 23Rd Midwest Artificial Intelligence and Cognitive Science Conference, , April 21-22, Cincinnati, OH; Yampolskiy, R.V., Leakproofing singularity—artificial intelligence confinement problem (2012) Journal of Consciousness Studies (JCS), 19 (1-2), pp. 194-214; Yampolskiy, R.V., Fox, J., Artificial general intelligence and the human mental model (2012) In the Singularity Hypothesis: A Scientific and Philosophical Assessment, pp. 129-146. , edited by Amnon Eden, Jim Moor, Johnny Soraker, and Eric Steinhart, New York: Springer; Yampolskiy, R.V., Govindaraju, V., Embedded non-interactive continuous bot detection (2007) ACM Computers in Entertainment, 5 (4), pp. 1-11; Aaronson, S., (2013) The Ghost in the Quantum Turing Machine; Aleksander, I., Dunmall, B., Axioms and tests for the presence of minimal consciousness in agents I: Preamble (2003) Journal of Consciousness Studies, 10 (4-5), pp. 4-5; Arrabales, R., Ledezma, A., Sanchis, A., ConsScale: A plausible test for machine consciousness? (2008) Proceedings of the Nokia Workshop on Machine Consciousness—13th Finnish Artificial Intelligence Conference (Step 2008), pp. 49-57. , Helsinki, Finland; Ashby, L.H., Yampolskiy, R.V., Genetic algorithm and wisdom of artificial crowds algorithm applied to Light up (2011) Paper Presented at the 2011 16Th International Conference on Computer Games (CGAMES), , July 27-30, Louisville, KY; Bostrom, N., Are you living in a computer simulation? (2003) Philosophical Quarterly, 53 (211), pp. 243-255; Bostrom, N., Quantity of experience: Brain-duplication and degrees of consciousness (2006) Minds and Machines, 16 (2), pp. 185-200; Bostrom, N., The superintelligent will: Motivation and instrumental rationality in advanced artificial agents (2012) Minds and Machines, 22 (2), pp. 71-85; Cattell, R., Parker, A., Challenges for brain emulation: Why is it so difficult? (2012) Natural Intelligence, 1 (3), pp. 17-31; Chalmers, D.J., (1996) The Conscious Mind: In Search of a Fundamental Theory, , Oxford, UK: Oxford University Press; De Garis, H., Shuo, C., Goertzel, B., Ruiting, L., A world survey of artificial brain projects. Part I: Large-scale brain simulations (2010) Neurocomputing, 74 (1-3), pp. 3-29. , http://dx.doi.org/10.1016/j.neucom.2010.08.004; De, S., Rea, A.H.G., Linde, R., Noorbala, M., Salem, M.P., Vilenkin, A., Boltzmann brains and the scale-factor cutoff measure of the multiverse (2010) Physical Review D 82(6), 63520; Fox, J., Shulman, C., Superintelligence Does Not Imply Benevolence (2010) Paper Presented at the Eighth European Conference on Computing and Philosophy, , October 4-6, Munich, Germany; Fredkin, E., (1982) On the Soul, , Unpublished manuscript; Galilei, G., (1953) Dialogue concerning the Two Chief World Systems: Ptolemaic and Copernican, , Oakland: University of California Press; Gao, S., A quantum method to test the existence of consciousness (2002) The Noetic Journal, 3 (3), pp. 27-31; Goertzel, B., Mindplexes: The potential emergence of multiple levels of focused consciousness in communities of AI’s and humans (2003) Dynamical Psychology, , http://www.goertzel.org/dynapsyc/2003/mindplex.htm; Goertzel, B., (2006) Kinds of Minds. in the Hidden Pattern: A Patternist Philosophy of Mind, pp. 17-25. , Boca Raton, FL: BrownWalker Press; Goertzel, B., Lian, R., Arel, I., De Garis, H., Chen, S., A world survey of artificial brain projects. Part II: Biologically inspired cognitive architectures (2010) Neurocomputing, 74 (1-3), pp. 30-49; Hales, C., An empirical framework for objective testing for P-consciousness in an artificial agent (2009) Open Artificial Intelligence Journal, 3, pp. 1-15; Hall, J.S., Kinds of minds (2007) Beyond AI: Creating the Conscience of the Machine, pp. 241-248. , Amherst, NY: Prometheus Books; Hall, J.S., Self-improving AI: An analysis (2007) Minds and Machines, 17 (3), pp. 249-259. , October; Hanson, R., If uploads come first (1994) Extropy, 6 (2), pp. 10-15; Havel, I.M., On the way to intelligence singularity (2013) Beyond Artificial Intelligence, pp. 3-26. , edited by Jozef Kelemen, Jan Romportl, and Eva Zackova, Berlin: Springer; Herzing, D.L., Profiling nonhuman intelligence: An exercise in developing unbiased tools for describing other “types” of intelligence on earth (2014) Acta Astronáutica, 94 (2), pp. 676-680. , http://dx.doi.org/10.1016/j.actaastro.2013.08.007; Hughes, R., Yampolskiy, R.V., Solving sudoku puzzles with wisdom of artificial crowds (2013) International Journal of Intelligent Games and Simulation, 7 (1), p. 6; Kelly, K., (2007) The Evolutionary Mind of God, , http://kk.org/thetechnium/archives/2007/02/the_evolutionar.php; Kelly, K., (2007) A Taxonomy of Minds, , http://kk.org/thetechnium/archives/2007/02/a_taxonomy_of_m.php; Kelly, K., (2008) The Landscape of Possible Intelligences, , http://kk.org/thetechnium/archives/2008/09/the_landscape_o.php; Kelly, K., (2008) What Comes after Minds?, , http://kk.org/thetechnium/archives/2008/12/what_comes_afte.php; Kelly, K., (2009) Inevitable Minds, , http://kk.org/thetechnium/archives/2009/04/inevitable_mind.php; Kolmogorov, A.N., Three approaches to the quantitative definition of information (1965) Problems of Information Transmission, 1 (1), pp. 1-7; Krioukov, D., Kitsak, M., Sinkovits, R.S., Rideout, D., Meyer, D., Boguñá, M., Network cosmology (2012) Science Reports 2, , http://www.nature.com/srep/2012/121113/srep00793/abs/srep00793.html#supplementary-information; Lanza, R., A new theory of the universe (2007) American Scholar, 76 (2), p. 18; Legg, S., Is There an Elegant Universal Theory of Prediction? Paper presented at Algorithmic Learning Theory (2006) 17Th International Conference on Algorithmic Learning Theory, , Barcelona, Spain, October 7-10, 2006; Legg, S., Hutter, M., Universal intelligence: A definition of machine intelligence (2007) Minds and Machines, 17 (4), pp. 391-444. , December; Levin, L., Universal search problems (1973) Problems of Information Transmission, 9 (3), pp. 265-266; Lloyd, S., Ultimate physical limits to computation (2000) Nature, 406, pp. 1047-1054; Miller, M.S.P., Patterns for Cognitive Systems (2012) Paper Presented at the 2012 Sixth International Conference on Complex, Intelligent and Software Intensive Systems (CISIS), , July 4-6, Palermo, Italy; Omohundro, S.M., The Nature of Self-Improving Artificial Intelligence (2007) Paper Presented at the Singularity Summit, , September 8-9, San Francisco; Omohundro, S.M., The Basic AI Drives (2008) Proceedings of the First AGI Conference, Volume 171, Frontiers in Artificial Intelligence and Applications, pp. 483-492. , February, edited by P. Wang, B. Goertzel, and S. Franklin, Amsterdam: IOS Press; Port, A.C., Yampolskiy, R.V., Using a GA and wisdom of artificial crowds to solve solitaire battleship puzzles (2012) Paper Presented at the 2012 17Th International Conference on Computer Games (CGAMES), , July 30-August 1, Louisville, KY; Putnam, H., Brains and behavior (1980) Readings in Philosophy of Psychology, 1, pp. 24-36; Rice, H.G., Classes of recursively enumerable sets and their decision problems (1953) Transactions of the American Mathematical Society, 74 (2), pp. 358-366; Roberts, P., (2009) Mind Making: The Shared Laws of Natural and Artificial, , North Charleston, SC: CreateSpace; Sloman, A., The structure of the space of possible minds (1984) The Mind and the Machine: Philosophical Aspects of Artificial Intelligence, pp. 35-42. , Chichester, UK: Ellis Horwood; Sotala, K., Valpola, H., Coalescing minds: Brain uploading-related group mind scenarios (2012) International Journal of Machine Consciousness, 4 (1), pp. 293-312; (2011), http://en.wikipedia.org/wiki/Universal_Turing_machine, Accessed April 14; Vernon, D., Metta, G., Sandini, G., A survey of artificial cognitive systems: Implications for the autonomous development of mental capabilities in computational agents (2007) IEEE Transactions on Evolutionary Computation, 11 (2), pp. 151-180; Waser, M.R., Designing a Safe Motivational System for Intelligent Machines (2010) Paper Presented at the Third Conference on Artificial General Intelligence, , March 5-8, Lugano, Switzerland; Watson, J.D., Crick, F.H.C., Molecular structure of nucleic acids (1953) Nature, 171 (4356), pp. 737-738; Wolfram, S., (2002) A New Kind of Science, , May 14, Oxfordshire, UK: Wolfram Media; Yampolskiy, R.V., AI-Complete CAPTCHAs as zero knowledge proofs of access to an artificially intelligent system (2011) ISRN Artificial Intelligence no. 271878; Yampolskiy, R.V., (2011) Construction of an NP problem with an exponential lower bound, 1111, p. 0305; Yampolskiy, R.V., AI-Complete, AI-Hard, or AI-Easy— Classification of Problems in AI (2012) Paper Presented at the 23Rd Midwest Artificial Intelligence and Cognitive Science Conference, , April 21-22, Cincinnati, OH; Yampolskiy, R.V., Leakproofing singularity—artificial intelligence confinement problem (2012) Journal of Consciousness Studies (JCS), 19 (1-2), pp. 194-214; Yampolskiy, R.V., Artificial intelligence safety engineering: Why machine ethics is a wrong approach (2013) Philosophy and Theory of Artificial Intelligence, pp. 389-396. , Berlin: Springer; Yampolskiy, R.V., Efficiency theory: A unifying theory for information, computation and intelligence (2013) Journal of Discrete Mathematical Sciences and Cryptography, 16 (4-5), pp. 259-277; Yampolskiy, R.V., Turing test as a defining feature of AI-Completeness (2013) Artificial Intelligence, Evolutionary Computation and Metaheuristics—In the Footsteps of Alan Turing, pp. 3-17. , edited by Xin-She Yang, Berlin: Springer; Yampolskiy, R.V., What to do with the singularity paradox? (2013) Philosophy and Theory of Artificial Intelligence, pp. 397-413. , Berlin: Springer; Yampolskiy, R.V., Utility function security in artificially intelligent agents (2014) Journal of Experimental and Theoretical Artificial Intelligence (JETAI), pp. 1-17; Yampolskiy, R.V., Ashby, L., Hassan, L., Wisdom of artificial crowds—a metaheuristic algorithm for optimization (2012) Journal of Intelligent Learning Systems and Applications, 4 (2), pp. 98-107; Yampolskiy, R.V., Fox, J., Artificial general intelligence and the human mental model (2012) Singularity Hypotheses, pp. 129-145. , Berlin: Springer; Yampolskiy, R., Gavrilova, M., Artimetrics: Biometrics for artificial entities (2012) IEEE Robotics and Automation Magazine (RAM), 19 (4), pp. 48-58; Yampolskiy, R.V., Klare, B., Jain, A.K., Face Recognition in the Virtual World: Recognizing Avatar Faces (2012) Paper Presented at the 2012 11Th International Conference on Machine Learning and Applications (ICMLA), , December 12-15, Boca Raton, FL; Yonck, R., Toward a standard metric of machine intelligence (2012) World Future Review, 4 (2), pp. 61-70; Yudkowsky, E.S., (2001) Creating Friendly AI—The Analysis and Design of Benevolent Goal Architectures, , http://singinst.org/upload/CFAI.html; Yudkowsky, E., The Human Importance of the Intelligence Explosion (2006) Paper Presented at the Singularity Summit at Stanford, , May 13, Palo Alto, CA; Yudkowsky, E., Artificial intelligence as a positive and negative factor in global risk (2008) Global Catastrophic Risks, pp. 308-345. , edited by N. Bostrom and M. M. Cirkovic, Oxford, UK: Oxford University Press; Aboufadel, E.F., Olsen, J., Windle, J., Breaking the Holiday Inn Priority Club CAPTCHA (2005) College Mathematics Journal, 36 (2), pp. 101-108. , March; Von Ahn, L., (2004) Utilizing the Power of Human Cycles, , May, Thesis proposal, Carnegie Mellon University; Von Ahn, L., Blum, M., Hopper, N., Langford, J., CAPTCHA: Using Hard AI Problems for Security (2003) Paper Presented at Eurocrypt. Advances in Cryptology — EUROCRYPT 2003, pp. 294-311. , International Conference on the Theory and Applications of Cryptographic Techniques, Warsaw, Poland, May 4-8, 2003. Published in Lecture Notes in Computer Science 2656 (2003); Von Ahn, L., Blum, M., Langford, J., How lazy cryptographers do AI (2004) Communications of the ACM, 47 (2), pp. 56-60. , February; Baird, H.S., Bentley, J.L., Implicit CAPTCHAs (2005) Proceedings of the Spie/Is&T Conference on Document Recognition and Retrieval, , January, XII (DR&R2005), San Jose, CA; Baird, H.S., Moll, M.A., Wang, S.-Y., ScatterType: A legible but hard-to-segment CAPTCHA (2005) Proceedings of Eighth International Conference on Document Analysis and Recognition, 2, pp. 935-939. , August 29-September 1, New York: IEEE; Baird, H.S., Riopka, T., ScatterType: A Reading CAPTCHA Resistant to Segmentation Attack (2005) Paper Presented at Spie/Is&T Conference on Document Recognition and Retrieval XII (Dr&R2005), , January, San Jose, CA; Baird, H.S., Moll, M.A., Wang, S.-Y., A Highly Legible CAPTCHA that Resists Segmentation Attacks (2005) Paper Presented at Human Interactive Proofs, Second International Workshop (HIP 2005), , May 19-20, Bethlehem, PA; Baird, H.S., Popat, K., Human Interactive Proofs and Document Image Analysis (2002) Paper Presented at the Fifth International Workshop on Document Analysis Systems, , August 19-21, Princeton, NJ; Bentley, J., Mallows, C.L., CAPTCHA Challenge Strings: Problems and Improvements (2006) Paper Presented at Document Recognition and Retrieval, , January 18-19, San Jose, CA; Bergmair, R., Natural Language Steganography and an ‘AI-Complete” Security Primitive (2004) Paper Presented at the 21St Chaos Communication Congress, , December, Berlin; Blum, M., How to Prove a Theorem So No One Else Can Claim It (1986) Paper Presented at the International Congress of Mathematicians, , August 3-11, Berkeley, CA; Bostrom, N., Ethical issues in advanced artificial intelligence (2006) Review of Contemporary Philosophy, 5, pp. 66-73; Chalmers, D., The singularity: A philosophical analysis (2010) Journal of Consciousness Studies, 17, pp. 7-65; Chan, T.-Y., Using a Text-to-Speech Synthesizer to Generate a Reverse Turing Test (2003) Paper Presented at the 15Th IEEE International Conference on Tools with Artificial Intelligence (ICTAI’03), , November 3-5, Sacramento, CA; Chellapilla, K., Larson, K., Simard, P., Czerwinski, M., Designing Human Friendly Human Interaction Proofs (HIPs) (2005) Paper Presented at the Conference on Human Factors in Computing Systems, , April 2-7, Portland, OR; Chellapilla, K., Larson, K., Simard, P.Y., Czerwinski, M., Building Segmentation Based Human-Friendly Human Interaction Proofs (HIPs) (2005) Paper Presented at the Second International Workshop, Human Interactive Proofs, HIP 2005, , May 19-20, Bethlehem, PA; Chellapilla, K., Larson, K., Simard, P.Y., Czerwinski, M., Computers Beat Humans at Single Character Recognition in Reading Based Human Interaction Proofs (HIPs) (2005) Paper Presented at the Second Conference on Email and Anti-Spam, , July 21-22, Stanford, CA; Chellapilla, K., Simard, P., Using Machine Learning to Break Visual Human Interaction Proofs (HIPs) (2004) Paper Presented at Advances in Neural Information Processing Systems 17, , December, Neural Information Processing Systems (NIPS’2004), Vancouver, BC, Canada; Chen, J., Liu, J., Wei, Y., Peng, W., Combining Lexical Stability and Improved Lexical Chain for Unsupervised Word Sense Disambiguation (2009) Paper Presented at the Second International Symposium on Knowledge Acquisition and Modeling (KAM’09), , November 30, Wuhan, China; Chew, M., Baird, H.S., Baffletext: A Human Interactive Proof (2003) Proceedings of Spie-Is&T Electronic Imaging, Document Recognition and Retrieval, , January 23-24, X, San Jose, CA; Chew, M., Tygar, J.D., Image recognition CAPTCHAs (2004) Proceedings of the Seventh International Information Security Conference, , September 27-29, Palo Alto, CA; Coates, A.L., Baird, H.S., Fateman, R.J., Pessimal print: A reverse Turing test (2001) Proceedings of the Sixth International Conference on Document Analysis and Recognition, , September, Seattle, WA; Dailey, M., Namprempre, C., A Text Graphics Character CAPTCHA for Password Authentication (2004) Paper Presented at the IEEE Region 10, , November 21-24, Conference TENCON, Chian Mai, Thailand; Demasi, P., Szwarcfiter, J.L., Cruz, A.J.O., A Theoretical Framework to Formalize AGI-Hard Problems (2010) Paper Presented at the Third Conference on Artificial General Intelligence, , March 5-8, Lugano, Switzerland; French, R., The Turing test: The first fifty years (2000) Trends in Cognitive Sciences, 4 (3), pp. 115-121; Gentry, C., Ramzan, Z., Stubblebine, S., Secure Distributed Human Computation (2005) Paper Presented at the Sixth ACM Conference on Electronic Commerce, , June 5-8, Vancouver, BC, Canada; Good, I.J., Speculations concerning the first ultraintelligent machine (1966) Advances in Computers, 6, pp. 31-88; Hall, J.S., (2000) Ethics for Machines, , http://autogeny.org/ethics.html; Hall, R.V., (2006) CAPTCHA as a Web Security Control, , http://www.richhall.com/isc4350/captcha_20051217.htm, Accessed October 26; Hendler, J., We’ve come a long way, maybe … (2008) IEEE Intelligent Systems, 23 (5), pp. 2-3. , September; Hibbard, B., (2005) The Ethics and Politics of Super-Intelligent Machines, , July; Ide, N., Véronis, J., Introduction to the special issue on word sense disambiguation: The state of the art (1998) Computational Linguistics, 24 (1), pp. 1-40; Kochanski, G., Lopresti, D., Shih, C., A Reverse Turing Test Using Speech (2002) Proceedings of the International Conferences on Spoken Language Processing, , September 16-20, Denver, CO; Leahu, L., Sengers, P., Mateas, M., Interactionist AI and the Promise of Ubicomp, or, How to Put Your Box in the World Without Putting the World in Your Box (2008) Paper Presented at the Tenth International Conference on Ubiquitous Computing, , September 21-24, Seoul, South Korea; Liao, W.-H., A Captcha Mechanism by Exchange Image Blocks (2006) Paper Presented at the 18Th International Conference on Pattern Recognition (ICPR’06), , August 20-24, Hong Kong; Liao, W.-H., Chang, C.-C., Embedding Information within Dynamic Visual Patterns (2004) Paper Presented at the IEEE International Conference on Multimedia and Expo ICME’04, , June 27-30, Taipei, Taiwan; Lopresti, D., Leveraging the CAPTCHA problem (2005) Proceedings of the Second HIP Conference, , May 19-20, Bethlehem, PA; Mallery, J.C., Thinking About Foreign Policy: Finding an Appropriate Role for Artificial Intelligence Computers (1988) Ph.D. Dissertation, , MIT Political Science Department, Cambridge, MA; May, M., Inaccessibility of CAPTCHA (2005) Alternatives to Visual Turing Tests on the Web, , http://www.w3.org/TR/turingtest/, November, W3C Working Group Note; McIntire, J.P., Havig, P.R., McIntire, L.K., Ideas on Authenticating Humanness in Collaborative Systems Using AI-Hard Problems in Perception and Cognition (2009) Paper Presented at the IEEE National Aerospace and Electronics Conference (NAECON), , July 21-23, Dayton, OH; McIntire, J.P., McIntire, L.K., Havig, P.R., A Variety of Automated Turing Tests for Network Security: Using AI-Hard Problems in Perception and Cognition to Ensure Secure Collaborations (2009) Paper Presented at the International Symposium on Collaborative Technologies and Systems (CTS’09), , May 18-22, Baltimore, MD; Mert, E., Dalkilic, C., Word Sense Disambiguation for Turkish (2009) Paper Presented at the 24Th International Symposium on Computer and Information Sciences (ISCIS 2009), , September 14-16, Guzelyurt, Turkey; Misra, D., Gaj, K., Face Recognition CAPTCHAs (2006) Paper Presented at the International Conference on Telecommunications, Internet and Web Applications and Services (AICT-ICIW’06), , February 19-25, Guadeloupe, French Caribbean; Mori, G., Malik, J., Recognizing objects in adversarial Clutter: Breaking a visual CAPTCHA (2003) Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition, , June 18-20, Madison, WI; Moy, G., Jones, N., Harkless, C., Potter, R., Distortion estimation techniques in solving visual CAPTCHAs (2004) Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR 2004), , June 27-July 2, Washington, DC; Mueller, E.T., Daydreaming and Computation (1987) Phd Dissertation, , March, University of California, Los Angeles; Naor, M., (1996) Verification of a Human in the Loop Or Identification via the Turing Test, , http://www.wisdom.weizmann.ac.il/~naor/PAPERS/human_abs.html, Accessed October 7, 2006; Navigli, R., Velardi, P., Structural semantic interconnections: A knowledge-based approach to word sense disambiguation (2005) IEEE Transactions on Pattern Analysis and Machine Intelligence, 27 (7), pp. 1075-1086. , July; Nejad, A.S., (2010) A Framework for Analyzing Changes in Health Care Lexicons and Nomenclatures, , April, PhD dissertation, Concordia University; Phillips, P.J., Ross Beveridge, J., An Introduction to Biometric-Completeness: The Equivalence of Matching and Quality (2009) Paper Presented at the IEEE Third International Conference on Biometrics: Theory, Applications, and Systems (BTAS’09), , September 28-30, Washington, DC; Pope, C., Kaur, K., Is It Human or Computer? Defending E-Commerce with Captchas (2005) IT Professional, 7 (2), pp. 43-49. , March/April; Raymond, E.S., (1991) Jargon File Version 2.8.1, , http://catb.org/esr/jargon/oldversions/jarg282.txt, March 22; Rui, Y., Liu, Z., ARTiFACIAL: Automated reverse Turing test using FACIAL features (2003) Proceedings of the 11Th ACM International Conference on Multimedia, , November 2-8, Berkeley, CA; Rui, Y., Liu, Z., Excuse me, but are you human? (2003) Proceedings of the 11Th ACM International Conference on Multimedia, , Berkeley, CA; Rui, Y., Liu, Z., Kallin, S., Janke, G., Paya, C., Characters or faces: A user study on ease of use for HIPs (2005) Proceedings of the Second International Workshop on Human Interactive Proofs, , May 18-20, Lehigh University, Bethlehem, PA; Russell, S., Norvig, P., (2003) Artificial Intelligence: A Modern Approach, , Upper Saddle River, NJ: Prentice Hall; Rusu, A., Govindaraju, V., Handwritten CAPTCHA: Using the Difference in the Abilities of Humans and Machines in Reading Handwritten Words (2004) Paper Presented at the Ninth International Workshop on Frontiers in Handwriting Recognition, IWFHR-9 2004, , October 26-29, Tokyo; Rusu, A., Govindaraju, V., A human interactive proof algorithm using handwriting recognition (2005) Proceedings of Eighth International Conference on Document Analysis and Recognition, , August 29-September 1; Sampson, R.M., (2006) Reverse Turing Tests and Their Applications, , http://www-users.cs.umn.edu/~sampra/research/ReverseTuringTest.PDF, Accessed October 8; Shahaf, D., Amir, E., Towards a Theory of AI Completeness (2007) Paper Presented at the Eighth International Symposium on Logical Formalizations of Commonsense Reasoning (Commonsense 2007), , March 26-28, Stanford, CA; Shapiro, S.C., Artificial intelligence (1992) Encyclopedia of Artificial Intelligence, pp. 54-57. , edited by Stuart C. Shapiro, New York: Wiley; Shulman, C.M., Arms Control and Intelligence Explosions (2009) Paper Presented at the Seventh European Conference on Computing and Philosophy, , July 2-4, Barcelona, Spain; Simard, P.Y., Szeliski, R., Benaloh, J., Couvreur, J., Calinov, I., Using Character Recognition and Segmentation to Tell Computer from Humans (2003) Paper Presented at the Seventh International Conference on Document Analysis and Recognition, , August, Edinburgh; Sparrow, R., Killer robots (2007) Journal of Applied Philosophy, 24 (1), pp. 62-77; Turing, A., Computing machinery and intelligence (1950) Mind, 59 (236), pp. 433-460; Wang, S.-Y., Baird, H.S., Bentley, J.L., CAPTCHA Challenge Tradeoffs: Familiarity of Strings versus Degradation of Images (2006) Paper Presented at the Eighteenth International Conference on Pattern Recognition, , August 20-24, Hong Kong; Xu, J., Lipton, R., Essa, I., Sung, M., Zhu, Y., Mandatory human participation: A new authentication scheme for building secure systems (2003) Proceedings of the 12Th International Conference on Computer Communications and Networks, , October 20-22, Dallas, TX; Yampolskiy, R.V., AI-Complete, AI-Hard, or AI-Easy: Classification of Problems in Artificial Intelligence (2011) Technical Report #02, , http://louisville.edu/speed/computer/tr/UL_CECS_02_2011.pdf, September 12, Louisville, KY: University of Louisville; Yampolskiy, R.V., Govindaraju, V., Embedded non-interactive continuous bot detection (2007) ACM Computers in Entertainment, 5 (4), pp. 1-11; Yudkowsky, E., Artificial Intelligence as a Positive and Negative Factor in Global Risk (2008) Global Catastrophic Risks, pp. 308-345. , edited by N. Bostrom and M. M. Cirkovic, Oxford, UK: Oxford University Press; Aaronson, S., The Complexity of Agreement (2005) Proceedings of the 37Th Annual ACM Symposium on the Theory of Computing, pp. 634-643; Ali, N., Hindi, M., Yampolskiy, R.V., Evaluation of Authorship Attribution Software on a Chat Bot Corpus (2011) Paper Presented at the 23Rd International Symposium on Information, Communication and Automation Technologies (ICAT2011), , October 27-29, Sarajevo, Bosnia and Herzegovina; Diagnostic and Statistical Manual of Mental Disorders (2000) 4Th Edition, Text Revision (DSM-IV-TR), , Arlington, VA: American Psychiatric Association; Armstrong, S., Chaining God: A Qualitative Approach to AI, Trust and Moral Systems (2007) New European Century, , http://www.neweuropeancen-tury.org/GodAI.pdf; Armstrong, S., Utility Indifference (2010) Technical Report 2010-1, pp. 1-5. , Oxford, UK: Future of Humanity Institute, Oxford University; Aumann, R.J., Agreeing to disagree (1976) Annals of Statistics, 4 (6), pp. 1236-1239; Bishop, M., Why computers can’t feel pain (2009) Minds and Machines, 19 (4), pp. 507-516; De Blanc, P., (2007) Convergence of Expected Utilities with Algorithmic Probability, , http://arxiv.org/abs/0712.4318; De Blanc, P., (2009) Convergence of Expected Utility for Universal AI, , http://arxiv.org/abs/0907.5598; De Blanc, P., (2011) Ontological Crises in Artificial Agents’ Value Systems, , http://arxiv.org/abs/1105.3821; Bostrom, N., Are you living in a computer simulation? (2003) Philosophical Quarterly, 53 (211), pp. 243-255; Bostrom, N., Ethical issues in advanced artificial intelligence (2006) Review of Contemporary Philosophy, 5, pp. 66-73; Bostrom, N., What is a singleton? (2006) Linguistic and Philosophical Investigations, 5 (2), pp. 48-54; Bostrom, N., Superintelligence: The control problem (2011) Paper Presented at Philosophy and Theory of Artificial Intelligence (PT-AI2011), , October 3-4, Thessaloniki, Greece; Brown, J.C., Loglan (1960) Scientific American, 202, pp. 43-63; (2011) Why No Wireheading?, , http://lesswrong.com/lw/69r/why_no_wireheading/; Dennett, D.C., Why you can’t make a computer that feels pain (1978) Synthese, 38 (3), pp. 415-456. , July; Devito, C.L., Oehrle, R.T., A language based on the fundamental facts of science (1990) Journal of the British Interplanetary Society, 43, pp. 561-568; Dewey, D., Learning What to Value (2011) Paper Presented at the Fourth International Conference on Artificial General Intelligence, , August 3-6, Mountain View, CA; Finin, T., Weber, J., Wiederhold, G., Gensereth, M., Fritzzon, R., McKay, D., McGuire, J., Beck, C., Draft Specification of the KQML Agent-Communication Language, , http://www.csee.umbc.edu/csee/research/kqml/kqmlspec/spec.html, June 15; Frederick, S., Loewenstein, G., O’Donoghue, T., Time discounting and time preference: A critical review (2002) Journal of Economic Literature, 40 (2), pp. 351-401; Fredkin, E., (1992) Finite Nature. Paper Presented at the Proceedings of the Xxviith Rencotre De Moriond, , March 15-22, Savoie, France; Gildert, S., Pavlov’s AI—What Did It Mean?, , http://physicsandcake.wordpress.com/2011/01/22/pavlovs-ai-what-did-it-mean; Goertzel, B., Mindplexes: The potential emergence of multiple levels of focused consciousness in communities of AI’s and humans (2003) Dynamical Psychology, , http://www.goertzel.org/dynapsyc/2003/mindplex.htm; Goertzel, B., (2005) Potential Computational Linguistics Resources for Lojban, , http://www.goertzel.org/new_research/lojban_AI.pdf, March 6; Goodhart, C., Monetary relationships: A view from Threadneedle Street (1975) Papers in Monetary Economics, 1. , Sydney: Reserve Bank of Australia; Heath, R.G., Electrical self-stimulation of the brain in man (1963) American Journal of Psychiatry, 120, pp. 571-577; Hibbard, B., (2011) Model-Based Utility Functions, , http://arxiv.org/abs/1111.3934; Hutter, M., (2010) Universal Artificial Intelligence: Sequential Decisions Based on Algorithmic Probability, , New York: Springer; Kaczynski, T., (1995) Industrial Society and Its Future, , September 19, New York Times; Kanazawa, S., Hellberg, J., Intelligence and substance use (2010) Review of General Psychology, 14 (4), pp. 382-396; Lenat, D., EURISKO: A program that learns new heuristics and domain concepts (1983) Artificial Intelligence, 21, pp. 61-98; Levitt, S.D., Dubner, S.J., (2006) Freakonomics: A Rogue Economist Explores the Hidden Side of Everything, , New York: Morrow; (2012) TV Tropes, , http://tvtropes.org/pmwiki/pmwiki.php/Main/LiteralGenie; Mahoney, M., (2011) The Wirehead problem—candidate Solutions?, , AGI@list-box.com mailinglist; Muehlhauser, L., Helm, L., The singularity and machine ethics (2012) The Singularity Hypothesis: A Scientific and Philosophical Assessment, pp. 101-126. , edited by A. Eden, J. Soraker, J. Moor, and E. Steinhart, Berlin: Springer; Neches, R., Fikes, R., Finin, T., Gruber, T., Patil, R., Senator, T., Swartout, W.R., Enabling technology for knowledge sharing (1991) AI Magazine, 12 (3), pp. 37-56; Nozick, R., (1977) Anarchy, State, and Utopia, , New York: Basic Books; Olds, J., Milner, P., Positive reinforcement produced by electrical stimulation of septal area and other regions of rat brain (1954) Journal of Comparative and Physiological Psychology, 47, pp. 419-427; Omohundro, S.M., The Basic AI Drives (2008) Proceedings of the First AGI Conference, Volume 171, Frontiers in Artificial Intelligence and Applications, pp. 483-492. , February, edited by P. Wang, B. Goertzel, and S. Franklin, Washington, DC: IOS Press; Orseau, L., Ring, M., Self-modification and mortality in artificial agents (2011) Paper Presented at the Fourth International Conference on Artificial General Intelligence, , August 3-6, Mountain View, CA; Patil, R., McKay, D., Finin, T., Fikes, R., Gruber, T., Patel-Schneider, P.F., Neches, R., An Overview of the DARPA Knowledge Sharing Effort (1992) Paper Presented at the Third International Conference on Principles of Knowledge Representation and Reasoning, , August, San Mateo, CA; Pearce, D., (2012) Wirehead Hedonism versus Paradise Engineering, , http://wireheading.com, Accessed March 7; (2000), http://www.utilitarian.org/wireheading.html; Rice, H., Classes of recursively enumerable sets and their decision problems (1953) Transactions of American Mathematical Society, 74, pp. 358-366; Ring, M., Orseau, L., Delusion, Survival, and Intelligent Agents (2011) Paper Presented at the Fourth International Conference on Artificial General Intelligence, , August 3-6, Mountain View, CA; Schrôdinger, E., Die gegenwärtige Situation in der Quantenmechanik (1935) Naturwissenschaften, 23 (48), pp. 807-812. , November; Steunebrink, B., Schmidhuber, J., A Family of Gödel Machine Implementations (2011) Paper Presented at the Fourth Conference on Artificial General Intelligence (AGI-11), , August 3-6, Mountain View, California; Stoklosa, T., Super intelligence (2010) Nature, 467, p. 878; Turing, A.M., On computable numbers, with an application to the entscheidungs problem (1936) Proceedings of the London Mathematical Society, 42, pp. 230-265; Tyler, T., (2011) Rewards versus Goals, , http://matchingpennies.com/rewards_vs_goals/; Tyler, T., (2011) Utility Counterfeiting, , http://matchingpennies.com/utility_counterfeiting; Tyler, T., (2011) The Wirehead Problem, , http://alife.co.uk/essays/the_wirehead_problem/; Wagman, B., Stephens, T., Surprising “ultra-conserved” regions discovered in human genome (2004) UC Santa Cruz Currents Online, , http://currents.ucsc.edu/03-04/05-10/genome.html; Welch, C., (2011) Discussion of Pavlov’s AI—What Did It Mean?, , http://physicsandcake.wordpress.com/2011/01/22/pavlovs-ai-what-did-it-mean/; (2012), http://wiki.lesswrong.com/wiki/Wireheading; (2006) The Open-Source Wish Project, , http://www.homeonthestrange.com/phpBB2/viewforum.php?f=4; Wolfram, S., (2002) A New Kind of Science, , May 14, Oxfordshire, UK: Wolfram Media; Yampolskiy, R.V., AI-Complete CAPTCHAs as zero knowledge proofs of access to an artificially intelligent system (2011) ISRN Artificial Intelligence 271878; Yampolskiy, R.V., Online Poker Security: Problems and Solutions (2007) Paper Presented at the EUROSIS North American Simulation and AI in Games Conference (GAMEON-NA2007), , September 10-12, Gainesville, FL; Yampolskiy, R.V., Behavioral modeling: An overview (2008) American Journal of Applied Sciences, 5 (5), pp. 496-503; Yampolskiy, R.V., Detecting and Controlling Cheating in Online Poker (2008) Paper Presented at the Fifth Annual IEEE Consumer Communications and Networking Conference (CCNC2008), , January 10-12, Las Vegas, NV; Yampolskiy, R.V., Artificial Intelligence Safety Engineering: Why Machine Ethics Is a Wrong Approach (2011) Paper Presented at Philosophy and Theory of Artificial Intelligence (PT-AI2011), , October 3-4, Thessaloniki, Greece; Yampolskiy, R.V., What to Do with the Singularity Paradox? (2011) Paper Presented at Philosophy and Theory of Artificial Intelligence (PT-AI2011), , October 3-4, Thessaloniki, Greece; Yampolskiy, R.V., Leakproofing singularity—artificial intelligence confinement problem (2012) Journal of Consciousness Studies (JCS), 19 (1-2), pp. 194-214; Yampolskiy, R.V., Turing test as a defining feature of AI-Completeness (2013) Artificial Intelligence, Evolutionary Computation and Metaheuristics—In the Footsteps of Alan Turing, pp. 3-17. , edited by Xin-She Yang, New York: Springer; Yampolskiy, R.V., Fox, J., Artificial Intelligence and the Human Mental Model (2012) In the Singularity Hypothesis: A Scientific and Philosophical Assessment, pp. 129-145. , edited by Amnon Eden, Jim Moor, Johnny Soraker, and Eric Steinhart, New York Springer; Yampolskiy, R., Gavrilova, M., Artimetrics: Biometrics for artificial entities (2012) IEEE Robotics and Automation Magazine (RAM), 19 (4), pp. 48-58; Yampolskiy, R.V., Govindaraju, V., Behavioral Biometrics for Recognition and Verification of Game Bots (2007) Paper Presented at the Eighth Annual European Game-On Conference on Simulation and AI in Computer Games (GAMEON’2007), , November 20-22, Bologna, Italy; Yampolskiy, R.V., Govindaraju, V., Behavioral biometrics: A survey and classification (2008) International Journal of Biometric (IJBM), 1 (1), pp. 81-113; Yampolskiy, R.V., Govindaraju, V., Behavioral Biometrics for Verification and Recognition of Malicious Software Agents (2008) Paper Presented at Sensors, and Command, Control, Communications, and Intelligence (C3I) Technologies for Homeland Security and Homeland Defense VII, , March 16-20, SPIE Defense and Security Symposium, Orlando, Florida; Yampolskiy, R.V., Klare, B., Jain, A.K., Face Recognition in the Virtual World: Recognizing Avatar Faces (2012) Paper Presented at the Eleventh International Conference on Machine Learning and Applications (ICMLA’12), , December 12-15, Boca Raton, FL; Yudkowsky, E., (2007) The Hidden Complexity of Wishes, , http://lesswrong.com/lw/ld/the_hidden_complexity_of_wishes/; Yudkowsky, E., Artificial intelligence as a positive and negative factor in global risk (2008) Global Catastrophic Risks, pp. 308-345. , edited by N. Bostrom and M. M. Cirkovic, Oxford, UK: Oxford University Press; Yudkowsky, E., Complex value systems in friendly AI (2011) Artificial General Intelligence, pp. 388-393. , edited by Jürgen Schmidhuber, Kristinn Thórisson, and Moshe Looks, Berlin: Springer; Yudkowsky, E.S., (2001) Creating Friendly AI—The Analysis and Design of Benevolent Goal Architectures, , http://singinst.org/upload/CFAI.html; Zuse, K., (1969) Rechnender Raum. Braunschweig, , Germany: Vieweg; Aaronson, S., Guest column: NP-complete problems and physical reality (2005) ACM Sigact News, 36 (1), pp. 30-52; Ailon, N., Chazelle, B., Clarkson, K.L., Liu, D., Mulzer, W., Seshadhri, C., Self-improving algorithms (2011) SIAM Journal on Computing, 40 (2), pp. 350-375; Ali, N., Schaeffer, D., Yampolskiy, R.V., Linguistic Profiling and Behavioral Drift in Chat Bots (2012) Paper Presented at the Midwest Artificial Intelligence and Cognitive Science Conference, , April 21-22, Cincinnati, OH, 27; Anckaert, B., Madou, M., De Bosschere, K., A model for self-modifying code (2007) Information Hiding, pp. 232-248. , New York: Springer; Anderson, M.L., Oates, T., A review of recent research in metareasoning and metalearning (2007) AI Magazine, 28 (1), p. 12; Archetti, C., Bertazzi, L., Grazia Speranza, M., Reoptimizing the traveling salesman problem (2003) Networks, 42 (3), pp. 154-159; Ashby, L.H., Yampolskiy, R.V., Genetic Algorithm and Wisdom of Artificial Crowds Algorithm Applied to Light Up (2011) Paper Presented at the 16Th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, , July 27-30, Educational and Serious Games, Louisville, KY; Ausiello, G., Bonifáci, V., Escoffier, B., (2011) Complexity and Approximation in Reoptimization, , London: Imperial College Press/World Scientific; Ausiello, G., Escoffier, B., Monnot, J., Paschos, V.T., Reoptimization of minimum and maximum traveling salesman’s tours (2006) Algorithm Theory-Swat 2006, pp. 196-207. , New York: Springer; Beck, M.B., Rouchka, E.C., Yampolskiy, R.V., Finding data in DNA: Computer forensic investigations of living organisms (2013) Digital Forensics and Cyber Crime, pp. 204-219. , edited by Marcus Rogers and Kathryn C. Seigfried-Spellar, Berlin: Springer; Beck, M., Yampolskiy, R., DNA as a medium for hiding data (2012) BMC Bioinformatics, 13, pp. A23; Bekenstein, J.D., Information in the holographic universe (2003) Scientific American, 289 (2), pp. 58-65; Böckenhauer, H.-J., Hromkovič, J., Mömke, T., Widmayer, P., On the hardness of reoptimization (2008) SOFSEM 2008: Theory and Practice of Computer Science, pp. 50-65. , Berlin: Springer; Bolander, T., Logical theories for agent introspection (2003) Computer Science, 70 (5), p. 2002; Bonfante, G., Marion, J.-Y., Reynaud-Plantey, D., A Computability Perspective on Self-Modifying Programs (2009) Paper Presented at the Seventh IEEE International Conference on Software Engineering and Formal Methods, , November 23-27, Hanoi, Vietnam; Bostrom, N., What is a singleton? (2006) Linguistic and Philosophical Investigations, 5 (2), pp. 48-54; Bostrom, N., (2014) Superintelligence: Paths, Dangers, Strategies, , Oxford, UK: Oxford University Press; Bremermann, H.J., Quantum noise and information (1967) Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, 4, pp. 15-20; Burks, A.W., Von Neumann, J., (1966) Theory of Self-Reproducing Automata, , Chicago: University of Illinois Press; Chalmers, D., The singularity: A philosophical analysis (2010) Journal of Consciousness Studies, 17, pp. 7-65; Cheng, B.H.C., De Lemos, R., Giese, H., Inverardi, P., Magee, J., Andersson, J., Becker, B., Cukic, B., Software engineering for self-adaptive systems: A research roadmap (2009) Software Engineering for Self-Adaptive Systems, pp. 1-26. , edited by Betty H. C. Cheng, Rogerio De Lemos, Holger Giese, Paola Inverardi, and Jeff Magee, New York: Springer; Conitzer, V., Sandholm, T., Definition and complexity of some basic metareasoning problems (2003) Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pp. 613-618; De Garis, H., The 21st century artilect: Moral dilemmas concerning the ultra intelligent machine (1990) Revue Internationale De Philosophie, 44 (172), pp. 131-138; Einstein, A., Does the inertia of a body depend upon its energy-content? (1905) Annalen Der Physik, 18, pp. 639-641; Fallenstein, B., Soares, N., Problems of Self-Reference in Self Improving Space-Time Embedded Intelligence (2014) MIRI Technical Report, , https://intelligence.org/wp-content/uploads/2014/05/Fallenstein-Soares-Problems-of-self-reference-in-self-improving-space-time-embedded-intelligence.pdf; Fox, D., The limits of intelligence (2011) Scientific American, 305 (1), pp. 36-43; Gagliolo, M., Universal search (2007) Scholarpedia, 2 (11), p. 2575; Gavrilova, M.L., Yampolskiy, R.V., State-of-the-art in robot authentication [From the Guest Editors]. Robotics and Automation Magazine (2010) IEEE, 17 (4), pp. 23-24; Good, I.J., Speculations concerning the first ultraintelligent machine (1966) Advances in Computers, 6, pp. 31-88; Hall, J.S., Engineering utopia (2008) Frontiers in Artificial Intelligence and Applications, 171, p. 460; Hall, J.S., VARIAC: An autogenous cognitive architecture (2008) Frontiers in Artificial Intelligence and Applications, 171, p. 176; Hall, J.S., Self-improving AI: An analysis (2007) Minds and Machines, 17 (3), pp. 249-259; Heylighen, F., Brain in a vat cannot break out (2012) Journal of Consciousness Studies, 19 (1-2), pp. 1-2; Hutter, M., Universal algorithmic intelligence: A mathematical top-down approach (2007) Artificial General Intelligence, pp. 227-290. , edited by B. Goertzer and C. Pennachin, Berlin: Springer; Hutter, M., Can intelligence explode? (2012) Journal of Consciousness Studies, 19 (1-2), pp. 1-2; Khalifa, A.B., Yampolskiy, R.V., GA with wisdom of artificial crowds for solving mastermind satisfiability problem (2011) International Journal of Intelligent Games and Simulation, 6 (2), p. 6; Kolmogorov, A.N., Three approaches to the quantitative definition of information (1965) Problems of Information Transmission, 1 (1), pp. 1-7; Krauss, L.M., Starkman, G.D., (2004) Universal Limits on Computation; Leon, J., Lori, A., Continuous self-evaluation for the self-improvement of software (2001) Self-Adaptive Software, 1936, pp. 27-39; Wrong, L., (2014) Acausal Trade, , http://wiki.lesswrong.com/wiki/Acausal_trade, Accessed. September 29; Levin, L., Universal search problems (1973) Problems of Information Transmission, 9 (3), pp. 265-266; Lloyd, S., Ultimate physical limits to computation (2000) Nature, 406, pp. 1047-1054; Loosemore, R., Goertzel, B., Why an intelligence explosion is probable (2012) Singularity Hypotheses, pp. 83-98. , edited by Amnon H. Eden, James H. Moor, Johnny H. Soraker, and Eric Steinhart, Berlin: Springer; Mahoney, M., (2008) Is There a Model for RSI? SL4, , http://www.sl4.org/archive/0806/18997.html, June 15; Mahoney, M., (2008) Is There a Model for RSI? SL4, , http://www.sl4.org/archive/0806/19028.html, June 20; Mahoney, M., (2010) A Model for Recursively Self Improving Programs, , http://mattmahoney.net/rsi.pdf; Majot, A.M., Yampolskiy, R.V., AI Safety Engineering through Introduction of Self-Reference into Felicific Calculus via Artificial Pain and Pleasure (2014) Paper Presented at the 2014 IEEE International Symposium on Ethics in Science, , May 23-24, Chicago; Mavrogiannopoulos, N., Kisserli, N., Preneel, B., A taxonomy of self-modifying code for obfuscation (2011) Computers and Security, 30 (8), pp. 679-691; Melkikh, A.V., The no free lunch theorem and hypothesis of instinctive animal behavior (2014) Artificial Intelligence Research, 3 (4), p. 43; Minsky, M., Artificial intelligence (1966) Scientific American, 215 (3), pp. 247-260; Muehlhauser, L., Salamon, A., Intelligence explosion: Evidence and import (2012) Singularity Hypotheses, pp. 15-42. , edited by Amnon H. Eden, James H. Moor, Johnny H. Soraker, and Eric Steinhart, Berlin: Springer; Nivel, E., Kristinn, R.T., Self-Programming: Operationalizing Autonomy (2008) Paper Presented at Proceedings of the 2Nd Conference on Artificial General Intelligence, , Arlington, VA, March 6-9, 2009; Nivel, E., Thórisson, K.R., Steunebrink, B.R., Dindo, H., Pezzulo, G., Rodriguez, M., Hernandez, C., Sanz, R., (2013) Bounded Recursive Self-Improvement; Omohundro, S.M., The Nature of Self-Improving Artificial Intelligence (2007) Paper Presented at the Singularity Summit, , September 8-9, San Francisco; Omohundro, S., Rational artificial intelligence for the greater good (2012) Singularity Hypotheses, pp. 161-179. , edited by Amnon H. Eden, James H. Moor, Johnny H. Soraker, and Eric Steinhart, Berlin: Springer; Orseau, L., Ring, M., Self-Modification and Mortality in Artificial Agents (2011) Paper Presented at the Fourth International Conference on Artificial General Intelligence, , August 3-6, Mountain View, CA; Pearce, D., The biointelligence explosion (2012) Singularity Hypotheses, pp. 199-238. , edited by Amnon H. Eden, James H. Moor, Johnny H. Soraker, and Eric Steinhart, Berlin: Springer; Petrean, L., Polymorphic and metamorphic code applications in portable executable files protection (2010) Acta Technica Napocensis, 51 (1), pp. 1-6; Port, A.C., Yampolskiy, R.V., Using a GA and Wisdom of Artificial Crowds to Solve Solitaire Battleship Puzzles (2012) Paper Presented at the 17Th International Conference on Computer Games (CGAMES), , July 30-August 1, Louisville, KY: IEEE; Rice, H.G., Classes of recursively enumerable sets and their decision problems (1953) Transactions of the American Mathematical Society, 74 (2), pp. 358-366; Sandberg, A., The physics of information processing superobjects: Daily life among the Jupiter brains (1999) Journal of Evolution and Technology, 5 (1), pp. 1-34; Schaeffer, J., Burch, N., Bjornsson, Y., Kishimoto, A., Muller, M., Lake, R., Paul, L., Sutphen, S., Checkers is solved (2007) Science, 317 (5844), pp. 1518-1522; Schaul, T., Schmidhuber, J., (2010) Metalearning. Scholarpedia, 5 (6), p. 4650; Schmidhuber, J., A general method for incremental self-improvement and multiagent learning (1999) Evolutionary Computation, pp. 81-123. , Theory and Applications, X. Yao, Ed., Singapore: World Publishing; Schmidhuber, J., Optimal ordered problem solver (2004) Machine Learning, 54 (3), pp. 211-254; Schmidhuber, J., Completely self-referential optimal reinforcement learners (2005) Artificial Neural Networks: Formal Models and Their Applications—ICANN2005, pp. 223-233. , edited by Włodzisław Duch, Janusz Kacprzyk, Erkki Oja and Sławomir Zadrożny. Lecture Notes in Computer Science, Springer Berlin Heidelberg; Schmidhuber, J., Gödel machines: Self-referential universal problem solvers making provably optimal self-improvements (2005) Artificial General Intelligence, pp. 199-227. , edited by Ben Goertzel and Cassio Pennachin, Berlin, Germany: Springer-Verlag; Schmidhuber, J., Gödel machines: Towards a technical justification of consciousness (2005) Adaptive Agents and Multi-Agent Systems II, pp. 1-23. , edited by Daniel Kudenko, Dimitar Kazakov, and Eduardo Alonso, Berlin: Springer; Schmidhuber, J., Gödel machines: Fully self-referential optimal universal self-improvers (2007) Artificial General Intelligence, pp. 199-226. , edited by Ben Goertzel and Cassio Pennachin, Berlin, Germany: Springer-Verlag; Schmidhuber, J., Ultimate cognition à la Gödel (2009) Cognitive Computation, 1 (2), pp. 177-193; Schmidhuber, J., Zhao, J., Wiering, M., Shifting inductive bias with success-story algorithm, adaptive Levin search, and incremental self-improvement (1997) Machine Learning, 28 (1), pp. 105-130; Shahaf, D., Amir, E., Towards a Theory of AI Completeness (2007) Paper Presented at the Eighth International Symposium on Logical Formalizations of Commonsense Reasoning (Commonsense 2007), , March 26-28, Stanford, CA; Shannon, C.E., A mathematical theory of communication (1948) Bell Systems Technical Journal, 27 (3), pp. 379-423; Smart, J.M., Evo devo universe? A framework for speculations on cosmic culture (2009) Cosmos and Culture: Cultural Evolution in a Cosmic Context, pp. 201-295. , edited by Mark L. Lupisella and Steven J. Dick, Washington, DC: US Government Printing Office. NASA SP-2009-4802; Sotala, K., Advantages of artificial intelligences, uploads, and digital minds (2012) International Journal of Machine Consciousness, 4 (1), pp. 275-291; Sotala, K., Yampolskiy, R.V., Responses to catastrophic AGI risk: A survey (2015) Physica Scripta, p. 90; Steunebrink, B., Schmidhuber, J., A Family of Gödel Machine Implementations (2011) Paper Presented at the Fourth Conference on Artificial General Intelligence (AGI-11), , August 3-6, Mountain View, CA; Stewart, J.E., The meaning of life in a developing universe (2010) Foundations of Science, 15 (4), pp. 395-409; Tipler, F.J., (1994) The Physics of Immortality: Modern Cosmology, God, and the Resurrection of the Dead, , New York: Random House; Turchin, V.F., The concept of a supercompiler (1986) ACM Transactions on Programming Languages and Systems (TOPLAS), 8 (3), pp. 292-325; Turing, A., Computing machinery and intelligence (1950) Mind, 59 (236), pp. 433-460; Turing, A., On computable numbers, with an application to the Entscheidungs problem (1936) Proceedings of the London Mathematical Society, 2 (42), pp. 230-265; Vidal, C., (2013) The Beginning and The End: The Meaning of Life in a Cosmological Perspective; Waser, M.R., Bootstrapping a Structured Self-Improving and Safe Autopoietic Self (2014) Paper Presented at the Annual International Conference on Biologically Inspired Cognitive Architectures, , November 9, Boston; Wheeler, J.A., (1990) Information, Physics, Quantum: The Search for Links, , Austin: University of Texas; Wiedermann, J., A computability argument against superintelligence (2012) Cognitive Computation, 4 (3), pp. 236-245; Wiedermann, J., Is there something beyond AI? Frequently emerging, but seldom answered questions about artificial super-intelligence (2012) Beyond AI: Artificial Dreams, pp. 76-86. , edited by J. Jomportl, I. Pavel, E. Zackova, M. Polak, and R. Schuster, Pilsen, Czech: University of West Bohemia; Wolfram, S., (2002) A New Kind of Science, , May 14, Oxfordshire, UK: Wolfram Media; Wolpert, D.H., Macready, W.G., No free lunch theorems for optimization (1997) IEEE Transactions on Evolutionary Computation, 1 (1), pp. 67-82; Yampolskiy, R.V., AI-Complete CAPTCHAs as Zero Knowledge Proofs of Access to an Artificially Intelligent System (2011) ISRN Artificial Intelligence 271878; Yampolskiy, R.V., Ahmed, E.L.B., Wisdom of artificial crowds algorithm for solving NP-hard problems International Journal of Bio-Inspired Computation (IJBIC), 3 (6), pp. 358-369; Yampolskiy, R., Anderson, P., Arney, J., Misic, V., Clarke, T., Printer Model Integrating Genetic Algorithm for Improvement of Halftone Patterns (2004) Paper Presented at the Western New York Image Processing Workshop (WNYIPW), , September 24, IEEE Signal Processing Society, Rochester, NY; Yampolskiy, R., Cho, G., Rosenthal, R., Gavrilova, M., Experiments in Artimetrics: Avatar Face Recognition (2012) Transactions on Computational Science, 16, pp. 77-94; Yampolskiy, R., Joshua, F., 2012. Safety engineering for artificial general intelligence Topoi, 32 (2), pp. 217-226. , October 2013; Yampolskiy, R., Gavrilova, M., Artimetrics: Biometrics for artificial entities (2012) IEEE Robotics and Automation Magazine (RAM), 19 (4), pp. 48-58; Yampolskiy, R.V., (2011) Construction of an NP Problem with an Exponential Lower Bound; Yampolskiy, R.V., AI-Complete, AI-Hard, or AI-Easy—Classification of Problems in AI (2012) Paper Presented at the 23Rd Midwest Artificial Intelligence and Cognitive Science Conference, pp. 21-22. , Cincinnati, OH; Yampolskiy, R.V., Computing Partial Solutions to Difficult AI Problems (2012) Paper Presented at the 23Rd Midwest Artificial Intelligence and Cognitive Science Conference, , April 21-22, Cincinnati, OH; Yampolskiy, R.V., Leakproofing singularity-artificial intelligence confinement problem (2012) Journal of Consciousness Studies (JCS), 19 (1-2), pp. 194-214; Yampolskiy, R.V., Artificial intelligence safety engineering: Why machine ethics is a wrong approach (2013) Philosophy and Theory of Artificial Intelligence, pp. 389-396. , edited by Vincent C. Müller, Berlin: Springer; Yampolskiy, R.V., Efficiency theory: A unifying theory for information, computation and intelligence (2013) Journal of Discrete Mathematical Sciences and Cryptography, 16 (4-5), pp. 259-277; Yampolskiy, R.V., What to do with the singularity paradox? (2013) Philosophy and Theory of Artificial Intelligence, pp. 397-413. , Berlin: Springer; Yampolskiy, R.V., Turing test as a defining feature of AI-Completeness (2013) Artificial Intelligence, Evolutionary Computing and Metaheuristics, pp. 3-17. , edited by Xin-She Yang, Berlin: Springer; Yampolskiy, R.V., (2014) The Universe Ofminds; Yampolskiy, R.V., Utility function security in artificially intelligent agents (2014) Journal of Experimental and Theoretical Artificial Intelligence (JETAI), 26 (3), pp. 373-389; Yampolskiy, R.V., Ashby, L., Hassan, L., Wisdom of artificial crowds—a metaheuristic algorithm for optimization (2012) Journal of Intelligent Learning Systems and Applications, 4 (2), pp. 98-107; Yampolskiy, R.V., Fox, J., Artificial general intelligence and the human mental model (2012) Singularity Hypotheses: A Scientific and Philosophical Assessment, p. 129. , edited by Amnon H. Eden, James H. Moor, Johnny H. Soraker, and Eric Steinhart, Berlin: Springer; Yonck, R., Toward a standard metric of machine intelligence (2012) World Future Review, 4 (2), pp. 61-70; Yudkowsky, E., Levels of organization in general intelligence (2007) Artificial General Intelligence, pp. 389-501. , edited by B. Goertzer and C. Pennachin, Berlin: Springer; Yudkowsky, E., Recursive Self-Improvement (2008) Less Wrong, , http://lesswrong.com/lw/we/recursive_selfimprovement/, December 1, Accessed September 29, 2014; Yudkowsky, E., (2010) Timeless Decision Theory, , San Francisco: Singularity Institute; Yudkowsky, E., (2013) Intelligence Explosion Microeconomics, , http://www.intelligence.org/files/IEM.pdf, MIRI Technical Report 2013-1. Berkeley, CA: Machine Intelligence Research Institute; Yudkowsky, E., The Procrastination Paradox (Brieftechnical note) (2014) MIRI Technical Report, , https://intelligence.org/files/ProcrastinationParadox.pdf; Yudkowsky, E., Hanson, R., The Hanson-Yudkowsky AI-Foom Debate (2008) MIRI Technical Report, , http://intelligence.org/files/AIFoomDebate.pdf; Yudkowsky, E., Herreshoff, M., Tiling Agents for SelfModifying AI, and the Löbian Obstacle (2013) MIRI Technical Report, , http://intel-ligence.org/files/TilingAgentsDraft.pdf; Yudkowsky, E.S., (2001) General Intelligence and Seed AI—Creating Complete Minds Capable of Open-Ended Self-Improvement, , http://singinst.org/ourresearch/publications/GISAI/; Yudkowsky, E.S., Coherent Extrapolated Volition (2004) Singularity Institute for Artificial Intelligence, , http://singinst.org/upload/CEV.html, May; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) IEEE Intelligent Systems 21(4), 1217. , July/August; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-26; Armstrong, S., Chaining God: A Qualitative Approach to AI, Trust and Moral Systems (2007) New European Century, , http://www.neweuropeancen-tury.org/GodAI.pdf; Asimov, I., Runaround (1942) Astounding Science Fiction, , March; Bancel, P., Nelson, R., The GCP event experiment: Design, analytical methods, results (2008) Journal of Scientific Exploration, 22 (4), pp. 309-333; Benford, G., Me/Days (1988) Alien Flesh, , London: Gollancz; Benford, A., (2009) Artificial Intelligence Will Kill Our Grandchildren, , http://berglas.org/Articles/AIKillGrandchildren/AIKillGrandchildren.html, February 22; Bishop, M., Why computers can’t feel pain (2009) Minds and Machines, 19 (4), pp. 507-516; Bostrom, N., Ethical issues in advanced artificial intelligence (2006) Review of Contemporary Philosophy, 68 (5), pp. 66-73; Bostrom, N., (2008) Oracle AI, , http://lesswrong.com/lw/qv/the_rhythm_of_disagreement/; Bostrom, N., Yudkowsky, E., The ethics of artificial intelligence (2011) Cambridge Handbook of Artificial Intelligence, , http://www.nickbostrom.com/ethics/artificial-intelligence.pdf, edited by William Ramsey and Keith Frankish. Cambridge, UK: Cambridge University Press; Brin, D., (1987) Lungfish, , http://www.davidbrin.com/lungfish1.htm; Bugaj, S., Goertzel, B., Five ethical imperatives and their implications for human-AGI interaction (2007) Dynamical Psychology, , http://goertzel.org/dynapsyc/2007/Five_Ethical_Imperatives_svbedit.htm; Butler, S., (1863) Darwin among the Machines [To the Editor of the Press], , June 13, The Press, Christchurch, New Zealand; Chalmers, D., The singularity: A philosophical analysis (2010) Journal of Consciousness Studies, 17, pp. 7-65; De Garis, H., (2005) The Artilect War, , Palm Springs, CA: ETC; Dennett, D.C., Why you can’t make a computer that feels pain (1978) Synthese, 38 (3), pp. 415-456. , July; Dietrich, E., After the humans are gone (2007) Journal of Experimental and Theoretical Artificial Intelligence, 19 (1), pp. 55-67; Drexler, E., (1986) Engines of Creation, , Norwell, MA: Anchor Press; Epstein, R.G., (1997) Computer Psychologists Command Big Bucks, , http://www.cs.wcupa.edu/~epstein/comppsy.htm; Fox, J., Shulman, C., Superintelligence Does Not Imply Benevolence (2010) Paper Presented at the Eighth European Conference on Computing and Philosophy, , October 4-6, Munich, Germany; Freeman, T., (2009) Using Compassion and Respect to Motivate an Artificial Intelligence, , http://www.fungible.com/respect/paper.html; Gavrilova, M., Yampolskiy, R., Applying Biometric Principles to Avatar Recognition (2010) Paper Presented at the International Conference on Cyberworlds (CW2010), , October 20-22, Singapore; Geraci, R.M., Spiritual robots: Religion and our scientific view of the natural world (2006) Theology and Science, 4 (3), pp. 229-246; Geraci, R.M., Religion for the robots (2007) Sightings, , http://divinity.uchicago.edu/martycenter/publications/sightings/archive_2007/0614.shtml, June 14, Chicago: Martin Marty Center at the University of Chicago; Geraci, R.M., Apocalyptic AI: Religion and the promise of artificial intelligence (2008) Journal of the American Academy of Religion, 76 (1), pp. 138-166; Gibson, W., (1984) Neuromancer, , New York: Ace Science Fiction; Goertzel, B., Thoughts on AI morality (2002) Dynamical Psychology, , http://www.goertzel.org/dynapsyc; Goertzel, B., The all-seeing (A)I (2004) Dynamic Psychology, , http://www.goertzel.org/dynapsyc; Goertzel, B., Encouraging a positive transcension (2004) Dynamical Psychology, , http://www.goertzel.org/dynapsyc/2004/PositiveTranscension.htm; Goertzel, B., (2006) Apparent Limitations on the “AI Friendliness” and Related Concepts Imposed by the Complexity of the World, , http://www.goertzel.org/papers/LimitationsOnFriendliness.pdf, September; Good, I.J., Speculations concerning the first ultraintelligent machine (1966) Advances in Computers, 6, pp. 31-88; Gordon, D.F., Well-Behaved Borgs, Bolos, and Berserkers (1998) Paper Presented at the 15Th International Conference on Machine Learning (ICML98), , San Francisco; Gordon-Spears, D., Assuring the behavior of adaptive agents (2004) Agent Technology from a Formal Perspective, pp. 227-257. , edited by Christopher A. Rouff et al., Dordrecht, the Netherlands: Kluwer; Gordon-Spears, D.F., 2003. Asimov’s laws: Current progress (2003) Lecture Notes in Computer Science, 2699, pp. 257-259; Hall, J.S., (2000) Ethics for Machines, , http://autogeny.org/ethics.html, Hall, Storrs, Ethics for Machines; Hanson, R., Economics of the singularity (2008) IEEE Spectrum, 45 (6), pp. 45-50. , June; Hanson, R., (2009) Prefer Law to Values, , http://www.overcoming-bias.com/2009/10/prefer-law-to-values.html, October 10; Hawking, S., Science in the next millennium (1998) Presentation at the Second Millennium Evening at the White House, , March 6, Washington, DC; Hibbard, B., Super-intelligent machines (2001) Computer Graphics, 35 (1), pp. 11-13; Hibbard, B., (2003) Critique of the SIAI Guidelines on Friendly AI, , http://www.ssec.wisc.edu/~billh/g/SIAI_critique.html; Hibbard, B., (2005) The Ethics and Politics of Super-Intelligent Machines, , http://www.ssec.wisc.edu/~billh/g/SI_ethics_politics.doc, July; Hibbard, B., (2005) Critique of the SIAI Collective Volition Theory, , http://www.ssec.wisc.edu/~billh/g/SIAI_CV_critique.html, December; Horvitz, E., Selman, B., (2009) Interim Report from the AAAI Presidential Panel on Long-Term AI Futures, , http://www.aaai.org/Organization/Panel/panel-note.pdf, August; De Garis, H., (1999), http://en.wikipedia.org/wiki/Hugo_de_Garis; Joy, B., Why the future doesn’t need us (2000) Wired Magazine, 8 (4). , http://archive.wired.com/wired/archive/8.04/joy.html, April; Kaczyński, T., (1995) Industrial Society and Its Future, , September 19, New York Times; Kaczynski, T., The Unabomber Manifesto: Industrial Society and Its Future, , Filiquarian Publishing, LLC; Kurzweil, R., (2005) The Singularity is Near: When Humans Transcend Biology, , New York: Viking Press; Legg, S., (2006) Friendly AI is Bunk. in Vetta Project, , http://commonsen-seatheism.com/wp-content/uploads/2011/02/Legg-Friendly-AI-is-bunk.pdf; Lin, P., Abney, K., Bekey, G., Robot ethics: Mapping the issues for a mechanized world (2011) Artificial Intelligence, 175 (5-6), pp. 942-949; McCauley, L., AI Armageddon and the three laws of robotics (2007) Ethics and Information Technology, 9 (2), pp. 153-164; Menzel, P., D’Aluisio, F., (2001) Robo Sapiens Evolution of a New Species, , Cambridge, MA: MIT Press; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems 21(4), 1821. , July/August; Nagel, T., What is it like to be a bat? (1974) Philosophical Review, 83 (4), pp. 435-450; Omohundro, S.M., The Nature of Self-Improving Artificial Intelligence (2007) Paper Presented at the Singularity Summit, , September 8-9, San Francisco; Omohundro, S.M., The Basic AI Drives (2008) Proceedings of the First AGI Conference, Volume 171, Frontiers in Artificial Intelligence and Applications, pp. 483-492. , February, edited by P. Wang, B. Goertzel, and S. Franklin, Amsterdam: IOS Press; Pynadath, D.V., Milind, T., Revisiting Asimov’s first law: A response to the call to arms (2002) Intelligent Agents VIII, Lecture Notes in Computer Science, pp. 307-320; (2011) Singularity Institute for Artificial Intelligence, , http://singinst.org/riskintro/index.html, San Francisco; Sawyer, R.J., Robot ethics (2007) Science, p. 318. , November 16; Sharkey, N., The ethical frontiers of robotics (2008) Science, 322, pp. 1800-1801. , December 19; Shulman, C., Jonsson, H., Tarleton, N., Machine Ethics and Superintelligence (2009) Paper Presented at the Fifth Asia-Pacific Computing and Philosophy Conference, , October 1-2, Tokyo; Shulman, C., Tarleton, N., Jonsson, H., Which Consequentialism? Machine Ethics and Moral Divergence (2009) Paper Presented at the Asia-Pacific Conference on Computing and Philosophy (APCAP’09), , October 1-2, Tokyo; Solomonoff, R.J., The time scale of artificial intelligence: Reflections on social effects (1985) North-Holland Human Systems Management, 5, pp. 149-153; Sotala, K., Evolved Altruism, Ethical Complexity, Anthropomorphic Trust: Three Factors Misleading Estimates of the Safety of Artificial General Intelligence (2009) Paper Presented at the Seventh European Conference on Computing and Philosophy (ECAP’09), , Barcelona, Spain, July 2-4, 2009; Sotala, K., Yampolskiy, R.V., Responses to catastrophic AGI risk: A survey (2015) Physica Scripta No. 90:018001, , January; (2008) IEEE Spectrum, , http://spectrum.ieee.org/computing/hardware/tech-luminaries-address-singularity, June, Special Report: The Singularity; (2015), http://en.wikipedia.org/wiki/Three_Laws_of_Robotics, Last modified January 14; Tonkens, R., A challenge for machine ethics (2009) Minds and Machines, 19 (3), pp. 421-438; Turing, A., Computing machinery and intelligence (1950) Mind, 59 (236), pp. 433-460; Turing, A.M., Intelligent machinery, a heretical theory (1996) Philosophia Mathematica, 4 (3), pp. 256-260; Turney, P., Controlling super-intelligent machines (1991) Canadian Artificial Intelligence 27:3, 4 (12), p. 35; Vinge, V., The Coming Technological Singularity: How to Survive in the Post-human Era (1993) Paper Presented at Vision 21: Interdisciplinary Science and Engineering in the Era of Cyberspace, , https://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html, March 30-31, Cleveland, OH; Warwick, K., Cyborg morals, cyborg values, cyborg ethics (2003) Ethics and Information Technology, 5, pp. 131-137; Waser, M., Deriving a Safe Ethical Architecture for Intelligent Machines (2010) Paper Presented at the Eighth Conference on Computing and Philosophy (ECAP’10), , October 4-6, Münich, Germany; Waser, M.R., Discovering the Foundations of a Universal System of Ethics as a Road to Safe Artificial Intelligence (2008) AAAI Technical Report FS-08-04, , Menlo Park, CA: AAAI; Waser, M.R., Designing a Safe Motivational System for Intelligent Machines (2010) Paper Presented at the Third Conference on Artificial General Intelligence, , March 5-8, Lugano, Switzerland; Weld, D.S., Etzioni, O., The First Law of Robotics (A Call to Arms) (1994) Paper Presented at the Twelfth National Conference on Artificial Intelligence (AAAI), , July 31-August 4, Seattle, WA; Yampolskiy, R.V., Govindaraju, V., Behavioral Biometrics for Recognition and Verification of Game Bots (2007) Paper Presented at the Eighth Annual European Game-On Conference on Simulation and AI in Computer Games (GAMEON’2007), , November 20-22, Bologna, Italy; Yampolskiy, R.V., Govindaraju, V., Behavioral Biometrics for Verification and Recognition of Malicious Software Agents (2008) Paper Presented at Sensors, and Command, Control, Communications, and Intelligence (C3I) Technologies for Homeland Security and Homeland Defense VII, , March 16-20, SPIE Defense and Security Symposium, Orlando, FL; Yampolskiy, R.V., Behavioral Biometrics for Verification and Recognition of AI Programs (2007) Paper Presented at the 20Th Annual Computer Science and Engineering Graduate Conference (Gradconf2007), , April 13, Buffalo, NY; Yampolskiy, R.V., Leakproofing the singularity: Artificial intelligence confinement problem (2012) Journal of Consciousness Studies, 19 (2), pp. 194-214; Yudkowsky, E., (2005) What is Friendly AI?, , http://singinst.org/ourresearch/publications/what-is-friendly-ai.html; Yudkowsky, E., Artificial intelligence as a positive and negative factor in global risk (2008) Global Catastrophic Risks, pp. 308-345. , edited by N. Bostrom and M. M. Cirkovic, Oxford, UK: Oxford University Press; Yudkowsky, E.S., (2001) Creating Friendly AI—The Analysis and Design of Benevolent Goal Architectures, , http://singinst.org/upload/CFAI.html; Yudkowsky, E.S., (2001) General Intelligence and Seed AI—Creating Complete Minds Capable of Open-Ended Self-Improvement, , http://sin-ginst.org/ourresearch/publications/GISAI/; Yudkowsky, E.S., (2002) The Ai-Box Experiment, , http://yudkowsky.net/singularity/aibox; Yudkowsky, E.S., Coherent Extrapolated Volition (2004) Singularity Institute for Artificial Intelligence, , http://singinst.org/upload/CEV.html, May; Yudkowsky, E.S., Three Major Singularity Schools (2007) Singularity Institute Blog, , http://yudkowsky.net/singularity/schools, September; Ajina, S., Yampolskiy, R.V., Essoukri, N., Amara, B., SVM Classification of Avatar Facial Recognition (2011) Paper Presented at the Eighth International Symposium on Neural Networks (ISNN2011), , May 29-June 1, Guilin, China; Ali, N., Hindi, M., Yampolskiy, R.V., Evaluation of Authorship Attribution Software on a Chat Bot Corpus (2011) Paper Presented at the 23Rd International Symposium on Information, Communication and Automation Technologies (ICAT2011), pp. 1-6. , October 27-29, Sarajevo, Bosnia and Herzegovina; Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics and Information Technology, 7 (3), pp. 149-155; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12, pp. 251-261; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) IEEE Intelligent Systems, 21 (4), pp. 12-17. , July/August; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-26; Bishop, M., Why computers can’t feel pain (2009) Minds and Machines, 19 (4), pp. 507-516; Bostrom, N., (2008) Oracle AI, , http://lesswrong.com/lw/qv/the_rhythm_of_disagreement/; Bouhhris, M., Beck, M., Mohamed, A.A., Artificial Human-Face Recognition via Daubechies Wavelet Transform and SVM (2011) Paper Presented at the 16Th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, pp. 18-25. , July 27-30, Educational and Serious Games, Louisville, KY; Butler, S., (1863) Darwin among the Machines [To the Editor of the Press], , June 13, The Press, Christchurch, New Zealand; Chalmers, D., The singularity: A philosophical analysis (2010) Journal of Consciousness Studies, 17, pp. 7-65; Dennett, D.C., Why you can’t make a computer that feels pain (1978) Synthese, 38 (3), pp. 415-456. , July; Drexler, E., (1986) Engines of Creation, , New York: Anchor Press; Epstein, R.G., (1997) Computer Psychologists Command Big Bucks, , http://www.cs.wcupa.edu/~epstein/comppsy.htm; Gavrilova, M., Yampolskiy, R., Applying Biometric Principles to Avatar Recognition (2010) Paper Presented at the International Conference on Cyberworlds (CW2010), , October 20-22, Singapore; Gordon, D.F., Well-Behaved Borgs, Bolos, and Berserkers (1998) Paper Presented at the 15Th International Conference on Machine Learning (ICML98), , San Francisco; Gordon-Spears, D., Assuring the behavior of adaptive agents (2004) Agent Technology from a Formal Perspective, pp. 227-259. , edited by Christopher A. Rouff et al., Dordrecht, the Netherlands; Gordon-Spears, D.F., 2003. Asimov’s laws: Current progress (2003) Lecture Notes in Computer Science, 2699, pp. 257-259; Grau, C., There is no “I” in “robot”: Robots and utilitarianism (2006) IEEE Intelligent Systems, 21 (4), pp. 52-55; Guo, S., Zhang, G., (2009) Robot Rights. Science, 323, p. 876. , February 13; Hall, J.S., (2000) Ethics for Machines, , http://autogeny.org/ethics.html, Hall, S; Hall, J.S., Self-Improving AI: An analysis (2007) Minds and Machines, 17 (3), pp. 249-259. , October; Hanson, R., (2009) Prefer Law to Values, , http://www.overcomingbias.com/2009/10/prefer-law-to-values.html, October 10; Joy, B., Why the future doesn’t need us (2000) Wired Magazine, 8 (4). , http://www.usc.edu/molecular-science/timespacerand.pdf, April; Kaczynski, T., (1995) Industrial Society and Its Future, , September 19, New York Times; Lin, P., Abney, K., Bekey, G., Robot ethics: Mapping the issues for a mechanized world (2011) Artificial Intelligence, 175 (5-6), pp. 942-949; Margaret, A., Henry, J., Computer ethics: The role of personal, informal, and formal codes (1996) Journal of Business Ethics, 15 (4), p. 425; McDermott, D., Why Ethics Is a High Hurdle for AI (2008) Paper Presented at the North American Conference on Computers and Philosophy (NACAP’08), , http://cs-www.cs.yale.edu/homes/dvm/papers/ethical-machine.pdf, July, Bloomington, IN; Mohamed, A., D’Souza, D., Baili, N., Yampolskiy, R.V., Avatar Face Recognition Using Wavelet Transform and Hierarchical Multi-scale LBP (2011) Tenth International Conference on Machine Learning and Applications (ICMLA’11), , December 18-21, Honolulu, USA; Mohamed, A., Yampolskiy, R.V., An Improved LBP Algorithm for Avatar Face Recognition (2011) Paper Presented at the 23Rd International Symposium on Information, Communication and Automation Technologies (ICAT2011), , October 27-29, Sarajevo, Bosnia and Herzegovina; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21. , July/August; Powers, T.M., Prospects for a Kantian machine (2006) IEEE Intelligent Systems, 21 (4), pp. 46-51. , July/August; Rappaport, Z.H., Robotics and artificial intelligence: Jewish ethical perspectives (2006) Acta Neurochirurgica, 98, pp. 9-12; Roh, D., Do humanlike machines deserve human rights? (2009) Wired, , http://www.wired.com/culture/culturereviews/magazine/17-02/st_essay, January 19; Ruvinsky, A.I., Computational ethics (2007) Encyclopedia of Information Ethics and Security, pp. 73-76. , edited by Marian Quigley, Hershey, PA: IGI Global; Sawyer, R.J., (2007) Robot Ethics, 318, p. 1037. , November 16; Sharkey, N., The ethical frontiers of robotics (2008) Science, 322, pp. 1800-1801. , December 19; Sparrow, R., (2007) Killer Robots, 24 (1), pp. 62-77; Tonkens, R., A challenge for machine ethics (2009) Minds and Machines, 19 (3), pp. 421-438; Veruggio, G., (2010) Roboethics, 17 (2), pp. 105-109; Wallach, W., Allen, C., (2006) Ethicalife: A New Field of Inquiry. Paper Presented at Ethicalife: Analifex Workshop, , Bloomington, IN. June 3-7; Warwick, K., Cyborg morals, cyborg values, cyborg ethics (2003) Ethics and Information Technology, 5, pp. 131-137; Wendell, W., Colin, A., (2008) Moral Machines: Teaching Robots Right from Wrong., , Oxford, U; Yampolskiy, R.V., Behavioral Biometrics for Verification and Recognition of AI Programs (2007) Paper Presented at the 20Th Annual Computer Science and Engineering Graduate Conference (Gradconf2007), , Buffalo, NY; Yampolskiy, R.V., Leakproofing singularity—artificial intelligence confinement problem (2012) Journal of Consciousness Studies (JCS), 19 (1-2), pp. 194-214; Yampolskiy, R.V., Cho, G., Rosenthal, R., Gavrilova, M.L., Evaluation of Face Detection and Recognition Algorithms on Avatar Face Datasets (2011) Paper Presented at the International Conference on Cyberworlds (CW2011), , October 4-6, Banff, Alberta, Canada; Yampolskiy, R.V., Govindaraju, V., Behavioral Biometrics for Verification and Recognition of Malicious Software Agents (2008) Paper Presented at the Sensors, and Command, Control, Communications, and Intelligence (C3I) Technologies for Homeland Security and Homeland Defense VII, , March 16-20, SPIE Defense and Security Symposium, Orlando, FL; Yampolskiy, R.V., Govindaraju, V., Behavioral Biometrics for Recognition and Verification of Game Bots (2007) Paper Presented at the Eighth Annual European Game-On Conference on Simulation and AI in Computer Games (GAMEON’2007), , November 20-22, Bologna, Italy; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) IEEE Intelligent Systems 21(4), 1217. , July/August; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-26; Armstrong, S., The AI in a box boxes you (2010) Less Wrong, , http://lesswrong.com/lw/1pz/the_ai_in_a_box_boxes_you/, February 2; Bancel, P., Nelson, R., The GCP event experiment: Design, analytical methods, results (2008) Journal of Scientific Exploration, 22 (3), pp. 309-333; Ben, D.J., Honorton, C., Does Psi exist? Replicable evidence for an anomalous process of information transfer (1994) Psychological Bulletin 115(1), 418; Boebert, W.E., Kain, R.Y., A Further Note on the Confinement Problem (1996) Paper Presented at the 30Th Annual 1996 International Carnahan Conference on Security Technology, , October 2-4, Lexington, KY; Bostrom, N., Are you living in a computer simulation? (2003) Philosophical Quarterly, 53 (211), pp. 243-255; Bostrom, N., Ethical issues in advanced artificial intelligence (2006) Review of Contemporary Philosophy, 5, pp. 66-73; Bostrom, N., (2008) Oracle AI, , http://lesswrong.com/lw/qv/the_rhythm_of_disagreement/; Bostrom, N., Information hazards: A typology of potential harms from knowledge (2011) Review of Contemporary Philosophy, 10, pp. 44-79; Bostrom, N., Yudkowsky, E., The ethics of artificial intelligence (2011) Cambridge Handbook of Artificial Intelligence, , http://www.nickbostrom.com/ethics/artificial-intelligence.pdf, edited by William Ramsey and Keith Frankish. Cambridge, UK: Cambridge University Press; Chalmers, D., The singularity: A philosophical analysis (2010) Journal of Consciousness Studies, 17, pp. 7-65; Coleman, E., The surveyability of long proofs (2008) Foundations of Science, 14 (1-2), pp. 27-43; Corwin, J., (2002) AI Boxing, , http://www.sl4.org/archive/0207/4935.html, July 20, SL4.org; Drexler, E., (1986) Engines of Creation, , New York: Anchor Press; Epstein, R.G., (1997) Computer Psychologists Command Big Bucks, , http://www.cs.wcupa.edu/~epstein/comppsy.htm; Gavrilova, M., Yampolskiy, R., Applying Biometric Principles to Avatar Recognition (2010) Paper Presented at the International Conference on Cyberworlds (CW2010), , October 20-22, Singapore; Gentry, C., (2009) A Fully Homomorphic Encryption Scheme, , http://crypto.stanford.edu/craig/craig-the-sis.pdf, September, PhD dissertation, Stanford University; Hall, J.S., (2000) Ethics for Machines, , http://autogeny.org/ethics.html; Hall, J.S., Self-Improving AI: An Analysis (2007) Minds and Machines, 17 (3), pp. 249-259. , October; Hibbard, B., (2005) The Ethics and Politics of Super-Intelligent Machines, , http://www.ssec.wisc.edu/~billh/g/SI_ethics_politics.doc, July; Honorton, C., Ferrari, D.C., Future telling: A metaanalysis of forced-choice precognition experiments, 1935-1987 (1989) Journal of Parapsychology, 53, pp. 281-308. , December; Kemmerer, R.A., Shared resource matrix methodology: An approach to identifying storage and timing channels (1983) ACM Transactions on Computer Systems, 1 (3), pp. 256-277. , August; Kemmerer, R.A., A Practical Approach to Identifying Storage and Timing Channels: Twenty Years Later (2002) Paper Presented at the 18Th Annual Computer Security Applications Conference (ACSAC’02), , December 9-13, Las Vegas, NV; Lampson, B.W., A note on the confinement problem (1973) Communications of the ACM, 16 (10), pp. 613-615. , October; Lipner, S.B., A comment on the confinement problem. 5th Symposium on Operating Systems Principles (1975) ACM Operations Systems Review, 9 (5), pp. 192-196. , November; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21. , July/August; Moskowitz, I.S., Kang, M.H., Covert Channels— Here to Stay? (1994) Paper Presented at the Ninth Annual Conference on Safety, Reliability, Fault Tolerance, Concurrency and Real Time, Security, , June 27-July 1, Computer Assurance (COMPASS’94), Gaithersburg, MD; Provos, N., Honeyman, P., Hide and seek: An introduction to steganography (2003) IEEE Security and Privacy, 1 (3), pp. 32-44. , May-June; Schmidt, S., Schneider, R., Utts, J., Walach, H., Distant intentionality and the feeling of being stared at: Two meta-analyses (2004) British Journal of Psychology, 95 (2), pp. 235-247; Targ, R., Puthoff, H.E., Information transmission under conditions of sensory shielding (1974) Nature, 251, pp. 602-607. , October; Tonkens, R., A challenge for machine ethics (2009) Minds and Machines, 19 (3), pp. 421-438; Vassar, M., (2005) AI Boxing (Dogs and Helicopters), , http://sl4.org/archive/0508/11817.html, August 2; Vinge, V., The Coming Technological Singularity: How to Survive in the Post-human Era (1993) Paper Presented at Vision 21: Interdisciplinary Science and Engineering in the Era of Cyberspace, , March 30-31, Cleveland, OH; Yampolskiy, R.V., Behavioral Biometrics for Verification and Recognition of AI Programs (2007) Paper Presented at the 20Th Annual Computer Science and Engineering Graduate Conference (Gradconf2007), , April 13, Buffalo, NY; Yampolskiy, R.V., Govindaraju, V., Computer security: A survey of methods and systems (2007) Journal of Computer Science, 3 (7), pp. 478-486; Yampolskiy, R.V., Govindaraju, V., Behavioral Biometrics for Recognition and Verification of Game Bots (2007) Paper Presented at the Eighth Annual European Game-On Conference on Simulation and AI in Computer Games (GAMEON’2007), , November 20-22, Bologna, Italy; Yampolskiy, R.V., Govindaraju, V., Behavioral Biometrics for Verification and Recognition of Malicious Software Agents (2008) Paper Presented at Sensors, and Command, Control, Communications, and Intelligence (C3I) Technologies for Homeland Security and Homeland Defense VII, , March 16-20, SPIE Defense and Security Symposium, Orlando, FL; Yudkowsky, E., Artificial intelligence as a positive and negative factor in global risk (2008) Global Catastrophic Risks, pp. 308-345. , edited by N. Bostrom and M. M. Cirkovic, Oxford, UK: Oxford University Press; Yudkowsky, E.S., (2001) Creating Friendly AI—The Analysis and Design of Benevolent Goal Architectures, , http://singinst.org/upload/CFAI.html; Yudkowsky, E.S., (2002) The Ai-Box Experiment, , http://yudkowsky.net/singularity/aibox; Aaronson, S., Is P versus NP formally independent? (2003) Bulletin of the European Association for Theoretical Computer Science, 81, pp. 109-136. , October; Aaronson, S., NP-Complete problems and physical reality (2005) ACM Sigactnews, 36 (1), pp. 30-52. , March; Aaronson, S., (2011) Why Philosophers Should Care about Computational Complexity, , http://www.scottaaronson.com/papers/philos.pdf, August; Aaronson, S., Why philosophers should care about computational complexity (2012) Computability: Godel, Turing, Church, and Beyond, pp. 261-328. , edited by B. Copeland, C. Posy, and O. Shagrir, Cambridge, MA: MIT Press; Adleman, L., (1979) Time, Space, and Randomness, , http://www.usc.edu/molecular-science/timespacerand.pdf, April, Technical Report: MIT/LCS/TM-131; Agrawal, M., Kayal, N., Saxena, N., (2004) PRIMES is in P. Annals of Mathematics, 160 (2), pp. 781-793; Anantharam, V., Verdu, S., Bits through queues (1996) IEEE Transactions on Information Theory, 42 (1), pp. 4-18; Bedekar, A.S., Azizoglu, M., The information-theoretic capacity of discretetime queues (1998) IEEE Transactions on Information Theory, 44 (2), pp. 446-461; Borges, J.L., (2000) The Library of Babel, , Jeffrey, NH: Godine; Braga, G.M., Semantic theories of information (1977) Information Sciences (Ciencia Da Informaçâo), 6 (2), pp. 69-73; Brookes, B.C., The fundamental equation of information science (1975) Problems of Information Science, 530, pp. 115-130; Burgin, M., Information: Paradoxes, contradictions, and solutions (2003) Triple C: Cognition, Communication, Co-Operation, 1 (1), pp. 53-70; Cabuk, S., Brodley, C.E., Shields, C., IP Covert Timing Channels: Design and Detection (2004) Paper Presented at the 11Th ACM Conference on Computer and Communications Security, , October 25-29, Washington, DC; Chaitin, G.J., On the length of programs for computing finite binary sequences (1966) Journal of the ACM (JACM), 13 (4), pp. 547-569; Cook, S., The P versus NP Problem, , http://www.claymath.org/millennium/P_vs_NP/Official_Problem_Description.pdf:1-19, (accessed January 10, 2011); Cook, S.A., Reckhow, R.A., The relative efficiency of propositional proof systems (1979) The Journal of Symbolic Logic, 44 (1), pp. 36-50; Dawkins, R., (1976) The Selfish Gene, , New York: Oxford University Press; Dhulipala, A.K., Fragouli, C., Orlitsky, A., Silence-based communication (2010) IEEE Transactions on Information Theory, 56 (1), pp. 350-366; Doucette, D., Bichler, R., Hofkirchner, W., Raffl, C., Toward a new science of information (2007) Data Sciences Journal, 6 (7), pp. 198-205; Fleissner, P., Hofkirchner, W., Emergent information: Towards a unified information theory (1996) Biosystems, 38 (2-3), pp. 243-248; Floridi, L., What is the philosophy of information? (2002) Metaphilosophy, 33 (1-2), pp. 123-145; Fluckiger, F., Towards a unified concept of information: Presentation of a new approach (1997) World Futures: The Journal of General Evolution 49/50(3-4), p. 309. , July; Fragouli, C., Orlitsky, A., Silence Is Golden and Time Is Money: Power-Aware Communication for Sensor Networks (2005) Paper Presented at the 43Rd Allerton Conference on Communication, Control, and Computing, , September 28-30, Champaign, IL; Fredkin, E., Finite Nature (1992) Paper Presented at the 27Th Rencotre De Moriond Series: Moriond Workshops, , January 25-February 1, Les Arcs, Savoie, France; Garey, M.R., Johnson, D.S., (1979) Computers and Intractability: A Guide to the Theory of Np-Completeness, , New York: Freeman; Giles, J., Hajek, B., An information-theoretic and game-theoretic study of timing channels (2002) IEEE Transactions on Information Theory, 48 (9), pp. 2455-2477; Hall, J.S., Self-improving AI: An analysis (2007) Minds and Machines, 17 (3), pp. 249-259. , October; Hartley, R.V.L., Transmission of information (1928) Bell System Technical Journal, 7 (3), pp. 535-563. , July; Hintikka, J., On semantic information (1970) Physics, Logic, and History, pp. 147-172. , edited by Wolfgang Yourgrau, New York: Plenum Press; Hofkirchner, W., Cognitive Sciences in the Perspective of a Unified Theory of Information (1999) Paper Presented at the 43Rd Annual Meeting of the International Society for the Systems Sciences (ISSS), , June, Pacific Grove, CA; Hofkirchner, W., A Unified Theory of Information as Transdisciplinary Framework (2005) Ict&S Center for Advanced Studies and Research, , http://www.idt.mdh.se/ECAP-2005/articles/BIOSEMANTICS/WolfgangHofkirchner/WolfgangHofkirchner.pdf; Hofkirchner, W., How to achieve a unified theory of information. Triple C: Cognition, Communication (2009) Co-Operation, 7 (2), pp. 357-368; Holmstrom, J., Koli, T., (2002) Making the Concept of Information Operational. Master’s Thesis, Mid Sweden University, , http://www.palmius.com/joel/lic/infoop.pdf; Huffman, D.A., A Method for the Construction of Minimum-Redundancy Codes (1952) Proceedings of the IRE, pp. 1098-1101. , September; (2011), http://en.wikipedia.org/wiki/Illegal_prime, Accessed December 6; Impagliazzo, R., Williams, R., Communication complexity with synchronized clocks (2010) Paper Presented at the IEEE 25Th Annual Conference on Computational Complexity (CCC’10), , June 9-11, Washington, DC; Ji, S., Computing with Numbers, Words, or Molecules: Integrating Mathematics, Linguistics and Biology through Semiotics (2003) Paper Presented at Reports of the Research Group on Mathematical Linguistics, , February 5-11, Tarragona, Spain; Karp, R.M., Reducibility among combinatorial problems (1972) Complexity of Computer Computations, pp. 85-103. , edited by R. E. Miller and J. W. Thatcher, New York: Plenum; Kelly, J.L., A new interpretation of information rate (1956) Bell System Technical Journal, 35, pp. 917-926; Kolmogorov, A.N., Three approaches to the quantitative definition of information (1965) Problems of Information Transmission, 1 (1), pp. 1-7; Langefors, B., (1966) Theoretical Analysis of Information Systems, , Lund, Sweden: Studentlitteratur; Legg, S., Hutter, M., Universal intelligence: A definition of machine intelligence (2007) Minds and Machines, 17 (4), pp. 391-444. , December; Levin, L., Universal search problems (1973) Problems of Information Transmission, 9 (3), pp. 265-266; Levin, L., Average-case complete problems (1986) SIAM Journal on Computing, 15, pp. 285-286; Lloyd, S., Ultimate physical limits to computation (2000) Nature, 406, pp. 1047-1054; Marchal, B., Calculabilite, Physique et Cognition (1998) Phd Thesis, , L’Universite des Sciences et Technologies De Lilles; Martin-Löf, P., The definition of random sequences (1966) Information and Control, 9 (6), pp. 602-619; Mizzaro, S., Towards a theory of epistemic information (2001) Information Modelling and Knowledge Bases, 12, pp. 1-20; Moravec, H., (1999) Robot, , Hoboken, NJ: Wiley Interscience; Omohundro, S.M., The Nature of Self-Improving Artificial Intelligence (2007) Paper Presented at the Singularity Summit, , September 8-9, San Francisco; Papadimitriou, C.H., NP-Completeness: A Retrospective. Paper presented at the 24th International Colloquium on Automata (1997) Languages and Programming (ICALP’97), , July 7-11, Bologna, Italy; Pervez, A., Information as form (2009) Triple C: Cognition, Communication, Co-Operation, 7 (1), pp. 1-11; (2007), http://www.emc.com/emc-plus/rsa-labs/his-torical/the-rsa-challenge-numbers.htm, (accessed January 10, 2011); Schmidhuber, J., Simple algorithmic theory of subjective beauty, novelty, surprise, interestingness, attention, curiosity, creativity, art, science, music, jokes (2009) Journal of SICE, 48 (1), pp. 21-32; Schmidhuber, J., Formal theory of creativity, fun, and intrinsic motivation (1990-2010) (2010) IEEE Transactions on Autonomous Mental Development, 2 (3), pp. 230-247; Schmidhuber, J., A computer scientist’s view of life, the universe, and everything (1997) Foundations of Computer Science: Potential-Theory-Cognition, pp. 201-288. , edited by C. Freksa, New York: Springer; Schmidhuber, J., (2000) Algorithmic Theories of Everything, , http://arxiv.org/pdf/quant-ph/0011122v2, November 30; Schmidhuber, J., The Speed Prior: A New Simplicity Measure Yielding Near-Optimal Computable Predictions (2002) Paper Presented at the 15Th Annual Conference on Computational Learning Theory (COLT 2002), , July 8-10, Sydney, Australia; Shannon, C.E., A mathematical theory of communication (1948) Bell Systems Technical Journal, 27 (3), pp. 379-423. , July; Solomonoff, R., (1960) A Preliminary Report on a General Theory of Inductive Inference, , February 4, Report V-131. Cambridge, MA: Zator; Sundaresan, R., Verdu, S., Robust decoding for timing channels (2000) IEEE Transactions on Information Theory, 46 (2), pp. 405-419; Trakhtenbrot, B.A., A survey of Russian approaches to Perebor (Brute-force searches) algorithms (1984) Annals of the History of Computing, 6 (4), pp. 384-400; Turing, A., On computable numbers, with an application to the Entscheidungsproblem (1936) Proceedings of the London Mathematical Society, 2 (42), pp. 230-265; Wigderson, A., P, NP and Mathematics—A Computational Complexity Perspective (2006) Paper Presented at the International Conference of Mathematicians, , August, ICM e En, Madrid; Wigderson, A., (2009) Knowledge, Creativity and P versus NP, , http://www.math.ias.edu/~avi/PUBLICATIONS/MYPAPERS/AW09/AW09.pdf; Wolfram, S., (2002) A New Kind of Science, , May 14, Oxfordshire, UK: Wolfram Media; Yampolskiy, R.V., AI-Complete CAPTCHAs as zero knowledge proofs of access to an artificially intelligent system (2011) ISRN Artificial Intelligence 271878; Yampolskiy, R.V., Reznik, L., Adams, M., Harlow, J., Novikov, D., Resource awareness in computational intelligence (2011) International Journal of Advanced Intelligence Paradigms, 3 (3), pp. 305-322; Yampolskiy, R.V., Application ofbio-inspired algorithm to the problem of integer factorisation (2010) International Journal of Bio-Inspired Computation (IJBIC), 2 (2), pp. 115-123; Yampolskiy, R.V., (2011) Construction of an NP Problem with an Exponential Lower Bound; Yampolskiy, R.V., El-Barkouky, A., Wisdom of artificial crowds algorithm for solving NP-Hard problems (2011) International Journal of Bio-Inspired Computation (IJBIC), 3 (6), pp. 358-369; Yao, A.C., Some complexity questions related to distributed computing (1979) STOC’79 Proceedings of the 11Th STOC, pp. 209-213; Zhong, Y.X., Mechanism Approach to a Unified Theory of Artificial Intelligence (2005) Paper Presented at the IEEE International Conference on Granular Computing, , July 25-27, Beijing; Zuse, K., (1969) Rechnender Raum. Braunschweig, , Germany: Vieweg; Muehlhauser, L., Yampolskiy, R., Roman Yampolskiy on AI Safety Engineering (2013) Machine Intelligence Research Institute, , http://intelligence.org/2013/07/15/roman-interview/, July 15; Yampolskiy, R., (2013) Welcome to less Wrong!, , http://lesswrong.com/lw/h3p/welcome_to_less_wrong_5th_thread_march_2013, September 16, (5th thread, March 2013). Less Wrong},
document_type={Book},
source={Scopus},
}

@ARTICLE{Sotala2015,
author={Sotala, K. and Yampolskiy, R.V.},
title={Responses to catastrophic AGI risk: A survey},
journal={Physica Scripta},
year={2015},
volume={90},
number={1},
doi={10.1088/0031-8949/90/1/018001},
art_number={018001},
note={cited By 25},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921044343&doi=10.1088%2f0031-8949%2f90%2f1%2f018001&partnerID=40&md5=5f3b05b04075600f36c6f7875f167118},
abstract={Many researchers have argued that humanity will create artificial general intelligence (AGI) within the next twenty to one hundred years. It has been suggested that AGI may inflict serious damage to human well-being on a global scale ('catastrophic risk'). After summarizing the arguments for why AGI may pose such a risk, we review the fields proposed responses to AGI risk. We consider societal proposals, proposals for external constraints on AGI behaviors and proposals for creating AGIs that are safe due to their internal design. © 2015 The Royal Swedish Academy of Sciences.},
author_keywords={AI risk;  artificial general intelligence;  artificial intelligence;  catastrophic risk;  existential risk;  friendly AI;  machine ethics},
keywords={Molecular physics, Artificial general intelligences;  Catastrophic risks;  External constraints;  Global scale;  Internal design;  Well being, Artificial intelligence},
references={Anderson, M., Anderson, S.L., (2011) Machine Ethics; Bostrom, N., Ćirković, M.M., (2008) Global Catastrophic Risks; Bostrom, N., (2014) Superintelligence: Paths, Dangers, Strategies; www.gpo.gov/fdsys/pkg/PLAW-106publ398/html/PLAW-106publ398.htm, National Defense Authorization 2001 Public Law 106-398, 114 Stat. 1654 (An act by the US Congress); Eden, A., Søraker, J., Moor, J.H., Steinhart, E., (2012) Singularity Hypotheses: A Scientific and Philosophical Assessment (The Frontiers Collection); http://spectrum.ieee.org/computing/hardware/tech-luminaries-address-singularity, IEEE Spectrum 2008 Tech luminaries address singularity The Singularity: Special Report; Kringelbach, M.L., Berridge, K.C., (2009) Pleasures of the Brain (Series in Affective Science); Pylyshyn, Z.W., (1987) The Robot's Dilemma: The Frame Problem in Artificial Intelligence; Wood, D.M., Kirstie, B., (2006) A Report on the Surveillance Society: For the Information Commissioner, by the Surveillance Studies Network; Adams, S.S., Mapping the landscape of human-level artificial general intelligence (2012) AI Mag., 33, pp. 25-42; Agar, N., Ray Kurzweil and uploading (2011) J. Evolution Technol, 22, pp. 23-36; Agliata, D., Tantleff-Dunn, S., The impact of media exposure on males' body image (2004) J. Social Clinical Psych., 23, pp. 7-22; Allen, C., Wallach, W., Moral machines: Contradiction in terms of abdication of human responsibility (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 55-68; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) J. Exp. Theor. Art. Intell., 12, pp. 251-261; Allen, C., Smit, I., Wendell, W., Artificial morality (2005) Ethics Info. Technol, 7, pp. 149-155; Allen, C., Wallach, W., Iva Smit, I., Why machine ethics? (2006) IEEE Intell. Systems, 21, pp. 12-17; Amdahl, G.M., Validity of the single processor approach to achieving large scale computing capabilities (1967) Proc. Spring Joint Computer Conference (AFIPS '67), pp. 483-485; Anderson, M., Anderson, S.L., Armen, C., (2005) Machine Ethics; Anderson, M., Anderson, S.L., Armen, C., (2005), pp. 1-7; Anderson, M., Anderson, S.L., Armen, C., (2005), pp. 9-16; Anderson, M., Anderson, S.L., Armen, C., An approach to computing ethics (2006) IEEE Intell. Systems, 21, pp. 56-63; Anderson, M., (2010); Anderson, S.L., The unacceptability of Asimov's three laws of robotics as a basis for machine ethics (2011) Machine Ethics, pp. 285-296; Annas, G.J., Andrews, L.B., Isasi, R.M., Protecting the endangered human (2002) Am. J. Law Med., 28, pp. 151-178; Anthony, D., Robbins, T., Lewis, J.R., Conversion and brainwashing in new religious movements (2004) The Oxford Handbook of New Religious Movements, pp. 243-297; Ronald, C., Arkin, R.C., (2009) Governing Lethal Behavior in Autonomous Robots; Armstrong, S., (2007) Chaining God; Armstrong, S., (2010) Utility Indifference, , www.fhi.ox.ac.uk/reports/2010-1.pdf; Armstrong, S., Sotala, K., How we're predicting AI - Or failing to (2012) Proc. Int. Conf. Beyond AI 2012, 5-6 November 2012, Pilsen, Czech Republic; Armstrong, S., Sandberg, A., Bostrom, N., Thinking inside the box (2012) Minds Machines, 22, pp. 299-324; Asaro, P.M., Robots and responsibility from a legal perspective Proc. IEEE Conf. on Robotics and Automation, Workshop on Roboethics; Ashley, K.D., McLaren, B.M., Reasoning with reasons in case-based comparisons (1995) Proc. First International Conf. on Case-Based Reasoning Research and Development, 1010, pp. 133-144; Asimov, I., Runaround (1942) Astounding Science-Fiction, pp. 94-103; Axelrod, R., Davis, L., The evolution of strategies in the iterated Prisoner's Dilemma (1987) Genetic Algorithms and Simulated Annealing, pp. 32-41; Baars, B.J., The conscious access hypothesis (2002) Trends Cogn. Sci., 6, pp. 47-52; Baars, B.J., Laureys, S., Global workspace theory of consciousness (2005) The Boundaries of Consciousness, pp. 45-53; Bach, J., Goertzel, B., Ikl, M., (2012) Artificial General Intelligence (Lecture Notes in Artificial Intelligence; Bamford, S., A framework for approaches to transfer of a mind's sub-strate (2012) Int. J. Machine Consciousness, 4, pp. 23-34; Baum, S.D., Goertzel, B., Goertzel, T.G., How long until human-level AI? Results from an expert assessment (2011) Technol. Forecasting Social Change, 78, pp. 185-195; Beavers, A.F., Between angles or animals: The question of robot ethics; Or is Kantian moral agency desirable? (2009) 18th Ann. Meeting of Association for Practical and Professional Ethics, Cincinnati, OH; Beavers, A.F., Moral machines and the threat of ethical nihilsm (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 333-344; Bello, P., Bringsjord, S., On how to build a moral machine (2012) Topoi; Benatar, D., (2006) Better Never to Have Been; Berglas, A., (2012); Blackmore, S., She won't be me (2012) J. Consciousness Studies, 19, pp. 16-19; Bostrom, N., How long before superintelligence? (1998) Int. J. Futures Studies, 2; Bostrom, N., Existential risks (2002) J. Evolution Technol., 9; Bostrom, N., Smit, I., Lasker, G.E., Ethical issues in advanced artificial intelligence (2003) Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, 2, pp. 12-17; Bostrom, N., Tandy, C., (2004) The Future of Human Evolution, pp. 339-371; Bostrom, N., Technological revolutions (2007) Nanoscale, pp. 129-152; Bostrom, N., The superintelligent will (2012) Minds Machines, 22, pp. 71-85; Bostrom, N., Cirkovic, M.M., Introduction (2011) Global Catastrophic Risks, pp. 1-30; Bostrom, N., Yudkowsky, E., The ethics of artificial intelligence (2014) Cambridge Handbook of Artificial Intelligence, p. 316; Brain, M., (2003) Robotic Nation; Brandt, R.B., (1979) A Theory of the Good and the Right; Branwen, G., Slowing Moore's Law; Brin, D., (1998) The Transparent Society; Bringsjord, S., Bringsjord, A., Eden, A.H., Moor, J.H., Soraker, J.H., Steinhart, E., Belief in the singularity is fideistic (2012) Singularity Hypotheses, p. 395; Brooks, R.A., I, Rodney Brooks, am a robot (2008) IEEE Spectrum, 45, pp. 68-71; Brynjolfsson, E., McAfee, A., (2011) Race Against the Machine; Bryson, J., Kime, P., (1998) Just Another Artefact; Bryson, J.J., Wilks, Y., Robots should be slaves (2010) Close Engagements with Artificial Companions, 8, pp. 63-126; Bugaj, S.V., Goertzel, B., Five ethical imperatives and their implications for human-AGI interaction (2007) Dynamical Psychology; Butler, S., Darwin among the machines (1863) The Press; Cade, C.M., (1966) Other Worlds Than Ours; Calandrino, J.A., Clarkson, W., Felten, E.W., Bubble trouble (2011) Proc. 20th USENIX Security Symp, pp. 267-280; Cassimatis, N., Mueller, E.T., Winston, P.H., Achieving human-level intelligence through integrated systems and research (2006) AI Mag., 27, pp. 12-14; Casti, J.L., (2012) X-Events; Cattell, R., Parker, A., Challenges for Brain Emulation: Why is Building A Brain so Difficult?; Commodity Futures Trading Commission and Securities and Exchange Commission (2010) Findings Regarding the Market Events of May 6, 2010; Chalmers, D.J., (1996) The Conscious Mind (Philosophy of Mind Series); Chalmers, D.J., The singularity (2010) J. Consciousness Studies, 17, pp. 7-65; Paul, F., Christiano, P.F., Indirect normativity write-up (2012) Ordinary Ideas; Clark, G., (2007) A Farewell to Alms; Clarke, R., Asimov's laws of robotics (1993) Computer, 26, pp. 53-61; Clarke, R., Asimov's laws of robotics (1994) Computer, 27, pp. 57-66; Cloos, C., (2005), pp. 38-45; Dahm, W.J.A., (2010); Daley, W., Mitigating potential hazards to humans from the development of intelligent machines (2011) Synthese, 2, pp. 44-50; Davis, E., (2013); Dayan, P., Dolan, R.J., Sharot, T., Models of value and choice (2011) Neuroscience of Preference and Choice, pp. 33-52; De Garis, H., (2005) The Artilect War: Cosmists Vs Terrans; De Waal, F., Wright, R., Korsgaard, C.M., Kitcher, P., Singer, P., (2006) Primates and Philosophers; Degabriele, J.P., Paterson, K., Watson, G., Provable security in the real world (2011) IEEE Security Privacy Mag., 9, pp. 33-41; Dennett, D.C., Pylyshyn, Z.W., Cognitive wheels (1987) The Robot's Dilemma, pp. 41-64; Dennett, D.C., The mystery of David Chalmers (2012) J. Consciousness Studies, 19, pp. 86-95; Deutsch, D., (2011) The Beginning of Infinity; Dewey, D., Schmidhuber, J., Thrisson, K.R., Looks, M., Learning what to value (2011) Artificial General Intelligence, 6830, pp. 309-314; Dietrich, E., After the humans are gone (2014) Philosophy Now; Docherty, B., Goose, S., (2012) Losing Humanity; Douglas, T., Moral enhancement (2008) J. Appl. Phil., 25, pp. 228-245; Drexler, K.E., (1986) Engines of Creation; Eckersley, P., Sandberg, A., Is brain emulation dangerous? (2013) J. Artif. Gen. Intell., 4, pp. 170-194; Eisen, M., (2011) Amazon's $23,698,655.93 Book about Flies It is NOT Junk; Felten, E.W., Schneider, M.A., Timing attacks on Web privacy (2000) Proc. 7th ACM Conference on Computer and Communications Security - CCS '00, pp. 25-32; Ferguson, M.J., Hassin, R., Implicit motivation (2007) Handbook of Motivation Science, pp. 150-166; Fox, J., Shulman, C., Mainzer, K., Superintelligence does not imply benevolence (2010) ECAP10, VIII European Conference of Computing and Philosophy; Frankfurt, H.G., Freedom of the will and the concept of a person (1971) J. Phil., 68, pp. 5-20; Franklin, S., Patterson, F.G., Jr., The LIDA architecture (2006) IDPT-2006 Proc.; Freeman, T., (2008); Freeman, T., (2009); Friedman, B., Kahn, P.H., Human agency and responsible computing (1992) J. Syst. Software, 17, pp. 7-14; Gewirth, A., (1978) Reason and Morality; Gips, J., Ford, K.M., Glymour, C.N., Hayes, P.J., Towards the ethical robot (1995) Android Epistemology, pp. 243-252; Goertzel, B., (2006); Goertzel, B., Coherent aggregated volition (2010) The Multiverse According to Ben; Goertzel, B., (2010); Goertzel, B., (2012); Goertzel, B., Thoughts on AI morality (2002) Dynamical Psychology; Goertzel, B., Encouraging a positive transcension (2004) Dynamical Psychology; Goertzel, B., Growth, choice and joy (2004) Dynamical Psychology; Goertzel, B., Should humanity build a global AI nanny to delay the singularity until it's better understood? (2012) J. Consciousness Studies, 19, pp. 96-111; Goertzel, B., When should two minds be considered versions of one another? (2012) Int. J. Machine Consciousness, 4, pp. 177-185; Goertzel, B., Bugaj, S.V., (2008) Stages of Ethical Development in Artificial General Intelligence Systems Artificial General Intelligence, pp. 448-459; Goertzel, B., Pitt, J., Nine ways to bias open-source AGI toward friendliness (2012) J. Evolution Technol., 22, pp. 116-131; Golle, P., Partridge, K., Tokuda, H., Beigl, M., Friday, A., Brush, A., Tobe, Y., (2009) On the Anonymity of Home/work Location Pairs Pervasive Computing, pp. 390-397; Good, I.J., Alt, F.L., Rubino, M., Speculations concerning the first ultraintelligent machine (1965) Advances in Computers Volume 6, pp. 31-88; Good, I.J., Some future social repercussions of computers (1970) Int. J. Environ. Studies, 1, pp. 67-79; Good, I.J., Hayes, J.E., Michie, D., Pao, Y.-H., Ethical machines (1982) Intelligent Systems, pp. 555-560; Diana, F., Gordon-Spears, D.F., Hinchey, M.G., Rash, J.L., Truszkowski, W.F., Rou, C., Gordon-Spears, D.F., (2003) Asimov's Laws Formal Approaches to Agent-Based Systems, pp. 257-259; Christopher Grau, G., There is no i in Robot (2006) IEEE Intell. Syst., 21, pp. 52-55; Groesz, L.M., Levine, M.P., Murnen, S.K., The effect of experimental presentation of thin media images on body satisfaction (2001) Int. J. Eating Disorders, 31, pp. 1-16; Guarini, M., Particularism and the classification and reclassification of moral cases (2006) IEEE Intell. Systems, 21, pp. 22-28; Gubrud, M.V., (1997) Nanotechnology and International Security; Gunkel, D.J., (2012) The Machine Question; Guterl, F., (2012) The Fate of the Species; Haidt, J., (2006) The Happiness Hypothesis; Hall, J.S., (2007) Beyond AI; Hall, J.S., Allho, F., Lin, P., Moor, J., Weckert, J., Roco, M.C., (2007) Ethics for Artificial Intellects Nanoethics, pp. 339-352; Hall, J.S., Wang, P., Goertzel, B., Franklin, S., Engineering utopia (2008) Artificial General Intelligence Frontiers, pp. 460-467; Hall, J.S., Anderson, M., Anderson, S.L., Ethics for self-improving machines Machine Ethics, pp. 512-523; Hallevy, G., (2010) The Criminal Liability of Artificial Intelligence Entities; Hanson, R., (2007) Shall We Vote on Values, but Bet on Beliefs?; Hanson, R., Prefer law to values (2009) Overcoming Bias; Hanson, R., If uploads come first (1994) Extropy, 6; Hanson, R., (1998) Economic Growth Given Machine Intelligence; Hanson, R., Economics of the singularity (2008) IEEE Spectrum, 45, pp. 45-50; Hanson, R., Meet the new conflict, same as the old conflict (2012) J. Consciousness Studies, 19, pp. 119-125; Hare, R.D., Clark, D., Grann, M., Thornton, D., Psychopathy and the predictive validity of the PCL-R (2000) Behavioral Sci. Law, 18, pp. 623-645; Harris, G.T., Rice, M.E., Patrick, C.J., Treatment of psychopathy (2006) Handbook of Psychopathy, pp. 555-572; Hart, D., Goertzel, B., (2008) OpenCog: A Software Framework for Integrative Artificial General Intelligence; Hauskeller, M., My brain, my mind, and i (2012) Int. J. Machine Consciousness, 4, pp. 187-200; Hayworth, K.J., Electron imaging technology for whole brain neural circuit mapping (2012) Int. J. Machine Consciousness, 4, pp. 87-108; Heylighen, F., Modelski, G., Devezas, T., Thompson, W.R., (2007), pp. 284-309; Heylighen, F., Brain in a vat cannot break out (2012) J. Consciousness Studies, 19, pp. 126-142; Hibbard, B., (2005); Hibbard, B., (2005) Critique of the SIAI Collective Volition Theory; Hibbard, B., (2012) The Error in My 2001 VisFiles Column; Hibbard, B., Super-intelligent machines (2001) ACM SIGGRAPH Computer Graphics, 35, pp. 13-15; Hibbard, B., Wang, P., Goertzel, B., Franklin, S., Open source AI (2008) Artificial General Intelligence Frontiers, pp. 473-477; Hibbard, B., Model-based utility functions (2012) J. Artificial Gen. Intell., 3, pp. 1-24; Hibbard, B., Bach, J., Goertzel, B., Ikl, M., Decision support for safe AI design (2012) Artificial General Intelligence, 7716, pp. 117-125; Hibbard, B., Bach, J., Goertzel, B., Ikl, M., Avoiding unintended AI behaviors (2012) Artificial General Intelligence, 7716, pp. 107-116; Hollerbach, J.M., Mason, M.T., Henrik, I., Christensen, H.I., (2009) A Roadmap for US Robotics; Hopkins, P.D., Why uploading will not work, or, the ghosts haunting transhumanism (2012) Int. J. Machine Consciousness, 4, pp. 229-243; Horvitz, E.J., Selman, B., (2009) Interim Report from the AAAI Presidential Panel on Long-term AI Futures; Hughes, J., (2001) Relinquishment or Regulation; Hutter, M., Can intelligence explode? (2012) J. Consciousness Studies, 19, pp. 143-166; Jenkins, A., Artificial intelligence and the real world (2003) Futures, 35, pp. 779-786; Joy, B., (2000); Joyce, R., (2001) Evolution and Morality; Karnofsky, H., Thoughts on the singularity institute (SI) (2012) Less Wrong; Karnofsky, H., Tallinn, J., (2011) Karnofsky and Tallinn Dialog on SIAI Efficacy; Kipnis, D., Does power corrupt? (1972) J. Personality Social Psych., 24, pp. 33-41; Koene, R.A., Experimental research in whole brain emulation (2012) Int. J. Machine Consciousness, 4, pp. 35-65; Koene, R.A., Eden, A.H., Moor, J.H., Soraker, J.H., Steinhart, E., (2012); Kornai, A., Bounding the impact of AGI (2014) J. Experimental Theor. Artificial Intell, 26, pp. 417-438; Kurzweil, R., (2001); Kurzweil, R., (2002); Kurzweil, R., (2005) The Singularity is Near; Lampson, B.W., A note on the confinement problem (1973) Comm. ACM, 16 (10), pp. 613-615; Legg, S., (2009) Funding Safe AGI Vetta Project; Legg, S., Hutter, M., (2007) A Collection of Definitions of Intelligence Advances in General Intelligence: Concepts, pp. 17-24; Lehman-Wilzig, S.N., Frankenstein unbound (1981) Futures, 13, pp. 442-457; Levy, D., The ethical treatment of artificially conscious robots (2009) Int. J. Social Robotics, 1, pp. 209-216; Lewis, D., Dispositional theories of value (1989) Proc. Aristotelian Soc. Suppl. Volumes, 63, pp. 113-137; Loosemore, R., Goertzel, B., Eden, A.H., Moor, J.H., Soraker, J.H., Steinhart, E., Why an intelligence explosion is probable (2012) Singularity Hypotheses, p. 83; Mainzer, K., (2010) ECAP10, VIII European Conference of Computing and Philosophy; Mann, S., Nolan, J., Wellman, B., Sousveillance (2003) Surveillance Soc., 1, pp. 331-355; McCauley, L., AI armageddon and the three laws of robotics (2007) Ethics Information Technol., 9, pp. 153-164; McCulloch, W.S., Toward some circuitry of ethical robots; Or, an observational science of the genesis of social evaluation in the mind-like behavior of artifacts (1956) Acta Biotheoretica, 11, pp. 147-156; McDermott, D., Response to the singularity by David Chalmers (2012) J. Consciousness Studies, 19, pp. 167-172; McGinnis, J.O., Accelerating AI (2010) Northwestern University Law Rev., 104, pp. 1253-1270; McKibben, B., (2003) Enough; McLaren, B.M., Extensionally defining principles and cases in ethics (2003) Artificial Intell., 150, pp. 145-181; McLaren, B.M., Computational models of ethical reasoning (2006) IEEE Intell. Syst., 21, pp. 29-37; McLeod, P., Plunkett, K., Rolls, E.T., (1998) Introduction to Connectionist Modelling of Cognitive Processes; Hans Meuer, H., Strohmaier, E., Dongarra, J., Simon, H., (2012); Miller, J.D., (2012) Singularity Rising; Minsky, M., Singh, P., Sloman, A., The St Thomas common sense symposium (2004) AI Mag., 25, pp. 113-124; Moore, D., Shannon, C., Brown, J., Code-red (2002) Proc. Second ACM SIGCOMM Workshop on Internet Measurment (IMW '02), pp. 273-284; Moore, D., Paxson, V., Savage, S., Shannon, C., Staniford, S., Weaver, N., Inside the slammer worm (2003) IEEE Security Privacy Mag., 1, pp. 33-39; Moravec, H.P., (1988) Mind Children; Moravec, H.P., (1992); Moravec, H.P., When will computer hardware match the human brain? (1998) J. Evolution Technol., 1; Moravec, H.P., (1999) Robot; Moskowitz, G.B., Li, P., Kirk, E.R., The implicit volition model (2004) Adv. Experimen. Social Psychol., 36, pp. 317-413; Muehlhauser, L., (2012) Less Wrong; Muehlhauser, L., Helm, L., Eden, A.H., Moor, J.H., Soraker, J.H., Steinhart, E., The singularity and machine ethics (2012) Singularity Hypotheses, p. 101; Muehlhauser, L., Salamon, A., Eden, A.H., Moor, J.H., Soraker, J.H., Steinhart, E., Intelligence explosion (2012) Singularity Hypotheses, p. 15; Murphy, R., Woods, D.D., Beyond Asimov (2009) IEEE Intell. Syst., 24, pp. 14-20; Napier, W., Bostrom, N., Cirkovic, M.M., Hazards from comets and asteroids (2011) Global Catastrophic Risks, pp. 222-237; Narayanan, A., Shmatikov, V., Robust de-anonymization of large sparse datasets (2008) 2008 IEEE Symposium on Security and Privacy, pp. 111-125; Narayanan, A., Shmatikov, V., De-anonymizing social networks (2009) 30th IEEE Symp. on Security and Privacy, pp. 173-187; Narayanan, A., Shmatikov, V., (2009) De-anonymizing Social Networks; Narayanan, A., Paskov, H., Gong, N.Z., Bethencourt, J., Stefanov, E., Shin, E.C.R., Song, D., On the feasibility of internet-scale author identification (2012) 2012 IEEE Symp. on Security and Privacy, pp. 300-314; Nielsen, T.D., Jensen, F.V., Learning a decision maker's utility function from (possibly) inconsistent behavior (2004) Artificial Intell., 160, pp. 53-78; Nordmann, A., Singular simplicity (2008) IEEE Spectrum; Nordmann, A., If and then (2007) NanoEthics, 1, pp. 31-46; Olson, M., (1982) The Rise and Decline of Nations; Omohundro, S.M., (2007) The Nature of Self-improving Artificial Intelligence; Omohundro, S.M., Wang, P., Goertzel, B., Franklin, S., The basic AI drives (2008) Artificial General Intelligence Frontiers, pp. 483-492; Omohundro, S.M., Eden, A.H., Moor, J.H., Soraker, J.H., Steinhart, E., Rational artificial intelligence for the greater Good (2012) Singularity Hypotheses, p. 161; Orseau, L., Ring, M., Schmidhuber, J., Thrisson, K.R., Looks, M., Self-modification and mortality in artificial agents (2011) Artificial General Intelligence, 6830, pp. 1-10; Persson, I., Savulescu, J., The perils of cognitive enhancement and the urgent imperative to enhance the moral character of humanity (2008) J. Appl. Philosophy, 25, pp. 162-177; Persson, I., Savulescu, J., (2012) Unfit for the Future; Peterson, N.R., Pisoni, D.B., Miyamoto, R.T., Cochlear implants and spoken language processing abilities (2010) Restorative Neurology and Neuroscience, 28, pp. 237-250; Pinker, S., (2002) The Blank Slate; Plaut, D.C., Banich, M.T., Mack, M., Connectionist modeling of language (2003) Mind, Brain, and Language, pp. 143-168; Posner, R.A., (2004) Catastrophe; Potapov, A., Rodionov, S., Universal Empathy and Ethical Bias for Artificial General Intelligence; Powers, T.M., Prospects for a Kantian machine (2006) IEEE Intell. Syst., 21, pp. 46-51; Powers, T.M., Incremental machine ethics (2011) IEEE Robotics Automation Mag., 18, pp. 51-58; Pynadath, D.V., Tambe, M., Revisiting Asimov's first law (2002) Intelligent Agents VIII, 2333, pp. 307-320; Railton, P., Facts and values (1986) Phil. Topics, 14 (2), pp. 5-31; Rajab, M.A., Zarfoss, J., Monrose, F., Terzis, A., My botnet is bigger than yours (maybe, better than yours) (2007) Proc. of 1st Workshop on Hot Topics in Understanding Botnets (HotBots '07); Ramamurthy, U., Baars, B.J., D'Mello, S.K., Franklin, S., (2006) Proc. Seventh International Conference on Cognitive Modeling, pp. 244-249; Reynolds, C., Cassinelli, A., (2009); Ring, M., Orseau L, Schmidhuber, J., Thrisson, K.R., Looks, M., (2011) Delusion, Survival, and Intelligent Agents, pp. 11-20; Salekin, R.T., Salekin, R.T., Lynam, D.R., (2010) Treatment of Child and Adolescent Psychopathy Handbook of Child and Adolescent Psychopathy, pp. 343-373; Sandberg, A., (2009) An Overview of Models of Technological Singularity; Sandberg, A., (2001) Friendly Superintelligence; Sandberg A, Eden, A.H., Moor, J.H., Soraker, J.H., Steinhart, E., Models of a singularity (2012) Singularity Hypotheses; Sandberg, A., Bostrom, N., (2008) Whole Brain Emulation; Sandberg, A., Bostrom, N., (2011) Machine Intelligence Survey; Schmidhuber, J., Ultimate cognition à la Gödel (2009) Cogn. Comput., 1, pp. 177-193; Schmidhuber, J., Thrisson, K.R., Looks, M., (2011) Artificial General Intelligence, 6830; Scott, J.C., (1998) Seeing Like A State; Searle, J.R., (1992) The Rediscovery of the Mind; Shachtman, N., (2007); Shulman, C., ; Shulman, C., (2010) Whole Brain Emulation and the Evolution of Superorganisms; Shulman, C., (2010) Omohundro's Basic AI Drives and Catastrophic Risks; Shulman, C., Sandberg A, Mainzer, K., Implications of a software-limited singularity (2010) ECAP10, VIII European Conference of Computing and Philosophy; Shulman, C., Jonsson, H., Tarleton, N., Reynolds, C., Cassinelli, A., Which consequentialism? Machine ethics and moral divergence (2009) AP-CAP 2009, pp. 23-25; Shulman, C., Jonsson, H., Tarleton, N., Reynolds, C., Cassinelli, A., Machine ethics and superintelligence (2009) AP-CAP 2009, pp. 95-97; Smith, M., Desires, values, reasons, and the dualism of practical reason (2009) Ratio, 22, pp. 98-125; Snaider, J., McCall, R., Franklin S, Schmidhuber, J., Thrisson, K.R., Looks, M., The LIDA framework as a general tool for AGI (2011) Artificial General Intelligence, 6830, pp. 133-142; Sobel, D., Full information accounts of well-being (1994) Ethics, 104, pp. 784-810; Sobolewski, M., (2012) German Cabinet to Agree Tougher Rules on High-frequency Trading (Reuters); Solomono, R.J., The time scale of artificial intelligence (1985) Human Syst. Management, 5, pp. 149-153; Solum, L.B., Legal personhood for artificial intelligences (1992) North Carolina Law Rev., 70, pp. 1231-1287; Sotala, K., Advantages of artificial intelligences, uploads, and digital minds (2012) Int. J. Machine Consciousness, 4, pp. 275-291; Sotala, K., Valpola, H., Coalescing minds (2012) Int. J. Machine Consciousness, 4, pp. 293-312; Spears, D.F., Rou, C., Hinchey, M., Rash, J., Truszkowski, W., Gordon-Spears, D.F., Assuring the behavior of adaptive agents (2006) Agent Technology from A Formal Perspective (NASA Monographs in Systems and Software Engineering), pp. 227-257; Stahl, B.C., Can a computer adhere to the categorical imperative? A contemplation of the limits of transcendental ethics in IT (2002) 14th Int. Conf. on Systems Research, Informatics and Cybernetics: Symposium on Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, pp. 13-18; Staniford, S., Paxson, V., Weaver N, Boneh, D., How to own the internet in your spare time (2002) Proc. 11th USENIX Security Symp., pp. 149-167; Steunebrink, B.R., Schmidhuber J, Schmidhuber, J., Thrisson, K.R., Looks, M., A family of Gödel machine implementations (2011) Artificial General Intelligence, 6830, pp. 275-280; Suber, P., (2002); Sullins, J.P., Ethics and artificial life (2005) Ethics Inf. Technol., 7, pp. 139-148; Sullins, J.P., When is a robot a moral agent? (2006) Int. Rev. Inf. Ethics, 6, pp. 23-30; Stillwaggon Swan, L., Howard, J., Digital immortality (2012) Int. J. Machine Consciousness, 4, pp. 245-256; Sweeney, L., Weaving technology and policy together to maintain confidentiality (1997) J. Law Med. Ethics, 25, pp. 98-110; Tanyi, A., (2006) An Essay on the Desire-based Reasons Model; Tarleton, N., (2010) Coherent Extrapolated Volition; Tenenbaum, J.B., Grifiths, T.L., Kemp, C., Theory-based Bayesian models of inductive learning and reasoning (2006) Trends Cogn. Sci., 10, pp. 309-318; Thomas, M.S.C., McClelland, J.L., Sun, R., Connectionist models of cognition (2008) The Cambridge Handbook of Computational Psychology (Cambridge Handbooks in Psychology), pp. 23-58; Trope, Y., Liberman, N., Construal-level theory of psychological distance (2010) Psychological Rev, 117, pp. 440-463; Turing, A.M., (1951); Turney, P., Controlling super-intelligent machines (1991) Can. Artificial Intell., 27, pp. 3-35; Tversky, A., Kahneman, D., The framing of decisions and the psychology of choice (1981) Science, 211, pp. 453-458; Van Gelder, T., What might cognition be, if not computation? (1995) J. Philosophy, 92, pp. 345-381; Van Kleef, G.A., Oveis, C., Van Der Lwe, I., Luokogan, A., Goetz, J., Keltner, D., Power, distress, and compassion (2008) Psychological Sci., 19 (12), pp. 1315-1322; Van Kleef, G.A., Homan, A.C., Finkenauer, C., Gündemir, S., Stamkou, E., Breaking the rules to rise to power (2011) Social Psychological Personality Sci., 2, pp. 500-507; Verdoux, P., Risk mysterianism and cognitive boosters (2010) J. Futures Studies, 15, pp. 1-20; Verdoux, P., Emerging technologies and the future of philosophy (2011) Metaphilosophy, 42, pp. 682-707; Versenyi, L., Can robots be moral? (1974) Ethics, 84, pp. 248-259; Vinge, V., (1993) The Coming Technological Singularity, pp. 11-22; Walker, M., (2008); Walker, M., Personal identity and uploading (2011) J. Evolution Technol., 22, pp. 37-51; Wallach, W., Robot minds and human ethics (2010) Ethics Inf. Technol., 12, pp. 243-250; Wallach, W., Allen, C., (2009) Moral Machines; Wallach, W., Allen, C., Framing robot arms control (2012) Ethics Inf. Technol., 15; Wallach, W., Allen, C., Smit, I., Machine morality (2008) AI Society, 22, pp. 565-582; Wallach, W., Franklin, S., Allen, C., A conceptual and computational model of moral decision making in human and artificial agents (2010) Topics Cogn. Sci., 2, pp. 454-485; Wallach, W., Allen, C., Franklin, S., Consciousness and ethics (2011) Int. J. Machine Consciousness, 3, pp. 177-192; Wang P, Bach, J., Goertzel, B., Ikl, M., Motivation management in AGI systems 2012 (2012) Artificial General Intelligence, 7716, pp. 352-361; Wang, P., Goertzel, B., Franklin, S., (2008) Artificial General Intelligence Frontiers; Warwick, K., (1998) The Mind of the Machine; Warwick, K., Cyborg morals, cyborg values, cyborg ethics (2003) Ethics Inf. Technol., 5, pp. 131-137; Warwick, K., Implications and consequences of robots with biological brains (2010) Ethics Inf. Technol., 12, pp. 223-224; Waser, M.R., Discovering the foundations of a universal system of ethics as a road to safe artificial intelligence (2008) Biologically Inspired Cognitive Architectures, pp. 195-200; Waser, M.R., Samsonovich, A.V., A safe ethical system for intelligent machines (2009) Biologically Inspired Cognitive Architectures, pp. 194-199; Waser, M.R., Schmidhuber, J., Thrisson, K.R., Looks, M., Rational universal benevolence (2011) Artificial General Intelligence, 6830, pp. 153-162; Weld, D., Etzioni, O., Hayes-Roth, B., Korf, R.E., The first law of robotics (a call to arms) (1994) Proc. Twelfth National Conf. on Artificial Intelligence, pp. 1042-1047; Weng, Y.-H., Chen, C.-H., Sun, C.-T., Safety intelligence and legal machine language Service (2008) Robot Applications; Weng, Y.-H., Chen, C.-H., Sun, C.-T., Toward the human-robot co-existence society (2009) Int. J. Social Robotics, 1, pp. 267-282; Whitby, B., (1996) Reflections on Artificial Intelligence; Whitby, B., Oliver, K., (2000); Wiener, N., Some moral and technical consequences of automation (1960) Science, 131, pp. 1355-1358; Wilson, G.S., Minimizing global catastrophic and existential risks from emerging technologies through international law Virginia Environ (2014) Law J., 31, pp. 307-364; Wilson, T.D., (2002) Strangers to Ourselves; Yampolskiy, R.V., Leakproofing the singularity: Artificial intelligence confinement problem (2012) J. Consciousness Studies, 1, pp. 194-214; Yampolskiy, R.V., Artificial intelligence safety engineering (2013) Philosophy and Theory of Artificial Intelligence, 5, pp. 389-396; Yampolskiy, R.V., Fox, J., Safety engineering for artificial general intelligence (2012) Topoi; Yudkowsky, E., (2001); Yudkowsky, E., (2004); Yudkowsky, E., Hard takeoff (2008) Less Wrong; Yudkowsky, E., Value is fragile (2009) Less Wrong; Yudkowsky, E., Reply to Holden on tool AI (2012) Less Wrong; Yudkowsky, E., (1996) Staring into the Singularity; Yudkowsky, E., (2011), pp. 308-345; Yudkowsky, E., (2011) Complex Value Systems Are Required to Realize Valuable Futures; Zimmerman, D., Why Richard Brandt does not need cognitive psychotherapy, and other glad news about idealized preference theories in meta-ethics (2003) J. Value Inquiry, 37, pp. 373-394},
document_type={Review},
source={Scopus},
}

@ARTICLE{Malle2016243,
author={Malle, B.F.},
title={Integrating robot ethics and machine morality: the study and design of moral competence in robots},
journal={Ethics and Information Technology},
year={2016},
volume={18},
number={4},
pages={243-256},
doi={10.1007/s10676-015-9367-8},
note={cited By 24},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934784483&doi=10.1007%2fs10676-015-9367-8&partnerID=40&md5=650ca5d012cebf19a7247556f741c319},
abstract={Robot ethics encompasses ethical questions about how humans should design, deploy, and treat robots; machine morality encompasses questions about what moral capacities a robot should have and how these capacities could be computationally implemented. Publications on both of these topics have doubled twice in the past 10 years but have often remained separate from one another. In an attempt to better integrate the two, I offer a framework for what a morally competent robot would look like (normally considered machine morality) and discuss a number of ethical questions about the design, use, and treatment of such moral robots in society (normally considered robot ethics). Instead of searching for a fixed set of criteria of a robot’s moral competence I identify the multiple elements that make up human moral competence and probe the possibility of designing robots that have one or more of these human elements, which include: moral vocabulary; a system of norms; moral cognition and affect; moral decision making and action; moral communication. Juxtaposing empirical research, philosophical debates, and computational challenges, this article adopts an optimistic perspective: if robotic design truly commits to building morally competent robots, then those robots could be trustworthy and productive partners, caretakers, educators, and members of the human community. Moral competence does not resolve all ethical concerns over robots in society, but it may be a prerequisite to resolve at least some of them. © 2015, Springer Science+Business Media Dordrecht.},
author_keywords={Human-robot interaction;  Moral cognition;  Moral psychology;  Social cognition;  Social robotics},
keywords={Cognitive systems;  Decision making;  Design;  Human computer interaction;  Machine design;  Philosophical aspects;  Robotics;  Robots, Computational challenges;  Empirical research;  Human communities;  Moral cognition;  Moral psychology;  Multiple elements;  Social cognition;  Social robotics, Human robot interaction},
references={Alicke, M.D., Culpable control and the psychology of blame (2000) Psychological Bulletin, 126, pp. 556-574; Allen, C., The future of moral machines. The New York Times: Opinionator. Retrieved December 29, 2014 (2011) from, , http://opinionator.blogs.nytimes.com/2011/12/25/the-future-of-moral-machines/; Anderson, M., Anderson, S., (2011) Machine ethics, , Cambridge University Press, Cambridge; Antaki, C., (1994) Explaining and arguing: The social organization of accounts, , Sage, London; Arkin, R.C., (2009) Governing lethal behavior in autonomous robots, , CRC Press, Boca Raton, FL; Asaro, P.M., What should we want from a robot ethic? (2006) International Review of Information Ethics, 6, pp. 9-16; Avramova, Y.R., Inbar, Y., Emotion and moral judgment (2013) Wiley Interdisciplinary Reviews Cognitive Science, 4, pp. 169-178; Baumeister, R.F., Leary, M.R., The need to belong: Desire for interpersonal attachments as a fundamental human motivation (1995) Psychological Bulletin, 117, pp. 497-529; Bello, P., Cognitive foundations for a computational theory of mindreading (2012) Advances in Cognitive Systems, 1, pp. 59-72; Bicchieri, C., (2006) The grammar of society: The nature and dynamics of social norms, , Cambridge University Press, New York, NY; Blomkamp, N., Kinberg, S., (2015) Chappie [Motion picture], , USA: Sony Pictures Home Entertainment; Brachman, R.J., Systems that know what they’re doing (2002) IEEE Intelligent Systems, 17, pp. 67-71; Breazeal, C.L., (2002) Designing sociable robots, , MIT Press, Cambridge, MA; Bringsjord, S., But perhaps robots are essentially non-persons (2009) Erwägen Wissen Ethik, 20, pp. 193-195; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) Intelligent Systems, IEEE, 21, pp. 38-44; Calverley, D.J., Android science and animal rights, does an analogy exist? (2006) Connection Science, 18, pp. 403-417; Coates, D.J., Tognazzini, N.A., The contours of blame (2012) Blame: Its nature and norms, pp. 3-26. , Coates DJ, Tognazzini NA, (eds), Oxford University Press, New York, NY; Coeckelbergh, M., Robot rights? Towards a social-relational justification of moral consideration (2010) Ethics and Information Technology, 12, pp. 209-221; Cox, M.T., Metareasoning, monitoring, and self-explanation (2011) Metareasoning, pp. 131-149. , Cox MT, Raja A, (eds), The MIT Press, Cambridge, MA; Csibra, G., Gergely, G., Natural pedagogy (2009) Trends in Cognitive Sciences, 13, pp. 148-153; Cushman, F., Crime and punishment: Distinguishing the roles of causal and intentional analyses in moral judgment (2008) Cognition, 108, pp. 353-380; Cushman, F., Young, L., Patterns of moral judgment derive from nonmoral psychological representations (2011) Cognitive Science, 35, pp. 1052-1075; DeBaets, A.M., Can a robot pursue the good? Exploring artificial moral agency (2014) Journal of Evolution and Technology, 24, pp. 76-86; Dersley, I., Wootton, A., Complaint sequences within antagonistic argument (2000) Research on Language and Social Interaction, 33, pp. 375-406; Eisenberg, N., Emotion, regulation, and moral development (2000) Annual Review of Psychology, 51, pp. 665-697; Emde, R.N., Social referencing research: Uncertainty, self, and the search for meaning (1992) Social referencing and the social construction of reality in infancy, pp. 79-94. , Feinman S, (ed), Plenum Press, New York, NY; Fehr, E., Fischbacher, U., Third-party punishment and social norms (2004) Evolution and Human Behavior, 25, pp. 63-87; Fisher, M., Spielberg, S., Weaver, B., (2014) Extant (Television series.), , CBS, Los Angeles; Fiske, S.T., Taylor, S.E., (2008) Social cognition: From brains to culture, , McGraw-Hill, Boston, MA; Flack, J.C., de Waal, F.B.M., Any animal whatever”. Darwinian building blocks of morality in monkeys and apes (2000) Journal of Consciousness Studies, 7, pp. 1-29; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds and Machines, 14, pp. 349-379; Ford, K.M., Hayes, P.J., (1991) Reasoning agents in a dynamic world: The frame problem, , JAI Press, Greenwich, CT; Fridin, M., Kindergarten social assistive robot: First meeting and ethical issues (2014) Computers in Human Behavior, 30, pp. 262-272; Garcia, E., Jimenez, M.A., De Santos, P.G., Armada, M., The evolution of robotics research (2007) IEEE Robotics Automation Magazine, 14, pp. 90-103; Gilovich, T., Keltner, D., Nisbett, R.E., (2013) Social psychology, , W.W. Norton & Co, New, NY; Grau, C., There is no “I” in “Robot”: Robots and utilitarianism (2011) Machine ethics, pp. 451-463. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Gray, K., Young, L., Waytz, A., Mind perception is the essence of morality (2012) Psychological Inquiry, 23, pp. 101-124; Greene, J.D., Nystrom, L.E., Engell, A.D., Darley, J.M., Cohen, J.D., The neural bases of cognitive conflict and control in moral judgment (2004) Neuron, 44, pp. 389-400; Guglielmo, S., Monroe, A.E., Malle, B.F., At the heart of morality lies folk psychology (2009) Inquiry: An Interdisciplinary Journal of Philosophy, 52, pp. 449-466; Gunkel, D.J., A vindication of the rights of machines (2014) Philosophy & Technology, 27, pp. 113-132; Haidt, J., The emotional dog and its rational tail: A social intuitionist approach to moral judgment (2001) Psychological Review, 108, pp. 814-834; Hamlin, J.K., Moral judgment and action in preverbal infants and toddlers: Evidence for an innate moral core (2013) Current Directions in Psychological Science, 22, pp. 186-193; Harenski, C.L., Harenski, K.A., Shane, M.S., Kiehl, K.A., Aberrant neural processing of moral violations in criminal psychopaths (2010) Journal of Abnormal Psychology, 119, pp. 863-874; Heath, J., (2001) Communicative action and rational choice. Studies in contemporary German social thought, , MIT Press, Cambridge, MA; Hilton, D.J., Causal explanation: From social perception to knowledge-based causal attribution (2007) Social psychology: Handbook of basic principles, pp. 232-253. , Kruglanski AW, Higgins ET, (eds), Guilford Press, New York, NY; Hoffman, M.L., Empathy and prosocial behavior (2008) Handbook of emotions, pp. 440-455. , Lewis M, Haviland-Jones JM, Barrett LF, (eds), Guilford Press, New York, NY; Hofmann, B., Ethical challenges with welfare technology: A review of the literature (2013) Science and Engineering Ethics, 19, pp. 389-406; Huebner, B., Dwyer, S., Hauser, M., The role of emotion in moral psychology (2009) Trends in Cognitive Sciences, 13, pp. 1-6; Hutcherson, C.A., Gross, J.J., The moral emotions: A social—functionalist account of anger, disgust, and contempt (2011) Journal of Personality and Social Psychology, 100, pp. 719-737; Johnson, A.M., Axinn, S., The morality of autonomous robots (2013) Journal of Military Ethics, 12, pp. 129-141; Kahn, P.H., Jr., Kanda, T., Ishiguro, H., Gill, B.T., Ruckert, J.H., Shen, S., Gary, H.E., Do people hold a humanoid robot morally accountable for the harm it causes?. Proceedings of the Seventh Annual ACM/IEEE International Conference on Human-Robot Interaction (pp (2012) 33–40), , New York, NY: ACM; Kibble, R., Can an unmanned drone be a moral agent? Ethics and accountability in military robotics. In D. J. Gunkel, J. J. Bryson, & S. Torrance (Eds.), The machine question: AI, ethics and moral responsibility (Proceedings of symposium “Machine Question: AI, Ethics, and Moral Responsibility” AISB/IACAP 2012) (pp. 62–67) (2012) The Society for the Study of Artificial Intelligence and Simulation of Behaviour; Knobe, J., Person as scientist, person as moralist (2010) Behavioral and Brain Sciences, 33, pp. 315-329; Knobe, J., Fraser, B., (2008) Causal judgment and moral judgment: Two experiments. Moral psychology (Vol. 2): The cognitive science of morality: Intuition and diversity (Vol. 2, pp. 441–447), , Cambridge, MA: MIT Press; Kohlberg, L., (1984) The psychology of moral development: The nature and validity of moral stages, , Harper & Row, San Francisco, CA; Lin, P., The ethics of autonomous cars. The Atlantic. Retrieved September 30, 2014 (2013) from, , http://www.theatlantic.com/technology/archive/2013/10/the-ethics-of-autonomous-cars/280360/; Lin, P., Abney, K., Bekey, G.A., (2012) Robot ethics: The ethical and social implications of robotics, , (eds), MIT Press, Cambridge, MA; Littman, M.L., Value-function reinforcement learning in Markov games (2001) Cognitive Systems Research, 2, pp. 55-66; Lomas, M., Chevalier, R., Cross, E.V., Garrett, R.C., Hoare, J., Kopack, M., Explaining robot actions. Proceedings of the 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI) (pp (2012) 187–188), , Boston: MA; Luo, Q., Nakic, M., Wheatley, T., Richell, R., Martin, A., Blair, R.J.R., The neural basis of implicit moral attitude—An IAT study using event-related fMRI (2006) NeuroImage, 30, pp. 1449-1457; Malle, B.F., How people explain behavior: A new theoretical framework (1999) Personality and Social Psychology Review, 3, pp. 23-48; Malle, B.F., (2004) How the mind explains behavior: Folk explanations, meaning, and social interaction, , MIT Press, Cambridge, MA; Malle, B.F., Time to give up the dogmas of attribution: A new theory of behavior explanation (2011) Advances of experimental social psychology, pp. 297-352. , Zanna MP, Olson JM, (eds), 44, Academic Press, San Diego, CA; Malle, B.F., Dickert, S., Values (2007) The encyclopedia of social psychology, , Baumeister RF, Vohs KD, (eds), Sage, Thousand Oaks, CA; Malle, B.F., Guglielmo, S., Monroe, A.E., A theory of blame (2014) Psychological Inquiry, 25, pp. 147-186; Malle, B.F., Scheutz, M., Moral competence in social robots. IEEE International Symposium on Ethics in Engineering, Science, and Technology (pp. 30–35). Presented at the IEEE International Symposium on Ethics in Engineering, Science, and Technology (2014) June, , Chicago, IL: IEEE; Malle, B.F., Scheutz, M., Arnold, T., Voiklis, J., Cusimano, C., Sacrifice one for the good of many? People apply different moral norms to human and robot agents. HRI’15: Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction (pp (2015) 117–124), , New York, NY: ACM; McCullough, M.E., Kurzban, R., Tabak, B.A., Putting revenge and forgiveness in an evolutionary context (2013) Behavioral and Brain Sciences, 36, pp. 41-58; McKenna, M., Directed blame and conversation (2012) Blame: Its nature and norms, pp. 119-140. , Coates DJ, Tognazzini NA, (eds), Oxford University Press, New York, NY; Mental Health Advisory Team (MHAT) IV: Operation Iraqi Freedom 05-07 Final report. Washington, DC: Office of the Surgeon (2006) Multinational Force-Iraq, , Office of the Surgeon General, United States Army Medical Command; Mikhail, J., Universal moral grammar: Theory, evidence and the future (2007) Trends in Cognitive Sciences, 11, pp. 143-152; Milgram, S., Behavioral study of obedience (1963) Journal of Abnormal and Social Psychology, 67, pp. 371-378; Millar, J., An ethical dilemma: When robot cars must kill, who should pick the victim? Robohub. Robohub.org. Retrieved September 28, 2014 (2014) from, , http://robohub.org/an-ethical-dilemma-when-robot-cars-must-kill-who-should-pick-the-victim/; Mithen, S., (1998) Creativity in human evolution and prehistory, , (ed), Taylor & Francis, New York, NY; Monroe, A.E., Dillon, K.D., Malle, B.F., Bringing free will down to earth: People’s psychological concept of free will and its role in moral judgment (2014) Consciousness and Cognition, 27, pp. 100-108; Monroe, A.E., Malle, B.F., From uncaused will to conscious choice: The need to study, not speculate about people’s folk concept of free will (2010) Review of Philosophy and Psychology, 1, pp. 211-224; Monroe, A.E., Malle, B.F., Free will without metaphysics (2014) Surrounding free will, pp. 25-48. , Mele AR, (ed), Oxford University Press, New York, NY; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21, pp. 18-21; Nisbett, R.E., Wilson, T.D., Telling more than we know: Verbal reports on mental processes (1977) Psychological Review, 84, pp. 231-259; Nourbakhsh, I.R., (2013) Robot futures, , MIT Press, Cambridge, MA; Initiative, O.R., If death by autonomous car is unavoidable, who should die? (2014) Reader poll results; Initiative, O.R., My (autonomous) car (2014) my safety: Results from our reader poll; Parthemore, J., Whitby, B., What makes any agent a moral agent? Reflections on machine consciousness and moral agency (2013) International Journal of Machine Consciousness, 4, pp. 105-129; Paxton, J.M., Ungar, L., Greene, J.D., Reflection and reasoning in moral judgment (2012) Cognitive Science, 36, pp. 163-177; Petersen, S., The ethics of robot servitude (2007) Journal of Experimental & Theoretical Artificial Intelligence, 19, pp. 43-54; Powell, N.L., Derbyshire, S.W.G., Guttentag, R.E., Biases in children’s and adults’ moral judgments (2012) Journal of Experimental Child Psychology, 113, pp. 186-193; Powers, T.M., Prospects for a Kantian machine (2006) IEEE Intelligent Systems, 21, pp. 46-51; Powers, T.M., Incremental machine ethics (2011) Robotics & Automation Magazine, IEEE, 18, pp. 51-58; Pylyshyn, Z.W., (1987) The Robot’s dilemma: The frame problem in artificial intelligence, , (ed), Ablex, Norwood, NJ; Ryle, G., (1949) The concept of mind, , Penguin Press, London; Schank, R.C., Abelson, R.P., (1977) Scripts, plans, goals, and understanding: An inquiry into human knowledge structures, , Erlbaum, Hillsdale, NJ; Scheutz, M., The affect dilemma for artificial agents: Should we develop affective artificial agents? (2012) IEEE Transactions on Affective Computing, 3, pp. 424-433; Scheutz, M., Crowell, C.R., (2007) (2007). The burden of embodied autonomy: Some reflections on the social and ethical implications of autonomous robots, , Proceedings of Workshop on Roboethics at ICRA, Rome, Italy; Towards morally sensitive action selection for autonomous social robots (2015) The 24th IEEE international symposium on robot and human interactive communication, 2015 RO-MAN, , Scheutz, M., Malle, B. F., & Briggs, G., Presented at the 24th IEEE International Symposium on Robot and Human Interactive Communication. (2015). RO-MAN. Japan: Kobe; Scheutz, M., Malle, B.F., (2014) (2014). “Think and do the right thing”: A plea for morally competent autonomous robots, , Presented at the: IEEE Ethics conference, Chicago, IL; Semin, G.R., Manstead, A.S.R., (1983) The accountability of conduct: A social psychological analysis, , Academic Press, London; Shaver, K.G., (1985) The attribution of blame: Causality, responsibility, and blameworthiness, , Springer, New York; Sullins, J.P., Introduction: Open questions in roboethics (2011) Philosophy & Technology, 24, p. 233; Talamadupula, K., Schermerhorn, P., Benton, J., Kambhampati, S., Scheutz, M., (2011) Planning for agents with changing goals. ICAPS 2011 System Demonstration, , Freiburg, Germany; Tanaka, F., Cicourel, A., Movellan, J.R., Socialization between toddlers and robots at an early childhood education center (2007) Proceedings of the National Academy of Sciences, 104, pp. 17954-17958; Tedeschi, J.T., Reiss, M., Verbal strategies as impression management (1981) The psychology of ordinary social behaviour, pp. 271-309. , Antaki C, (ed), Academic Press, London; Thiessen, E.D., Kronstein, A.T., Hufnagle, D.G., The extraction and integration framework: A two-process account of statistical learning (2013) Psychological Bulletin, 139, pp. 792-814; Tomasello, M., Vaish, A., Origins of human cooperation and morality (2013) Annual Review of Psychology, 64, pp. 231-255; Traverso, V., The dilemmas of third-party complaints in conversation between friends (2009) Journal of Pragmatics, 41, pp. 2385-2399; Turiel, E., (1983) The development of social knowledge: Morality and convention, , Cambridge University Press, Cambridge, England; Van Berkum, J.J.A., Holleman, B., Nieuwland, M., Otten, M., Murre, J., Right or wrong? The brain’s fast response to morally objectionable statements (2009) Psychological Science, 20, pp. 1092-1099; van Wynsberghe, A., Designing robots for care: Care centered value-sensitive design (2013) Science and Engineering Ethics, 19, pp. 407-433; Veloso, M., Aisen, M., Howard, A., Jenkins, O.C., Mutlu, B., Scassellati, B., Human-robot interaction: Japan, South Korea, and China. WTEC Panel Report. Arlington, VA: World Technology Evaluation Center (2012) Inc; Veruggio, G., Solis, J., Van der Loos, M., Roboethics: Ethics applied to robotics (2011) IEEE Robotics Automation Magazine, 18, pp. 21-22; Voiklis, J., Cusimano, C., Malle, B.F., A social-conceptual map of moral criticism (2014) Proceedings of the 36th annual conference of the cognitive science society, pp. 1700-1705. , Bello P, Guarini M, McShane M, Scassellati B, (eds), Cognitive Science Society, Austin, TX; Walker, M.U., (2006) Moral repair: Reconstructing moral relations after wrongdoing, , Cambridge University Press, New York, NY; Wallach, W., Robot minds and human ethics: The need for a comprehensive model of moral decision making (2010) Ethics and Information Technology, 12, pp. 243-250; Wallach, W., Allen, C., (2008) Moral machines: Teaching robots right from wrong, , Oxford University Press, New York, NY; Warneken, F., Lohse, K., Melis, A.P., Tomasello, M., Young children share the spoils after collaboration (2011) Psychological Science, 22, pp. 267-273; Weiner, B., (1995) Judgments of responsibility: A foundation for a theory of social conduct, , Guilford Press, New York, NY; Williams, K.D., Ostracism: A temporal need-threat model (2009) Advances in experimental social psychology, pp. 275-314. , Zanna MP, (ed), 41, Elsevier Academic Press, San Diego, CA; Wolpert, D.M., Flanagan, J.R., Motor prediction (2001) Current Biology, 11, pp. R729-R732; Wright, J.C., Bartsch, K., Portraits of early moral sensibility in two children’s everyday conversations (2008) Merrill-Palmer Quarterly, 54, pp. 56-85; Wyman, E., Rakoczy, H., Tomasello, M., Normativity and context in young children’s pretend play (2009) Cognitive Development, 24, pp. 146-155},
document_type={Article},
source={Scopus},
}

@ARTICLE{Danielson2010251,
author={Danielson, P.},
title={Designing a machine to learn about the ethics of robotics: The N-reasons platform},
journal={Ethics and Information Technology},
year={2010},
volume={12},
number={3},
pages={251-261},
doi={10.1007/s10676-009-9214-x},
note={cited By 24},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955552320&doi=10.1007%2fs10676-009-9214-x&partnerID=40&md5=07ee8b984777d879e407138da19c5b54},
abstract={We can learn about human ethics from machines. We discuss the design of a working machine for making ethical decisions, the N-Reasons platform, applied to the ethics of robots. This N-Reasons platform builds on web based surveys and experiments, to enable participants to make better ethical decisions. Their decisions are better than our existing surveys in three ways. First, they are social decisions supported by reasons. Second, these results are based on weaker premises, as no exogenous expertise (aside from that provided by the participants) is needed to seed the survey. Third, N-Reasons is designed to support experiments so we can learn how to improve the platform. We sketch experimental results that show the platform is a success as well as pointing to ways it can be improved. © 2010 Springer Science+Business Media B.V.},
author_keywords={Empirical philosophy;  Ethical decision making;  Robot ethics;  Surveys},
keywords={Empirical philosophy;  Ethical decision making;  Robot ethics;  Web-based surveys, Experiments;  Machine design;  Philosophical aspects;  Surveying, Surveys},
references={Danielson, P., (1992) Artificial Morality: Virtuous Robots for Virtual Games, , London: Routledge; Danielson, P., Evolving artificial moralities: Genetic strategies, spontaneous orders, & moral catastrophe (1996) Chaos and Society 18, pp. 329-344. , A. Albert (Ed.), Amsterdam: IOS Press; Danielson, P., Evolutionary models of cooperative mechanisms: Artificial morality and genetic programming (1998) Modeling Rationality, Morality, and Evolution 7, pp. 423-441. , P. Danielson (Ed.), New York: Oxford University Press; Danielson, P., Robots for the rest of us or for the 'best' of us (1999) Ethics and Information Technology, 1, pp. 77-83; Danielson, P., Competition among cooperators: Altruism and reciprocity (2002) Proceedings of the National Academy of Sciences, 99, pp. 7237-7242; Danielson, P.A., Can robots have a conscience? Review of Wendell Wallach and colin allen, moral machines: Teaching robots right from wrong (2009) Nature, 457 (29), p. 540; Danielson, P., Ahmad, R., Bornik, Z., Dowlatabadi, H., Levy, E., Deep, cheap, and improvable: Dynamic democratic norms & the ethics of biotechnology (2007) Ethics and the Life Sciences, pp. 315-326. , A. Fred (Ed.), Charlottesville: Philosophy Documentation Center; Dryzek, J.S., List, C., Social choice theory and deliberative democracy: A reconciliation (2003) British Journal of Political Science, 33 (1), pp. 1-28; Mesoudi, A., Danielson, P., (2007) Parallel ethical worlds: An experimental design for applied ethics, , http://ge3ls-arch-working-papers/cae-ge3ls-working-paper-005-pew.pdf, (Accessed 11 Nov 2007); Lin, P., Bekey, G., Abney, K., (2008) Autonomous miltary robotics: Risk, ethics, and design, , http://ethics.calpoly.edu/ONR_report.pdf/, (Accessed 5 Jan 2009); Mesoudi, A., Danielson, P., Ethics, evolution and culture (2008) Theory in Biosciences, 127 (3), pp. 229-240; Salganik, M., Dodds, P.S., Watts, D.J., Unpredictability in an artificial cultural market: Experimental study of inequality and unpredictability in an artificial cultural market (2006) Science, 311, pp. 854-856; Skyrms, B., (1996) Evolution of the Social Contract, , Cambridge: Cambridge University Press; Thaler, R.H., Sunstein, C.R., (2009) Nudge: Improving Decisions about Health, Wealth, and Happiness, , Penguin: Non-Classics; Wallach, W., Allen, C., (2008) Moral Machines: Teaching Robots Right from Wrong, , USA: Oxford University Press},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Malle2016125,
author={Malle, B.F. and Scheutz, M. and Forlizzi, J. and Voiklis, J.},
title={Which robot am I thinking about? The impact of action and appearance on people's evaluations of a moral robot},
journal={ACM/IEEE International Conference on Human-Robot Interaction},
year={2016},
volume={2016-April},
pages={125-132},
doi={10.1109/HRI.2016.7451743},
art_number={7451743},
note={cited By 23},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964798502&doi=10.1109%2fHRI.2016.7451743&partnerID=40&md5=9932f8dd3e8bd8a092a41b471f6076cd},
abstract={In three studies we found further evidence for a previously discovered Human-Robot (HR) asymmetry in moral judgments: that people blame robots more for inaction than action in a moral dilemma but blame humans more for action than inaction in the identical dilemma (where inaction allows four persons to die and action sacrifices one to save the four). Importantly, we found that people's representation of the "robot" making these moral decisions appears to be one of a mechanical robot. For when we manipulated the pictorial display of a verbally described robot, people showed the HR asymmetry only when making judgments about a mechanicallooking robot, not a humanoid robot. This is the first demonstration that robot appearance affects people's moral judgments about robots. © 2016 IEEE.},
author_keywords={Anthropomorphism;  Humanrobot interaction;  Machine morality;  Moral psychology;  Robot ethics},
keywords={Anthropomorphic robots;  Man machine systems;  Robots, Anthropomorphism;  Human robots;  Humanoid robot;  Moral judgment;  Moral psychology;  Pictorial displays;  Robot appearance;  Robot ethics, Human robot interaction},
references={Victor, D., (2015) Elon Musk and Stephen Hawking among Hundreds to Urge ban on Military Robots, , http://www.nytimes.com/2015/07/28/technology/elon-musk-andstephen-hawking-among-hundreds-to-urge-ban-on-militaryrobots.html?_r=0, 27-Jul-2015. [Online]. Available: [Accessed: 06-Oct; Malle, B.F., Scheutz, M., Moral competence in social robots (2014) Proceedings of IEEE International Symposium on Ethics in Engineering, Science, and Technology, Ethics'2014, pp. 30-35. , Chicago, IL:IEEE; Scheutz, M., Malle, B.F., Think and do the right thing': A plea for morally competent autonomous robots (2014) Proceedings of the IEEE International Symposium on Ethics in Engineering, Science, and Technology, Ethics'2014, pp. 36-39. , Red Hook, NY: Curran Associates/ IEEE Computer Society; Sparrow, R., Killer robots (2007) J. Appl. Philos., 24, pp. 62-77; Asaro, P.M., A body to kick, but still no soul to damn: Legal perspectives on robotics (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 169-186. , P. Lin, K. Abney, and G. Bekey, Eds. MIT Press; Arkin, R.C., (2009) Governing Lethal Behavior in Autonomous Robots, , Boca Raton, FL: CRC Press; Litoiu, A., Ullman, D., Kim, J., Scassellati, B., Evidence that robots trigger a cheating detector in humans (2015) Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction, HRI '15, pp. 165-172; Ju, W., (2014) The Design of Implicit Interactions, , Morgan & Claypool Publishers; Buchanan, R., Wicked problems in design thinking (1992) Des. Issues, 8 (2), pp. 5-21. , Apr; Malle, B.F., Scheutz, M., Arnold, T., Voiklis, J., Cusimano, C., Sacrifice one for the good of many? People apply different moral norms to human and robot agents (2015) HRI '15: Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction, pp. 117-124. , New York, NY: ACM; Greene, J.D., Nystrom, L.E., Engell, A.D., Darley, J.M., Cohen, J.D., The neural bases of cognitive conflict and control in moral judgment (2004) Neuron, 44 (2), pp. 389-400. , Oct; Briggs, G., Scheutz, M., How robots can affect human behavior: Investigating the effects of robotic displays of protest and distress (2014) Int. J. Soc. Robot., 6 (2), pp. 1-13; Kahn, P.H., Jr., Kanda, T., Ishiguro, H., Gill, B.T., Ruckert, J.H., Shen, S., Gary, H.E., Severson, R.L., Do people hold a humanoid robot morally accountable for the harm it causes? (2012) Proceedings of the Seventh Annual ACM/IEEE International Conference on Human-Robot Interaction, New York, NY, pp. 33-40; Monroe, A.E., Dillon, K.D., Malle, B.F., Bringing free will down to Earth: People's psychological concept of free will and its role in moral judgment (2014) Conscious. Cogn., 27, pp. 100-108. , Jul; DiSalvo, C.F., Gemperle, F., Forlizzi, J., Kiesler, S., All robots are not created equal: The design and perception of humanoid robot heads (2002) Proceedings of the 4th Conference on Designing Interactive Systems (DIS '02): Processes, Practices, Methods, and Techniques, pp. 321-326; Eyssel, F., Kuchenbrandt, D., Bobinger, S., De Ruiter, L., Hegel, F., If you sound like me, you must be more human': On the interplay of robot and user features on human-robot acceptance and anthropomorphism (2012) Proc. 7th ACMIEEE Int. Conf. Hum.-Robot Interact. HRI12, pp. 125-126. , Mar; Forlizzi, J., (2007) Towards the Design and Development of Future Robotic Products and Systems, p. 506. , Aug; Dragan, A.D., Bauman, S., Forlizzi, J., Srinivasa, S.S., Effects of robot motion on human-robot collaboration (2015) Proc. Tenth Annu. ACMIEEE Int. Conf. Hum.-Robot Interact. HRI, 15, pp. 51-58; Hinds, P.J., Roberts, T.L., Jones, H., Whose job is it anyway? A study of human-robot interaction in a collaborative task (2004) Hum.- Comput. Interact., 19 (1-2), pp. 151-181. , Mar; Harrison, C., Visual social semiotics: Understanding how still images make meaning (2003) Tech. Commun., 50 (1), pp. 46-60. , Feb; Bransford, J.D., Johnson, M.K., Contextual prerequisites for understanding: Some investigations of comprehension and recall (1972) J. Verbal Learn. Verbal Behav., 11 (6), pp. 717-726. , Dec; Johnson-Laird, P.N., (1983) Mental Models: Towards A Cognitive Science of Language, Inference, and Consciousness, , Cambridge, MA: Harvard University Press; Mani, A., Sundaram, H., Modeling user context with applications to media retrieval (2006) Multimed. Syst., 12, pp. 339-353. , Aug; Malle, B.F., Guglielmo, S., Monroe, A.E., A theory of blame (2014) Psychol. Inq., 25 (2), pp. 147-186; Voiklis, J., Cusimano, C., Malle, B.F., A social-conceptual map of moral criticism (2014) Proceedings of the 36th Annual Conference of the Cognitive Science Society, pp. 1700-1705. , P. Bello, M. Guarini, M. McShane, and B. Scassellati, Eds. Austin, TX: Cognitive Science Society; Greene, J.D., Sommerville, R.B., Nystrom, L.E., Darley, J.M., Cohen, J.D., An fMRI investigation of emotional engagement in moral judgment (2001) Science, 293 (5537), pp. 2105-2108. , Sep; Caruso, E.M., Gino, F., Blind ethics: Closing one's eyes polarizes moral judgments and discourages dishonest behavior (2011) Cognition, 118 (2), pp. 280-285. , Feb; Amit, E., Greene, J.D., You see, the ends don't justify the means: Visual imagery and moral judgment (2012) Psychol. Sci., 23 (8), pp. 861-868. , Aug; McCloud, S., (1994) Understanding Comics: The Invisible Art, , New York, NY: HarperPerennial; Crump, M.J.C., McDonnell, J.V., Gureckis, T.M., Evaluating Amazon's Mechanical Turk as a tool for experimental behavioral research (2013) PLoS ONE, 8 (3), p. e57410. , Mar; Mason, W., Suri, S., Conducting behavioral research on Amazon's Mechanical Turk (2012) Behav. Res. Methods, 44, pp. 1-23. , Mar; Paolacci, G., Chandler, J., Ipeirotis, P.G., Running experiments on Amazon Mechanical Turk (2010) Judgm. Decis. Mak., 5 (5), pp. 411-419; Paolacci, G., Chandler, J., Inside the turk understanding mechanical turk as a participant pool (2014) Curr. Dir. Psychol. Sci., 23 (3), pp. 184-188. , Jun; Schmidt, F.L., Statistical significance testing and cumulative knowledge in psychology: Implications for training of researchers (1996) Psychol. Methods, 1 (2), pp. 115-129; Gray, H.M., Gray, K., Wegner, D.M., Dimensions of mind perception (2007) Science, 315 (5812), p. 619. , Feb; Eyssel, F., Kuchenbrandt, D., Social categorization of social robots: Anthropomorphism as a function of robot group membership (2012) Br. J. Soc. Psychol., 51 (4), pp. 724-731. , Dec; Powers, A., Kramer, A.D.I., Lim, S., Kuo, J., Lee, S., Kiesler, S., Eliciting information from people with a gendered humanoid robot (2005) IEEE Int. Workshop Robot Hum. Interact. Commun. ROMAN, pp. 158-163. , Aug},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{SantonideSio2017411,
author={Santoni de Sio, F.},
title={Killing by Autonomous Vehicles and the Legal Doctrine of Necessity},
journal={Ethical Theory and Moral Practice},
year={2017},
volume={20},
number={2},
pages={411-429},
doi={10.1007/s10677-017-9780-7},
note={cited By 22},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028237980&doi=10.1007%2fs10677-017-9780-7&partnerID=40&md5=40b1349cf5540c2482b96c20d45672a3},
abstract={How should autonomous vehicles (aka self-driving cars) be programmed to behave in the event of an unavoidable accident in which the only choice open is one between causing different damages or losses to different objects or persons? This paper addresses this ethical question starting from the normative principles elaborated in the law to regulate difficult choices in other emergency scenarios. In particular, the paper offers a rational reconstruction of some major principles and norms embedded in the Anglo-American jurisprudence and case law on the “doctrine of necessity”; and assesses which, if any, of these principles and norms can be utilized to find reasonable guidelines for solving the ethical issue of the regulation of the programming of autonomous vehicles in emergency situations. The paper covers the following topics: the distinction between “justification” and “excuse”, the legal prohibition of intentional killing outside self-defence, the incommensurability of goods, and the legal constrains to the use of lethal force set by normative positions: obligations, responsibility, rights, and authority. For each of these principles and constrains the possible application to the programming of autonomous vehicles is discussed. Based on the analysis, some practical suggestions are offered. © 2017, The Author(s).},
author_keywords={Ethics of autonomous vehicles;  Ethics of self-driving cars;  Legal doctrine of necessity;  Robot ethics;  Trolley problem},
references={Alexander, L., Moore, M.S., Deontological Ethics (2015) The Stanford Encyclopedia of Philosophy (Spring, p. 2015. , http://plato.stanford.edu/archives/spr2015/entries/ethics-deontological/, Edition, Edward N. Zalta ed; Asaro, P., A body to kick, but still no soul to damn: legal perspectives on robotics (2011) Robot ethics: the ethical and social implications of robotics, pp. 169-186. , Lin P, Abney K, Bekey GA, (eds), MIT Press, Cambridge; Austin, J.L., Urmson, J.O., Warnock, G.J., A Plea for excuses (1956) J.L. Austin (1961) Philosophical papers, , Oxford: Oxford University Press; Bonnefon, J.F., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2016) Science, 352 (6293), pp. 1573-1576; Christie, G.C., The defense of necessity considered from the legal and moral points of view (1999) Duke Law J, 48 (5), pp. 975-1042; Cohan, J., Homicide by necessity (2006) Chapman Law Review, 10 (1), pp. 119-185; Dennis, I.H., On necessity as a defence to crime: possibilities, problems and the limits of justification and excuse (2009) Crim Law Philos, 3 (1), pp. 29-49; (2004) Eagle v Chambers, , rtr 9; Fletcher, G.P., (2000) Rethinking criminal law, , Oxford University Press, New York; Foot, P., The problem of abortion and the doctrine of double effect (1967) Oxford Review, 5, pp. 5-15; Gerdes, J.C., Thornton, S.M., Maurer, M., Gerdes, J.C., Lenz, B., Winner, H., Implementable ethics for autonomous vehicles (2015) Autonomes Fahren, pp. 87-102. , http://link.springer.com/chapter/10.1007%2F978-3-662-45854-9_5, Springer, Berlin Heidelberg; (2003) RTR 10, , Goddard & Walker v Greenwood; Harris, J., The survival lottery (1975) Philosophy, 50 (191), pp. 81-87; Hart, H.L.A., (1961) The concept of law, , Clarendon, Oxford; (1912) Latta v. New Orleans & N.W. Ry, , 59 So. 250; Lin, P., Maurer, M., Gerdes, J.C., Lenz, B., Winner, H., Why ethics matters for autonomous cars (2015) Autonomes Fahren, pp. 69-85. , http://link.springer.com/chapter/10.1007/978-3-662-45854-9_4, Springer, Berlin Heidelberg; Matthias, A., The responsibility gap: ascribing responsibility for the actions of learning automata (2004) Ethics Inf Technol, 6 (3), pp. 175-183; McSherry, B., The doctrine of necessity and medical treatment (2002) J Law Med, 10 (1), pp. 10-16; (1958) Tentative Draft No 8, , Model Penal Code; Moore, M.S., (1997) Placing blame: a general theory of the criminal law, , Clarendon Press, Oxford; Moore, M.S., (2010) Act and crime: the philosophy of action and its implications for criminal law, , Oxford University Press, New York; Norrie, A., (2014) Crime, reason and history, , Cambridge University Press, New York; Nyholm, S., Smids, J., The ethics of accident-algorithms for self-driving cars: an applied trolley problem? (2016) Ethical Theory Moral Pract, 19 (5), pp. 1275-1289; Pagallo, U., The Laws of Robots: Crimes, Contracts (2013) and Torts, , Springer, Dordrecht; Quinn, W., Actions, intentions, and consequences: the doctrine of double effect (1989) Philos Public Aff, 18 (4), pp. 334-351; (1884) R v Dudley and Stephens, , 14 QBD 273 DC; (1849) R v Longbottom, , 3 Cox 439; (1846) R v Swindall and Osborne, , 2 Car & Kir 230; (2001) Re A (conjoined twins), , 2 WLR 480; Robinson, P.H., A theory of justification: societal harm as a prerequisite for criminal liability. 23 UCLA L (1975) Rev, 23, pp. 266-292; (1974) Ruiz v Forman, , 514 S.W.2d 817; Taxonomy and definitions for terms related to on-road motor vehicle automated driving systems, , SAE Information Report (J3016); Santoni de Sio, F., Ethics and self-driving cars: a white paper on responsible innovation in automated driving systems (2016) Dutch Ministry of Infrastructure and Environment Rijkswaterstaat; Singer, P., Utility and the survival lottery (1977) Philosophy, 52 (200), pp. 218-222; Smith, J.C., Justification and excuse in the criminal law (1989) Sweet &, , Maxwell, London; Smith, B.W., (2015) Regulation and the Risk of Inaction In: Maurer M, Gerdes JC, Lenz B, Winner H (eds) Autonomes Fahren, pp. 593-609. , http://link.springer.com/chapter/10.1007%2F978-3-662-45854-9_27#page-1, Springer, Berlin; Sparrow, R., Killer Robots (2007) J Appl Philos, 24 (1), pp. 62-77; (2002) 72 Conn. App 736, , State v. Scribner; Taurek, J.M., Should the numbers count? (1977) Philos Public Aff, 6 (4), pp. 293-316; Thomson, J.J., The trolley problem (1985) The Yale Law Journal, 94 (6), pp. 1395-1415; Thomson, J.J., Rights (1986) restitution and risk: Essays in moral theory, , Harvard University Press, Cambridge; Thomson, J.J., (1990) The realm of rights, , Harvard University Press, Cambridge; Cas. 360 C.C.E.D (1842); Wood, A., Scheffler, S., Humanity as end in itself (2011) On What Matters, 2. , http://oxfordindex.oup.com/view/10.1093/acprof:osobl/9780199572816.003.0003, Oxford University Press, New York},
document_type={Article},
source={Scopus},
}

@ARTICLE{Anderson2015324,
author={Anderson, M. and Anderson, S.L.},
title={Toward ensuring ethical behavior from autonomous systems: A case-supported principle-based paradigm},
journal={Industrial Robot},
year={2015},
volume={42},
number={4},
pages={324-331},
doi={10.1108/IR-12-2014-0434},
note={cited By 22},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931039373&doi=10.1108%2fIR-12-2014-0434&partnerID=40&md5=681dfdd1d37c9f6c9272b9b880eb839d},
abstract={Purpose: This paper aims to propose a paradigm of case-supported principle-based behavior (CPB) to help ensure ethical behavior of autonomous machines. The requirements, methods, implementation and evaluation components of the CPB paradigm are detailed. Design/methodology/approach: The authors argue that ethically significant behavior of autonomous systems can be guided by explicit ethical principles abstracted from a consensus of ethicists. Particular cases of ethical dilemmas where ethicists agree on the ethically relevant features and the right course of action are used to help discover principles needed for ethical guidance of the behavior of autonomous systems. Findings: Such a consensus, along with its corresponding principle, is likely to emerge in many areas in which autonomous systems are apt to be deployed and for the actions they are liable to undertake, as we are more likely to agree on how machines ought to treat us than on how human beings ought to treat one another. Practical implications: Principles are comprehensive and comprehensible declarative abstractions that succinctly represent this consensus in a centralized, extensible and auditable way. Systems guided by such principles are likely to behave in a more acceptably ethical manner, permitting a richer set of behaviors in a wider range of domains than systems not so guided, and will exhibit the ability to defend this behavior with pointed logical explanations. Social implications: A new threshold has been reached where machines are being asked to make decisions that can have an ethically relevant impact on human beings. It can be argued that such machine ethics ought to be the driving force in determining the manner and extent to which autonomous systems should be permitted to interact with them. Originality/value: Developing and employing principles for this use is a complex process, and new tools and methodologies will be needed by engineers to help contend with this complexity. The authors offer the CPB paradigm as an abstraction to help mitigate this complexity. © Emerald Group Publishing Limited [ISSN 0143-991X].},
author_keywords={Artificial intelligence;  Autonomous robots;  Ethics},
keywords={Abstracting;  Artificial intelligence;  Curricula;  Intelligent robots;  Robots, Autonomous machines;  Autonomous systems;  Complex Processes;  Design/methodology/approach;  Ethical principles;  Ethics;  Relevant features;  Social implication, Philosophical aspects},
references={Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12 (3), pp. 251-261; Anderson, M., Anderson, S.L., Robot be good (2010) Scientific American Magazine, 303 (4), pp. 72-77; Anderson, M., Anderson, S., GenEth: A general ethical dilemma analyzer (2014) Proceedings of the Twenty-eighth AAAI Conference on Artificial Intelligence, pp. 253-261. , Quebec City, CA; Bentham, J., (1799) An Introduction to the Principles and Morals of Legislation, , Oxford University Press, Oxford; Bringsjord, S., Arkoudas, K., Bello, P., Towards a general logicist methodology for engineering ethically correct robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44; Gips, J., Towards the ethical robot (1995) Android Epistemology, pp. 243-252. , Ford, K. M., Glymour, C. and Hayes, P. Eds, MIT Press, Cambridge, MA; Grau, C., There is no 'I' in 'robot': Robots and utilitarianism (2006) IEEE Intelligent Systems, 21 (4), pp. 52-55; Guarini, M., Particularism and the classification and reclassification of moral cases (2006) IEEE Intelligent Systems, 21 (4), pp. 22-28; Kant, I., (1785) Groundwork of the Metaphysic of Morals, , Riga; Khan, A.F.U., The ethics of autonomous learning systems (1995) Android Epistemology, pp. 253-265. , MIT Press, Cambridge, MA; Lavrač, N., Džeroski, S., (1997) Inductive Logic Programming: Techniques and Applications, , Ellis Harwood Series in Artificial Intelligence, Prentice Hall, NJ; McLaren, B.M., Extensionally defining principles and cases in ethics: An AI model (2003) Artificial Intelligence Journal, 150, pp. 145-181. , November; Pereira, L.M., Saptawijaya, A., Modeling morality with prospective logic (2007) Progress in Artificial Intelligence: Lecture Notes in Computer Science, 4874, pp. 99-111; Powers, T.M., Prospects for a Kantian machine (2006) IEEE Intelligent Systems, 21 (4), pp. 46-51; Ross, W.D., (1930) The Right and the Good, , Oxford University Press, Oxford; Rzepka, R., Araki, K., What could statistics do for ethics? The idea of common sense processing based safety valve (2005) Proceedings of the AAAI Fall Symposium on Machine Ethics, pp. 85-87. , Anderson, M., Anderson, S. L. and Armen, C. Eds, AAAI Press, Palo Alto, CA; Turing, A.M., Computing machinery and intelligence (1950) Mind, 59, pp. 433-460; Waldrop, M.M., A question of responsibility (1987) Chapter 11, Man Made Minds: The Promise of Artificial Intelligence, , Walker and Company, New York, NY},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Shim20132328,
author={Shim, J. and Arkin, R.C.},
title={A taxonomy of robot deception and its benefits in HRI},
journal={Proceedings - 2013 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2013},
year={2013},
pages={2328-2335},
doi={10.1109/SMC.2013.398},
art_number={6722151},
note={cited By 22},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893543820&doi=10.1109%2fSMC.2013.398&partnerID=40&md5=4df8afbc0bc757b3b39cdf45b85b7665},
abstract={Deception is a common and essential behavior in humans. Since human beings gain many advantages from deceptive capabilities, we can also assume that robotic deception can provide benefits in several ways. Particularly, the use of robotic deception in human-robot interaction contexts is becoming an important and interesting research question. Despite its importance, very little research on robot deception has been conducted. Furthermore, no basic metrics or definitions of robot deception have been proposed yet. In this paper, we review the previous work on deception in various fields including psychology, biology, and robotics and will propose a novel way to define a taxonomy of robot deception. In addition, we will introduce an interesting research question of robot deception in HRI contexts and discuss potential approaches. © 2013 IEEE.},
author_keywords={Human- robot interaction;  Robot behavior;  Robot deception;  Robot ethics},
keywords={Human being;  Research questions;  Robot behavior;  Robot ethics;  Robot interactions, Cybernetics;  Human robot interaction;  Man machine systems;  Research;  Taxonomies, Robotics},
references={Morin, S.A., Shepherd, R.F., Kwok, S.W., Stokes, A.A., Nemiroski, A., Whitesides, G.M., Camouflage and display for soft machines (2012) Science, 337 (6096), pp. 828-832. , Aug; Floreano, D., Mitri, S., Magnenat, S., Keller, L., Evolutionary conditions for the emergence of communication in robots (2007) Current Biology, 17 (6), pp. 514-519. , Mar; Shim, J., Arkin, R.C., Biologically-inspired deceptive behavior for a robot (2012) 12th International Conference on Simulation of Adaptive Behavior, pp. 401-411; Wagner, A.R., Arkin, R.C., Acting deceptively: Providing robots with the capacity for deception (2011) I. J. Social Robotics, 3 (1), pp. 5-26; Hawthorne, L., (2006) Military Deception, , Joint Publication, JP 3-13.4; Meehan, W.J., Fm 90-2 battlefield deception (1988) Army Field Manuals; Defense, U.D.O., (2009) Unmanned Systems Integrated Roadmap, pp. 2009-2034. , FY; Sexton, D.J., (1986) The Theory and Psychology of Military Deception, , SUNY press; Carey, N., Ford, J., Chahl, J., Biologically inspired guidance for motion camouflage (2004) Control Conference, 2004, 3, pp. 1793-1799. , 5th Asian, Vol.3; Rano, I., An optimal control strategy for two-dimensional motion camouflage with non-holonimic constraints (2012) Biological Cybernetics, 106 (4-5), pp. 261-270; Johnstone, R.A., Grafen, A., Dishonesty and the handicap principle (1993) Animal Behaviour, 46 (4), pp. 759-764. , Oct; Davis, J., Arkin, R., Mobbing behavior and deceit and its role in bio-inspired autonomous robotic agents (2012) International Conference on Swarm Intelligence, pp. 276-283; Terada, K., Ito, A., Can a robot deceive humans? (2010) Proceedings of the 5th ACM/IEEE International Conference on Human-robot Interaction, pp. 191-192. , ser. HRI '10. Piscataway, NJ, USA: IEEE Press; Short, E., Hart, J., Vu, M., Scassellati, B., No fair!!: An interaction with a cheating robot (2010) Proceedings of the 5th ACM/IEEE International Conference on Human-robot Interaction, pp. 219-226. , ser. HRI '10. Piscataway, NJ, USA: IEEE Press; Vazquez, M., May, A., Steinfeld, A., Chen, W.-H., A deceptive robot referee in a multiplayer gaming environment Collaboration Technologies and Systems (CTS), 2011 International Conference On, 2011, pp. 204-211; Brewer, B., Klatzky, R., Matsuoka, Y., Visual-feedback distortion in a robotic rehabilitation environment (2006) Proceedings of the IEEE, 94 (9), pp. 1739-1751; Matsuzoe, S., Tanaka, F., How smartly should robots behave?: Comparative investigation on the learning ability of a care-receiving robot (2012) RO-MAN, 2012, pp. 339-344. , IEEE; Tanaka, F., Kimura, T., Care-receiving robot as a tool of teachers in child education (2010) Interaction Studies, 11 (2), pp. 263-268; Chisholm, R.M., Feehan, T.D., The intent to deceive (1977) Journal of Philosophy, 74 (3), pp. 143-159; Depaulo, B.M., Kashy, D.A., Kirkendol, S.E., Wyer, M.M., Epstein, J.A., Lying in everyday life (1996) Journal of Personality and Social Psychology, 70 (5), pp. 979-995. , May; Dunnigan, J.F., Nofi, A.A., (2001) Victory and Deceit, , 2nd edition: Deception and trickery in war, " Writers Press Books; Whaley, B., Toward a general theory of deception (1982) Journal of Strategic Studies, 5 (1), pp. 178-192. , Mar; Bell, J., Whaley, B., (1991) Cheating and Deception, , TRANSACTION PUBL; Erat, S., Gneezy, U., White lies (2009) Rady Working Paper, Rady School of Management, , UC San Diego; Rowe, N.C., Designing good deceptions in defense of information systems (2004) Proceedings of the 20th Annual Computer Security Applications Conference, pp. 418-427. , ser. ACSAC '04. Washington, DC, USA: IEEE Computer Society; Dennett, D.C., (1987) The Intentional Stance, , Bradford Books, reprint ed. Cambridge, MA: The MIT Press, Mar; De Waal, F., (1986) Deception in the Natural Communication of Chimpanzees, , Mitchell and Tompson; Adar, E., Tan, D.S., Teevan, J., Benevolent deception in human computer interaction (2013) Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 1863-1872. , ser. CHI '13. New York, NY, USA: ACM; Vaughan, R.T., Sumpter, N., Henderson, J., Frost, A., Cameron, S., Experiments in automatic flock control (2000) Robotics and Autonomous Systems, 31 (1-2), pp. 109-117; Steele, M.A., Halkin, S.L., Smallwood, P.D., McKenna, T.J., Mitsopoulos, K., Beam, M., Cache protection strategies of a scatterhoarding rodent: Do tree squirrels engage in behavioural deception? (2008) Animal Behaviour; Dennett, D.C., When hal kills, who's to blame? Computer ethics (1997) HAL's Legacy: 2001's Computer as Dream and Reality, , D. G. Stork, Ed. Cambridge, MA: MIT Press; Miller, F., Wendler, D., Swartzman, L., Deception in research on the placebo effect (2005) PLoS Med, 2 (9), pp. e262; Gneezy, U., Deception: The role of consequences (2005) American Economic Review, 95 (1), pp. 384-394. , September; Sharkey, N., The ethical frontiers of robotics (2008) Science, 322 (5909), pp. 1800-1801; Economist, T., (2012) Morals and the Machine, , The Economist Newspaper Limited; Lin, P., Abney, K., Bekey, G., (2011) Robot Ethics, , MIT Press; Wallach, W., Allen, C., (2008) Moral Machines : Teaching Robots Right from Wrong: Teaching Robots Right from Wrong, , Oxford University Press, USA; Sinnott-Armstrong, W., Consequentialism (2012) The Stanford Encyclopedia of Philosophy, , E. N. Zalta, Ed; Christine, K., Two arguments against lying (1988) Argumentation, 2; Arkin, R., The ethics of robotics deception (2010) 1st International Conference of International Association for Computing and Philosophy, pp. 1-3},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Arnold201781,
author={Arnold, T. and Kasenberg, D. and Scheutz, M.},
title={Value alignment or misalignment - What will keep systems accountable?},
journal={AAAI Workshop - Technical Report},
year={2017},
volume={WS-17-01 - WS-17-15},
pages={81-88},
note={cited By 21},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045276127&partnerID=40&md5=fa6c749c157a02113fb2891967a225da},
abstract={Machine learning's advances have led to new ideas about the feasibility and importance of machine ethics keeping pace, with increasing emphasis on safety, containment, and alignment. This paper addresses a recent suggestion that inverse reinforcement learning (IRL) could be a means to so-called "value alignment." We critically consider how such an approach can engage the social, norm-infused nature of ethical action and oudine several features of ethical appraisal that go beyond simple models of behavior, including unavoidably temporal dimensions of norms and counterfactuals. We propose that a hybrid approach for computational architectures still offers the most promising avenue for machines acting in an ethical fashion. © Copyright 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
keywords={Alignment;  Computer games;  Deep learning;  Inverse problems;  Knowledge based systems;  Operations research;  Philosophical aspects;  Reinforcement learning, Computational architecture;  Counterfactuals;  Hybrid approach;  Inverse reinforcement learning;  Temporal dimensions, Problem solving},
references={Abel, D., MacGlashan, J., Littman, M.L., Reinforcement learning as a framework for ethical decision making (2016) Workshops at the Thirtieth AAAI Conference on Artificial Intelligence; Abney, K., Robotics, ethical theory, and metaethics: A guide for the perplexed (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 35-52; Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics and Information Technology, 7 (3), pp. 149-155; Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge University Press; Armstrong, S., Motivated value selection for artificial agents (2015) Workshops at the Twenty-Ninth AAAI Conference on Artificial Intelligence, pp. 12-20; Arnold, T., Scheutz, M., Against the moral hiring test: Accountable design and the moral reasoning of autonomous systems (2016) Ethics and Inf. Technol., 18 (2), pp. 103-115; Bekey, G.A., Lin, P., Abney, K., Bekey, G.A., (2012) Robot Ethics, the Ethical and Social Implications of Robotics; Bicchieri, C., (2005) The Grammar of Society: The Nature and Dynamics of Social Norms, , Cambridge University Press; Blass, J.A., Forbus, K.D., Moral decision-making by analogy: Generalizations vs. Exemplars (2015) Proceedings of the 29th AAAI Conference on Artificial Intelligence; Borowiec, S., (2016) Alphago Seals 4-1 Victory Overgo Grandmaster Lee Sedol; Bostrom, N., Yudkowsky, E., The ethics of artificial intelligence (2014) The Cambridge Handbook of Artificial Intelligence, pp. 316-334; Bostrom, N., (2014) Superintelligence: Paths, Dangers, Strategies, , OUP Oxford; Bratman, M.E., (2013) Shared Agency: A Planning Theory of Acting Together, , Oxford University Press; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44; Bryson, J.J., Patiency is not a virtue: Ai and the design of ethical systems (2016) 2016 AAAI Spring Symposium Series; Crawford, KateCalo, R., There is a blind spot in ai research (2016) Nature; Dehghani, M., Tomai, E., Forbus, K.D., Klenk, M., An integrated reasoning approach to moral decisionmaking La AAAI, pp. 1280-1286; Ding, X.C., Smith, S.L., Belta, C., Rus, D., LTL control in uncertain environments with probabilistic satisfaction guarantees (2011) IFAC Proceedings Volumes (IFAC- PapersOnline), 18, pp. 3515-3520. , PART l; Dzifcak, J., Scheutz, M., Baral, C., Schermerhorn, P., What to do and how to do it: Translating natural language directives into temporal and dynamic logic representation for goal management and action execution Proceedings of the 2009 IEEE International Conference on Robotics and Automation (ICRA '09); Ju, W., The design of implicit interactions (2015) Synthesis Lectures on Human-Centered Informatics, 8 (2), pp. 1-93; Moor, J.H., The nature, importance, and difficulty of machine ethics (2011) Machine Ethics, pp. 13-20; Neff, G., Nagy, P., Automation, algorithms, and politics- talking to bots: Symbiotic agency and the case of tay (2016) International Journal of Communication, 10, p. 17; Pasquale, F., (2015) The Black Box Society: The Secret Algorithms that Control Money and Information, , Harvard University Press; Pereira, L.M., Saptawijaya, A., (2016) Counterfactuals, Logic Programming and Agent Morality, , Logic, Argumentation & Reasoning. Springer; Puterman, M.L., (1994) Markov Decision Processes: Discrete Stochastic Dynamic Programming, , New York, NY, USA: John Wiley & Sons, Inc. 1st edition; Riedl, M.O., Harrison, B., Using stories to teach human values to artificial agents (2016) Proceedings of the 2nd International Workshop on AI, , Ethics and Society, Phoenix, Arizona; Russell, S., Dewey, D., Tegmark, M., (2016) Research Priorities for Robust and Beneficial Artificial Intelligence, , arXivpreprint arXiv:1602.03506; Schermerhorn, P., Kramer, J., Brick, T., Anderson, D., Dingier, A., Scheutz, M., DIARC: A Testbed for Natural Human-Robot Interactions (2006) Proceedings OfAAAI 2006 Robot Workshop, , 1972-1973; Scheutz, M., Crowell, C., The burden of embodied autonomy: Some reflections on the social and ethical implications of autonomous robots (2007) Proceedings of Workshop on Roboethics AtlCRA 2007; Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Van Den Driessche, G., Schrittwieser, J., Lanctot, M., Mastering the game of go with deep neural networks and tree search (2016) Nature, 529 (7587), pp. 484-489; Soares, N., (2015) The Value Learning Problem, , Technical report, Citeseer; Stevenson, A., Cordy, J.R., A survey of grammatical inference in software engineering (2014) Science of Computer Programming, 96 (P4), pp. 444-459; Sun, R., Moral judgment, human motivation, and neural networks (2013) Cognitive Computation, 5 (4), pp. 566-579; Tanz, J., (2016) Soon We Won?t Program Computers, , we?ll train them like dogs; Taylor, J., Yudkowsky, E., LaVictoire, P., Critch, A., (2016) Alignment for Advanced Machine Learning Systems, , Technical report, Technical Report 20161, MIRI; Theodorou, A., Wortham, R., Bryson, J.J., (2016) Why is My Robot Behaving Like That? Designing Transparency for Real Time Inspection of Autonomous Robots, , forthcoming; Walsh, T., (2016) The Singularity May Never Be Near, , arXiv preprint arXiv:1602.06462; Wolchover, N., Concerns of an artificial intelligence pioneer (2015) Quanta Magazine, p. 21; Wolff, E.M., Topcu, U., Murray, R.M., Robust control of uncertain Markov Decision Processes with temporal logic specifications (2012) 2012 IEEE 51st IEEE Conference on Decision and Control (CDC), pp. 3372-3379; Yampolskiy, R.V., Artificial intelligence safety engineering: Why machine ethics is a wrong approach (2013) Philosophy and Theory of Artificial Intelligence, pp. 389-396. , Springer; Yudkowsky, E., Artificial intelligence as a positive and negative factor in global risk (2008) Global Catastrophic Risks, 1, p. 303},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Pereira2011398,
author={Pereira, L.M. and Saptawijaya, A.},
title={Modeling morality with prospective logic},
journal={Machine Ethics},
year={2011},
volume={9780521112352},
pages={398-421},
doi={10.1017/CBO9780511978036.023},
note={cited By 21},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858325716&doi=10.1017%2fCBO9780511978036.023&partnerID=40&md5=baeb6c8241b4dba245c3a2b272a5359b},
abstract={Morality no longer belongs only to the realm of philosophers. Recently, there has been a growing interest in understanding morality from the scientific point of view. This interest comes from various fields, for example, primatology (de Waal 2006), cognitive sciences (Hauser 2007; Mikhail 2007), neuroscience (Tancredi 2005), and other various interdisciplinary perspectives (Joyce 2006; Katz 2002). The study of morality also attracts the artificial intelligence community from the computational perspective and has been known by several names, including machine ethics, machine morality, artificial morality, and computational morality. Research on modeling moral reasoning computationally has been conducted and reported on, for example, at the AAAI 2005 Fall Symposium on Machine Ethics (Guarini 2005; Rzepka and Araki 2005). There are at least two reasons to mention the importance of studying morality from the computational point of view. First, with the current growing interest to understand morality as a science, modeling moral reasoning computationally will assist in better understanding morality. Cognitive scientists, for instance, can greatly benefit in understanding complex interaction of cognitive aspects that build human morality; they may even be able to extract moral principles people normally apply when facing moral dilemmas. Modeling moral reasoning computationally can also be useful for intelligent tutoring systems, for instance, to aid in teaching morality to children. Second, as artificial agents are more and more expected to be fully autonomous and work on our behalf, equipping agents with the capability to compute moral decisions is an indispensable requirement. © Cambridge University Press 2011.},
keywords={Autonomous agents;  Behavioral research;  Computer aided instruction;  Education;  Philosophical aspects;  Teaching, Artificial agents;  Cognitive aspects;  Cognitive science;  Intelligent tutoring system;  Moral reasoning;  On-machines, Computation theory},
references={Alferes, J.J., Brogi, A., Leite, J.A., Pereira, L.M., Evolving Logic Programs (2002) Procs. 8Th European Conf. On Logics in Artificial Intelligence (JELIA’02), , Pages 50–61 of: Flesca, S., Greco, S., Leone, N., and Ianni, G. (eds), LNCS 2424. Springer; Anderson, M., Anderson, S., Armen, C., Medethex: A prototype medical ethics advisor (2006) Procs. 18Th Conf. On Innovative Applications of Artificial Intelligence (IAAI-06); Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44; De Waal, F., (2006) Primates and Philosophers, How Morality Evolved, , Princeton U.P; Dell’Acqua, P., Pereira, L.M., Preferential theory revision (2005) Procs. Computational Models of Scientific Reasoning and Applications, , Pages 69–84 of: Pereira, L. M., and Wheeler, G. (eds); Dell’Acqua, P., Pereira, L.M., Preferential theory revision (extended version) (2007) Journal of Applied Logic, 5 (4), pp. 586-601; Foot, P., The problem of abortion and the doctrine of double effect (1967) Oxford Review, 5, pp. 5-15; Gelfond, M., Lifschitz, V., The stable model semantics for logic programming (1988) 5Th Intl. Logic Programming Conf, , Kowalski, R., and Bowen, K. A. (eds), MIT Press; Gigerenzer, G., Engel, C., (2006) Heuristics and the Law, , eds), MIT Press; Guarini, M., Particularism and generalism: How ai can help us to better understand moral cognition (2005) Machine Ethics: Papers from the AAAI Fall Symposium, , Anderson, M., Anderson, S., and Armen, C. (eds), AAAI Press; Hauser, M.D., (2007) Moral Minds: How Nature Designed Our Universal Sense of Right and Wrong, , Little Brown; Joyce, R., (2006) The Evolution of Morality, , The MIT Press; Kakas, A., Kowalski, R., Toni, F., The Role of Abduction in Logic Programming (1998) Handbook of Logic in Artificial Intelligence and Logic Programming, 5. , Pages 235–324 of: Gabbay, D., Hogger, C., and Robinson, J. (eds), Oxford U. P; Kamm, F.M., (2006) Intricate Ethics: Rights, Responsibilities, and Permissible Harm, , Oxford U. P; Katz, L.D., (2002) Evolutionary Origins of Morality, Cross-Disciplinary Perspectives, , Imprint Academic; Kowalski, R., (2006) The Logical Way to Be Artificially Intelligent, , Page 122 of: Toni, F., and Torroni, P. (eds), Procs. of CLIMA VI, LNAI. Springer; Lopes, G., Pereira, L.M., Prospective logic programming with acorda (2006) Workshop on Empirically Successful Computerized Reasoning, , Procs. of the FLoC’06, 3rd Intl. J. Conf. on Automated Reasoning; McLaren, B.M., Computational models of ethical reasoning: Challenges, initial steps, and future directions (2006) IEEE Intelligent Systems, 21 (4), pp. 29-37; Mikhail, J., Universal moral grammar: Theory, evidence, and the future (2007) Trends in Cognitive Sciences, 11 (4), pp. 143-152; Otsuka, M., Double effect, triple effect and the trolley problem: Squaring the circle in looping cases (2008) Utilitas, 20 (1), pp. 92-110; Pereira, L.M., Lopes, G., Prospective logic agents (2007) Procs. 13Th Portuguese Intl.Conf. On Artificial Intelligence (EPIA’07), , Neves, J. M., Santos, M. F., and Machado, J. M. (eds), Springer LNAI; Pereira, L.M., Saptawijaya, A., Moral decision making with acorda (2007) Short Papers Call, Local Procs. 14Th Intl. Conf. On Logic for Programming Artificial Intelligence and Reasoning (LPAR’07), , Dershowitz, N., and Voronkov, A. (eds); Powers, T.M., Prospects for a kantian machine (2006) IEEE Intelligent Systems, 21 (4), pp. 46-51; Rzepka, R., Araki, K., What could statistics do for ethics? The idea of a commonsense-processing-based safety valve (2005) Machine Ethics: Papers from the AAAI Fall Symposium, , Anderson, M., Anderson, S., and Armen, C, AAAI Press; Tancredi, L., (2005) Hardwired Behavior: What Neuroscience Reveals about Morality, , Cambridge U. P},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Vanderelst201856,
author={Vanderelst, D. and Winfield, A.},
title={An architecture for ethical robots inspired by the simulation theory of cognition},
journal={Cognitive Systems Research},
year={2018},
volume={48},
pages={56-66},
doi={10.1016/j.cogsys.2017.04.002},
note={cited By 20},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020386786&doi=10.1016%2fj.cogsys.2017.04.002&partnerID=40&md5=2b300ca799b9fbc723e3d17de46182f8},
abstract={The expanding ability of robots to take unsupervised decisions renders it imperative that mechanisms are in place to guarantee the safety of their behaviour. Moreover, intelligent autonomous robots should be more than safe; arguably they should also be explicitly ethical. In this paper, we put forward a method for implementing ethical behaviour in robots inspired by the simulation theory of cognition. In contrast to existing frameworks for robot ethics, our approach does not rely on the verification of logic statements. Rather, it utilises internal simulations which allow the robot to simulate actions and predict their consequences. Therefore, our method is a form of robotic imagery. To demonstrate the proposed architecture, we implement a version of this architecture on a humanoid NAO robot so that it behaves according to Asimov's laws of robotics. In a series of four experiments, using a second NAO robot as a proxy for the human, we demonstrate that the Ethical Layer enables the robot to prevent the human from coming to harm in simple test scenarios. © 2017 The Authors},
author_keywords={Ethical robots;  Machine ethics;  Machine Morality;  Self-simulation;  Simulation theory},
keywords={Architecture;  Cognitive systems;  Philosophical aspects;  Robotics;  Robots, Asimov's Laws;  Internal simulations;  Logic statements;  Proposed architectures;  Robot ethics;  Self-simulation;  Simple tests;  Simulation theory, Intelligent robots, Article;  behavior;  cognition;  ethics;  imagery;  prediction;  priority journal;  robotics;  simulation},
references={Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics and Information Technology, 7 (3), pp. 149-155; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-26. , http://www.aaai.org/ojs/index.php/aimagazine/article/view/2065/2052; Anderson, M., Anderson, S.L., Robot be good (2010) Scientific American, 303 (4), pp. 72-77; Arkin, R.C., Governing lethal behavior: Embedding ethics in a hybrid deliberative/reactive robot architecture part i: Motivation and philosophy (2008) 2008 3rd ACM/IEEE international conference on human-robot interaction (HRI), pp. 121-128. , IEEE; Arkin, R.C., Ulam, P., Wagner, A.R., Moral decision making in autonomous systems: Enforcement, moral emotions, dignity, trust, and deception (2012) Proceedings of the IEEE, 100 (3), pp. 571-589; Asimov, I., I, Robot (1950), Gnome Press; Barsalou, L.W., Perceptual symbol systems (1999) Behavioral and Brain Sciences, 22 (4), pp. 577-660; Barsalou, L.W., Grounded cognition: Past, present, and future (2010) Topics in Cognitive Science, 2 (4), pp. 716-724. , https://doi.org/10.1111/j.1756-8765.2010.01115.x; Bekey, G.A., Autonomous robots: From biological inspiration to implementation and control (2005), MIT Press; Bongard, J., Zykov, V., Lipson, H., Resilient machines through continuous self-modeling (2006) Science, 314 (5802), pp. 1118-1121; Botvinick, M.M., Hierarchical models of behavior and prefrontal function (2008) Trends in Cognitive Sciences, 12 (5), pp. 201-208; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44; Demiris, Y., Johnson, M., Simulation theory of understanding others: A robotics perspective (2006) Imitation and social learning in robots, humans and animals: Behavioural, social and communicative dimensions, pp. 89-102. , C.L. Nehaniv D. Kirstin Cambridge University Press; Deng, B., Machine ethics: The robot's dilemma (2015) Nature, 523 (7558), p. 20; Dennis, L.A., Fisher, M., Winfield, A.F.T., Towards verifiably ethical robot behaviour (2015) CoRR, p. abs/1504. , http://arxiv.org/abs/1504.03592; Dijkstra, K., Post, L., Mechanisms of embodiment (2015) Frontiers in Psychology, 6 (October), pp. 1-11. , http://journal.frontiersin.org/article/10.3389/fpsyg.2015.01525; Ding, M., Ikeura, R., Mukai, T., Nagashima, H., Hirano, S., Matsuo, K., Sun, M., Hosoe, S., Comfort estimation during lift-up using nursing-care robotriba (2012) 2012 First international conference on innovative engineering systems (ICIES), pp. 225-230. , IEEE; Donoso, M., Collins, A.G.E., Koechlin, E., Human cognition: Foundations of human reasoning in the prefrontal cortex (2014) Science (New York, NY), 344 (6191), pp. 1481-1486. , http://www.ncbi.nlm.nih.gov/pubmed/24876345; Gallese, V., Keysers, C., Rizzolatti, G., A unifying view of the basis of social cognition (2004) Trends in Cognitive Sciences, 8 (9), pp. 396-403; Gärdenfors, P., Conceptual spaces: The geometry of thought (2004), MIT Press; Gips, J., Creating ethical robots: A grand challenge (2005) AAAI fall 2005 symposium on machine ethics, pp. 1-7. , M. Anderson S.L. Anderson C. Armen; Goeldner, M., Herstatt, C., Tietze, F., The emergence of care robotics—A patent and publication analysis (2015) Technological Forecasting and Social Change, 92, pp. 115-131; Govindarajulu, N.S., Bringsjord, S., Ethical regulation of robots must be embedded in their operating systems (2015) A construction manual for robots’ ethical systems, pp. 85-99. , Springer; Haines, W., Consequentialism (2015) The internet encyclopedia of philosophy, , http://www.iep.utm.edu, J. Fieser B. Dowden; Hegarty, M., Mechanical reasoning by mental simulation (2004) Trends in Cognitive Sciences, 8 (6), pp. 280-285. , http://linkinghub.elsevier.com/retrieve/pii/S1364661304001007; Hesslow, G., Conscious thought as simulation of behaviour and perception (2002) Trends in Cognitive Sciences, 6 (6), pp. 242-247; Hesslow, G., The current status of the simulation theory of cognition (2012) Brain Research, 1428, pp. 71-79; Holland, O., A strongly embodied approach to machine consciousness (2007) Journal of Consciousness Studies, 14 (7), pp. 97-110. , http://www.ingentaconnect.com/content/imp/jcs/2007/00000014/00000007/art00007; Hunter, J.D., Matplotlib: A 2D graphics environment (2007) Computing In Science & Engineering, 9 (3), pp. 90-95; Kahneman, D., Thinking, fast and slow (2011), Macmillan; Kato, Y., Kanda, T., Ishiguro, H., May i help you?: Design of human-like polite approaching behavior (2015) Proceedings of the tenth annual ACM/IEEE international conference on human-robot interaction. HRI ’15, pp. 35-42. , http://doi.acm.org/10.1145/2696454.2696463, ACM New York, NY, USA; Kortenkamp, D., Simmons, R., Robotic systems architectures and programming (2008) Springer handbook of robotics, pp. 187-206. , Springer; Kosslyn, S.M., Ganis, G., Thompson, W.L., Neural foundations of imagery (2001) Nature Reviews Neuroscience, 2 (9), pp. 635-642; Kruse, T., Pandey, A.K., Alami, R., Kirsch, A., Human-aware robot navigation: A survey (2013) Robotics and Autonomous Systems, 61 (12), pp. 1726-1743; Lieto, A., Chella, A., Frixione, M., Conceptual spaces for cognitive architectures: A lingua franca for different levels of representation (2016) Biologically Inspired Cognitive Architectures; Lin, P., Abney, K., Bekey, G.A., Robot ethics: The ethical and social implications of robotics (2011), MIT Press; Macaluso, I., Ardizzone, E., Chella, A., Cossentino, M., Gentile, A., Gradino, R., Infantino, I., Scardino, G., Experiences with cicerobot, a museum guide cognitive robot (2005) Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics), 3673 LNAI, pp. 474-482; Mackworth, A.K., Architectures and ethics for robots (2011) Machine ethics, pp. 204-221. , M. Anderson S.L. Anderson Cambridge University Press; Marques, H.G., Holland, O., Architectures for functional imagination (2009) Neurocomputing, 72, pp. 743-759; Michel, O., (2004), Webotstm: Professional mobile robot simulation. arXiv preprint cs/0412052; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Murphy, R., Introduction to AI robotics (2000), MIT Press; Murphy, R., Woods, D., Beyond Asimov: The three laws of responsible robotics (2009) IEEE Intelligent Systems, 24 (4); Nigam, A., Riek, L.D., Social context perception for mobile robots (2015) 2015 IEEE/RSJ international conference on intelligent robots and systems (IROS), pp. 3621-3627. , IEEE; Picard, R.W., Picard, R., (1997) Affective computing, 252. , MIT press Cambridge; Pinker, S., How the mind works (1997), W.W. Norton & Company; Royakkers, L., van Est, R., A literature review on new robotics: Automation from love to war (2015) International Journal of Social Robotics, 7 (5), pp. 549-570; Shanton, K., Goldman, A., Simulation theory (2010) Wiley Interdisciplinary Reviews: Cognitive Science, 1 (4), pp. 527-538; Sharkey, N., The ethical frontiers of robotics (2008) Science, 322 (5909), pp. 1800-1801; Vaughan, R., Zuluga, M., Use your illusion: Sensorimotor self-simulation allows complex agents to plan with incomplete self-knowledge (2006) From Animals to Animats 9, 4095, pp. 406-421. , http://www.springerlink.com/content/h3243h8005365586/abstract/%5Cnhttp://www.springerlink.com/content/h3243h8005365586/fulltext.pdf, <;; Vaughan, R.T., Gerkey, B.P., Reusable robot software and the player/stage project (2007) Software engineering for experimental robotics, pp. 267-289. , Springer; Waldrop, M.M., No drivers required (2015) Nature, 518 (7537), p. 20; Wallach, W., Allen, C., Moral machines: Teaching robots right from wrong (2008), Oxford University Press; Wilson, M., Six views of embodied cognition (2002) Psychonomic Bulletin & Review, 9 (4), pp. 625-636; Winfield, A., (2012), Robotics: A very short introduction. OUP Oxford; Winfield, A.F., Blum, C., Liu, W., Towards an ethical robot: Internal, consequences and ethical action selection (2014) Advances in autonomous robotics systems, pp. 85-96. , Springer; Winfield, A.F.T., Robots with internal models: A route to self-aware and hence safer robots (2014) The computer after me: Awareness and self-awareness in autonomic systems, , J. Pitt 1st ed. Imperial College Press London; Xin, L., Bin, D., The latest status and development trends of military unmanned ground vehicles (2013) 2013 Chinese automation congress, pp. 533-537. , http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6775792; Young, L., Dungan, J., Where in the brain is morality? everywhere and maybe nowhere (2012) Social Neuroscience, 7 (1), pp. 1-10; Ziemke, T., Jirenhed, D.A., Hesslow, G., Internal simulation of perception: A minimal neuro-robotic model (2005) Neurocomputing, 68 (1-4), pp. 85-104; Zwaan, R., The immersed experiencer: Toward an embodied theory of language comprehension (2003) Psychology of Learning and Motivation – Advances in Research and Theory, 44, pp. 35-62. , arXiv:04},
document_type={Article},
source={Scopus},
}

@ARTICLE{Borenstein201631,
author={Borenstein, J. and Arkin, R.},
title={Robotic Nudges: The Ethics of Engineering a More Socially Just Human Being},
journal={Science and Engineering Ethics},
year={2016},
volume={22},
number={1},
pages={31-46},
doi={10.1007/s11948-015-9636-2},
note={cited By 20},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955725253&doi=10.1007%2fs11948-015-9636-2&partnerID=40&md5=733669abec20b0fa511fe2cd10a9ac0c},
abstract={Robots are becoming an increasingly pervasive feature of our personal lives. As a result, there is growing importance placed on examining what constitutes appropriate behavior when they interact with human beings. In this paper, we discuss whether companion robots should be permitted to “nudge” their human users in the direction of being “more ethical”. More specifically, we use Rawlsian principles of justice to illustrate how robots might nurture “socially just” tendencies in their human counterparts. Designing technological artifacts in such a way to influence human behavior is already well-established but merely because the practice is commonplace does not necessarily resolve the ethical issues associated with its implementation. © 2015, Springer Science+Business Media Dordrecht.},
author_keywords={Autonomy;  Design ethics;  Nudges;  Paternalism;  Rawls;  Robot companions;  Robot ethics;  Social justice},
keywords={engineering;  ethics;  human;  morality;  robotics;  social justice, Engineering;  Humans;  Moral Development;  Morals;  Robotics;  Social Justice},
references={Anderson, S.L., Asimov’s “three laws of robotics” and machine metaethics (2008) Ai & Society, 22 (4), pp. 477-493; Ariely, D., Berns, G.S., Neuromarketing: The hope and hype of neuroimaging in business (2010) Nature Reviews Neuroscience, 11, pp. 284-292; Arkin, R.C., (1998) Behavior-based robotics, , MIT Press, Cambridg; Arkin, R., (2009) Governing lethal behavior in autonomous robots, , Chapman-Hall, Newyor; Arkin, R.C., Integrating behavioral, perceptual, and world knowledge in reactive navigation (1990) Designing autonomous agents, pp. 105-122. , Maes P, (ed), MIT Press, Bradfor; Arkin, R., Fujita, M., Takagi, T., Hasegawa, R., An ethological and emotional basis for human-robot interaction (2003) Robotics and Autonomous Systems, 42, pp. 191-201; Arkin, R.C., Scheutz, M., Tickle-Degnen, L., Preserving dignity in patient caregiver relationships using moral emotions and robots. 2014 IEEE International Symposium on Ethics in Engineering (2014) Science and Technology, , Chicago: I; http://www.acm.org/about/code-of-ethics, Association for Computing Machinery (ACM). (1992). ACM code of ethics and professional conduct. Accessed 24 Oct 2014; Borenstein, J., Pearson, Y., Companion robots and the emotional development of children (2013) Law, Innovation and Technology, 5 (2), pp. 172-189; Brooks, A., Arkin, R.C., Behavioral overlays for non-verbal communication expression on a humanoid robot (2007) Autonomous Robots, 22 (1), pp. 55-75; Brutzman, D., Davis, D., Lucas, G., Jr., McGhee, R., Run-time ethics checking for autonomous unmanned vehicles: Developing a practical approach (2013) Proceedings of the 18th International Symposium on Unmanned Untethered Submersible Technology (UUST), , Portsmouth, New Hampshir; Clarke, R., Asimov’s laws of robotics: Implications for information technology-part I (1993) Computer, 26 (12), pp. 53-61; Dworkin, G., Paternalism. In E. N (2014) Zalta, , http://plato.stanford.edu/archives/sum2014/entries/paternalism/, Ed.: The Stanford encyclopedia of philosoph; Fehr, E., Bernhard, H., Rockenbach, B., Egalitarianism in young children (2008) Nature, 454 (7208), pp. 1079-1083; Fisher, R., Is it ok to torture or murder a robot? (2013) BBC, , http://www.bbc.com/future/story/20131127-would-you-murder-a-robot; Hansson, S.O., The ethics of enabling technology (2007) Cambridge Quarterly of Healthcare Ethics, 16 (3), pp. 257-267; Harris, C.E., Jr., Paternalism and the enforcement of morality (1977) Southwestern Journal of Philosophy, 8 (2), pp. 85-93; Hyson, M., Taylor, J.L., Caring about caring: What adults can do to promote young children’s prosocial skills (2011) YC Young Children, 66 (4), pp. 74-83; http://www.ieee.org/about/corporate/governance/p7-8.html, IEEE. (2014). IEEE code of ethics. Accessed 24 Oct 2014; Kramer, A.D.I., Guillory, J.E., Hancock, J.T., Experimental evidence of massive-scale emotional contagion through social networks (2014) PNAS, 111 (24), pp. 8788-8790; Li, J. (2013). The nature of the bots: how people respond to robots, virtual agents and humans as multimodal stimuli. In Proceedings of the 15th ACM on International conference on multimodal interaction (ICMI ‘13) (pp. 337–340). New York, NY; Morin, C., Neuromarketing: The new science of consumer behavior (2011) Society, 48, pp. 131-135; Moshkina, L., Improving request compliance through robot affect (2012) Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence, pp. 2031-2037; Moshkina, L., Park, S., Arkin, R.C., Lee, J.K., Jung, H., TAME: Time-varying affective response for humanoid robots (2011) International Journal of Social Robotics, 3 (3), pp. 207-221; Murphy, R., Woods, D.D., Beyond asimov: The three laws of responsible robotics (2009) IEEE Intelligent Systems, 24 (4), pp. 14-20; http://www.nspe.org/sites/default/files/resources/pdfs/Ethics/CodeofEthics/Code-2007-July.pdf, National Society of Professional Engineers (NSPE). (2007). NSPE code of ethics for engineers. Accessed 24 Oct 2014; Norman, D.A., Shallice, T., Attention to action: Willed and automatic control of behaviour (1986) Consciousness and self-regulation: Advances in research and theory, , Davidson RJ, Schwartz GE, Shapiro D, (eds), Plenum Press, New Yor; Nozick, R., (1974) Anarchy, state, and utopia, , Basic Books, New Yor; Pear, R., Employers get leeway on health incentives (2013) The New York Times, , http://www.nytimes.com/2013/05/30/business/new-rules-give-employers-leeway-on-use-of-health-incentives.html; Pearson, Y., Borenstein, J., The intervention of robot caregivers and the cultivation of children’s capability to play (2013) Science and Engineering Ethics, 19 (1), pp. 123-137; Persson, I., Savulescu, J., Getting moral enhancement right: the desirability of moral bioenhancement (2013) Bioethics, 27 (3), pp. 124-131; Rawls, J., (1971) A theory of justice, , Harvard University Press, Cambridge, M; Riek, L.D., Howard, D., A code of ethics for the human-robot interaction profession. Presented at WeRobot 2014 Conference (2014) University of Miami; Salter, T., Werry, I., Michaud, F., Going into the wild in child–robot interaction studies: Issues in social robotic development (2008) Intelligent Service Robotics, 1 (2), pp. 93-108; Salvini, P., Datteri, E., Laschi, C., Dario, P., Scientific models and ethical issues in hybrid bionic systems research (2008) Ai & Society, 22 (3), pp. 431-448; Salvini, P., Laschi, C., Dario, P., Design for acceptability: Improving robots’ coexistence in human society (2010) International Journal of Social Robotics, 2 (4), pp. 451-460; Sen, A., Equality of what (1982) Choice, welfare and measurement, pp. 353-369. , Sen A, (ed), Blackwell, Oxfor; Siegel, M., (2003) The sense-think-act paradigm revisited, 1st International Workshop on Robotic Sensing (ROSE’, 3, p. 5; Singer, P.W., (2009) Wired for war, , The Penguin Press, New Yor; Sparrow, R., The march of the robot dogs (2002) Ethics and Information Technology, 4 (4), pp. 305-318; Sparrow, R., Egalitarianism and moral bioenhancement (2014) The American Journal of Bioethics, 14 (4), pp. 20-28; Sung, J.-Y., Guo, L., Grinter, R.E., Christensen, H.I., My roomba is rambo: Intimate home appliances. UbiComp 2007: Ubiquitous computing (2007) Lecture Notes in Computer Science, 4717, pp. 145-162; Thaler, R.H., Sunstein, C.R., (2008) Nudge: Improving decisions about health, wealth, and happiness, , Yale University Press, New Have; Thomas, F., Johnston, O., (1981) The illusion of life: Disney animation, , Hyperion, New Yor; (2010) The International Forum for Social Development, , http://www.un.org/esa/socdev/documents/ifsd/SocialJustice.pdf, Social justice in an open world, The role of the United Nation; Wallach, W., Allen, C., (2009) Moral machines: Teaching robots right from wrong, , Oxford University Press Inc, New Yor},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Anderson20084,
author={Anderson, M. and Anderson, S.L.},
title={ETHEL: Toward a principled ethical eldercare system},
journal={AAAI Fall Symposium - Technical Report},
year={2008},
volume={FS-08-02},
pages={4-11},
note={cited By 19},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-65649120373&partnerID=40&md5=d88c19e0531da8c7f1e00170c2922312},
abstract={We have developed an approach to computing ethics that entails the discovery of ethical principles through machine learning and the incorporation of these principles into a system's decision procedure. We summarize our pertinent previous work in machine ethics and present an extension of this work in the domain of eldercare: EthEl, a prototype system that uses a machine-discovered ethical principle to provide guidance for its actions.},
keywords={Learning systems, Computing ethics;  Decision procedure;  Eldercare;  Ethical principles;  Prototype system;  Provide guidances, Philosophical aspects},
references={(1986) Blackboard Systems, , Engelmore, R., and Morgan, A. eds. . Reading, Mass.: Addison-Wesley; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12, pp. 251-261; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) Artificial Intelligence Magazine, 28. , Winter; Anderson, S., Anderson, M., (2007) The Consequences for Human Beings of Creating Ethical Robots, , In [17]; Anderson, M., Anderson, S.L., An approach to computing ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 22-28. , July/August; Anderson, M., Anderson, S.L., MedEthEx: A prototype medical ethics advisor (2006) Proceedings of the Eighteenth Conference on Innovative Applications of Artificial Intelligence, , Boston, Massachusetts, August; Beauchamp, T.L., Childress, J.F., (1979) Principles of Biomedical Ethics, , Oxford University Press; Boden, M., (2006) Robots and Anthropomorphism, , In [16]; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44. , July/August; Buchanan, A.E., Brock, D.W., (1989) Deciding for Others: the Ethics of Surrogate Decision Making, pp. 48-57. , Cambridge University Press; Gips, J., (1995) Towards the Ethical Robot. Android Epistemology, pp. 243-252. , Cambridge MA: MIT Press; Grau, C., There Is no "I" in "Robot": Robots and utilitarianism (2006) IEEE Intelligent Systems, 21 (4), pp. 52-55. , July/August; Guarini, M., Particularism and the classification and reclassification of moral cases (2006) IEEE Intelligent Systems, 21 (4), pp. 22-28. , July/August; Khan, A.F.U., The ethics of autonomous learning systems (1995) Android Epistemology, pp. 253-265. , Cambridge MA: MIT Press; Lavrač, N., Džeroski, S., (1997) Inductive Logic Programming: Techniques and Applications, , Ellis Harwood; McLaren, B.M., Extensionally defining principles and cases in ethics: An AI model (2003) Artificial Intelligence Journal, 150, pp. 145-181. , November; Metzler, T., Human implications of human-robot interaction (2006) AAAI Technical Report WS-06-09, , AAAI Press; Metzler, T., Human implications of human-robot interaction (2007) AAAI Technical Report WS-07-107, , AAAI Press; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21. , July/August; Powers, T.M., Prospects for a Kantian machine (2006) IEEE Intelligent Systems, 21 (4), pp. 46-51. , July/August; Rawls, J., Outline for a decision procedure for ethics (1951) Philosophical Review, 60; Ross, W.D., (1930) The Right and the Good, , Clarendon Press, Oxford; Rzepka, R., Araki, K., What could statistics do for ethics? the idea of common sense processing based safety valve (2005) Proceedings of the AAAI Fall Symposium on Machine Ethics, pp. 85-87. , AAAI Press; Syrdal, D.S., Walters, M.L., Otero, N., Koay, K.L., Dautenhann, K., He knows when you are sleeping (2007) Privacy and the Personal Robot Companion, , In [17]; Turkle, S., (2006) Robot As Rorschach: New Complicities for Companionship, , In [16]; Waldrop, M.M., A question of responsibility (1987) Man Made Minds: the Promise of Artificial Intelligence, , Chap. 11 in . NY: Walker and Company, 1987; (1991) Ethical Issues in Information Systems, p. 260. , Reprinted in R. Dejoie et al., eds. . Boston, MA: Boyd and Fraser},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Coeckelbergh201161,
author={Coeckelbergh, M.},
title={You, robot: On the linguistic construction of artificial others},
journal={AI and Society},
year={2011},
volume={26},
number={1},
pages={61-69},
doi={10.1007/s00146-010-0289-z},
note={cited By 18},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651459106&doi=10.1007%2fs00146-010-0289-z&partnerID=40&md5=8f5f539e852fd92b44fc013d8613d782},
abstract={How can we make sense of the idea of 'personal' or 'social' relations with robots? Starting from a social and phenomenological approach to human-robot relations, this paper explores how we can better understand and evaluate these relations by attending to the ways our conscious experience of the robot and the human-robot relation is mediated by language. It is argued that our talk about and to robots is not a mere representation of an objective robotic or social-interactive reality, but rather interprets and co-shapes our relation to these artificial quasi-others. Our use of language also changes as a result of our experiences and practices. This happens when people start talking to robots. In addition, this paper responds to the ethical objection that talking to and with robots is both unreal and deceptive. It is concluded that in order to give meaning to human-robot relations, to arrive at a more balanced ethical judgment, and to reflect on our current form of life, we should complement existing objective-scientific methodologies of social robotics and interaction studies with interpretations of the words, conversations, and stories in and about human-robot relations. © 2010 The Author(s).},
author_keywords={Hermeneutics;  Human-robot relations;  Language;  Phenomenology;  Robot ethics},
references={Asaro, P.M., What should we want from a robot ethic? (2006) Int Rev Inf Ethics, 6, pp. 9-16; Breazeal, C., Toward sociable robots (2003) Robot Auton Syst, 42, pp. 167-175; Brooks, R., Will robots rise up and demand their rights? (2000) Time, , June 19 2000; Coeckelbergh, M., Personal robots, appearance, and human good: A methodological reflection on roboethics (2009) Int J Soc Robot, 1 (3), pp. 217-221; Coeckelbergh, M., Robot rights? Towards a social-relational justification of moral consideration (2010) Ethics Inf Technol, , doi: 10. 1007/s10676-010-9235-5; Coeckelbergh, M., Moral appearances: Emotions, robots, and human morality (2010) Ethics Inf Technol, , doi: 10. 1007/s10676-010-9221-y; Dautenhahn, K., What is a robot companion-friend, assistant, or butler? Intelligent robots and systems (2005) IEEE/RSJ International Conference On In Intelligent Robots and Systems; Dautenhahn, K., Methodology and themes of human-robot interaction: a growing research field (2007) Int J Adv Robot Syst, 4 (1), pp. 103-108; Floridi, L., Artificial intelligences's new frontier: artificial companions and the fourth revolution (2008) Metaphilosophy, 39 (4-5), pp. 651-655; Ihde, D., (1990) Technology and the Lifeworld, , Bloomington/Minneapolis: Indiana University Press; Latour, B., (1993) We have Never Been Modern (Trans: Porter C), , Cambridge, MA: Harvard University Press; Levy, D., (2007) Love and Sex with Robots: The Evolution of Human-Robot Relationships, , New York: Harper; Levy, D., The ethical treatment of artificially conscious robots (2009) Int J Soc Robot, 1 (3), pp. 209-216; Searle, J.R., Minds, brains and programs (1980) Behav Brain Sci, 3 (3), pp. 417-457; Searle, J.R., (1995) The Construction of Social Reality, , London: The Penguin Press; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Mind Mach, 16, pp. 141-161; Torrance, S., Ethics and consciousness in artificial agents (2008) AI & Soc, 22, pp. 495-521; Turing, A.M., Computing machinery and intelligence (1950) Mind, 59, pp. 433-460; Turkle, S., (1984) The Second Self: Computers and the Human Spirit, , New York: Simon and Schuster; Turkle, S., (2005) Relational Artifacts/children/elders: The Complexities of Cybercompanions, , http://www.androidscience.com/proceedings2005/TurkleCogSci2005AS.pdf, Accessed 19 March 2010; Turkle, S., Taggart, W., Kidd, C.D., Dasté, O., Relational artifacts with children and elders: the complexities of cybercompanionship (2006) Connect Sci, 18 (4), pp. 347-361; Whitby, B., Sometimes it's hard to be a robot: a call for action on the ethics of abusing artificial agents (2008) Interact Comput, 20 (3), pp. 326-333; Wittgenstein, L., (1953) Philosophical investigations (eds and trans: Hacker PMS, Schulte J), , Wiley-Blackwell, Oxford, 2009},
document_type={Article},
source={Scopus},
}

@ARTICLE{Yampolskiy2013217,
author={Yampolskiy, R. and Fox, J.},
title={Safety Engineering for Artificial General Intelligence},
journal={Topoi},
year={2013},
volume={32},
number={2},
pages={217-226},
doi={10.1007/s11245-012-9128-9},
note={cited By 17},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884508469&doi=10.1007%2fs11245-012-9128-9&partnerID=40&md5=c066f851b2cacec62655643c1e6374fe},
abstract={Machine ethics and robot rights are quickly becoming hot topics in artificial intelligence and robotics communities. We will argue that attempts to attribute moral agency and assign rights to all intelligent machines are misguided, whether applied to infrahuman or superhuman AIs, as are proposals to limit the negative effects of AIs by constraining their behavior. As an alternative, we propose a new science of safety engineering for intelligent artificial agents based on maximizing for what humans value. In particular, we challenge the scientific community to develop intelligent systems that have human-friendly values that they provably retain, even under recursive self-improvement. © 2012 Springer Science+Business Media B.V.},
author_keywords={AI confinement;  AI safety;  Friendly artificial intelligence;  Intelligence explosion;  Machine ethics;  Robot rights},
references={Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) J Exp Theor Artif Intell, 12, pp. 251-261; Allen, C., Smit, I., Wallach, W., Artificial morality: top-down, bottom-up, and hybrid approaches (2005) Ethics Inf Technol, 7 (3), pp. 149-155; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) IEEE Intell Syst, 21 (4), pp. 12-17; Anderson, M., Anderson, S.L., Machine ethics: creating an ethical intelligent agent (2007) AI Mag, 28 (4), pp. 15-26; Arneson, R.J., What, if anything, renders all humans morally equal? (1999) Peter Singer and His Critics, , D. Jamieson (Ed.), Oxford: Blackwell; Asimov, I., Runaround (1942) In: Astounding science fiction, pp. 94-103. , March; Berg, P., Baltimore, D., Brenner, S., Roblin, R.O., Singer, M.F., Summary statement of the Asilomar conference on recombinant DNA molecules (1975) Proc Natl Acad Sci USA, 72 (6), pp. 1981-1984; Bishop, M., Why computers can't feel pain (2009) Mind Mach, 19 (4), pp. 507-516; Bostrom, N., Existential risks: analyzing human extinction scenarios and related hazards (2002) J Evol Technol, 9 (1); Bostrom, N., How long before superintelligence (2006) Linguist Philos Investig, 5 (1), pp. 11-30; Butler, S., (1863) Darwin among the machines, letter to the Editor, , The Press, Christchurch, New Zealand, 13 June 1863; Butler, S., (1872) Erewhon: Or, over the range, , Penguin, London; Chalmers, D.J., The singularity: a philosophical analysis (2010) J Conscious Stud, 17, pp. 7-65; Churchland, P.S., (2011) Brain Trust, , Princeton: Princeton University Press; Clarke, R., Asimov's laws of robotics: implications for information technology, part 1 (1993) IEEE Comput, 26 (12), pp. 53-61; Clarke, R., Asimov's laws of robotics: implications for information technology, part 2 (1994) IEEE Comput, 27 (1), pp. 57-66; de Garis, H., (2005) The Artilect War: Cosmists versus Terrans, , Palm Springs: ETC. Publications; Dennett, D.C., Why you can't make a computer that feels pain (1978) Synthese, 38 (3), pp. 415-456; Drescher, G., (2006) Good and Real: Demystifying Paradoxes from Physics to Ethics, , Cambridge: MIT Press; Drexler, E., (1986) Engines of Creation, , New York: Anchor Press; Fox, J., (2011) Morality and super-optimizers, , Paper presented at the Future of Humanity Conference, 24 Oct 2011, van Leer Institute, Jerusalem; Fox, J., Shulman, C., Superintelligence does not imply benevolence (2010) Proceedings of the VIII European Conference on Computing and Philosophy, , K. Mainzer (Ed.), Munich: Verlag Dr. Hut; Gauthier, D., (1986) Morals by Agreement, , Oxford: Oxford University Press; Gavrilova, M., Yampolskiy, R., Applying biometric principles to avatar recognition (2011) Trans Comput Sci XII, pp. 140-158; Goertzel, B., (2011) Does humanity need an AI nanny, , H+ Magazine, 17 Aug 2011; Goertzel, B., Pennachin, C., (2007) Essentials of General Intelligence: The Direct Path to Artificial General Intelligence, , Berlin: Springer; Good, I.J., Speculations concerning the first ultraintelligent machine (1965) Adv Comput, 6, pp. 31-88; Gordon, D.F., (1998) Well-behaved Borgs, bolos, and berserkers, , Paper presented at the 15th International Conference on Machine Learning (ICML98), San Francisco, CA; Gordon-Spears, D.F., Asimov's laws: current progress (2003) Lect Notes Comput Sci, 2699, pp. 257-259; Gordon-Spears, D.F., Assuring the behavior of adaptive agents (2005) Agent Technology from a Formal Perspective, pp. 227-259. , M. Hinchey, J. Rash, W. Truszkowski, D. F. Gordon-Spears, and C. Rouff (Eds.), Amsterdam: Kluwer; Grau, C., There is no "I" in "Robot": robots and utilitarianism (2006) IEEE Intell Syst, 21 (4), pp. 52-55; Guo, S., Zhang, G., Robot rights (2009) Science, 323 (5916), p. 876; Hall, J.S., (2007) Beyond AI: Creating the Conscience of the Machine, , Amherst: Prometheus; Hall, J.S., Self-improving AI: an analysis (2007) Mind Mach, 17 (3), pp. 249-259; Hanson, R., (2010) Prefer law to values, , http://www.overcomingbias.com/2009/10/prefer-law-to-values.html, Overcoming Bias, 10 Oct 2010. Retrieved 15 Jan 2012, from; Hobbes, T., (1651) Leviathan, , Oxford University Press, Oxford; Hutter, M., (2005) Universal Artificial Intelligence: Sequential Decisions Based on Algorithmic Probability, , Berlin: Springer; Joy, B., (2000) Why the future doesn't need us, , Wired Magazine, 8, April 2000; Kaczynski, T., Industrial society and its future (1995) The New York Times, , 19 Sep 1995; Kurzweil, R., (2006) The Singularity is near: When Humans Transcend Biology, , New York: Penguin; LaChat, M.R., Artificial intelligence and ethics: an exercise in the moral imagination (1986) AI Mag, 7 (2), pp. 70-79; Legg, S., (2006) Unprovability of Friendly AI, , http://www.vetta.org/2006/09/unprovability-of-friendly-ai/, Vetta Project, 15 Sep 2006. Retrieved Jan. 15, 2012, from; Legg, S., Hutter, M., Universal intelligence: a definition of machine intelligence (2007) Mind Mach, 17 (4), pp. 391-444; Lin, P., Abney, K., Bekey, G., Robot ethics: mapping the issues for a mechanized world (2011) Artif Intell, 175 (5-6), pp. 942-949; McCauley, L., AI Armageddon and the three laws of robotics (2007) Ethics Inf Technol, 9 (2), pp. 153-164; McDermott, D., (2008) Why ethics is a high hurdle for AI, , Paper presented at the North American Conference on Computers and Philosophy, Bloomington, IN; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intell Syst, 21 (4), pp. 18-21; Omohundro, S.M., The basic AI drives (2008) The Proceedings of the First AGI Conference, pp. 483-492. , P. Wang, B. Goertzel, and S. Franklin (Eds.), Amsterdam: IOS Press; Pierce, M.A., Henry, J.W., Computer ethics: the role of personal, informal, and formal codes (1996) J Bus Ethics, 14 (4), pp. 425-437; Powers, T.M., Prospects for a Kantian machine (2006) IEEE Intell Syst, 21 (4), pp. 46-51; Pynadath, D.V., Tambe, M., (2001) Revisiting Asimov's first law: A response to the call to arms, , Paper presented at the Intelligent Agents VIII. International Workshop on Agents, Theories, Architectures and Languages (ATAL'01); Rappaport, Z.H., Robotics and artificial intelligence: jewish ethical perspectives (2006) Acta Neurochir Suppl, 98, pp. 9-12; Roth, D., Do humanlike machines deserve human rights? (2009) Wired, 17. , 19 Jan 2009; Ruvinsky, A.I., Computational ethics (2007) Encyclopedia of Information Ethics and Security, p. 76. , M. Quigley (Ed.), Hershey: IGI Global; Salamon, A., Rayhawk, S., Kramár, J., How intelligible is intelligence? (2010) Proceedings of the VIII European Conference on Computing and Philosophy, , K. Mainzer (Ed.), Munich: Verlag Dr. Hut; Sawyer, R.J., Robot ethics (2007) Science, 318 (5853), p. 1037; Sharkey, N., The ethical frontiers of robotics (2008) Science, 322 (5909), pp. 1800-1801; Sotala, K., From mostly harmless to civilization-threatening: pathways to dangerous artificial general intelligences (2010) Proceedings of the VIII European Conference on Computing and Philosophy, , K. Mainzer (Ed.), Munich: Verlag Dr. Hut; Sotala, K., Advantages of artificial intelligences, uploads, and digital minds (2012) Int J Mach Conscious, 4, pp. 275-291; Sparrow, R., Killer robots (2007) J Appl Philos, 24 (1), pp. 62-77; Tonkens, R., A challenge for machine ethics (2009) Mind Mach, 19 (3), pp. 421-438; Tooby, J., Cosmides, L., The psychological foundations of culture (1992) The Adapted Mind: Evolutionary Psychology and the Generation of Culture, pp. 19-136. , J. Barkow, J. Tooby, and L. Cosmides (Eds.), Oxford: Oxford University Press; Vassar, M., (2005) AI boxing (dogs and helicopters), , http://sl4.org/archive/0508/11817.html, 2 Aug 2005. Retrieved 18 Jan 2012, from; Veruggio, G., Roboethics (2010) IEEE Robot Autom Mag, 17 (2), pp. 105-109; von Ahn, L., Blum, M., Hopper, N., Langford, J., CAPTCHA: using hard AI problems for security (2003) Advances in cryptology-EUROCRYPT 2003: International conference on the theory and applications of cryptographic techniques, pp. 293-311. , In: E. Biham (ed), Warsaw, Poland, May 4-8, 2003 proceedings. Lecture notes in computer science 2656, Berlin, Springer; Wallach, W., Allen, C., (2006) EthicALife: A new field of inquiry, , Paper presented at the AnAlifeX workshop, USA; Wallach, W., Allen, C., (2008) Moral Machines: Teaching Robots Right from Wrong, , Oxford: Oxford University Press; Warwick, K., Cyborg morals, cyborg values, cyborg ethics (2003) Ethics Inf Technol, 5, pp. 131-137; Weld, D.S., Etzioni, O., (1994) The first law of robotics (a call to arms), , Paper presented at the Twelfth National Conference on Artificial Intelligence (AAAI); Wright, R., (2001) Nonzero: The Logic of Human Destiny, , New York: Vintage; Yampolskiy, R.V., (2011) AI-complete CAPTCHAs as zero knowledge proofs of access to an artificially intelligent system, , ISRN Artificial Intelligence, 271878; Yampolskiy, R.V., (2011) Artificial intelligence safety engineering: Why machine ethics is a wrong approach, , Philosophy and Theory of Artificial Intelligence, 3-4 Oct, Thessaloniki, Greece; Yampolskiy, R.V., (2011) What to do with the singularity paradox?, , Paper presented at the Philosophy and Theory of Artificial Intelligence (PT-AI2011), 3-4 Oct, Thessaloniki, Greece; Yampolskiy, R.V., Leakproofing singularity: the artificial intelligence confinement problem (2012) J Conscious Stud, 19 (1-2), pp. 194-214; Yampolskiy, R.V., Turing test as a defining feature of AI-completeness (2012) Artificial intelligence, evolutionary computation and metaheuristics-in the footsteps of Alan Turing, , In: Yang X-S (ed). Springer, Berlin; Yampolskiy, R.V., Fox, J., Artificial intelligence and the human mental model (2012) The singularity hypothesis: A scientific and philosophical assessment, , In: Eden A, Moor J, Soraker J, Steinhart E (eds) Springer, Berlin (in press); Yampolskiy, R., Gavrilova, M., (2012) Artimetrics: Biometrics for artificial entities, , IEEE Robot Autom Mag (RAM) (In press); Yampolskiy, R.V., Govindaraju, V., (2008) Behavioral biometrics for verification and recognition of malicious software agents, , Sensors, and Command, Control, Communications, and Intelligence (C3I) Technologies for Homeland Security and Homeland Defense VII. SPIE Defense and Security Symposium, Orlando, Florida, 16-20 Mar; Yudkowsky, E., (2002) The AI-box experiment, , http://yudkowsky.net/singularity/aibox, Retrieved 15 Jan 2012, from; Yudkowsky, E., (2007) The logical fallacy of generalization from fictional evidence, , http://lesswrong.com/lw/k9/the_logical_fallacy_of_generalization_from/, Less Wrong. Retrieved 20 Feb 2012, from; Yudkowsky, E., Artificial intelligence as a positive and negative factor in global risk (2008) Global Catastrophic Risks, pp. 308-345. , N. Bostrom, M. M. Ćirković (Eds.), Oxford: Oxford University Press; Yudkowsky, E., (2010) Timeless decision theory, , http://singinst.org/upload/TDT-v01o.pdf, Retrieved 15 Jan 2012, from; Yudkowsky, E., Complex value systems are required to realize valuable futures (2011) Artificial General Intelligence: 4th International Conference, AGI 2011, Mountain View, CA, USA, August 3-6, 2011, Proceedings, pp. 388-393. , J. Schmidhuber, K. R. Thórisson, and M. Looks (Eds.), Berlin: Springer; Yudkowsky, E., (2011) Open problems in friendly artificial intelligence, , Paper presented at the Singularity Summit, New York; Yudkowsky, E., Bostrom, N., The ethics of artificial intelligence (2011) Cambridge Handbook of Artificial Intelligence, , W. Ramsey and K. Frankish (Eds.), Cambridge: Cambridge University Press},
document_type={Article},
source={Scopus},
}

@ARTICLE{Yudkowsky2011388,
author={Yudkowsky, E.},
title={Complex value systems in friendly AI},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2011},
volume={6830 LNAI},
pages={388-393},
doi={10.1007/978-3-642-22887-2_48},
note={cited By 17},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79961184481&doi=10.1007%2f978-3-642-22887-2_48&partnerID=40&md5=c6e8a458dbea75fd3497ded5dd8dd55c},
abstract={A common reaction to first encountering the problem statement of Friendly AI ("Ensure that the creation of a generally intelligent, self-improving, eventually superintelligent system realizes a positive outcome") is to propose a simple design which allegedly suffices; or to reject the problem by replying that "constraining" our creations is undesirable or unnecessary. This paper briefly presents some of the reasoning which suggests that Friendly AI is solvable, but not simply or trivially so, and that a wise strategy would be to invoke detailed learning of and inheritance from human values as a basis for further normalization and reflection. © 2011 Springer-Verlag Berlin Heidelberg.},
author_keywords={anthropomorphism;  Friendly AI;  machine ethics},
keywords={anthropomorphism;  Complex values;  Friendly AI;  Human values;  machine ethics;  Problem statement},
references={Computer Stupidities: Programming, , http://www.rinkworks.com/stupid/cs_programming.shtml; Kurzweil, R., (2005) The Singularity Is Near: When Humans Transcend Biology, , Viking, New York; Omohundro, S., The basic AI drives (2008) Proceedings of the First AGI Conference, pp. 483-492. , Wang, P., Goertzel, B., Franklin, S. (eds.). IOS Press, Amsterdam; Schmidhuber, J., Gödel machines: Fully self-referential optimal universal self-improvers (2006) Artificial General Intelligence, pp. 119-226. , Goertzel, B., Pennachin, C. (eds.), Springer, Heidelberg; Hibbard, B., Super-intelligent machines (2001) ACM SIGGRAPH Computer Graphics, 35, p. 1; Hibbard, B., (2004) Message to the SL4 Email List, , http://yudkowsky.net/singularity/AIRisk_Hibbard.html, archived at; McDermott, D., Artificial intelligence meets natural stupidity (1976) SIGART Newsletter, 57, pp. 4-9; Frankena, W., (1973) Ethics, , 2nd edn. Prentice Hall, Englewood Cliffs; Tarleton, N., Coherent Extrapolated Volition: A Meta-level Approach to Machine Ethics, , http://singinst.org/upload/coherent-extrapolated-volition.pdf},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Anderson200453,
author={Anderson, M. and Anderson, S.L. and Armen, C.},
title={Towards machine ethics},
journal={AAAI Workshop - Technical Report},
year={2004},
volume={WS-04-02},
pages={53-59},
note={cited By 17},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-32144449766&partnerID=40&md5=5563ccf7a85575c91359f80fd292636b},
abstract={We contend that the ethical ramifications of machine behavior, as well as recent and potential developments in machine autonomy, necessitate adding an ethical dimension to at least some machines. We lay the theoretical foundation for machine ethics by discussing the rationale for, the feasibilty of, and the benefits of adding an ethical dimension to machines. Finally, we present details of prototype systems and motivate future work. Copyright © 2004, American Association for Artificial Intelligence. All rights reserved.},
keywords={Ethical ramifications;  Machine autonomy;  Machine behavior;  Machine ethics, Artificial intelligence;  Computer science;  Information technology, Learning systems},
references={Anderson, S.L., We are our values (2000) Questioning Matters, An Introduction to Philosophical Inquiry, pp. 606-608. , edited by D. Kolak, Mayfield Publishing Company, Mountain View, California; Bentham, J., (1799) An Introduction to the Principles and Morals of Legislation, , Oxford; Barquin, R.C., (1992) Pursuit of A "Ten Commandments for Computer Ethics", , http://www.brook.edu/its/cei/default.htm, Computer Ethics Institute; Beauchamp, T.L., Childress, J.F., (1979) Principles of Biomedical Ethics, , Oxford University Press; Frankena, W., To be or do, That is the question (1993) Doing and Being, Selected Readings in Moral Philosophy, 208. , edited by J. G. Haber, Macmillan, New York; Heckerman, D.E., Horvitz, E.J., Nathwani, B.N., Toward normative expert systems (1992) Methods of Information in Medicine, 31, pp. 90-105; Mill, J.S., (1974) Utilitarianism, in Utilitarianism and Other Writings, 253. , edited by M. Warnock, New American Library, New York; Mitchell, T., (1997) Machine Learning, , McGraw Hill; Rawls, J., Outline for a Decision Procedure for Ethics (1951) Philosophical Review, 60; Ross, W.D., (1930) The Right and the Good, , Clarendon Press, Oxford},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Gunkel201887,
author={Gunkel, D.J.},
title={The other question: can and should robots have rights?},
journal={Ethics and Information Technology},
year={2018},
volume={20},
number={2},
pages={87-99},
doi={10.1007/s10676-017-9442-4},
note={cited By 16},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031504615&doi=10.1007%2fs10676-017-9442-4&partnerID=40&md5=883ef6a400549341742ed938ec3c33c1},
abstract={This essay addresses the other side of the robot ethics debate, taking up and investigating the question “Can and should robots have rights?” The examination of this subject proceeds by way of three steps or movements. We begin by looking at and analyzing the form of the question itself. There is an important philosophical difference between the two modal verbs that organize the inquiry—can and should. This difference has considerable history behind it that influences what is asked about and how. Second, capitalizing on this verbal distinction, it is possible to identify four modalities concerning social robots and the question of rights. The second section will identify and critically assess these four modalities as they have been deployed and developed in the current literature. Finally, we will conclude by proposing another alternative, a way of thinking otherwise that effectively challenges the existing rules of the game and provides for other ways of theorizing moral standing that can scale to the unique challenges and opportunities that are confronted in the face of social robots. © 2017, The Author(s).},
author_keywords={David Hume;  Emmanuel Levinas;  Ethics;  Philosophy of technology;  Rights;  Robotics;  Social robots},
keywords={Philosophical aspects;  Robotics, David Hume;  Emmanuel Levinas;  Ethics;  Philosophy of technology;  Rights;  Social robots, Robots},
references={Anderson, M., Anderson, S.L., (2011) Machine ethics, , Cambridge University Press, Cambridge; Asaro, P., What should we want from a robot ethic? (2006) International Review of Information Ethics, 6 (12), pp. 9-16. , http://www.i-r-i-e.net/inhalt/006/006_full.pdf; Bartneck, C., van der Hoek, M., Mubin, O., Mahmud, A.A., Daisy, daisy, give me your answer do!—Switching off a robot (2007) In Proceedings of the 2nd ACM/IEEE international conference on human-robot interaction, pp. 217-222; Bartnek, C., Hu, J., Exploring the abuse of robots (2008) Interaction Studies, 9 (3), pp. 415-433; Bauman, Z., (1984) Postmodern ethics, , Blackwell, Oxford; Bentham, J., (1780) An introduction to the principles of morals and legislation, , Burns JH, Hart HL, (eds), Oxford University Press, Oxford; Birch, T., Moral considerability and universal consideration (1993) Environmental Ethics, 15, pp. 313-332; Bostrom, N., (2014) Superintelligence: Paths, dangers, strategies, , Oxford University Press, New York; Breazeal, C.L., (2002) Designing sociable robots, , MIT Press, Cambridge, MA; Bryson, J., Robots should be slaves (2010) Close engagements with artificial companions: Key social, psychological, ethical and design issues, pp. 63-74. , Wilks Y, (ed), John Benjamins, Amsterdam; Bryson, J., Patiency is not a virtue: AI and the design of ethical systems. AAAI Spring Symposium Series (2016) Ethical and Moral Considerations in Non-Human Agents, , http://www.aaai.org/ocs/index.php/SSS/SSS16/paper/view/12686; Calarco, M., (2008) Zoographies: The question of the animal from Heidegger to Derrida, , Columbia University Press, New York; Callicott, J.B., (1989) In defense of the land ethic: Essays in environmental philosophy, , State University of New York Press, Albany, NY; Carpenter, J., (2015) Culture and human-robot interaction in militarized spaces: A war story, , Ashgate, New York; Coeckelbergh, M., Robot rights? Towards a social-relational justification of moral consideration (2010) Ethics and Information Technology, 12 (3), pp. 209-221; Coeckelbergh, M., (2012) Growing moral relations: Critique of moral status ascription, , Palgrave MacMillan, New York; Coeckelbergh, M., Gunkel, D.J., Facing animals: A relational, other-oriented approach to moral standing (2014) Journal of Agricultural & Environmental Ethics, 27 (5), pp. 715-733; Coeckelbergh, M., Gunkel, D.J., Response to “The Problem of the Question About Animal Ethics” by Michal Piekarski (2016) Journal of Agricultural and Environmental Ethics, 29 (4), pp. 717-721; (2016) Draft Report with Recommendations to the Commission on Civil Law Rules on Robotics., , http://www.europarl.europa.eu/, Committee on Legal Affairs; Darling, K., Extending legal protection to social robots (2012) IEEE Spectrum, , http://spectrum.ieee.org/automaton/robotics/artificial-intelligence/extending-legal-protection-to-social-robots; Darling, K., Extending legal protection to social robots: The effects of anthropomophism, empathy, and violent behavior toward robotic objects (2016) Robot law, pp. 213-231. , Calo R, Froomkin AM, Kerr I, (eds), Edward Elgar, Northampton, MA; De Angeli, A., Brahnam, S., Wallis, P., Abuse: The dark side of human–computer interaction (2005) Interact, p. 2005. , http://www.agentabuse.org/; De Tocqueville, A., (2004) Democracy in America, , Penguin, New York; Dennett, D.C., (1998) Brainstorms: Philosophical essays on mind and psychology, , MIT Press, Cambridge, MA; Derrida, J., (2005) Paper Machine, , Stanford University Press, Stanford, CA; Derrida, J., (2008) The animal that therefore I am, , Wills D, (ed), Fordham University Press, New York; Feenberg, A., (1991) Critical theory of technology, , Oxford University Press, Oxford; Floridi, L., (2013) The ethics of information, , Oxford University Press, Oxford; (2007) Bots on the ground: In the field of battle (or even above it), robots are a soldier’s best friend., , http://www.washingtonpost.com/wp-dyn/content/article/2007/05/05/AR2007050501009.html, Garreau, J. Washington Post, 6 May; Gerdes, A., The issue of moral consideration in robot ethics (2015) ACM SIGCAS Computers & Society, 45 (3), pp. 274-280; Goertzel, B., Thoughts on AI morality. Dynamical Psychology: An International (2002) Interdisciplinary Journal of Complex Mental Processes, , http://www.goertzel.org/dynapsyc/2002/AIMorality.htm; Gunkel, D.J., (2007) Thinking otherwise: Philosophy, communication, technology, , Purdue University Press, West Lafayette, IN; Gunkel, D.J., (2012) The machine question: Critical perspectives on AI, robots, and ethics, , MIT Press, Cambridge, MA; Güzeldere, G., The many faces of consciousness: A field guide (1997) The nature of consciousness: Philosophical debates, pp. 1-68. , Block N, Flanagan O, Güzeldere G, (eds), MIT Press, Cambridge, MA; Hall, J.S., Ethics for machines. KurzweilAI.net (2001) July, p. 5. , http://www.kurzweilai.net/ethics-for-machines; Haraway, D.J., (2008) When species meet, , University of Minnesota Press, Minneapolis, MN; Heidegger, M., (1977) The question concerning technology and other essays, , Harper & Row, New York; Hudson, W.D., (1969) The is/ought question: A collection of papers on the central problem in moral philosophy, , Macmillan, London; Hume, D., (1980) A treatise of human nature, , Oxford University Press, New York; Johnson, D.G., Computer systems: Moral entities but not moral agents (2006) Ethics and Information Technology, 8 (4), pp. 195-204; Kant, I., (1983) Grounding for the metaphysics of morals, , Hackett Publishing, Indianapolis, IN; Kurzweil, R., (2005) The singularity is near: When humans transcend biology, , Viking, New York; Levinas, E., (1969) Totality and infinity: An essay on exteriority, , Duquesne University, Pittsburgh, PA; Levy, D., (2005) Robots unlimited: Life in a virtual age, , CRC Press, Boca Raton, FL; Levy, D., The ethical treatment of artificially conscious robots (2009) International Journal of Social Robotics, 1 (3), pp. 209-216; Løgstrup, K.E., (1997) The ethical demand, , University of Notre Dame Press, Notre Dame; Lyotard, J.F., (1984) The postmodern condition: A report on knowledge, , University of Minnesota Press, Minneapolis, MN; MacIntyre, A., Fink, H., Introduction (1997) The ethical demand, , Løgstrup KE, (ed), University of Notre Dame Press, Notre Dame; Marx, K., (1977) Capital: A critique of political economy, , Vintage Books, New York; Nealon, J., (1998) Alterity Politics: Ethics and performative subjectivity, , Duke University Press, Durham, NC; Nourbakhsh, I., (2013) Robot futures, , MIT Press, Cambridge; Piekarski, M., (2016) Journal of Agricultural and Environmental Ethics, 29 (4), pp. 705-715; Reeves, B., Nass, C., (1996) The media equation: How people treat computers, television, and new media like real people and places, , Cambridge University Press, Cambridge; Rosenthal-von der Pütten, A.M., Krämer, N.C., Hoffmann, L., Sobieraj, S., Eimler, S.C., An experimental study on emotional reactions towards a robot (2013) International Journal of Social Robotics, 5 (1), pp. 17-34; Schurz, G., (1997) The is-ought problem: An investigation in philosophical logic, , Springer, Dordrecht; Searle, J., How to derive “ought” from “is (1964) The Philosophical Review, 73 (1), pp. 43-58; Seibt, J., Nørskov, M., Andersen, S.S., (2016) What social robots can and should do: Proceedings of robophilosophy 2016, , IOS Press, Amsterdam; Singer, P., (2009) & Sagan, A, , https://www.theguardian.com/commentisfree/2009/dec/14/rage-against-machines-robots, When robots have feelings, The Guardian; Singer, P.W., (2009) Wired for war: The robotics revolution and conflict in the twenty-first century, , Penguin Books, New York; Sparrow, R., The turing triage test (2004) Ethics and Information Technology, 6 (4), pp. 203-213; Suzuki, Y., Galli, L., Ikeda, A., Itakura, S., Kitazaki, M., Measuring empathy for human and robot hand pain using electroencephalography (2015) Scientific Reports, p. 5; Turkle, S., (2012) Alone together: Why we expect more from technology and less from each other, , Basic Books, New York; Vallor, S., (2016) Technology and the virtues: A philosophical guide to a future worth wanting, , Oxford University Press, Oxford; Velmans, M., (2000) Understanding consciousness, , Routledge, London; Wallach, W., Allen, C., (2009) Moral machines: Teaching robots right from wrong, , Oxford University Press, Oxford; Weizenbaum, J., (1976) Computer power and human reason: From judgment to calculation, , W. H. Freeman, San Francisco; Whitby, B., Sometimes it’s hard to be a robot: A call for action on the ethics of abusing artificial agents (2008) Interacting with Computers, 20 (3), pp. 326-333},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kernaghan2014485,
author={Kernaghan, K.},
title={The rights and wrongs of robotics: Ethics and robots in public organizations},
journal={Canadian Public Administration},
year={2014},
volume={57},
number={4},
pages={485-506},
doi={10.1111/capa.12093},
note={cited By 16},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84916205076&doi=10.1111%2fcapa.12093&partnerID=40&md5=7877997dfe257e8cd8aa2643ecf609e5},
abstract={Some electronics experts believe that robots, like present-day computers, will be commonplace. A diverse assortment of robots, with varying purposes, capacities, forms, and sizes, is emerging with significant implications for the policy, service and regulatory responsibilities of government. This paper explores three public policy fields - aging, health care and defence - where the use of robotics is already substantial or where it is projected to grow substantially and where significant ethical issues exist or are anticipated. Applying ethical theories to the use of robotics is difficult. In the near-term, the focus should be on the ethical standards and behaviour of those designing, manufacturing, programming and operating robots. Several key topics in contemporary public sector ethics, including personal moral responsibility, privacy and accountability, are central to the emerging field of robot ethics. This suggests developing an ethics regime for robotics and examining the need for laws and regulations governing its use. © The Institute of Public Administration of Canada 2014.},
references={Abney, K., Robotics, ethical theory and metaethics: A guide for the perplexed (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 39-52. , edited by Patrick Lin, Keith Abney and George A. Bekey. Cambridge. Mass.: MIT Press; Allen, C., Wallach, W., Moral machines: Contradiction in terms or abdication of human responsibility (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 55-68. , edited by Patrick Lin, Keith Abney and George A. Bekey. Cambridge. Mass.: MIT Press; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-26; Arkin, R., (2007) Governing Lethal Behavior: Embedding Ethics in a Hybrid Deliberative/Reactive Robot Architecture., , http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=52B9156631002C98A1D787BD3E6154F6?doi=10.1.1.110.1610&rep=rep1&type=pdf, Representational and Architectural Considerations. Available at:; Asaro, P.M., What should we want from a robot ethic? (2006) International Review of Information Ethics, 6, pp. 9-16; Asimov, I., (1950) I, Robot, , Gnome Press; Asimov, I., (1985) Robots and Empire, , Doubleday Books; Bekey, G.A., Current trends in robotics: Technology and ethics (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 17-34. , edited by Patrick Lin, Keith Abney and George A. Bekey. Cambridge. Mass.: MIT Press; Borenstein, J., Pearson, Y., Robot caregivers: Harbingers of expanded freedom for all? (2010) Ethics of Information Technology, 12, pp. 277-288; Calo, M.R., Robots and privacy (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 187-201. , edited by Patrick Lin, Keith Abney and George A. Bekey. Cambridge. Mass.: MIT Press; Capurro, R., Nagenborg, M., (2009) Ethics and Robotics, , Amsterdam: IOS Press; Clarke, R., Asimov's laws of robotics: Implications for information technology (1994), http://www.anu.edu.au/people/Roger.Clarke/SOS/Asimov.html, Roger Clarke's Web-Site. Available at:; Coeckelbergh, M., Health care, capabilities, and AI assistive technologies (2010) Ethical Theory and Moral Practice, 13, pp. 181-190; (2009), http://www.usrobotics.us/reports/CCC%20Report.pdf, (May 21). A Roadmap for US Robotics: From Internet to Robotics. Available at:; Crnkovic, G.D., Curuklu, B., Robots: Ethical by design (2012) Ethics and Information Technology, 14, pp. 61-72; Datteri, E., Predicting the long-term effects of human-robot interaction: A reflection on responsibility in medical robotics (2013) Science and Engineering Ethics, 19, pp. 139-160; Decker, M., Caregiving robots and ethical reflection: The perspective of interdisciplinary technology assessment (2008) Artificial Intelligence & Society, 22 (3), pp. 3315-3330; Duffy, B.R., Anthropomorphism and the social robot (2003) Robotics and Autonomous Systems, 42 (3-4), pp. 177-190. , March); (2012), http://europa.eu/rapid/press-release_IP-12-360_en.htm, (April 12). Digital Agenda: Commission consults on rules for wirelessly connected devices - the "Internet of Things." Brussels. Available at:; Forlizzi, J., DiSalvo, C., Gemperle, F., Assistive robotics and an ecology of elders living independently in their homes (2004) Human-Computer Interaction, 19, pp. 25-59; Gates, B., A robot in every home (2007), pp. 58-65. , http://www.scientificamerican.com/article.cfm?id=a-robot-in-every-home, January). Scientific American, Available at:; Guizzo, E., World robot population reaches 8.6 million (2010), http://spectrum.ieee.org/automaton/robotics/industrial-robots/041410-world-robot-population, IEEE Spectrum. Available at:; Hirose, S., A code of conduct for robots coexisting with human beings (1996) Robotics and Autonomous Systems, 18, pp. 101-107. , http://www.sciencedirect.com/science/article/pii/0921889095000747, Available at:; Holman, D.F., (2013), http://opencanada.org/wp-content/uploads/2013/08/SL12CIC017-SSWGP-Holman-v3.pdf, August). The Future of Drones in Canada: Perspectives from a Former RCAF Fighter Pilot. Canadian International Council and Canadian Defence and Foreign Affairs Institute. Available at:; Hornyak, T., Medical robot RP-VITA gets FDA approval (2013), http://ces.cnet.com/8301-34441_1-57563095/medical-robot-rp-vita-gets-fda-approval, January 9). CNET. Available at:; Howlader, D., Moral and ethical questions for robotics public policy (2011) Synesis: A Journal of Science, Technology, Ethics, and Policy, pp. G1-G6; Isom, J., Robotics Laboratory (2005), A Brief History of Robotics. Available at: robotics.megagiant.com/history.html; Levy, D., The ethical treatment of artificially conscious robots (2009) International Journal of Social Robotics, 1 (3), pp. 209-216; Levy, D., The ethics of robot prostitutes (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 223-231. , edited by Lin, Patrick, Keith Abney and George A. Bekey. Cambridge, Mass: MIT Press; Lin, P., Drone-ethics briefing: What a leading robot expert told the CIA (2011), http://www.theatlantic.com/technology/archive/2011/12/drone-ethics-briefing-what-a-leading-robot-expert-told-the-cia/250060, December 15). The Atlantic. Available at:; Lin, P., Bekey, G., Abney, K., (2008), http://ethics.calpoly.edu/ONR_report.pdf, (December 20). Autonomous Military Robotics: Risk, Ethics and Design. San Louis Obispo: California Polytechnic State University. Available at:; Lin, P., Abney, K., Bekey, G., Robot ethics: Mapping the issues for a mechanized world (2011) Artificial Intelligence, 175, pp. 942-949; Lin, P., Abney, K., Bekey, G.A., (2012) Robot Ethics: The Ethical and Social Implications of Robotics, , eds. Cambridge, Mass: MIT Press; Lokhorst, G.-J., van den Hoven, J., Responsibility for military robots (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 145-156. , edited by Lin, Patrick, Keith Abney and George Bekey. Cambridge, Mass: MIT Press; Lovgren, S., Robot code of ethics to prevent android abuse, protect humans (2007), http://news.nationalgeographic.com/news/2007/03/070316-robot-ethics.html, March 16). National Geographic News. Available at:; Matthias, A., Is the Concept of an Ethical Governor Philosophically Sound? (2011), http://www.academia.edu/473656/Is_the_Concept_of_an_Ethical_Governor_Philosophically_Sound, Proceedings of the TIL Ting Perspectives 2011, Tilburg University, Netherlands. Available at:; Merchant, B., These killer autonomous robots are already switched on (2013), http://motherboard.vice.com/blog/these-killer-autonomous-robots-are-already-in-the-trenches, Motherboard. Available at:; Moor, J.H., Four Kinds of Ethical Robots (2009) Philosophy Now, 72, pp. 12-14. , http://philosophynow.org/issues/72/Four_Kinds_of_Ethical_Robots, March/April). Available at:; Murphy, R., Woods, D.D., Beyond Asimov: Three laws of responsible robotics (2009) Intelligent Systems, 24 (4), pp. 14-20. , http://cmapsinternal.ihmc.us/rid=1JD6BQHJT-139V14J-L2D/36.%20Laws%20of%20Robotics%20(WoodsMurphy).pdf, (July/August)Available at:; A robot to make the rounds (2011), http://spinoff.nasa.gov/spinoff2003/hm_4.html, Available at:; (2013), http://robotics.ece.auckland.ac.nz/index.php?option=com_content&task=view&id=31, Robotics History Timeline. Available at:; Robotics, V.O., (2013), http://www.cra.org/ccc/files/docs/2013-Robotics-Roadmap, (March 20). A Roadmap for US Robotics: From Internet to Robotics, 2013 Edition. Available at:; Roger, K., Guse, L., Murdoch, E., Osterreicher, A., Social commitment robots and dementia (2012) Canadian Journal of Aging, 31 (1), pp. 87-94; Rosenberg, R.S., The social impact of intelligent artefacts (2008) AI and Society, 22, pp. 367-383; Scheutz, M., The inherent dangers of unidirectional emotional bonds between humans and social robots (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 205-221. , edited by Lin, Patrick, Keith Abney and George Bekey. Cambridge, Mass: MIT Press; Sharkey, N., Killing made easy: From joysticks to politics (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 111-128. , edited by Lin, Patrick, Keith Abney, and George Bekey. Cambridge, Mass: MIT Press; Sharkey, N., Sharkey, A., The eldercare factory (2012) Gerontology, 58, pp. 282-288; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics and Information Technology, 14, pp. 27-40; Siciliano, B., Khatib, O., (2008) Springer Handbook of Robotics, , eds. Berlin: Springer; Singer, P.W., Isaac Asimov's Laws of Robotics are wrong (2009), http://www.brookings.edu/research/opinions/2009/05/18-robots-singer, May 18). Brookings Institution. Available at:; Sparrow, R., Killer robots (2007) Journal of Applied Philosophy, 24 (1), pp. 62-77; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Minds and Machines, 16, pp. 141-161; Stewart, J., Ready for the robot revolution? (2011), http://www.bbc.co.uk/news/technology-15146053, BBC News: Technology. Available at:; Sullins, J.P., When is a robot a moral agent? (2006) International Review of Information Ethics, 6, pp. 24-30; Taylor, R.H., Menciassi, A., Fichtinger, G., Dario, P., Medical Robotics and Computer-Integrated Surgery (2008) Springer Handbook of Robotics, pp. 1199-1222. , edited by Siciliano, Bruno and Oussama Khatib. Berlin: Springer; (2012), http://www.economist.com/node/21556234, (June 2). "Morals and the machine." Available at:; Tonkens, R., Out of character: On the creation of virtuous machines (2012) Ethics of Information Technology, 14, pp. 137-149; (2011), http://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=24835&section=text, Guideline for External Use of Web 2.0. Available at:; Turcu, C., Turcu, C., Gaitan, V., Integrating robots into the Internet of Things (2012) International Journal of Circuits, Systems and Signal Processing, 6 (6), pp. 430-437; Veruggio, G., Abney, K., Roboethics: The applied ethics for a new science (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 347-363. , edited by Lin, Patrick, Keith Abney and George A. Bekey. Cambridge. Mass.: MIT Press; Wallach, W., From robots to techno sapiens: Ethics, law and public policy in the development of robotics and neurotechnologies (2011) Law, Innovation and Technology, 3 (2), pp. 185-207; Wallach, W., (2012), http://ieet.org/index.php/IEET/more/wallach20120427, April 27). "Issues in the development of robotics and neurotechnologies." Institute for Ethics and Emerging Technologies. Available at:; Warren, P., Launching a new kind of warfare (2006), http://www.theguardian.com/technology/2006/oct/26/guardianweeklytechnologysection.robots, October 26). The Guardian. Available at:; Whitby, B., Do you want a robot lover: The ethics of caring technologies (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 233-248. , edited by Lin, Patrick, Keith Abney and George A. Bekey. Cambridge. Mass.: MIT Press; Whitby, B., Sometimes it's hard to be a robot: A call for action on the ethics of abusing artificial agents (2008) Interacting with Computers, 20, pp. 326-333},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wallach2008463,
author={Wallach, W.},
title={Implementing moral decision making faculties in computers and robots},
journal={AI and Society},
year={2008},
volume={22},
number={4},
pages={463-475},
doi={10.1007/s00146-007-0093-6},
note={cited By 16},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-41549124569&doi=10.1007%2fs00146-007-0093-6&partnerID=40&md5=7367bf7122717788611e8485336630af},
abstract={The challenge of designing computer systems and robots with the ability to make moral judgments is stepping out of science fiction and moving into the laboratory. Engineers and scholars, anticipating practical necessities, are writing articles, participating in conference workshops, and initiating a few experiments directed at substantiating rudimentary moral reasoning in hardware and software. The subject has been designated by several names, including machine ethics, machine morality, artificial morality, or computational morality. Most references to the challenge elucidate one facet or another of what is a very rich topic. This paper will offer a brief overview of the many dimensions of this new field of inquiry. © Springer-Verlag London Limited 2007.},
keywords={Hardware and software;  Moral judgment;  Moral reasoning;  Science fictions, Philosophical aspects},
references={Adams, B.C., Breazeal, R.A., Brooks, B.S., Humanoid robots: A new kind of tool (2000) IEEE Intell Syst Appl. Special Issue on Humanoid Robotics, 15 (4), pp. 25-31; Allen, C., Calculated morality: Ethical computing in the limit (2002) Cognitive, Emotive and Ethical Aspects of Decision Making and Human Action, I. , In: Smit I, Lasker G (eds) IIAS, Windsor; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) J Exp Theor Artif Intell, 12, pp. 251-261; Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up and hybrid approaches (2006) Ethics N Inf Technol, 7, pp. 149-155; Anderson, M., Anderson, S., Armen, C., An approach to computing ethics (2006) IEEE Intell Syst, 21 (4), pp. 56-63; Asimov, I., (1950) I Robot, , Gnome Press, New York; Asimov, I., (1985) Robots and Empire, , Grafton Books, London; (2001) Principles of Biomedical Ethics, , Beauchamp and Childress 5th edn. Oxford University Press, New York; Boella, G., van der Torre, L., Verhagen, H., Introduction to normative multiagent systems (2005) Proceedings of the Symposium on Normative Multi-Agent Systems, AISB-05, pp. 1-7. , In: University of Hertfordshire, Hatfield; Breazeal, C., (2002) Designing Sociable Robots, , MIT, Cambridge; Brooks, R., (2002) Flesh and Machines, , Pantheon Press, New York; Calverley, D., Additional thoughts concerning the legal status of a non-biological machine (2005) Machine Ethics, , In: Anderson M, Anderson S, Armen C (eds) AAAI Press, Menlo Park. Technical Report FS-05-06; Clarke, R., Asimov's laws of robotics: Implications for information technology. Published in two parts (1993) IEEE Comput, 26 (12), pp. 53-61. , and 27(1) 57-66; de Garis, H., (2005) The Artilect War: Cosmists Vs Terrans: A Bitter Controversy Concerning Whether Humans Should Build Godlike Massively Intelligent Machines, , ETC Publications, Palm Springs; Damasio, A., (1995) Descartes' Error, , Picador, London; Danielson, P., (1992) Artificial Morality: Virtuous Robots for Virtual Games, , Routledge, New York; Danielson, P., (1998) Modeling Rationality, Morality and Evolution, , Oxford University Press, Oxford; DeSousa, R., (1987) The Rationality of Emotions, , MIT Press, Cambridge; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds Mach, 14 (3), pp. 349-379; Franklin, S., IDA: A conscious artifact? (2003) J Conscious Stud. Special Issue on Machine Consciousness, 10 (4-5), pp. 47-66. , In Holland O (ed); Friedman, B., Kahn, P., Human agency and responsible computing: Implications for computer system design (1992) J Syst Softw, 17 (1), pp. 7-14; Gips, J., Towards the ethical robot (1991) Android Epistemology, pp. 243-252. , In: Ford K, Glymour C, Hayes P (eds) MIT, Cambridge; Goleman, D., (1995) Emotional Intelligence, , Bantam Books, New York; Guarini, M., Particularism and classification and reclassification of moral cases (2006) IEEE Intell Syst, 21 (4), pp. 22-28; (2003) J Conscious Stud. Special Issue on Machine Consciousness, 10 (4-5). , Holland O (ed); Joy, W., Why the future does not need us (2000) Wired Magazine, 8 (4); Kennedy, C., Reducing indifference: Steps towards autonomous agents with human concerns. Artificial intelligence, ethics and (quasi-) human rights (2000) Proceedings of AISB-2000 Workshop, pp. 7-16. , In: University of Birmingham, Birmingham; Kennedy, C., Agents for trustworthy ethical assistance (2004) Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, 3. , In: Smit I, Lasker G and Wallach W (eds) IIAS, Windsor; Knaus, W., APACHE 1978-2001: The development of a quality assurance system based on prognosis (2002) Arch Surg, 137 (1), pp. 37-41; Kraus, S., (2001) Strategic Negotiations in Multiagent Environments, , MIT, Cambridge; Kurzweil, R., (1999) The Age of Spiritual Machines: When Computers Exceed Human Intelligence, , Viking, New York; Kurzweil, R., (2002) Are We Spiritual Machines? Ray Kurzweil Vs. the Critics of Strong A.I, , in Richards JW (ed) Discovery Institute Press; Kurzweil, R., (2005) The Singularity Is Near, , Viking, New York; Lang, C., (2002) Ethics for Artificial Intelligence, , http://www.philosophy.wisc.edu/lang/AIEthics/index.htm; Moravec, H., (1998) Robot: Mere Machine to Transcendent Mind, , Oxford University Press, Oxford; Nissenbaum, H., Accountability in a computerized society (1996) Sci Eng Ethics, 2, pp. 25-42; Nolfi, N., Evolutionary robotics: Exploiting the full power of self-organization (1998) Connection Science, (10), pp. 167-183. , 3-4; Picard, R., (1997) Affective Computing, , MIT, Cambridge; Pollack, J., (2004) Seven Questions for the Age of Robots", , http://www.jordanpollack.com/sevenlaws.htm, talk given at Yale University 4 February 2004; Scassellati, B., Foundations for a theory of mind for a humanoid robot (2001), http://www.ai.mit.edu/projects/lbr/hrg/2001/scassellati-phd.pdf, PhD Thesis. Department of Electrical Engineering and Computer Science, MIT; Simon, H.A., (1982) Models of Bounded Rationality, , MIT, Cambridge; Smit, I., Robots, Quo Vadis (2003) Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intellignce, , In: Smit I, Lasker G, Wallach W (eds) IIAS, Windsor; Salovey, P., Mayer, J.D., Emotional intelligence (1990) Imagin Cogn Pers, 9, pp. 185-211; Turing, A., Computing machinery and intelligence (1950) Mind, 49, pp. 433-460; Wallach, W., Robot morals and human ethics (2003) Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, 2. , In: Smit I, Lasker L, Wallach W (eds) IIAS, Windsor; Wallach, W., Artificial morality: Bounded rationality, bounded morality and emotions (2004) Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, 3. , In: Smit I, Lasker G, Wallach W (eds) IIAS, Windsor; Weckert, J., Trusting agents (2005) Ethics of New Information Technology: CEPE2005, pp. 407-412. , In: Enschede, Holland; Whitby, B., Oliver, K., How to avoid a robot takeover: Political and ethical choices in the design and introduction of intelligent artifacts. Artificial intelligence, ethics and (quasi-) human rights (2000) Proceedings of AISB-2000 Workshop, pp. 53-58. , In: University of Birmingham, Birmingham},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sawyer20071037,
author={Sawyer, R.J.},
title={Robot ethics},
journal={Science},
year={2007},
volume={318},
number={5853},
pages={1037},
doi={10.1126/science.1151606},
note={cited By 16},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-36249029931&doi=10.1126%2fscience.1151606&partnerID=40&md5=388c45d7859b2e0eaa15f73493d1af53},
keywords={behavior;  editorial;  ethics;  government;  human;  law;  machine;  priority journal;  robotics},
document_type={Editorial},
source={Scopus},
}

@ARTICLE{Petersen200743,
author={Petersen, S.},
title={The ethics of robot servitude},
journal={Journal of Experimental and Theoretical Artificial Intelligence},
year={2007},
volume={19},
number={1},
pages={43-54},
doi={10.1080/09528130601116139},
note={cited By 16},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847283903&doi=10.1080%2f09528130601116139&partnerID=40&md5=9b661a50fdf12c23f1c54a843db2f9b5},
abstract={Assume we could someday create artificial creatures with intelligence comparable to our own. Could it be ethical use them as unpaid labor? There is very little philosophical literature on this topic, but the consensus so far has been that such robot servitude would merely be a new form of slavery. Against this consensus I defend the permissibility of robot servitude, and in particular the controversial case of designing robots so that they want to serve (more or less particular) human ends. A typical objection to this case draws an analogy to the genetic engineering of humans: if designing eager robot servants is permissible, it should also be permissible to design eager human servants. Few ethical views can easily explain even the wrongness of such human engineering, however, and those few explanations that are available break the analogy with engineering robots. The case turns out to be illustrative of profound problems in the field of population ethics.},
author_keywords={Artificial intelligence;  Computer ethics;  Intelligence;  Population ethics;  Robot ethics;  Robot labour;  Robot rights;  Robotics;  Servitude;  Slavery},
keywords={Artificial intelligence;  Computation theory;  Genetic engineering;  Human engineering;  Robots, Computer ethics;  Population ethics;  Robot ethics;  Robot labor;  Robot rights, Robotics},
references={Adams, D., (1982) The Restaurant at the End of the Universe, , New York: Pocket Books, original work published 1980; Aristotle, Nicomachean Ethics. T. Icwin, Transl., Indianapolis: Hackett, 1985 (original work published ca. 350 BCE); I. Asimov, I, Robot. Greenwich, Connecticut: Fawcett, 1970 (original work published 1950); Block, R., Korea to test 1000 remote-controlled domestic robots (2006) Avaliable, , http:// www.engadget.com/2006/07/02/korea-to- test-1-000-remote-controlled-domestic-robots, online at:, accessed 28 September; Clark, A., (2001) Mindware, , Oxford: Oxford University Press; Dennett, D.C., Language and intelligence (1994) What is Intelligence, pp. 161-178. , J. Khalfa, Ed, Cambridge: Cambridge University Press; Huxley, A., (1998) Brave New World, , New York: HarperCollins, original work published 1932; I. Kant, Lectures on Ethics, L. Infileld, Transi., New York: Harper Torchbooks, 1963 (original work published 1930); I. Kant, Foundations of the Metaphysics of Morals. L.W. Beck, Transl., New York: Macmillan, 1989 (original work published 1785); LaChat, M.R., Artificial intelligence and ethics: An exercise in the moral imagination (1986) AI Magazine, 1, pp. 70-79; R. Lucas, Why bother? Ethical computers-that's why!, in Conferences in Research and Practice in Information Technology, J. Weckert, Ed., 1, Canberra: Australian Computer Society, 2001, pp. 33-38; Lycan, W.G., (1995) Consciousness, , Cambridge, MA: MIT Press, original work published 1987; Mill, J.S., Utilitarianism (1993) On Liberty and Utilitarianism, pp. 131-211. , New York: Bantam Books, original work published 1863; Parfit, D., (1987) Reasons and Persons, , Oxford: Oxford University Press, original work published 1984; J. Ryberg, T. Tännsjö and G. Arrhenius, The repugnant conclusion, in The Stanford Encyclopedia of Philosophy, E.N., Zalta, Ed., Avaliable online at: ; http://plato.stanford.edu/archives/spr2006/ entries/repugnant-conclusion/ (accessed 4 October 2006); Trust me, Trust me, I'm a robot, Economist. Avaliable online at: http://www.economist.com/ displaystory.cfm?story_id = 7001829 (accessed 5 October 2006); Walker, M., Mary Poppins 3000s of the world unite: A moral paradox in the creation of artificial intelligence (2006) Avaliable, , http://ieet.org/index.php/IEET/more/walker20060101, online at:, accessed 4 March; Zunt, D., Who did actually invent the word robot and what does it mean? (2006) Avaliable, , http://capek.misto.cz/english/robot.html, online at:, accessed 21 September},
document_type={Article},
source={Scopus},
}

@ARTICLE{Anderson200610,
author={Anderson, M. and Anderson, S.L.},
title={Machine ethics},
journal={IEEE Intelligent Systems},
year={2006},
volume={21},
number={4},
pages={10-11},
doi={10.1109/MIS.2006.70},
art_number={1667946},
note={cited By 16},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33747236090&doi=10.1109%2fMIS.2006.70&partnerID=40&md5=82f499a6a423ee8668fd6345c9c53cf9},
document_type={Editorial},
source={Scopus},
}

@ARTICLE{Brundage2014355,
author={Brundage, M.},
title={Limitations and risks of machine ethics},
journal={Journal of Experimental and Theoretical Artificial Intelligence},
year={2014},
volume={26},
number={3},
pages={355-372},
doi={10.1080/0952813X.2014.895108},
note={cited By 15},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903277501&doi=10.1080%2f0952813X.2014.895108&partnerID=40&md5=bb98d7479772634c74d991aea91c61e2},
abstract={Many authors have proposed constraining the behaviour of intelligent systems with machine ethics to ensure positive social outcomes from the development of such systems. This paper critically analyses the prospects for machine ethics, identifying several inherent limitations. While machine ethics may increase the probability of ethical behaviour in some situations, it cannot guarantee it due to the nature of ethics, the computational limitations of computational agents and the complexity of the world. In addition, machine ethics, even if it were to be solved at a technical level, would be insufficient to ensure positive social outcomes from intelligent systems. © 2014 Taylor & Francis.},
author_keywords={artificial general intelligence;  machine ethics;  risk},
keywords={Intelligent systems;  Risks, Artificial general intelligences;  Computational agents;  Computational limitations;  Inherent limitations;  Social outcomes;  Technical levels, Philosophical aspects;  Risks},
references={Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12, pp. 251-261; Allenby, B., The ethics of emerging technologies: Real time macroethical assessment (2009) IEEE International Symposium on Sustainable Systems and Technology, ISSST '09; Allen, C., Wallach, W., (2010) Moral Machines: Teaching Robots Right from Wrong, , New York, NY: Oxford University Press; Allenby, B., Sarewitz, D., Out of control: How to live in an unfathomable world (2011) New Scientist, 2812, pp. 28-29; Anderson, M., Anderson, S.L., (2011) Machine Ethics, , New York, NY: Cambridge University Press; Arkin, R., (2009) Governing Lethal Behavior in Autonomous Robots, , London: Chapman and Hall; Berker, S., The normative insignificance of neuroscience (2009) Philosophy and Public Affairs, 37, pp. 293-329; Berlin, I., (1991) The Crooked Timber of Humanity: Chapters in the History of Ideas, , New York, NY: Alfred A. Knopf; Boehm, C., (2012) Moral Origins: The Evolution of Virtue, Altruism, and Shame, , New York, NY: Basic Books; Boehm Bringsjord, S., (2009) Unethical but Rule-bound Robots Would Kill Us All, , http://kryten.mm.rpi.edu/PRES/AGI09/SB_agi09_ethicalrobots.pdf, Retrieved February 28, 2013; Bringsjord, S., Bello, P., On how to build a moral machine (2012) Topoi, pp. 0167-7411; Bringsjord, S., Johnson, J., Rage against the machine (2012) The Philosophers' Magazine, 57, pp. 90-95; Bringsjord, S., Taylor, J., Van Heuveln, B., Arkoudas, K., Clark, M., Wojtowicz, R.L., Piagetian roboethics via category theory: Moving beyond mere formal operations to engineer robots whose decisions are guaranteed to be ethically correct (2011) Machine Ethics, pp. 361-374. , M. Anderson & S. L. Anderson (Eds.), New York, NY: Cambridge University Press; Cloos, C., Utilibot project: An autonomous mobile robot based on utilitarianism (2005) American Association for Artificial Intelligence; Cloos Crouch, W., The most important unsolved problems in ethics (2012) Practical Ethics, , http://blog.practicalethics.ox.ac.uk/2012/10/the-most-important-unsolved- problems-in-ethics-or-how-to-be-a-high-impact-philosopher-part-iii/, (blog). Retrieved February 28, 2013; Cushman, F.A., Young, L., Greene, J., Multi-system moral psychology (2012) The Moral Psychology Handbook, pp. 47-71. , J. M. Doris & the Moral Psychology Research Group (Eds.), New York, NY: Oxford University Press; Darwin, C., (1871) The Descent of Man, and Selection in Relation to Sex, , London: John Murray; Deghani, M., Tomai, E., Forbus, K., Klenk, M., An integrated reasoning approach to moral decision making (2011) Machine Ethics, pp. 422-441. , M. Anderson & S. L. Anderson (Eds.), New York, NY: Cambridge University Press; Klenk Freeman, T., (2009) Using Compassion and Respect to Motivate An Artificial Intelligence, , http://www.fungible.com/respect/paper.html, Retrieved February 28, 2013; Gert, B., (2007) Common Morality: Deciding What to Do, , New York, NY: Oxford University Press; Gigerenzer, G., Moral satisficing: Rethinking moral behavior as bounded rationality (2010) Topics in Cognitive Science, 2, pp. 528-554; Goertzel, B., (2006) Apparent Limitations on the AI Friendliness and Related Concepts Imposed by the Complexity of the World, , http://www.goertzel.org/papers/LimitationsOnFriendliness.pdf, Retrieved February 28, 2013; Gomila, A., Amengual, A., Moral emotions for autonomous agents (2009) Handbook of Research on Synthetic Emotions and Sociable Robotics: New Applications in Affective Computing and Artificial Intelligence, pp. 166-180. , J. Vallverdu & D. Casacuberta (Eds.), Hershey: IGI Global; Gowans, C., (1987) Moral Dilemmas, , New York, NY: Oxford University Press; Grau, C., There is no i in Robot: Robots and utilitarianism (2006) IEEE Intelligent Systems, 21, pp. 52-55; Guarini, M., Computational neural modeling and the philosophy of ethics: Reflections on the particularism-generalism debate (2011) Machine Ethics, pp. 316-334. , M. Anderson & S. L. Anderson (Eds.), New York, NY: Cambridge University Press; Haidt, J., (2012) The Righteous Mind: Why Good People Are Divided by Politics and Religion, , New York, NY: Pantheon; Hanson, R., Economic growth given machine intelligence (2001) Journal of Artificial Intelligence Research, , http://hanson.gmu.edu/aigrow.pdf; Helbing, D., (2010) Systemic Risks in Society and Economics, , Lausanne: International Risk Governance Council; Horgan, T., Timmons, M., What does the frame problem tell us about moral normativity? (2009) Ethical Theory and Moral Practice, 12, pp. 25-51; (2012) Losing Humanity: The Case Against Killer Robots, , Human Rights Watch and International Human Rights Clinic, New York, NY: Human Rights Watch; Klein, C., The dual track theory of moral decision-making: A critique of the neuroimaging evidence (2011) Neuroethics, 4, pp. 143-162; Lenman, J., Consequentialism and cluelessness (2000) Philosophy and Public Affairs, 29, pp. 342-370; Mackworth, A., Architectures and ethics for robots: Constraint satisfaction as a unitary design framework (2011) Machine Ethics, pp. 335-360. , M. Anderson & S. L. Anderson (Eds.), New York, NY: Cambridge University Press; Matthias, A., Algorithmic moral control of war robots: Philosophical questions (2011) Law, Science, and Technology, 3, pp. 279-301; Mayer, R.C., Davis, J.H., Schoorman, F.D., An integrative model of organizational trust (1995) Academy of Management Review, 20, pp. 709-734; McLaren, B., Computational models of ethical reasoning: Challenges, initial steps, and future directions (2011) Machine Ethics, pp. 297-315. , M. Anderson & S. L. Anderson (Eds.), New York, NY: Cambridge University Press; Müller, V., Autonomous cognitive systems in real-world environments: Less control, more flexibility and better interaction (2012) Cognitive Computation, 4, pp. 212-215; Nelson, R., Sarewitz, D., Three rules for technological fixes (2008) Nature, 456, pp. 871-872; Omohundro, S., The basic AI drives (2008) Proceedings of the First AGI Conference: Frontiers in Artificial Intelligence and Applications, 171, pp. 483-492. , P. Wang, B. Goertzel, & S. Franklin (Eds.), Amsterdam: IOS Press; Parfit, D., (2011) On What Matters, , New York, NY: Oxford University Press; Pojman, L., (2005) Ethics: Discovering Right & Wrong, , Belmont, CA: Wadsworth Publishing; Pontier, M., Widdershoven, G., Hoorn, J., Moral coppelia-Combining ratio with affect in ethical reasoning (2012) IBERAMIA 2012, pp. 442-451. , J. Pavón, N. D. Duque-Méndez, & R. Fuentes- Fernández (Eds.), Lecture Notes in Computer Science. New York: Springer; Powers, T., Prospects for a kantian machine (2011) Machine Ethics, pp. 464-475. , M. Anderson & S. L. Anderson (Eds.), New York, NY: Cambridge University Press; Reynolds, C.J., On the computational complexity of action evaluations (2005) Presented at Computer Ethics: Philosophical Enquiry, , http://affect.media.mit.edu/pdfs/05.reynolds-cepe.pdf; Ross, W.D., (1988) The Right and the Good, , Cambridge: Hackett Publishing; Savulescu, J., Persson, I., (2012) Unfit for the Future: The Need for Moral Enhancement, , New York, NY: Oxford University Press; Shaw, W., (1999) Contemporary Ethics: Taking Account of Utilitarianism, , Hoboken, NJ: Wiley-Blackwell; Shulman, C., (2010) Omohundro's Basic AI Drives and Catastrophic Risks, , Berkeley, CA: Machine Intelligence Research Institute; Shulman, C., Tarleton, N., Jonsson, H., Which consequentialism? Machine ethics and moral divergence (2009) Proceedings of AP-CAP 2009, pp. 23-25. , C. Reynolds & A. Cassinelli (Eds.), Tokyo: University of Tokyo; Sinnott-Armstrong, W., (1988) Moral Dilemmas (Philosophical Theory), , Hoboken, NJ: Blackwell; Sotala, K., Yampolskiy, R., (2013) Responses to Catastrophic AGI Risk: A Survey, , (Technical Report No. 2013-2) Berkeley, CA: Machine Intelligence Research Institute; Taleb, N., (2007) The Black Swan, , New York, NY: Random House; Tarleton, N., (2010) Coherent Extrapolated Volition: A Meta-level Approach to Machine Ethics, , Berkeley, CA: Machine Intelligence Research Institute; Tosic, P., Agha, G., On the computational complexity of predicting dynamical evolution of large agent ensembles (2005) Proceedings of the Third European Workshop on Multi-agent Systems EUMAS '05, pp. 415-426. , M. P. Gleizes, G. A. Kaminka, A. Nowé S. Ossowski, K. Tuyls, & K. Verbeeck (Eds.), Brussels: Flemish Academy of Sciences; Wallach, W., Allen, C., (2010) Moral Machines: Teaching Robots Right from Wrong, , New York, NY: Oxford University Press; Wang, P., (2006) Rigid Flexibility: The Logic of Intelligence, , New York, NY: Springer; Waser, M., Rational universal benevolence: Simpler, safer, and wiser than Friendly AI (2011) Artificial General Intelligence: Lecture Notes in Computer Science, 6830, pp. 153-162; Williams, B., (1973) Problems of the Self, , Cambridge: Cambridge University Press; Williams, B., Smart, J.J.C., (1973) Utilitarianism: For and Against, , New York, NY: Cambridge University Press; Wolf, S., Moral saints (1982) The Journal of Philosophy, 79, pp. 419-439; Yudkowsky, E., (2001) Creating Friendly AI 1.0: The Analysis and Design of Benevolent Goal Architectures, , Berkeley, CA: Machine Intelligence Research Institute; Yudkowsky, E., Levels of organization in general intelligence (2007) Artificial General Intelligence, pp. 389-502. , B. Goertzel & C. Pennachin (Eds.), New York, NY: Springer; Yudkowsky, E., Complex value systems are required to realize valuable futures (2011) Proceedings of AGI 2011, pp. 388-393. , J. Schmidhuber, K. R. Thórisson, & M. Looks (Eds.), New York, NY: Springer},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Tonkens2012137,
author={Tonkens, R.},
title={Out of character: On the creation of virtuous machines},
journal={Ethics and Information Technology},
year={2012},
volume={14},
number={2},
pages={137-149},
doi={10.1007/s10676-012-9290-1},
note={cited By 15},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860161974&doi=10.1007%2fs10676-012-9290-1&partnerID=40&md5=e5802e1455eb3903e0b2e2de2eaffa78},
abstract={The emerging discipline of Machine Ethics is concerned with creating autonomous artificial moral agents that perform ethically significant actions out in the world. Recently, Wallach and Allen (Moral machines: teaching robots right from wrong, Oxford University Press, Oxford, 2009) and others have argued that a virtue-based moral framework is a promising tool for meeting this end. However, even if we could program autonomous machines to follow a virtue-based moral framework, there are certain pressing ethical issues that need to be taken into account, prior to the implementation and development stages. Here I examine whether the creation of virtuous autonomous machines is morally permitted by the central tenets of virtue ethics. It is argued that the creation of such machines violates certain tenets of virtue ethics, and hence that the creation and use of those machines is impermissible. One upshot of this is that, although virtue ethics may have a role to play in certain near-term Machine Ethics projects (e. g. designing systems that are sensitive to ethical considerations), machine ethicists need to look elsewhere for a moral framework to implement into their autonomous artificial moral agents, Wallach and Allen's claims notwithstanding. © 2012 Springer Science+Business Media B.V.},
author_keywords={Autonomous artificial moral agents;  Machine ethics;  Social justice;  Virtue ethics;  Wallach and Allen},
references={Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) IEEE Intelligent Systems, 21 (4), pp. 12-17; Anderson, S., Asimov's 'three laws of robotics' and machine metaethics (2008) AI & Society, 22 (4), pp. 477-493; Anderson, M., Anderson, S., The status of machine ethics: A report from the AAAI symposium (2007) Minds and Machines, 17 (1), pp. 1-10; Anderson, M., Anderson, S., Machine ethics: creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-26; Arkin, R., Ethical robots in warfare (2009) IEEE Technology and Society Magazine, pp. 30-33. , Spring; Arkin, R., (2009) Governing Lethal Behavior in Autonomous Robots, , Dordrecht: Chapman & Hall; Asaro, P., How just could a robot war be? (2008) Current Issues in Computing and Philosophy, pp. 50-64. , P. Brey, A. Briggle, and K. Waelbers (Eds.), Amsterdam: IOS Press; Calverley, D.J., Imagining a non-biological machine as a legal person (2008) AI & Society, 22 (4), pp. 523-537; Foot, P., Euthanasia (1977) Philosophy & Public Affairs, 6 (2), pp. 85-112; Grau, C., There is no 'I' in 'Robot': Robots and utilitarianism (2006) IEEE Intelligent Systems, 21 (4), pp. 52-55; Guarini, M., Bello, P., Robotic warfare: Some challenges in moving from non civilian to civilian theaters (2011) Robot ethics: The ethical and social implications of robotics, , In P. Lin, G. Bekey & K. Abney (Eds.), Cambridge: MIT Press; Hursthouse, R., Virtue theory and abortion (1997) Virtue Ethics: A Critical Reader, pp. 227-244. , D. Statman (Ed.), Washington: Georgetown University Press; Hursthouse, R., (1999) On Virtue Ethics, , Oxford: Oxford University Press; Krishnan, A., (2009) Killer Robots: The Legality and Ethicality of Autonomous Weapons, , Farnham: Ashgate; Lin, P., Bekey, G., Abney, K., (2008) Report on autonomous military robotics: Risk, ethics, and design, , http://ethics.calpoly.edu/ONR_report.pdf, Available at: Retrieved February 1, 2010; McMahan, J., (2009) Killing in War, , Oxford: Clarendon Press; Moor, J., The nature, importance, and difficulty of Machine Ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Oakley, J., Cocking, D., (2001) Virtue Ethics and Professional Roles, , Cambridge: Cambridge University Press; Powers, T.M., Prospects for a Kantian machine (2006) IEEE Intelligent Systems, 21 (4), pp. 46-51; Singer, P.W., (2009) Wired for War: The Robotics Revolution and Conflict in the 21st Century, , New York: Penguin; Sparrow, R., Killer robots (2007) Journal of Applied Philosophy, 24 (1), pp. 62-77; Swanton, C., (2003) Virtue Ethics: A Pluralistic View, , New York: Oxford University Press; Tonkens, R., A challenge for machine ethics (2009) Minds and Machines, 19 (3), pp. 421-438; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford: Oxford University Press},
document_type={Article},
source={Scopus},
}

@BOOK{Anderson20111,
author={Anderson, M. and Anderson, S.L.},
title={Machine ethics},
journal={Machine Ethics},
year={2011},
volume={9780521112352},
pages={1-538},
doi={10.1017/CBO9780511978036},
note={cited By 15},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927108085&doi=10.1017%2fCBO9780511978036&partnerID=40&md5=af1352cce51e0ae767f6bccb0bab8b29},
abstract={The new field of machine ethics is concerned with giving machines ethical principles, or a procedure for discovering a way to resolve the ethical dilemmas they might encounter, enabling them to function in an ethically responsible manner through their own ethical decision making. Developing ethics for machines, in contrast to developing ethics for human beings who use machines, is by its nature an interdisciplinary endeavor. The essays in this volume represent the first steps by philosophers and artificial intelligence researchers toward explaining why it is necessary to add an ethical dimension to machines that function autonomously, what is required in order to add this dimension, philosophical and practical challenges to the machine ethics project, various approaches that could be considered in attempting to add an ethical dimension to machines, work that has been done to date in implementing these approaches, and visions of the future of machine ethics research. © Cambridge University Press 2011.},
keywords={Artificial intelligence, Ethical decision making;  Ethical dilemma;  Ethical principles;  Human being;  Interdisciplinary endeavor, Philosophical aspects},
document_type={Book},
source={Scopus},
}

@ARTICLE{Howard20181521,
author={Howard, A. and Borenstein, J.},
title={The Ugly Truth About Ourselves and Our Robot Creations: The Problem of Bias and Social Inequity},
journal={Science and Engineering Ethics},
year={2018},
volume={24},
number={5},
pages={1521-1536},
doi={10.1007/s11948-017-9975-2},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029675266&doi=10.1007%2fs11948-017-9975-2&partnerID=40&md5=f2a1576054e1f82483755e5e8fee4327},
abstract={Recently, there has been an upsurge of attention focused on bias and its impact on specialized artificial intelligence (AI) applications. Allegations of racism and sexism have permeated the conversation as stories surface about search engines delivering job postings for well-paying technical jobs to men and not women, or providing arrest mugshots when keywords such as “black teenagers” are entered. Learning algorithms are evolving; they are often created from parsing through large datasets of online information while having truth labels bestowed on them by crowd-sourced masses. These specialized AI algorithms have been liberated from the minds of researchers and startups, and released onto the public. Yet intelligent though they may be, these algorithms maintain some of the same biases that permeate society. They find patterns within datasets that reflect implicit biases and, in so doing, emphasize and reinforce these biases as global truth. This paper describes specific examples of how bias has infused itself into current AI and robotic systems, and how it may affect the future design of such systems. More specifically, we draw attention to how bias may affect the functioning of (1) a robot peacekeeper, (2) a self-driving car, and (3) a medical robot. We conclude with an overview of measures that could be taken to mitigate or halt bias from permeating robotic technology. © 2017, Springer Science+Business Media B.V.},
author_keywords={Artificial intelligence;  Design ethics;  Implicit bias;  Professional ethics;  Robot ethics},
keywords={algorithm;  artificial intelligence;  car;  female;  human;  information processing;  learning;  male;  medical technology;  prejudice;  racism;  robotics;  sexism;  social justice;  statistical bias, Algorithms;  Artificial Intelligence;  Automobiles;  Bias;  Biomedical Technology;  Datasets as Topic;  Female;  Humans;  Learning;  Male;  Prejudice;  Racism;  Robotics;  Sexism;  Social Justice},
references={(2016) 2016 Physicians Specialty Data Report, , https://www.aamc.org/data/workforce/reports/457712/2016-specialty-databook.html, Accessed August 30, 2017; (2014) Racial disparities in sentencing, , https://www.aclu.org/sites/default/files/assets/141027_iachr_racial_disparities_aclu_submission_0.pdf, Submitted to the Inter-American Commission on Human Rights 153rd Session, October 27, 2014, Accessed August 31, 2017; Angwin, J., Larson, J., Mattu, S., Kirchner, L., (2016) Machine bias: There’s software used across the country to predict future criminals. And it’s biased against blacks, , https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing, ProPublica, May 23, Accessed June 28, 2017; Bian, L., Leslie, S.J., Cimpian, A., Gender stereotypes about intellectual ability emerge early and influence children’s interests (2017) Science, 355 (6323), pp. 389-391; Bogost, I., Artificial Intelligence’ has become meaningless (2017) The Atlantic, , https://www.theatlantic.com/technology/archive/2017/03/what-is-artificial-intelligence/518547, March 4, Accessed August 30, 2017; Bolukbasi, T., Chang, K.-W., Zou, J., Saligrama, V., Kalai, A., (2016) Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings, , https://arxiv.org/pdf/1607.06520.pdf, Accessed July 3, 2017; Borenstein, J., Herkert, J., Miller, K., Self-driving cars: Ethical responsibilities of design engineers (2017) IEEE Technology and Society Magazine, 36 (2), pp. 67-75; Borenstein, J., Howard, A., Wagner, A., Pediatric robotics and ethics: The robot is ready to see you now but should it be trusted? (2017) Robot ethics 2.0, , Lin P, Abney K, Bekey G, (eds), Oxford University Press, Oxford; Brownstein, M., Implicit bias (2016) The Stanford Encyclopedia of Philosophy, , https://plato.stanford.edu/archives/win2016/entries/implicit-bias/, E. N. Zalta, Accessed July 3, 2017; Caliskan, A., Bryson, J.J., Narayanan, A., Semantics derived automatically from language corpora contain human-like biases (2017) Science, 356 (6334), pp. 183-186; Carpenter, J., (2015) Google’s algorithm shows prestigious job ads to men, but not to women, , http://www.independent.co.uk/life-style/gadgets-and-tech/news/googles-algorithm-shows-prestigious-job-ads-to-men-but-not-to-women-10372166.html, Independent, July 7, Accessed July 3, 2017; Carty, S.S., (2011) Many cars tone deaf to women’s voices, , http://www.autoblog.com/2011/05/31/women-voice-command-systems/, Autoblog, May 31, Accessed February 4, 2017; Castellanos, S., Capital One pursues ‘explainable AI’ to guard against bias in models (2016) The Wall Street Journal, , http://blogs.wsj.com/cio/2016/12/06/capital-one-pursues-explainable-ai-to-guard-against-bias-in-models/, December 2, Accessed February 10, 2017; Chavalarias, D., Ioannidis, J.P.A., Science mapping analysis characterizes 235 biases in biomedical research (2010) Journal of Clinical Epidemiology, 63 (11), pp. 1205-1215; Chawla, N.V., Hall, L.O., Bowyer, K.W., Kegelmeyer, W.P., SMOTE: Synthetic minority oversampling technique (2002) Journal of Artificial Intelligence Research, 16, pp. 321-357; Chayes, J., (2017) How machine learning advances will improve the fairness of algorithms, , Huffington Post, August 23. Accessed August 25, 2017; Datta, A., Tschantz, M.C., Datta, A., Automated experiments on ad privacy settings (2015) Proceedings on Privacy Enhancing Technologies, 2015 (1), pp. 92-112; Devlin, H., (2016) Discrimination by algorithm: Scientists devise test to detect AI bias, , https://www.theguardian.com/technology/2016/dec/19/discrimination-by-algorithm-scientists-devise-test-to-detect-ai-bias, The Guardian, December 19, Accessed February 9, 2017; (2016) Artificial Intelligence, Automation, and the Economy, , https://obamawhitehouse.archives.gov/sites/whitehouse.gov/files/documents/Artificial-Intelligence-Automation-Economy.PDF, Accessed February 7, 2017; (2016) Big data: A tool for inclusion or exclusion? Understanding the issues, , https://www.ftc.gov/system/files/documents/reports/big-data-tool-inclusion-or-exclusion-understanding-issues/160106big-data-rpt.pdf, FTC report, Accessed July 3, 2017; Finley, K., (2016) Tech giants team up to keep AI from getting out of hand, , https://www.wired.com/2016/09/google-facebook-microsoft-tackle-ethics-ai/, Wired, September 28, Accessed February 7, 2017; Freeman, D., (2016) Self-driving cars could save millions of lives: But there’s a catch, , http://www.huffingtonpost.com/entry/the-moral-imperative-thats-driving-the-robot-revolution_us_56c22168e4b0c3c550521f64, HuffPost Tech, February 18, Accessed January 30, 2017; Gendler, T.S., On the epistemic costs of implicit bias (2011) Philosophical Studies, 156, pp. 33-63; Green, A., Carney, D., Pallin, D., Ngo, L., Raymond, K., Lezzoni, L., Banaji, M., Implicit bias among physicians and its prediction of thrombolysis decisions for black and white patients (2007) Journal of General Internal Medicine, 22, pp. 1231-1238; Griffiths, J., (2016) New Zealand passport robot thinks this Asian man’s eyes are closed, , http://www.cnn.com/2016/12/07/asia/new-zealand-passport-robot-asian-trnd/, CNN, December 9, Accessed February 4, 2017; Guarino, B., (2016) Google faulted for racial bias in image search results for black teenagers, , The Washington Post, June 10; Hackett, R., Singapore is getting driverless taxi cabs (2016) Fortune, , http://fortune.com/2016/04/05/singapore-driverless-car-taxi-nutonomy/, April 5, Accessed February 8, 2017; Hall, W., Chapman, M., Lee, K.M., Merino, Y.M., Thomas, T.W., Payne, B.K., Eng, E., Coyne-Beasley, T., Implicit racial/ethnic bias among health care professionals and its influence on health care outcomes: A systematic review (2015) American Journal of Public Health, 105 (12), pp. e60-e76; Hardt, M., (2014) How Big Data is Unfair: Understanding Unintended Sources of Unfairness in Data Driven Decision Making, , https://medium.com/@mrtz/how-big-data-is-unfair-9aa544d739de#.v96yl9fy6, Medium, September 26, Accessed January 28, 2017; Hardt, M., Price, E., Srebro, N., (2016) Equality of opportunity in supervised learning, , https://arxiv.org/pdf/1610.02413.pdf, October 11, Accessed February 8, 2017; Harpur, P., From universal exclusion to universal equality: Regulating ableism in a digital age (2013) Northern Kentucky Law Review, 40 (3), pp. 529-565; Holroyd, J., Responsibility for implicit bias (2012) Journal of Social Philosophy, 43, pp. 274-306; (2017) Ethically Aligned Design: A Vision for Prioritizing Human Wellbeing with Artificial Intelligence and Autonomous Systems, , http://standards.ieee.org/develop/indconn/ec/ead_brochure.pdf, Accessed February 7, 2017; Johnson, D.D.P., Blumstein, D.T., Fowler, J.H., Haselton, M.G., The evolution of error: error management, cognitive constraints, and adaptive decision-making biases (2013) Trends in Ecology and Evolution, 28 (8), pp. 474-481; Kane, L., (2010) Exclusive ethics survey results: Doctors struggle with tougher-than-ever dilemmas, , http://www.medscape.com/viewarticle/731485, Medscape, November 11, Accessed February 8, 2017; Kang, C., (2016) The 15-Point federal checklist for self-driving cars, , The New York Times, September 21; Kay, M., Matuszek, C., Munson, S.A., Unequal representation and gender stereotypes in image search results for occupations (2015) Proceedings of the 33Rd Annual ACM Conference on Human Factors in Computing Systems (CHI ‘15), pp. 3819-3828. , New York, NY, ACM; Kotsiantis, S., Kanellopoulos, D., Pintelas, P., Handling imbalanced datasets: A review (2006) GESTS International Transactions on Computer Science and Engineering, 30, pp. 25-36; Kuipers, B., Why and how should robots behave ethically? (2016) Robophilosophy 2016/TRANSOR 2016, , https://web.eecs.umich.edu/~kuipers/papers/Kuipers-robophilosophy-16-abstract.pdf, Aarhus, Denmark, Accessed February 10, 2017; Larson, S., (2016) Research shows gender bias in Google’s voice recognition, , http://www.dailydot.com/debug/google-voice-recognition-gender-bias/, The Daily Dot, July 15, Accessed February 4, 2017; Levin, S., (2016) A beauty contest was judged by AI and the robots didn’t like dark skin, , https://www.theguardian.com/technology/2016/sep/08/artificial-intelligence-beauty-contest-doesnt-like-black-people, The Guardian, September 8, Accessed February 4, 2017; McFarland, M., (2016) Robot’s role in killing Dallas shooter is a first, , http://money.cnn.com/2016/07/08/technology/dallas-robot-death/, CNN.com, July 11, Accessed February 8, 2017; McHugh, C., Way, J., What is good reasoning? (2016) Philosophy and Phenomenological Research; (2017) MIT Media Lab to participate in $27 million initiative on AI ethics and governance, , http://news.mit.edu/2017/mit-media-lab-to-participate-in-ai-ethics-and-governance-initiative-0110, MIT News, January 10, Accessed February 7, 2017; Muench, U., Sindelar, J., Busch, S.H., Buerhaus, P.I., Salary differences between male and female registered nurses in the united states (2015) JAMA, 313 (12), pp. 1265-1267; Nwana, H.S., Software agents: An overview (1996) Knowledge Engineering Review, 11 (3), pp. 1-40; Reducing the impact of bias in the stem workforce: Strengthening excellence and innovation (2016) A Report of the Interagency Policy Group on Increasing Diversity in the Stem Workforce by Reducing the Impact of Bias; Otterbacher, J., New evidence shows search engines reinforce social stereotypes (2016) Harvard Business Review, , https://hbr.org/2016/10/new-evidence-shows-search-engines-reinforce-social-stereotypes, October 20, Accessed February 4, 2017; Pulliam-Moore, C., Google photos identified black people as ‘gorillas,’ but racist software isn’t new (2015) Fusion, , http://fusion.net/story/159736/google-photos-identified-black-people-as-gorillas-but-racist-software-isnt-new/, July 1, Accessed February 4, 2017; Robinson, D., Koepke, L., (2016) Stuck in a Pattern: Early Evidence on “predictive policing” and Civil Rights, , https://www.teamupturn.com/reports/2016/stuck-in-a-pattern, A report from Upturn, Accessed January 28, 2017; Rodger, J.A., Pendharkar, P.C., A field study of the impact of gender and user’s technical experience on the performance of voice-activated medical tracking application (2004) International Journal of Human-Computer Studies, 60 (5-6), pp. 529-544; Rose, A., Are face-detection cameras racist? (2010) Time, , http://content.time.com/time/business/article/0,8599,1954643,00.html, January 22, Accessed February 4, 2017; Šabanović, S., Chang, W.-L., Bennett, C.C., Piatt, J.A., Hakken, D., A Robot of My Own: Participatory Design of Socially Assistive Robots for Independently Living Older Adults Diagnosed with Depression (2015) Human Aspects of IT for the Aged Population. Design for Aging, pp. 104-114. , Springer International Publishing, Cham; (2016) Taxonomy and Definitions for Terms Related to Driving Automation Systems for On-Road Motor Vehicles J3016, , http://standards.sae.org/j3016_201609/, Accessed January 17, 2017; Spencer, S.J., Steele, C.M., Quinn, D.M., Stereotype threat and women’s math performance (1999) Journal of Experimental Social Psychology, 35 (1), pp. 4-28; Steele, C.M., (2010) Whistling Vivaldi: And other clues to how stereotypes affect us (issues of our time), , W. W. Norton and Co, New York, NY; Stone, P., Brooks, R., Brynjolfsson, E., Calo, R., Etzioni, O., Hager, G., (2016) Artificial intelligence and life in 2030, , http://ai100.stanford.edu/2016-report, One hundred year study on artificial intelligence: Report of the 2015–2016 study panel. Stanford, CA: Stanford University, Accessed February 7, 2017; Tatman, R., Google’s speech recognition has a gender bias (2016) Making Noise and Hearing Things, , https://makingnoiseandhearingthings.com/2016/07/12/googles-speech-recognition-has-a-gender-bias/, July 12, Accessed February 9, 2017; Toor, A., Drones will begin delivering blood and medicine in the US (2016) The Verge, , http://www.theverge.com/2016/8/2/12350274/zipline-drone-delivery-us-launch-blood-medicine, August 2, Accessed February 8, 2017; Wagner, L., North Dakota legalizes armed police drones (2015) The Two-Way, , http://www.npr.org/sections/thetwo-way/2015/08/27/435301160/north-dakota-legalizes-armed-police-drones, August 27, Accessed February 8, 2017},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gunkel20171,
author={Gunkel, D.J.},
title={Mind the gap: responsible robotics and the problem of responsibility},
journal={Ethics and Information Technology},
year={2017},
pages={1-14},
doi={10.1007/s10676-017-9428-2},
note={cited By 14; Article in Press},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025076629&doi=10.1007%2fs10676-017-9428-2&partnerID=40&md5=1175b99c276096f3cade0ba501b9dc4c},
abstract={The task of this essay is to respond to the question concerning robots and responsibility—to answer for the way that we understand, debate, and decide who or what is able to answer for decisions and actions undertaken by increasingly interactive, autonomous, and sociable mechanisms. The analysis proceeds through three steps or movements. (1) It begins by critically examining the instrumental theory of technology, which determines the way one typically deals with and responds to the question of responsibility when it involves technology. (2) It then considers three instances where recent innovations in robotics challenge this standard operating procedure by opening gaps in the usual way of assigning responsibility. The innovations considered in this section include: autonomous technology, machine learning, and social robots. (3) The essay concludes by evaluating the three different responses—instrumentalism 2.0, machine ethics, and hybrid responsibility—that have been made in face of these difficulties in an effort to map out the opportunities and challenges of and for responsible robotics. © 2017 Springer Science+Business Media B.V.},
author_keywords={Ethics;  Machine ethics;  Philosophy;  Responsibility;  Robot;  Robotics;  Technology},
keywords={Engineering education;  Philosophical aspects;  Robots;  Technology, Autonomous technology;  Ethics;  Instrumental theories;  Philosophy;  Responsibility;  Social robots;  Standard operating procedures, Robotics},
document_type={Article in Press},
source={Scopus},
}

@BOOK{Lin20171,
author={Lin, P. and Jenkins, R. and Abney, K.},
title={Robot ethics 2.0: From autonomous cars to artificial intelligence},
journal={Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence},
year={2017},
pages={1-424},
doi={10.1093/oso/9780190652951.001.0001},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052536583&doi=10.1093%2foso%2f9780190652951.001.0001&partnerID=40&md5=55897654d7525d280255f48bed63f916},
abstract={As a game-changing technology, robotics naturally will create ripple effects through society. Some of them may become tsunamis. So it’s no surprise that “robot ethics”-the study of these effects on ethics, law, and policy-has caught the attention of governments, industry, and the broader society, especially in the past several years. Since our first book on the subject in 2012, a groundswell of concern has emerged, from the Campaign to Stop Killer Robots to the Campaign Against Sex Robots. Among other bizarre events, a robot car has killed its driver, and a kamikaze police robot bomb has killed a sniper. Given these new and evolving worries, we now enter the second generation of the debates-robot ethics 2.0. This edited volume is a one-stop authoritative resource for the latest research in the field, which is often scattered across academic journals, books, media articles, reports, and other channels. Without presuming much familiarity with either robotics or ethics, this book helps to make the discussion more accessible to policymakers and the broader public, as well as academic audiences. Besides featuring new use-cases for robots and their challenges-not just robot cars, but also space robots, AI, and the internet of things (as massively distributed robots)-we also feature one of the most diverse group of researchers on the subject for truly global perspectives. © Oxford University Press 2017. All rights reserved.},
author_keywords={Artificial intelligence;  Autonomous;  Cars;  Ethics;  Law;  Philosophy;  Policy;  Psychology;  Responsibility;  Robots},
document_type={Book},
source={Scopus},
}

@ARTICLE{Arnold2016103,
author={Arnold, T. and Scheutz, M.},
title={Against the moral Turing test: accountable design and the moral reasoning of autonomous systems},
journal={Ethics and Information Technology},
year={2016},
volume={18},
number={2},
pages={103-115},
doi={10.1007/s10676-016-9389-x},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962303009&doi=10.1007%2fs10676-016-9389-x&partnerID=40&md5=529a5e07a68ceebad4e91adfcd6b228b},
abstract={This paper argues against the moral Turing test (MTT) as a framework for evaluating the moral performance of autonomous systems. Though the term has been carefully introduced, considered, and cautioned about in previous discussions (Allen et al. in J Exp Theor Artif Intell 12(3):251–261, 2000; Allen and Wallach 2009), it has lingered on as a touchstone for developing computational approaches to moral reasoning (Gerdes and Øhrstrøm in J Inf Commun Ethics Soc 13(2):98–109, 2015). While these efforts have not led to the detailed development of an MTT, they nonetheless retain the idea to discuss what kinds of action and reasoning should be demanded of autonomous systems. We explore the flawed basis of an MTT in imitation, even one based on scenarios of morally accountable actions. MTT-based evaluations are vulnerable to deception, inadequate reasoning, and inferior moral performance vis a vis a system’s capabilities. We propose verification—which demands the design of transparent, accountable processes of reasoning that reliably prefigure the performance of autonomous systems—serves as a superior framework for both designer and system alike. As autonomous social robots in particular take on an increasing range of critical roles within society, we conclude that verification offers an essential, albeit challenging, moral measure of their design and performance. © 2016, Springer Science+Business Media Dordrecht.},
author_keywords={Artificial moral agents;  Human–robot interaction;  Moral Turing test;  Robot ethics;  Verification},
keywords={Artificial intelligence;  Design;  Human robot interaction;  Philosophical aspects;  Robots;  Verification, Autonomous systems;  Computational approach;  Moral agents;  Moral reasoning;  Robot ethics;  Robot interactions;  Social robots;  Turing tests, Machine design},
references={Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental & Theoretical Artificial Intelligence, 12 (3), pp. 251-261; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) Intelligent Systems, IEEE, 21 (4), pp. 12-17; Ball, P., The truth about the Turing Test (2015) BBC, , http://www.bbc.com/future/story/20150724-the-problem-with-the-turing-test/; Bringsjord, S., (1992) What robots can and can’t be, , Kluwer Academic, Dordrecht; Calo, R., Robotics and the lessons of cyberlaw (2015) California Law Review, 103, p. 513; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds and Machines, 14 (3), pp. 349-379; Gerdes, A., The issue of moral consideration in robot ethics (2015) SIGCAS Computers & Society, 45 (3), p. 274; Gerdes, A., Øhrstrøm, P., Preliminary reflections on a moral Turing test (2013) In Proceedings of ETHICOMP, pp. 167-174; Gerdes, A., Øhrstrøm, P., Issues in robot ethics seen through the lens of a moral Turing test (2015) Journal of Information, Communication and Ethics in Society, 13 (2), pp. 98-109; Harnad, S., Other bodies, other minds: A machine incarnation of an old philosophical problem (1991) Minds and Machines, 1 (1), pp. 43-54; Henig, R., Death by robot (2015) New York Times, , www.nytimes.com/2015/01/11/magazine/death-by-robot.html; Hintikka, J., Cogito, ergo sum: Inference or performance? (1962) The Philosophical Review, pp. 3-32; Johnson-Laird, P.N., (1988) The computer and the mind: An introduction to cognitive science, , Harvard University Press, Cambridge; Kurzweil, R., (2005) The singularity is near: When humans transcend biology, , Penguin, Harmondsworth; Lin, P., The ethics of autonomous cars (2013) The Atlantic, , www.theatlantic.com/technology/archive/2013/10/theethics-of-autonomous-cars/280360/; Lin, P., We’re building superhuman robots. Will they be heroes, or villains? (2015) Washington Post, , www.washingtonpost.com/news/in-theory/wp/2015/11/02/were-building-superhuman-robots-will-they-be-heroes-or-villains/; (2015) In Proceedings of 10th ACM/IEEE International Conference on Human–Robot Interaction, , Malle, B. F., Scheutz, M., Arnold, T., Voiklis, J. T., & Cusimano, C. Sacrifice one for the good of many? People apply different; Millar, J., An ethical dilemma: When robot cars must kill,who should pick the victim? Robohub (2014) robohub.org/an-ethicaldilemma-when-robot-cars-must-kill-who-should-pick-thevictim/, , robohub.org/an-ethicaldilemma-when-robot-cars-must-kill-who-should-pick-thevictim/; Moor, J.H., The status and future of the Turing test (2001) Minds and Machines, 11 (1), pp. 77-93; (2014) Open Roboethics Initiative, , http://www.openroboethics.org/results-my-autonomous-car-my-safety/, Open Roboethics Initiative. My (autonomous) car, my safety: Results from our reader poll; Pagallo, U., (2013) The laws of robots: Crimes, contracts, and torts, , 10, Springer Science & Business Media, Berlin; Pasquale, F., (2015) The black box society: The secret algorithms that control money and information, , Harvard University Press, Cambridge; (2014) The Guardian, , www.theguardian.com/technology/2014/jun/09/scientists-disagree-over-whether-turing-test-has-been-passed/, Sample, I., & Hern, A; (2014) In Ethics in Science, Technology and Engineering, , Scheutz, M., & Malle, B. F. “Think and do the right thing”—A plea for morally competent autonomous robots, 2014 IEEE International Symposium on (pp. 1-4). IEEE; Stahl, B.C., Information, ethics, and computers: The problem of autonomous moral agents (2004) Minds and Machines, 14 (1), pp. 67-83; Turing, A.M., Computing machinery and intelligence (1950) Mind, 59, pp. 433-460; Wallach, W., Allen, C., (2008) Moral machines: Teaching robots right from wrong, , Oxford University Press, Oxford; Wilson, P., Utility-theoretic indexing (1979) Journal of the American Society for Information Science, 30 (3), pp. 169-170; (2015) In Affective Computing and Intelligent Interaction (ACII), 2015 International Conference on, , Wilson, J. R., & Scheutz, M. A model of empathy to shape trolley problem moral judgements. In Affective Computing and Intelligent Interaction (ACII), (pp. 112–118). IEEE},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wynsberghe2013433,
author={Wynsberghe, A.V.},
title={A method for integrating ethics into the design of robots},
journal={Industrial Robot},
year={2013},
volume={40},
number={5},
pages={433-440},
doi={10.1108/IR-12-2012-451},
art_number={17094475},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883420548&doi=10.1108%2fIR-12-2012-451&partnerID=40&md5=56592b6e3a1e3996db54e1581ef23939},
abstract={Purpose - With the rapid and pervasive introduction of robots into human environments, ethics scholars along with roboticists are asking how ethics can be applied to the discipline of robotics. The purpose of this paper is to provide a concrete example of incorporating ethics into the design process of a robot in healthcare. Design/methodology/approach - The approach for including ethics in the design process of care robots used in this paper is called the Care-Centered Value Sensitive Design (CCVSD) approach. The CCVSD approach presented here provides both an outline of the components demanding ethical attention as well as a step-by-step manner in which such considerations may proceed in a prospective manner throughout the design process of a robot. This begins from the moment of idea generation and continues throughout the design of various prototypes. In this paper, this approach's utility and prospective methodology are illustrated by proposing a novel care robot, the «wee-bot», for the collection and testing of urine samples in a hospital context. Findings - The results of applying the CCVSD approach inspired the design of a novel robot for the testing of urine in pediatric oncology patients - the «wee-bot» robot - and showed that it is possible to successfully incorporate ethics into the design of a care robot by exploring and prescribing design requirements. In other words, the use of the CCVSD approach allowed for the translation of ethical values into technical design requirements as was shown in this paper. Practical implications - This paper provides a practical solution to the question of how to incorporate ethics into the design of robots and bridges the gap between the work of roboticists and robot ethicists so that they may work together in the design of a novel care robot. Social implications - In providing a solution to the issue of how to address ethical issues in the design of robots, the aim is to mitigate issues of societal concern regarding the design, development and implementation of robots in healthcare. Originality/value - This paper is the first and only presentation of a concrete prospective methodology for including ethics into the design of robots. While the example given here is tailored to the healthcare context, the approach can be adjusted to fit another context and/or robot design. Copyright © 2013 Emerald Group Publishing Limited. All rights reserved.},
author_keywords={Care robots;  Design and robots;  Ethics;  Ethics and design;  Robot ethics;  Robots;  Value-sensitive design},
keywords={Design/methodology/approach;  Ethics;  Human environment;  Pediatric oncology;  Practical solutions;  Robot ethics;  Social implication;  Value sensitive design, Bridges;  Concretes;  Health care;  Philosophical aspects;  Robots, Machine design},
references={Asaro, P., What should we want from a robot ethic? (2006) International Review of Information Ethics, 6, pp. 8-16; Coeckelbergh, M., Health care, capabilities, and AI assistive technologies (2010) Ethical Theory and Moral Practice, 13 (2), pp. 181-190; Floridi, L., Sanders, J., On the morality of artificial agents (2004) Minds and Machines, 14 (3), pp. 349-379; Friedman, B., Kahn, P.H., Borning, A., Human values, ethics, and design (2006) Human-Computer Interaction and Management Information Systems: Foundations, pp. 348-372. , Zhang, P. and Galletta, D. (Eds) M.E. Sharpe, Armonk, NY; Le Dante, C.A., Poole, E.S., Wyche, S.P., (2009) Values As Lived Experience: Evolving Value Sensitive Design in Support of Value Discovery, pp. 1141-1150. , ACM, New York, NY; Lo, A.C., Guarino, P.D., Richards, L.G., Haselkorn, J.K., Wittenberg, G.F., Federman, D.G., Ringer, R.J., Peduzzi, P., Robot-assisted therapy for long-term upper-limb impairment after stroke (2010) The New England Journal of Medicine, 362 (19), pp. 1772-1783; Meadows, M.S., (2011) We Robot: Skywalker's Hand Blade Runners Iron Man Slutbots and How Fiction Became Fact Lyons Press, , Guilford, CT; Mutlu, B., Forlizzi, J., Robots in organizations (2008) Proceedings of HRI'08, , ACM, New York, NY; Nicklin, W., McVeety, J.E., Canadian nurses' perceptions of patient safety in nursing (2002) Canadian Journal of Nursing Leadership, 15 (3), pp. 11-21; Nissenbaum, H., How computer systems embody values (2001) IEEE Computer, , March; Onishi, M., Luo, Z.W., Odashima, T., Hirano, S., Tahara, K., Mukai, T., Generation of human care behaviors by human-interactive robot RI-MAN (2007) Proceedings -IEEE International Conference on Robotics and Automation, pp. 3128-3129; Saenz, A., (2010) Incredible TUG Robots Automate Delivery in Hospitals Singularity Hub, , Moffett Field CA; Satoh, H., Kawabata, T., Sankai, Y., Bathing care assistance with robot suit HAL (2009) ROBIO'09 Proceedings of the 2009 International Conference on Robotics and Biomimetics, pp. 498-503. , IEEE, Piscataway, NJ; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics and Information Technology, 14 (1), pp. 27-40; Sharkey, N., Sharkey, A., The rights and wrongs of robot care (2011) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 267-282. , Lin, P., Abney, K. and Bekey, G. (Eds) The MIT Press, Cambridge, MA; Singer, P.W., (2009) Wired for War: The Robotics Revolution and Conflict in the Twenty-First Century, , Penguin Press, New York, NY; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Minds and Machines, 16 (2), pp. 141-161; Tronto, J.C., (1993) Moral Boundaries: A Political Argument for An Ethic of Care, , Routledge, New York, NY; Tronto, J.C., Creating caring institutions: Politics, plurality, and purpose (2010) Ethics and Social Welfare, 4 (2), pp. 158-171; Vallor, S., Carebots and caregivers: Sustaining the ethical ideal of care in the twenty-first century (2011) Philosophy and Technology, 24 (3), pp. 251-268; Van Tilburg, C.M., Leistikow, I., Rademaker, C., Bierings, M., Van Dijk, A., Healthcare failure mode and effect analysis: A useful proactive risk analysis in a pediatric oncology ward (2006) Qual. Saf. Health Care, 15, pp. 58-63; Van Wynsberghe, A., Designing robots for care: Care centered value-sensitive design (2012) Journal of Science and Engineering Ethics, 4; Van Wynsberghe, A., (2012) Designing Robots with Care: Creating An Ethical Framework for the Future Design and Implementation of Care Robots University of Twente Enschede; Van Wynsberghe, A., Gastmans, C., Telesurgery: An ethical appraisal (2008) Journal of Medical Ethics, 34 (10); Verbeek, P.-P., (2011) Moralizing Technology: Understanding and Designing the Morality of Things the University of Chicago Press, , Chicago, IL; Veruggio, G., Operto, F., Roboethics: Social and ethical implications of robotics (2008) Springer Handbook of Robotics, pp. 1499-1524. , Siciliano, B. and Khatib, O. (Eds) Springer, Berlin; Wallach, W., Allen, C., (2010) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press, New York, NY; Kawamoto, H., Sankai, Y., (2002) Power Assist System HAL-3 for Gait Disorder Person, pp. 196-203. , Springer, London; Kazerooni, H., Exoskeletons for human performance augmentation (2008) Springer Handbook of Robotics, pp. 773-798. , Siciliano, B. and Khatib, O. (Eds) Springer, Berlin; Lin, P., Abney, K., Bekey, G., (2011) Robot Ethics: The Ethical and Social Implications of Robotics, , The MIT Press, Cambridge, MA},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wallach2013125,
author={Wallach, W. and Allen, C.},
title={Framing robot arms control},
journal={Ethics and Information Technology},
year={2013},
volume={15},
number={2},
pages={125-135},
doi={10.1007/s10676-012-9303-0},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879788112&doi=10.1007%2fs10676-012-9303-0&partnerID=40&md5=7421c1489381a8c0da1049f62172ab20},
abstract={The development of autonomous, robotic weaponry is progressing rapidly. Many observers agree that banning the initiation of lethal activity by autonomous weapons is a worthy goal. Some disagree with this goal, on the grounds that robots may equal and exceed the ethical conduct of human soldiers on the battlefield. Those who seek arms-control agreements limiting the use of military robots face practical difficulties. One such difficulty concerns defining the notion of an autonomous action by a robot. Another challenge concerns how to verify and monitor the capabilities of rapidly changing technologies. In this article we describe concepts from our previous work about autonomy and ethics for robots and apply them to military robots and robot arms control. We conclude with a proposal for a first step toward limiting the deployment of autonomous weapons capable of initiating lethal force. © 2012 Springer Science+Business Media Dordrecht.},
author_keywords={Autonomous weapons;  Machine ethics;  Military robots;  Moral machines;  Operational morality;  Robot arms control},
keywords={Arms-control agreements;  Autonomous action;  Military robots;  Operational morality;  Robot arms, Philosophical aspects, Robotic arms},
references={Altmann, J., Preventive arms control for uninhabited military vehicles (2009) Ethics for robotics, , In R. Capurro & M. Nagenborg (Eds.). AKA Verlag, Heidelberg; Arkin, R., (2009) Governing Lethal Behavior in Autonomous Robots, , Chapman and Hall: CRC; Arkin, R., (2012) Presentations at the EPIIC international symposium on conflict in the 21st century, , Tufts University, February 22, 23; Asaro, P., How just could a robot war be? (2008) Current Issues in Computing and Philosophy, pp. 50-64. , P. Brey, A. Briggle, and K. Waelbers (Eds.), Amsterdam, The Netherlands: IOS Press; Borenstein, J., The ethics of autonomous military robots (2008) Studies in Ethics, Law, and Technology, 2 (1). , http://www.bepress.com/selt/vol2/iss1/art2, Article 2. doi: 10. 2202/1941-6008. 1036. Available at; Dahm, W.J.A., Killer robots are science fiction (2012) The Wall Street Journal, , http://online.wsj.com/article/SB10001424052970204883304577221590015475180.html, February 16th 2011. Available online at. Accessed 13 Oct 2012; Dancy, J., Contribution to discussion on "The Future of Moral Machines", On the human (2011) National Humanities Center, , http://onthehuman.org/2011/12/the-future-of-moral-machines/, Accessed 1 May 2012; Dennett, D.C., (1978) Brainstorms, , Cambridge: MIT Press; Finn, P., A future for drones: Automated killing (2011) The Washington post, , http://www.washingtonpost.com/national/national-security/a-future-for-drones-automated-killing/2011/09/15/gIQAVy9mgK_story.html, September 19, 2011. Available online at. Accessed 19 December 2011; Fodor, J.A., (1983) The Modularity of Mind, , Cambridge: MIT Press; Gips, J., Towards the ethical robot (1991) Android epistemology, pp. 243-252. , In K. G. Ford, C. Glymour, & P. J. Hayes (Eds.). Cambridge: MIT press; Gormley, D.M., (2008) Missile Contagion: Cruise Missile Proliferation and the Threat to International Security, , London: Praeger; Hollnagel, E., Woods, D.D., Leveson, N., (2006) Resiliance engineering: Concepts and precepts, , (Eds.). Aldershot: Ashgate Publishing; Kim, T.-G., Machine gun-armed robots to guard DMZ (2010) The Korea Times, , http://www.koreatimes.co.kr/www/news/biz/2010/06/123_68227.html, June 24, 2010. Available online at. Accessed 19 December 2011; Krishnan, A., (2009) Killer Robots: Legality and Ethicality of Autonomous Weapons, , Burlington: Ashgate; Lin, P., Drone-ethics briefing: What a leading robot expert told the CIA (2011) The Altantic, , http://www.theatlantic.com/technology/archive/2011/12/drone-ethics-briefing-what-a-leading-robot-expert-told-the-cia/250060/, December 15, 2011. Available online at. Accessed 19 December 2011; Lokhorst, G., van den Hoven, J., Responsibility for military robots (2012) Robot ethics, , In P. Lin, K. Abney, & G. A. Bekey (Eds.). Cambridge: MIT Press; Matthias, A., Algorithmic moral control of war robots: Philosophical questions (2011) Law, Innovation and Technology, 3 (2), pp. 279-301; McCarthy, J., Hayes, P.J., Some philosophical problems from the standpoint of artificial intelligence (1969) Machine Intelligence, 4, pp. 463-502. , In D. Michie, & B. Meltzer (Eds.). Edinburgh: Edinburgh University Press; Sharkey, N., The automation and proliferation of military drones and the protection of civilians (2011) Law, Innovation and Technology, 3 (2), pp. 229-240; Sharkey, N., Killing made easy: From joysticks to politics (2012) Robot Ethics, , P. Lin, K. Abney, and G. A. Bekey (Eds.), Cambridge: MIT Press; Singer, P.W., (2009) Wired for War, , New York: Penguin Press; Sparrow, R., Predators or plowshares? Arms control of robotic weapons (2009) IEEE Technology and Society, 28 (1), pp. 25-29; Sparrow, R., Robotic weapons and the future of war (2011) New wars and new soldiers: Military ethics in the contemporary world, pp. 117-133. , In J. Wolfendale, & P. Tripodi (Eds.). Surrey, UK & Burlington, VA: Ashgate; Stahl, B.C., (2002) Can a computer adhere to the categorical imperative? A contemplation of the limits of transcendental ethics in IT, , Paper presented at the international conference on systems research, informatics and cybernetics, Baden Baden, GE; Taleb, N.N., (2007) The Black Swan: The Impact of the Highly Improbable, , New York: Random House; (2002) Ad Hoc study on human robot interface issues, , http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA411834, U. S. Army Science Board. Available online at. Accessed 19 April 2012; (2008) MHAT-IV, , http://www.armymedicine.army.mil/reports/mhat/mhat_iv/mhat-iv.cfm, U. S. Army Medical Department. Accessed 20 December 2011; (2009) Unmanned Aircraft Systems Flight Plan 2009-2047, , http://www.govexec.com/pdfs/072309kp1.pdf, U. S. Air Force. Available at. Accessed 19 April 2012; (2009) Fiscal Year 2009-2034 Unmanned systems integrated roadmap, , http://www.acq.osd.mil/psa/docs/UMSIntegratedRoadmap2009.pdf, U. S. Department of Defense. Accessed 20 December 2011; (2012) Task force report: The role of autonomy in DoD systems, , http://www.fas.org/irp/agency/dod/dsb/autonomy.pdf, U. S. Department of Defense. Accessed 22 September 2012; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford: Oxford University Press; Woods, D.D., Hollnagel, E., (2006) Joint cognitive systems: Patterns in cognitive systems engineering, , Boca Raton: CRC Press},
document_type={Article},
source={Scopus},
}

@ARTICLE{Powers201151,
author={Powers, T.M.},
title={Incremental machine ethics},
journal={IEEE Robotics and Automation Magazine},
year={2011},
volume={18},
number={1},
pages={51-58},
doi={10.1109/MRA.2010.940152},
art_number={5751975},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955557986&doi=10.1109%2fMRA.2010.940152&partnerID=40&md5=6f0a02ffba01e8be78fa029365b06254},
abstract={Approaches to programming ethical behavior for computer systems face challenges that are both technical and philosophical in nature. In response, an incrementalist account of machine ethics is developed: a successive adaptation of programmed constraints to new, morally relevant abilities in computers. This approach allows progress under conditions of limited knowledge in both ethics and computer systems engineering and suggests reasons that we can circumvent broader philosophical questions about computer intelligence and autonomy. © 2006 IEEE.},
keywords={Computer intelligences;  Ethical behavior, Behavioral research;  Philosophical aspects, Computer systems programming},
references={Allison, G., (1971) Essence of Decision: Explaining the Cuban Missile Crisis, , Boston MA: Little Brown; Arkin, R.C., (2009) Governing Lethal Behavior in Autonomous Robots, , Boca Raton FL: CRC Press; Arrow, K., A strategy of decision: Policy evaluation as a social process by David Braybrooke; Charles E. Lindblom (1964) Polit. Sci. Q., 79 (4), pp. 584-588; Braybrooke, D., Lindblom, C.E., (1963) A Strategy of Decision, , New York, NY: The Free Press; Davidson, D., (2001) Essays on Actions and Events, , New York, NY: Oxford Univ. Press; Forester, J., Bounded rationality and the politics of muddling through (1984) Public Admin. Rev., 44 (1), pp. 23-31; Hayes, M., (2001) The Limits of Policy Change: Incrementalism, Worldview, and the Rule of Law, , Washington, DC: Georgetown Univ. Press; Hughes, T., The evolution of large technological systems (1989) The Social Construction of Technological Systems, , W. Bijker, T. Hughes, and T. Pinch, Eds. Cambridge, MA: MIT Press; Johnson, D., Powers, T.M., Computers as surrogate agents (2008) Information Technology and Moral Philosophy, , M. J. Van den Hoven and J. Weckert, Eds. New York: Cambridge Univ. Press; Kohlberg, L., Essays on moral development (1981) The Philosophy of Moral Development, 1. , San Francisco, CA: Harper & Row; Knott, J., Miller, G., Verkuilen, J., Adaptive incrementalism and complexity: Experiments with two-person cooperative signaling games (2003) J. Public Admin. Res. Theory, 13 (3), pp. 341-36; Lindblom, C., The science of muddling through (1959) Public Admin. Rev., 19 (2), pp. 79-88; Lindblom, C., (1965) The Intelligence of Democracy, , New York: The Free Press; Lindblom, C., Still muddling, not yet through (1979) Public Admin. Rev., 39 (6), pp. 517-526; Lustick, I., Explaining the variable utility of disjointed incrementalism: Four propositions (1980) Amer. Polit. Sci. Rev., 74 (2), pp. 342-353; Premfors, R., Review article: Charles Lindblom and Aaron Wildavsky (1981) Brit. J. Polit. Sci., 11 (2), pp. 201-225; Searle, J., (1984) Minds Brains, and Science, , Cambridge MA: Harvard Univ. Press; Herbert, H.S., A behavioral model of rational choice (1957) Models of Man, Social and Rational: Mathematical Essays on Rational Human Behavior in A Social Setting, , New York: Wiley; Smith, B., Limits of correctness in computers (1985) ACM SIGCAS Comput. Soc., 14 (4), pp. 18-26; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , New York: Oxford Univ. Press; Wildavsky, A., (1964) The Politics of the Budgetary Process, , Boston MA: Little, Brown},
document_type={Article},
source={Scopus},
}

@BOOK{Anderson201121,
author={Anderson, S.L.},
title={Machine metaethics},
journal={Machine Ethics},
year={2011},
volume={9780521112352},
pages={21-27},
doi={10.1017/CBO9780511978036.003},
note={cited By 14},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926971823&doi=10.1017%2fCBO9780511978036.003&partnerID=40&md5=a878ef794d732fe54561b36633490f17},
abstract={The newly emerging field of machine ethics is concerned with ensuring that the behavior of machines toward human users is ethically acceptable. There are domains in which intelligent machines could play a significant role in improving our quality of life as long as concerns about their behavior can be overcome by ensuring that they behave ethically. Machine metaethics examines the field of machine ethics. It talks about the field, rather than doing work in it. Examples of questions that fall within machine metaethics are: How central are ethical considerations to the development of artificially intelligent agents? What is the ultimate goal of machine ethics? What does it mean to add an ethical dimension to machines? Is ethics computable? Is there a single correct ethical theory that we should try to implement? Should we expect the ethical theory we implement to be complete? That is, should we expect it to tell a machine how to act in every ethical dilemma? How important is consistency? If it is to act in an ethical manner, is it necessary to determine the moral status of the machine itself?. When does machine behavior have ethical import? How should a machine behave in a situation in which its behavior does have ethical import? Consideration of these questions should be central to the development of artificially intelligent agents that interact with humans. © Cambridge University Press 2011.},
keywords={Intelligent agents, Ethical considerations;  Ethical dilemma;  Ethical theories;  Human users;  Intelligent machine;  Machine behavior;  Quality of life, Philosophical aspects},
references={Anderson, M., Anderson, S.L., Armen, C., Medethex: Towards a medical ethics advisor (2005) Proceedings of the AAAI Fall Symposium on Caring Machines: AI and Eldercare, , Menlo Park, California; Dennett, D., (2006) Computers as Prostheses for the Imagination,”, , invited talk presented at the International Computers and Philosophy Conference, Laval, France, May 3; McLaren, B.M., Extensionally defining principles and cases in ethics: An ai model (2003) Artificial Intelligence Journal, 150 (1-2), pp. 145-1813; Ross, W.D., (1930) The Right and the Good, , Oxford University Press, Oxford},
document_type={Book Chapter},
source={Scopus},
}

@BOOK{VanWynsberghe20151,
author={Van Wynsberghe, A.},
title={Healthcare Robots: Ethics, design and implementation},
journal={Healthcare Robots: Ethics, Design and Implementation},
year={2015},
pages={1-152},
note={cited By 13},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946412196&partnerID=40&md5=5c270c5c2c8d9f4983cbe6c4f2369c97},
abstract={This study deals with an underexplored area of the emerging technologies debate: Robotics in the healthcare setting. The author explores the role of care and develops a value-sensitive ethical framework for the eventual employment of care robots. Highlighting the range of positive and negative aspects associated with the initiative to design and use care robots, it draws out essential content as a guide to future design both reinforcing this study’s contemporary relevance, and giving weight to its prescriptions. The book speaks to, and is meant to be read by, a range of disciplines from science and engineering to philosophers and ethicists. © Aimee van Wynsberghe 2015. All rights reserved.},
keywords={Health care;  Philosophical aspects;  Robots, Design and implementations;  Emerging technologies;  Future designs;  Science and engineering, Machine design},
references={Akrich, M., The de-scription of technical objects (1992) Shaping Technology/Building Society: Studies in Sociotechnical Change, pp. 205-224. , W. E. Bijker and J. Law, Cambridge, MA: MIT Press; Albrechtslund, A., Ethics and technology design (2007) Ethics and Information Technology, 9 (1), pp. 63-72; Anderson, M., Anderson, S., Machine Ethics: Creating an Ethical Intelligent Agent (2007) AI Magazine, 28 (4); Anderson, M., Anderson, S., Robot be good: A call for ethical autonomous machines (2010) Scientific American, 303 (4), pp. 15-24; Argall, B., Billard, A., A Survey of Tactile Human-Robot Interactions (2010) Robotics and Autonomous Systems, 58 (10), pp. 1159-1176; Arras, K., Cerqui, D., (2005) Do We Want to Share Our Lives and Bodies with Robots?, , A 2000 People Survey; Asaro, P., What should we want from a robot ethic? (2006) International Review of Information Ethics, 6, pp. 8-16; Asaro, P., Modeling the moral user. Technology and Society Magazine (2009) IEEE, 28 (1), pp. 20-24; Barras, C., Useful, loveable and unbelievably annoying (2009) The New Scientist, pp. 22-23; Beauchamp, T.L., Childress, J.F., (2001) Principles of Biomedical Ethics, , Oxford/New York: Oxford University Press; Beetz, M., Klank, U., Kresse, I., (2011) Robotic Roommates Making Pancakes, , Humanoid Robots (Humanoids), 2011 11th IEEE-RAS International Conference on; Bekey, G., Current Trends in Robotics: Technology and Ethics (2011) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 17-34. , P. Lin, K. Abney and G. Bekey, Cambridge, MA: MIT Press; Bensalem, S., Gallien, M., Ingrand, F., Designing Autonomous Robots (2009) IEEE Robotics and Automation Magazine, 16 (1), pp. 67-77; Bicchi, A., Peshkin, M., Colgate, J., Safety for Physical Human-Robot Interaction (2008) Springer Handbook of Robotics, pp. 1335-1348. , B. Siciliano and O. Khatib, Berlin: Springer; Bijker, W.E., Law, J., (1992) Shaping Technology/Building Society: Studies in Sociotechnical Change, , Cambridge, MA: MIT Press; Billard, A., Calinon, S., Dillmann, R., Schaal, S., Robot Programming by Demonstration (2008) Springer Handbook of Robotics, pp. 1371-1394. , B. Siciliano and O. Khatib, Berlin: Springer; Bischoff, R., Graefe, V., HERMES – an Intelligent Humanoid Robot Designed and Tested for Dependability (2003) Springer Tracts in Advanced Robotics: Experimental Robotics VIII, 5, pp. 64-74; Borenstein, J., Pearson, Y., Robot Caregivers: Ethical Issues across the Human Life (2011) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 251-266. , P. Lin, K. Abney and G. Bekey, Cambridge, MA: MIT Press; Borgmann, A., (1987) Technology and the Character of Contemporary Life: A Philosophical Inquiry, , Chicago: University of Chicago Press; Breazeal, C.L., (2004) Designing Sociable Robots, , Cambridge, MA: MIT Press; Breazeal, C., Aryananda, L., Recognition of Affective Communicative Intent in Robot-Directed Speech (2002) Autonomous Robots, 12 (1), pp. 83-104; Breazeal, C., Takanishi, A., Kobayashi, T., Social Robots that Interact with People (2008) Springer Handbook of Robotics, pp. 1349-1370. , B. Siciliano and O. Khatib, Berlin: Springer; Brey, P., Artifacts as Social Agents (2005) Inside the Politics of Technology Agency and Normativity in the Co-Production of Technology and Society, pp. 61-84. , H. Harbers (ed.), Amsterdam: Amsterdam University Press; Brey, P., Values in Technology and Disclosive Computer Ethics (2010) The Cambridge Handbook of Information and Computer Ethics, pp. 41-58. , L. Floridi, Cambridge: Cambridge University Press; Brey, P., From Moral Agents to Moral Factors: The Structural Ethics Approach (2014) Anticipatory Ethics for Emerging Technologies, Nanoethics, pp. 1-13. , P. Brey; Brock, O., Kuffner, J., Xiao, J., (2008) Motion for Manipulation Tasks, pp. 615-646. , B. Siciliano and O. Khatib, Berlin: Springer; Buber, M., (1958) I and Thou, , New York: Scribner; Buss, M., Beetz, M., (2010) Cotesys – Cognition for Technical Systems, , Kunstliche Intelligenz; Butterfield, J., (2003) Collins English Dictionary, , Glasgow: HarperCollins; Callon, M., The Sociology of an Actor-Network: The Case of the Electric Vehicle (1986) Mapping the Dynamics of Science and Technology: Sociology of Science in the Real World, pp. 19-24. , M. Callon, J. Law and A. Rip, Basingstoke: Macmillan; Campion, G., Chung, W., Wheeled Robots (2008) Springer Handbook of Robotics, pp. 391-410. , B. Siciliano and O. Khatib, Berlin: Springer; Capek, K., Selver, P., (1923) R.U.R. (Rossum’s Universal Robots): A Fantastic Melodrama, , Garden City, NY: Doubleday, Page & Co; Capurro, R., (2009) Ethics and Robotics, pp. 117-123. , R. Capurro and M. Nagenborg, Heidelberg; [Amsterdam]: AKA; IOS Press; Capurro, R., Nagenborg, M., (2009) Ethics and Robotics, , Heidelberg; [Amsterdam]: AKA; IOS Press; Chen, T., King, C.-H., Thomaz, A., Kemp, C., (2011) Touched by a Robot: An Investigation of Subjective Responses to Robot-Initiated Touch, , Human-Robot Interaction (HRI), 2011 6th ACM/IEEE International Conference on; Chung, W., Fu, L., Hsu, S., Motion Control (2008) Springer Handbook of Robotics, pp. 133-160. , B. Siciliano and O. Khatib, Berlin: Springer; Coeckelbergh, M., Health care, capabilities, and AI assistive technologies (2010) Ethical Theory and Moral Practice, 13 (2), pp. 181-190; Cooley, M., From judgment to calculation (2007) AI & Society, 21 (4), pp. 395-409; Cooper, C., Selwood, A., Blanchard, M., Abuse of people with dementia by family carers: Representative cross sectional survey (2009) British Medical Journal, 338 (7694), pp. 583-585; Correia, M., Waitzberg, D., The impact of malnutrition on morbidity, mortality, length of hospital stay and costs evaluated through a multivariate model analysis (2003) Clinical Nutrition (Edinburgh, Scotland), 22 (3), pp. 235-239; Cotin, S., Delingette, H., Ayache, N., A hybrid elastic model for real-time cutting, deformations, and force feedback for surgery training and simulation (2000) VISUAL COMPUTER, 16, pp. 437-452; Cummings, M., Integrating ethics in design through the value-sensitive design approach (2006) Science and Engineering Ethics, 12, pp. 701-715; Daniilidis, K., Eklundh, J., 3-D Vision and Recognition (2008) Springer Handbook of Robotics, pp. 543-562. , B. Siciliano and O. Khatib, Berlin: Springer; Dautenhahn, K., Roles and functions of robots in human society – Implications from research in autism therapy (2003) Robotica, 21, pp. 443-452; Dautenhahn, K., Werry, I., Towards interactive robots in autism therapy: Background, motivation and challenges (2004) Pragmatics & Cognition, 12 (1), pp. 1-35; Dautenhahn, K., Woods, S., Kaouri, C., (2005) What is a Robot Companion – Friend, Assistant Or Butler?, pp. 1192-1197. , Intelligent Robots and Systems, 2005. (IROS 2005). 2005 IEEE/RSJ International Conference on; Davies, A., Snaith, P., Mealtime problems in a continuing-care hospital for the elderly (1980) Age and Ageing, 9 (2), pp. 100-105; Decker, M., Caregiving robots and ethical reflection: The perspective of interdisciplinary technology assessment (2008) AI & Society, 22 (3), pp. 315-330; Den Hoven, J., (2007) ICT and Value Sensitive Design, pp. 67-72. , International Federation for Information Processing – Publications – IFIP (233); Der, H., Reinkensmeyer, D., Rehabilitation and Health Care Robotics (2008) Springer Handbook of Robotics, pp. 1223-1252. , B. Siciliano and O. Khatib, Berlin: Springer; Dietsch, J., People meeting robots in the workplace (2010) IEEE Robotics and Automation Magazine, 17 (2), pp. 15-16; Dubberly, H., How do you design? (2004) A Compendium of Models, , http://www.dubberly.com/articles/how-do-you-design.html; Engelberger, J.F., (1989) Robotics in Service, , Cambridge, MA: MIT Press; Evanoff, B.A., Use of mechanical patient lifts decreased musculoskeletal symptoms and injuries among health care workers (2004) Injury Prevention, 10 (4), pp. 212-216; Facility, T.R., (2008) Our Journey in 2008–9: Annual Report, , http://www.torontorehab.com/About-Us/Corporate-Publication/2008-2009/hospital.asp; Feng, P., Feenberg, A., Thinking about Design: Critical Theory of Technology and the Design Process (2008) Philosophy and Design: From Engineering to Architecture, pp. 105-118. , P. E. Vermaas, Dordrecht: Springer; Feron, E., Johnson, E., Aerial Robotics (2008) Springer Handbook of Robotics, pp. 1009-1030. , B. Siciliano and O. Khatib, Berlin: Springer; Floridi, L., Sanders, J., On the Morality of Artificial Agents (2004) Minds and Machines, 14 (3), pp. 349-379; Fong, T., Nourbakhsh, I., Dautenhahn, K., A survey of socially interactive robots (2003) Robotics and Autonomous Systems, 42 (3), p. 143; Franklin, S., Graesser, A., Is it an Agent, or Just a Program? A Taxonomy for Autonomous Agents (1997) Lecture Notes in Computer Science, p. 21; Franklin, S., Graesser, A., Olde, B., (1996) Virtual Mattie – an Intelligent Clerical Agent, , AAA Symposium on Embodied Cognition and Action, Cambridge, MA; Fraser, N., (1989) Unruly Practices: Power, Discourse, and Gender in Contemporary Social Theory, , Minneapolis: University of Minnesota Press; Friedman, B., Kahn, P.H., Borning, A., Value Sensitive Design and Information Systems (2006) Human-Computer Interaction and Management Information Systems: Foundations, , P. Zhang and D. Galletta, M.E. Sharpe; Friedrich, H., Münch, S., Dillmann, R., Robot Programming by Demonstration (RPD): Supporting the Induction by Human Interaction (1996) Machine Learning, 23 (2-3), pp. 163-189; Gadow, S.A., Nurse and Patient: The Caring Relationship (2002) Caring, Curing, Coping: Nurse, Physician, and Patient Relationships, pp. 31-43. , A. Bishop and J. Scudder, Tuscaloosa, AL: University of Alabama Press; Gill, S., Socio-ethics of interaction with intelligent interactive technologies (2008) AI & Society, 22 (3), pp. 283-300; Gilligan, C., (1982) In a Different Voice: Psychological Theory and Women’s Development, , Cambridge, MA: Harvard University Press; Goetz, J., Kiesler, S., (2002) Cooperation with a Robotic Assistant, pp. 578-579. , CHI Conference on Human Factors in Computing Systems; Hannaford, B., Okamura, A., Haptics (2008) Springer Handbook of Robotics, pp. 719-758. , B. Siciliano and O. Khatib, Berlin: Springer; Harbers, H., Mol, A., Stollmeyer, A., Food Matters: Arguments for an Ethnography of Daily Care (2002) Theory, Culture & Society, 19 (5), p. 207; Haselager, W.F., Robotics, philosophy and the problems of autonomy (2005) Pragmatics and Cognition, 13 (3), pp. 515-532; Hayashi, T., Control method of robot suit HAL working as operator’s muscle using biological and dynamical information (2005) IEEE, pp. 3063-3068; Heinzmann, J., Zelinsky, A., (1998) 3-D Facial Pose and Gaze Point Estimation Using a Robust Real-Time Tracking Paradigm, pp. 142-147. , Automatic Face and Gesture Recognition, 1998. Proceedings. Third IEEE International Conference on; Hertzberg, J., Chatila, R., AI Reasoning Methods for Robotics (2008) Springer Handbook of Robotics, pp. 207-228. , B. Siciliano and O. Khatib, Berlin: Springer; Hirano, T., Generation of Human Care Behaviors by Human-Interactive Robot RI-MAN (2007) IEEE, pp. 3128-3129; Hirose, S., Yamada, H., Snake-Like Robots (2009) IEEE Robotics and Automation Magazine, 16 (1), pp. 88-98; Hofmann, B., Why ethics should be part of health technology assessment (2008) International Journal of Technology Assessment in Health Care, 24 (4), pp. 423-429; Hosoda, K., Takuma, T., Nakamoto, A., Hayashi, S., Biped robot design powered by antagonistic pneumatic actuators for multi-modal locomotion (2008) Robotics and Autonomous Systems, 56 (1), pp. 46-53; Howcroft, D., Mitev, N., Wilson, M., What We May Learn From the Social Shaping of Technology Approach (2004) Social Theory and Philosophy for Information Systems, pp. 329-371. , J. Mingers and L. Willcocks, West Sussex, UK: John Wiley and Sons; Introna, L., Disclosive Ethics and Information Technology: Disclosing Facial Recognition Systems (2005) Ethics and Information Technology, 7 (2), pp. 75-86; Jain, A.K., Li, S.Z., (2005) Handbook of Face Recognition, , New York: Springer Science+Business Media, Inc; Jecker, N.S., Self, D.J., Separating Care and Cure: An Analysis of Historical and Contemporary Images of Nursing and Medicine (1991) Journal of Medicine and Philosophy, 16 (3), pp. 285-306; Jelsma, J., Designing “moralized” products: Theory and Practice (2006) User Behavior and Technology Development: Shaping Sustainable Relations between Consumers and Technologies, pp. 221-231. , P. Verbeek and A. Slob, Dordrecht: Springer; Kahn, R.E., Swain, M.J., Prokopowicz, P.N., Firby, R.J., Gesture Recognition Using the Perseus Architecture (1996) Computer Vision and Pattern Recognition, IEEE, pp. 734-741; Kajita, S., Espiau, B., Legged Robots (2008) Springer Handbook of Robotics, pp. 361-390. , B. Siciliano and O. Khatib, Berlin: Springer; Kavraki, L., Lavalle, S., Motion Planning (2008) Springer Handbook of Robotics, pp. 109-132. , B. Siciliano and O. Khatib, Berlin: Springer; Kawamoto, H., Sankai, Y., (2002) Power Assist System HAL-3 for Gait Disorder Person, pp. 196-203. , London, UK: Springer-Verlag; Kawasaki, H., Komatsu, T., Uchiyama, K., Kurimoto, T., (1999) Dexterous Anthropomorphic Robot Hand with Distributed Tactile Sensor: Gifu Hand II, , Mechatronics, IEEE/ASME Transactions on; Kazerooni, H., Exoskeletons for Human Performance Augmentation (2008) Springer Handbook of Robotics, pp. 773-798. , B. Siciliano and O. Khatib, Berlin: Springer; Kemp, C., Fitzpatrick, P., Hirukawa, H., Humanoids (2008) Springer Handbook of Robotics, pp. 1307-1334. , B. Siciliano and O. Khatib, Berlin: Springer; Kidd, C.D., (2008) Designing for Long-Term Human–Robot Interaction and Application to Weight Loss, , PhD dissertation; Kidd, C.D., Breazeal, C.L., (2006) Designing a Sociable Robot System for Weight Maintenance, IEEE, pp. 253-257; Kim, K.H., Bang, S.W., Kim, S.R., Emotion recognition system using short-term monitoring of physiological signals (2004) Medical & Biological Engineering & Computing, 42, pp. 419-427; Kiran, A.H., Responsible Design. A Conceptual Look at Interdependent Design-Use Dynamics (2011) Philosophy & Technology (1); Koggel, C.M., (1998) Perspectives on Equality: Constructing a Relational Theory, , Lanham, MD: Rowman & Littlefield Publishers; Koughnett, J.V., Jayaraman, S., Eagleson, R., Are there advantages to robotic-assisted surgery over laparoscopy from the surgeon’s perspective? (2009) Journal of Robotic Surgery, 3, pp. 79-82; Krapp, K., Activities of Daily Living Evaluation (2002) Encyclopedia of Nursing & Allied Health, , Detroit, MI: Gale Group, Inc; Kubrick, S., Clarke, A.C., Dullea, K., (1968) 2001, a Space Odyssey, , Burbank, CA: Warner Home Video; Kunze, L., Roehm, T., Beetz, M., (2011) Towards Semantic Robot Description Languages, pp. 5589-5595. , Robotics and Automation (ICRA), 2011 IEEE International Conference on; Latour, B., Where Are the Missing Masses? The Sociology of a Few Mundane Artifacts (1992) Shaping Technology/Building Society: Studies in Sociotechnical Change, pp. 225-258. , W. Bijker and J. Law, Cambridge, MA: MIT Press; Lauwers, T.B., Kantor, G.A., Hollis, R.L., (2006) A Dynamically Stable Singlewheeled Mobile Robot with Inverse Mouse-Ball Drive, pp. 2884-2889. , Robotics and Automation, 2006. ICRA 2006. Proceedings 2006 IEEE International Conference on; Le, C.A., Poole, E.S., Wyche, S.P., (2009) Values as Lived Experience: Evolving Value Sensitive Design in Support of Value Discovery, pp. 1141-1150. , New York: ACM; Leininger, M., Leininger’s theory of nursing: Culture care diversity and universality (1988) Nursing Science Quarterly, 2, pp. 11-20; Lin, P., Abney, K., Bekey, G., (2011) Robot Ethics: The Ethical and Social Implications of Robotics, , Cambridge, MA: MIT Press; Little, M.O., Care: From Theory to Orientation and Back (1998) The Journal of Medicine and Philosophy, 23 (2), pp. 190-209; Lofquist, L.H., Dawis, R., Values as second-order needs in the theory of work adjustment (1978) Journal of Vocational Behavior, 12 (1), pp. 12-19; Lytle, M., Robot care bears for the elderly (2002) BBC, , http://news.bbc.co.uk/2/hi/science/nature/1829021.stm; Macdorman, K.F., Ishiguro, H., The uncanny advantage of using androids in cognitive and social science research (2006) Interaction Studies, 7 (3), pp. 297-337; Manders-Huits, N., What Values in Design? The Challenge of Incorporating Moral Values into Design (2011) Science and Engineering Ethics, 17 (2), pp. 271-287; Maslow, A.H., (1970) Motivation and Personality, , New York: Harper & Row; Maurer, M., (2007) Some Ideas on ICT as It Influences the Future, , NEC Technology Forum, Tokyo; Max-Neef, M., Economic growth and quality of life: A threshold hypothesis (1995) Ecological Economics, 15 (2), pp. 115-118; Mayer, C., Radig, B., Sosnowski, S., Kuhnlenz, K., (2010) Towards Robotic Facial Mimicry: System Development and Evaluation, pp. 198-203. , Proceedings – IEEE International Workshop on Robot and Human Interactive Communication; Melchiorri, C., Kaneko, M., Robot Hands (2008) Springer Handbook of Robotics, pp. 345-360. , B. Siciliano and O. Khatib, Berlin: Springer; Metzler, T., Lewis, L., (2008) Ethical Views, Religious Views, and Acceptance of Robotic Applications: A Pilot Study, pp. 15-22. , www.aaai.org, Association for the Advancement of Artificial Intelligence; Minato, T., Shimada, M., Ishiguro, H., Itakura, S., Development of an Android Robot for Studying Human-Robot Interaction (2004) Lecture Notes in Computer Science, (3029), pp. 424-434; Minato, T., Yoshikawa, Y., Noda, T., (2007) CB2: A Child Robot with Biomimetic Body for Cognitive Developmental Robotics, pp. 557-562. , Humanoid Robots, 2007 7th IEEE-RAS International Conference on; Minguez, J., Lamiraux, F., Laumond, J., Motion Planning and Obstacle Avoidance (2008) Springer Handbook of Robotics, pp. 827-852. , B. Siciliano and O. Khatib, Berlin: Springer; Mitcham, C., (2005) Encyclopedia of Science, Technology and Ethics, , Detroit, MI: Macmillan Reference; Mitra, P., Niemeyer, G., Model-mediated Telemanipulation (2008) The International Journal of Robotics Research, 27 (2), pp. 253-262; Mol, A., Care and its values: Good food in the nursing home (2010) Care in Practice: On Tinkering in Clinics, Homes and Farms, , A. Mol, I. Moser and A. Pols, Bielefeld: Transcript Verlag; Mol, A., Moser, I., Pols, J., (2010) Care in Practice: On Tinkering in Clinics, Homes and Farms, , Bielefeld; Piscataway, NJ: Transcript; Distributed in North America by Transaction Publishers; Moor, J.H., Is Ethics Computable? (1995) Metaphilosophy, 26 (1-2), p. 1; Moor, J.H., Machine Ethics – The Nature, Importance, and Difficulty of Machine Ethics (2006) IEEE Intelligent Systems, 21 (4), p. 18; Moravec, H.P., (1999) Robot: Mere Machine to Transcendent Mind, , New York: Oxford University Press; Mori, M., Bukimi no tani: The uncanny valley (1970) Energy, 7 (4), pp. 33-35; Morin, P., Samson, C., Motion Control of Wheeled Mobile Robots (2008) Springer Handbook of Robotics, pp. 799-826. , B. Siciliano and O. Khatib, Berlin: Springer; Mowshowitz, A., Technology as excuse for questionable ethics (2008) AI & Society, 22 (3), pp. 271-282; Mutlu, B., Forlizzi, J., (2008) Robots in Organizations: The Role of Workflow, Social, and Environmental Factors in Human-Robot Interaction, pp. 287-294. , Human-Robot Interaction (HRI), 2008, 3rd ACM/IEEE International Conference; Nathan, L.P., Friedman, B., Klasnja, P., (2008) Envisioning Systemic Effects on Persons and Society throughout Interactive System Design, pp. 1-10. , USA: ACM; Nedelsky, J., Reconceiving Rights and Constitutionalism (2008) Journal of Human Rights, 7 (2), pp. 139-173; Neven, L., But obviously not for me: Robots, laboratories and the defiant identity of elder test users (2010) Sociology of Health and Illness, 32 (2), pp. 335-347; Niemeyer, G., Preusche, C., Hirzinger, G., Telerobotics (2008) Springer Handbook of Robotics, pp. 741-758. , B. Siciliano and O. Khatib, Berlin: Springer; Nissenbaum, H., How computer systems embody values (2001) Computer, 34 (3), pp. 120-219; Noddings, N., (1984) Caring, a Feminine Approach to Ethics & Moral Education, , Berkeley: University of California Press; Noddings, N., (2002) Starting at Home Caring and Social Policy, , Berkeley: University of California Press; Nordmann, A., Rip, A., Mind the gap revisited (2009) Nature Nanotechnology, 4 (5), pp. 273-274; (1999) Standard For the Therapeutic Nurse-Client Relationship: For Registered Nurses and Registered Practical Nurses in Ontario: Standards of Practice, , The College of Nurses of Ontario; The Ethical Framework for Nurses in Ontario: Standards of Practice, , The College of Nurses of Ontario; Nussbaum, M.C., (2000) Women and Human Development: The Capabilities Approach, , Cambridge/New York: Cambridge University Press; Oh, J.-H., Hanson, D., Kim, W.-S., Design of Android Type Humanoid Robot Albert HUBO, pp. 1428-1433. , Intelligent Robots and Systems, 2006 IEEE/RSJ International Conference on; Oosterhof, N., (2005) Thinking Machines that Feel: The Role of Emotions in Artificial Intelligence Research, , Master’s thesis, University of Twente; Oosterlaken, I., Design for development: A capability approach (2009) Design Issues, 25 (4), pp. 91-102; Orpwood, R., Adlam, T., Evans, N., Chadd, J., Evaluation of an assisted-living smart home for someone with dementia (2008) Journal of Assistive Technologies, 2 (2), pp. 13-21; Payne, B.K., Cikovic, R., Empirical Examination of the Characteristics, Consequences, and Causes of Elder Abuse in Nursing Homes (1995) Journal of Elder Abuse & Neglect, 7 (4), pp. 61-74; Pellegrino, E.D., The Virtuous Physician, and the Ethics of Medicine (1985) Virtue and Medicine: Explorations in the Character of Medicine, 1. , E. Shelp, Dordrecht: D. Reidel Publishing Company; Picard, R.W., (2000) Affective Computing, , Cambridge, MA: MIT Press; Pillemer, K., Moore, D.W., Highlights from a Study of Abuse of Patients in Nursing Homes (1990) Journal of Elder Abuse & Neglect, 2 (1-2), pp. 5-29; Pineau, J., Montemerlo, M., Pollack, M., Towards robotic assistants in nursing homes: Challenges and results (2003) Robotics and Autonomous Systems, 42 (3), p. 271; Podnieks, E., (1990) National Survey on Abuse of the Elderly in Canada. Toronto, , Ontario: Ryerson Polytechnical Institute; Pollack, M.E., Brown, L., Colbry, D., (2002) Pearl: A Mobile Robotic Assistant for the Elderly, pp. 85-92. , AAAI 2002, Workshop on Automation as Caregiver: The Role of Intelligent Technology in Elder Care; Pols, A.J., (2004) Good Care: Enacting a Complex Ideal in Long-Term Psychiatry, , Utrecht: Trimbos-instituut; Prattichizzo, D., Trinkle, J., Grasping (2008) Springer Handbook of Robotics, pp. 671-700. , B. Siciliano and O. Khatib, Berlin: Springer; Rayman, R., Croome, K., Galbraith, N., Long-distance robotic telesurgery: A feasibility study for care in remote environments (2006) The International Journal of Medical Robotics + Computer Assisted Surgery, 2 (3), pp. 216-224; Rayman, R., Croome, K., Galbraith, N., Robotic telesurgery: A real-world comparison of ground- and satellite-based internet performance (2007) The International Journal of Medical Robotics + Computer Assisted Surgery, 3 (2), pp. 111-116; Razavi, S., (2007) The Political and Social Economy of Care in a Development Context: Conceptual Issues, Research Questions and Policy Options, , Geneva: United Nations Research Institute for Social Development; Reich, W.T., History of the notion of care (1995) Encyclopedia of Bioethics, pp. 219-331. , W. T. Reich, New York/London: Macmillan; Simon & Schuster; Prentice Hall International; Roach, M.S., (1999) The Human Act of Caring: A Blueprint for the Health Professions, , Ottawa: Canadian Hospital Association Press; Robotics, A., (2010) Nao, the ideal partner for research and robotics classrooms, , www.aldebaran-robotics.com/en; Ruddick, S., (1995) Maternal Thinking: Toward a Politics of Peace [With a New Preface], , Boston: Beacon Press; Rudnick, A., A meta-ethical critique of care ethics (2001) Theoretical Medicine and Bioethics, 22 (6), pp. 505-517; Russell, S.J., Norvig, P., (1995) Artificial Intelligence: A Modern Approach, , Englewood Cliffs, NJ: Prentice Hall; Saenz, A., Incredible TUG Robots Automate Delivery in Hospitals (2010) Singularity Hub, , http://singularityhub.com/2010/06/06/incredible-tug-robotsautomate-delivery-in-hospitals-video/; Sakamoto, D., Kanda, T., Ono, T., (2007) Android as a Telecommunication Medium with a Human-Like Presence, pp. 193-200. , USA: ACM; Sandelowski, M., Exploring the gender-technology relation in nursing (1997) Nursing Inquiry, 4 (4), pp. 219-228; Santoro, M., Marino, D., Tamburrini, G., Learning robots interacting with humans: From epistemic risk to responsibility (2008) AI & Society, 22 (3), pp. 301-314; Satoh, H., Kawabata, T., Sankai, Y., (2009) Bathing Care Assistance with Robot Suit HAL, IEEE, pp. 498-503; Schoenhofer, S., A Framework for Caring in a Technologically Dependent Nursing Practice Environment (2001) Advancing Technology, Caring and Nursing, pp. 3-11. , Rozzano Loscin ed., Westport, CT: Auburn House; Schulz, D., Burgard, W., Fox, D., Cremers, A.B., People Tracking with Mobile Robots Using Sample-Based Joint Probabilistic Data Association Filters (2003) The International Journal of Robotics Research, 22 (2), pp. 99-116; Sen, A., (1985) Commodities and Capabilities, , Amsterdam/New York: Elsevier; Sharkey, N., Sharkey, A., The Rights and Wrongs of Robot Care (2011) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 267-282. , P. Lin, K. Abney and G. Bekey, Cambridge, MA: MIT Press; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics and Information Technology, 14 (1), pp. 27-40; Shaw-Garlock, G., Looking Forward to Sociable Robots (2009) International Journal of Social Robotics, 1 (3), pp. 249-260; Shieh, M.Y., Lu, C.M., Chen, C.C., (2007) Design and Implementation of an Interactive Nurse Robot, pp. 2121-2125. , SICE, 2007 Annual Conference; Siciliano, B., Khatib, O., (2008) Springer Handbook of Robotics, , Berlin: Springer; Sidner, C.L., Dzikovska, M., A First Experiment in Engagement for Human-Robot Interaction in Hosting Activities (2005) Advances in Natural Multimodal Dialogue Systems, 30, pp. 55-76. , J. C. J. van Kuppevelt, L. Dybkjær, N. O. Bernsen and N. Ide, Netherlands: Springer; Silverstone, R., Hirsch, E., Morley, D., Information and communication technologies and the moral economy of the household (1992) Consuming Technologies: Media and Information in Domestic Spaces, pp. 15-31. , R. Silverstone and E. Hirsch, London: Routledge; Singer, P.W., (2009) Wired for War: The Robotics Revolution and Conflict in The Twentyfirst Century, , New York: Penguin Press; Smits, R., Leyten, J., Den Hertog, P., Technology assessment and technology policy in Europe: New concepts, new goals, new infrastructures (1995) Policy Sciences, 28 (3), pp. 271-299; Soraker, J., When Does the Mind matter? The Strengths and Limitations of the Informational Level of Abstraction Ethics and Information Technology; Sorensen, K., Domestication: The Enactment of Technology (2005) Domestication of Media and Technology, pp. 40-61. , T. Berker, M. Hartmann, Y. Punie and K. Ward, Open University Press; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Minds and Machines, 16 (2), pp. 141-161; Stabell, A., Eide, H., Solheim, G.A., Nursing Older People: Nursing home residents’ dependence and independence (2004) Journal of Clinical Nursing, 13 (6), pp. 677-686; Sullins, J., When is a robot a moral agent? (2006) International Review of Information Ethics, 6, pp. 23-30; Super, D.E., (1968) Work Values Inventory, , Boston: Houghton Mifflin; Sutton, R.S., Barto, A.G., (2010) Reinforcement Learning: An Introduction, , Cambridge, MA: MIT Press; Swierstra, T., Rip, A., Nano-ethics as NEST-ethics: Patterns of Moral Argumentation about New and Emerging Science and Technology (2007) Nanoethics, 1 (1), pp. 3-20; Tamburrini, G., Robot Ethics: A View from the Philosophy of Science (2009) Ethics and Robotics, pp. 11-22. , R. Capurro and M. Nagenborg, Heidelberg; [Amsterdam]: AKA; IOS Press; Tamura, T., Yonemitsu, S., Itoh, A., Is an entertainment robot useful in the care of elderly people with severe dementia? (2004) The Journals of Gerontology Series A: Biological Sciences and Medical Sciences, 59 (1), pp. M83-M85; Tenorth, M., (2011) Knowledge Processing for Autonomous Robots. Phd Dissertation, , München: Universitätsbibliothek der TU München; Tenorth, M., Beetz, M., Knowledge Processing for Autonomous Robot Control (2012) AAAI Spring Symposium: Designing Intelligent Robots; Tenorth, M., Jain, D., Beetz, M., Knowledge Representation for Cognitive Robots (2010) Kunstliche Intelligenz, 24 (3), pp. 233-240; Thaler, R.H., Sunstein, C.R., (2008) Nudge: Improving Decisions about Health, Wealth, and Happiness, , New Haven: Yale University Press; Thow-Hing, V.N., Torisson, K., Sarvadevabhatla, R.K., Cognitive Map Architecture: Facilitation of Human-Robot Interaction in Humanoid Robots (2009) IEEE Robotics and Automation Magazine, 16 (1), pp. 55-66; Thrun, S., Toward a Framework for Human-Robot Interaction (2004) Human- Computer Interaction, 19 (1), pp. 9-24; Thrun, S., Schulte, J., Rosenberg, C., Interaction with Mobile Robots in Public Places (2000) IEEE Intelligent Systems, pp. 7-11; Torrance, S., Ethics and consciousness in artificial agents (2008) AI & Society, 22 (4), pp. 495-521; Tronto, J., Creating Caring Institutions: Politics, Plurality, and Purpose (2010) Ethics and Social Welfare, 4 (2), pp. 158-171; Tronto, J.C., (1993) Moral Boundaries: A Political Argument for an Ethic of Care, , New York: Routledge; Turing, A.M., Computing machinery and intelligence (1950) Mind: A Quarterly Review of Psychology and Philosophy, 59 (236), p. 433; Turkle, S., (2011) Alone Together: Why We Expect More from Technology and less from Each Other, , New York: Basic Books; Vallor, S., Carebots and caregivers: Sustaining the ethical ideal of care in the twenty-first century (2011) Philosophy and Technology, 24 (3), pp. 251-268; Van De Poel, I., Values in engineering design (2009) Handbook of the Philosophy of Science. Volume 9: Philosophy of Technology and Engineering Sciences, , A. Meijers (ed.), Oxford: Elsevier; Van De Poel, I., Kroes, P., Can Technology Embody Values? (2014) Moral Agency and Technical Artefacts, , P. Kroes and P.-P. Verbeek, Dordrecht: Springer; Van Der Plas, A., Smits, M., Wehrmann, C., Beyond speculative robot ethics: A vision assessment study on the future of the robotic caretaker (2010) Accountability in Research, 17 (6), pp. 299-315; Van Gorp, A., Van De Poel, I., Deciding on Ethical Issues in Engineering Design (2008) Philosophy and Design: From Engineering to Architecture, pp. 77-90. , P. E. Vermaas, Dordrecht: Springer; Van Wynsberghe, A., Designing robots for care: Care centered valuesensitive design (2013) Science and Engineering Ethics, 19 (2), pp. 407-433; Van Wynsberghe, A., A Method for Integrating Ethics into the Design of Robots (2013) Industrial Robot, 40 (5), pp. 433-440; Van Wynsberghe, A., (2014) To Delegate Or Not to Delegate: Care Robots, Moral Agency and Moral Responsibility, , Machine Ethics in the Context of Medical and Care Agents, conference proceedings, April; Van Wynsberghe, A., Gastmans, C., Telesurgery: An ethical appraisal (2008) Journal of Medical Ethics, 34 (10); Van Wynsberghe, A., Gastmans, C., Telepsychiatry and the meaning of in-person contact: A preliminary ethical appraisal (2009) Medicine, Health Care, and Philosophy, 12 (4), pp. 469-476; Van Wynsberghe, A., Robbins, S., Ethicist as Designer: A pragmatic approach to ethics in the lab (2014) Science and Engineering Ethics, 20 (4), pp. 947-961; Vanlaere, L., Gastmans, C., A personalist approach to care ethics (2011) Nursing Ethics, 18 (2), pp. 161-173; Verbeek, P., Morality in Design; design ethics and the morality of technological artifacts (2008) Philosophy and Design: From Engineering to Architecture, pp. 91-102. , P. E. Vermaas, Dordrecht: Springer; Verbeek, P.-P., (2005) What Things Do: Philosophical Reflections on Technology, Agency, and Design, , Pennsylvania.: Pennsylvania State University Press; Verbeek, P.-P., Materializing Morality (2006) Science, Technology, & Human Values, 31 (3), pp. 361-380; Verbeek, P.-P., (2011) Moralizing Technology: Understanding and Designing the Morality of Things, , Chicago/London: The University of Chicago Press; Verkerk, M., The care perspective and autonomy (2001) Medicine, Health Care, and Philosophy, 4 (3), pp. 289-294; Verkerk, M.A., Busschbach, J.J.V., Karssing, E.D., Health-Related Quality of Life Research and the Capability Approach of Amartya Sen (2001) Quality of Life Research, 10 (1), pp. 49-55; Veruggio, G., Abney, K., Roboethics: The Applied Ethics for a New Science (2011) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 347-364. , P. Lin, K. Abney and G. Bekey, Cambridge, MA: MIT Press; Veruggio, G., Operto, F., Roboethics: A Bottom-up Interdisciplinary Discourse in the Field of Applied Ethics in Robotics (2006) International Review of Information Ethics, 6, pp. 3-8; Veruggio, G., Operto, F., Roboethics: Social and Ethical Implications of Robotics (2008) Springer Handbook of Robotics, pp. 1499-1524. , B. Siciliano and O. Khatib, Berlin: Springer; Villani, L., De Schutter, J., Force Control (2008) Springer Handbook of Robotics, pp. 161-186. , B. Siciliano and O. Khatib, Berlin: Springer; Vongsoasup, V., Mataric, M., Path Planning and Navigation for Geeves: A Tour-Guide/Greeter Robot; Wada, K., Shibata, T., Saito, T., (2005) Psychological and Social Effects of One Year Robot Assisted Activity on Elderly People at a Health Service Facility for the Aged, pp. 2785-2790. , Robotics and Automation, 2005. ICRA 2005. Proceedings of the 2005 IEEE International Conference on; (2008) WALL-E [Motion Picture], , Walt Disney Home Entertainment; Wallach, W., Robot minds and human ethics: The need for a comprehensive model of moral decision making (2010) Ethics and Information Technology, 12 (3), pp. 243-250; Wallach, W., Allen, C., (2010) Moral Machines: Teaching Robots Right from Wrong, , New York/Oxford: Oxford University Press; Wallach, W., Allen, C., Smit, I., Machine morality: Bottom-up and top-down approaches for modelling human moral faculties (2008) AI & Society, 22 (4), pp. 565-582; Wallach, W., Franklin, S., Allen, C., A conceptual and computational model of moral decision making in human and artificial agents (2010) Topics in Cognitive Science, 2 (3), pp. 454-485; Walters, M.L., Dautenhahn, K., Woods, S.N., Koay, K.L., (2007) Robotic Etiquette: Results from User Studies Involving a Fetch and Carry Task, pp. 317-324. , Human-Robot Interaction (HRI), 2007 2nd ACM/IEEE International Conference on; Weaver, K., Morse, J., Mitcham, C., Ethical sensitivity in professional practice: Concept analysis (2008) Journal of Advanced Nursing, 62 (5), pp. 607-618; Widdershoven, G., Technology and Care, from Opposition to Integration (2002) Between Technology and Humanity: The Impact of Technology on Health Care Ethics, pp. 35-48. , C. Gastmans, Leuven: Leuven University Press; Wilson, M., Making nursing visible? Gender, technology and the care plan as script (2002) Information Technology & People, 15 (2), pp. 139-158; Wong, P.-H., Technology, Recommendation and Design: On Being a ‘Paternalistic’ Philosopher (2011) Science and Engineering Ethics, 19 (1), pp. 27-42; Wood, R., Fly, robot fly (2008) IEEE Spectrum, 45 (3), pp. 25-29; Wright, L., Hickson, M., Frost, G., Eating together is important: Using a dining room in an acute elderly medical ward increases energy intake (2006) Journal of Human Nutrition and Dietetics, 19 (1), pp. 23-26; Yoshiro, U., Shinichi, O., Yosuke, T., (2005) Childcare Robot Papero is Designed to Play with and Watch over Children at Nursery, Kindergarten, School and at Home, pp. 1-11. , Development of Childcare Robot PaPeRo; Zaeh, M.F., Roesel, W., Bannat, A., Artificial Cognition in Production Systems (2010) IEEE Transactions on Automation Science and Engineering, 7 (3), pp. 1-27; Zhang, T., Zhu, B., Lee, L., Kaber, D., (2008) Service Robot Anthropomorphism and Interface Design for Emotion in Human–Robot Interaction, IEEE, pp. 674-679},
document_type={Book},
source={Scopus},
}

@BOOK{Guarini2011316,
author={Guarini, M.},
title={Computational neural modeling and the philosophy of ethics: Reflections on the particularism-generalism debate},
journal={Machine Ethics},
year={2011},
volume={9780521112352},
pages={316-334},
doi={10.1017/CBO9780511978036.019},
note={cited By 13},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927009567&doi=10.1017%2fCBO9780511978036.019&partnerID=40&md5=f1dea9ab3c70979d94dece34a7d2c2c6},
abstract={There are different reasons why someone might be interested in using a computer to model one or more dimensions of ethical classification, reasoning, discourse, or action. One reason is to build into machines the requisite level of “ethical sensitivity” for interacting with human beings. Robots in elder care, nannybots, autonomous combat systems for the military – these are just a few of the systems that researchers are considering. In other words, one motivation for doing machine ethics is to support practical applications. A second reason for doing work in machine ethics is to try to better understand ethical reasoning as humans do it. This paper is motivated by the second of the two reasons (which, by the way, need not be construed as mutually exclusive). There has been extensive discussion of the relationship between rules, principles, or standards, on the one hand, and cases on the other. Roughly put, those stressing the importance of the former tend to get labeled generalists, whereas those stressing the importance of the latter tend to get labeled particularists. There are many ways of being a particularist or a generalist. The dispute between philosophers taking up these issues is not a first-order normative dispute about ethical issues. Rather, it is a second-order dispute about how best to understand and engage in ethical reasoning. In short, it is a dispute in the philosophy of ethics. © Cambridge University Press 2011.},
keywords={Combat Systems;  Computational neural models;  Elder care;  Ethical issues;  First order;  Human being;  Second orders, Philosophical aspects},
references={Dancy, J., (2006) Ethics without Principles, , Oxford: Oxford University Press; Elman, J., Finding structure in time (1990) Cognitive Science, 14, pp. 179-211; Garfield, J., Particularity and principle: The structure of moral knowledge (2000) Moral Particularism, , B. Hooker and M. Little, eds. Oxford: Oxford University Press; Guarini, M., Computational theories of mind, and fodor’s analysis of neural network behaviour (2009) Journal of Experimental and Theoretical Artificial Intelligence, 21 (2), pp. 137-153; Guarini, M., Particularism, analogy, and moral cognition (2010) Minds and Machines, 20 (3), pp. 385-422; Henderson, D., Horgan, T., Iceberg epistemology (2000) Philosophy and Phenomenological Research, 61 (3), pp. 497-535; Horgan, T., Timmons, M., Morphological rationalism and the psychology of moral judgement (2007) Ethical Theory and Moral Practice, 10, pp. 279-295; Horgan, T., Timmons, M., What does the frame problem tell us about normativity? (2009) Ethical Theory and Moral Practice, 12, pp. 25-51; Jackson, F., Petit, P., Smith, M., Ethical particularism and patterns (2000) Moral Particularism, , B. Hooker and M. Little, eds. Oxford: Oxford University Press; Little, M.O., Moral generalities revisited (2000) Moral Particularism, , B. Hooker and M. Little, eds. Oxford: Oxford University Press; McKeever, S., Ridge, M., The many moral particularisms (2005) The Canadian Journal of Philosophy, 35, pp. 83-106; McNaughton, D., Rawling, P., Unprincipled ethics (2000) Moral Particularism, , B. Hooker and M. Little, eds. Oxford: Oxford University Press},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{vanderPlas2010299,
author={van der Plas, A. and Smits, M. and Wehrmann, C.},
title={Beyond speculative robot ethics: A vision assessment study on the future of the robotic caretaker},
journal={Accountability in Research},
year={2010},
volume={17},
number={6},
pages={299-315},
doi={10.1080/08989621.2010.524078},
note={cited By 13},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-78249289689&doi=10.1080%2f08989621.2010.524078&partnerID=40&md5=d01ae548175e155eeee63e81bb5f36a9},
abstract={In this article we develop a dialogue model for robot technology experts and designated users to discuss visions on the future of robotics in long-term care. Our vision assessment study aims for more distinguished and more informed visions on future robots. Surprisingly, our experiment also led to some promising co-designed robot concepts in which jointly articulated moral guidelines are embedded. With our model, we think to have designed an interesting response on a recent call for a less speculative ethics of technology by encouraging discussions about the quality of positive and negative visions on the future of robotics. © Taylor & Francis Group, LLC.},
author_keywords={Healthcare;  Long-term care;  Methodology;  Robots;  Vision assessment;  Visions},
keywords={article;  attitude to health;  biomedical technology assessment;  caregiver;  ethics;  forecasting;  health personnel attitude;  human;  independent living;  long term care;  methodology;  robotics;  social behavior, Attitude of Health Personnel;  Attitude to Health;  Caregivers;  Forecasting;  Humans;  Independent Living;  Long-Term Care;  Robotics;  Social Behavior;  Technology Assessment, Biomedical},
references={Asimov, I., (1950) I, Robot, , New York: Gnome Press; Bostrom, N., Ethical issues in advanced artificial intelligence (2006) Review of Contemporary Philosophy, 5, pp. 66-73; Butter, M., Rensma, A., van Boxsel, J., Kalisingh, S., Schoone, M., Leis, M., (2008) Robotics For Healthcare, Final Report, , Brussels: European Commission, DG Information Society; (2009) Dossier Vergrijzing, , www.CBS.nl, CBS, Available at, Last accessed on January 5,2010; Decker, M., Perspektiven der Robotik (1997) Überlegungen Zur Ersetzbarkeit Des Menschen, , In: Graue Reihe, Bd. 8, Europäische Akademie Bad Neuenahr-Ahrweiler; Decker, M., Caregiving robots and ethical reflection: The perspective of interdis-ciplinary technology assessment (2008) AI & Society, 22 (3), pp. 315-330; Dorrestein, S., Design your own Life. Over ethiek en gebruiksvriendelijk ontwerpen (2010) Moralicide, Nieuwe Morele Vocabulaires Over Technologie, , Zutphen: Klement; (2000) Vision Assessment: Shaping Technology In 21st Century Society; Towards a Repertoire For Technology Assessment, , Grin, J. and Grunwald, A. (ed.), Berlin: Springer; Grunwald, A., (2004) Vision Assessment As a New Element of the FTA Toolbox, , EU-US SEMINAR: New Technology Foresight, Forecasting & Assessment Methods, Seville, Spain, May 13-14, 2004; Grunwald, A., Converging technologies: Visions, increased contingencies of the conditio humana, and search for orientation (2007) Futures, 39, pp. 380-392; Heerink, M., Kröse, B., Wielinga, B., Eve, V., (2006) Human-robot User Studies In Eldercare: Lessons Learned. Proceedings, , ICOST, Belfast, UK; Hegel, F., Classes of applications for social robots: A user study (2007) IEEE International Conference On Robot and Human Interactive Communication, , Jeju, Korea; Lau, Y.Y., van t Hoff, C., van Est, R., Beyond the Surface (2009) An Exploration In Healthcare Robotics In Japan, , The Hague: Rathenau Instituut. Beyond Speculative Robot Ethics; Levy, D., The ethical treatment of artificially conscious robots (2009) International Journal of Social Robotics, 1, p. 3; Mambrey, P., Tepper, A., Technology assessment as metaphor assessment (2000) Vision Assessment: Shaping Technology In 21st Century Society, pp. 33-51. , Towards a Repertoire for Technology Assessment: Berlin: Springer; Nordmann, A., Rip, A., Mind the gap revisited (2009) Nature Nanotechnology, 4, pp. 273-274. , May; Ohnishi, N., In a Wired South Korea, Robots Will Feel Right at Home (2006) New York Times, , April 2, 2006; Roelofsen, A., Broerse, J., de Cock Buninga, T., Bunders, J., Exploring the future of ecological genomics: Integrating CTA with Vision Assessment (2008) Technological Forecasting and Social Change, 75, pp. 334-355; (2008) Langdurige Zorg Verzekerd: Over De Toekomst Van De AWBZ, , SER, Third Edition. The Hague: SER; Singer, P., Sagan, A., When robots have feelings. If, as seems likely, we develop super-intelligent machines, their right will need protection, too (2009) The Guardian, , December 14, 2009; Singer, P., (2009) Wired For War, , New York: The Penguin Press; Smaling, A., (2008) Dialoog En Empathie In De Methodologie, , Amsterdam: Uitgeverij SWP; Smits, M., Taming monsters: The cultural domestication of new technology (2006) Technology In Society, 28, pp. 489-504; Tepper, A., Future assessment by metaphors (1993) Behaviour and Information Technology, 12 (6), pp. 336-345; van den Berg, B., Competente technologie. Een pleidooi voor een inclusieve moraal (2010) Moralicide, , Zutphen: Klement; van der Plas, A., The robotic caretaker (2010) Designing a Dialogue About Visions On the Desired Future of Robots In Long-term Care, , Delft: TU Delft; Verbeek, P.P., (2009) Filosofie van Mens en Techniek, , Oratie. Enschede: Universiteit Twente},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Anderson20059,
author={Anderson, M. and Anderson, S.L. and Armen, C.},
title={MedEthEx: Toward a medical ethics advisor},
journal={AAAI Fall Symposium - Technical Report},
year={2005},
volume={FS-05-02},
pages={9-16},
note={cited By 13},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33645958566&partnerID=40&md5=2527f9dfba6693bb1ee63292084a746b},
abstract={As part of a larger Machine Ethics Project, we are developing an ethical advisor that provides guidance to health care workers faced with ethical dilemmas. MedEthEx is an implementation of Beauchamp's and Childress' Principles of Biomedical Ethics that harnesses machine learning techniques to abstract decision principles from cases in a particular type of dilemma with conflicting prima facie duties and uses these principles to determine the correct course of action in similar and new cases. We believe that accomplishing this will be a useful first step towards creating machines that can interact with those in need of health care, including the elderly, in a way that is sensitive to ethical issues that may arise.},
keywords={Biomedical Ethics;  Health care workers;  Medical ethics advisor, Decision making;  Health care;  Human computer interaction;  Learning systems;  Regulatory compliance;  Social aspects, Biomedical engineering},
references={Anderson, M., Anderson, S., Armen, C., Toward machine ethics: Implementing two action-based ethical theories (2005) Proceedings of the AAAI 2005 Fall Symposium on Machine Ethics, , Crystal City, VA; Anderson, M., Anderson, S., Armen, C., Toward machine ethics (2004) Proceedings of AAAI 2004 Workshop on Agent Organizations: Theory and Practice, , San Jose, CA; Buchanan, A.E., Brock, D.W., (1989) Deciding for Others: The Ethics of Surrogate Decision Making, pp. 48-57. , Cambridge University Press; Bratko, I., Refining complete hypotheses in ILP (1999) Inductive Logic Programming, , LNAI 1634, Springer; Beauchamp, T.L., Childress, J.F., (1979) Principles of Biomedical Ethics, , Oxford University Press; Ford, K., Glymour, C., Hayes, P.J., (1991) Android Epistemology, , MIT Press; Lavrac, N., Dzeroski, S., (1997) Inductive Logic Programming: Techniques and Applications, , Ellis Harwood; Mappes, T.A., DeGrazia, D., (2001) Biomedical Ethics, 5 th Edtion, pp. 39-42. , McGraw-Hill, New York; Rawls, J., Outline for a decision procedure for ethics (1951) Philosophical Review, 60; Ross, W.D., (1930) The Right and the Good, , Clarendon Press, Oxford},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Sullins2005139,
author={Sullins, J.P.},
title={Ethics and artificial life: From modeling to moral agents},
journal={Ethics and Information Technology},
year={2005},
volume={7},
number={3},
pages={139-148},
doi={10.1007/s10676-006-0003-5},
note={cited By 13},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646926672&doi=10.1007%2fs10676-006-0003-5&partnerID=40&md5=7b16de3d6499834ff769f1078212ddda},
abstract={Artificial Life (ALife) has two goals. One attempts to describe fundamental qualities of living systems through agent based computer models. And the second studies whether or not we can artificially create living things in computational mediums that can be realized either, virtually in software, or through biotechnology. The study of ALife has recently branched into two further subdivisions, one is "dry" ALife, which is the study of living systems "in silico" through the use of computer simulations, and the other is "wet" ALife that uses biological material to realize what has only been simulated on computers, effectively wet ALife uses biological material as a kind of computer. This is challenging to the field of computer ethics as it points towards a future in which computer and bioethics might have shared concerns. The emerging studies into wet ALife are likely to provide strong empirical evidence for ALife's most challenging hypothesis: that life is a certain set of computable functions that can be duplicated in any medium. I believe this will propel ALife into the midst of the mother of all cultural battles that has been gathering around the emergence of biotechnology. Philosophers need to pay close attention to this debate and can serve a vital role in clarifying and resolving the dispute. But even if ALife is merely a computer modeling technique that sheds light on living systems, it still has a number of significant ethical implications such as its use in the modeling of moral and ethical systems, as well as in the creation of artificial moral agents. © Springer 2006.},
author_keywords={Artificial life;  Ethical status of artificial agents;  Machine ethics;  Simulating evolutionary ethics},
keywords={Artificial agents;  Artificial Life;  Computable functions;  Computer ethics;  Computer modeling techniques;  Computer models;  Ethical implications;  Simulating evolutionary ethics, Biological materials;  Biological systems;  Biotechnology;  Computer simulation;  Information technology, Philosophical aspects},
references={Anderson, M., Anderson, S.L., Armen, C., Towards Machine Ethics (2004) Proceedings of AAAI Workshop on Agent Organizations: Theory and Practice, , San Jose, CA, July; Bedeau, M.A., Philosophical Aspects of Artificial Life. In Towards a Practice of Autonomous Systems (1992) Proceedings of the First European Conference on Artificial Life, pp. 494-503. , MIT Press, Cambridge; Bedau, M.A., Artificial Life (2003) Philosophy of Computing and Information, , L. Floridi, editor Blackwell Publishers; Dawkins, R., (1989) The Selfish Gene, , Oxford University Press Oxford; Dawkins, R., (1996) The Blind Watchmaker: Why the Evidence of Evolution Reveals a Universe Without Design, , W.W. Norton and Company, Inc; Dennett, D., Artificial Life as Philosophy (1994) Artificial Life, 1 (3), pp. 291-292; Dennett, D., (1995) Darwin's Dangerous Idea: Evolution and the Meanings of Life, , Simon and Schuster New York; Elton, M., Should Vegetarians Play Video Games? (2000) Philosophical Papers; Emmeche, C., Life as an Abstract Phenomenon: Is Artificial Life Possible? In Towards a Practice of Autonomous Systems (1992) Proceedings of the First European Conference on Artificial Life, pp. 466-474. , MIT Press, Cambridge; Emmeche, C., (1994) The Garden in the Machine, the Emerging Science of Artificial Life, , Steven Sampson, translator, Princeton University Press Princeton; Epstein, J.M., Axtell, R., (1996) Growing Artificial Societies: Social Science from the Bottom Up, , MIT Press Cambridge; Floridi, L., Sanders, J.W., On the Morality of Artificial Agents (2004) Minds and Machines, 14 (3), pp. 349-379. , 10.1023/B:MIND.0000035461.63578.9d; Helmreich, S., (1998) Silicon Second Nature: Culturing Artificial Life in a Digital World, , University of California Press Berkeley; Horgan, J., From Complexity to Perplexity (1995) Scientific American, p. 104. , June:; Horgan, J., (1996) The End of Science, , Addison-Wesley, Reading; Langton, C.G., Artificial Life (1989) SFI Studies in the Sciences of Complexity, Proc. Vol. VI, , Chris Langton, editor Addison-Wesley, Redwood City; Levy, S., (1992) Artificial Life: The Quest for a New Creation, , Pantheon Books New York; Lewontin, R., (1992) Complexity: Life at the Edge of Chaos, , Macmillan Publishing Company New York; Olson, E.T., The Ontological Basis of Strong Artificial (1997) Life Artificial Life, 3 (1), pp. 29-39; Pattee, H.H., Simulations Realizations and Theories of Life (1987) The Proceedings of an Interdisciplinary Workshop on the Synthesis and Simulation of Living Systems, 6. , C. Langton, editor, Artificial Life: held September in Los Alamos, New Mexico Addison-Wesley, Redwood City, CA, 1989; Pepper, J.W., Smuts, B.B., The Evolution of Cooperation in an Ecological Context: An Agent-Based Model (2000) Dynamics in Human and Primate Societies: Agent-Based Modeling of Social and Spatial Processes, , T.A Kohler G.J Gumerman Oxford University Press New York; Rauch, J., Seeing Around Corners: The New Science of Artificial Societies (2002) The Atlantic Monthly, , April; Rasmussen, S., Aspects of Information, Life, Reality, and Physics (1992) Artificial Life II: The Proceedings of the Workshop on Artificial Life, 10, pp. 767-774. , C. Langton, C. Taylor, J.D. Farmer, S. Rasmussen, editors held February 1990 in Santa Fe, New Mexico Addison-Wesley, Redwood City; Rasmussen, L., Chen, D., Deamer, D., Krakauer, N., Packard, P., Stadler, S., Bedau, M., Transitions From Nonliving and Living Matter (2004) Science, 303, pp. 963-965. , 10.1126/science.1093669; Ray, T., An Approach to the Synthesis of Life (1992) Artificial Life II: The Proceedings of the Workshop on Artificial Life, 10, pp. 767-774. , C. Langton, C. Taylor, J.D. Farmer S. Rasmussen, editors held February 1990 in Santa Fe, New Mexico Addison-Wesley, Redwood City; Sober, E., Learning From Functionalism - Prospects for Strong Artificial Life (1992) Artificial Life II: The Proceedings of the Workshop on Artificial Life, 10. , C. Langton et al., editors held February 1990 in Santa Fe, New Mexico Addison-Wesley, Redwood City; Sober, E., Wilson, D., (1998) Unto Others: The Evolution and Psychology of Unselfish Behavior, , Harvard University Press Boston; Sullins, J., Knowing Life: Possible Solutions to the Practical Epistemological Limits in the Study of Artificial Life (2000) The Journal of Experimental and Theoretical Artificial Intelligence, 12 (1), pp. 13-22. , 1033.68918 10.1080/095281300146281; Szostak, J., Bartel, D., Luisi, P., Synthesizing Life (2001) Nature, 409, pp. 383-390. , 10.1038/35053176},
document_type={Article},
source={Scopus},
}

@ARTICLE{Pearson201423,
author={Pearson, Y. and Borenstein, J.},
title={Creating "companions" for children: The ethics of designing esthetic features for robots},
journal={AI and Society},
year={2014},
volume={29},
number={1},
pages={23-31},
doi={10.1007/s00146-012-0431-1},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899476721&doi=10.1007%2fs00146-012-0431-1&partnerID=40&md5=9261f386dbe570bca5000a8eee7563df},
abstract={Taking the term "companion" in a broad sense to include robot caregivers, playmates, assistive devices, and toys, we examine ethical issues that emerge from designing companion robots for children. We focus on the relative importance and potential ethical implications of creating robots with certain types of esthetic features. We include an examination of whether robots ought to be made to appear or act humanlike, and whether robots should be gendered. In our estimation, this line of ethical inquiry may even provide insight into the nature and appropriateness of existing institutions and widely accepted interactions among human beings. © 2012 Springer-Verlag London Limited.},
author_keywords={Children;  Design ethics;  Gender;  Human-robot interaction;  Robot companions;  Robot ethics},
keywords={Philosophical aspects;  Robots, Children;  Design ethics;  Gender;  Robot companion;  Robot ethics, Machine design},
references={Banks, M.R., Willoughby, L.M., Banks, W.A., Animal-assisted therapy and loneliness in nursing homes: use of robotic versus living dogs (2008) J Am Med Dir Assoc, 9 (3), pp. 173-177; Bartneck, C., Kanda, T., Ishiguro, H., Hagita, N., My robot doppelganger: A critical look at the uncanny valley (2009) Robot and Human Interactive Communication RO-MAN; Belpaeme, T., Morse, A., Time will tell-why it is too early to worry (2010) Interact Stud, 11 (2), pp. 191-195; Borenstein, J., Pearson, Y., Robot caregivers: harbingers of expanded freedom for all? (2010) Ethics Inf Technol, 12 (3), pp. 277-288; Breazeal, C., (2002) Designing Sociable Robots, , Cambridge: MIT Press; Brown, W.M., Price, M.E., Kang, J., Pound, N., Zhao, Y., Yu, H., Fluctuating asymmetry and preferences for sex-typical bodily characteristics (2008) PNAS, 105 (35), pp. 12938-12943; Capurro, R., Ethics and robotics (2009) Ethics and Robotics, pp. 117-123. , M. Nagenborg and R. Capurro (Eds.), Heidelberg: IOS Press; Carpenter, J., Davis, J.M., Erwin-Stewart, N., Lee, T.R., Bransford, J.D., Vye, N., Gender representation and humanoid robots designed for domestic use (2009) Int J Soc Robot, 1, pp. 261-265; Ceceri, K., My Keepon dances into stores in October! (2011) Wired Magazine, , http://www.wired.com/geekdad/2011/10/my-keepon-dances-into-stores-in-october/, Accessed 9 Oct 2011; Coeckelbergh, M., Humans, animals, and robots: a phenomenological approach to human-robot relations (2011) Int J Soc Rob, 3 (2), pp. 197-204; Crowell, C.R., Scheutz, M., Schemerhorn, P., Villano, M., Gendered voice and robotic entities: Perceptions and reactions of male and female subjects (2009) IEEE/RSJ international conference on intelligent robots and systems, pp. 3735-3741. , (October); De Angeli, A., Brahnam, S., Sex stereotypes and conversational agents (2006) Proceedings of the AVI 2006 workshop on gender and interaction: Real and virtual women in a male world, Venice, Italy, , http://sherylbrahnam.com/papers/EN2033.pdf, Accessed 30 May 2012; Eyssel, F., Kuchenbrandt, D., Bobinger, S., de Ruiter, L., Hegel, F., If You Sound Like Me, you Must Be More Human': on the interplay of robot and user features on human-robot acceptance and anthropomorphism HRI'12 (2012) Proceedings of the 7th annual ACM/IEEE international conference on human-robot interaction pages (March), pp. 125-126; Feil-Seifer, D., Mataric, M.J., Socially assistive robotics: ethical issues related to technology (2011) IEEE Rob Autom, 18 (1), pp. 24-31; Fine, C., (2010) Delusions of Gender: How Our Minds, Society, and Neurosexism Create a Difference, , New York: W W Norton and Company; Fior, M., Nugent, S., Beran, T.N., Ramirez-Serrano, A., Kuzyk, R., Children's relationships with robots: robot is child's new friend (2010) J Phys Agents, 4 (3), pp. 9-17; Goetz, J., Kiesler, S., Powers, A., Matching robot appearance and behavior to tasks to improve human-robot cooperation (2003) Proceedings of the 12th IEEE international workshop on robot and human interactive communication (RO-MAN 2003), pp. 55-60. , Milbrae; Green, V.A., Bigler, R., Catherwood, D., The variability and flexibility of gender-typed toy play: a close look at children's behavioral responses to counterstereotypic models (2004) Sex Roles, 51 (7-8), pp. 371-386; Halpern, D., Katz, J.E., Unveiling robotophobia and cyber-dystopianism: The role of gender, technology and religion on attitudes towards robots HRI'12 (2012) Proceedings of the 7th annual ACM/IEEE international conference on human-robot interaction pages, pp. 139-140. , (March); Hanson, D., Olney, A., Prilliman, S., Mathews, E., Zielke, M., Hammons, D., Fernandez, R., Stephanou, H., Upending the uncanny valley (2005) Proceedings of the 20th National Conference On Artificial Intelligence 4 (AAAI'05). AAAI Press, pp. 1728-1729. , In: Cohn A; Hausman, B.L., (1995) Changing Sex: Transsexualism, Technology, and the Idea of Gender, , Durham: Duke University Press; Ho, C.-C., Macdorman, K.F., Dwi Pramono, Z.A.D., Human emotion and the uncanny valley: A GLM, MDS, and Isomap analysis of robot video ratings (2008) Proceedings of the 3rd ACM/IEEE International Conference On Human Robot Interaction (HRI '08), pp. 169-176. , ACM, New York; (2011) Positive impact of industrial robots on employment, , http://www.ifr.org/uploads/media/Metra_Martech_Study_on_robots_02.pdf, International Federation of Robotics (IFR), Accessed 18 June 2012; (2011) World robotics 2011 (executive summary), , http://www.worldrobotics.org/uploads/media/2011_Executive_Summary.pdf, International Federation of Robotics (IFR), Accessed 31 May 2012; Kaplan, F., Who is afraid of the humanoid? Investigating cultural differences in the acceptance of robots (2004) Int J Humanoid Rob, 1 (3), pp. 1-16; MacDorman, K.F., Ishiguro, H., The uncanny advantage of using androids in social and cognitive science research (2006) Interact Stud, 7 (3), pp. 297-337; MacDorman, K.F., Vasudevan, S.K., Ho, C., Does Japan really have robot mania? Comparing attitudes by implicit and explicit measures (2009) AI & Soc, 23 (4), pp. 485-510; Melson, G.F., Child development robots: social forces, children's perspectives (2010) Interact Stud, 11 (2), pp. 227-232; Mitchell, W.J., Szerszen, K.A., Lu, A.S., Schermerhorn, P.W., Scheutz, M., MacDorman, K.F., A mismatch in the human realism of face and voice produces an uncanny valley (2011) I-Perception, 2 (1), pp. 10-12; Mondada, F., Bonani, M., Raemy, X., Pugh, J., Cianci, C., Klaptocz, A., Magnenat, S., Martinoli, A., The e-puck, a robot designed for education in engineering (2009) Proceedings of the 9th Conference On Autonomous Robot Systems and Competitions, 1 (1), pp. 59-65; Mori, M., The uncanny valley (KF MacDorman and N Kageki, Trans.) (2012) IEEE Robotics and Automation, 19 (2), pp. 98-100. , http://spectrum.ieee.org/automaton/robotics/humanoids/the-uncanny-valley, (Original work published in 1970). doi: 10. 1109/MRA. 2012. 2192811, Accessed 18 June 2012; Nass, C., Yen, C., (2010) The Man Who Lied to His Laptop: What Machines Teach Us about Human Relationships, , New York: Penguin Group; Nishida, T., Towards robots with good will (2009) Ethics and Robotics, pp. 105-116. , R. Capurro and M. Nagenborg (Eds.), Heidelberg: IOS Press; Nomura, T., Tagaki, S., Exploring effects of educational backgrounds and gender in human robot interaction (2011) International conference on user science and engineering (i-USEr), pp. 24-29; Parks, J.A., Lifting the burden of women's care work: Should robots replace the human touch? (2010) Hypatia, 25 (1), pp. 100-120; Prazak, B., Kronreif, G., Hochgatterer, A., Furst, M., A toy robot for physically disabled children (2004) Technol Disabil, 16, pp. 131-136; Reber, R., Schwarz, N., Winkielman, P., Processing fluency and aesthetic pleasure: is beauty in the perceiver's processing experience (2004) Pers Soc Psychol Rev, 8 (4), pp. 364-382; Richey, S., The impact of anti-assimilationist beliefs on attitudes toward immigration (2010) Int Stud Q, 54, pp. 197-212; Robertson, J., Gendering humanoid robots: robo-sexism in Japan (2010) Body Soc, 16 (2), pp. 1-36; Salter, T., Werry, I., Michaud, F., Going into the wild in child-robot interaction studies: issues in social robotic development (2008) Intel Serv Robot, 1 (2), pp. 93-108; Sharkey, N., Sharkey, A., The crying shame of robot nannies: an ethical appraisal (2010) Interact Stud, 11 (2), pp. 161-190; Siegel, M., Breazeal, C., Norton, M.I., Persuasive robotics: The influence of robot gender on human behavior (2009) IEEE/RSJ international conference on intelligent robots and systems, pp. 2563-2568; Tucker, A., Robot babies (2009) Smithsonian Magazine, pp. 56-65. , http://www.smithsonianmag.com/science-nature/Birth-of-a-Robot.html, (July), Accessed 8 Oct 2011; Turkle, S., A nascent robotics culture: New complicities for companionship (2006) AAAI Technical Report Series (July); Wagner, C., 'The Japanese way of robotics': Interacting 'naturally' (2009) With Robots As a National Character? In: The 18th IEEE International Symposium On Robot and Human Interactive Communication (September), Pp 510-515; Walters, M.L., Syrdal, S., Dautenhahn, K., Boekhorst, R., Koay, K.L., Avoiding the uncanny valley: Robot appearance, personality, and consistency of behavior in an attention-seeking home scenario for a robot companion (2008) Auton Robot, 24, pp. 159-178; Whitehouse, D., Japanese develop 'female' android (2005) BBC News, , http://news.bbc.co.uk/2/hi/science/nature/4714135.stm, July 27, Accessed 5 May 2012; Woods, S., Dautenhahn, K., Schulz, J., Exploring the design of space robots: children's perspectives (2006) Interact Comput, 18 (5-6), pp. 1390-1418},
document_type={Article},
source={Scopus},
}

@BOOK{Moor201113,
author={Moor, J.H.},
title={The nature, importance, and difficulty of machine ethics},
journal={Machine Ethics},
year={2011},
volume={9780521112352},
pages={13-20},
doi={10.1017/CBO9780511978036.002},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927048956&doi=10.1017%2fCBO9780511978036.002&partnerID=40&md5=7179565bbe97d55387e524e92a834939},
abstract={Implementations of machine ethics might be possible in situations ranging from maintaining hospital records to overseeing disaster relief. But what is machine ethics, and how good can it be?. The question of whether machine ethics exists or might exist in the future is difficult to answer if we can't agree on what counts as machine ethics. Some might argue that machine ethics obviously exists because humans are machines and humans have ethics. Others could argue that machine ethics obviously doesn't exist because ethics is simply emotional expression and machines can't have emotions. A wide range of positions on machine ethics are possible, and a discussion of the issue could rapidly propel us into deep and unsettled philosophical issues. Perhaps, understandably, few in the scientific arena pursue the issue of machine ethics. You're unlikely to find easily testable hypotheses in the murky waters of philosophy. But we can't – and shouldn't – avoid consideration of machine ethics in today's technological world. As we expand computers' decision-making roles in practical matters, such as computers driving cars, ethical considerations are inevitable. Computer scientists and engineers must examine the possibilities for machine ethics because, knowingly or not, they've already engaged – or will soon engage – in some form of it. Before we can discuss possible implementations of machine ethics, however, we need to be clear about what we're asserting or denying. © Cambridge University Press 2011.},
keywords={Disaster prevention, Computer scientists;  Counts-as;  Disaster relief;  Emotional expressions;  Ethical considerations;  On-machines;  Technological world, Philosophical aspects},
references={Simon, H., Re: Dartmouth seminar 1956 (1999) Carnegie Mellon Univ. Archives, p. 20. , J. Berleur, Herbert A. Simon Col lection, Nov; Lewis, J., Robots of arabia (2005) Wired, 13 (11), pp. 188-195. , www.wired.com/wired/archive/13.11/camel.html?pg=1&topic=camel&topic_set=, Nov; Moor, J.H., Is ethics computable? (1995) Metaphilosophy, 26 (1-2), pp. 1-21; Wallach, W., Allen, C., Smit, I., (2005) “Machine Morality: Bottom-Up and Top-Down Approaches for Modeling Human Moral Faculties,” Machine Ethics, pp. 94-102. , M. Anderson, S.L. Anderson, and C. Armen, eds., AAAI Press; Van Den Hoven, J., Lokhorst, G.J., Deontic logic and computer-supported computer ethics (2002) Cyberphilosophy: The Intersection of Computing and Philosophy, pp. 280-289. , H. Moor and T.W. Bynum, eds., Blackwell; Wiegel, V., Van Den Hoven, J., Lokhorst, G.J., Privacy, deontic epistemic action logic and software agents (2005) Ethics of New Information Technology, Proc. 6Th Int’L Conf. Computer Ethics: Philosophical Enquiry (CEPE 05), pp. 419-434. , Center for Telematics and Information Technology, Univ. of Twente; Anderson, M., Anderson, S.L., Armen, C., Towards machine ethics: Implementing two action-based ethical theories (2005) Machine Ethics, pp. 1-7. , M. Anderson, S.L. Anderson, and C. Armen, eds., AAAI Press; Gips, J., Creating Ethical Robots: A Grand Challenge, , www.cs.bc.edu/∼gips/EthicalRobotsGrandChallenge.pdf, AAAI Fall 2005 Symposium on Machine Ethics; Moor, J.H., Are there decisions computers should never make? (1979) Nature and System, 1 (4), pp. 217-229; Searle, J.R., Minds, brains, and programs (1980) Behavioral and Brain Sciences, 3 (3), pp. 417-457},
document_type={Book Chapter},
source={Scopus},
}

@BOOK{Anderson2011285,
author={Anderson, S.L.},
title={The unacceptability of Asimov’s three laws of robotics as a basis for machine ethics},
journal={Machine Ethics},
year={2011},
volume={9780521112352},
pages={285-296},
doi={10.1017/CBO9780511978036.017},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921023830&doi=10.1017%2fCBO9780511978036.017&partnerID=40&md5=120c41bf0660c848164c003ce7226760},
abstract={Once people understand that machine ethics is concerned with how intelligent machines should behave, they often maintain that Isaac Asimov has already given us an ideal set of rules for such machines. They have in mind Asimov's Three Laws of Robotics: A robot may not injure a human being, or, through inaction, allow a human being to come to harm. A robot must obey the orders given it by human beings except where such orders would conflict with the First Law. A robot must protect its own existence as long as such protection does not conflict with the First or Second Law. (Asimov 1976) I shall argue that in “The Bicentennial Man” (Asimov 1976), Asimov rejected his own Three Laws as a proper basis for Machine Ethics. He believed that a robot with the characteristics possessed by Andrew, the robot hero of the story, should not be required to be a slave to human beings as the Three Laws dictate. He further provided an explanation for why humans feel the need to treat intelligent robots as slaves, an explanation that shows a weakness in human beings that makes it difficult for them to be ethical paragons. Because of this weakness, it seems likely that machines like Andrew could be more ethical than most human beings. © Cambridge University Press 2011.},
keywords={Philosophical aspects;  Robotics;  Robots, First law;  Human being;  Intelligent machine;  Second law;  Set of rules, Intelligent robots},
references={Anderson, S., Being morally responsible for an action versus acting responsibly or irresponsibly (1995) Journal of Philosophical Research, 20, pp. 451-462; Asimov, I., The bicentennial man (1976) Philosophy and Science Fiction (Philips, M, pp. 183-216. , ed.), pp, Prometheus Books, Buffalo, NY; Bentham, J., (1799) An Introduction to the Principles of Morals and Legislation, p. 1969. , chapter 17 (Burns, J. and Hart, H., eds.), Clarendon Press, Oxford; Kant, I., Our duties to animals (1780) Lectures on Ethics, pp. 239-241. , Infield, L., trans.), Harper & Row, New York, NY; Kant, I., (1785) The Groundwork of the Metaphysic of Morals, p. 1948. , (Paton, H. J., trans.), Barnes and Noble, New York; Machan, T., Do animals have rights? (1991) Public Affairs Quarterly, 5 (2), pp. 163-173; Singer, P., All animals are equal (1975) Animal Liberation: A New Ethics for Our Treatment of Animals, pp. 1-22. , Random House, New York; Tooley, M., Abortion and infanticide (1972) Philosophy and Public Affairs, 2, pp. 47-66; Warren, M., On the moral and legal status of abortion (1997) Ethics in Practice, , La Follette, H., ed.), Blackwell, Oxford},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Anderson20071,
author={Anderson, M. and Anderson, S.L.},
title={The status of machine ethics: A report from the AAAI Symposium},
journal={Minds and Machines},
year={2007},
volume={17},
number={1},
pages={1-10},
doi={10.1007/s11023-007-9053-7},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547364379&doi=10.1007%2fs11023-007-9053-7&partnerID=40&md5=796c18388f6c30daeec7d53e36729c2a},
abstract={This paper is a summary and evaluation of work presented at the AAAI 2005 Fall Symposium on Machine Ethics that brought together participants from the fields of Computer Science and Philosophy to the end of clarifying the nature of this newly emerging field and discussing different approaches one could take towards realizing the ultimate goal of creating an ethical machine. © 2007 Springer Science+Business Media.},
author_keywords={Artificial intelligence;  Machine ethics},
keywords={Computer science;  Learning systems, Machine ethics;  Philosophy, Artificial intelligence},
references={Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12, pp. 251-261; Anderson, S. (2005). Asimov's 'Three Laws of Robotics' and machine metaethics. In M. Anderson, S. Anderson, & C. Armen (Eds.), Machine ethics: Papers from the AAAI Fall Symposium, Technical Report FS-05-06. Menlo Park, CA: AAAI Press; Machine ethics: Papers from the AAAI Fall Symposium (2005), Anderson, M, Anderson, S, & Armen, C, Eds, Technical Report FS-05-06. Menlo Park, CA: AAAI Press; Anderson, M., Anderson, S., Armen, C., MedEthEx: A prototype medical ethics advisor (2006) Proceedings of the eighteenth conference on innovative applications of artificial intelligence (IAAI-06), , Boston, MA; Arkoudas, K., Bringsjord, S., & Bello, P. (2005). Toward ethical robots via mechanized deontic logic. In M. Anderson, S. Anderson, & C. Armen (Eds.), Machine ethics: Papers from the AAAI Fall Symposium, Technical Report FS-05-06. Menlo Park, CA: AAAI Press; Asimov, I., The bicentennial man (1976) The bicentennial man and other stories, , Doubleday; Grau, C. (2005). There is no T in 'Robo': Robotic utilitarians and utilitarian robots. In M. Anderson, S. Anderson, & C. Armen (Eds.), Machine ethics: Papers from the AAAI Fall Symposium, Technical Report FS-05-06. Menlo Park, CA: AAAI Press; Guarini, M. (2005). Particularism and generalism: How AI can help us to better understand moral cognition. In M. Anderson, S. Anderson, & C. Armen (Eds.), Machine ethics: Papers from the AAAI Fall Symposium, Technical Report FS-05-06. Menlo Park, CA: AAAI Press; McLaren, B. (2005). Lessons in machine ethics from the perspective of two computational models of ethical reasoning. In M. Anderson, S. Anderson, & C. Armen (Eds.), Machine ethics: Papers from the AAAI Fall Symposium, Technical Report FS-05-06. Menlo Park, CA: AAAI Press; Moor, J.H., The nature, importance, and difficulty of Machine Ethics (2006) IEEE Intelligent Systems Special Issue on Machine Ethics, 21 (4), pp. 18-21; Powers, T. (2005). Deontological machine ethics. In M. Anderson, S. Anderson, & C. Armen (Eds.), Machine ethics: Papers from the AAAI Fall Symposium, Technical Report FS-05-06. Menlo Park, CA: AAAI Press; Rzepka, R., & Araki, K. (2005). What could statistics do for ethics? The idea of a commonsense-processing-based safety valve. In M. Anderson, S. Anderson, & C. Armen (Eds.), Machine thics: Papers from the AAAI Fall Symposium, Technical Report FS-05-06. Menlo Park, CA: AAAI Press; Wallach, W., Allen, C., & Smit, I. (2005). Machine morality: Bottom-up and top-down approaches for modeling human moral faculties. In M. Anderson, S. Anderson. & C. Armen (Eds.), Machine ethics: Papers from the AAAI Fall Symposium, Technical Report FS-05-06. Menlo Park, CA: AAAI Press},
document_type={Article},
source={Scopus},
}

@ARTICLE{Trentesaux201714934,
author={Trentesaux, D. and Rault, R.},
title={Designing Ethical Cyber-Physical Industrial Systems},
journal={IFAC-PapersOnLine},
year={2017},
volume={50},
number={1},
pages={14934-14939},
doi={10.1016/j.ifacol.2017.08.2543},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042135535&doi=10.1016%2fj.ifacol.2017.08.2543&partnerID=40&md5=cadbf3de0b08dc282e4c9dc0a00d955f},
abstract={This paper deals with the risk of non-ethical behaviour of future cyber-physical industrial systems designed by researchers. The will of the authors is to foster researchers working on these innovative systems to pay attention to the possible consequences of their design on the welfare of humans interacting with these systems and their possible responsibility in case of an accident. Mainly focused on robotics, the literature relevant to ethics is shown to be scarce in the field of cyber-physical industrial system while relevant stakes are important. A set of recommendations is suggested and an example dealing with the industrial deployment of a cyber-physical system in transportation illustrates these recommendations. © 2017},
author_keywords={cyber-physical systems;  industrial systems;  machine ethics;  transportation},
keywords={Embedded systems;  Philosophical aspects;  Transportation, Cyber physicals;  Industrial deployment;  Industrial systems;  Innovative systems, Cyber Physical System},
references={Ackerman, E., (2016. Fatal Tesla Self-Driving Car Crash Reminds Us That Robots Aren't Perfect. IEEE Spectr. Technol. Eng. Sci. News; Alsegier, R.A., Roboethics: Sharing Our World with Humanlike Robots (2016) IEEE Potentials, 35, pp. 24-28; Anderson, S.L., Asimov's “Three Laws of Robotics” and Machine Metaethics (2008) AI Soc, 22, pp. 477-493; Bhadauria, S.S., Sharma, V., Litoriya, R., (2010) Empirical analysis of Ethical issues in the era of future information technology, , ICSTE V2-31-V2-35; Bird, S.J., Spier, R., Welcome to science and engineering ethics (1995) Sci. Eng. Ethics, 1, pp. 2-4; Capurro, R., Ethical Challenges of the Information Society in the 21st Century (2000) Int. Inf. Libr. Rev., 32, pp. 257-276; Delvaux, M., (2016. Civil law rules on robotics, European Parliament Legislative initiative procedure 2015/2103; Dreier, T., Sgenannt, D., Legal aspects of service robotics (2012) Poiesis Prax., 9, pp. 201-217; Kumar, N., Kharkwal, N., Kohli, R., Choudhary, S., (2016), pp. 111-114. , Ethical aspects and future of artificial intelligence, in: 2016 International Conference on Innovation and Challenges in Cyber Security; Le Mortellec, A., Clarhaut, J., Sallez, Y., Berger, T., Trentesaux, D., Embedded holonic fault diagnosis of complex transportation systems (2013) Eng. Appl. Artif. Intell., 26, pp. 227-240; Lee, J., Bagheri, B., Kao, H.-A., A Cyber-Physical Systems architecture for Industry 4.0-based manufacturing systems (2015) Manuf. Lett., 3, pp. 18-23; Lin, P., Abney, K., Bekey, G.A., (2012) Roboethics: The Applied Ethics for a New Science, in: Robot Ethics: The Ethical and Social Implications of Robotics, p. 400. , MIT Press; Marvel, J.A., Norcross, R., Implementing speed and separation monitoring in collaborative robot workcells (2017) Robot. Comput.-Integr. Manuf., 44, pp. 144-155; Matsuzaki, H., Lindemann, G., (2015. The autonomy-safety-paradox of service robotics in Europe and Japan: a comparative analysis. AI Soc. 1–17; Mitchell, T., (1997) Machine Learning, , McGraw Hill; Morahan, M., Ethics in management (2015) IEEE Eng. Manag. Rev., 43, pp. 23-25; Nagenborg, M., Capurro, R., Weber, J., Pingel, C., Ethical regulations on robotics in Europe (2007) AI Soc., 22, pp. 349-366; Palmerini, E., Bertolini, A., Battaglia, F., Koops, B.-J., Carnevale, A., Salvini, P., (2016. RoboLaw: Towards a European framework for robotics regulation. Robot. Auton. Syst; Thekkilakattil, A., Dodig-Crnkovic, G., , pp. 39-44. , (2015. Ethics Aspects of Embedded and Cyber-Physical Systems, IEEE COMPSAC; Trentesaux, D., Borangiu, T., Thomas, A., Emerging ICT concepts for smart, safe and sustainable industrial systems (2016) Comput. Ind., 81, pp. 1-10; Trentesaux, D., Millot, P., A human-centered design to break the myth of the « Magic Human » in Intelligent Manufacturing Systems (2016) Studies in Computational Intelligence. Springer, 640, pp. 103-114; van Gorp, A., Ethical issues in engineering design processes; regulative frameworks for safety and sustainability (2007) Des. Stud., 28, pp. 117-131},
document_type={Article},
source={Scopus},
}

@ARTICLE{Malle20173,
author={Malle, B.F. and Scheutz, M. and Austerweil, J.L.},
title={Networks of social and moral norms in human and robot agents},
journal={Intelligent Systems, Control and Automation: Science and Engineering},
year={2017},
volume={84},
pages={3-17},
doi={10.1007/978-3-319-46667-5_1},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010341432&doi=10.1007%2f978-3-319-46667-5_1&partnerID=40&md5=221f15661608c5913ce057fd40a2dc5c},
abstract={The most intriguing and ethically challenging roles of robots in society are those of collaborator and social partner. We propose that such robots must have the capacity to learn, represent, activate, and apply social and moral norms—they must have a norm capacity. We offer a theoretical analysis of two parallel questions: what constitutes this norm capacity in humans and how might we implement it in robots? We propose that the human norm system has four properties: flexible learning despite a general logical format, structured representations, context-sensitive activation, and continuous updating. We explore two possible models that describe how norms are cognitively represented and activated in context-specific ways and draw implications for robotic architectures that would implement either model. © Springer International Publishing AG 2017.},
author_keywords={Cognitive architecture;  Human-robot interaction;  Moral norms;  Norm processing;  Robot ethics;  Social norms},
references={Aarts, H., Dijksterhuis, A., The silence of the library: Environment, situational norm, and social behavior (2003) J Pers Soc Psychol, 84 (1), pp. 18-28; Andrighetto, G., Villatoro, D., Conte, R., Norm internalization in artificial societies (2010) AI Commun, 23 (4), pp. 325-339; Bicchieri, C., (2006) The Grammar of Society: The Nature and Dynamics of Social Norms, , Cambridge University Press, New York; Bower, G.H., Organizational factors in memory (1970) Cogn Psychol, 1 (1), pp. 18-46; Brennan, G., Eriksson, L., Goodin, R.E., Southwood, N., (2013) Explaining Norms, , Oxford University Press, New York; Cialdini, R.B., Kallgren, C.A., Reno, R.R., A focus theory of normative conduct: A theoretical refinement and reevaluation of the role of norms in human behavior (1991) Advances in Experimental Social Psychology, 24, pp. 201-234. , Zanna MP, Academic Press, San Diego, CA; Harvey, M.D., Enzle, M.E., A cognitive model of social norms for understanding the transgression helping effect (1981) J Pers Soc Psychol, 41 (5), pp. 866-875; Hechter, M., Opp, K.D., (2001) Social Norms, , Russell Sage Foundation, New York; Malle, B.F., Integrating robot ethics and machine morality: The study and design of moral competence in robots (2015) Ethics Inf Technol, , [online first]; Malle, B.F., Scheutz, M., Moral competence in social robots (2014) IEEE International Symposium on Ethics in Engineering, Science, and Technology, pp. 30-35. , IEEE, Chicago, IL; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intell Syst, 21 (4), pp. 18-21; Nourbakhsh, I.R., (2013) Robot Futures, , MIT Press, Cambridge; Schank, R.C., Abelson, R.P., (1977) Scripts, Plans, Goals, and Understanding, , Erlbaum, Hillsdale; Sullins, J.P., Introduction: Open questions in roboethics (2011) Philoso Technol, 24 (3), p. 233; Šabanović, S., Robots in society, society in robots (2010) Int J Social Robot, 2 (4), pp. 439-450; Ullmann-Margalit, E., The emergence of norms (1977) Clarendon Library of Logic and Philosophy, , Clarendon Press, Oxford; Van Berkum, J.J.A., Holleman, B., Nieuwland, M., Otten, M., Murre, J., Right or wrong? The brains fast response to morally objectionable statements (2009) Psychol Sci, 20 (9), pp. 1092-1099; Veruggio, G., Solis, J., Van der Loos, M., Roboethics: Ethics applied to robotics (2011) IEEE Robot Autom Mag, 18 (1), pp. 21-22},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Alaieri2016159,
author={Alaieri, F. and Vellino, A.},
title={Ethical decision making in robots: Autonomy, trust and responsibility autonomy trust and responsibility},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={9979 LNAI},
pages={159-168},
doi={10.1007/978-3-319-47437-3_16},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992520904&doi=10.1007%2f978-3-319-47437-3_16&partnerID=40&md5=d390b33a7dcaccddb385513d4670aebb},
abstract={Autonomous robots such as self-driving cars are already able to make decisions that have ethical consequences. As such machines make increasingly complex and important decisions, we will need to know that their decisions are trustworthy and ethically justified. Hence we will need them to be able to explain the reasons for these decisions: ethical decision-making requires that decisions be explainable with reasons. We argue that for people to trust autonomous robots we need to know which ethical principles they are applying and that their application is deterministic and predictable. If a robot is a self-improving, self-learning type of robot whose choices and decisions are based on past experience, which decision it makes in any given situation may not be entirely predictable ahead of time or explainable after the fact. This combination of non-predictability and autonomy may confer a greater degree of responsibility to the machine but it also makes them harder to trust. © Springer International Publishing AG 2016.},
author_keywords={Autonomy;  Responsibility;  Robot ethics;  Trust},
keywords={Behavioral research;  Decision making;  Philosophical aspects;  Robotics, After-the-fact;  Autonomy;  Ethical decision making;  Ethical principles;  Non-predictability;  Responsibility;  Robot ethics;  Trust, Robots},
references={Alaieri, F., Vellino, A., (2016) The Ethical Characteristics of Autonomous Robots, , http://hdl.handle.net/10393/34809, We Robot Poster, April; Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics Inf. Technol, 7 (3), pp. 149-155; Allen, C., Wallach, W., Smit, I., Why machine ethics (2006) IEEE Intell. Syst, 21 (4), pp. 12-17; Anderson, M., Erson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Mag, 28 (4), pp. 15-26; Asaro, P., Robots and responsibility from a legal perspective (2007) IEEE International Conference on Robotics and Automation, Rome, Italy; Asaro, P., What should we want from a robot ethic (2006) Int. Rev. Inform. Ethics, 6, pp. 9-16; Bass, D., (2016) Clippy’s Back: The Future of Microsoft is Chatbots, , http://www.bloomberg.com/features/2016-microsoftfuture-ai-chatbots/, Bloomberg Businessweek, March; Beer, J.M., Fisk, A.D., Toward a framework for levels of robot autonomy in humanrobot interaction (2014) J. Hum.-Robot Interac., 3 (2), pp. 74-99; Colombo, M., Hartmann, S., Bayesian cognitive science, unification, and explanation (2015) Br. J. Philos. Sci, , axv036; Crabb, P.B., Stern, S.E., Technology traps (2012) Ethical Impact of Technological Advancements and Applications in Society, pp. 39-46. , Luppicini, R. (ed.), IGI Global, April; Silver, D., Huang, A., Maddison, C.J., Mastering the game of Go with deep neural networks and tree search (2016) Nature, 529 (7587), pp. 484-489; Dodig-Crnkovic, G., Persson, D., Sharing moral responsibility with robots: A pragmatic approach (2008) Tenth Scandinavian Conference on Artificial Intelligence, SCAI 2008, pp. 165-168; Gert, B., (1998) Morality: Its Nature and Justification, , Oxford University Press, USA; Hellström, T., On the moral responsibility of military robots (2012) Ethics Inf. Technol, 15 (2), pp. 99-107; Hew, P.C., Artificial moral agents are infeasible with foreseeable technologies (2014) Ethics Inform. Technol, 16 (3), pp. 197-206; Jarvik, M., How to understand moral responsibility? TRAMES (2003) J. Humanit. Soc. Sci, 7 (3), pp. 147-163; Johnson, D.G., Computer systems: Moral entities but not moral agents. Ethics Inf (2006) Technol, 8 (4), pp. 195-204; Johnson, D.G., Technology with no human responsibility (2014) J. Bus. Ethics, 127 (4), pp. 707-715; Kuflik, A., Computers in control: Rational transfer of authority or irresponsible abdication of autonomy? (1999) Ethics Inf. Technol, 1 (3), pp. 173-184; Lomas, M., Chevalier, R., Vincent Cross, I.I.E., Garrett, R.C., Hoare, J., Kopack, M., Explaining robot actions (2012) Proceedings of the Seventh Annual ACM/IEEE International Conference on Human-Robot Interaction, pp. 187-188. , ACM; Malle, B.F., Integrating robot ethics and machine morality: The study and design of moral competence in robots (2015) Ethics Inf. Technol, 18 (70), pp. 1-14; Miller, K.W., Moral responsibility for computing artifacts: “The Rules” (2011) IT Prof, 13 (3), pp. 57-59; Moyer, C., (2016) How Google’s Alphago Beat a Go World Champion, , http://www.theatlantic.com/technology/archive/2016/03/the-invisible-opponent/475611/, The Atlantic, March; Noorman, M., Johnson, D.G., Negotiating autonomy and responsibility in military robots (2014) Ethics Inf. Technol, 16 (1), pp. 51-62; Royakkers, L., A literature review on new robotics: Automation from love to war (2015) Int. J. Soc. Robot, 7 (5), pp. 1-22; Scheutz, M., Malle, B.F., Think and do the right thinga plea for morally competent autonomous robots (2014) 2014 IEEE International Symposium on Ethics in Science, Technology and Engineering, pp. 1-4. , IEEE; Stahl, B.C., Responsible computers? A case for ascribing quasi-responsibility to computers independent of personhood or agency (2006) Ethics Inf. Technol, 8 (4), pp. 205-213; Tzafestas, S.G., (2016) Roboethics. a Navigating Overview, 79. , Springer, Heidelberg; Wallach, W., (2015) A Dangerous Master. How to Keep Technology from Slipping beyond Our Control, , Basic Books, New York},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Tonkens2012149,
author={Tonkens, R.},
title={THE CASE AGAINST ROBOTIC WARFARE: A RESPONSE TO ARKIN},
journal={Journal of Military Ethics},
year={2012},
volume={11},
number={2},
pages={149-168},
doi={10.1080/15027570.2012.708265},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866279058&doi=10.1080%2f15027570.2012.708265&partnerID=40&md5=6aa95cd1c49af6f85657e5451f52007d},
abstract={Semi-autonomous robotic weapons are already carving out a role for themselves in modern warfare. Recently, Ronald Arkin has argued that autonomous lethal robotic systems could be more ethical than humans on the battlefield, and that this marks a significant reason in favour of their development and use. Here I offer a critical response to the position advanced by Arkin. Although I am sympathetic to the spirit of the motivation behind Arkin's project and agree that if we decide to develop and use these machines they ought to be programmed to behave ethically, there are several major problems with his view as it stands. At present, it is not clear whether such machines would be capable of behaving more ethically than humans. More importantly, to the extent that humans would remain in the context of war, human moral transgressions will continue, especially in the face of complicated ethical challenges accompanying automated warfare. Moreover, even if machines could be more ethical than humans in certain ways and in certain situations, this says nothing about whether warfare that contains these machines would itself be overall more ethical than warfare that does not include them as participants, or whether the inclusion of lethal robots is the best way to guard against human moral transgressions in war. © 2012 Copyright Taylor and Francis Group, LLC.},
author_keywords={Automated warfare;  autonomous lethal robotic systems;  robot ethics;  Ronald Arkin},
references={Allen, C., Gary, V., Jason, Z., Prolegomena to any Future Artificial Moral Agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12 (3), pp. 251-261; Arkin, R., (2009) Governing Lethal Behavior in Autonomous Robots, , Dordrecht: Chapman & Hall; Arkin, R., Ethical Robots in Warfare (2009) IEEE Technology and Society Magazine, pp. 30-33. , Spring; Arkin, R., The Case for Ethical Autonomy in Unmanned Systems (2010) Journal of Military Ethics, 9 (4), pp. 332-341; Asaro, P., How Just Could a Robot War Be? (2008) Current Issues in Computing and Philosophy, pp. 50-64. , In: Brey P., Briggle A., Waelbers K., editors Amsterdam: IOS Press; Bufacchi, V., Jean, M.A., Torture, Terrorism, and the State: A Refutation of the Ticking-bomb Argument (2006) Journal of Applied Philosophy, 23 (3), pp. 355-373; Hawk, W.J., Pacifism: Reclaiming the moral presumption (2009) Ethics in practice, pp. 735-745. , In: LaFollette H., editors (3rd edition), Oxford: Blackwell; (2010), http://www.dep.forces.gc.ca/dep-ped/index-eng.aspx, Note; Guarini, M., Paul, B., Robotic Warfare: Some Challenges in Moving from Non-civilian to Civilian Theaters (2011) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 129-144. , In: Lin Patrick, Bekey George, Abney Keith, editors Cambridge: MIT Press; Krishnan, A., (2009) Killer Robots, , Dordrecht: Ashgate; Lin, P., Bekey, G., Abney, K., Autonomous Military Robotics: Risk, Ethics, and Design (2008) Funded by US Department of Defense/Office of Naval Research, , http://ethics.calpoly.edu/ONR_report.pdf, accessed, available at:; Internet. Accessed November 11, 2011; McMahan, J., (2009) Killing in War, , Oxford: Oxford University Press; Sharkey, N., Cassandra or False Prophet of Doom: AI Robots and War (2008) IEEE Intelligent Systems, 23 (4), pp. 14-17; Singer, P.W., (2010) Wired for War: The Robotics Revolution and Conflict in the 21 st Century, , New York: Penguin; Slim, H., (2008) Killing Civilians: Method, Madness, and Morality in War, , New York: Columbia University Press; Sparrow, R., Killer Robots (2007) Journal of Applied Philosophy, 24 (1), pp. 62-77; Strawser, B.J., Moral predators: The Duty to Employ Uninhabited Aerial Vehicles (2010) Journal of Military Ethics, 9 (4), pp. 268-342; Sullins, J., RoboWarfare: Can Robots Be More Ethical than Humans on the Battlefield? (2010) Ethics and Information Technology, 12, pp. 263-275; Tonkens, R., A Challenge for Machine Ethics (2009) Minds and Machines, 19 (3), pp. 421-438; Tonkens, R., Out of Character: On the Creation of Virtuous Machines (2011) Ethics and Information Technology, 14 (2), pp. 137-149; Tonkens, R., Should Autonomous Robots be Pacifists? (2012) Ethics and Information Technology, , Online first May 16, 2012; Walzer, M., (2000) Just and Unjust War: A Moral Argument with Historical Illustrations, , 3 rd edition, New York: Basic Books},
document_type={Article},
source={Scopus},
}

@ARTICLE{Guarini2010385,
author={Guarini, M.},
title={Particularism, analogy, and moral cognition},
journal={Minds and Machines},
year={2010},
volume={20},
number={3},
pages={385-422},
doi={10.1007/s11023-010-9200-4},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650731221&doi=10.1007%2fs11023-010-9200-4&partnerID=40&md5=841b6d59dde62e9e738ab78f20c148e6},
abstract={'Particularism' and 'generalism' refer to families of positions in the philosophy of moral reasoning, with the former playing down the importance of principles, rules or standards, and the latter stressing their importance. Part of the debate has taken an empirical turn, and this turn has implications for AI research and the philosophy of cognitive modeling. In this paper, Jonathan Dancy's approach to particularism (arguably one of the best known and most radical approaches) is questioned both on logical and empirical grounds. Doubts are raised over whether Dancy's brand of particularism can adequately explain the graded nature of similarity assessments in analogical arguments. Also, simple recurrent neural network models of moral case classification are presented and discussed. This is done to raise concerns about Dancy's suggestion that neural networks can help us to understand how we could classify situations in a way that is compatible with his particularism. Throughout, the idea of a surveyable standard-one with restricted length and complexity-plays a key role. Analogical arguments are taken to involve multidimensional similarity assessments, and surveyable contributory standards are taken to be attempts to articulate the dimensions of similarity that may exist between cases. This work will be of relevance both to those who have interests in computationally modeling human moral cognition and to those who are interested in how such models may or may not improve our philosophical understanding of such cognition. © 2010 Springer Science+Business Media B.V.},
author_keywords={Analogy;  Jonathan Dancy;  Machine ethics;  Moral cognition;  Neural networks;  Particularism},
keywords={Analogy;  Jonathan Dancy;  Machine ethics;  Moral cognition;  Particularism, Ontology;  Philosophical aspects;  Recurrent neural networks;  Standards, Cognitive systems},
references={Anderson, M., Anderson, S.L., Machine ethics: Creating and ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-26; Anderson, M., Anderson, S.L., Armen, C., An approach to computing ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 56-63; Brewer, S., Exemplary reasoning: Semantics, pragmatics, and the rational force of legal argument by analogy (1996) Harvard Law Review, 99, p. 923; Dancy, J., (1993) Moral Reasons, , Blackwell Oxford; Dancy, J., Can a particularist learn the difference between right and wrong? (1999) Proceedings from the 20th World Congress of Philosophy, Volume I: Ethics, , K. Brinkmann (eds). Philosophy Documentation Center Bowling Green, Ohio; Dancy, J., 'The particularist's progress (2000) Moral Particularism, , B. Hooker M. Little (eds). Oxford University Press Oxford; Dancy, J., (2006) Ethics Without Principles, , Oxford University Press Oxford; Dancy, J., Moral particularism (2009) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/spr2009/entries/moral-particularism/, E. N. Zalta (Ed.) (Spring Ed.); Elman, J., Finding structure in time (1990) Cognitive Science, 14, pp. 179-211. , 10.1207/s15516709cog1402-1; Garfield, J., Particularity and principle: The structure of moral knowledge (2000) Moral Particularism, , B. Hooker M. Little (eds). Oxford University Press Oxford; Horgan, T., Timmons, M., Morphological rationalism and the psychology of moral judgement (2007) Ethical Theory and Moral Practice, 10, pp. 279-295. , 10.1007/s10677-007-9068-4; Horgan, T., Timmons, M., What does the Frame Problem tell us about Normativity? (2009) Ethical Theory and Moral Practice, 12, pp. 25-51; Jackson, F., Petit, P., Smith, M., Ethical particularism and patterns (2000) Moral Particularism, , B. Hooker M. Little (eds). Oxford University Press Oxford; Little, M.O., Moral generalities revisited (2000) Moral Particularism, , B. Hooker M. Little (eds). Oxford University Press Oxford; McKeever, S., Ridge, M., The many moral particularisms (2005) The Canadian Journal of Philosophy, 35, pp. 83-106; McKeever, S., Ridge, M., (2006) Principled Ethics: Generalism As A Regulative Ideal, , Oxford University Press Oxford 10.1093/0199290652.001.0001; McLaren, B.M., Extensionally defining principles and cases in ethics: An AI model (2003) Artificial Intelligence Journal, 150, pp. 145-181. , 1082.68809 10.1016/S0004-3702(03)00135-8; McLaren, B.M., Computational models of ethical reasoning: Challenges, initial steps, and future directions (2006) IEEE Intelligent Systems, 21 (4), pp. 29-37; McNaughton, D., Rawling, P., Unprincipled ethics (2000) Moral Particularism, , B. Hooker M. Little (eds). Oxford University Press Oxford; Sun, R., (2002) Duality of the Mind: A Bottom Up Approach Toward Cognition, , Lawrence Erlbaum Associates Mahway, NJ; Thomson, J.J., A defense of abortion (1971) Philosophy & Public Affairs, 1 (3), pp. 47-66; Wallach, W., Allen, C., (2008) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press Oxford},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Danielson2002162,
author={Danielson, P.},
title={Video surveillance for the rest of us: Proliferation, privacy, and ethics education},
journal={International Symposium on Technology and Society},
year={2002},
pages={162-167},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036048265&partnerID=40&md5=b3e17a60836f5faf0419e5821c827f63},
abstract={The ethics of video surveillance has focused on policy and professional issues. But more individuals will use and encounter remote video surveillance technology as these devices become cheaper and easier to use. We propose an educational approach to the ethics of the emerging practice of non-professional remote video surveillance. Extending the approach to ethics and technology used in our Robot Ethics Lab, we first sketch an abstract model to explain some of the value issues surveillance technology generates. Second, using widely available robotic toys and networking software, we show how working within a technologically and ethically rich environment can move us from a crude remote surveillance prototype towards a more acceptable social contract covering this technology.},
keywords={Broadband networks;  Computer networks;  Computer software;  Remote control;  Robotics;  Software prototyping;  Video conferencing, Robotic toys;  Video surveillance technologies, Closed circuit television systems},
references={(2001) X10 Product Description, , http://X10.com; CCTV FAQ., , Privacy International: London; Bristow, M., Sex scandal grips Taiwan (2001) BBC News; Radwanski, G., (2001) Privacy Commissioner releases finding on video surveillance by RCMP in Kelowna, , Office of the Privacy Commissioner of Canada: Ottawa; Danielson, P., (2001) Ethics for Robots: Open-ended Ethics & Technology, , A paper presented to the Association for Moral Education, Vancouver; Danielson, P., Robots for the rest of us or for the 'best' of us (1999) Ethics and Information Technology, 1, pp. 77-83; Danielson, P., (1991) Artificial Morality, , London: Routledge & Chapman Hall; MacDonald, C., A laser in my pocket (1998) Radar/Ethics & Technology Review, 1 (1); Danielson, P., Competition among cooperators: Altruism and reciprocity Proceedings of the National Academy of Sciences, , in press; Kollock, P., (1998) Transforming Social Dilemmas: Group Identity and Co-operation, in Modeling Rationality Morality, and Evolution, , P. Danielson, Editor. Oxford University Press: New York; Skyrms, B., The stag hunt (2001) Proceedings and Addresses of the American Philosophical Association, pp. xiii; Whitaker, R., (1999) The end of privacy: How total surveillance is becoming a reality, p. 195. , New York: New Press; Reeder, A., (1998) Last Count: To See and Be Seen, in Atlantic, p. 69; Mann, S., (1997) WearCam concept: MaybeCam, , http://www.eyetap.org/wearcam/maybecamera/; (2001) Guide to Closed Circuit Television (CCTV) destruction; Holgate, L., (2002) WebRemote, , http://www.webremote.co.uk/; Silverstein, A., (2001) WebBrick 2.4., , http://amnon.best.vwh.net/Homepage/Lego/; Schave, R.J., (2000) Re: Easy Telerobotics, no programming needed, , LEGO Users Group Network; Green, M.W., (1999) The Appropriate and Effective Use of Security Technologies in U.S. Schools: A Guide for Schools and Law Enforcement Agencies, , National Institute of Justice: Washington, D.C; Turkle, S., (1984) The second self: computers and the human spirit, p. 362. , New York: Simon and Schuster; Rawls, J., (1971) A theory of justice, pp. xv. , Cambridge, Mass.: Belknap Press of Harvard University Press},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{vanWynsberghe2019719,
author={van Wynsberghe, A. and Robbins, S.},
title={Critiquing the Reasons for Making Artificial Moral Agents},
journal={Science and Engineering Ethics},
year={2019},
volume={25},
number={3},
pages={719-735},
doi={10.1007/s11948-018-0030-8},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042189041&doi=10.1007%2fs11948-018-0030-8&partnerID=40&md5=f2cc175e33498f68f690a39f3664bf7c},
abstract={Many industry leaders and academics from the field of machine ethics would have us believe that the inevitability of robots coming to have a larger role in our lives demands that robots be endowed with moral reasoning capabilities. Robots endowed in this way may be referred to as artificial moral agents (AMA). Reasons often given for developing AMAs are: the prevention of harm, the necessity for public trust, the prevention of immoral use, such machines are better moral reasoners than humans, and building these machines would lead to a better understanding of human morality. Although some scholars have challenged the very initiative to develop AMAs, what is currently missing from the debate is a closer examination of the reasons offered by machine ethicists to justify the development of AMAs. This closer examination is especially needed because of the amount of funding currently being allocated to the development of AMAs (from funders like Elon Musk) coupled with the amount of attention researchers and industry leaders receive in the media for their efforts in this direction. The stakes in this debate are high because moral robots would make demands on society; answers to a host of pending questions about what counts as an AMA and whether they are morally responsible for their behavior or not. This paper shifts the burden of proof back to the machine ethicists demanding that they give good reasons to build AMAs. The paper argues that until this is done, the development of commercially available AMAs should not proceed further. © 2018, The Author(s).},
author_keywords={Artificial moral agents;  Machine ethics;  Robot ethics},
keywords={artificial intelligence;  ethicist;  ethics;  morality;  robotics, Artificial Intelligence;  Ethical Analysis;  Ethicists;  Moral Development;  Morals;  Robotics},
references={Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics and Information Technology, 7 (3), pp. 149-155; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental & Theoretical Artificial Intelligence, 12 (3), pp. 251-261; Allen, C., Wallach, W., Moral machines: Contradition in terms of abdication of human responsibility? (2011) Robot ethics: The ethical and social implications of robotics, pp. 55-68. , Lin P, Abney K, Bekey GA, (eds), MIT Press, Cambridge; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) IEEE Intelligent Systems, 21 (4), pp. 12-17; Anderson, S.L., Machine metaethics (2011) Machine Ethics, , M. Anderson, S. L. Anderson, New York, Cambridge University Press; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-26; Anderson, M., Anderson, S.L., Robot be good: A call for ethical autonomous machines (2010) Scientific American, 303 (4), pp. 15-24; Anderson, M., Anderson, S.L., (2011) Machine ethics, , Cambridge University Press, Cambridge; (1998) The Nicomachean ethics, , http://books.google.nl/books?id=Dk2VFlZyiJQC, Oxford University Press. Retrieved from, Accessed 24 Oct 2014; Arkin, R., (2009) Governing lethal behavior in autonomous robots, , CRC Press, Boca Raton; Asimov, I., (1963) I, Robot, , Spectra, New York; Baier, A., Trust and antitrust (1986) Ethics, 96 (2), pp. 231-260; Bryson, J., Robots should be slaves (2008) Close Engagements with Artificial Companions: Key Social, Psychological, Ethical and Design Issue, pp. 63-74. , https://books.google.nl/books?id=EPznZHeG89cC, In Y. Wilks (Ed.), Amsterdam: John Benjamins Publishing. Retrieved from, Accessed 7 Mar 2017; Cellan-Jones, R., Stephen Hawking warns artificial intelligence could end mankind (2014) BBC News, , http://www.bbc.com/news/technology-30290540.Accessed29Aug2016, Retrieved from; Coeckelbergh, M., Robot rights? Towards a social-relational justification of moral consideration (2010) Ethics and Information Technology, 12 (3), pp. 209-221; Darling, K., (2012) Extending Legal Protection to Social Robots: The Effects of Anthropomorphism, Empathy, and Violent Behavior Towards Robotic Objects, , https://papers.ssrn.com/abstract=2044797, Rochester, NY, Retrieved from; Deng, B., Machine ethics: The robot’s dilemma (2015) Nature News, 523 (7558), p. 24; Dietrich, E., Homo sapiens 2.0: Why we should build the better robots of our nature (2001) Journal of Experimental & Theoretical Artificial Intelligence, 13 (4), pp. 323-328; Doris, J.M., Persons, situations, and virtue ethics (1998) Nous, 32 (4), pp. 504-530. , http://www.jstor.org/stable/pdfplus/2671873.pdf?acceptTC=true, (,).,., (,)., Retrieved from; Finlay, S., Four faces of moral realism (2007) Philosophy Compass, 2 (6), pp. 820-849; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds and Machines, 14 (3), pp. 349-379; Friedman, B., Nissenbaum, H., Bias in computer systems (1996) ACM Transactions on Information Systems, 14 (3), pp. 330-347. , https://doi.org/10.1145/230538.230561, Retrieved 10 Feb 2017; Gershgorn, D., (2017) Inside the Mechanical Brain of the world’s First Robot Citizen, , https://qz.com/1121547/how-smart-is-the-first-robot-citizen/, Retrieved 29 Dec 2017; Gips, J., Toward the ethical robot (1994) Android Epistemology, , K. M. Ford, C. Glymour, P. Hayes, Cambridge, MIT Press; Greene, J., (2013) Moral tribes: Emotion, reason, and the gap between us and them, , 1, Penguin Press, New York; Gunkel, D.J., A vindication of the rights of machines (2014) Philosophy & Technology, 27 (1), pp. 113-132; Haidt, J., The emotional dog and its rational tail: A social intuitionist approach to moral judgment (2001) Psychological Review, 108 (4), pp. 814-834; Haidt, J., Joseph, C., The Innate Mind: Volume 3: Foundations and the Future (Evolution and Cognition) (2008) The innate mind, , Carruthers P, Laurence S, Stich S, (eds), Oxford University Press, New York; Hardwig, J., The role of trust in knowledge (1991) The Journal of Philosophy, 88 (12), pp. 693-708; Hatmaker, T., (2017) Saudi Arabia Bestows Citizenship on a Robot Named Sophia, , http://social.techcrunch.com/2017/10/26/saudi-arabia-robot-citizen-sophia/, Retrieved 12 Feb 2018; Himma, K.E., Artificial agency, consciousness, and the criteria for moral agency: What properties must an artificial agent have to be a moral agent? (2009) Ethics and Information Technology, 11 (1), pp. 19-29; Johnson, D.G., Miller, K.W., Un-making artificial moral agents (2008) Ethics and Information Technology, 10 (2-3), pp. 123-133; Kristjánsson, K., Emulation and the use of role models in moral education (2006) Journal of Moral Education, 35 (1), pp. 37-49. , http://www.tandfonline.com/doi/abs/10.1080/03057240500495278, Retrieved from, Accessed 25 Oct 2014; Lokhorst, G.-J., van den Hoven, J., Responsibility for Military Robots (2011) Robot ethics: The ethical and social implications of robotics, pp. 145-155. , Lin P, Abney K, Bekey GA, (eds), MIT Press, Cambridge; Markoff, J., Relax, the terminator is far away (2015) The New York Times, , http://www.nytimes.com/2015/05/26/science/darpa-robotics-challenge-terminator.html, Retrieved from, Accessed 29 Aug 2016; Merritt, M., Virtue ethics and situationist personality psychology (2000) Ethical Theory and Moral Practice, 3 (4), pp. 365-383; Miller, K.W., Wolf, M.J., Grodzinsky, F., This “ethical trap” is for roboticists, not robots: on the issue of artificial agent ethical decision-making (2017) Science and Engineering Ethics, 23 (2), pp. 389-401; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Moor, J., Four kinds of ethical robots (2009) Philosophy Now, (72), pp. 12-14. , https://philosophynow.org/issues/72/Four_Kinds_of_Ethical_Robots, Retrieved from, Accessed 10 Feb 2017; (2012) The Economist, , http://www.economist.com/node/21556234, Retrieved from, Accessed 7 Mar 2017; Nagenborg, M., Artificial moral agents: An intercultural perspective (2007) International Review of Information Ethics, 7, pp. 129-133. , http://www.i-r-i-e.net/inhalt/007/13-nagenborg.pdf, Retrieved 12 Feb 2018; Nissenbaum, H., How computer systems embody values (2001) Computer -Los Almalitos-, 34, p. 120; Peters, A., Having a heart attack? (2018) This AI Helps Emergency Dispatchers Find Out, , https://www.fastcompany.com/40515740/having-a-heart-attack-this-ai-helps-emergency-dispatchers-find-out, Retrieved January 16, 2018, from; Pizarro, D., Nothing More than Feelings? The Role of Emotions in Moral Judgment (2000) Journal for the Theory of Social Behaviour, 30 (4), pp. 355-375; Roeser, S., (2010) Moral emotions and intuitions, , Springer, Berlin; Rutkin, A., (2014) Ethical Trap: Robot Paralysed by Choice of Who to Save, , https://www.newscientist.com/article/mg22329863-700-ethical-trap-robot-paralysed-by-choice-of-who-to-save/, Retrieved 12 Feb 2018; Scheutz, M., (2016) The need for moral competency in autonomous agent architectures, pp. 515-525. , http://link.springer.com/chapter/10.1007/978-3-319-26485-1_30, In V. C. Müller (Ed.), Springer International Publishing. Retrieved from, Accessed 29 Aug 2016; Shafer-Landau, R., Ethical disagreement, ethical objectivism and moral indeterminacy (1994) Philosophy and Phenomenological Research, 54 (2), pp. 331-344; Sharkey, A., Should we welcome robot teachers? (2016) Ethics and Information Technology; Sharkey, A., Can robots be responsible moral agents? And why should we care? (2017) Connection Science, 29 (3), pp. 210-216; Sharkey, N., The ethical frontiers of robotics (2008) Science, 322 (5909), pp. 1800-1801; Sharkey, N., The evitability of autonomous robot warfare (2012) International Review of the Red Cross, 94 (886), pp. 787-799; Sharkey, N., Sharkey, A., The Rights and Wrongs of Robot Care (2011) Robot ethics: The ethical and social implications of robotics, pp. 267-282. , Lin P, Abney K, Bekey GA, (eds), MIT Press, Cambridge; Sharkey, N., Wynsberghe, A., Robbins, S., Hancock, E., (2017) Our Sexual Future with Robots, , https://responsible-roboticsmyxf6pn3xr.netdna-ssl.com/wp-content/uploads/2017/11/FRR-Consultation-Report-Our-Sexual-Future-with-robots-.pdf, The Hague, Netherlands, Retrieved from, Accessed 1 Feb 2018; Shirky, C., (2009) A Speculative Post on the Idea of Algorithmic Authority, , http://www.shirky.com/weblog/2009/11/a-speculative-post-on-the-idea-of-algorithmic-authority/, Retrieved 12 Feb 2018; Simon, J., The entanglement of trust and knowledge on the Web (2010) Ethics and Information Technology, 12 (4), pp. 343-355; Street, S., A darwinian dilemma for realist theories of value (2006) Philosophical Studies, 127 (1), pp. 109-166; Tonkens, R., A challenge for machine ethics (2009) Minds and Machines, 19 (3), pp. 421-438; Vallor, S., Moral deskilling and upskilling in a new machine age: Reflections on the ambiguous future of character (2015) Philosophy & Technology, 28 (1), pp. 107-124; van de Poel, I., Translating Values into design requirements (2013) Philosophy and engineering: Reflections on practice, principles, and process, , Mitchfelder D, McCarty N, Goldberg DE, (eds), Springer, Dordrecht; van den Hoven, J., ICT and value sensitive design (2007) The information society: Innovation, legitimacy, ethics and democracy in honor of professor Jacques Berleur s.j, 233, pp. 67-72. , Goujon P, Lavelle S, Duquenoy P, Kimppa K, (eds), Springer, Boston; van Wynsberghe, A., Designing robots for care: Care centered value-sensitive design (2012) Science and Engineering Ethics, 19 (2), pp. 407-433; van Wynsberghe, A., A method for integrating ethics into the design of robots (2013) Industrial Robot: An International Journal, 40 (5), pp. 433-440; van Wynsberghe, A., (2015) Healthcare Robots: Ethics, Design and Implementation. Healthcare Robots: Ethics, Design and Implementation, , https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946412196&partnerID=40&md5=5c270c5c2c8d9f4983cbe6c4f2369c97, Retrieved from, Accessed 29 Aug 2016; van Wynsberghe, A., Service robots, care ethics, and design (2016) Ethics and Information Technology, 18 (4), pp. 311-321; van Wynsberghe, A., Robbins, S., Ethicist as designer: A pragmatic approach to ethics in the lab (2014) Science and Engineering Ethics, 20 (4), pp. 947-961. , https://doi.org/10.1007/s11948-013-9498-4; Waldrop, M.M., A question of responsibility (1987) AI Magazine, 8 (1), p. 28; Wallach, W., Implementing moral decision making faculties in computers and robots (2007) AI & Society, 22 (4), pp. 463-475; Wallach, W., Robot minds and human ethics: The need for a comprehensive model of moral decision making (2010) Ethics and Information Technology, 12 (3), pp. 243-250; Wallach, W., Allen, C., (2010) Moral Machines: Teaching Robots Right from Wrong, , https://www.amazon.com/Moral-Machines-Teaching-Robots-Right/dp/0199737975, New York, Oxford University Press, Retrieved from, Accessed 10 Feb 2017; Wiegel, V., Building blocks for artificial moral agents (2006) Proceedings of Ethicalalife06 Workshop, , https://www.researchgate.net/profile/Vincent_Wiegel/publication/228615030_Building_blocks_for_artificial_moral_agents/links/55fabe5708aeafc8ac3fe6f8/Buildingblocks-for-artificial-moral-agents.pdf, Retrieved 12 Feb 2018; Wiegel, V., Wendell Wallach and Colin Allen: Moral machines: Teaching robots right from wrong (2010) Ethics and Information Technology, 12 (4), pp. 359-361},
document_type={Article},
source={Scopus},
}

@ARTICLE{SantonideSio20161745,
author={Santoni de Sio, F. and van Wynsberghe, A.},
title={When Should We Use Care Robots? The Nature-of-Activities Approach},
journal={Science and Engineering Ethics},
year={2016},
volume={22},
number={6},
pages={1745-1760},
doi={10.1007/s11948-015-9715-4},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946780565&doi=10.1007%2fs11948-015-9715-4&partnerID=40&md5=1d08c2b0063ca2e24ae32b0e67b21d65},
abstract={When should we use care robots? In this paper we endorse the shift from a simple normative approach to care robots ethics to a complex one: we think that one main task of a care robot ethics is that of analysing the different ways in which different care robots may affect the different values at stake in different care practices. We start filling a gap in the literature by showing how the philosophical analysis of the nature of healthcare activities can contribute to (care) robot ethics. We rely on the nature-of-activities approach recently proposed in the debate on human enhancement, and we apply it to the ethics of care robots. The nature-of-activities approach will help us to understand why certain practice-oriented activities in healthcare should arguably be left to humans, but certain (predominantly) goal-directed activities in healthcare can be fulfilled (sometimes even more ethically) with the assistance of a robot. In relation to the latter, we aim to show that even though all healthcare activities can be considered as practice-oriented, when we understand the activity in terms of different legitimate ‘fine-grained’ descriptions, the same activities or at least certain components of them can be seen as clearly goal-directed. Insofar as it allows us to ethically assess specific functionalities of specific robots to be deployed in well-defined circumstances, we hold the nature-of-activities approach to be particularly helpful also from a design perspective, i.e. to realize the Value Sensitive Design approach. © 2015, The Author(s).},
author_keywords={Care Centered Value Sensitive Design;  Care robot ethics;  Nature-of-activities approach;  Robot ethics;  Value Sensitive Design},
keywords={ethics;  health care delivery;  human;  robotics;  standards;  trends, Delivery of Health Care;  Humans;  Robotics},
references={Anderson, M., Anderson, S., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 1 (28), pp. 15-26; Anscombe, G.E.M., (1957) Intention, , Basil Blackwell, Oxford; Asaro, P., What should we want from a robot ethic? (2006) Ethics and robotics, , Capurro R, Nagenborg M, (eds), IOS Press, Amsterdam; (2011) Robots and privacy. In Robot ethics: The ethical and social implications of robotics, , Calo, R., Cambridge: MIT Press; Coeckelbergh, M., Health care, capabilities, and AI assistive technologies (2010) Ethical Theory Moral Practice, 13, pp. 181-190; Dante, M., Tamburrini, G., Learning robots and human responsibility (2006) International Review of Information Ethics, 6, pp. 46-51; Decker, M., Caregiving robots and ethical reflection: The perspective of interdisciplinary technology assessment (2008) AI & Society, 22 (3), pp. 315-330; Draper, H., Sorell, T., Bedaf, S., Sverre Syrdal, D., Gutierrez-Ruiz, C., Duclos, A., Ethical dimensions of human-robot interactions in the care of older people: Insights from 21 focus groups convened in the UK, France and the Netherlands (2014) Social robotics: Lecture notes in computer science, pp. 135-145. , Beetz M, (ed), 8755; Friedman, B., Human values, ethics, and design (2003) The human-computer interaction handbook, pp. 1177-1201. , L. Erlbaum Associates Inc., Hillsdale; Lin, P., Abney, K., Bekey, G., (2011) Robot ethics: The ethical and social implications of robotics, , MIT Press, Cambridge; Lo, A.C., Guarino, P.D., Richards, L.G., Haselkorn, J.K., Wittenberg, G.F., Federman, D.G., Robot-assisted therapy for long-term upper-limb impairment after stroke (2010) The New England Journal of Medicine, 362 (19), pp. 1772-1783; Manders-Huits, N., What values in design? The challenge of incorporating moral values into design (2011) Science and Engineering Ethics, 17 (2), pp. 271-287; McIntyre, A., (1985) After virtue, , Duckworth, London; (1998) Values in the design of computer systems, Computers in Society, , Nissenbaum, H., March 1998, 38–39; Rawls, J., Two concepts of rules (1955) The Philosophical Review, 64 (1), pp. 3-32; Cognitive enhancement: Ethical and policy implications in international perspectives, , Santoni de Sio, F., Faber, N., Savulescu, J., & Vincent, N. A. (in press). Why less praise for enhanced performance? Moving beyond responsibility-shifting, authenticity, and cheating to a nature-of-activities approach. In F. Jotterand & V. Dubljevic (Eds.), Oxford: Oxford University Press; Santoni de Sio, F., Robichaud, P., Vincent, N.A., Who should enhance? Conceptual and normative dimensions of cognitive enhancement (2014) Humana.Mente Journal of Philosophical Studies, 26, pp. 179-197; Searle, J.R., (1995) The construction of social reality, , Free Press, New York; Sharkey, A., Robots and human dignity: A consideration of the effects of robot care on the dignity of older people (2014) Ethics and Information Technology, 16 (1), pp. 63-75; Sharkey, N., Sharkey, A., The rights and wrongs of robot care (2011) Robot ethics: The ethical and social implications of robotics, pp. 267-282. , Lin P, Abney K, Bekey G, (eds), MIT Press, Cambridge; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics and Information Technology, 14 (1), pp. 27-40; Sorell, T., Draper, H., Robot carers, ethics, and older people (2014) Ethics and Information Technology, 16 (3), pp. 183-195; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Minds and Machines, 16 (2), pp. 141-161; Sullins, J., When is a robot a moral agents? (2006) International Review of Information Ethics, 6 (12), pp. 23-30; Tronto, J., (1993) Moral boundaries: A political argument for an ethic of care, , Routledge, New York; Vallor, S., Carebots and caregivers: Sustaining the ethical ideal of care in the twenty-first century (2011) Philosophy and Technology, 24 (3), pp. 251-268; van den Hoven, J., ICT and value sensitive design (2007) The information society: Innovations, legitimacy, ethics and democracy, pp. 67-72. , Goujon P, Lavelle S, Duquenoy P, Kimppa K, Laurent V, (eds), IFIP International Federation for Information Processing, 233, Springer, Boston; Van Wynsberghe, A., Designing robots for care: Care centered value-sensitive design (2012) Science and Engineering Ethics, 19 (2), pp. 407-433; Van Wynsberghe, A., A method for integrating ethics into the design of robots (2013) Industrial Robot, 40 (5), pp. 433-440; Van Wynsberghe, A., (2015) Robots in healthcare: Design, use and implementation, , Ashgate, Farnham; Veruggio, G., Operto, F., Roboethics: Social and ethical implications of robotics (2008) Springer handbook of robotics, pp. 1499-1524. , Siciliano B, Khatib O, (eds), Springer, Berlin; Wallach, W., Allen, C., (2010) Moral machines: Teaching robots right from wrong, , Oxford University Press, New York},
document_type={Article},
source={Scopus},
}

@ARTICLE{Torrance20149,
author={Torrance, S.},
title={Artificial consciousness and artificial ethics: Between realism and social relationism},
journal={Philosophy and Technology},
year={2014},
volume={27},
number={1},
pages={9-29},
doi={10.1007/s13347-013-0136-5},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899485908&doi=10.1007%2fs13347-013-0136-5&partnerID=40&md5=80afb54e737c0511260e179fbc765c88},
abstract={I compare a 'realist' with a 'social-relational' perspective on our judgments of the moral status of artificial agents (AAs). I develop a realist position according to which the moral status of a being - particularly in relation to moral patiency attribution - is closely bound up with that being's ability to experience states of conscious satisfaction or suffering (CSS). For a realist, both moral status and experiential capacity are objective properties of agents. A social relationist denies the existence of any such objective properties in the case of either moral status or consciousness, suggesting that the determination of such properties rests solely upon social attribution or consensus. A wide variety of social interactions between us and various kinds of artificial agent will no doubt proliferate in future generations, and the social-relational view may well be right that the appearance of CSS features in such artificial beings will make moral role attribution socially prevalent in human-AA relations. But there is still the question of what actual CSS states a given AA is capable of undergoing, independently of the appearances. This is not just a matter of changes in the structure of social existence that seem inevitable as human-AA interaction becomes more prevalent. The social world is itself enabled and constrained by the physical world, and by the biological features of living social participants. Properties analogous to certain key features in biological CSS are what need to be present for nonbiological CSS. Working out the details of such features will be an objective scientific inquiry.},
author_keywords={Artificial (or machine) ethics;  Artificial (ormachine) consciousness;  Artificial agents;  Biomachine spectrum;  Consciousness-satisfaction-suffering (CSS);  Expanding ethical circle;  Machine question;  Moral agents;  Moral patients;  Moral status attribution;  Otherminds problem;  Phenomenal-valuational holism;  Realism;  Social constitutivity;  Social interaction;  Social-relationism},
references={Arkin, R.C., (2009) Governing Lethal Behavior in Autonomous Systems, , Boca Raton: CRC; Bisson, T., (1991) Theyre Made out of Meat, , http://www.eastoftheweb.com/short-stories/UBooks/TheyMade.shtml, Omni, 4. April, 1991 Accessed 10 January 2013; Block, N., Troubles with functionalism (1978) Perception and Cognition: Issues in the Foundations of Psychology. Minnesota Studies in the Philosophy of Science, pp. 261-325. , C. Savage (Ed.) Minneapolis: University of Minnesota Press; Chalmers, D., Facing up to the problem of consciousness (1995) Journal of Consciousness Studies, 2 (3), pp. 200-219; Coeckelbergh, M., Personal robots, appearance, and human good: A methodological reflection on roboethics (2009) International Journal of Social Robotics, 1 (3), pp. 217-221; Coeckelbergh, M., Robot rights? Towards a social-relational justification of moral consideration (2010) Ethics and Information Technology, 12 (3), pp. 209-221; Coeckelbergh, M., (2012) Growing Moral Relations: A Critique of Moral Status Ascription, , Basingstoke: Macmillan; Coeckelbergh, M., The moral standing of machines: Towards a relational and non-Cartesian moral hermeneutics Philos. Technol, 2013. , This issue; Depraz, N., La traduction de leib, une crux phaenomenologica (1997) Etudes Phénoménologiques, p. 3; Depraz, N., Lucidité du corps (2001) De Lempiricisme Transcendental en Phénoménologie, , Dordrecht: Kluwer; Gallagher, S., (2005) How the Body Shapes the Mind, , Oxford: Clarendon; Gallagher, S., Phenomenological contributions to a theory of social cognition (2005) Husserl Studies, 21 (2), pp. 95-110; Gallagher, S., (2012) You i Robot Ai and Society, , doi:10.1007/s00146-012-0420-4; Gallagher, S., Zahavi, D., (2008) The Phenomenological Mind: An Introduction to Philosophy of Mind and Cognitive Science, , London: Taylor & Francis; Gallie, W.B., Essentially contested concepts (1955) Proceedings of the Aristotelian Society, 56, pp. 167-198; Gunkel, D., Thinking otherwise: Philosophy, communication, technology (2007) West Lafayette: Purdue, , University Press; Gunkel, D., (2012) The Machine Question: Critical Perspectives on AI, Robots and Ethics, , Cambridge: MIT Press; Gunkel, D., A vindication of the rights of machines (2013) Philos. Technol, , This issue doi:10.1007/s13347-013-0121-z; Hanna, R., Thompson, E., The mind-body-body problem (2003) Theoria et Historia Scientiarum: International Journal for Interdisciplinary Studies, 7, pp. 24-44; Harris, S., (2010) The Moral Landscape: How Science Can Determine Human Values, , London: Random House; Holland, O., A strongly embodied approach to machine consciousness (2007) Journal of Consciousness Studies, 14 (7), pp. 97-110; Kurzweil, R., (2005) The Singularity Is Near: When Humans Transcend Biology, , Viking; Leopold, A., A land ethic (1948) A Sand County Almanac with Essays on Conservation from Round River, , NY: Oxford University Press; Levine, J., Materialism and qualia: The explanatory gap (1983) Pacific Philosophical Quarterly, 64, pp. 354-361; Levy, D., The ethical treatment of artificially conscious robots (2009) International Journal of Social Robotics, 1 (3), pp. 209-216; Naess, A., The shallow and the deep long-range ecology movements (1973) Inquiry, 16, pp. 95-100; Oregan, J., How to build consciousness into a robot: The sensorimotor approach (2007) 50 Years of Artificial Intelligence, pp. 332-346. , M. Lungarella et al. (Eds.) Heidelberg: Springer; Oregan, J.K., Noë, A., A sensorimotor account of vision and visual consciousness (2001) Behavioral and Brain Sciences, 24 (5), pp. 939-972; Regan, T., (1983) The Case for Animal Rights, , Berkeley: University of California Press; Sharkey, N., Suchman, L., Wishful mnemonics and autonomous killing machines (2013) AISB Quarterly, 136, pp. 14-22; Shear, J., (1997) Explaining Consciousness: The Hard Problem, , Cambridge: MIT Press; Singer, P., (1975) Animal Liberation: A New Ethics for Our Treatment of Animals, , NY: New York Review of Books; Singer, P., (2011) The Expanding Circle: Ethics, Evolution and Moral Progress, , New Jersey: Princeton University Press; Sloman, A., The structure of the space of possible minds (1984) The Mind and the Machine: Philosophical Aspects of Artificial Intelligence, pp. 35-42. , Torrance, S. (ed) Chichester, Sussex: Ellis Horwood; Sparrow, R., Killer robots (2007) Journal of Applied Philosophy, 24 (1), pp. 62-77; Stuart, S., Machine consciousness: Cognitive and kinaesthetic imagination (2007) Journal of Consciousness Studies, 14 (7), pp. 141-153; Thompson, E., (2001) Between Ourselves: Second-person Issues in the Study of Consciousness, 8 (5-7). , Thorverton, UK: Imprint Academic Also published in Journal of Consciousness Studies 2001; Thompson, E., (2007) Mind in Life: Biology, Phenomenology, and the Sciences of Mind, , Cambridge: Harvard University Press; Turing, A., Computing machinery and intelligence (1950) Mind, 59, pp. 433-460; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , NY: Oxford University Press; Wallach, W., Allen, C., Franklin, S., Consciousness and ethics: Artificially conscious moral agents (2011) International Journal of Machine Consciousness, 3 (1), pp. 177-192; Wittgenstein, L., (1953) Philosophical Investigations, , Oxford: Blackwell; Zahavi, D., Beyond empathy. Phenomenological approaches to intersubjectivity (2001) Journal of Consciousness Studies, 8 (5-7), pp. 5-7; Ziemke, T., The embodied self: Theories, hunches and robot models (2007) Journal of Consciousness Studies, 14 (7), pp. 167-179},
document_type={Article},
source={Scopus},
}

@ARTICLE{Ashrafian201429,
author={Ashrafian, H.},
title={AIonAI: A Humanitarian Law of Artificial Intelligence and Robotics},
journal={Science and Engineering Ethics},
year={2014},
volume={21},
number={1},
pages={29-40},
doi={10.1007/s11948-013-9513-9},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891823409&doi=10.1007%2fs11948-013-9513-9&partnerID=40&md5=670f40ed9379a4e143a7eba7e68f884a},
abstract={The enduring progression of artificial intelligence and cybernetics offers an ever-closer possibility of rational and sentient robots. The ethics and morals deriving from this technological prospect have been considered in the philosophy of artificial intelligence, the design of automatons with roboethics and the contemplation of machine ethics through the concept of artificial moral agents. Across these categories, the robotics laws first proposed by Isaac Asimov in the twentieth century remain well-recognised and esteemed due to their specification of preventing human harm, stipulating obedience to humans and incorporating robotic self-protection. However the overwhelming predominance in the study of this field has focussed on human–robot interactions without fully considering the ethical inevitability of future artificial intelligences communicating together and has not addressed the moral nature of robot–robot interactions. A new robotic law is proposed and termed AIonAI or artificial intelligence-on-artificial intelligence. This law tackles the overlooked area where future artificial intelligences will likely interact amongst themselves, potentially leading to exploitation. As such, they would benefit from adopting a universal law of rights to recognise inherent dignity and the inalienable rights of artificial intelligences. Such a consideration can help prevent exploitation and abuse of rational and sentient beings, but would also importantly reflect on our moral code of ethics and the humanity of our civilisation. © 2014, Springer Science+Business Media Dordrecht.},
author_keywords={Artificial intelligence;  Ethics;  Human rights;  Humanitarian;  Philosophy;  Robotics},
keywords={artificial intelligence;  ethics;  human;  human rights;  medical ethics;  morality;  robotics, Artificial Intelligence;  Codes of Ethics;  Human Rights;  Humans;  Morals;  Robotics},
references={A novel modification of the Turing test for artificial intelligence and robotics in healthcare. The International Journal of Medical Robotics and Computer Assisted Surgery, , Ashrafian, H., Darzi, A., & Athanasiou, T. (2014); Ashrafian, H., Ahmed, K., Athanasiou, T., The ethics of animal research (2010) Key topics in surgical research and methodology, , Athanasiou T, Debas H, Darzi A, (eds), Springer, Berlin:; Asimov, I., The evitable conflict (1950) Astounding Science Fiction, 29 (1), pp. 48-68; Asimov, I., The evitable conflict (1950) Astounding Science Fiction, 45 (4), pp. 48-68; Asimov, I., (1985) Robots and empire, , Doubleday, New York:; Bostrom, N., Are you living in a computer simulation? (2003) Philosophical Quarterly, 53 (211), pp. 243-255; Dick, P.K., (1968) Do androids dream of electric sheep?, , Doubleday, New York:; Principles of robotics: Regulating robots in the real world, , http://www.epsrc.ac.uk/research/ourportfolio/themes/engineering/activities/Pages/principlesofrobotics.aspx, EPSRC and AHRC (2010); Translation of the text on the Cyrus Cylinder () © Trustees of the British Museum, , http://www.britishmuseum.org/explore/highlights/articles/c/cyrus_cylinder_-_translation.aspx, Finkel, I. (2012); Kurzweil, R., (2005) The singularity is near: When humans transcend biology, , Viking (Penguin Group), New York:; Russell, W.M.S., Burch, R.L., (1959) The principles of humane experimental technique, , Methuen, London:; The Universal Declaration of Human Rights (UDHR), , http://www.un.org/en/documents/udhr/, United Nations (1948); Euron Roboethics Roadmap, , http://www.roboethics.org/index_file/Roboethics, Veruggio, G. (2007); Wallach, W., Allen, C., (2009) Moral machines: Teaching robots right from wrong, , Oxford University Press (OUP), New York:},
document_type={Article},
source={Scopus},
}

@ARTICLE{Scheutz2013,
author={Scheutz, M.},
title={What is robot ethics?},
journal={IEEE Robotics and Automation Magazine},
year={2013},
volume={20},
number={4},
pages={20+165},
doi={10.1109/MRA.2013.2283184},
art_number={6678596},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890527604&doi=10.1109%2fMRA.2013.2283184&partnerID=40&md5=c937ba011d6034fbbe314d0ed1e288c8},
abstract={Robot ethics is a growing interdisciplinary research effort roughly in the intersection of applied ethics and robotics with the aim of understanding the ethical implications and consequences of robotic technology. This article argues that the best approach to robot ethics addresses researchers, theorists, and scholars from areas as diverse as robotics, computer science, psychology, law, philosophy, and others. Many areas of robotics are impacted, especially those where robots interact with humans, ranging from elder care and medical robotics, to robots for various search and rescue missions, including military robots, to all kinds of service and entertainment robots. While military robots were initially a main focus of the discussion (e.g., whether and when autonomous robots should be allowed to use lethal force or to make those decisions autonomously, etc.), in recent years, the impact of other types of robots, in particular social robots, has become an increasingly important topic as well (see the various articles in [2]). © 1994-2011 IEEE.},
references={Briggs, G., Scheutz, M., Investigating the effects of robotic displays of protest and distress (2012) Proc. Conf. Social Robots, pp. 238-247; Lin, P., Abney, K., Bekey, G., (2011) Robot Ethics-The Ethical and Social Implications of Robotics, , Cambridge, MA: MIT Press; Veruggio, G., Solis, J., Loos Der M.Van, RoboEthics (2011) IEEE Robot. Automat. Mag, 18 (1)},
document_type={Note},
source={Scopus},
}

@BOOK{Anderson2011476,
author={Anderson, S.L. and Anderson, M.},
title={A prima facie duty approach to machine ethics: Machine learning of features of ethical dilemmas, prima facie duties, and decision principles through a dialogue with ethicists},
journal={Machine Ethics},
year={2011},
volume={9780521112352},
pages={476-492},
doi={10.1017/CBO9780511978036.028},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921517884&doi=10.1017%2fCBO9780511978036.028&partnerID=40&md5=22e1080971d7959a441b29163fc426d0},
abstract={In our early work on attempting to develop ethics for a machine, we first established that it is possible to create a program that can compute the ethically correct action when faced with a moral dilemma using a well-known ethical theory (Anderson et al. 2006). The theory we chose, Hedonistic Act Utilitarianism, was ideally suited to the task because its founder, Jeremy Bentham (1781), described it as a theory that involves performing “moral arithmetic.” Unfortunately, few contemporary ethicists are satisfied with this teleological ethical theory that bases the rightness and wrongness of actions entirely on the likely future consequences of those actions. It does not take into account justice considerations, such as rights and what people deserve in light of their past behavior; such considerations are the focus of deontological theories like Kant's Categorical Imperative, which have been accused of ignoring consequences. The ideal ethical theory, we believe, is one that combines elements of both approaches. The prima facie duty approach to ethical theory, advocated by W.D. Ross (1930), maintains that there isn't a single absolute duty to which we must adhere, as is the case with the two aforementioned theories, but rather a number of duties that we should try to follow (some teleological and others deontological), each of which could be overridden on occasion by one of the other duties. © Cambridge University Press 2011.},
keywords={Data privacy;  Network security, Andersons;  Decision principles;  Ethical dilemma;  Ethical theories, Philosophical aspects},
references={Anderson, M., Anderson, S., Armen, C., An approach to computing ethics (2006) IEEE Intelligent Systems, 21 (4); Anderson, M., Anderson, S., Armen, C., Medethex: A prototype medical ethics advisor (2006) Proceedings of the Eighteenth Conference on Innovative Applications of Artificial Intelligence, , Boston, Massachusetts, August; Anderson, M., Anderson, S., Ethel: Toward a principled ethical eldercare robot (2008) Proceedings of the AAAI Fall 2008 Symposium on AI in Eldercare: New Solutions to Old Problems, , Arlington, Virginia, November; Anderson, M., Anderson, S., An ethical robot (2010) Scientific American, , October; (1979) Principles of Biomedical Ethics, , Beauchamp and Childress, Oxford, UK: Oxford University Press; Bentham, J., (1781) An Introduction to the Principles of Morals and Legislation, , Clarendon Press, Oxford; Kant, I., (1785) The Groundwork of the Metaphysic of Morals, , trans. by H. J. Paton (1964). New York: Harper & Row; Mill, J.S., (1863) Utilitarianism, Parker, , Son and Bourn, London; Rawls, J., Outline for a decision procedure for ethics (1951) The Philosophical Review, 60 (2), pp. 177-197; Ross, W.D., (1930) The Right and the Good, , Oxford University Press, Oxford},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Wareham201135,
author={Wareham, C.},
title={On the moral equality of artificial agents},
journal={International Journal of Technoethics},
year={2011},
volume={2},
number={1},
pages={35-42},
doi={10.4018/jte.2011010103},
note={cited By 10},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864572089&doi=10.4018%2fjte.2011010103&partnerID=40&md5=78ba0408ebea1ac6317d3154bb6f8b0c},
abstract={Artificial agents such as robots are performing increasingly significant ethical roles in society. As a result, there is a growing literature regarding their moral status with many suggesting it is justified to regard manufactured entities as having intrinsic moral worth. However, the question of whether artificial agents could have the high degree of moral status that is attributed to human persons has largely been neglected. To address this question, the author developed a respect-based account of the ethical criteria for the moral status of persons. From this account, the paper employs an empirical test that must be passed in order for artificial agents to be considered alongside persons as having the corresponding rights and duties.Copyright © 2011, IGI Global.},
author_keywords={Artificial Agents;  Information Ethics;  Moral Status;  Moral Turing Test;  Personhood;  Rights;  Robot Ethics},
references={Adam, A., Ethics for things (2008) Ethics and Information Technology, 10, pp. 149-154. , doi:10.1007/s10676-008-9169-3; Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics and Information Technology, 7, pp. 149-155. , doi:10.1007/s10676-006-0004-4; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental & Theoretical Artificial Intelligence, 12 (3), pp. 251-261. , doi:10.1080/09528130050111428; Bedau, M., Artificial life: Organization, adaptation and complexity from the bottom up (2003) Trends in Cognitive Sciences, 7 (11), pp. 505-511. , doi:10.1016/j. tics.2003.09.012; Bedau, M., Artificial life (2004) Philosophy of Computing and Information, pp. 97-211. , Floridi, L. (Ed.). Oxford, UK: Blackwell Press; Block, N., Psychologism and behaviorism (1981) The Philosophical Review, 90, pp. 5-43. , doi:10.2307/2184371; Bringsjord, S., On building robot persons: A response to Zlatev (2004) Minds and Machines, 14 (3), pp. 381-385. , doi:10.1023/B:MIND.0000035477.39773.21; Buchanan, A., Moral status and human enhancement (2009) Philosophy & Public Affairs, 37 (4), pp. 346-381. , doi:10.1111/j.1088-4963.2009.01166.x; Coeckelberg, M., Robot rights? Towards a social-relational justification of moral consideration (2010) Ethics and Information Technology, 12, pp. 209-221. , doi:10.1007/s10676-010-9235-5; Dennett, D., When HAL kills, who's to blame? Computer ethics (1997) HAL's Legacy: 2001's Computer As Dream and Reality, , Stork, D. G. (Ed.). Cambridge, MA: MIT Press; Floridi, L., Information ethics: A reappraisal (2008) Ethics and Information Technology, 10, pp. 189-204. , doi:10.1007/s10676-008-9176-4; Hare, R.D., (2003) The Psychopathy Checklist- Revised, , Toronto, Canada: Multi-Health Systems; Himma, K.E., There's something about Mary: The moral value of things qua information objects (2004) Ethics and Information Technology, 6, pp. 145-159. , doi:10.1007/s10676-004-3804-4; Libin, A., Libin, E., Person-robot interactions from the robopsychologists point of view: The robotic psychology and robotherapy approach (2004) Proceedings of the IEEE, 92 (11), pp. 1789-1803. , doi:10.1109/JPROC.2004.835366; Mill, J.S., (1957) Utilitarianism, , Indianapolis, IN: The Liberal Arts Press; Regan, T., (1983) The Case for Animal Rights, , Berkeley, CA: UCLA Press; Scanlon, T., (1998) What We Owe to Each Other, , Cambridge, MA: The Belknap Press of Harvard University Press; Searle, J., Minds, brains and programs (1980) The Behavioral and Brain Sciences, 3, pp. 417-457. , doi:10.1017/S0140525X00005756; Singer, P., (1993) Practical Ethics, , Cambridge, UK: Cambridge University Press; Stahl, B.C., Information ethics and computers: The problem of autonomous moral agents (2004) Minds and Machines, 14, pp. 67-83. , doi:10.1023/B:MIND.0000005136.61217.93; Turing, A., Computing machinery and intelligence (1950) Mind, 59 (236), pp. 433-460. , doi:10.1093/mind/LIX.236.433; Versanyi, L., Can robots be moral? (1974) Ethics, 84 (3), pp. 248-259. , doi:10.1086/291922; Wallace, R.J., (1994) Responsibility and the Moral Sentiments, , Cambridge, MA: Harvard University Press; White, T., (2007) Defense of Dolphins: The New Moral Frontier, , Oxford, UK: Blackwell doi:10.1002/9780470694152},
document_type={Article},
source={Scopus},
}

@ARTICLE{Scheutz201757,
author={Scheutz, M.},
title={The case for explicit ethical agents},
journal={AI Magazine},
year={2017},
volume={38},
number={4},
pages={57-64},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040817456&partnerID=40&md5=97bccea7088db517b979f8d368f90fb9},
abstract={Morality is a fundamentally human trait that permeates all levels of human society, from basic etiquette and normative expectations of social groups, to formalized legal principles upheld by societies. Hence, future interactive AI systems, in particular, cognitive systems on robots deployed in human settings, will have to meet human normative expectations, for otherwise these system risk causing harm. While the interest in machine ethics has increased rapidly in recent years, there are only very few current efforts in the cognitive systems community to investigate moral and ethical reasoning. And there is currently no cognitive architecture that has even rudimentary moral or ethical competence, that is, the ability to judge situations based on moral principles such as norms and values and make morally and ethically sound decisions. We hence argue for the urgent need to instill moral and ethical competence in all cognitive system intended to be employed in human social contexts. © Copyright 2017, Association for the Advancement of Artificial Intelligence. All rights reserved.},
keywords={Philosophical aspects, Cognitive architectures;  Human society;  Human traits;  Legal principles;  Social context;  Social groups;  Sound decision;  System risk, Cognitive systems},
references={Arkin, R., Ulam, P., An ethical adaptor: Behavioral modification derived from moral emotions (2009) Proceedings of the IEEE 2009 International Symposium on Computational Intelligence in Robotics and Automation (CIRA 2009), pp. 381-387. , Piscataway, NJ: Institute for Electrical and Electronics Engineers; Arkin, R., Wagner, A., Duncan, B., Responsibility and lethality for unmanned systems: Ethical pre-mission responsibility advisement (2009) 2009 IEEE Workshop on Roboethics, , Kobe, Japan 17 May; Arkin, R.C., Balch, T., Aura: Principles and Practice in Review (1997) Journal of Experimental and Theoretical Artificial Intelligence, 9 (2), pp. 175-189; Arnold, T., Scheutz, M., Feats without heroes: Norms, means, and ideal robotic action (2016) Frontiers in Robotics and AI, 3 (32); Asimov, I., (1942) Runaround. Astounding Science Fiction, pp. 94-103. , (March):; Bello, P., Bridewell, W., There is no agency without attention (2017) AI Magazine, 38 (4); Blass, J.A., Forbus, K.D., Moral decision-making by analogy: Generalizations versus exemplars (2015) Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, , Austin, TX. Palo Alto, CA: AAAI Press; Briggs, G., Scheutz, M., A hybrid architectural approach to understanding and appropriately generating indirect speech acts (2013) Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence, pp. 1213-1219. , Bellevue, WA. Palo Alto, CA: AAAI Press; Briggs, G., Scheutz, M., "Sorry, i can't do that:" Developing mechanisms to appropriately reject directives in human-robot interactions (2015) Artificial Intelligence for Human-Robot Interaction: Papers from the AAAI 2015 Fall Symposium, pp. 32-36. , ed. B. Hayes and M. Gombolay. Palo Alto, CA: AAAI Press; Dehghani, M., Tomai, E., Iliev, R., Klenk, M., Moraldm: A computational model of moral decision-making (2008) Proceedings of the 30th Annual Conference of the Cognitive Science Society, , Washington, D.C. Austin, TX: Cognitive Science Society Inc; Fasola, J., Mataric, M., A socially assistive robot exercise coach for the elderly (2013) Journal of Human-Robot Interaction, 2 (2), pp. 3-32; Forbus, K.D., Hinrichs, T.R., Analogy and relational representations in the companion cognitive architecture (2017) AI Magazine, 38 (4); Gert, B., (2005) Morality: Its Nature and Justification, , Oxford, UK: Oxford University Press; Gips, J., Toward the ethical robot (1995) Android Epistemology, pp. 243-252. , ed. K. M. Ford, C. Glymour, and P. J. Hayes. Cambridge, MA: AAAI Press /The MIT Press; Iba, W., Langley, P., Exploring moral reasoning in a cognitive architecture (2011) Proceedings of the Thirty-Third Annual Meeting of the Cognitive Science Society, , Boston, MA. Austin, TX: Cognitive Science Society Inc; Laird, J., Lebiere, C., Rosenbloom, P., A standard model of the mind: Toward a common computational framework across artificial intelligence, cognitive science, neuroscience, and robotics (2017) AI Magazine, 38 (4); Licato, J., Sun, R., Bringsjord, S., Structural representation and reasoning in a hybrid cognitive architecture (2014) 2014 International Joint Conference on Neural Networks (IJCNN 2014), pp. 891-898. , Piscataway, NJ: Institute for Electrical and Electronics Engineers; McShane, M., Natural language understanding (nlu, not nlp) in cognitive systems (2017) AI Magazine, 38 (4); Malle, B.F., Scheutz, M., Moral competence in social robots (2014) Proceedings of the IEEE 2014 International Symposium on Ethics in Engineering, Science, and Technology, pp. 30-35. , Piscataway, NJ: Institute for Electrical and Electronics Engineers; Malle, B.F., Scheutz, M., Austerweil, J.L., Networks of social and moral norms in human and robot agents (2015) International Conference on Robot Ethics ICRE 2015, , Lisbon, Portugal; Mikhail, J., Any animal whatever? Harmful battery and its elements as building blocks of moral cognition (2014) Ethics, 124 (4), pp. 750-786; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems., 21 (4), pp. 18-21; Moor, J.H., Four kinds of ethical robots (2009) Philosophy Now, 72; Russell, S., Dewey, D., Tegmark, M., Research priorities for robust and beneficial artificial intelligence (2015) AI Magazine, 36 (4), pp. 61-70; Scassellati, B., Admoni, H., Mataric, M., Robots for use in autism research (2012) Annual Review of Biomedical Engineering, 14, pp. 275-294. , Palo Alto, CA: Annual Reviews, Inc; Scheutz, M., The inherent dangers of unidirectional emotional bonds between humans and social robots (2012) Anthology on Robo-Ethics, , ed. P. Lin, G. Bekey, and K. Abney. Cambridge, MA: The MIT Press; Scheutz, M., The need for moral competency in autonomous agent architectures (2016) Fundamental Issues of Artificial Intelligence, pp. 517-527. , ed. V. C. Müller. Berlin: Springer; Scheutz, M., Schermerhorn, P., Kramer, J., Anderson, D., First steps toward natural human-like hri (2007) Autonomous Robots, 22 (4), pp. 411-423. , May},
document_type={Article},
source={Scopus},
}

@ARTICLE{Cervantes2016278,
author={Cervantes, J.-A. and Rodríguez, L.-F. and López, S. and Ramos, F. and Robles, F.},
title={Autonomous Agents and Ethical Decision-Making},
journal={Cognitive Computation},
year={2016},
volume={8},
number={2},
pages={278-296},
doi={10.1007/s12559-015-9362-8},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944707234&doi=10.1007%2fs12559-015-9362-8&partnerID=40&md5=da1808f209184ed16a08c8c0bef5c4a0},
abstract={Machine ethics, also known as artificial morality, is a newly emerging field concerned with ensuring appropriate behavior of machines toward humans and other machines. In this article, we discuss the importance of machine ethics and present a computational model of ethical decision-making for autonomous agents. The proposed model implements a mechanism for integrating the results of diverse assessments into a unique cue, and takes into account the agent’s preferences, good and bad past experiences, ethical rules, and current emotional state as the main factors involved in choosing the most appropriate option. The design of the model is based on theories and models developed in fields such as neuroscience, psychology, artificial intelligence, and cognitive informatics. In particular, the model attempts to emulate neural mechanisms of the human brain involved in ethical decision-making. © 2015, Springer Science+Business Media New York.},
author_keywords={Artificial moral agent;  Cognitive informatics;  Cognitive process;  Ethical decision-making;  Machine ethics},
keywords={Artificial intelligence;  Computation theory;  Decision making;  Information science;  Philosophical aspects, Cognitive informatics;  Cognitive process;  Computational model;  Emotional state;  Ethical decision making;  Human brain;  Moral agents;  Neural mechanisms, Autonomous agents},
references={Fuster, J., (2008) The prefrontal cortex, , Academic Press, Waltham; Kibele, A., Non-consciously controlled decision making for fast motor reactions in sports: a priming approach for motor responses to non-consciously perceived movement features (2006) Psychol Sport Exerc, 7, pp. 591-610; Bechara, A., Damasio, H., Damasio, A., Emotion, decision making and the orbitofrontal cortex (2000) Cereb Cortex, 10, pp. 295-307. , COI: 1:STN:280:DC%2BD3c7ps1Wqug%3D%3D, PID: 10731224; Wallis, J.D., Orbitofrontal cortex and Its contribution to decision-making (2007) Annu Rev Neurosci, 30, pp. 31-56. , COI: 1:CAS:528:DC%2BD2sXptFKntb0%3D, PID: 17417936; Wallach, W., Allen, C., Smit, I., Machine morality: bottom-up and top-down approaches for modelling human moral faculties (2008) AI Soc, 22, pp. 565-582; Wallach, W., Implementing moral decision making faculties in computers and robots (2008) AI Soc, 22, pp. 463-475; Harman, G., (1977) The nature of morality: an introduction to ethics, , Oxford University Press, Oxford; Wallach, W., Franklin, S., Allen, C., A conceptual and computational model of moral decision making in human and artificial agents (2010) Top Cogn Sci, 2, pp. 454-485. , PID: 25163872; Fong, T., Nourbakhsh, I., Dautenhahn, K., A survey of socially interactive robots (2003) Robot Auton Syst, 42, pp. 143-166; Czubenko, M., Kowalczuk, Z., Ordys, A., Autonomous driver based on an intelligent system of decision-making (2015) Cogn Comput, 7, pp. 569-581; Juha, R., Jukka, H., Vili, K., Antti, T., Matti, P., Minotaurus: a system for affective human-robot interaction in smart environments (2014) Cogn Comput, 6, pp. 940-953; Paul, W., Barbara, L.T., Affective robotics: modelling and testing cultural prototypes (2014) Cogn Comput, 6, pp. 814-840; Bechara, A., The role of emotion in decision-making: evidence from neurological patients with orbitofrontal damage (2004) Brain Cogn, 55, pp. 30-40. , PID: 15134841; Damasio, A.R., Everitt, B.J., Bishop, D., The somatic marker hypothesis and the possible functions of the prefrontal cortex [and discussion] (1996) Philos Trans R Soc Lond B Biol Sci, 351, pp. 1413-1420. , COI: 1:STN:280:DyaK2s%2FpslWkug%3D%3D, PID: 8941953; Loewenstein, G.F., Weber, E.U., Hsee, C.K., Welch, N., Risk as feelings (2001) Psychol Bull, 127, pp. 267-310. , COI: 1:STN:280:DC%2BD3M3kslCisQ%3D%3D, PID: 11316014; Tom, S.M., Fox, C.R., Trepel, C., Poldrack, R.A., The neural basis of loss aversion in decision-making under risk (2007) Science, 315, pp. 515-518. , COI: 1:CAS:528:DC%2BD2sXotFCisQ%3D%3D, PID: 17255512; Tversky, A., Kahneman, D., Rational choice and the framing of decisions (1986) J Bus, 211, pp. 251-278; Gul, F.A., The joint and moderating role of personality and cognitive style on decision making (1984) Account Rev, 59, pp. 264-277; Thatcher, A., De La Cour, A., Small group decision-making in face-to-face and computer-mediated environments: the role of personality (2003) Behav Inf Technol, 22, pp. 203-218; Broeders, R., Van den Bos, K., Müller, P.A., Ham, J., Should I save or should I not kill? How people solve moral dilemmas depends on which rule is most accessible (2011) J Exp Soc Psychol, 47, pp. 923-934; Anderson, M., Anderson, S.L., Machine ethics: creating an ethical intelligent agent (2007) AI Mag, 28, pp. 15-26; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) Intell Syst, 21, pp. 12-17; Wallach, W., Robot minds and human ethics: the need for a comprehensive model of moral decision making (2010) Ethics Inf Technol, 12, pp. 243-250; Hagras, H., Callaghan, V., Colley, M., Clarke, G., Pounds-Cornish, A., Duman, H., Creating an ambient-intelligence environment using embedded agents (2004) Intell Syst IEEE, 19, pp. 12-20; Ostos, R., Cervantes, J.F., Ramos, F.F., Castillo, B., Occello, M., Context-sensitive ecosystem of intelligent environments (2012) Proceedings of the 8th international conference on intelligent environments (IE); 2012 June 26–29, pp. 72-79. , Guanajuato: Mexico. IEEE Computer Society; Laird, J.E., Newell, A., Rosenbloom, P.S., SOAR: an architecture for general intelligence (1987) Artif Intell, 33, pp. 1-64; Laird, J.E., (2012) The Soar cognitive architecture, , The MIT Press, Cambridge; Baars, B.J., Franklin, S., An architectural model of conscious and unconscious brain functions: global workspace theory and IDA (2007) Neural Netw, 20, pp. 955-961. , PID: 17998071; Best, B.J., Lebiere, C., Cognitive agents interacting in real and virtual worlds (2006) Cognition and multi-agent interaction: from cognitive modeling to social simulation, pp. 186-218. , Ron S, (ed), Cambridge University Press, Cambridge; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) J Exp Theor Artif Intell, 12, pp. 251-261; Breazeal, C., Toward sociable robots (2003) Robot Auton Syst, 42, pp. 167-175; Kaplan, F., Talking, A.I.B.O., First experimentation of verbal interactions with an autonomous four-legged robot (2000) Learning to behave: interacting agents CELE-TWENTE Workshop on Language Technology, pp. 57-63; Tsagarakis, N.G., Metta, G., Sandini, G., Vernon, D., Beira, R., Becchi, F., Righetti, L., Carrozza, M.C., iCub: the design and realization of an open humanoid platform for cognitive and neuroscience research (2007) Adv Robot, 21, pp. 1151-1175; Hirai, K., Hirose, M., Haikawa, Y., Takenaka, T., The development of Honda humanoid robot (1998) IEEE international conference on robotics and automation, pp. 1321-1326; Gigerenzer, G., Moral satisficing: rethinking moral behavior as bounded rationality (2010) Top Cogn Sci, 2, pp. 528-554. , PID: 25163875; Honarvar, A.R., Ghasem-Aghaee, N., An artificial neural network approach for creating an ethical artificial agent (2009) Proceedings of the IEEE international symposium on computational intelligence in robotics and automation (CIRA); 2009 December 15–18, pp. 290-295. , Daejeon: Korea. IEEE Computer Society; Dehghani, M., Tomai, E., Forbus, K.D., Klenk, M., An integrated reasoning approach to moral decision-making (2008) Proceedings of the twenty-third AAAI conference on artificial intelligence; 2008 July, 13-17, pp. 1280-1286. , Chicago, USA. AAAI; Coelho H, da Rocha C, António C, Trigo P. Decision making for agent moral conducts. In: Proceedings of the INForum 2010 - Simpósio de Informática; 2010 September 9–10; Braga, Portugal. INForum; 2010. pp. 721732; Franklin, S., Strain, S., McCall, R., Baars, B., Conceptual commitments of the LIDA model of cognition (2013) J Artif Gen Intell, 4, pp. 1-22; Snaider, J., McCall, R., Franklin, S., The LIDA framework as a general tool for AGI (2011) Artifical general intelligence, pp. 133-142. , Schmidhuber J, Thórisson KR, Moshe L, (eds), Springer, Berlin; Honarvar, A.R., Ghasem-Aghaee, N., Casuist BDI-agent: a new extended BDI architecture with the capability of ethical reasoning (2009) Artificial intelligence and computational intelligence, pp. 86-95. , Deng H, Wang L, Wang FL, Lei J, (eds), Springer, Berlin; Borg, J.S., Hynes, C., Van, H.J., Grafton, S., Sinnott-Armstrong, W., Consequences, action, and intention as factors in moral judgments: an fMRI Investigation (2006) J Cogn Neurosci, 18, pp. 803-817; De Martino, B., Kumaran, D., Seymour, B., Dolan, R.J., Frames, biases, and rational decision-making in the human brain (2006) Science, 313, pp. 684-687. , PID: 16888142; Lu, L.C., Rose, G.M., Blodgett, J.G., The effects of cultural dimensions on ethical decision making in marketing: an exploratory study (1999) J Bus Ethics, 18, pp. 91-105; O’Fallon, M.J., Butterfield, K.D., A review of the empirical ethical decision-making literature: 1996–2003 (2005) J Bus Ethics, 59, pp. 375-413; Rolls, E.T., The orbitofrontal cortex and reward (2000) Cereb Cortex, 10, pp. 284-294. , COI: 1:STN:280:DC%2BD3c7ps1WqtQ%3D%3D, PID: 10731223; O’Doherty, J., Kringelbach, M.L., Rolls, E.T., Hornak, J., Andrews, C., (2001) Abstract reward and punishment representations in the human orbitofrontal cortex, 4, pp. 95-102; Opris, I., Bruce, C.J., Neural circuitry of judgment and decision mechanisms (2005) Brain Res Rev, 48, pp. 509-526. , PID: 15914255; Ernst, M., Paulus, M.P., Neurobiology of decision making: a selective review from a neurocognitive and clinical perspective (2005) Biol Psychiatry, 58, pp. 597-604. , PID: 16095567; Gold, J.I., Shadlen, M.N., The neural basis of decision making (2007) Annu Rev Neurosci, 30, pp. 535-574. , COI: 1:CAS:528:DC%2BD2sXptFKnu7w%3D, PID: 17600525; Schultz, W., Tremblay, L., Hollerman, J.R., Reward processing in primate orbitofrontal cortex and basal ganglia (2000) Cereb Cortex, 10, pp. 272-283. , COI: 1:STN:280:DC%2BD3c7ps1WqtA%3D%3D, PID: 10731222; Crescentini, C., Seyed-Allaei, S., Vallesi, A., Shallice, T., Two networks involved in producing and realizing plans (2012) Neuropsychologia, 50, pp. 1521-1535. , PID: 22433287; Hoshi, E., Tanji, J., Area-selective neuronal activity in the dorsolateral prefrontal cortex for information retrieval and action planning (2004) J Neurophysiol, 91, pp. 2707-2722. , PID: 14749313; Markic, O., Rationality and emotions in decision making (2009) Interdiscip Descr Complex Syst, 7, pp. 54-64; Greene, J.D., Nystrom, L.E., Engell, A.D., Darley, J.M., Cohen, J.D., The neural bases of cognitive conflict and control in moral judgment (2004) Neuron, 44, pp. 389-400. , COI: 1:CAS:528:DC%2BD2cXpslOgtrc%3D, PID: 15473975; Miller, E.K., Cohen, J.D., An integrative theory of prefrontal cortex function (2001) Ann Rev Neurosci, 24, pp. 167-202. , COI: 1:CAS:528:DC%2BD3MXls1Shsro%3D, PID: 11283309; Chambers, R.A., Taylor, J.R., Potenza, M.N., Developmental neurocircuitry of motivation in adolescence: a critical period of addiction vulnerability (2003) Am J Psychiatry, 160, pp. 1041-1052. , PID: 12777258; Volkow, N.D., Fowler, J.S., Addiction, a disease of compulsion and drive: involvement of the orbitofrontal cortex (2000) Cerebral cortex, 10, pp. 318-325. , COI: 1:STN:280:DC%2BD3c7ps1ajsg%3D%3D, PID: 10731226; Haber, S.N., Calzavara, R., The cortico-basal ganglia integrative network: the role of the thalamus (2009) Brain Res Bull, 78, pp. 69-74. , PID: 18950692; Kennerley, S.W., Walton, M.E., Behrens, T.E.J., Buckley, M.J., Rushworth, M.F.S., Optimal decision making and the anterior cingulate cortex (2006) Nat Neurosci, 9, pp. 940-947. , COI: 1:CAS:528:DC%2BD28XmtFCmtr8%3D, PID: 16783368; Van Staveren, I., Beyond utilitarianism and deontology: ethics in economics (2007) Rev Polit Econ, 19, pp. 21-35; Gross, C.G., Rodman, H.R., Gochin, P.M., Colombo, M.W., Baum, E.B., Inferior temporal cortex as a pattern recognition device (1992) Computational Learning and Cognition: proceedings of the 3rd NEC research symposium, pp. 44-73. , Philadelphia: Siam; Rodman, H.R., Development of inferior temporal cortex in the monkey (1994) Cereb Cortex, 4, pp. 484-498. , COI: 1:STN:280:DyaK2M7jsFWisg%3D%3D, PID: 7833650; Frey, S., Kostopoulos, P., Petrides, M., Orbitofrontal involvement in the processing of unpleasant auditory information (2000) Eur J Neurosci, 12, pp. 3709-3712. , COI: 1:STN:280:DC%2BD3M%2Fjtlemuw%3D%3D, PID: 11029640; O’Doherty, J.P., Reward representations and reward-related learning in the human brain: insights from neuroimaging (2004) Curr Opin Neurobiol, 14, pp. 769-776. , PID: 15582382; Rogers, R.D., Ramnani, N., Mackay, C., Wilson, J.L., Jezzard, P., Carter, C.S., Smith, S.M., Distinct portions of anterior cingulate cortex and medial prefrontal cortex are activated by reward processing in separable phases of decision-making cognition (2004) Biol Psychiatry, 55, pp. 594-602. , PID: 15013828; Rizzolatti, G., Fadiga, L., Gallese, V., Fogassi, L., Premotor cortex and the recognition of motor actions (1996) Cogn Brain Res, 3, pp. 131-141. , COI: 1:STN:280:DyaK283ot1WrtA%3D%3D; Hoshi, E., Tanji, J., Integration of target and body-part information in the premotor cortex when planning action (2000) Nature, 408, pp. 466-470. , COI: 1:CAS:528:DC%2BD3cXos1Srtrw%3D, PID: 11100727; Ford, R.C., Richardson, W.D., Ethical decision making: a review of the empirical literature (1994) J Bus Ethics, 13, pp. 205-221; Ferrell, O.C., Gresham, L.G., A contingency framework for understanding ethical decision making in marketing (1985) J Market, 49, pp. 87-96; Wang, Y., Liu, D., Ruhe, G., Formal description of the cognitive process of decision making (2004) Proceedings of the third IEEE international conference on cognitive informatics; 2004 August 16–17, pp. 124-130. , British Columbia: Canada. IEEE Computer Society; Yingxu, W., A novel decision grid theory for dynamic decision-making (2005) Proceedings of the fourth IEEE conference on cognitive informatics; 2005 August 8–10, pp. 308-314. , California: USA. IEEE Computer Society; Wang, Y., Inference algebra (IA): a denotational mathematics for cognitive computing and machine reasoning (I) (2011) Int J Cogn Inf Nat Intell, 5, pp. 61-82; Wang, Y., Inference Algebra (IA): a denotational mathematics for cognitive computing and machine reasoning (II) (2012) Int J Cogn Inf Nat Intell, 6, pp. 21-47. , COI: 1:CAS:528:DC%2BC38XhslCqsLrL; Morten, K., The human orbitofrontal cortex: linking reward to hedonic experience (2005) Nat Rev Neurosci, 6, pp. 691-702; Wang, Y., RTPA: a denotational mathematics for manipulating intelligent and computational behaviors (2008) Int J Cogn Inf Nat Intell, 2, pp. 44-62; Forgas, J.P., Mood and judgment: the affect infusion model (AIM) (1995) Psychol Bull, 117, pp. 39-66. , COI: 1:STN:280:DyaK2M7nsFKmsg%3D%3D, PID: 7870863; Hockey, R.J., John, M.A., Clough, P.J., Bdzola, L., Effects of negative mood states on risk in everyday decision making (2000) Cogn Emot, 14, pp. 823-855; Ekman, P., Basic emotions (1999) Handb Cogn Emot, 98, pp. 45-60; Ekman, P., Are there basic emotions? (1992) Psychol Rev, 99, pp. 550-553. , COI: 1:STN:280:DyaK38zms1Kksg%3D%3D, PID: 1344638; Hunt, S.D., Vitell, S., A general theory of marketing ethics (1986) J Macromarket, 6, pp. 5-16; Harsanyi, J.C., A theory of prudential values and a rule utilitarian theory of morality (1995) Soc Choice Welfare, 12, pp. 319-333; Vitell, S.J., Nwachukwu, S.L., Barnes, J.H., The effects of culture on ethical decision-making: an application of Hofstede’s typology (1993) J Bus Ethics, 12, pp. 753-760; Hochschild, A.R., Emotion work, feeling rules, and social structure (1979) Am J Sociol, 85, pp. 551-575; Rodríguez, L.F., Ramos, F., Wang, Y., Cognitive computational models of emotions and affective behaviors (2012) Int J Softw Sci Comput Intell (IJSSCI), 2, pp. 41-63; Wang, Y., On the cognitive processes of human perception with emotions, motivations, and attitudes (2007) J Cogn Inf Nat Intell, 1, pp. 1-13},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gerdes201598,
author={Gerdes, A. and Øhrstrøm, P.},
title={Issues in robot ethics seen through the lens of a moral turing test},
journal={Journal of Information, Communication and Ethics in Society},
year={2015},
volume={13},
number={2},
pages={98-109},
doi={10.1108/JICES-09-2014-0038},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929174278&doi=10.1108%2fJICES-09-2014-0038&partnerID=40&md5=badbb3b25e7c5095c409369c1451cfdc},
abstract={Purpose – The purpose of this paper is to explore artificial moral agency by reflecting upon the possibility of a Moral Turing Test (MTT) and whether its lack of focus on interiority, i.e. its behaviouristic foundation, counts as an obstacle to establishing such a test to judge the performance of an Artificial Moral Agent (AMA). Subsequently, to investigate whether anMTTcould serve as a useful framework for the understanding, designing and engineering of AMAs, we set out to address fundamental challenges within the field of robot ethics regarding the formal representation of moral theories and standards. Here, typically three design approaches to AMAs are available: top-down theory-driven models and bottom-up approaches which set out to model moral behaviour by means ofmodels for adaptive learning, such as neural networks, and finally, hybrid models, which involve components from both top-down and bottom-up approaches to the modelling of moral agency. With inspiration from Allen and Wallace (2009, 2000) as well as Prior (1949, 2003), we elaborate on theoretically driven approaches to machine ethics by introducing deontic tense logic. Finally, withinthis framework, we explore the character of human interaction with a robot which has successfully passed an MTT. Design/methodology/approach – The ideas in this paper reflect preliminary theoretical considerations regarding the possibility of establishing a MTT based on the evaluation of moral behaviour, which focusses on moral reasoning regarding possible actions. The thoughts reflected fall within the field of normative ethics and apply deontic tense logic to discuss the possibilities and limitations of artificial moral agency. Findings – The authors stipulate a formalisation of logic of obligation, time and modality, which may serve as a candidate for implementing a system corresponding to an MTT in a restricted sense. Hence, the authors argue that to establish a present moral obligation, we need to be able to make a description of the actual situation and the relevant general moral rules. Such a description can never be complete, as the combination of exhaustive knowledge about both situations and rules would involve a God eye’s view, enabling one to know all there is to know and take everything relevant into consideration before making a perfect moral decision to act upon. Consequently, due to this frame problem, from an engineering point of view, we can only strive for designing a robot supposed to operate within a restricted domain and within a limited space-time region. Given such a setup, the robot has to be able to perform moral reasoning based on a formal description of the situation and any possible future developments. Although a system of this kind may be useful, it is clearly also limited to a particular context. It seems that it will always be possible to find special cases (outside the context for which it was designed) in which a given system does not pass the MTT. This calls for a new design of moral systems with trust-related components which will make it possible for the system to learn from experience. Originality/value – It is without doubt that in the near future we are going to be faced with advanced social robots with increasing autonomy, and our growing engagement with these robots calls for the exploration of ethical issues and stresses the importance of informing the process of engineering ethical robots. Our contribution can be seen as an early step in this direction. © Emerald Group Publishing Limited.},
author_keywords={Artificial moral agents;  Deontic tense logic;  Moral turing test;  Robot ethics},
references={Allen, C., Garvy, V., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental & Theoretical Artificial Intelligence, 12 (3), pp. 251-261; Anderson, M., Erson, L.S., Armen, C., (2004) "Towards Machine Ethics", , www.aaai.org/Papers/Workshops/2004/WS-04-02/WS04-02-008.pdf, available at; Anderson, M., Anderson, S., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-26; Benford, G., Malartre, E., (2007) Beyond Human-Living with Robots and Cyborgs, , A Forge Book, New York, NY; Dautenhahn, K., Socially intelligent robots: Dimensions of human-robot interaction (2007) Philosophical Transactions: Biological Sciences, 362 (1480), pp. 679-704; Dreyfus, H.L., (1992) What Computers Still Can't Do, , MIT Press, Cambridge, MA; Levy, D., (2008) Love and Sex with Robots, , Duckworth, London; Lin, P., Abney, K., Bekey, G.A., (2012) Robot Ethics-The Ethical and Social Implications of Robotics, , The MIT Press, Cambridge, London; Logstrup, K.E., (1997) The Ethical Demand, , University of Notre Dame Press, Notre Dame; McDermott, D., Why ethics is a high hurdle for AI (2008) North American Conference on Computers and Philosophy (NA-CAP), , www.cs.yale.edu/homes/dvm/papers/ethical-machine.pdf, Bloomington, IN, 30 June, available at; Moor, J., The nature, importance, and dificulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Moor, J., Four kinds of ethical robots (2009) Philosophy Now, 72, pp. 12-14; Ohrstrom, P., Hasle, P., Future contingents (2011) The Stanford Encyclopedia of Philosophy, , Summer, Edition; Ohrstrom, P., Zeller, J., Sandborg-Petersen, U., Prior's defence of Hintikka's theorem. A discussion of prior's 'the logic of obligation and the obligations of the logician' (2012) Synthese, 188 (3), pp. 449-454; Prior, A.N., (1949) Logic and the Basis of Ethics, , Oxford University Press, Oxford; Prior, A.N., (2003) Papers on Time and Tense, , in Hasle, P., Ohrstrom, P., Brauner, T. and Copeland, T. (Eds), Oxford University Press, Oxford; Proyas, A., (2004) 20Th Century Fox, , I Robot; Putnam, H., Robots: Machines or artificially created life? (1964) The Journal of Philosophy, 61 (21); Quinn, W.S., Actions, intentions, and consequences: The doctrine of double effect (1989) Philosophy & Public Affairs, 18 (4); Searle, J.R., Minds, brains and programs (1980) Behavioral and Brain Sciences, Cambridge University Press, Cambridge, 3, pp. 417-424; Searle, J.R., How artificial intelligence fails (1995) The World & I. Currents in Modern Thought-Artificial Intelligence: Oxymoron Or New Frontier, pp. 285-295; Turing, A., Computing machinery and intelligence (1950) Mind, 59, pp. 433-460; Turkle, S., (2011) Alone Together-Why We Expect More from Technology and less from Each Other, Basic Books, , New York, NY; Versenyi, L., Can Robots be Moral? (1974) Ethics, 84 (3), pp. 248-249; Wallach, W., Allan, C., (2009) Moral Machines-Teaching Robots Right from Wrong, , Oxford Scholarship Online; Wilks, Y., (2010) Natural Language Processing 8: Close Engagements with Artificial Companions-Key Social, Psychological, Ethical and Design Issues, , John Benjamins Publishing Company, Amsterdam},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bendel201517,
author={Bendel, O.},
title={Surgical, therapeutic, nursing and sex robots in machine and information ethics},
journal={Intelligent Systems, Control and Automation: Science and Engineering},
year={2015},
volume={74},
pages={17-32},
doi={10.1007/978-3-319-08108-3_2},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921381820&doi=10.1007%2f978-3-319-08108-3_2&partnerID=40&md5=c84bbd20389201538e38050ed87c12da},
abstract={Machine medical ethics is a novel field of research for ethicists, philosophers, artificial intelligence experts, information scientists, and medical specialists. I identify surgical, therapeutic, nursing and sex robots as the primary types of medical machines in this context. I raise general questions about machine ethics with a view to its development and application, specific questions about medical machine ethics (the term and concept which I prefer), and broad questions spanning multiple non-machine ethics, including information, technology, business and legal ethics, and interrelationships between these diverse ethics and machine medical ethics. Samples of each type of question are provided in my descriptions of surgical, therapeutic, nursing and sex robots. In particular, progress in information and technology ethics is needed in order to solve moral problems involving medical machines, and progress in machine ethics to prevent some of the problems. © Springer International Publishing Switzerland 2015},
references={Research, A.B.I., (2011) Healthcare and medical robots, , Allied Business Intelligence, Oyster Bay; (2011), https://www.abiresearch.com/press/medical-robots-market-to-approach-13-billion-in-20, Medical robots market to approach $1.3 Billion in 2016; Anderson, M., Anderson, S.L., (2011) Machine ethics, , Cambridge University Press, Cambridge; Austin, H., (2013) Virtual girl dubbed ‘Sweetie’ snares thousands of would-be sex predators, , http://worldnews.nbcnews.com/_news/2013/11/05/21316335-virtual-girl-dubbed-sweetie-snares-thousands-of-would-be-sex-predators, In: World News, 5 Sept 2013; Becker, H., Scheermesser, M., Früh, M., (2013) Robotik in Betreuung und Gesundheitsversorgung, , TA-SWISS 58/2013. vdf Hochschulverlag, Zürich; Bekey, G.A., Current trends in robotics: Technology and ethics (2012) Robot ethics: The ethical and social implications of robotics, pp. 17-34. , In: Lin P, Abney K, Bekey GA, The MIT Press, Cambridge; Bendel, O., (2012) Die Medizinethik in der Informationsgesellschaft: Überlegungen zur Stellung der Informationsethik, , In: Informatik-Spektrum, November 2012 (“Online-First”- Article on SpringerLink); Bendel, O., (2012) Maschinenethik. Contribution for the Gabler Wirtschaftslexikon, , http://wirtschaftslexikon.gabler.de/Definition/maschinenethik.html, Gabler/ Springer, Wiesbaden; Bendel, O., (2012) Informationsethik. Contribution for the Gabler Wirtschaftslexikon, , http://wirtschaftslexikon.gabler.de/Definition/informationsethik.html, Gabler/ Springer, Wiesbaden; Bendel, O., (2013) Ich bremse auch für Tiere: Überlegungen zu einfachen moralischen Maschinen, , http://www.inside-it.ch/articles/34646, In: inside-it.ch, 4 Dec 2013; Bendel, O., (2013) In: IT for Health, 02/2013, pp. 2-4. , Dr. Robot entdeckt die Moral: Maschinen- und Menschenethik im Gesundheitsbereich; Bendel, O., Towards a machine ethics (2013) In: 1st PACITA project conference technology on assessment and policy areas of great transitions: Book of abstracts, pp. 229-230. , http://pacita.strast.cz/en/conference/documents, 13–15 Mar 2013. Prague; Bendel, O., (2013) Technikethik. Contribution for the Gabler Wirtschaftslexikon, , http://wirtschaftslexikon.gabler.de/Definition/technikethik.html, Gabler/ Springer, Wiesbaden; Bendel, O., (2013) Roboterethik. Contribution for the Gabler Wirtschaftslexikon, , http://wirtschaftslexikon.gabler.de/Definition/roboterethik.html, Gabler/ Springer, Wiesbaden; Bittner, U., Germis, C., (2012) Hospi bringt die Medizin, , http://www.faz.net/aktuell/wirtschaft/unternehmen/pflegeroboter-hospi-bringt-diemedizin-11620830.html, In: FAZ.NET, 28 Jan 2012; Bleisch, B., (2013) Wenn uns der Roboter pflegt. Interview with Susanne Boshammer, , http://www.srf.ch/kultur/roboter-wie-wir/wenn-uns-der-roboter-pflegt, In:, SRF Kultur, 11 Oct 2013; Butter, M., Rensma, A., Van Boxsel, J., Robotics for healthcare (2008) Final Report, , http://www.tno.nl/downloads/TNOKvL_report_RoboticsforHealthcare.pdf, 3 Oct 2008; Datteri, E., Tamburrini, G., Ethical reflections on healthcare robotics (2009) Ethics and robotics, pp. 35-48. , In: Capurro R, Nagenborg M, Akademische Verlagsgesellschaft AKA, Heidelberg; David, L., (2007) Love and sex with robots: The evolution of human-robot relationships, , Harper Perennial, New York; Decker, M., Technology assessment of service robotics (2012) Robo- and information ethics: Some fundamentals, pp. 53-88. , In: Decker M, Gutmann M, LIT Verlag, Münster; Decker, M., (2013) Mein roboter handelt moralischer als ich? Ethische Aspekte einer Technikfolgenabschätzung der Servicerobotik, pp. 215-231. , In: Bogner A (ed) Ethisierung der Technik – Technisierung der Ethik: Der Ethik-Boom im Lichte der Wissenschafts- und Technikforschung. Baden-Baden; Göbel, E., (2010) Unternehmensethik: Grundlagen und praktische Umsetzung, , Lucius & Lucius, Stuttgart; Grimm, M.-O., (2011) Da Vinci OP-Roboter—Marketing Instrument oder medizinischer Fortschritt?, (9), p. 6. , In: Management & Krankenhaus, 9 Sept 2011; Hänßler, B., (2012) Stets zu Liebesdiensten, , http://www.stuttgarter-zeitung.de/inhalt.sexroboter-stets-zu-liebesdiensten.59ec16f3-55c3-4bef-a7ba-d24eccfa8d47.html, In: Stuttgarter-Zeitung.de, 29 Aug 2012; Hartwell, L., (2007), http://www.wired.com/underwire/2007/10/so-who-wants-to/, So who wants to F**k a robot?’ In: Wired.com, 10 June 2007; Hertzberg, J., Lingemann, K., Nüchter, K., (2012) Mobile Roboter: Eine Einführung Aus Sicht der Informatik, , Springer, Berlin and Heidelberg; Höffe, O., (2008) Lexikon der Ethik, , 7th edn. C. H. Beck, München; Kollek, R., (2013) Ethik der Technikfolgenabschätzung in Medizin und Gesundheitswesen: Herausforderungen für Theorie und Praxis, pp. 199-214. , In: Bogner A (ed) Ethisierung der Technik – Technisierung der Ethik: Der Ethik-Boom im Lichte der Wissenschafts- und Technikforschung. Baden-Baden; Kuhlen, R., (2004) Informationsethik: Umgang Mit Wissen Und Informationen in Elektronischen Räumen, , UVK, Konstanz; Lin, P., Abney, K., Bekey, G., (2012) Robot ethics: The ethical and social implications of robotics, , The MIT Press, Cambridge; Moor, J., (2011) The nature, importance, and difficulty of machine ethics, pp. 13-20. , In: Anderson M, Anderson SL (eds) Machine ethics. Cambridge University Press, Cambridge; Pfeifer, R., Körper, Intelligenz, Autonomie (2003) Autonome maschinen, pp. 137-159. , In: Christaller T, Wehner J, Westdeutscher Verlag, Wiesbaden; Pieper, A., (2007) Einführung in Die Ethik, , 6th edn. A. Francke Verlag, Tübingen and Basel; Schöne-Seifert, B., (2007) Grundlagen der Medizinethik, , Kröner, Stuttgart; Wallach, W., Allen, C., (2009) Moral machines: Teaching robots right from wrong, , Oxford University Press, Oxford; Yeoman, I., Mars, M., Robots, men and sex tourism (2012) Futures, 44 (4), pp. 365-371},
document_type={Article},
source={Scopus},
}

@ARTICLE{Powers2013227,
author={Powers, T.M.},
title={On the Moral Agency of Computers},
journal={Topoi},
year={2013},
volume={32},
number={2},
pages={227-236},
doi={10.1007/s11245-012-9149-4},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884518122&doi=10.1007%2fs11245-012-9149-4&partnerID=40&md5=764d008c635e319c1579b4a89621a83b},
abstract={Can computer systems ever be considered moral agents? This paper considers two factors that are explored in the recent philosophical literature. First, there are the important domains in which computers are allowed to act, made possible by their greater functional capacities. Second, there is the claim that these functional capacities appear to embody relevant human abilities, such as autonomy and responsibility. I argue that neither the first (Doman-Function) factor nor the second (Simulacrum) factor gets at the central issue in the case for computer moral agency: whether they can have the kinds of intentional states that cause their decisions and actions. I give an account that builds on traditional action theory and allows us to conceive of computers as genuine moral agents in virtue of their own causally efficacious intentional states. These states can cause harm or benefit to moral patients, but do not depend on computer consciousness or intelligence. © 2013 Springer Science+Business Media Dordrecht.},
author_keywords={Computer ethics;  Machine ethics;  Moral agency},
references={Allen, C., Intentionality: natural and artificial (1995) Comparative Approaches to Cognitive Science, pp. 93-110. , J. A. Meyer and H. L. Roitblat (Eds.), Cambridge: MIT Press; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) J Exp Theor Artif Intell, 12, pp. 251-261; (2009) The Nicomachean ethics, , Aristotle, (trans. WD Ross,). Oxford University Press, Oxford; Bratman, M.E., Planning and the Stability of Intention (1992) Minds Mach, 2 (1), pp. 1-6; Brooks, R.A., (2002) Flesh and Machines: How Robots Will Change Us, , New York: Pantheon Books; Danielson, P., (1992) Artificial Morality: Virtuous Robots for Virtual Games, , New York: Routledge; Davidson, D., Actions, reasons, and causes (1963) J Philos, 60, pp. 685-700. , Reprinted in Davidson (2001) Essays on actions in events. Oxford University Press, Oxford, pp 3-20; Davidsson, P., Johansson, S., On the metaphysics of agents (2005) In: Proceedings of the fourth international joint conference on autonomous agents and multiagent systems, pp. 1299-1300; Dennett, D.C., (1996) The Intentional Stance, , Cambridge: MIT Press; Dretske, F.I., The intentionality of cognitive states (1980) Midwest Studies in Philosophy, 2, pp. 281-294. , P. French (Ed.), Minneapolis: University of Minnesota Press; Floridi, L., Information ethics: its nature and scope (2008) Information technology and moral philosophy, , In: van den Hoven MJ, Weckert J (eds). Cambridge University Press, Cambridge; Floridi, L., Sanders, J.W., Artificial evil and the foundation of computer ethics (2001) Ethics Inf Technol, 3, pp. 55-66; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds Mach, 14, pp. 349-379. , also in Anderson and Anderson (2011); Floridi, L., Savulescu, J., Information ethics: agents, artefacts and new cultural perspectives (2006) Ethics Inf Technol, 8, pp. 155-156; Fodor, J., (2000) The Mind Doesn't Work that Way: The Scope and Limits of Computational Psychology, , Cambridge: MIT Press; Greene, J.D., The cognitive neuroscience of moral judgment (2009) The Cognitive Neurosciences, , 4th edn., M. Gazzaniga (Ed.), Cambridge: MIT Press; Haugeland, J., The intentionality all-stars (1990) Philos Perspect, 4, pp. 383-427. , Reprinted in Haugeland J ed (1998) Having thought. Harvard University Press, Cambridge, pp 127-170; Johnson, D.G., Computer systems: moral entities but not moral agents (2006) Ethics Inf Technol, 8, pp. 195-204. , also in Anderson and Anderson (2011); Johnson, D.G., Miller, K., Un-making artificial moral agents (2008) Ethics Inf Technol, 10, pp. 123-133; Johnson, D.G., Powers, T.M., Computer systems and responsibility: a normative look at technological complexity (2005) Ethics Inf Technol, 7 (2), pp. 99-107. , Kluwer; Johnson, D.G., Powers, T.M., (2005) Ethics and technology: A program for future research, , In: Mitcham C (ed) Encyclopedia of science, technology, and ethics. Macmillan Reference, Detroit; Johnson, D.G., Powers, T.M., Computers as surrogate agents (2008) Information Technology and Moral Philosophy, , M. J. van den Hoven and J. Weckert (Eds.), Cambridge: Cambridge University Press; Kurzweil, R., (2000) The Age of Spiritual Machines, , New York: Viking Penguin; McClintock, A., (1995) The Convergence of Machine and Human Nature, , Hampshire: Ashgate; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intell Syst, , also in Anderson and Anderson (2011); Moravec, H., Rise of the robots (2008) Sci Am, 18, pp. 12-19; Powers, T.M., Incremental machine ethics (2011) IEEE Robot Autom, 18 (1), pp. 51-58; Simon, H.A., (1977) Models of discovery: And other topics in the methods of the sciences, , Springer, New York; Simon, H.A., Machines as mind (1996) Machines and Thought: The Legacy of Alan Turing, 1. , In: Millican P, Clark A (eds). Oxford University Press, Oxford; Searle, J., Minds, brains, and programs (1980) Behav Brain Sci, 3, pp. 417-424; Searle, J., (1983) Intentionality, , Cambridge: Cambridge University Press; Searle, J., (2001) Rationality in Action, , Cambridge: MIT Press; Sullins, J.P., When is a robot a moral agent? (2006) Int Rev Inf Ethics, 6, pp. 23-30. , also in Anderson and Anderson (2011); Symons, J., Explanation, representation, and the dynamical hypothesis (2001) Minds Mach, 11, pp. 521-541; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , New York: Oxford University Press},
document_type={Article},
source={Scopus},
}

@ARTICLE{Yampolskiy2013397,
author={Yampolskiy, R.V.},
title={What to do with the singularity paradox?},
journal={Studies in Applied Philosophy, Epistemology and Rational Ethics},
year={2013},
volume={5},
pages={397-413},
doi={10.1007/978-3-642-31674-6_30},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952790272&doi=10.1007%2f978-3-642-31674-6_30&partnerID=40&md5=0035913163993b47f79f09e435537c53},
abstract={The paper begins with an introduction of the Singularity Paradox, an observation that: “Superintelligent machines are feared to be too dumb to possess commonsense”. Ideas from leading researchers in the fields of philosophy, mathematics, economics, computer science and robotics regarding the ways to address said paradox are reviewed and evaluated. Suggestions are made regarding the best way to handle the Singularity Paradox. © Springer-Verlag Berlin Heidelberg 2013.},
author_keywords={AI-box;  Friendliness;  Machine ethics;  Singularity paradox},
references={(1999), http://en.wikipedia.org/wiki/Hugo_de_Garis, Hugo de Garis, Wikipedia.org; (2008), http://spectrum.ieee.org/computing/hardware/tech-luminaries-address-singularity, Tech Luminaries Address Singularity, IEEE Spectrum. Special Report: The Singularity (June; Armstrong, S., Chaining God: A qualitative approach to AI, trust and moral systems (2007) New European Century, , http://www.neweuropeancentury.org/GodAI.pdf; Asimov, I., (1942) Runaround in Astounding Science Fiction, , March; Bancel, P., Nelson, R., The GCP Event Experiment: Design, Analytical Methods, Results (2008) Journal of Scientific Exploration, 22 (4); Benford, G., Me/Days (1988) Alien Flesh. Victor Gollancz, , London; Berglas, A., (2009), http://berglas.org/Articles/AIKillGrandchildren/AIKillGrandchildren.html, Artificial Intelligence Will Kill Our Grandchildren (February 22; Bishop, M., Why Computers Can’t Feel Pain (2009) Minds and Machines, 19 (4), pp. 507-516; Bostrom, N., Ethical Issues in Advanced Artificial Intelligence (2006) Review of Contemporary Philosophy, 5, pp. 66-73; Bostrom, N., (2008), http://lesswrong.com/lw/qv/the_rhythm_of_disagreement/, Oracle AI; Bostrom, N., Yudkowsky, E., The Ethics of Artificial Intelligence (2011) Cambridge Handbook of Artificial Intelligence, , Ramsey, W., Frankish, K. (eds.), Cambridge University Press; Brin, D., (1987), http://www.davidbrin.com/lungfish1.html, Lungfish; Bugaj, S., Goertzel, B., Five Ethical Imperatives and their Implications for Human- AGI Interaction (2007) Dynamical Psychology, , http://goertzel.org/dynapsyc/2007/Five_Ethical_Imperatives_svbedit.html; Butler, S., (1863) Darwin among the Machines, , To the Editor of Press, Christchurch, New Zealand, June 13; Chalmers, D., The Singularity: A Philosophical Analysis (2010) Journal of Consciousness Studies, 17, pp. 7-65; Dennett, D.C., Why You Can’t Make a Computer That Feels Pain (1978) Synthese, 38 (3), pp. 415-456; Dietrich, E., After the Humans are Gone (2007) Journal of Experimental & Theoretical Artificial Intelligence, 19 (1), pp. 55-67; Drexler, E., (1986) Engines of Creation, , Anchor Press; Fox, J., Shulman, C., Superintelligence Does Not Imply Benevolence (2010) 8Th European Conference on Computing and Philosophy, , Munich, Germany, October 4-6; Freeman, T., (2009) Using Compassion and Respect to Motivate an Artificial Intelligence, , http://www.fungible.com/respect/paper.html; Garis, H.D., (2005) The Artilect War, , ETC publications; Geraci, R.M., Apocalyptic AI: Religion and the Promise of Artificial Intelligence (2008) The Journal of the American Academy of Religion, 76 (1), pp. 138-166; Geraci, R.M., (2007) Religion for the Robots, Sightings, , http://divinity.uchicago.edu/martycenter/publications/~sightings/archive_2007/0614.shtml, Martin Marty Center at the University of Chicago, June 14; Geraci, R.M., Spiritual Robots: Religion and Our Scientific View of the Natural World (2006) Theology and Science, 4 (3), pp. 229-246; Gibson, W., (1984) Neuromancer, , Ace Science Fiction, New York; Goertzel, B., The All-Seeing (A)I (2004) Dynamic Psychology, , http://www.goertzel.org/dynapsyc; Goertzel, B., (2006), http://www.goertzel.org/papers/LimitationsOnFriendliness.pdf, Apparent Limitations on the “AI Friendliness” and Related Concepts Imposed By the Complexity of the World (September; Goertzel, B., Encouraging a Positive Transcension (2004) Dynamical Psychology, , http://www.goertzel.org/dynapsyc/2004/PositiveTranscension.html; Goertzel, B., Thoughts on AI Morality (2002) Dynamical Psychology, , http://www.goertzel.org/dynapsyc; Good, I.J., Speculations Concerning the First Ultraintelligent Machine (1966) Advances in Computers, 6, pp. 31-88; Gordon-Spears, D., Assuring the behavior of adaptive agents (2004) Agent Technology from a Formal Perspective, pp. 227-259. , Rouff, C.A., et al. (eds.), Kluwer; Gordon-Spears, D.F., Asimov’s Laws: Current Progress (2003) FAABS 2002. LNCS (LNAI), 2699, pp. 257-259. , Hinchey, M.G., Rash, J.L., Truszkowski, W.F., Rouff, C.A., Gordon-Spears, D.F. (eds.), Springer, Heidelberg; Gordon, D.F., Well-Behaved Borgs, Bolos, and Berserkers (1998) 15Th International Conference on Machine Learning (ICML 1998), , San Francisco, CA; Hall, J.S., (2000) Ethics for Machines, , http://autogeny.org/ethics.html; Hanson, R., Economics of the Singularity (2008) IEEE Spectrum, 45 (6), pp. 45-50; Hanson, R., (2009), http://www.overcomingbias.com/2009/10/prefer-law-to-values.html, Prefer Law to Values (October 10; Hawking, S., Science in the Next Millennium (1998) The Second Millennium Evening at the White House, , Washington, DC, March 6; Hibbard, B., (2005), http://www.ssec.wisc.edu/~billh/g/SIAI_CV_critique.html, Critique of the SIAI Collective Volition Theory (December; Hibbard, B., (2003), http://www.ssec.wisc.edu/~billh/g/SIAI_critique.html, Critique of the SIAI Guidelines on Friendly AI; Hibbard, B., (2005), http://www.ssec.wisc.edu/~billh/g/SI_ethics_politics.doc, The Ethics and Politics of Super-Intelligent Machines (July; Hibbard, B., Super-Intelligent Machines (2001) Computer Graphics, 35 (1), pp. 11-13; Horvitz, E., Selman, B., (2009), http://aaai.org/Organization/Panel/panel-note.pdf, Interim Report from the AAAI Presidential Panel on Long- Term AI Futures (August; Joy, B., Why the Future Doesn’t Need Us (2000) Wired Magazine, 8 (4). , April; Kaczynski, T., (1995) Industrial Society and Its Future, , The New York Times, September 19 (; Kurzweil, R., (2005) The Singularity is Near: When Humans Transcend Biology, , Viking; Legg, S., (2006), http://commonsenseatheism.com/wp-content/uploads/2011/02/, Friendly AI is Bunk, Vetta Project; McCauley, L., AI Armageddon and the Three Laws of Robotics (2007) Ethics and Information Technology, 9 (2); Nagel, T., What is it Like to be a Bat? (1974) The Philosophical Review, 83 (4), pp. 435-450; Omohundro, S.M., The Basic AI Drives (2008) Proceedings of the First AGI Conference. Frontiers in Artificial Intelligence and Applications, 171. , Wang, P., Goertzel, B., Franklin, S. (eds.), IOS Press (February; Omohundro, S.M., (2007) The Nature of Self-Improving Artificial Intelligence, , Singularity Summit, San Francisco, CA; Pynadath, D.V., Tambe, M., Revisiting Asimov’s First Law: A Response to the Call to Arms (2002) ATAL 2001. LNCS (LNAI), 2333, p. 307. , Meyer, J.-J.C., Tambe, M. (eds.), Springer, Heidelberg; Sawyer, R.J., Robot Ethics (2007) Science, 318, p. 1037; Shulman, C., Jonsson, H., Tarleton, N., Machine Ethics and Superintelligence (2009) 5Th Asia-Pacific Computing & Philosophy Conference, , Tokyo, Japan, October 1-2; Shuman, C., Tarleton, N., Jonsson, H., Which Consequentialism? Machine Ehics and Moral Divergence (2009) Asia-Pacific Conference on Computing and Philosophy (APCAP 2009), , Tokyo, Japan, October 1-2; Solomonoff, R.J., The Time Scale of Artificial Intelligence: Reflections on Social Effects (1985) North-Holland Human Systems Management, 5, pp. 149-153; Sotala, K., Evolved Altruism, Ethical Complexity, Anthropomorphic Trust (2009) 7Th European Conference on Computing and Philosophy (ECAP 2009), , Barcelona, July 2-4; Turing, A., Computing Machinery and Intelligence (1950) Mind, 59 (236), pp. 433-460; Turing, A.M., Intelligent Machinery, A Heretical Theory (1996) Philosophia Mathematica, 4 (3), pp. 256-260; Turney, P., Controlling Super-Intelligent Machines (1991) Canadian Artif. Intell., p. 27; Vinge, V., The Coming Technological Singularity: How to Survive in the Posthuman Era (1993) Vision 21: Interdisciplinary Science and Engineering in the Era of Cyberspace, pp. 11-22. , Cleveland, OH, March 30-31; Warwick, K., Cyborg Morals, Cyborg Values, Cyborg Ethics (2003) Ethics and Information Technology, 5, pp. 131-137; Waser, M., Deriving a Safe Ethical Architecture for Intelligent Machines (2010) 8Th Conference on Computing and Philosophy (ECAP 2010), , October 4-6; Waser, M.R., Designing a Safe Motivational System for Intelligent Machines (2010) The Third Conference on Artificial General Intelligence, , Lugano, Switzerland, March 5-8; Waser, M.R., (2008) Discovering the Foundations of a Universal System of Ethics as a Road to Safe Artificial Intelligence, , AAAI Technical Report FS-08-04, Menlo Park, CA; Weld, D.S., Etzioni, O., The First Law of Robotics (A Call to Arms) (1994) National Conference on Artificial Intelligence, pp. 1042-1047; Yampolskiy, R.V., AI-Complete CAPTCHAs as Zero Knowledge Proofs of Access to an Artificially Intelligent System (2011) ISRN Artificial Intelligence, pp. 271-878; Yampolskiy, R.V., Artificial Intelligence Safety Engineering: Why Machine Ethics is a Wrong Approach (2011) Philosophy and Theory of Artificial Intelligence (PT-AI 2011), , Thessaloniki, Greece, October 3-4; Yampolskiy, R.V., Leakproofing Singularity - Artificial Intelligence Confinement Problem (2012) Journal of Consciousness Studies (JCS), 19 (1-2); Yudkowsky, E., Artificial Intelligence as a Positive and Negative Factor in Global Risk (2008) Global Catastrophic Risks, pp. 308-345. , Bostrom, N., Cirkovic, M.M. (eds.), Oxford University Press, Oxford; Yudkowsky, E., (2005), http://singinst.org/ourresearch/publications/what-is-friendly-ai.html, What is Friendly AI?; Yudkowsky, E.S., (2002), http://yudkowsky.net/singularity/aibox, The AI-Box Experiment; Yudkowsky, E.S., (2004), http://singinst.org/upload/CEV.html, Coherent Extrapolated Volition, Singularity Institute for Artificial Intelligence (May; Yudkowsky, E.S., (2001), http://singinst.org/upload/CFAI.html, Creating Friendly AI - The Analysis and Design of Benevolent Goal Architectures; Yudkowsky, E.S., (2001), http://singinst.org/ourresearch/publications/GISAI/, General Intelligence and Seed AI; Yudkowsky, E.S., Three Major Singularity Schools (2007) Singularity Institute Blog, , http://yudkowsky.net/singularity/schools, (September},
document_type={Book Chapter},
source={Scopus},
}

@BOOK{McD1Ermott201188,
author={McD1Ermott, D.},
title={What matters to a machine?},
journal={Machine Ethics},
year={2011},
volume={9780521112352},
pages={88-114},
doi={10.1017/CBO9780511978036.007},
note={cited By 9},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878444450&doi=10.1017%2fCBO9780511978036.007&partnerID=40&md5=9d02c9084928b3581c2fd75f7c203bc3},
abstract={Why Is Machine Ethics Interesting?. There has recently been a flurry of activity in the area of “machine ethics” [38, 4, 3, 5, 58]. My purpose in this article is to argue that ethical behavior is an extremely difficult area to automate, both because it requires “solving all of AI” and because even that might not be sufficient. Why is machine ethics interesting? Why do people think we ought to study it now? If we're not careful, the reason might come down to the intrinsic fascination of the phrase “machine ethics.” The title of one recent review of the field is Moral Machines. One's first reaction is that moral machines are to be contrasted with … what? Amoral machines? Immoral machines? What would make a machine ethical or unethical? Any cognitive scientist would love to know the answer to these questions. However, it turns out that the field of machine ethics has little to say about them. So far, papers in this area can usefully be classified as focusing on one, maybe two, of the following topics: Altruism: The use of game-theoretic simulations to explore the rationality or evolution of altruism [9, 12]. Constraint: How computers can be used unethically, and how to program them so that it is provable that they do not do something unethical [28, 29], such as violate someone's privacy. Reasoning: The implementation of theories of ethical reasoning [38, 4] for its own sake, or to help build artificial ethical advisors. […] © Cambridge University Press 2011.},
keywords={Behavioral research, Ethical behavior;  Game-theoretic, Philosophical aspects},
references={Adams, I., (2001) The Nobel Peace Prize and the Laureates: An Illustrated Biographical History, , Science History Publications; Ainslie, G., (2001) Breakdown of Will, , Cambridge University Press; Amigoni, F., Schiaffonati, V., Machine ethics and human ethics: A critical view (2005) Proceedings of the AAAI 2005 Fall Symposium on Machine Ethics, pp. 103-104. , AAAI Press; Anderson, M., Anderson, S.L., Special issue on machine ethics (2006) IEEE Intelligent Systems, 21 (4); Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-58; Arkin, R.C., (2007) Governing Lethal Behavior: Embedding Ethics in a Hybrid Deliberative/Reactive Robot Architecture, , Technical report, GIT-GVU-07–11, Georgia Institute of Technology Mobile Robot Laboratory; Armour, P.G., Sarbanes-oxley and software projects (2005) Comm. ACM, 48 (6), pp. 15-17; Asimov, I., (1950) I, Robot, , Gnome Press; Axelrod, R., Hamilton, W.D., The evolution of cooperation (1981) Science, 211 (4489), pp. 1390-1396; Block, N., Troubles with functionalism (1978) Perception and Cognition: Issues in the Foundation of Psychology, Minn. Studies in the Phil. of Sci, pp. 261-325. , C. Wade Savage, Somewhat revised edition in Ned Block (ed.) Readings in the Philosophy ofPsychology. Harvard University Press, Cambridge, Mass., vol. 1, pages 268–306, 1980; Martin, A., Conway. Sensory-perceptual episodic memory and its context: Autobiographical memory (2001) Phil. Trans. Royal Society, 356, pp. 1375-1384; Danielson, P., Competition among cooperators: Altruism and reciprocity (2002) Proc. Nat’l. Acad. Sci, 99, pp. 7237-7242; Dennett, D.C., Consciousness explained (1991) Little, Brown and Company, , Boston; Fetzer, J.H., (1990) Artificial Intelligence: Its Scope and Limits, , Kluwer Academic Publishers, Dordrecht; Fetzer, J.H., (2002) Computers and Cognition: Why Minds are Not Machines, , Kluwer Academic Publishers, Dordrecht; Floridi, L., (2004) The Blackwell Guide to the Philosophy of Computing and Information, , Blackwell Publishing, Malden, Mass; Fodor, J., (1975) The Language of Thought. Thomas Y, , Crowell, New York; Frankfurt, H.G., Freedom of the will and the concept of a person (1971) J. of Phil, 68, pp. 5-20; Frey, R., Morris, C., (1993) Value, Welfare, and Morality, , Cambridge University Press; Gentner, D., Holyoak, K.J., Kokinov, B.K., (2001) The Analogical Mind: Perspectives from Cognitive Science, , The MIT Press, Cambridge, Mass; Ghallab, M., Nau, D., Traverso, P., (2004) Automated Planning: Theory and Practice, , Morgan Kaufmann Publishers, San Francisco; Hare, R.M., (1981) Moral Thinking: Its Levels, Method, and Point, , Oxford University Press, USA; Harman, G., (2000) Desired Desires, pp. 138-157. , Frey and Morris [19], Also in Gilbert Harman, Explaining Value: and Other Essays in Moral Philosophy. Oxford: Clarendon Press, pp. 117–136; Hofstadter, D.R., (1995) Fluid Concepts and Creative Analogies: Computer Models of the Fundamental Mechanisms of Thought, , By Douglas Hofstadter and the Fluid Analogies Research Group. Basic Books, New York; Hooker, B., Rule consequentialism (2008) Stanford Encyclopedia of Philosophy; Hsu, J., Real soldiers love their robot brethren (2009) Live Science, , May 21, 2009; Michael, A., Jenike. Obsessive-compulsive disorder (2004) New England J. of Medicine, 350 (3), pp. 259-265; Johnson, D., (2001) Computer Ethics, , Prentice Hall, Upper Saddle River; Johnson, D., Computer Ethics, pp. 65-75. , Floridi [16]; Kant, I., (1964) Groundwork of the Metaphysic of Morals, , New York, Harper & Row; Lakoff, G., Johnson, M., (1980) Metaphors We Live By, , Chicago, University Press; Lasky, K.B., Lehner, P.E., Metareasoning and the problem of small worlds (1994) IEEE Trans. Sys., Man, and Cybernetics, 24 (11), pp. 1643-1652; Levin, J., Functionalism (2009) Stanford Encyclopedia of Philosophy, , Online resource; Lewis, D., An argument for the identity theory (1966) J. of Phil, 63, pp. 17-25; McDermott, D., (2001) Mind and Mechanism, , MIT Press, Cambridge, Mass; Mill, J.S., (1861) Utilitarianism, , Oxford University Press, New York, Reprinted many times, including edition edited by Roger Crisp (1998); Minsky, M., (1986) The Society of Mind, , Simon and Schuster, New York; James, H., Moor. The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Sys, 21 (4), pp. 18-21; Nagel, T., (1986) The View from Nowhere, , Oxford University Press; Némirovsky, I., (2004) Suite Française, , Éditions Denoël, Paris, English translation by Sandra Smith published by Vintage, 2007; Newell, A., (1962) Some Problems of Basic Organization in Problem-Solving Programs, , Technical Report 3283-PR, RAND, Santa Monica: The RAND Corporation. Earlier version appeared in [61]; (2007) United Arab Emirates (UAE), , lcweb2.loc.gov/frd/cs/profiles/UAE.pdf; Parfit, D., (1984) Reasons and Persons, , Oxford University Press; Plato, (2000) The Republic, , Cambridge University Press, Cambridge, 360 BCE. Translation by Tom Griffith and G.R.F Ferrari. Cambridge University Press, Cambridge; Putnam, H., Degree of confirmation” and inductive logic (1963) The Philosophy of Rudolf Carnap. the Open Court Publishing Company, pp. 271-292, 1975. , A. Schilpp, editor, Lasalle, Ill, Also in Hilary Putnam, Mathematics, Matter and Method: Philosophical Papers, Vol. 1. Cambridge University Press: Cambridge; Rey, G., (1997) Contemporary Philosophy of Mind: A Contentiously Classical Approach, , Blackwell Publishers, Cambridge, Mass; Rosenblueth, A., Wiener, N., Bigelow, J., Behavior, purpose and teleology (1943) Philosophy of Science, pp. 18-24; David Ross, W., (1930) The Right and the Good, , Oxford University Press; Russell, S., Norvig, P., (2003) Artificial Intelligence: A Modern Approach, , Prentice Hall; Savage, L.J., (1954) Foundations of Statistics, , Wiley, New York; Searle, J.R., Is the brain’s mind a computer program (1990) Scientific American, 262, pp. 26-31; Searle, J.R., (1992) The Rediscovery of the Mind, , MIT Press, Cambridge, Mass; Silberschatz, A., Gagne, G., Galvin, P.B., (2008) Operating System Concepts, , John Wiley & Sons, Incorporated, New York; Singer, P., (1993) Practical Ethics, , Cambridge University Press; Swinson, R.P., Antony, M.M., Rachman, S., Richter, M.A., (2001) Obsessive-Compulsive Disorder: Theory, Research, and Treatment, , Guilford Press, New York; Tulving, E., (1983) Elements of Episodic Memory, , Clarendon Press, Oxford; Tulving, E., What is episodic memory? Current directions in psych (1993) Sci, 2 (3), pp. 67-70; Wallach, W., Allen, C., (2008) Moral Machines, , Oxford University Press; Wegner, D.M., (2002) The Illusion of Conscious Will, , MIT Press, Cambridge, Mass; Wiener, N., (1948) Cybernetics: Or Control and Communication in the Animal and the Machine, , Technology Press, New York; Yovits, M.C., Jacobi, G.T., Goldstein, G.D., (1962) Self-Organizing Systems 1962, , Spartan Books; Ziff, P., The feelings of robots (1959) Analysis, 19 (3), pp. 64-68},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Tzafestas2018,
author={Tzafestas, S.G.},
title={Roboethics: Fundamental concepts and future prospects},
journal={Information (Switzerland)},
year={2018},
volume={9},
number={6},
doi={10.3390/INFO9060148},
art_number={148},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059656988&doi=10.3390%2fINFO9060148&partnerID=40&md5=0f5f6014577578e1b37314aaa183b01a},
abstract={Many recent studies (e.g., IFR: International Federation of Robotics, 2016) predict that the number of robots (industrial, service/social, intelligent/autonomous) will increase enormously in the future. Robots are directly involved in human life. Industrial robots, household robots, medical robots, assistive robots, sociable/entertainment robots, and war robots all play important roles in human life and raise crucial ethical problems for our society. The purpose of this paper is to provide an overview of the fundamental concepts of robot ethics (roboethics) and some future prospects of robots and roboethics, as an introduction to the present Special Issue of the journal Information on "Roboethics". We start with the question of what roboethics is, as well as a discussion of the methodologies of roboethics, including a brief look at the branches and theories of ethics in general. Then, we outline the major branches of roboethics, namely: medical roboethics, assistive roboethics, sociorobot ethics, war roboethics, autonomous car ethics, and cyborg ethics. Finally, we present the prospects for the future of robotics and roboethics. © 2018 by the authors.},
author_keywords={Assistive roboethics;  Cyborg ethics;  Ethical liability;  Ethics;  Medical roboethics;  Roboethics;  Robot morality;  Sociorobot ethics;  Sociotechnical system;  Technoethics;  War roboethics},
keywords={Cyborgs;  Industrial robots;  Medical problems;  Philosophical aspects;  Robotics, Ethics;  Roboethics;  Sociorobot ethics;  Sociotechnical systems;  Technoethics, Intelligent robots},
references={Sabanovic, S., Robots in society, society in robots (2010) Int. J. Soc. Robots, 24, pp. 439-450; Veruggio, G., The birth of roboethics (2005) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA 2005): Workshop on Robot Ethics, pp. 1-4. , Barcelona, Spain, 18 April; Lin, P., Abney, K., Bekey, G.A., (2011) Robot Ethics: The Ethical and Social Implications of Robotics, , MIT Press: Cambridge, MA, USA; Capurro, R., Nagenborg, M., (2009) Ethics and Robotics, , IOS Press: Amsterdam, The Netherlands; Tzafestas, S.G., (2015) Roboethics: A Navigating Overview, , Springer: Berlin, Germany; Dordrecht, The Netherlands; Dekoulis, G., (2017) Robotics: Legal, Ethical, and Socioeconomic Impacts, , InTech: Rijeka, Croatia; Jha, U.C., (2016) Killer Robots: Lethal Autonomous Weapon Systems Legal, Ethical, and Moral Challenges, , Vij Books India Pvt: New Delhi, India; Gunkel, D.J.K., (2012) The Machine Question: Critical Perspectives on AI, Robots, and Ethics, , MIT Press: Cambridge, MA, USA; Dekker, M., Guttman, M., (2012) Robo-and-Information Ethics: Some Fundamentals, , LIT Verlag: Muenster, Germany; Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge University Press: Cambridge, UK; Veruggio, G., Solis, J., Van der Loos, M., Roboethics: Ethics Applied to Robotics (2001) IEEE Robot. Autom. Mag, 18, pp. 21-22; Capurro, R., Ethics in Robotics, , http://www.i-r-i-e.net/inhalt/006/006_full.pdf, (accessed on 10 June 2018); Lin, P., Abney, K., Jenkins, R., (2018) Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence, , Oxford University Press: Oxford, UK; Veruggio, G., Roboethics Roadmap (2006) Proceedings of the EURON Roboethics Atelier, , Genoa, Italy, 27 Feberuary-3 March; Arkin, R., (2009) Governing Lethal Behavior of Autonomous Robots, , Chapman and Hall: New York, NY, USA; Moore, R.K., (2015) AI Ethics: Artificial Intelligence, Robots, and Society, , www.cs.bath.ac.uk/~jjb/web/ai.html, CPSR: Seattle,WA, USA (accessed on 10 June 2018); Asaro, P.M., What should we want from a robot ethics? (2006) IRIE Int. Rev. Inf. Ethics, 6, pp. 9-16; Tzafestas, S.G., (2017) Systems, Cybernetics, Control, and Automation: Ontological, Epistemological, Societal, and Ethical Issues, , River Publishers: Gistrup, Denmark; Verrugio, P.M., Operto, F., Roboethics: A bottom-up interdisciplinary discourse in the field of applied ethics in robotics (2006) IRIE Int. Rev. Inf. Ethics, 6, pp. 2-8; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press: Oxford, UK; Wallach, W., Allen, C., Smit, I., Machine morality: Bottom-up and top-down approaches for modeling moral faculties (2008) J. AI Soc, 22, pp. 565-582; Asimov, I., (1991) Runaround: Astounding Science Fiction (March 1942), , Republished in Robot Visions: New York, NY, USA; Gert, B., (1988) Morality, , Oxford University Press: Oxford, UK; Gips, J., Toward the ethical robot (1992) Android Epistemology, , Ford, K., Glymour, C., Mayer, P., Eds.; MIT Press: Cambridge, MA, USA; Bringsjord, S., Ethical robots: The future can heed us (2008) AI Soc, 22, pp. 539-550; Dekker, M., Can humans be replaced by autonomous robots?. Ethical reflections in the framework of an interdisciplinary technology assessment (2007) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA'07), , Rome, Italy, 10-14 April; Pence, G.E., (2000) Classic Cases in Medical Ethics, , McGraw-Hill: New York, NY, USA; Mappes, G.E., DeGrazia, T.M.D., (2006) Biomedical Ethics, , McGraw-Hill: New York, NY, USA; North, M., The Hippocratic Oath (translation), , www.nlm.nih.gov/hmd/greek/greek_oath.html, National Library of Medicine, Greek Medicine (accessed on 10 June 2018); Paola, I.A., Walker, R., Nixon, L., (2009) Medical Ethics and Humanities, , Jones & Bartlett Publisher: Sudbary, MA, USA; (1995) Medical Ethics, , https://www.ama.assn.organdhttps://www.ama.assn.org/delivering-care/ama-code-medical-ethics, accessed on 10 June 2018; Beabou, G.R., Wennenmann, D.J., (1993) Applied Professional Ethics, , University of Press of America: Milburn, NJ, USA; Rowan, J.R., Sinaih, S., Jr., (2002) Ethics for the Professions, , Cencage Learning: Boston, MA, USA; Dickens, B.M., Cook, R.J., Legal and ethical issues in telemedicine and robotics (2006) Int. J. Gynecol. Obstet, 94, pp. 73-78; (2001) International Classification of Functioning, Disability, and Health, , World Health Organization: Geneva, Switzerland; Tanaka, H., Yoshikawa, M., Oyama, E., Wakita, Y., Matsumoto, Y., Development of assistive robots using international classification of functioning, disability, and health (ICF) (2013) J. Robot, 2013; Tanaka, H., Wakita, Y., Matsumoto, Y., Needs analysis and benefit description of robotic arms for daily support (2015) Proceedings of the RO-MAN' 15: 24th IEEE International Symposium on Robot and Human Interactive Communication, , Kobe, Japan, 31 August-4 September; http://resna.org/certification/RESNA_Code_of_Ethics.pdf, (accessed on 10 June 2018); www.crccertification.com/pages/crc_ccrc_code_of_ethics/10.php, (accessed on 10 June 2018); Tzafestas, S.G., (2016) Sociorobot World: A Guided Tour for All, , Springer: Berlin, Germany; Fog, T., Nourbakhsh, I., Dautenhahn, K., A survey of socially interactive robots (2003) Robot. Auton. Syst, 42, pp. 143-166; Darling, K., Extending legal protections in social robots: The effect of anthropomorphism, empathy, and violent behavior towards robots (2016) Robot Law, , Calo, M.R., Froomkin, M., Ker, I., Eds.; Edward Elgar Publishing: Brookfield, VT, USA; Melson, G.F., Kahn, P.H., Jr., Beck, A., Friedman, B., Robotic pets in human lives: Implications for the human-animal bond and for human relationships with personified technologies (2009) J. Soc. Issues, 65, pp. 545-567; Breazeal, C., (2002) Designing Sociable Robots, , MIT Press: Cambridge, MA, USA; Sawada, T., Takagi, T., Fujita, M., Behavior selection and motion modulation in emotionally grounded architecture for QRIO SDR-4XIII (2004) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'2004), pp. 2514-2519. , Sendai, Japan, 28 September-2 October; Asaro, P., (2008) How Just Could a Robot War Be, , IOS Press: Amsterdam, The Netherlands; Walzer, M., (2000) Just and Unjust Wars: A Moral Argument Historical with Illustrations, , Basic Books: New York, NY, USA; Coates, A.J., (1997) The Ethics of War, , University of Manchester Press: Manchester, UK; Asaro, A., Robots and responsibility from a legal perspective (2007) Proceedings of the 2007 IEEE International Conference on Robotics and Automation: Workshop on Roboethics, , Rome, Italy, 10-14 April; (2012) HRW-IHRC, Losing Humanity: The Case against Killer Robots, , www.hrw.org, Human Rights Watch: New York, NY, USA (accessed on 10 June 2018); Marcus, G., Moral Machines, , www.newyorker.com/news_desk/moral_machines, (accessed on 24 November 2012); Absolutely Everything You Need to Know, , http://recombu.com/cars/article/self-driving-cars-everything-you-need-to-know, (accessed on 10 June 2018); (2013), http://lesswrong.com/lw/gfv/notes_on_autonomous_cars, (accessed on 10 June 2018); Lynch, W., (1982) Wilfred Implants: Reconstructing the Human Body, , Van Nostrand Reihold: New York, NY, USA; Clynes, M., Kline, S., (1995) Cyborgs and Space. Astronautics, pp. 29-33. , http://www.tantrikastrologer.in/book/linked/2290.pdf, (accessed on 10 June 2018); Warwick, K., A Study of Cyborgs. Royal Academy of Engineering, , www.ingenia.org.uk/Ingenia/Articles/217, (accessed on 10 June 2018); Warwick, K., Homo Technologicus: Threat or Opportunity? (2016) Philosophies, 1, p. 199; www.mnn.com/leaderboard/stories/7-real-life-humancyborgs, (accessed on 10 June 2018); Warwick, K., Cyborg moral, cyborg values, cyborg ethics (2003) Ethics Inf. Technol, 5, pp. 131-137; Palese, E., Robots and cyborgs: To be or to have a body? (2012) Poiesis Prax, 8, pp. 19-196; Moravec, H., (1998) Robot: Mere Machine to Trancendent Mind, , Oxford University Press: Oxford, UK; Torresen, J., A review of future and ethical perspectives of robotics and AI (2018) Front. Robot. AI; MacDorman, K.F., Androids as an experimental apparatus: Why is there an uncanny valley and can we exploit it? (2005) Proceedings of the CogSci 2005 Workshop: Toward Social Mechanisms of Android Science, pp. 106-118. , Stresa, Italy, 25-26 July; (2016) IEEE Ethical Aligned Design, , http://standards.ieee.org/develop/indconn/ec/ead_v1.pdf, IEEE Standards Association: Piscataway, NJ, USA; (accessed on 10 June 2018); Coeckelberg, M., Robot Rights? Towards a social-relational justification of moral consideration (2010) Ethics Inf. Technol, 12, pp. 209-221; Should Robots Make Life/Death Decisions? (2015) Proceedings of the UN Discussion on Lethal Autonomous Weapons, , UN Palais des Nations, Geneva, Switzerland, 13-17 April; Sullins, J.P., Robots, love, and sex: The ethics of building a love machine (2012) IEEE Trans. Affect. Comput, 3, pp. 389-409; Cheok, A.D., Ricart, C.P., Edirisinghe, C., Special Issue "Love and Sex with Robots", , http://www.mdpi.com/journal/mti/special_issues/robots, (accessed on 10 June 2018); Levy, D., (2008) Love and Sex with Robots: The Evolution of Human-Robot Relationship, , Harper Perrenial: London, UK; Bostrom, N., Ethical issues in advanced artificial intelligence (2003) InCognitive, Emotive and Ethical Aspects of Decision Making in Humans and Artificial Intelligence, 2, pp. 12-17. , Lasker, G.E., Marreiros, G.,Wallach,W., Smit, I., Eds.; International Institute for Advanced Studies in Systems Research and Cybernetics: Tecumseh, ON, Canada; Barfield, W., Williams, A., Cyborgs and enhancement technology (2017) Philosophies, 2, p. 4},
document_type={Review},
source={Scopus},
}

@BOOK{Pereira2015197,
author={Pereira, L.M. and Saptawijaya, A.},
title={Bridging two realms of machine ethics},
journal={Rethinking Machine Ethics in the Age of Ubiquitous Technology},
year={2015},
pages={197-224},
doi={10.4018/978-1-4666-8592-5.ch010},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957373898&doi=10.4018%2f978-1-4666-8592-5.ch010&partnerID=40&md5=b672dfd51a81d5fae3581dc71b3ddadc},
abstract={We address problems in machine ethics dealt with using computational techniques. Our research has focused on Computational Logic, particularly Logic Programming, and its appropriateness to model morality, namely moral permissibility, its justification, and the dual-process of moral judgments regarding the realm of the individual. In the collective realm, we, using Evolutionary Game Theory in populations of individuals, have studied norms and morality emergence computationally. These, to start with, are not equipped with much cognitive capability, and simply act from a predetermined set of actions. Our research shows that the introduction of cognitive capabilities, such as intention recognition, commitment, and apology, separately and jointly, reinforce the emergence of cooperation in populations, comparatively to their absence. Bridging such capabilities between the two realms helps understand the emergent ethical behavior of agents in groups, and implements them not just in simulations, but in the world of future robots and their swarms. Evolutionary Anthropology provides teachings. © 2015, IGI Global.},
keywords={Computer games;  Game theory;  Logic programming;  Philosophical aspects, Cognitive capability;  Computational logic;  Computational technique;  Dual process;  Ethical behavior;  Evolutionary game theory;  Intention recognition;  Moral judgment, Computation theory},
references={Abeler, J., Calaki, J., Andree, K., Basek, C., The power of apology (2010) Economics Letters, 107 (2), pp. 233-235; Alferes, J.J., Pereira, L.M., Swift, T., Abduction in well-founded semantics and generalized stable models via tabled dual programs (2004) Theory and Practice of Logic Programming, 4 (4), pp. 383-428; Anderson, M., Anderson, S.L., EthEl: Toward a principled ethical eldercare robot (2008) AAAI Fall Symposium Technical Report on AI in Eldercare, , Palo Alto, CA: AAAI Press; Anderson, M., Anderson, S.L., Robot be good: A call for ethical autonomous machines (2010) Scientific American, 303 (4), pp. 54-59. , PMID:20923132; Anderson, M., Anderson, S.L., Armen, C., Towards machine ethics: Implementing two actionbased ethical theories (2005) AAAI Fall Symposium Technical Report on Machine Ethics, , Palo Alto, CA: AAAI Press; Anderson, M., Anderson, S.L., Armen, C., MedEthEx: a prototype medical ethics advisor (2006) Proceedings of the Eighteenth Conference on Innovative Applications of Artifical Intelligence (IAAI'06), , Palo Alto, CA: AAAI Press; Ashford, E., Mulgan, T., Contractualism (2007) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/entries/contractualism/, E. N. Zalta (Ed.), Fall 2012 Edition, Retrieved from; Axelrod, R., (1984) The Evolution of Cooperation, , New York: Basic Books; Axelrod, R., An evolutionary approach to norms (1986) The American Political Science Review, 80 (4), pp. 1095-1111; Baral, C., Gelfond, M., Rushton, N., Probabilistic reasoning with answer sets (2009) Theory and Practice of Logic Programming, 9 (1), pp. 57-144; Baumard, N., (2010) Comment nous sommes devenus moraux: Une histoire naturelle du bien et du mal, , Paris: Odile Jacob; Boehm, C., (1999) Hierarchy in the Forest: The Evolution of Egalitarian Behavior, , Cambridge, MA: Harvard University Press; Boehm, C., (2012) Moral Origins: The Evolution of Virtue, Altruism, and Shame, , New York: Basic Books; Bonabeau, E., Dorigo, M., Theraulaz, G., (1999) Swarm Intelligence: From Natural to Artificial Systems, , New York: Oxford University Press; Börgers, T., Sarin, R., Learning Through Reinforcement and Replicator Dynamics (1997) Journal of Economic Theory, 77 (1), pp. 1-14; Bowles, S., Gintis, H., (2011) A Cooperative Species: Human Reciprocity and Its Evolution, , Princeton: Princeton University Press; Boyd, R., Richerson, P., Punishment allows the evolution of cooperation (or anything else) in sizable groups (1992) Ethology and Sociobiology, 13 (3), pp. 171-195; Bratman, M.E., (1987) Intention, Plans and Practical Reasoning, , Cambridge, MA: Harvard University Press; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44; Bringsjord, S., Taylor, J., van Heuveln, B., Arkoudas, K., Clark, M., Wojtowicz, R., Piagetian roboethics via category theory: Moving beyond mere formal operations to engineer robots whose decisions are guaranteed to be ethically correct (2011) Machine Ethics, pp. 361-374. , M. Anderson & S. L. Anderson (Eds.), New York, NY: Cambridge University Press; Charniak, E., Goldman, R.P., A Bayesian model of plan recognition (1993) Artificial Intelligence, 64 (1), pp. 53-79; Churchland, P., (2011) Braintrust: What Neuroscience Tells Us about Morality, , Princeton: Princeton University Press; Cohen, P.R., Levesque, H.J., Intention is Choice with Commitment (1990) Artificial Intelligence, 42 (2-3), pp. 213-261; Cushman, F., Young, L., Greene, J.D., Multi-system moral psychology (2010) The Moral Psychology Handbook, , J. M. Doris (Ed.), New York: Oxford University Press; Dell'Acqua, P., Pereira, L.M., Preferential theory revision (2007) Journal of Applied Logic, 5 (4), pp. 586-601; Elster, J., A plea for mechanisms (1998) Social Mechanisms: An analytical approach to social theory, pp. 45-73. , P. Hedström & R. Swedberg (Eds.), Cambridge, NY: Cambridge University Press; Epstude, K., Roese, N.J., The functional theory of counterfactual thinking (2008) Personality and Social Psychology Review, 12 (2), pp. 168-192. , PMID:18453477; Erdal, D., Whiten, A., Boehm, C., Knauft, B., On human egalitarianism: An evolutionary product of machiavellian status escalation? (1994) Current Anthropology, 35 (2), pp. 175-183; Fischbacher, U., Utikal, V., On the acceptance of apologies (2013) Games and Economic Behavior, 82, pp. 592-608; Foot, P., The problem of abortion and the doctrine of double effect (1967) Oxford Review, 5, pp. 5-15; Frank, R.H., Cooperation through Emotional Commitment (2001) Evolution and the capacity for commitment, pp. 55-76. , R. M. Nesse (Ed.), New York: Russell Sage; Ganascia, J.-G., Modelling ethical rules of lying with Answer Set Programming (2007) Ethics and Information Technology, 9 (1), pp. 39-47; Ganascia, J.-G., An Agent-Based Formalization for Resolving Ethical Conflicts (2012) Proceedings of the Workshop on Belief Change, Non-monotonic Reasoning, and Conflict Resolution (BNC@ECAI'12), , Montpellier, France; Gazzaniga, M.S., (2006) The Ethical Brain: The Science of Our Moral Dilemmas, , New York: Harper Perennial; Gelfond, M., Lifschitz, V., The stable model semantics for logic programming (1988) Proceedings of the Fifth International Conference on Logic Programming (ICLP), pp. 1070-1080. , Cambridge, MA: MIT Press; Gintis, H., Beyond selfishness in modeling human behavior (2001) Evolution and the capacity for commitment, , R. M. Nesse (Ed.), New York: Russell Sage; Greene, J., (2013) Moral Tribes: Emotion, Reason, and the Gap Between Us and Them, , New York: The Penguin Press HC; Groves, T., Incentives in Teams (1973) Econometrica, 41 (4), pp. 617-631; Guarini, M., Computational neural modeling and the philosophy of ethics: Reflections on the particularism-generalism debate (2011) Machine Ethics, pp. 316-334. , M. Anderson & S. L. Anderson (Eds.), New York, NY: Cambridge University Press; Han, T.A., (2013) Intention Recognition, Commitments and Their Roles in the Evolution of Cooperation: From Artificial Intelligence Techniques to Evolutionary Game Theory Models. SAPERE series, 9, , Berlin: Springer-Verlag; Han, T.A., Pereira, L.M., Context-dependent incremental intention recognition through Bayesian network model construction (2011) Proceedings of the Eighth UAI Bayesian Modeling Applications Workshop, 818, pp. 50-58. , http://ceur-ws.org/Vol-818/paper7.pdf, A. Nicholson (Ed.), CEUR Workshop Proceedings; Retrieved from; Han, T.A., Pereira, L.M., Lenaerts, T., (2014) Emergence of Commitments in Public Goods Game: Restricting vs. Avoiding Non-Committers (Submitted), , http://centria.di.fct.unl.pt/~lmp/publications/online-papers/commitment_restriction.pdf, Retrieved from; Han, T.A., Pereira, L.M., Santos, F.C., Intention recognition promotes the emergence of cooperation (2011) Adaptive Behavior, 19 (3), pp. 264-279; Han, T.A., Pereira, L.M., Santos, F.C., The role of intention recognition in the evolution of cooperative behavior (2011) Proceedings of the 22nd International Joint Conference on Artificial Intelligence, pp. 1684-1689. , WalshT. (Ed.), AAAI Press; Han, T.A., Pereira, L.M., Santos, F.C., Corpus-based intention recognition in cooperation dilemmas (2012) Artificial Life, 18 (4), pp. 365-383. , PMID:22938562; Han, T.A., Pereira, L.M., Santos, F.C., The emergence of commitments and cooperation (2012) Proceedings of the Eleventh International Conference on Autonomous Agents and Multiagent Systems, pp. 559-566. , International Foundation for Autonomous Agents and Multiagent Systems; Han, T.A., Pereira, L.M., Santos, F.C., Intention Recognition, Commitment, and The Evolution of Cooperation (2012) Proceedings of IEEE Congress on Evolutionary Computation, pp. 1-8. , IEEE Press; Han, T.A., Pereira, L.M., Santos, F.C., Lenaerts, T., Good agreements make good friends (2013) Scientific Reports, p. 3. , PMID:24045873; Han, T.A., Pereira, L.M., Santos, F.C., Lenaerts, T., Why is it so hard to say sorry: The evolution of apology with commitments in the iterated Prisoner's Dilemma (2013) Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence, pp. 177-183. , Palo Alto: AAAI Press; Han, T.A., Pereira, L.M., Santos, F.C., Lenaerts, T., Emergence of Cooperation via Intention Recognition, Commitment, and Apology -- A Research Summary AI Communications, , press; Han, T.A., Saptawijaya, A., Pereira, L.M., Moral reasoning under uncertainty (2012) Proceedings of the Eighteenth International Conference on Logic for Programming Artificial Intelligence and Reasoning (LNCS), 7180, pp. 212-227. , Bjørner N. Voronkov A. (Eds.), Berlin:Springer-Verlag; Hardin, G., The tragedy of the commons (1968) Science, 162 (3859), pp. 1243-1248. , PMID:5699198; Hauser, M., Cushman, F., Young, L., Jin, R.K., Mikhail, J., A dissociation between moral judgments and justifications (2007) Mind & Language, 22 (1), pp. 1-21; Hauser, M.D., (2006) Moral Minds: The Nature of Right and Wrong, , New York: Harper Perennial; Heinze, C., (2003) Modeling Intention Recognition for Intelligent Agent Systems, , (Doctoral Dissertation). The University of Melbourne, Australia; Henrich, J., Boyd, R., Why people punish defectors: Weak conformist transmission can stabilize costly enforcement of norms in cooperative dilemmas (2001) Journal of Theoretical Biology, 208 (1), pp. 79-89. , PMID:11162054; Hofbauer, J., Sigmund, K., (1998) Evolutionary Games and Population Dynamics, , New York, NY: Cambridge University Press; Inhelder, B., Piaget, J., (1958) The Growth of Logical Thinking from Childhood to Adolescence, , New York, NY: Basic Books; Jackson, M.O., Mechanism theory (2000) Optimization and Operations Research, , U. Derigs (Ed.), Paris: EOLSS Publishers; Jonsen, A.R., Toulmin, S., (1988) The Abuse of Casuistry: A History of Moral Reasoning, , Oakland, CA: University of California Press; Kamm, F.M., (2006) Intricate Ethics: Rights, Responsibilities, and Permissible Harm, , New York, NY: Oxford University Press; Kowalski, R., (2011) Computational Logic and Human Thinking: How to be Artificially Intelligent, , New York, NY: Cambridge University Press; Krebs, D.L., (2011) The Origins of Morality: An Evolutionary Account, , New York: Oxford University Press; Lesh, N., (1998) Scalable and Adaptive Goal Recognition, , (Doctoral Dissertation). University of Washington; Lopes, G., Pereira, L.M., Prospective programming with ACORDA (2006) Proceedings of the FLoC'06 Workshop on Empirically Successful Computerized Reasoning (ESCoR'06), , Seattle, USA; Lopes, G., Pereira, L.M., Prospective storytelling agents (2010) Proceedings of the Twelfth International Symposium on Practical Aspects of Declarative Languages (LNCS), 5937, pp. 294-296. , CarroM.PeñaR. (Eds.), Berlin: Springer-Verlag; Markman, K.D., Gavanski, I., Sherman, S.J., McMullen, M.N., The mental simulation of better and worse possible worlds (1993) Journal of Experimental Social Psychology, 29 (1), pp. 87-109; McAfee, R.P., Mechanism Design by Competing Sellers (1993) Econometrica, 61 (6), pp. 1281-1312; McCloy, R., Byrne, R.M.J., Counterfactual thinking about controllable events (2000) Memory & Cognition, 28 (6), pp. 1071-1078. , PMID:11105533; McIntyre, A., Doctrine of double effect (2004) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/entries/double-effect/, E. N. Zalta (Ed.), Fall 2011 edition, Retrieved from; McLaren, B.M., Computational models of ethical reasoning: Challenges, initial steps, and future directions (2006) IEEE Intelligent Systems, 21 (4), pp. 29-37; Meltzoff, A.N., Imitation and other minds: the "like me" hypothesis (2005) Perspectives On Imitation: From Neuroscience to Social Science. Imitation, Human Development, and Culture, pp. 55-77. , Cambridge, MA: MIT Press; Migliore, S., Curcio, G., Mancini, F., Cappa, S.F., Counterfactual thinking in moral judgment: An experimental study (2014) Frontiers in Psychology, 5, p. 451. , PMID:24904468; Murakami, Y., Utilitarian Deontic Logic (2004) Proceedings of the Fifth International Conference on Advances in Modal Logic (AiML'04), , London: King's College Publications; Myerson, R., Incentive compatibility and the bargaining problem (1979) Econometrica, 47 (1), pp. 61-73; Naor, M., Pinkas, B., Sumner, R., Privacy preserving auctions and mechanism design (1999) Proceedings of the 1st ACM Conference on Electronic Commerce, pp. 129-139. , ACM; Nesse, R.M., Natural selection and the capacity for subjective commitment (2001) Evolution and the Capacity for Commitment, pp. 1-44. , R. M. Nesse (Ed.), New York: Russell Sage; Nesse, R.M., (2001) Evolution and the Capacity for Commitment, , New York: Russell Sage; Nisan, N., Ronen, A., Algorithmic mechanism design (1999) Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, pp. 129-140. , ACM; Nowak, M.A., (2006) Evolutionary Dynamics: Exploring the Equations of Life, , Cambridge, MA: Harvard University Press; Nowak, M.A., Five rules for the evolution of cooperation (2006) Science, 314 (5805), pp. 1560-1563. , PMID:17158317; Nowak, M.A., Sigmund, K., Tit for tat in heterogeneous populations (1992) Nature, 355 (6357), pp. 250-253; Ohtsubo, Y., Watanabe, E., Do sincere apologies need to be costly? Test of a costly signaling model of apology (2009) Evolution and Human Behavior, 30 (2), pp. 114-123; Ostrom, E., (1990) Governing the commons: The evolution of institutions for collective action, , Cambridge, MA: Cambridge University Press; Pearl, J., (2009) Causality: Models, Reasoning and Inference, , New York, NY: Cambridge University Press; Pereira, L.M., Evolutionary Tolerance (2012) Philosophy and Cognitive Science-Western & Eastern Studies (SAPERE), 2, pp. 263-287. , L. Magnani & L. Ping (Eds.), Berlin: Springer-Verlag; Pereira, L.M., Turing is Among Us (2012) Journal of Logic and Computation, 22 (6), pp. 1257-1277; Pereira, L.M., Can we not Copy the Human Brain in the Computer? (2014) Brain.org, pp. 118-126. , Lisbon: Fundação Calouste Gulbenkian; Pereira, L.M., Dell'Acqua, P., Pinto, A.M., Lopes, G., Inspecting and preferring abductive models (2013) The Handbook on Reasoning-Based Intelligent Systems, pp. 243-274. , K. Nakamatsu & L. C. Jain (Eds.), World Scientific Publishers; Pereira, L.M., Han, T.A., Evolution Prospection (2009) Proceedings of the First KES International Symposium IDT (New Advances in Intelligent Decision Technologies), 199, pp. 51-63. , NakamatsuK.Phillips-WrenG.JainL. C.HowlettR. J. (Eds.), Berlin: Springer-Verlag; Pereira, L.M., Han, T.A., Intention recognition via causal Bayes networks plus plan generation (2009) Proceedings of 14th Portuguese International Conference on Artificial Intelligence (LNCS), 5816, pp. 138-149. , Berlin: Springer-Verlag; Pereira, L.M., Han, T.A., Intention recognition with evolution prospection and causal Bayesian networks (2011) Computational Intelligence for Engineering Systems: Emergent Applications, pp. 1-33. , A. Madureira, J. Ferreira, & Z. Vale (Eds.), Berlin: Springer-Verlag; Pereira, L.M., Saptawijaya, A., Moral Decision Making with ACORDA (2007) Local Proceedings of the Fourteenth International Conference on Logic for Programming Artificial Intelligence and Reasoning (LPAR'07), , Yerevan, Armenia; Pereira, L.M., Saptawijaya, A., Modelling Morality with Prospective Logic (2007) Proceedings of the Thirteenth Portuguese Conference on Artificial Intelligence (LNCS), 4874, pp. 99-111. , NevesJ. M.SantosM. F.MachadoJ. M. (Eds.), Berlin: Springer-Verlag; Pereira, L.M., Saptawijaya, A., Modelling Morality with Prospective Logic (2009) International Journal of Reasoning-based Intelligent Systems, 1 (3-4), pp. 209-221; Pereira, L.M., Saptawijaya, A., Modelling Morality with Prospective Logic (2011) Machine Ethics, pp. 398-421. , M. Anderson & S. L. Anderson (Eds.), New York, NY: Cambridge University Press; Pereira, L.M., Saptawijaya, A., (2014) Counterfactuals in Logic Programming with Applications to Agent Morality, , http://centria.di.fct.unl.pt/~lmp/publications/online-papers/moral_counterfactuals.pdf, (Submitted). Retrieved from; Phelps, S., McBurney, P., Parsons, S., Evolutionary mechanism design: A review (2010) Autonomous Agents and Multi-Agent Systems, 21 (2), pp. 237-264; Pinheiro, F.L., Pacheco, J.M., Santos, F.C., From Local to Global Dilemmas in Social Networks (2012) PLoS ONE, 7 (2), p. e32114. , PMID:22363804; Powers, T.M., Prospects for a Kantian machine (2006) IEEE Intelligent Systems, 21 (4), pp. 46-51; Rahwan, I., Simari, G., (2009) Argumentation in Artificial Intelligence, , Berlin: Springer-Verlag; Rand, D.G., Fudenberg, D., Dreber, A., It's the thought that counts: The role of intentions in noisy repeated games (2013) Social Science Research Network, , http://ssrn.com/abstract=2259407, Retrieved from; Rawls, J., (1971) A Theory of Justice, , Cambridge, MA: Belknap Press of Harvard University Press; Ross, D., (2005) Economic theory and cognitive science: Microexplanation, , Cambridge, MA: MIT press; Ross, W.D., (1930) The Right and the Good, , New York: Oxford University Press; Roy, O., (2009) Thinking before Acting: Intentions, Logic, Rational Choice, , (Doctoral Dissertation). ILLC Dissertation Series DS-2008-03, Amsterdam; Roy, P., Bouchard, B., Bouzouane, A., Giroux, S., A hybrid plan recognition model for alzheimer's patients: interleaved-erroneous dilemma (2007) Proceedings of IEEE/WIC/ACM International Conference on Intelligent Agent Technology, pp. 131-137; Sadri, F., Logic-based approaches to intention recognition (2011) Handbook of Research on Ambient Intelligence: Trends and Perspectives, pp. 346-375. , N.-Y. Chong & F. Mastrogiovanni (Eds.), Hershey, PA: IGI Global; Saptawijaya, A., Pereira, L.M., Tabled abduction in logic programs (Technical Communication of ICLP 2013) (2013) Theory and Practice of Logic Programming, Online Supplement, 13 (4-5). , http://journals.cambridge.org/downloadsup.php?file=/tlp2013008.pdf, Retrieved from; Saptawijaya, A., Pereira, L.M., Incremental tabling for query-driven propagation of logic program updates (2013) Proceedings of the Nineteenth International Conference on Logic for Programming Artificial Intelligence and Reasoning (LNCS), 8312, pp. 694-709. , McMillanK.MiddeldorpA.VoronkovA. (Eds.), Berlin:Springer-Verlag; Saptawijaya, A., Pereira, L.M., Joint tabling of logic program abductions and updates (Technical Communication of ICLP 2014) (2014) Theory and Practice of Logic Programming, Online Supplement, 14 (4-5). , http://arxiv.org/abs/1405.2058, Retrieved from; Saptawijaya, A., Pereira, L.M., The Potential of Logic Programming as a Computational Tool to Model Morality A Construction Manual for Robots' Ethical Systems: Requirements, Methods, Implementations (Cognitive Technologies), , press, In R. Trappl (Ed.), Berlin: Springer-Verlag; Scanlon, T.M., Contractualism and utilitarianism (1982) Utilitarianism and Beyond, , A. Sen & B. Williams (Eds.), New York, NY: Cambridge University Press; Scanlon, T.M., (1998) What We Owe to Each Other, , Cambridge, MA: Harvard University Press; Scanlon, T.M., (2008) Moral Dimensions: Permissibility, Meaning, Blame, , Cambridge, MA: Harvard University Press; Searle, J.R., (1995) The Construction of Social Reality, , New York: The Free Press; Searle, J.R., (2010) Making the Social World: The Structure of Human Civilization, , New York: Oxford University Press; Segbroeck, S.V., Jong, S.D., Nowé, A., Santos, F.C., Lenaerts, T., Learning to coordinate in complex networks (2010) Adaptive Behavior, 18 (5), pp. 416-427; Sigmund, K., (2010) The Calculus of Selfishness, , Princeton, NJ: Princeton University Press; Sober, E., Wilson, D., (1998) Unto Others: The Evolution and Psychology of Unselfish Behavior, , Cambridge, MA: Harvard University Press; Sperber, D., Individualisme méthodologique et cognitivisme (1997) Cognition et sciences sociales, pp. 123-136. , R. Boudon, F. Chazel, & A. Bouvier (Eds.), Paris: Presses Universitaires de France; Swift, T., Warren, D.S., XSB: Extending Prolog with tabled logic programming (2012) Theory and Practice of Logic Programming, 12 (1-2), pp. 157-187; Thomson, J.J., A defense of abortion (1971) Philosophy & Public Affairs, 1 (1), pp. 47-66; Thomson, J.J., The trolley problem (1985) The Yale Law Journal, 279 (6), pp. 1395-1415; Tomasello, M., (2008) Origins of Human Communication, , Cambridge, MA: MIT Press; Tomasello, M., (2014) A Natural History of Human Thinking, , Cambridge, MA: Harvard University Press; Tzeng, J.-Y., Toward a more civilized design: Studying the effects of computers that apologize (2004) International Journal of Human-Computer Studies, 61 (3), pp. 319-345; Utz, S., Matzat, U., Snijders, C., On-line reputation systems: The effects of feedback comments and reactions on building and rebuilding trust in on-line auctions (2009) International Journal of Electronic Commerce, 13 (3), pp. 95-118; van den Hoven, J., Lokhorst, G.-J., Deontic logic and computer-supported computer ethics (2002) Metaphilosophy, 33 (3), pp. 376-386; van Gelder, A., Ross, K.A., Schlipf, J.S., The well-founded semantics for general logic programs (1991) Journal of the ACM, 38 (3), pp. 620-650; Wiegel, V., (2007) SophoLab; Experimental Computational Philosophy, , (Doctoral dissertation). Delft University of Technology, The Netherlands; Winikoff, M., Implementing commitment-based interactions (2007) Proceedings of the Sixth International Joint Conference on Autonomous Agents and Multiagent Systems, pp. 868-875; Wooldridge, M., Jennings, N.R., The cooperative problem-solving process (1999) Journal of Logic and Computation, 9 (4), pp. 563-592},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Bello2013251,
author={Bello, P. and Bringsjord, S.},
title={On How to Build a Moral Machine},
journal={Topoi},
year={2013},
volume={32},
number={2},
pages={251-266},
doi={10.1007/s11245-012-9129-8},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884520204&doi=10.1007%2fs11245-012-9129-8&partnerID=40&md5=e2ac8f1e3b2d4d56e1ad475701b36697},
abstract={Herein we make a plea to machine ethicists for the inclusion of constraints on their theories consistent with empirical data on human moral cognition. As philosophers, we clearly lack widely accepted solutions to issues regarding the existence of free will, the nature of persons and firm conditions on moral agency/patienthood; all of which are indispensable concepts to be deployed by any machine able to make moral judgments. No agreement seems forthcoming on these matters, and we don't hold out hope for machines that can both always do the right thing (on some general ethic) and produce explanations for its behavior that would be understandable to a human confederate. Our tentative solution involves understanding the folk concepts associated with our moral intuitions regarding these matters, and how they might be dependent upon the nature of human cognitive architecture. It is in this spirit that we begin to explore the complexities inherent in human moral judgment via computational theories of the human cognitive architecture, rather than under the extreme constraints imposed by rational-actor models assumed throughout much of the literature on philosophical ethics. After discussing the various advantages and challenges of taking this particular perspective on the development of artificial moral agents, we computationally explore a case study of human intuitions about the self and causal responsibility. We hypothesize that a significant portion of the variance in reported intuitions for this case might be explained by appeal to an interplay between the human ability to mindread and to the way that knowledge is organized conceptually in the cognitive system. In the present paper, we build on a pre-existing computational model of mindreading (Bello et al. 2007) by adding constraints related to psychological distance (Trope and Liberman 2010), a well-established psychological theory of conceptual organization. Our initial results suggest that studies of folk concepts involved in moral intuitions lead us to an enriched understanding of cognitive architecture and a more systematic method for interpreting the data generated by such studies. © 2012 Springer Science+Business Media B.V.(outside the USA).},
author_keywords={Computational cognitive modeling;  Experimental psychology;  Machine ethics;  Mindreading},
references={Arkin, R., (2009) Governing lethal behavior in autonomous robots, , Chapman and Hall/CRC, Boca Raton, FL; Badre, D., D'Esposito, M., Functional magnetic resonance imaging evidence for hierarchical organization of the prefrontal cortex (2007) J Cogn Neurosci, 19, pp. 2082-2099; Beavers, A., Moral machines and the threat of ethical nihilism (2011) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 333-344. , P. Lin, G. Bekey, and K. Abney (Eds.), Cambridge: MIT Press; Bello, P., Shared representations of belief and their effects on action selection: a preliminary computational cognitive model (2011) In: Proceedings of the 33rd annual conference of the Cognitive Science Society, pp. 2997-3002; Bello, P., Cognitive foundations for a computational theory of mindreading (2012) Adv Cogn Syst, 1, pp. 59-72; Bello, P., Bignoli, P., Cassimatis, N., Attention and association explain the emergence of reasoning about false belief in young children (2007) In: Proceedings of the 8th international conference on cognitive modeling, pp. 169-174. , University of Michigan, Ann Arbor; Bello, P., Guarini, M., Introspection and mindreading as mental simulation (2010) In: Proceedings of the 32nd annual conference of the cognitive science society, pp. 2022-2028. , Austin, TX; Berns, G.S., Bell, E., Capra, C.M., Prietula, M.J., Moore, S., Anderson, B., Ginges, J., Atran, S., The price of your soul: neural evidence for the non-utilitarian representation of sacred values (2012) Philos Trans R Soc Lond B Biol Sci, 1589, pp. 754-762; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intell Syst, 21, pp. 38-44; Cannon, E., Woodward, A., Infants generate goal-based action predictions (2012) Dev Sci, 15, pp. 292-298; Cassimatis, N., A cognitive substrate for human-level intelligence (2006) AI Mag, 27, pp. 45-56; Cassimatis, N., Bello, P., Langley, P., Ability, parsimony and breadth in models of highe-rorder cognition (2008) Cogn Sci, 33, pp. 1304-1322; Egan, A., Seeing and believing: perception, belief formation, and the divided mind (2008) Philos Stud, 140, pp. 47-63; Feit, N., (2008) Belief about the Self: A Defense of the Property Theory of Content, , New York: Oxford University Press; Goldman, A., (2006) Simulating Minds: The Philosophy, Psychology, and Neuroscience of Mindreading, , Oxford: Oxford University Press; Govindarajalu, N., Bringsjord, S., Logic-based simulations of mirror testing for self-consciousness (2011) In: Proceedings of the first international conference of IACAP celebrating 25 years of computing and philosophy (CAP) conferences: The computational turn: Past, presents, futures?, , Aarhus, Denmark; Guarini, M., Computational neural modeling and the philosophy of ethics (2011) Machine Ethics, pp. 316-334. , M. Anderson and S. Anderson (Eds.), Cambridge: Cambridge University Press; Kauppinin, A., The rise and fall of experimental philosophy (2007) Philos Explor, 10, pp. 95-118; Knobe, J., Nichols, S., Free will and the bounds of the self (2011) Oxford Handbook of Free Will, pp. 530-554. , 2nd edn., R. Kane (Ed.), New York: Oxford University Press; Langley, P., Laird, J., Rogers, S., Cognitive architectures: research issues and challenges (2009) Cogn Syst Res, 10, pp. 141-160; Mill, J.S., (1979) Utilitarianism, , Hackett Publishing (original work published in 1861); Mueller, E., (2006) Commonsense Reasoning, , San Fransisco: Morgan Kaufmann; Rim, S., (2011) Distance-dependent focus on causal antecedents versus causal consequents, , Doctoral dissertation, New York University; Scally, J., Cassimatis, N., Uchida, H., Worlds as a unifying element of knowledge representation (2011) In: AAAI fall symposium series, pp. 280-287; Swallow, K.M., Zacks, J.M., Abrams, R.A., Event boundaries in perception affect memory encoding and updating (2009) J Exp Psychol Gen, 138, pp. 236-257; Trope, Y., Liberman, N., Construal level theory of psychological distance (2010) Psychol Rev, 117, pp. 440-463},
document_type={Article},
source={Scopus},
}

@ARTICLE{Pearson2013123,
author={Pearson, Y. and Borenstein, J.},
title={The Intervention of Robot Caregivers and the Cultivation of Children's Capability to Play},
journal={Science and Engineering Ethics},
year={2013},
volume={19},
number={1},
pages={123-137},
doi={10.1007/s11948-011-9309-8},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874578438&doi=10.1007%2fs11948-011-9309-8&partnerID=40&md5=6abcacf72252a11c72cfc72329045faa},
abstract={In this article, the authors examine whether and how robot caregivers can contribute to the welfare of children with various cognitive and physical impairments by expanding recreational opportunities for these children. The capabilities approach is used as a basis for informing the relevant discussion. Though important in its own right, having the opportunity to play is essential to the development of other capabilities central to human flourishing. Drawing from empirical studies, the authors show that the use of various types of robots has already helped some children with impairments. Recognizing the potential ethical pitfalls of robot caregiver intervention, however, the authors examine these concerns and conclude that an appropriately designed robot caregiver has the potential to contribute positively to the development of the capability to play while also enhancing the ability of human caregivers to understand and interact with care recipients. © 2011 Springer Science+Business Media B.V.},
author_keywords={Capabilities approach;  Disability;  Robot caregivers;  Robot ethics;  The capability to play},
keywords={adolescent;  article;  caregiver;  child;  child development;  cognitive defect;  disabled person;  ethics;  human;  recreation;  robotics, Adolescent;  Caregivers;  Child;  Child Development;  Cognition Disorders;  Disabled Persons;  Humans;  Play and Playthings;  Robotics},
references={Banks, M.R., Willoughby, L.M., Banks, W.A., Animal-assisted therapy and loneliness in nursing homes: Use of robotic versus living dogs (2008) Journal of the American Medical Directors Association, 9 (3), pp. 173-177; Bekoff, M., Pierce, J., (2010) Wild Justice: The Moral Lives of Animals, , Chicago: University Of Chicago Press; Borenstein, J., Pearson, Y., Robot caregivers: Harbingers of expanded freedom for all? (2010) Ethics and Information Technology, 12 (3), pp. 277-288; Coeckelbergh, M., Health care, capabilities, and AI assistive technologies (2010) Ethical Theory and Moral Practice, 13 (2), pp. 181-190; Coeckelbergh, M., You, robot: On the linguistic construction of artificial others (2011) AI and Society, 26 (1), pp. 61-69; Duncan, A.F., Caughy, M.O., Parenting style and the vulnerable child syndrome (2009) Journal of Child and Adolescent Psychiatric Nursing, 22 (4), pp. 228-234; Faucounau, V., Wu, Y.H., Boulay, M., Maestrutti, M., Rigaud, A.S., Caregivers' requirements for in-home robotic agent for supporting community-living elderly subjects with cognitive impairment (2009) Technology and Health Care, 17 (1), pp. 33-40; Ginsburg, K.R., The importance of play in promoting healthy child development and maintaining strong parent-child bonds (2007) Pediatrics, 119 (1), pp. 182-191. , The Committee on Communications, the Committee on Psychosocial Aspects of Child, Family Health; Heimlich, K., Animal-assisted therapy and the severely disabled child: A quantitative study (2001) Journal of Rehabilitation, , http://www.findarticles.com/p/articles/mi_m0825/is_4_67/ai_81759719/, Accessed 19 May 2011; Huizinga, J., (1950) Homo Ludens: A Study of the Play Element in Culture, , Boston: Beacon Press; Kahn Jr., P.H., Friedman, B., Perez-Granados, D., Freier, N.G., Robotic pets in the lives of preschool children (2006) Interaction Studies, 7 (3), pp. 405-436; Kim, D., Hazlett, R., Godfrey, H., Rucks, G., Portee, D., Bricout, J., On the relationship between autonomy, performance, and satisfaction: Lessons from a three-week user study with post-SCI patients using a smart 6DOF assistive robotic manipulator (2010) 2010 IEEE International Conference on Robotics and Automation (ICRA, pp. 217-222; Li, H.C.W., Chung, O.K.J., Chiu, S.Y., The impact of cancer on children's physical, emotional, and psychosocial well-being (2010) Cancer Nursing, 33 (1), pp. 47-54; Mone, G., (2010) The new face of therapy, Popular Science (June), pp. 68-93; Murphy, N.A., Christian, B., Caplin, D.A., Young, P.C., The health of caregivers for children with disabilities: Caregiver perspectives (2006) Child: Care, Health and Development, 33 (2), pp. 180-187; Narvaez, D., Human flourishing and moral development: Cognitive science and neurobiological perspectives on virtue development (2008) Handbook of Moral and Character Education, pp. 310-327. , L. Nucci and D. Narvaez (Eds.), Mahwah, NJ: Erlbaum; Nussbaum, M.C., (2000) Women and Human Development, , New York: Cambridge University Press; Nussbaum, M.C., (2006) Frontiers of Justice, , Cambridge, MA: Belknap Press; Poletz, L., Encarnação, P., Adams, K., Cook, A., Robot skills and cognitive performance of preschool children (2010) Technology and Disability, 22 (3), pp. 117-126; Prazak, B., Kronreif, G., Hochgatterer, A., Furst, M., A toy robot for physically disabled children (2004) Technology and Disability, 16 (3), pp. 131-136; Scassellati, B., How social robots will help us to diagnose, treat, and understand autism (2007) Robotics Research, pp. 552-563. , S. Thrun, R. Brooks, and H. Durrant-Whyte (Eds.), New York: Springer; Sen, A., (1999) Development as Freedom, , New York: Alfred A. Knopf; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2010) Ethics and Information Technology, , doi: 10. 1007/s10676-010-9234-6; Sharkey, N., Sharkey, A., The crying shame of robot nannies: An ethical appraisal (2010) Interaction Studies, 11 (2), pp. 161-190; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Minds and Machines, 16 (2), pp. 141-161; Spiegel, A., (2008) Old-fashioned play builds serious skills, , http://www.npr.org/templates/story/story.php?storyId=19212514, NPR Morning Edition (February 21), Accessed 19 May 2011; Stiegler, L., Davis, R., Managing sound sensitivity in individuals with ASDs (2011) The ASHA Leader, , http://www.asha.org/Publications/leader/2011/110118/Managing-Sound-Sensitivity-in-Individuals-With-ASDs.htm, Accessed 19 May 2011; Toboso, M., Rethinking disability in Amartya Sen's approach: ICT and equality of opportunity (2011) Ethics and Information Technology, 13 (2), pp. 107-118; Turkle, S., (2011) Alone Together: Why We Expect More from Technology and less from Each Other, , New York: Basic Books; Vallor, S., Carebots and caregivers: Sustaining the ethical ideal of care in the twenty-first century (2011) Philosophy & Technology (Online First), , http://www.springerlink.com/content/p1v784663073q357/, Accessed 22 July 2011; Wright, R.J., Cohen, S., Carey, V., Weiss, S.T., Gold, D.R., Parental stress as a predictor of wheezing in infancy: A prospective birth-cohort study (2002) American Journal of Respiratory and Critical Care Medicine, 165 (3), pp. 358-365},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Tanaka2012253,
author={Tanaka, F. and Matsuzoe, S.},
title={Learning verbs by teaching a care-receiving robot by children: An experimental report},
journal={HRI'12 - Proceedings of the 7th Annual ACM/IEEE International Conference on Human-Robot Interaction},
year={2012},
pages={253-254},
doi={10.1145/2157689.2157781},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859945847&doi=10.1145%2f2157689.2157781&partnerID=40&md5=a62d73c40eb9fd56ef3a6a1a53461424},
abstract={We investigate the use of care-receiving robot (CRR) for the purpose of supporting childhood education. In contrast to the conventional teaching agents that are designed to play the role of human teachers or caregivers, the robot here receives cares from children. We hypothesize that by using this CRR, we may construct a new educational framework whose goal is to promote children's spontaneous learning by teaching through teaching the CRR. The paper describes an experiment for investigating whether a CRR can promote children's learning English verbs through teaching it. © 2012 Authors.},
author_keywords={care-receiving robot;  child education;  child-robot interaction;  crr;  direct teaching;  learning by teaching;  learning reinforcement;  learning support;  robot ethics},
keywords={child-robot interaction;  crr;  Direct teachings;  Learning by teaching;  Learning support, Human computer interaction;  Human robot interaction;  Man machine systems, Education},
references={Ghosh, M., Tanaka, F., The impact of different competence levels of care-receiving robot on children (2011) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011), pp. 2409-2415; Tanaka, F., Kimura, T., The use of robots in early education: A scenario based on ethical consideration (2009) Proceedings of the 18th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN 2009), pp. 558-560; Tanaka, F., Kimura, T., Care-receiving robot as a tool of teachers in child education (2010) Interaction Studies, 11 (2), pp. 263-268},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Pontier2012442,
author={Pontier, M.A. and Widdershoven, G. and Hoorn, J.F.},
title={Moral Coppélia - Combining ratio with affect in ethical reasoning},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2012},
volume={7637 LNAI},
pages={442-451},
doi={10.1007/978-3-642-34654-5_45},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906665627&doi=10.1007%2f978-3-642-34654-5_45&partnerID=40&md5=28f1eab796c45b82c599909d053e1c2b},
abstract={We present an integration of rational moral reasoning with emotional intelligence. The moral reasoning system alone could not simulate the different human reactions to the Trolley dilemma and the Footbridge dilemma. However, the combined system can simulate these human moral decision making processes. The introduction of affect in rational ethics is important when robots communicate with humans in a practical context that includes moral relations and decisions. Moreover, the combination of ratio and affect may be useful for applications in which human moral decision making behavior is simulated, for example, when agent systems or robots provide healthcare support. © Springer-Verlag Berlin Heidelberg 2012.},
author_keywords={Cognitive modeling;  Cognitive robotics;  Emotion modeling;  Emotional computing;  Machine ethics;  Moral reasoning},
keywords={Decision making;  Philosophical aspects, Cognitive model;  Cognitive robotics;  Emotion modeling;  Emotional computing;  Moral reasoning, Artificial intelligence},
references={Anderson, M., Anderson, S., Armen, C., Toward machine ethics: Implementing two action-based ethical theories (2005) Machine Ethics: Papers from the AAAI Fall Symposium, , Association for the Advancement of Artificial Intelligence Menlo Park, CA; Banks, M.R., Willoughby, L.M., Banks, W.A., Animal-assisted therapy and loneliness in nursing homes-use of robotic versus living dogs (2008) Journal of the American Medical Directors A Ssociation, 9, pp. 173-177; Beauchamp, T.L., Childress, J.F., (2001) Principles of Biomedical Ethics, , Oxford University Press New York; Bosse, T., Pontier, M.A., Siddiqui, G.F., Treur, J., Incorporating emotion regulation into virtual stories (2007) IVA 2007. LNCS (LNAI), 4722, pp. 339-347. , Pelachaud, C., Martin, J.C., Andre, E., Chollet, G., Karpouzis, K., Pele, D. (eds.) Springer, Heidelberg; Bosse, T., Hoorn, J.F., Pontier, M.A., Siddiqui, G.F., Robot's experience of another robot: Simulation (2008) Cog Sci 2008, pp. 2498-2503. , Sloutsky, V., Love, B.C., McRae, K. (eds.); Bosse, T., Gratch, J., Hoorn, J.F., Pontier, M.A., Siddiqui, G.F., Comparing three computational models of affect (2010) Advances in PAAMS. AISC, 70, pp. 175-184. , Demazeau, Y., Dignum, F., Corchado, J.M., Pérez, J.B., et al. (eds.) Springer, Heidelberg; Depaulo, B.M., Kashy, D.A., Kirkendol, S.E., Wyer, M.M., Ep-Stein, J.A., Lying in everyday life (1996) Journal of Personality and Social Psychology, 70 (5), pp. 979-995; Greene, J.D., Sommerville, R.B., Nystrom, L.E., Darley, J.M., Cohen, J.D., An fMRI Investigation of Emotional Enga gement in Moral Judgment (2001) Science, 293 (5537), pp. 2105-2108. , doi:10.1126/science.1062872; Haidt, J., The emotional dog and its rational tail-A social intuitionist approach to moral judgment (2001) Psychological Review, 108 (4), pp. 814-834; Hoorn, J.F., Pontier, M.A., Siddiqui, G.F., Coppélius' concoction: Similarity and complementarity among three affect-related agent models (2012) Cognitive Systems Research Journal, pp. 33-49; Hoorn, J.F., Pontier, M.A., Siddiqui, G.F., When the user is instrument to robot goals (2008) 7th IEEE/WIC/ACM International Conference on Intelligent Agent Technology (IAT 2008, pp. 296-301; Konijn, E.A., Hoorn, J.F., Some like it bad testing a model for perceiving and experiencing fictional characters (2005) Media Psychology, 7 (2), pp. 107-144; Marsella, S., Gratch, J., EMA: A Model of Emotional Dynamics (2009) Cognitive Systems Research, 10 (1), pp. 70-90; Noddings, N., (1984) Caring-A Feminine Approach to Ethics and Moral Education, , University of Calfiornia Press, Berkeley and Los Angeles; Ohnsorge, K., Widdershoven, G.A.M., Monological versus dialogical consciousness-two epistemological views on the use of theory in clinical ethical practice (2011) Bioethics, 25 (7), pp. 361-369; Pantazidou, M., Nair, I., Ethic of care: Guiding principles for engineering teaching & practice (1999) Journal of Engineering Education, 88 (2), pp. 205-212; Picard, R., (1997) Affective Computing, , MIT Press Cambridge; Pontier, M.A., (2011) Virtual Agents for Human Communication-Emotion Regulation and Involvement-Distance Trade-Offs in Embodied Conversational Agents and Robots, , Doctoral dissertation VU University, Amsterdam; Pontier, M.A., Hoorn, J.F., Toward machines that behave ethically better than humans do (2012) Proceedings of the 34th International Annual Conference of the Cognitive Science Society, CogSci 2012, , in press; Robins, B., Dautenhahn, K., Boekhorst, R.T., Billard, A., Robotic assistants in therapy and education of children with autism can a small humanoid robot help encourage social interaction skills (2005) Journal of Univers Al Access in the Information Society, 4, pp. 105-120; Van Vugt, H.C., Hoorn, J.F., Konijn, E.A., Interactive engagement with embodied agents: An empirically validated framework (2009) Computer Animation and Virtual Worlds, 20 (2-3), pp. 195-204; Van Wynsberghe, A., Designing robots for care; Care centered value-sensitive design (2012) Journal of Science and Engineering Ethics, , in press; Wada, K., Shibata, T., Social effects of robot therapy in a care house (2009) JACIII, 13, pp. 386-392; (2010), http://www.who.int/topics/ageing/en/, WHO Health topics: Ageing},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Honarvar2009290,
author={Honarvar, A.R. and Ghasem-Aghaee, N.},
title={An artificial neural network approach for creating an ethical artificial agent},
journal={Proceedings of IEEE International Symposium on Computational Intelligence in Robotics and Automation, CIRA},
year={2009},
pages={290-295},
doi={10.1109/CIRA.2009.5423190},
art_number={5423190},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951150138&doi=10.1109%2fCIRA.2009.5423190&partnerID=40&md5=a1062707bdac0ca93d7f0114d22aa060},
abstract={Autonomous robotic systems and intelligent artificial agents' capability have advanced dramatically. Since the intelligent artificial agents have been developing more autonomous and human-like, the capability of them to make moral decisions becomes an important issue. In this work we developed an artificial neutral network which considered various effective factors for ethical assessment of an action to determine that if a behavior or an action is ethically permissible or not. We integrated this net to the BDI-Agent model as a part of its reasoning process to behave ethically in various environments.},
author_keywords={AMA;  Artificial ethical agent;  Artificial neural network;  BDI-agent;  Ethical reasoning;  Machine ethics},
keywords={Agent model;  AMA;  Artificial agents;  Artificial ethical agent;  Artificial Neural Network;  Artificial neural network approach;  Artificial neutral network;  Autonomous robotic systems;  Effective factors;  Reasoning machine;  Reasoning process, Autonomous agents;  Intelligent agents;  Intelligent robots;  Robotics, Neural networks},
references={Anderson, M., Anderson, S., Ethical Healthcare Agents (2008) Studies in Computational Intelligence, 107, pp. 233-325. , Springer; Wiegel, V., (2007) Experimental Computational Philosophy, , SophoLab, Ph.D. dissertation, Faculty of Technology, Policy and Management, Delft University of Technology; Wiegel, V., Van Den Berg, J., Combining Moral Theory, Modal Logic and Mas to Create Well-Behaving Artificial Agents (2009) Social Robotics, 1. , springer; Wallach, W., Allen, C., EthicALife: A new field of inquiry AnAlifeX Workshop, USA, 2006; Tonkens, R., (2009) A Challenge for Machine Ethics, Minds and Machines, , springer; Anderson, M., Anderson, S., Armen, C., (2005) Toward Machine Ethics: Implementing Two Action-Based Ethical Theories: AAAI 2005 Fall Symp. Machine Ethics, pp. 1-16. , AAAI Press; Anderson, M., Anderson, S.L., Machine Ethics: Creating an Ethical Intelligent Agent (2007) AI Magazine, 28 (4); Allen, C., Smit, I., Wallach, W., Artificial Morality: Top-Down, Bottom-Up, and Hybrid Approaches (2006) Ethics and Information Technology, 7, pp. 149-155; Rao, G., BDI Agents: From Theory to Practice Proceedings of the First International Conference on Multi-Agent Systems (ICMAS95), San Fransisco, USA, 1995; Shiu, P.S., (2004) Foundations of Soft Case-Based Reasoning, , Wiley-Interscience; Kolodner, (1993) Case-Based Reasoning, , Morgan Kaufmann: San Mateo, CA; Gips, (1995) Towards the Ethical Robot, Android Epistemology, pp. 243-252. , Cambridge MA: MIT Press; Al-Fedaghi, S.S., Typification-Based Ethics for Artificial Agents Proceedings of Second IEEE International Conference on Digital Ecosystems and Technologies, 2008; Keefer, M., (2003) Moral Reasoning and Case-based Approaches to Ethical Instruction in Science, the Role of Moral Reasoning on Socioscientific Issues and Discourse in Science Education, , Springer; Guarini, M., Particularism and the Classification and Reclassification of Moral Cases (2006) IEEE Intelligent Systems, 21 (4); Weitz, B.A., Castleberry, S.B., Tanner, J.F., (2004) Selling: Building Partnerships, , McGraw-Hill; Rzepka, R., Araki, What Statistics Could Do for Ethics? - The Idea of Common Sense Processing Based Safety Valve. In: Technical report - machine ethics: Papers from the AAAI fall symposium (2005) Technical Report FS-05-06, pp. 85-87. , American Association of Artificial Intelligence, Menlo Park, CA; Bringsjord, S., Arkoudas, K., Bello, P., Toward a General Logicist Methodology for Engineering Ethically Correct Robots (2006) IEEE Intelligent Systems, 21 (4); Bringsjord, A.K., Toward ethical robots via mechanized deontic logic. In: Technical report - Machine ethics: Papers from the AAAI fall symposium (2005) Technical Report FS-05-06, , American Association of Artificial Intelligence, Menlo Park, CA; Van Den Hoven, J., Lokhorst, G.-J., Deontic Logic and Computer-Supported Computer Ethics (2002) Cyberphilosophy: The Intersection of Computing and Philosophy; Honarvar, A.R., Ghasem-Aghaee, N., Casuist BDI-Agent: A New Extended BDI Architecture with the Capability of Ethical Reasoning (2009) Artificial Intelligence and Computational Intelligence: International Conference, AICI 2009, Shanghai, China, , Springer Verlag; Hämäläinen, W., Do Computers Have Conscience? Implementing Artificial Morality, , http://cs.joensuu.fi/-whamalai/articles/ethics.pdf, available at and http://citeseerx.ist.psu.edu; Powers, T.M., Prospects for a Kantian Machine (2006) IEEE Intelligent Systems, 21 (4); Ganascia, J.-G., Using non-monotonic logic to model machine ethics Seventh International Computer Ethics Conference,University of San Diego, USA, 2007; Ganascia, J.-G., Modelling ethical rules of lying with Answer Set Programming (2007) Ethics and Information Technology, 9 (1)},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Prescott2017142,
author={Prescott, T.J.},
title={Robots are not just tools},
journal={Connection Science},
year={2017},
volume={29},
number={2},
pages={142-149},
doi={10.1080/09540091.2017.1279125},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018653811&doi=10.1080%2f09540091.2017.1279125&partnerID=40&md5=bba97ac264148c9329d8aa0fb5336288},
abstract={The EPSRC principles of robotics make a number of commitments about the ontological status of robots such as that robots are “just tools” or can give only “an impression or real intelligence”. This commentary proposes that this assumes, all too easily, that we know the boundary conditions of future robotics development, and argues that progress towards a more useful set of principles could begin by thinking carefully about the ontological status of robots. Whilst most robots are currently little more than tools, we are entering an era where there will be new kinds of entities that combine some of the properties of tools with psychological capacities that we had previously thought were reserved for complex biological organisms such as humans. The ontological status of robots might be best described as liminal–neither living nor simply mechanical. There is also evidence that people will treat robots as more than just tools regardless of the extent to which their machine nature is transparent. Ethical principles need to be developed that recognise these ontological and psychological issues around the nature of robots and how they are perceived. © 2017 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={machine intelligence;  ontological status of robots;  perceptions of robots;  principles of robotics;  Robot ethics},
keywords={Ontology;  Philosophical aspects;  Robotics;  Robots, Biological organisms;  Ethical principles;  Machine intelligence;  Ontological status;  Real intelligence;  Robot ethics, Intelligent robots},
references={(1945), https://www.gilderlehrman.org/history-by-era/postwar-politics-and-origins-cold-war/resources/physicists-predict-nuclear-arms-race, Preliminary statement. Retrieved from; Bostrom, N., (2014) Superintelligence: Paths, dangers, strategies, , Oxford: Oxford University Press; Brown, A., (2015), http://www.theguardian.com/commentisfree/2015/mar/12/mourn-robotic-dog-human-sony, March, To mourn a robotic dog is to be truly human guardian. Retrieved from; Bryson, J.J., (2009), April, Crude, cheesy, second-rate consciousness. Paper presented at The Second AISB Symposium Computing and Philosophy, Edinburgh; Bryson, J.J., Robots should be slaves (2010) Close engagements with artificial companions: Key social, psychological, ethical and design issue, pp. 63-74. , Wilks Y., (ed), Amsterdam: John Benjamins Publishing Company; Bryson, J.J., A role for consciousness in action selection (2012) International Journal of Machine Consciousness, 4 (2), pp. 471-482; Collins, E.C., Millings, A., Prescott, T.J., (2013), Attachment to assistive technology: A new conceptualisation. Paper presented at the Assistive Technology: From Research to Practice: AAATE 2013; Dennett, D.C., (1987) The intentional stance, , Cambridge: The MIT Press; Dennett, D.C., The practical requirements for making a conscious robot (1994) Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 349, pp. 133-146; Fellous, J.-M., (2004), From human emotions to robot emotions. Paper presented at the AAAI Spring Symposium on Architectures for modeling emotions: Cross-disciplinary foundations Menlo Park, CA; (2015), http://futureoflife.org/ai-open-letter/, An open letter: Research priorities for robust and beneficial artificial intelligence. Retrieved from; Heider, F., Simmel, M., An experimental study of apparent behavior (1944) The American Journal of Psychology, 57 (2), pp. 243-259; Heylighen, F., The global brain as a new utopia (2002) Zukunftsfiguren, , Maresch R., Rötzer F., (eds), Frankfurt: Suhrkamp; Huebner, B., Commonsense concepts of phenomenal consciousness: Does anyone care about functional zombies? (2010) Phenomenology and the Cognitive Sciences, 9 (1), pp. 133-155; Kahn, J., Peter, H., Ishiguro, H., Friedman, B., Kanda, T., Freier, N.G., Miller, J., What is a human?: Toward psychological benchmarks in the field of human–robot (2007) Interaction Studies, 8 (3), pp. 363-390; Kang, M., (2011) Sublime dreams of living machines: The automaton in the European imagination, , Cambridge, MA: Harvard University Press; Levy, D., (2007) Love and sex with robots, , London: Harper Collins; Lovgren, S., (2007), http://news.nationalgeographic.com/news/2007/03/070316-robot-ethics.html, March, Robot code of ethics to prevent android abuse, protect humans. National Geographic News. Retrieved from; Metzinger, T., (2009) The ego tunnel: The science of the mind and the myth of the self, , New York, NY: Basic Books; Qiu, J., Probing islands of consciousness in the damaged brain (2007) The Lancet Neurology, 6 (11), pp. 946-947; Robbins, P., Jack, A.I., The phenomenal stance (2006) Philosophical Studies, 127 (1), pp. 59-85; Rodogno, R., Social robots, fiction, and sentimentality (2016) Ethics and Information Technology, 18 (4), pp. 257-268; Seth, A.K., (2016), Why fish pain cannot and should not be ruled out. Animal Sentience, 2016.020; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Minds and Machines, 16 (2), pp. 141-161; Szollosy, M., Freud, Frankenstein and our fear of robots: Projection in our cultural perception of technology (2016) AI & SOCIETY, pp. 1-7; Tononi, G., Consciousness as integrated information: A provisional manifesto (2008) The Biological Bulletin, 215 (3), pp. 216-242},
document_type={Article},
source={Scopus},
}

@ARTICLE{Pereira2016141,
author={Pereira, L.M. and Saptawijaya, A.},
title={Modeling collective morality via evolutionary game theory},
journal={Studies in Applied Philosophy, Epistemology and Rational Ethics},
year={2016},
volume={26},
pages={141-157},
doi={10.1007/978-3-319-29354-7_9},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019728378&doi=10.1007%2f978-3-319-29354-7_9&partnerID=40&md5=7d3ba48274e26e467fb77b31a2d5e9ec},
abstract={We have been addressing problems in machine ethics dealt with by using computational techniques. In the preceding chapters, our research has focused on Computational Logic, particularly Logic Programming, and its appropriateness to model morality, namely moral permissibility, its justification, and the dual-process ofmoral judgments regarding the realm of the individual. Now, in the sections of this chapter, we address the collective realm computationally, using Evolutionary Game Theory in populations of individuals, to report on norms and morality emergence. These populations, to start with, are not equipped with much cognitive capability, and simply act from a predetermined set of actions. Our research has shown that the introduction of cognitive capabilities, such as intention recognition, commitment, apology, forgiveness, and revenge, separately and jointly, reinforce the emergence of cooperation in populations, comparatively to their absence. We then prospect future work concerned with adding guilt. In particular, we show: • how learning to recognize intentions and committing resolve cooperation dilemmas; • the evaluation of two strategies in the emergence of cooperation in groups, viz., avoidance versus restriction; • the role of apology in committed versus commitment-free repeated interactions; • how apology and forgiveness evolve to resolve failures in cooperative agreements; • the role that guilt may play to prime apology and forgiveness. © Springer International Publishing Switzerland 2016.},
references={Abeler, J., Calaki, J., Ree, K., Basek, C., The power of apology (2010) Econ. Lett, 107 (2), pp. 233-235; Axelrod, R., Hamilton, W.D., The evolution of cooperation (1981) Science, 211, pp. 1390-1396; Axelrod, R., (1984) The Evolution of Cooperation, , Basic Books, New York; Back, I., Flache, A., The adaptive rationality of interpersonal commitment (2008) Ration. Soc, 20, pp. 65-83; Buber, M., Guilt and guilt feelings (1957) Psychiatry, 20 (2), pp. 114-129; Cherry, T.L., McEvoy, D.M., Enforcing compliance with enviromental agreements in the absence of strong institutions: An experimental analysis (2013) Environ. Resour. Econ, 54 (1), pp. 63-77; Cullough, M.E., Kurzban, R., Tabak, B.A., Evolved mechanisms for revenge and forgiveness (2011) Human Agression and Violence: Causes, Manisfestations, and Consequences, , Shaver, P.R., Mikulincer, M. (eds.), American Psychological Association, Washington; Cushman, F.A., Macendoe, O., The coevolution of punishment and prosociality among learning agents (2009) Proceedings of 31St Annual Conference of the Cognitive Science Society, , Cognitive Science Society, Austin, TX; Damasio, A., (1994) Descartes’s Error, , Avon, New York; Fehr, E., Gachter, S., Altruistic punishment in humans (2002) Nature, 415, pp. 137-140; Fessler, D.M.T., Haley, K.J., (2012) The Strategy of Affect: Emotions in Human Cooperation. Genetic and Cultural Evolution of Cooperation, , The MIT Press, Cambridge; Fischbacher, U., Utikal, V., On the acceptance of apologies (2013) Games Econ. Behav, 82, pp. 592-608; Fischer, K.W., Tangney, J.P., Self-conscious emotions and the affect revolution: Framewok and introduction (1995) The Self-Conscious Emotions: Shame, Guilt, Embarrassment, and Pride, , Fischer, K.W., Tangney, J.P. (eds.), Guilford Press, New York; Frank, R., (1988) Passions within Reason: The Strategic Role of The Emotions, , W. W. Norton, New York; Han, T.A., (2013) Intention Recognition, Commitments and Their Roles in the Evolution of Cooperation: From Artificial Intelligence Techniques to Evolutionary Game Theory Models. SAPERE, , Springer, Berlin; Han, T.A., Pereira, L.M., State-of-the-art of intention recognition and its use in decision making (2013) AI Commun, 26 (2), pp. 237-246; Han, T.A., Pereira, L.M., Lenaerts, T., Avoiding or restricting defectors in public goods games? (2015) J. R. Soc. Interface, 12 (103); Han, T.A., Pereira, L.M., Santos, F.C., Intention recognition promotes the emergence of cooperation (2011) Adapt. Behav, 19, pp. 264-279; Han, T.A., Pereira, L.M., Santos, F.C., Corpus-based intention recognition in cooperation dilemmas (2012) Artif. Life, 18 (4), pp. 365-383; Han, T.A., Pereira, L.M., Santos, F.C., The emergence of commitments and cooperation (2012) Proceedings of 11Th International Conference on Autonomous Agents and Multiagent Systems; Han, T.A., Pereira, L.M., Santos, F.C., Intention recognition, commitment, and the evolution of cooperation (2012) Proceedings of IEEE Congress on Evolutionary Computation; Han, T.A., Pereira, L.M., Santos, F.C., Lenaerts, T., Good agreements make good friends (2013) Nat. Sci. Rep, 3 (2695); Han, T.A., Pereira, L.M., Santos, F.C., Lenaerts, T., Emergence of cooperation via intention recognition, commitment, and apology—a research summary (2015) AI Commun, 28; Han, T.A., Pereira, L.M., Santos, F.C., Lenearts, T., Why is it so hard to say sorry: The evolution of apology with commitments in the iterated prisoner’s dilemma (2013) IJCAI 2013, pp. 177-183. , AAAI Press; Han, T.A., Santos, F.C., Lenaerts, T., Pereira, L.M., Synergy between intention recognition and commitments in cooperation dilemmas (2015) Nat. Sci. Rep, 5 (9312); Han, T.A., Saptawijaya, A., Pereira, L.M., Moral reasoning under uncertainty (2012) Proceedings of 18Th International Conference on Logic for Programming, Artificial Intelligence and Reasoning (LPAR), LNCS, 7180, pp. 212-227. , Springer; Hofbauer, J., Sigmund, K., (1998) Evolutionary Games and Population Dynamics, , Cambridge University Press, New York; Ketelaar, T., Au, W.T., The effect of feeling guilt on the behaviour of uncooperative individuals in repeated social bargaining games: An affect as information interpretation of the role of emotion in social interaction (2003) Cogn. Emot, 17 (3); Lewis, M., Thinking and feeling—the elephant’s tail (1990) Thinking and Problem Solving in the Developmental Process: International Perspectives, , Maher, C.A., Schwebel, M., Fagley, N.S. (eds.), Erlbaum, NJ; Mameli, M., The role of emotions in ecological and practical rationality (2004) Emotion Evolution and Rationality, , Oxford University Press, Oxford; Martinez-Vaquero, L.A., Cuesta, J.A., Evolutionary stability and resistance to cheating in an indirect reciprocity model based on reputation (2013) Phys. Rev. E, 87 (5); Martinez-Vaquero, L.A., Cuesta, J.A., Spreading of intolerance under economic stress: Results from a reputation-based model (2014) Phys. Rev. E, 90 (2); Martinez-Vaquero, L.A., Han, T.A., Pereira, L.M., Lenaerts, T., Apology and forgiveness evolve to resolve failures in cooperative agreements (2015) Nat. Sci. Rep, 5 (10639); McCullough, M.E., (2008) Beyond Revenge, the Evolution of the Forgiveness Instinct, , Jossey-Bass, San Fransisco; McCullough, M.E., Pedersen, E.J., Tabak, B.A., Carter, E.C., Conciliatory gestures promote forgiveness and reduce anger in humans (2014) Proc. Natl. Acad. Sci. U.S.A, 111, pp. 11211-11216; Nesse, R.M., (2001) Evolution and the Capacity for Commitment, , Russell Sage, New York; Niedenthal, P.M., Tangney, J.P., Gavanski, I., If only I werent” versus “If only I hadn’t”: Distinguishing shame and guilt in counterfactual thinking (1994) J. Pers. Soc. Psychol., 67, pp. 585-595; Nowak, M.A., Sigmund, K., Tit for tat in heterogeneous populations (1992) Nature, 355, pp. 250-253; Nowak, M.A., Five rules for the evolution of cooperation (2006) Science, 314 (5805), pp. 1560-1563; Ohtsubo, Y., Watanabe, E., Do sincere apologies need to be costly? Test of a costly signaling model of apology (2009) Evolution and Human Behavior, 30 (2), pp. 114-123; Okamoto, K., Matsumura, S., The evolution of punishment and apology: An iterated prisoner’s dilemma model (2000) Evol. Ecol, 14, pp. 703-720; Pereira, L.M., Evolutionary tolerance (2012) Philosophy and Cognitive Science—Western & Eastern Studies. SAPERE, pp. 263-287. , Magnani,L., Ping, L. (eds.), Springer, Berlin; Pereira, L.M., Software sans emotions butwith ethical discernment (2016) Morality and Emotion: (Un)Conscious Journey to Being, , Silva, S.G. (ed.), Routledge, London; Pereira, L.M., Saptawijaya, A., Modelling morality with prospective logic (2011) Machine Ethics, pp. 398-421. , Anderson, M., Anderson, S.L. (eds.), Cambridge University Press, New York; Pereira, L.M., Saptawijaya, A., Abduction and beyond in logic programming with application to morality (2015) Journal of Logics and Their Applications, , http://goo.gl/yhmZzy, Accepted at Frontiers of Abduction, a special issue of IfCoLog; Pereira, L.M., Saptawijaya, A., Bridging two realms of machine ethics (2015) Rethinking Machine Ethics in the Age of Ubiquitous Technology, , White, J.B., Searle, R. (eds.), IGI Global, Pennsylvania; Pope, A., (1711) An Essay on Criticism, Part II, , Lewis, W. Russel Street, Covent Garden; Rawls, J., (1971) A Theory of Justice, , Harvard University Press, Cambridge; Saptawijaya, A., Pereira, L.M., The potential of logic programming as a computational tool to model morality (2015) A Construction Manual for Robots’ Ethical Systems: Requirements, Methods, Implementations,Cognitivetechnologies, , Trappl, R. (ed.), Springer, NewYork; Schneider, F., Weber, R.A., Long-term commitment and cooperation (2013) Tech. Rep.Working Paper Series, , University of Zurich, Department of Economics; Sigmund, K., (2010) The Calculus of Selfishness, , Princeton University Press, Princeton; Smith, N., (2008) I was Wrong: Themeanings of Apologies, 8. , Cambridge University Press, New York; Sterelny, K., (2012) The Evolved Apprentice, , MIT Press, Cambridge; Takaku, S., Weiner, B., Ohbuchi, K., A cross-cultural examination of the effects of apology and perspective taking on forgiveness (2001) J. Lang. Soc. Psychol, 20, pp. 144-166; Tangney, J.P., Dearing, R., (2002) Shame and Guilt, , Guilford Press, New York; Tangney, J.P., Stuewig, J., Malouf, E.T., Youman, K., Communicative functions of shame and guilt (2013) Cooperation and Evolution, , Sterelny, K., Joyce, R., Calcott, B., Fraser, B. (eds.), The MIT Press, Cambridge; Trivers, R.L., The evolution of reciprocal altruism (1971) Q. Rev. Biol, 46, pp. 35-57; Tzeng, J.Y., Toward a more civilized design: Studying the effect of computers that apologize (2004) Int. J. Hum.-Comput. Stud, 61 (3), pp. 319-345; Utz, S., Matzat, U., Snijders, C., On-line repotation systems: The effects of feedback comments and reactions on building and rebuilding trust in on-line auctions (2009) Int. J. Electron. Commer, 13 (3), pp. 95-118; Winikoff, M., Implementing commitment-based interactions (2007) Proceedings of 6Th International Conference on Autonomous Agents and Multiagent Systems; Wooldridge, M., Jennings, N.R., The cooperative problem-solving process (1999) J. Log. Comput, 9 (4), pp. 563-592; Zahavi, A., Mate selection—a selection for a handicap (1975) J. Theo. Biol, 53 (1), pp. 205-214; Zahavi, A., (1977) The Handicap Principle: A Missing Piece of Darwin’s Puzzle, , Oxford University Press, Oxford},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Briggs2012238,
author={Briggs, G. and Scheutz, M.},
title={Investigating the effects of robotic displays of protest and distress},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2012},
volume={7621 LNAI},
pages={238-247},
doi={10.1007/978-3-642-34103-8_24},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868679205&doi=10.1007%2f978-3-642-34103-8_24&partnerID=40&md5=6cc0ef1c64968b9b9516b57eab9f439c},
abstract={While research in machine ethics has investigated mechanisms for making artificial agents' decisions more ethical, there is currently not work investigating adaptations to human-robot interaction (HRI) that can promote ethical behavior on the human side. We present the first results from HRI experiments showing that verbal protests and affective displays can promote ethical behavior in human subjects. © 2012 Springer-Verlag.},
keywords={Artificial agents;  Ethical behavior;  Human subjects, Philosophical aspects;  Robotics, Behavioral research},
references={Kahn, P., Ishiguro, H., Gill, B., Kanda, T., Freier, N., Severson, R., Ruckert, J., Shen, S., Robovie, you'll have to go into the closet now: Children's social and moral relationships with a humanoid robot (2012) Developmental Psychology, 48, pp. 303-314; Wallach, W., Robot minds and human ethics: The need for a comprehensive model of moral decision making (2010) Ethics of Information Technology, 12, pp. 243-250; Arkin, R., (2009) Governing Lethal Behavior: Embedding Ethics in a Hybrid Deliberative/reactive Robot Architecture, , Technical Report GIT-GVU-07-11, Georgia Institute of Technology; Takayama, L., Groom, V., Nass, C., I'm sorry, dave: I'm afraid i won't do that: Social aspect of human-agent conflict (2009) Proceedings of the 27th International Conference on Human Factors in Computing Systems, ACM SIGCHI, pp. 2099-2107; Ogawa, K., Bartneck, C., Sakamoto, D., Kanda, T., Ono, T., Ishiguro, H., Can an android persuade you? (2009) Proceedings of the 18th IEEE International Symposium on Robot and Human Interactive Communication, pp. 516-521. , IEEE; Siegel, M., Breazeal, C., Norton, M., Persuasive robotics: The influence of robot gender on human behavior (2009) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 2563-2568. , IEEE; Rose, R., Scheutz, M., Schermerhorn, P., Towards a conceptual and methodological framework for determining robot believability (2010) Interaction Studies, 11 (2), pp. 314-335; Nass, C., Moon, Y., Machines and mindlessness: Social responses to computers (2000) Journal of Social Issues, 56 (1), pp. 81-103; Nass, C., Etiquette equality: Exhibitions and expectations of computer politeness (2004) Communications of the ACM, 47 (4), pp. 35-37; Dennett, D., Intentional systems (1971) The Journal of Philosophy, 68 (4), pp. 87-106; Zeng, Z., Pantic, M., Roisman, G., Huang, T., A survey of affect recognition methods: Audio, visual, and spontaneous expressions (2009) IEEE Transactions on Pattern Analysis and Machine Intelligence, 31 (1), pp. 39-58; Turkle, S., Relational artifacts/children/elders: The complexities of cybercompanions (2005) Toward Social Mechanisms of Android Science, pp. 62-73. , Cognitive Science Society; Bartneck, C., Verbunt, M., Mubin, O., Mahmud, A.A., To kill a mockingbird robot (2007) Proceedings of the ACM/IEEE International Conference on Human-Robot Interaction, pp. 81-87. , ACM; Bartneck, C., Van Der Hoek, M., Mubin, O., Mahmud, A.A., 'daisy, daisy, give me your answer do!': Switching off a robot (2007) Proceedings of the ACM/IEEE International Conference on Human-Robot Interaction, pp. 217-222. , ACM},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Torrance2011115,
author={Torrance, S.},
title={Machine ethics and the idea of a more-than-human moral world},
journal={Machine Ethics},
year={2011},
volume={9780521112352},
pages={115-137},
doi={10.1017/CBO9780511978036.008},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926952373&doi=10.1017%2fCBO9780511978036.008&partnerID=40&md5=74654987d1eef8025c113f5c07ef74ec},
abstract={“We are the species equivalent of that schizoid pair, Mr Hyde and Dr Jekyll; we have the capacity for disastrous destruction but also the potential to found a magnificent civilization. Hyde led us to use technology badly; we misused energy and overpopulated the earth, but we will not sustain civilization by abandoning technology. We have instead to use it wisely, as Dr Jekyll would do, with the health of the Earth, not the health of people, in mind.” –Lovelock 2006: 6–7. Introduction. In this paper i will discuss some of the broad philosophical issues that apply to the field of machine ethics. ME is often seen primarily as a practical research area involving the modeling and implementation of artificial moral agents. However this shades into a broader, more theoretical inquiry into the nature of ethical agency and moral value as seen from an AI or information-theoretical point of view, as well as the extent to which autonomous AI agents can have moral status of different kinds. We can refer to these as practical and philosophical ME respectively. Practical ME has various kinds of objectives. Some are technically well defined and relatively close to market, such as the development of ethically responsive robot care assistants or automated advisers for clinicians on medical ethics issues. Other practical ME aims are more long term, such as the design of a general purpose ethical reasoner/advisor – or perhaps even a “genuine” moral agent with a status equal (or as equal as possible) to human moral agents. © Cambridge University Press 2011.},
keywords={Philosophical aspects, Ethics issues;  Moral agents;  Reasoner;  Theoretical points, Autonomous agents},
references={Abram, D., (1996) The Spell of the Sensuous: Perception and Language in a More-Than- Human World, , NY: Random House; Aleksander, I., (2005) The World in My Mind, My Mind in the World: Key Mechanisms of Consciousness in Humans, Animals and Machines. Thorverton, Exeter: Imprint Academic; Bostrom, N., When machines outsmart humans (2000) Futures, 35 (7), pp. 759-764; Bostrom, N., The future of human evolution (2004) Death and Anti- Death: Two Hundred Years after Kant; Fifty Years after Turing, pp. 339-371. , C. Tandy, ed., Palo Alto, CA: Ria U.P; Bostrom, N., The ethics of superintelligent machines (2005) Symposium on Cognitive, Emotive and Ethical Aspects of Decisionmaking in Humans and Artificial Intelligence, , I. Smit, W.Wallach, and G.Lasker, InterSymp 05, Windsor, Ont: IIAS Press; Calverley, D., Android science and the animal rights movement: Are there analogies? (2005) Proceedings of Cogsci-2005 Workshop. Cognitive Science Society, pp. 127-136. , Stresa, Italy; Curry, P., (2006) Ecological Ethics: An Introduction, , Cambridge: Polity Press; De Jaegher, H., Social understanding through direct perception? Yes, by interacting (2008) Consciousness and Cognition, 18, pp. 535-542; De Jaegher, H., Di Paolo, E., Participatory sense-making: An enactive approach to social cognition (2007) Phenomenology and the Cognitive Sciences, 6 (4), pp. 485-507; De Waal, F., (2006) Primates and Philosophers: How Morality Evolved, , Oxford: Princeton U.P; Dennett, D., Why you can’t make a computer that feels pain (1978) Brainstorms: Philosophical Essays on Mind and Psychology, pp. 190-232. , Cambridge, MA: MIT Press; Dennett, D., The practical requirements for making a conscious robot (1998) Brainchildren: Essays on Designing Minds, pp. 153-170. , D. Dennett, London: Penguin Books; Di Paolo, E., Autopoiesis, adaptivity, teleology, agency (2005) Phenomenology and the Cognitive Sciences, 4, pp. 97-125; Dietrich, E., After the humans are gone.’ (2007) J. Experimental and Theoretical Art. Intell, 19 (1), pp. 55-67; Ernste, H., The pragmatism of life in poststructuralist times (2004) Environment and Planning A, 36, pp. 437-450; Floridi, L., Artificial intelligence’s new frontier: Artificial companions and the fourth revolution (2008) Metaphilosophy, 39 (4-5), pp. 651-655; Floridi, L., Information ethics, its nature and scope (2008) Moral Philosophy and Information Technology, pp. 40-65. , J. Van den Hoven and J. Weckert, eds., Cambridge: Cambridge U.P; Franklin, S., (1995) Artificial Minds, , Boston, MA: MIT Press; Frey, R.G., (1980) Interests and Rights: The Case against Animals, , Oxford: Clarendon Press; Gallagher, S., The practice of mind: Theory, simulation or primary interaction? (2001) Journal of Consciousness Studies, 8 (5-7), pp. 83-108; Gallagher, S., Direct perception in the intersubjective context (2008) Consciousness and Cognition, 17, pp. 535-543; Goertzel, B., Ten years to a positive singularity (if we really, really try) (2006) Talk to Transvision 2006, , http://www.goertzel.org/papers/tenyears.htm, Helsinki, Finland; Haikonen, P., (2003) The Cognitive Approach to Conscious Machines, , Thorverton, Devon: Imprint Academic; Holland, O., (2003) Machine Consciousness. Special Issue of Journal of Consciousness Studies, 10 (4-5); Jonas, H., (1996) The Phenomenon of Life: Toward a Philosophical Biology, , Evanston, Ill: Northwestern U.P. (originally published by Harper & Row N.Y. in 1996); Joy, B., Why the future doesn’t need us (2000) Wired, 8 (4). , www.wired.com/wired/archive/8.04/joy_pr.html; Kurzweil, R., One half of an argument (2001) The Edge, , http://www.edge.org/3rd_culture/kurzweil/kurzweil_index.html, (Response to Lanier 2000, 8.4.01; Kurzweil, R., (2005) The Singularity is Near: When Humans Transcend Biology, , NY: Viking Press; Kant, I., (1997) Lectures on Ethics, , P. Heath and J.B. Schneewind, eds. Cambridge: Cambridge U.P; Lachat, M., Playing god’ and the construction of artificial persons (2004) Symposium on Cognitive, Emotive and Ethical Aspects of Decision-Making in Humans and Artificial Intelligence, Intersymp 04, , I. Smit, W. Wallach and G. Lasker, eds., Windsor, Ont: IIAS Press; Lanier, J., One half a manifesto (2000) The Edge, , http://www.edge.org/3rd_culture/lanier/lanier_index.html; Leopold, A., A land ethic (1948) A Sand County Almanac with Essays on Conservation from round River, , New York: Oxford U.P; Lovelock, J., (1979) Gaia: A New Look at Life on Earth, , Oxford: Oxford U.P; Lovelock, J., (2006) The Revenge of Gaia: Why the Earth is Fighting Back, and How We Can Still save Humanity, , London: Allen Lane; Maturana, H., Varela, F., (1980) Autopoiesis and Cognition: The Realization of The Living, , Dordrecht, Holland: D. Reidel Publishing; Midgley, M., (1978) Beast and Man: The Roots of Human Nature, , Ithaca, N.J.: Cornell U.P; Moor, J., The nature, importance and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Moravec, H., (1988) Mind Children: The Future of Robot and Human Intelligence, , Cambridge, MA: Harvard U.P; Naess, A., The shallow and the deep, long-range ecology movements (1973) Inquiry, 16, pp. 95-100; Naess, A., Sessions, G., Basic principles of deep ecology (1984) Ecophilosophy, 6, pp. 3-7; Regan, T., (1983) The Case for Animal Rights, , Berkeley: University of California Press; Singer, P., (1977) Animal Liberation, , London: Granada; Sparrow, R., Killer robots (2007) Applied Philosophy, 24 (1), pp. 62-77; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Minds and Machines, 16 (2), pp. 141-161; Sylvan, R., Bennett, D., (1994) The Greening of Ethics: From Human Chauvinism to Deep- Green Theory, , Cambridge: White Horse Press; Thompson, E., (2007) Mind in Life: Biology, Phenomenology and the Sciences of Mind, , Cambridge, MA: Harvard U.P; Torrance, S., Towards an ethics for epersons (2000) Proc. AISB’00 Symposium on AI, Ethics And, , Quasi-) Human Rights, University of Birmingham; Torrance, S., Two conceptions of machine phenomenality (2007) Journal of Consciousness Studies, 14 (7); Torrance, S., Ethics, consciousness and artificial agents (2008) AI & Society, 22 (4); Torrance, S., (2009) Will Robots have Their Own Ethics?”, , Philosophy Now, April issue; Torrance, S., Clowes, R., Chrisley, R., Machine consciousness: Embodiment and imagination (2007) Special Issue of Journal of Consciousness Studies, 14 (4); Trevarthen, C., Reddy, V., Consciousness in infants (2007) The Blackwell Companion to Consciousness, pp. 41-57. , M. Velmans and S. Schneider, eds., Oxford: Blackwell & Co; Vinge, V., The coming technological singularity: How to survive in the post- human era (1993) Whole Earth Review, p. 77; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford: Oxford U.P; Wilson, E.O., (1984) Biophilia, , Cambridge, MA: Harvard U.P; Wilson, E.O., (1994) The Diversity of Life, , Harmondsworth: Penguin; Wright, R., (1994) The Moral Animal: Evolutionary Psychology and Everyday Life, , N.Y.: Pantheon Books; Yudkowsky, (2001) Creating Friendly AI, , www.singinst.org/upload/CFAI.html; Yudkovsky, Cognitive biases potentially affecting judgement of global risks (2008) Global Catastrophic Risks, pp. 91-119. , N. Bostrom and M. Cirkovic, eds., Oxford: Oxford U.P},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Weng20101919,
author={Weng, Y.-H.},
title={Beyond robot ethics: On a legislative consortium for social robotics},
journal={Advanced Robotics},
year={2010},
volume={24},
number={13},
pages={1919-1926},
doi={10.1163/016918610X527220},
note={cited By 7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77958604002&doi=10.1163%2f016918610X527220&partnerID=40&md5=0a4feffd020fe877941c244111551b61},
abstract={As robots are increasingly integrated into human society, associated problems will resemble or merge with those in other fields - we can refer to this phenomenon as the 'robot sociability problem'. In this paper, the author first analyzes the dynamic relationship between robot ethics, robotics and robot law, and then proposes a 'practical robots' approach for solving the robot sociability problem. As this approach is based on legal regulations, the author posits that a functional platform such as a 'legislative consortium for social robotics' is crucial at the initial stage for social robotics development. In conclusion, the author discusses how a legislative consortium for social robotics will be a useful approach for solving the robot sociability problem, especially emerging structural legislative problems that are related to autonomous robots. © 2010 Koninklijke Brill NV, Leiden and The Robotics Society of Japan.},
author_keywords={Robot ethics;  robot law;  robot policy;  social robotics;  social system design},
keywords={Autonomous robot;  Human society;  Initial stages;  Legal regulation;  Social robotics;  Social systems, Laws and legislation;  Machine design;  Robotics, Robots},
references={Veruggio, G., The birth of roboethics (2005) IEEE Int. Conf. on Robotics and Automation Workshop on Roboethics, , presented at Barcelona, Invited Talk; (2006) Roboethics Roadmap Release 1.1, , Unsigned Editorial European Robotics Research Network, Haverlee; Sim, H.B., Establishing a Korean robot ethics charter (2007) IEEE Int. Conf. on Robotics and Automation Workshop on Roboethics, , presented at Rome, Invited Talk; (2005) Robot Policy Middle Report - May 2005 Version, , Robot Policy Council Japan Ministry of Economy, Trade and Industry, Tokyo (in Japanese); (2007) Safety Guidelines for Next-Generation Robots, , Unsigned Editorial Japan Ministry of Economy, Trade and Industry, Tokyo (in Japanese); Weng, Y.H., Chen, C.H., Sun, C.T., The legal crisis of next generation robots: On safety intelligence (2007) Proc. 11th Int. Conf. on Artificial Intelligence and Law, pp. 205-209. , Palo Alto, CA; Sociability, , http://en.wiktionary.org/wiki/sociability; (2009) A Roadmap for US Robotics - From Internet to Robotics, , Unsigned Editorial Computing Community Consortium, Washington, DC; Weng, Y.H., Chen, C.H., Sun, C.T., Toward the human-robot co-existence society: On safety intelligence for next generation robots (2009) Int. J. Social Robotics, 1, pp. 267-282; http://www.iaea.org/About/index.html; http://www.w3.org/Consortium/mission.html; Weng, Y.H., Toward the human-robot co-existence society: On legislative consortium for social robotics (2009) IEEE Int. Conf. on Robotics and Automation Workshop on Service Robots in Urban Environments: Legal and Safety Issues, , presented at Kobe, Invited Talk; Blech, J., The future of war: Attack of the killer robots (2007) Spiegel Online Int., , http://www.spiegel.de/international/world/0,1518,500140,00.html; (2010) Robot Safety Standards Planned, , http://www.asahi.com/english/TKY201001260395.html, Unsigned Editorial; Sato, T., Moving object sensor technology for security and safety (2007) CREST Annual Research Report, , Japan Science and Technology Agency, Tokyo (in Japanese); Zyga, L., (2009) Living Safely with the Robots, Beyond Asimov's Laws, , http://www.physorg.com/news164887377.html, PhysOrg.com},
document_type={Article},
source={Scopus},
}

@ARTICLE{Etzioni2017174,
author={Etzioni, A. and Etzioni, O.},
title={The ethics of robotic caregivers},
journal={Interaction Studies},
year={2017},
volume={18},
number={2},
pages={174-190},
doi={10.1075/is.18.2.02etz},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038403756&doi=10.1075%2fis.18.2.02etz&partnerID=40&md5=756cc085f92d245f4a1f69fc2eba6aa2},
abstract={As Artificial Intelligence technology seems poised for a major take-off and changing societal dynamics are creating a high demand for caregivers for elders, children, and those infirmed, robotic caregivers may well be used much more often. This article examines the ethical concerns raised by the use of AI caregivers and concludes that many of these concerns are avoided when AI caregivers operate as partners rather than substitutes. Furthermore, most of the remaining concerns are minor and are faced by human caregivers as well. Nonetheless, because AI caregivers' systems are learning systems, an AI caregiver could stray from its initial guidelines. Therefore, subjecting AI caregivers to an AI-based oversight system is proposed to ensure that their actions remain both legal and ethical.},
author_keywords={Artificial Intelligence;  Caregivers;  Human-machine interaction;  Machine ethics},
references={(2014) Robots for the Elderly, , http://www.aljazeera.com/programmes/thecure/2014/06/robots-elderly-201469144119851480.html, June 10; Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge: Cambridge University Press; Bohannon, J., The synthetic therapist (2015) Science, 349 (6247), pp. 250-251; Bostrom, N., When machines outsmart humans (2014) CNN, , http://www.cnn.com/2014/09/09/opinion/bostrom-machine-superintelligence/index.html, September 8; Coeckelbergh, M., Health care, capabilities, and AI Assistive Technologies (2010) Ethical Theory and Moral Practice, 13 (2), pp. 181-190; D'Mello, A., Rise of the humans: Intelligence amplification will make us as smart as the Machines (2015) The Conversation, , http://theconversation.com/rise-of-the-humansintelligence-amplification-will-make-us-as-smart-as-the-machines-44767, October 12; Emspak, J., How a machine learns prejudice (2016) The Scientific American, , https://www.scientificamerican.com/article/how-a-machine-learns-prejudice, December 29; (2016) Artificial Intelligence (AI), , http://academic.eb.com/EBchecked/topic/37146/artificial-intelligence, Encyclopaedia Britannica, Britannica Academic. Encyclopædia Britannica Inc. Web, Accessed 5 July 2016; Etzioni, A., Etzioni, O., Keeping AI legal (2016) Vanderbilt Journal of Entertainment and Technology L Aw, , http://ssrn.com/abstract=2726612, Forthcoming; Etzioni, A., Etzioni, O., Killer robots won't doom humanity, but our fears of AI might (2016) Quartz, , http://qz.com/691286/ethics-bots-could-soothe-fears-about-aitaking-control-of-humanity, May 24; Feil-Seifer, D., Mataric, M., Ethical principles for socially assistive robotics (2011) IEEE Robotics & Automation Magazine, 18 (1), pp. 24-31. , Special issue on Roboethics, Veruggio, J. Solis and M. Van der loos; Fisher, M., Dennis, L., Webster, M., Verifying autonomous systems (2013) Communications of the ACM, 56 (9), pp. 84-93; Hawking, S., Tegmark, M., Wilczek, F., Russell, S., Transcending complacency on superintelligent machines (2014) The Huffington Post, , http://www.huffingtonpost.com/stephen-hawking/artificial-intelligence_b_5174265.html, June 19; MacCargar, B., (2005) Watts, Heat and Light: Measuring the Heat Output of Different Lamps, , http://www.reptileuvinfo.com/html/watts-heat-lights-lamp-heat-output.html, January; Markoff, J., (2015) Machines of Loving Grace: The Quest for Common Ground between Humans and Robots, , 1st ed.. New York, NY: ECCO, an imprint of HarperCollins Publishers; Mataric, M.J., Eriksson, J., Feil-Seifer, D.J., Winstein, C.J., Socially assistive robotics for post-stroke rehabilitation (2007) Journal of NeuroEngineering and Rehabilitation, 4 (1), p. 5; Mayer-Schönberger, V., Cukier, K., (2014) Big Data: A Revelution That Will Transform How We Live, Work and Think, , London: John Murray Publishers; Humanoid. Merriam-webster, N. D. Web, , Merriam-Webster.com, Accessed 6 June 2016; Robot. Merriam-webster, N. D. Web, , Merriam-Webster.com, Accessed 6 June 2016; Nakajima, H., Yamada, R., Brave, S., Morishima, Y., Nass, C., Kawaji, S., The functionality of human-machine collaboration systems - Mind model and social behavior (2003) SMC'03 Conference Proceedings. 2003 IEEE International Conference on Systems, Man and Cybernetics, 3, pp. 2381-2387; Price, R., Microsoft is deleting its AI chatbot's incredibly racist tweets (2016) Business Insider, , http://www.businessinsider.com/microsoft-deletes-racist-genocidal-tweetsfrom-ai-chatbot-tay-2016-3?r=UK&IR=T, March 24; Reese, H., Why Microsoft's Tay AI Bot went wrong (2016) Tech Republic, , http://www.techrepublic.com/article/why-microsofts-tay-ai-bot-went-wrong, March 24; Rheingold, H., (1985) Tools for Thought: The History and Future of Mind-expanding Technology, , Cambridge, Massachusetts: MIT Press; Rosenberg, T., Depressed? Try therapy without the therapist (2015) The New York Times, , http://opinionator.blogs.nytimes.com/2015/06/19/depressed-try-therapy-without-thetherapist, June 19; Sharkey, N., The ethical Frontiers of Robotics (2008) Science, 322, pp. 1800-1801; Sharkey, N., Sharkey, A., Artificial Intelligence and natural magic (2006) Artificial Intelligence Review, 25, pp. 9-19; Sharkey, N., Sharkey, A., The crying shame of robot nannies: An ethical appraisal (2010) Interaction Studies, 11 (2), pp. 161-190; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics and Information Technology, 14, pp. 27-40; Shea, S., (2006) Improving Medication Adherence: How to Talk with Patients About Their Medications, , Philadelphia, Pa: Lippincott Williams & Wilkins; Sparrow, R., The March of robot dogs (2002) Ethics and Information Technology, 4, pp. 305-318; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Minds and Machines; Sullins, J.P., When is a robot a moral agent? (2011) Machine Ethics, , M. Anderson & S. L. Anderson Eds, Cambridge: Cambridge University Press; Turkle, S., (2010) Alone Together: Why We Expect More from Technology and Less from Each Other, , New York: Basic Books; Turkle, S., The tethered self: Technology reinvents intimacy and solitude (2011) Continuing Higher Education Review, 75, pp. 28-31; Van Wynsberghe, A., Designing robots for care: Care centered value-sensitive data (2013) Science and Engineering Ethics, 19, pp. 407-433; Wallach, W., Allen, A., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford: Oxford University Press; Winfield, A.F., Blum, C., Liu, W., Towards an ethical robot: Internal models, consequences and ethical action selection (2014) Conference Towards Autonomous Robotic Systems, pp. 85-96. , Springer International Publishing},
document_type={Article},
source={Scopus},
}

@BOOK{VanWynsberghe20161,
author={Van Wynsberghe, A.},
title={Healthcare robots: Ethics, design and implementation},
journal={Healthcare Robots: Ethics, Design and Implementation},
year={2016},
pages={1-152},
doi={10.4324/9781315586397},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086063393&doi=10.4324%2f9781315586397&partnerID=40&md5=d65b9683ccc3f254b60dfeb5b8869f12},
abstract={This study deals with an underexplored area of the emerging technologies debate: robotics in the healthcare setting. The author explores the role of care and develops a value-sensitive ethical framework for the eventual employment of care robots. Highlighting the range of positive and negative aspects associated with the initiative to design and use care robots, it draws out essential content as a guide to future design both reinforcing this study's contemporary relevance, and giving weight to its prescriptions. The book speaks to, and is meant to be read by, a range of disciplines from science and engineering to philosophers and ethicists. © Aimee van Wynsberghe 2015. All rights reserved.},
references={Akrich, M., The de-scription of technical objects (1992) Shaping Technology/Building Society: Studies in Sociotechnical Change, pp. 205-224. , In W. E. Bijker and J. Law (eds), Cambridge, MA: MIT Press; Albrechtslund, A., Ethics and technology design (2007) Ethics and Information Technology, 9 (1), pp. 63-72; Anderson, M., Anderson, S., Machine Ethics: Creating an Ethical Intelligent Agent (2007) AI Magazine, 28 (4); Anderson, M., Anderson, S., Robot be good: A call for ethical autonomous machines (2010) Scientific American, 303 (4), pp. 15-24; Argall, B., Billard, A., A Survey of Tactile Human-Robot Interactions (2010) Robotics and Autonomous Systems, 58 (10), pp. 1159-1176; Arras, K., Cerqui, D., Do we want to share our lives and bodies with robots? (2005) A 2000 People Survey.; Asaro, P., What should we want from a robot ethic? (2006) International Review of Information Ethics, 6, pp. 8-16; Asaro, P., Modeling the moral user (2009) Technology and Society Magazine, IEEE, 28 (1), pp. 20-24; Barras, C., Useful, loveable and unbelievably annoying (2009) The New Scientist, pp. 22-23; Beauchamp, T.L., Childress, J.F., (2001) Principles of Biomedical Ethics, , Oxford/New York: Oxford University Press; Beetz, M., Klank, U., Kresse, I., Robotic Roommates Making Pancakes (2011) Humanoid Robots (Humanoids), 2011 11th IEEE-RAS International Conference on; Bekey, G., Current Trends in Robotics: Technology and Ethics (2011) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 17-34. , In P. Lin, K. Abney and G. Bekey (eds), Cambridge, MA: MIT Press; Bensalem, S., Gallien, M., Ingrand, F., Designing Autonomous Robots (2009) IEEE Robotics and Automation Magazine, 16 (1), pp. 67-77; Bicchi, A., Peshkin, M., Colgate, J., Safety for Physical Human-Robot Interaction (2008) Springer Handbook of Robotics, pp. 1335-1348. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Bijker, W.E., Law, J., (1992) Shaping Technology/Building Society: Studies in Sociotechnical Change, , Cambridge, MA: MIT Press; Billard, A., Calinon, S., Dillmann, R., Schaal, S., Robot Programming by Demonstration (2008) Springer Handbook of Robotics, pp. 1371-1394. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Bischoff, R., Graefe, V., HERMES - an Intelligent Humanoid Robot Designed and Tested for Dependability (2003) Springer Tracts in Advanced Robotics: Experimental Robotics VIII, 5, pp. 64-74; Borenstein, J., Pearson, Y., Robot Caregivers: Ethical Issues across the Human Life (2011) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 251-266. , In P. Lin, K. Abney and G. Bekey (eds), Cambridge, MA: MIT Press; Borgmann, A., (1987) Technology and the Character of Contemporary Life: A Philosophical Inquiry, , Chicago: University of Chicago Press; Breazeal, C.L., (2004) Designing Sociable Robots, , Cambridge, MA: MIT Press; Breazeal, C., Aryananda, L., Recognition of Affective Communicative Intent in Robot-Directed Speech (2002) Autonomous Robots, 12 (1), pp. 83-104; Breazeal, C., Takanishi, A., Kobayashi, T., Social Robots that Interact with People (2008) Springer Handbook of Robotics, pp. 1349-1370. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Brey, P., Artifacts as Social Agents (2005) Inside the Politics of Technology Agency and Normativity in the Co-production of Technology and Society, pp. 61-84. , In H. Harbers (ed.), Amsterdam: Amsterdam University Press; Brey, P., Values in Technology and Disclosive Computer Ethics (2010) The Cambridge Handbook of Information and Computer Ethics, pp. 41-58. , In L. Floridi (ed.), Cambridge: Cambridge University Press; Brey, P., From Moral Agents to Moral Factors: The Structural Ethics Approach (2014) Anticipatory Ethics for Emerging Technologies., pp. 1-13. , In P. Brey (2012). NanoEthics; Brock, O., Kuffner, J., Xiao, J., Motion for Manipulation Tasks (2008) Springer Handbook of Robotics, pp. 615-646. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Buber, M., (1958) I and Thou, , New York: Scribner; Buss, M., Beetz, M., (2010) CoTeSys - Cognition for Technical Systems, , Kunstliche Intelligenz; Butterfield, J., (2003) Collins English Dictionary, , Glasgow: HarperCollins; Callon, M., The Sociology of an Actor-Network: The Case of the Electric Vehicle (1986) Mapping the Dynamics of Science and Technology: Sociology of Science in the Real World, pp. 19-24. , In M. Callon, J. Law and A. Rip (eds), Basingstoke: Macmillan; Campion, G., Chung, W., Wheeled Robots (2008) Springer Handbook of Robotics, pp. 391-410. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Capek, K., Selver, P., (1923) R.U.R, , ( Rossum's Universal Robots): A Fantastic Melodrama. Garden City, NY: Doubleday, Page & Co; Capurro, R., Ethics and Robotics (2009) Ethics and Robotics, pp. 117-123. , In R. Capurro and M. Nagenborg (eds), Heidelberg; [Amsterdam]: AKA; IOS Press; Capurro, R., Nagenborg, M., (2009) Ethics and Robotics, , Heidelberg; [Amsterdam]: AKA; IOS Press; Chen, T., King, C.-H., Thomaz, A., Kemp, C., Touched by a Robot: An Investigation of Subjective Responses to Robot-initiated Touch (2011) Human-Robot Interaction (HRI), 2011 6th ACM/IEEE International Conference on; Chung, W., Fu, L., Hsu, S., Motion Control (2008) Springer Handbook of Robotics, pp. 133-160. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Coeckelbergh, M., Health care, capabilities, and AI assistive technologies (2010) Ethical Theory and Moral Practice, 13 (2), pp. 181-190; Cooley, M., From judgment to calculation (2007) AI & Society, 21 (4), pp. 395-409; Cooper, C., Selwood, A., Blanchard, M., Abuse of people with dementia by family carers: Representative cross sectional survey (2009) British Medical Journal, 338 (7694), pp. 583-585; Correia, M., Waitzberg, D., The impact of malnutrition on morbidity, mortality, length of hospital stay and costs evaluated through a multivariate model analysis (2003) Clinical nutrition ( Edinburgh, Scotland), 22 (3), pp. 235-239; Cotin, S., Delingette, H., Ayache, N., A hybrid elastic model for real-time cutting, deformations, and force feedback for surgery training and simulation (2000) VISUAL COMPUTER, 16, pp. 437-452; Cummings, M., Integrating ethics in design through the value-sensitive design approach (2006) Science and Engineering Ethics, 12, pp. 701-715; Daniilidis, K., Eklundh, J., 3-D Vision and Recognition (2008) Springer Handbook of Robotics, pp. 543-562. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Dautenhahn, K., Roles and functions of robots in human society - Implications from research in autism therapy (2003) Robotica, 21, pp. 443-452; Dautenhahn, K., Werry, I., Towards interactive robots in autism therapy: Background, motivation and challenges (2004) Pragmatics & Cognition, 12 (1), pp. 1-35; Dautenhahn, K., Woods, S., Kaouri, C., What is a Robot Companion - Friend, Assistant or Butler? (2005) Intelligent Robots and Systems, 2005, pp. 1192-1197. , (IROS 2005). 2005 IEEE/RSJ International Conference on; Davies, A., Snaith, P., Mealtime problems in a continuing-care hospital for the elderly (1980) Age and Ageing, 9 (2), pp. 100-105; Decker, M., Caregiving robots and ethical reflection: The perspective of interdisciplinary technology assessment (2008) AI & Society, 22 (3), pp. 315-330; Den Hoven, J., ICT and Value Sensitive Design (2007) International Federation for Information Processing - Publications - IFIP, 233, pp. 67-72; der, H.van., Reinkensmeyer, D., Rehabilitation and Health Care Robotics (2008) Springer Handbook of Robotics, pp. 1223-1252. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Dietsch, J., People meeting robots in the workplace (2010) IEEE Robotics and Automation Magazine, 17 (2), pp. 15-16; Dubberly, H., How do you design? (2004) A Compendium of Models, , http://www.dubberly.com/articles/how-do-you-design.html; Engelberger, J.F., (1989) Robotics in Service, , Cambridge, MA: MIT Press; Evanoff, B.A., Use of mechanical patient lifts decreased musculoskeletal symptoms and injuries among health care workers (2004) Injury Prevention, 10 (4), pp. 212-216; Facility, T.R., Our Journey in 2008-9: Annual Report. (2008), http://www.torontorehab.com/About-Us/Corporate-Publication/2008-2009/hospital.asp; Feng, P., Feenberg, A., Thinking about Design: Critical Theory of Technology and the Design Process (2008) Philosophy and Design: From Engineering to Architecture, pp. 105-118. , In P. E. Vermaas (ed.), Dordrecht: Springer; Feron, E., Johnson, E., Aerial Robotics (2008) Springer Handbook of Robotics, pp. 1009-1030. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Floridi, L., Sanders, J., On the Morality of Artificial Agents (2004) Minds and Machines, 14 (3), pp. 349-379; Fong, T., Nourbakhsh, I., Dautenhahn, K., A survey of socially interactive robots (2003) Robotics and Autonomous Systems, 42 (3), p. 143; Franklin, S., Graesser, A., Is it an Agent, or Just a Program? (1997) A Taxonomy for Autonomous Agents. Lecture Notes in Computer Science, 1193, p. 21; Franklin, S., Graesser, A., Olde, B., (1996) Virtual Mattie - an Intelligent Clerical Agent, , AAA Symposium on Embodied Cognition and Action, Cambridge, MA; Fraser, N., (1989) Unruly Practices: Power, Discourse, and Gender in Contemporary Social Theory, , Minneapolis: University of Minnesota Press; Friedman, B., Kahn, P.H., Borning, A., (2006) Value Sensitive Design and Information Systems, , In P. Zhang and D. Galletta (eds), Human-Computer Interaction and Management Information Systems: Foundations. M.E. Sharpe; Friedrich, H., Münch, S., Dillmann, R., Robot Programming by Demonstration (RPD): Supporting the Induction by Human Interaction (1996) Machine Learning, 23 (2-3), pp. 163-189; Gadow, S.A., Nurse and Patient: The Caring Relationship (2002) Caring, Curing, Coping: Nurse, Physician, and Patient Relationships, pp. 31-43. , In A. Bishop and J. Scudder (eds), Tuscaloosa, AL: University of Alabama Press; Gill, S., Socio-ethics of interaction with intelligent interactive technologies (2008) AI & Society, 22 (3), pp. 283-300; Gilligan, C., (1982) In a Different Voice: Psychological Theory and Women's Development, , Cambridge, MA: Harvard University Press; Goetz, J., Kiesler, S., Cooperation with a Robotic Assistant (2002) CHI Conference on Human Factors in Computing Systems, pp. 578-579; Hannaford, B., Okamura, A., Haptics (2008) Springer Handbook of Robotics, pp. 719-758. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Harbers, H., Mol, A., Stollmeyer, A., Food Matters: Arguments for an Ethnography of Daily Care (2002) Theory, Culture & Society, 19 (5), p. 207; Haselager, W.F., Robotics, philosophy and the problems of autonomy (2005) Pragmatics and Cognition, 13 (3), pp. 515-532; Hayashi, T., Control method of robot suit HAL working as operator's muscle using biological and dynamical information (2005) IEEE, pp. 3063-3068; Heinzmann, J., Zelinsky, A., 3-D Facial Pose and Gaze Point Estimation Using a Robust Real-time Tracking Paradigm (1998) Proceedings. Third IEEE International Conference on, pp. 142-147. , Automatic Face and Gesture Recognition, 1998; Hertzberg, J., Chatila, R., AI Reasoning Methods for Robotics (2008) Springer Handbook of Robotics, pp. 207-228. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Hirano, T., Generation of Human Care Behaviors by Human-Interactive Robot RI-MAN (2007) IEEE, pp. 3128-3129; Hirose, S., Yamada, H., Snake-Like Robots (2009) IEEE Robotics and Automation Magazine, 16 (1), pp. 88-98; Hofmann, B., Why ethics should be part of health technology assessment (2008) International Journal of Technology Assessment in Health Care, 24 (4), pp. 423-429; Hosoda, K., Takuma, T., Nakamoto, A., Hayashi, S., Biped robot design powered by antagonistic pneumatic actuators for multi-modal locomotion (2008) Robotics and Autonomous Systems, 56 (1), pp. 46-53; Howcroft, D., Mitev, N., Wilson, M., What We May Learn From the Social Shaping of Technology Approach (2004) Social Theory and Philosophy for Information Systems, pp. 329-371. , In J. Mingers and L. Willcocks (eds), West Sussex, UK: John Wiley and Sons; Introna, L., Disclosive Ethics and Information Technology: Disclosing Facial Recognition Systems (2005) Ethics and Information Technology, 7 (2), pp. 75-86; Jain, A.K., Li, S.Z., (2005) Handbook of Face Recognition, , New York: Springer Science+Business Media, Inc; Jecker, N.S., Self, D.J., Separating Care and Cure: An Analysis of Historical and Contemporary Images of Nursing and Medicine (1991) Journal of Medicine and Philosophy, 16 (3), pp. 285-306; Jelsma, J., Designing "moralized" products: Theory and Practice (2006) User Behavior and Technology Development: Shaping Sustainable Relations between Consumers and Technologies, pp. 221-231. , In P. Verbeek and A. Slob (eds), Dordrecht: Springer; Kahn, R.E., Swain, M.J., Prokopowicz, P.N., Firby, R.J., Gesture Recognition Using the Perseus Architecture (1996) Computer Vision and Pattern Recognition, IEEE, pp. 734-741; Kajita, S., Espiau, B., Legged Robots (2008) Springer Handbook of Robotics, pp. 361-390. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Kavraki, L., LaValle, S., Motion Planning (2008) Springer Handbook of Robotics, pp. 109-132. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Kawamoto, H., Sankai, Y., (2002) Power Assist System HAL-3 for Gait Disorder Person, pp. 196-203. , London, UK: Springer-Verlag; Kawasaki, H., Komatsu, T., Uchiyama, K., Kurimoto, T., (1999) Dexterous Anthropomorphic Robot Hand with Distributed Tactile Sensor: Gifu Hand II, , Mechatronics, IEEE/ASME Transactions on; Kazerooni, H., Exoskeletons for Human Performance Augmentation (2008) Springer Handbook of Robotics, pp. 773-798. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Kemp, C., Fitzpatrick, P., Hirukawa, H., Humanoids (2008) Springer Handbook of Robotics, pp. 1307-1334. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Kidd, C.D., (2008) Designing for Long-term Human-Robot Interaction and Application to Weight Loss, , PhD dissertation; Kidd, C.D., Breazeal, C.L., Designing a Sociable Robot System for Weight Maintenance (2006) IEEE, pp. 253-257; Kim, K.H., Bang, S.W., Kim, S.R., Emotion recognition system using short-term monitoring of physiological signals (2004) Medical & Biological Engineering & Computing, 42, pp. 419-427; Kiran, A.H., Responsible Design (2011) A Conceptual Look at Interdependent Design-Use Dynamics. Philosophy & Technology, 1; Koggel, C.M., (1998) Perspectives on Equality: Constructing a Relational Theory, , Lanham, MD: Rowman & Littlefield Publishers; Koughnett, J.V., Jayaraman, S., Eagleson, R., Are there advantages to robotic-assisted surgery over laparoscopy from the surgeon's perspective? (2009) Journal of Robotic Surgery, 3, pp. 79-82; Krapp, K., (2002) Activities of Daily Living Evaluation, , In Encyclopedia of Nursing & Allied Health. Detroit, MI: Gale Group, Inc; Kubrick, S., Clarke, A.C., Dullea, K., (1968) 2001, A Space Odyssey, , Burbank, CA: Warner Home Video; Kunze, L., Roehm, T., Beetz, M., Towards Semantic Robot Description Languages (2011) Robotics and Automation (ICRA), 2011 IEEE International Conference on, pp. 5589-5595; Latour, B., Where Are the Missing Masses? The Sociology of a Few Mundane Artifacts (1992) Shaping Technology/Building Society: Studies in Sociotechnical Change, pp. 225-258. , In W. Bijker and J. Law (eds), Cambridge, MA: MIT Press; Lauwers, T.B., Kantor, G.A., Hollis, R.L., A Dynamically Stable Singlewheeled Mobile Robot with Inverse Mouse-ball Drive (2006) Robotics and Automation, 2006. ICRA 2006. Proceedings 2006 IEEE International Conference on, pp. 2884-2889; Le, C.A., Poole, E.S., Wyche, S.P., Values as Lived Experience: Evolving Value Sensitive Design in Support of Value Discovery (2009), pp. 1141-1150. , New York: ACM; Leininger, M., Leininger's theory of nursing: Culture care diversity and universality (1988) Nursing Science Quarterly, 2, pp. 11-20; Lin, P., Abney, K., Bekey, G., (2011) Robot Ethics: The Ethical and Social Implications of Robotics, , Cambridge, MA: MIT Press; Little, M.O., Care: From Theory to Orientation and Back (1998) The Journal of Medicine and Philosophy, 23 (2), pp. 190-209; Lofquist, L.H., Dawis, R., Values as second-order needs in the theory of work adjustment (1978) Journal of Vocational Behavior, 12 (1), pp. 12-19; Lytle, M., Robot care bears for the elderly (2002) BBC, , http://news.bbc.co.uk/2/hi/science/nature/1829021.stm; MacDorman, K.F., Ishiguro, H., The uncanny advantage of using androids in cognitive and social science research (2006) Interaction Studies, 7 (3), pp. 297-337; Manders-Huits, N., What Values in Design? The Challenge of Incorporating Moral Values into Design (2011) Science and Engineering Ethics, 17 (2), pp. 271-287; Maslow, A.H., (1970) Motivation and Personality, , New York: Harper & Row; Maurer, M., (2007) Some Ideas on ICT as it Influences the Future, , NEC Technology Forum, Tokyo; Max-Neef, M., Economic growth and quality of life: A threshold hypothesis (1995) Ecological Economics, 15 (2), pp. 115-118; Mayer, C., Radig, B., Sosnowski, S., Kuhnlenz, K., Towards Robotic Facial Mimicry: System Development and Evaluation (2010) Proceedings - IEEE International Workshop on Robot and Human Interactive Communication, pp. 198-203; Melchiorri, C., Kaneko, M., Robot Hands (2008) Springer Handbook of Robotics, pp. 345-360. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Metzler, T., Lewis, L., Ethical Views, Religious Views, and Acceptance of Robotic Applications: A Pilot Study. (2008) Association for the Advancement of Artificial Intelligence, pp. 15-22. , www.aaai.org; Minato, T., Shimada, M., Ishiguro, H., Itakura, S., Development of an Android Robot for Studying Human-Robot Interaction (2004) Lecture Notes in Computer Science, 3029, pp. 424-434; Minato, T., Yoshikawa, Y., Noda, T., CB2: A Child Robot with Biomimetic Body for Cognitive Developmental Robotics (2007) Humanoid Robots, 2007 7th IEEE-RAS International Conference on, pp. 557-562; Minguez, J., Lamiraux, F., Laumond, J., Motion Planning and Obstacle Avoidance (2008) Springer Handbook of Robotics, pp. 827-852. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Mitcham, C., (2005) Encyclopedia of Science, Technology and Ethics, , Detroit, MI: Macmillan Reference; Mitra, P., Niemeyer, G., Model-mediated Telemanipulation (2008) The International Journal of Robotics Research, 27 (2), pp. 253-262; Mol, A., (2010) Care and its values: Good food in the nursing home, , In A. Mol, I. Moser and A. Pols (eds), Care in Practice: On Tinkering in Clinics, Homes and Farms. Bielefeld: Transcript Verlag; Mol, A., Moser, I., Pols, J., (2010) Care in Practice: On Tinkering in Clinics, Homes and Farms, , Bielefeld; Piscataway, NJ: Transcript; Distributed in North America by Transaction Publishers; Moor, J.H., Is Ethics Computable? (1995) Metaphilosophy, 26 (1-2), p. 1; Moor, J.H., Machine Ethics - The Nature, Importance, and Difficulty of Machine Ethics (2006) IEEE Intelligent Systems, 21 (4), p. 18; Moravec, H.P., (1999) Robot: Mere Machine to Transcendent Mind, , New York: Oxford University Press; Mori, M., Bukimi no tani: The uncanny valley (1970) Energy, 7 (4), pp. 33-35; Morin, P., Samson, C., Motion Control of Wheeled Mobile Robots (2008) Springer Handbook of Robotics, pp. 799-826. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Mowshowitz, A., Technology as excuse for questionable ethics (2008) AI & Society, 22 (3), pp. 271-282; Mutlu, B., Forlizzi, J., Robots in Organizations: The Role of Workflow, Social, and Environmental Factors in Human-robot Interaction (2008) Human-Robot Interaction (HRI), 2008, pp. 287-94. , 3rd ACM/IEEE International Conference; Nathan, L.P., Friedman, B., Klasnja, P., Envisioning Systemic Effects on Persons and Society throughout Interactive System Design (2008), pp. 1-10. , USA: ACM; Nedelsky, J., Reconceiving Rights and Constitutionalism (2008) Journal of Human Rights, 7 (2), pp. 139-173; Neven, L., "But obviously not for me": Robots, laboratories and the defiant identity of elder test users (2010) Sociology of Health and Illness, 32 (2), pp. 335-347; Niemeyer, G., Preusche, C., Hirzinger, G., Telerobotics (2008) Springer Handbook of Robotics, pp. 741-758. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Nissenbaum, H., How computer systems embody values (2001) Computer, 34 (3), pp. 120-119; Noddings, N., (1984) Caring, a Feminine Approach to Ethics & Moral Education, , Berkeley: University of California Press; Noddings, N., (2002) Starting at Home Caring and Social Policy, , Berkeley: University of California Press; Nordmann, A., Rip, A., Mind the gap revisited (2009) Nature Nanotechnology, 4 (5), pp. 273-274; (1999) Standard for the Therapeutic Nurse-client Relationship: For Registered Nurses and Registered Practical Nurses in Ontario: Standards of Practice, , The College of Nurses of Ontario; (1999) The Ethical Framework for Nurses in Ontario: Standards of Practice, , The College of Nurses of Ontario; Nussbaum, M.C., (2000) Women and Human Development: The Capabilities Approach, , Cambridge/New York: Cambridge University Press; Oh, J.-H., Hanson, D., Kim, W.-S., Design of Android Type Humanoid Robot Albert HUBO (2006) Intelligent Robots and Systems, 2006 IEEE/RSJ International Conference on, pp. 1428-1433; Oosterhof, N., (2005) Thinking Machines that Feel: The Role of Emotions in Artificial Intelligence Research, , Master's thesis, University of Twente; Oosterlaken, I., Design for development: A capability approach (2009) Design Issues, 25 (4), pp. 91-102; Orpwood, R., Adlam, T., Evans, N., Chadd, J., Evaluation of an assisted-living smart home for someone with dementia (2008) Journal of Assistive Technologies, 2 (2), pp. 13-21; Payne, B.K., Cikovic, R., Empirical Examination of the Characteristics, Consequences, and Causes of Elder Abuse in Nursing Homes (1995) Journal of Elder Abuse & Neglect, 7 (4), pp. 61-74; Pellegrino, E.D., The Virtuous Physician, and the Ethics of Medicine (1985) Virtue and Medicine: Explorations in the Character of Medicine, 1. , In E. Shelp (ed.), Dordrecht: D. Reidel Publishing Company; Picard, R.W., (2000) Affective Computing, , Cambridge, MA: MIT Press; Pillemer, K., Moore, D.W., Highlights from a Study of Abuse of Patients in Nursing Homes (1990) Journal of Elder Abuse & Neglect, 2 (1-2), pp. 5-29; Pineau, J., Montemerlo, M., Pollack, M., Towards robotic assistants in nursing homes: Challenges and results (2003) Robotics and Autonomous Systems, 42 (3), p. 271; Podnieks, E., (1990) National Survey on Abuse of the Elderly in Canada, , Toronto, Ontario: Ryerson Polytechnical Institute; Pollack, M.E., Brown, L., Colbry, D., Pearl: A mobile robotic assistant for the elderly (2002) AAAI 2002, Workshop on Automation as Caregiver: The Role of Intelligent Technology in Elder Care, pp. 85-92; Pols, A.J., (2004) Good Care: Enacting a Complex Ideal in Long-term Psychiatry, , Utrecht: Trimbos-instituut; Prattichizzo, D., Trinkle, J., Grasping (2008) Springer Handbook of Robotics, pp. 671-700. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Rayman, R., Croome, K., Galbraith, N., Long-distance robotic telesurgery: A feasibility study for care in remote environments (2006) The International Journal of Medical Robotics + Computer Assisted Surgery, 2 (3), pp. 216-224; Rayman, R., Croome, K., Galbraith, N., Robotic telesurgery: A real-world comparison of ground- and satellite-based internet performance (2007) The International Journal of Medical Robotics + Computer Assisted Surgery, 3 (2), pp. 111-116; Razavi, S., (2007) The Political and Social Economy of Care in a Development Context: Conceptual Issues, Research Questions and Policy Options, , Geneva: United Nations Research Institute for Social Development; Reich, W.T., History of the notion of care (1995) Encyclopedia of Bioethics, pp. 219-331. , In W. T. Reich (ed.), New York/London: Macmillan; Simon & Schuster; Prentice Hall International; Roach, M.S., (1999) The Human Act of Caring: A Blueprint for the Health Professions, , Ottawa: Canadian Hospital Association Press; Robotics, A., Nao, the ideal partner for research and robotics classrooms. (2010), www.aldebaran-robotics.com/en; Ruddick, S., (1995) Maternal Thinking: Toward a Politics of Peace [with a new preface], , Boston: Beacon Press; Rudnick, A., A meta-ethical critique of care ethics (2001) Theoretical Medicine and Bioethics, 22 (6), pp. 505-517; Russell, S.J., Norvig, P., (1995) Artificial Intelligence: A Modern Approach, , Englewood Cliffs, NJ: Prentice Hall; Saenz, A., Incredible TUG Robots Automate Delivery in Hospitals. (2010) Singularity Hub, , http://singularityhub.com/2010/06/06/incredible-tug-robotsautomate-delivery-in-hospitals-video/; Sakamoto, D., Kanda, T., Ono, T., Android as a Telecommunication Medium with a Human-like Presence (2007), pp. 193-200. , USA: ACM; Sandelowski, M., Exploring the gender-technology relation in nursing (1997) Nursing Inquiry, 4 (4), pp. 219-228; Santoro, M., Marino, D., Tamburrini, G., Learning robots interacting with humans: From epistemic risk to responsibility (2008) AI & Society, 22 (3), pp. 301-314; Satoh, H., Kawabata, T., Sankai, Y., Bathing Care Assistance with Robot Suit HAL (2009) IEEE, pp. 498-503; Schoenhofer, S., A Framework for Caring in a Technologically Dependent Nursing Practice Environment (2001) In Advancing Technology, Caring and Nursing, pp. 3-11. , Rozzano Loscin ed., Westport, CT: Auburn House; Schulz, D., Burgard, W., Fox, D., Cremers, A.B., People Tracking with Mobile Robots Using Sample-Based Joint Probabilistic Data Association Filters (2003) The International Journal of Robotics Research, 22 (2), pp. 99-116; Sen, A., (1985) Commodities and Capabilities, , Amsterdam/New York: Elsevier; Sharkey, N., Sharkey, A., The Rights and Wrongs of Robot Care (2011) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 267-282. , In P. Lin, K. Abney and G. Bekey (eds), Cambridge, MA: MIT Press; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics and Information Technology, 14 (1), pp. 27-40; Shaw-Garlock, G., Looking Forward to Sociable Robots (2009) International Journal of Social Robotics, 1 (3), pp. 249-260; Shieh, M.Y., Lu, C.M., Chen, C.C., Design and Implementation of an Interactive Nurse Robot (2007) SICE, 2007 Annual Conference, pp. 2121-2125; Siciliano, B., Khatib, O., (2008) Springer Handbook of Robotics, , Berlin: Springer; Sidner, C.L., Dzikovska, M., A First Experiment in Engagement for Human-Robot Interaction in Hosting Activities (2005) Advances in Natural Multimodal Dialogue Systems, 30, pp. 55-76. , In J. C. J. van Kuppevelt, L. Dybkjær, N. O. Bernsen and N. Ide (eds), Netherlands: Springer; Silverstone, R., Hirsch, E., Morley, D., Information and communication technologies and the moral economy of the household (1992) Consuming Technologies: Media and Information in Domestic Spaces, pp. 15-31. , In R. Silverstone and E. Hirsch (eds), London: Routledge; Singer, P.W., (2009) Wired for War: The Robotics Revolution and Conflict in the Twentyfirst Century, , New York: Penguin Press; Smits, R., Leyten, J., den Hertog, P., Technology assessment and technology policy in Europe: New concepts, new goals, new infrastructures (1995) Policy Sciences, 28 (3), pp. 271-299; Soraker, J., When Does the Mind matter? The Strengths and Limitations of the Informational Level of Abstraction. Ethics and Information Technology., , (forthcoming); Sorensen, K., Domestication: The Enactment of Technology (2005) Domestication of Media and Technology, pp. 40-61. , In T. Berker, M. Hartmann, Y. Punie and K. Ward (ed.), Open University Press; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Minds and Machines, 16 (2), pp. 141-161; Stabell, A., Eide, H., Solheim, G.A., Nursing Older People: Nursing home residents' dependence and independence (2004) Journal of Clinical Nursing, 13 (6), pp. 677-686; Sullins, J., When is a robot a moral agent? (2006) International Review of Information Ethics, 6, pp. 23-30; Super, D.E., (1968) Work Values Inventory, , Boston: Houghton Mifflin; Sutton, R.S., Barto, A.G., (2010) Reinforcement learning: An introduction, , Cambridge, MA: MIT Press; Swierstra, T., Rip, A., Nano-ethics as NEST-ethics: Patterns of Moral Argumentation about New and Emerging Science and Technology (2007) NanoEthics, 1 (1), pp. 3-20; Tamburrini, G., Robot Ethics: A View from the Philosophy of Science (2009) Ethics and Robotics, pp. 11-22. , In R. Capurro and M. Nagenborg (eds), Heidelberg; [Amsterdam]: AKA; IOS Press; Tamura, T., Yonemitsu, S., Itoh, A., Is an entertainment robot useful in the care of elderly people with severe dementia? (2004) The Journals of Gerontology Series A: Biological Sciences and Medical Sciences, 59 (1), pp. M83-M85; Tenorth, M., (2011) Knowledge Processing for Autonomous Robots, , PhD dissertation, München: Universitätsbibliothek der TU München; Tenorth, M., Beetz, M., Knowledge Processing for Autonomous Robot Control (2012) In AAAI Spring Symposium: Designing Intelligent Robots.; Tenorth, M., Jain, D., Beetz, M., Knowledge Representation for Cognitive Robots. (2010) Kunstliche Intelligenz, 24 (3), pp. 233-240; Thaler, R.H., Sunstein, C.R., (2008) Nudge: Improving Decisions about Health, Wealth, and Happiness, , New Haven: Yale University Press; Thow-Hing, V.N., Torisson, K., Sarvadevabhatla, R.K., Cognitive Map Architecture: Facilitation of Human-Robot Interaction in Humanoid Robots (2009) IEEE Robotics and Automation Magazine, 16 (1), pp. 55-66; Thrun, S., Toward a Framework for Human-Robot Interaction (2004) Human- Computer Interaction, 19 (1), pp. 9-24; Thrun, S., Schulte, J., Rosenberg, C., Interaction with Mobile Robots in Public Places (2000) IEEE Intelligent Systems, pp. 7-11; Torrance, S., Ethics and consciousness in artificial agents (2008) AI & Society, 22 (4), pp. 495-521; Tronto, J., Creating Caring Institutions: Politics, Plurality, and Purpose (2010) Ethics and Social Welfare, 4 (2), pp. 158-171; Tronto, J.C., (1993) Moral Boundaries: A Political Argument for an Ethic of Care, , New York: Routledge; Turing, A.M., Computing machinery and intelligence (1950) Mind: A Quarterly Review of Psychology and Philosophy, 59 (236), p. 433; Turkle, S., (2011) Alone Together: Why We Expect More from Technology and Less from Each Other, , New York: Basic Books; Vallor, S., Carebots and caregivers: Sustaining the ethical ideal of care in the twenty-first century (2011) Philosophy and Technology, 24 (3), pp. 251-268; van de Poel, I., Values in engineering design (2009) Handbook of the Philosophy of Science. Volume 9: Philosophy of Technology and Engineering Sciences., , In A. Meijers (ed.), Oxford: Elsevier; van de Poel, I., Kroes, P., (2014) Can Technology Embody Values? In P, , Kroes and P.-P. Verbeek (eds), Moral Agency and Technical Artefacts. Dordrecht: Springer; van der Plas, A., Smits, M., Wehrmann, C., Beyond speculative robot ethics: A vision assessment study on the future of the robotic caretaker (2010) Accountability in Research, 17 (6), pp. 299-315; van Gorp, A., Van de Poel, I., Deciding on Ethical Issues in Engineering Design (2008) Philosophy and Design: From Engineering to Architecture, pp. 77-90. , In P. E. Vermaas (ed.), Dordrecht: Springer; van Wynsberghe, A., Designing robots for care: Care centered valuesensitive design. (2013) Science and Engineering Ethics, 19 (2), pp. 407-433; van Wynsberghe, A., A Method for Integrating Ethics into the Design of Robots. (2013) Industrial Robot, 40 (5), pp. 433-440; van Wynsberghe, A., (2014) To Delegate or not to Delegate: Care Robots, Moral Agency and Moral Responsibility, , Machine Ethics in the Context of Medical and Care Agents, conference proceedings, April; van Wynsberghe, A., Gastmans, C., Telesurgery: An ethical appraisal (2008) Journal of Medical Ethics, 34 (10); van Wynsberghe, A., Gastmans, C., Telepsychiatry and the meaning of in-person contact: A preliminary ethical appraisal (2009) Medicine, Health Care, and Philosophy, 12 (4), pp. 469-476; van Wynsberghe, A., Robbins, S., Ethicist as Designer: A pragmatic approach to ethics in the lab (2014) Science and Engineering Ethics, 20 (4), pp. 947-961; Vanlaere, L., Gastmans, C., A personalist approach to care ethics (2011) Nursing Ethics, 18 (2), pp. 161-173; Verbeek, P., Morality in Design; design ethics and the morality of technological artifacts (2008) Philosophy and Design: From Engineering to Architecture, pp. 91-102. , In P. E. Vermaas (ed.), Dordrecht: Springer; Verbeek, P.-P., (2005) What things Do: Philosophical Reflections on Technology, Agency, and Design, , Pennsylvania.: Pennsylvania State University Press; Verbeek, P.-P., Materializing Morality (2006) Science, Technology, & Human Values, 31 (3), pp. 361-380; Verbeek, P.-P., (2011) Moralizing Technology: Understanding and Designing the Morality of Things, , Chicago/London: The University of Chicago Press; Verkerk, M., The care perspective and autonomy (2001) Medicine, Health Care, and Philosophy, 4 (3), pp. 289-294; Verkerk, M.A., Busschbach, J.J.V., Karssing, E.D., Health-Related Quality of Life Research and the Capability Approach of Amartya Sen (2001) Quality of Life Research, 10 (1), pp. 49-55; Veruggio, G., Abney, K., Roboethics: The Applied Ethics for a New Science (2011) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 347-364. , In P. Lin, K. Abney and G. Bekey (eds), Cambridge, MA: MIT Press; Veruggio, G., Operto, F., Roboethics: A Bottom-up Interdisciplinary Discourse in the Field of Applied Ethics in Robotics (2006) International Review of Information Ethics, 6, pp. 3-8; Veruggio, G., Operto, F., Roboethics: Social and Ethical Implications of Robotics (2008) Springer Handbook of Robotics, pp. 1499-1524. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Villani, L., de Schutter, J., Force Control (2008) Springer Handbook of Robotics, pp. 161-186. , In B. Siciliano and O. Khatib (eds), Berlin: Springer; Vongsoasup, V., Mataric, M., Path Planning and Navigation for Geeves: A Tour-Guide/Greeter Robot.; Wada, K., Shibata, T., Saito, T., Psychological and Social Effects of One Year Robot Assisted Activity on Elderly People at a Health Service Facility for the Aged (2005) Robotics and Automation, 2005. ICRA 2005. Proceedings of the 2005 IEEE International Conference on, pp. 2785-2790; (2008) Walt Disney Home Entertainment.; Wallach, W., Robot minds and human ethics: The need for a comprehensive model of moral decision making (2010) Ethics and Information Technology, 12 (3), pp. 243-250; Wallach, W., Allen, C., (2010) Moral Machines: Teaching Robots Right from Wrong, , New York/Oxford: Oxford University Press; Wallach, W., Allen, C., Smit, I., Machine morality: Bottom-up and top-down approaches for modelling human moral faculties (2008) AI & Society, 22 (4), pp. 565-582; Wallach, W., Franklin, S., Allen, C., A conceptual and computational model of moral decision making in human and artificial agents (2010) Topics in Cognitive Science, 2 (3), pp. 454-485; Walters, M.L., Dautenhahn, K., Woods, S.N., Koay, K.L., Robotic Etiquette: Results from User Studies Involving a Fetch and Carry Task (2007) Human- Robot Interaction (HRI), 2007 2nd ACM/IEEE International Conference on, pp. 317-324; Weaver, K., Morse, J., Mitcham, C., Ethical sensitivity in professional practice: Concept analysis (2008) Journal of Advanced Nursing, 62 (5), pp. 607-618; Widdershoven, G., Technology and Care, from Opposition to Integration (2002) Between Technology and Humanity: The Impact of Technology on Health Care Ethics, pp. 35-48. , In C. Gastmans (ed.), Leuven: Leuven University Press; Wilson, M., Making nursing visible? Gender, technology and the care plan as script (2002) Information Technology & People, 15 (2), pp. 139-158; Wong, P.-H., Technology, Recommendation and Design: On Being a 'Paternalistic' Philosopher (2011) Science and Engineering Ethics, 19 (1), pp. 27-42; Wood, R., Fly, robot fly (2008) IEEE Spectrum, 45 (3), pp. 25-29; Wright, L., Hickson, M., Frost, G., Eating together is important: Using a dining room in an acute elderly medical ward increases energy intake (2006) Journal of Human Nutrition and Dietetics, 19 (1), pp. 23-26; Yoshiro, U., Shinichi, O., Yosuke, T., Childcare Robot PaPeRo is Designed to Play with and Watch over Children at Nursery, Kindergarten, School and at Home (2005) Development of Childcare Robot PaPeRo, pp. 1-11; Zaeh, M.F., Roesel, W., Bannat, A., Artificial Cognition in Production Systems (2010) IEEE Transactions on Automation Science and Engineering, 7 (3), pp. 1-27; Zhang, T., Zhu, B., Lee, L., Kaber, D., Service Robot Anthropomorphism and Interface Design for Emotion in Human-Robot Interaction (2008) IEEE, pp. 674-679},
document_type={Book},
source={Scopus},
}

@ARTICLE{Bentzen2016268,
author={Bentzen, M.M.},
title={The principle of double effect applied to ethical dilemmas of social robots},
journal={Frontiers in Artificial Intelligence and Applications},
year={2016},
volume={290},
pages={268-279},
doi={10.3233/978-1-61499-708-5-268},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992663804&doi=10.3233%2f978-1-61499-708-5-268&partnerID=40&md5=869945a19b46aeedd8cfc1383726fb83},
abstract={The introduction of social robots into society will require that they follow ethical principles which go beyond consequentialism. In this paper, I show how to apply the principle of double effect to solve an ethical dilemma involving robots studied by Alan Winfield and colleagues. The principle of double effect states conditions for ethically acceptable behavior when there are both positive and negative consequences of an action. I propose a formal semantics with actions, causes, intentions, and utilities based upon the work of Judea Pearl, John Horty, and others.With this formal semantics, the question of whether an action is permitted according to the principle of double effect is reduced to deciding whether a certain formula is true or otherwise. © 2016 The authors and IOS Press. All rights reserved.},
author_keywords={Formal semantics;  Logic;  Robot ethics;  The principle of double effect},
keywords={Formal methods;  Philosophical aspects;  Robotics;  Semantics, Double effects;  Ethical dilemma;  Ethical principles;  Formal Semantics;  Logic;  Robot ethics;  Social robots, Robots},
references={Winfield, A.Ft., Blum, C., Liu, W., Towards an ethical robot: Internal models, consequences and ethical action selection (2014) Advances in Autonomous Robotics Systems, pp. 85-96. , M. Mistry, A. Leonardis, M. Witkowski, and C. Melhuish, editors, Springer; Bringsjord, S., Taylor, J., The divine-command approach to robot ethics (2012) Patrick Lina, Keith Abney, and George A. Bekey, pp. 85-108. , editors, Robot Ethics: The Ethical and Social Implications of Robotics, MIT Press; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press; Arkin, R., (2009) Governing Lethal Behavior in Autonomous Robots, , CRC Press; Bentzen, M.M., The limits of logic-based inherent safety of social robots Philosophy and Engineering : Exploring Boundaries, Expanding Connections, , In Diane P. Michelfelder, Byron Newberry, and Qin Zhu, editors, Springer, forthcoming; Foot, P., The problem of abortion and the doctrine of double effect (1967) Oxford Review, 5, pp. 5-15; Thomson, J.J., The trolley problem (1985) The Yale Law Journal, 94, pp. 1395-1415; Bostrom, N., Ethical issues in advanced artificial intelligence (2003) Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, 2, pp. 12-17. , I. Smit, W. Wallach, and G. Lasker, editors, Int. Institute of Advanced Studies in Systems Research and Cybernetics; Mangan, J., An historical analysis of the principle of double effect (1949) Theological Studies, 10, pp. 41-61; Quinn, W., Actions, intentions, and consequences: The doctrine of double effect (1989) Philosophy and Public Affairs, 18, pp. 334-351; McIntyre, A., Doctrine of double effect (2014) The Stanford Encyclopedia of Philosophy, , Edward N. Zalta, editor, Winter 2014 edition; John, F., (2001) Horty. Agency and Deontic Logic, , Oxford University Press; Pearl, J., (2009) Causality: Models Reasoning and Inference, , Cambridge University Press, 2nd edition; Bentzen, M.M., (2010) Stit Iit and Deontic Logic for Action Types, , PhD thesis, Section for Philosophy and Science Studies, Roskilde University; Blackburn, P., De Rijke, M., Venema, Y., (2001) Modal Logic, , Cambridge University Press; Bentzen, M.M., Action type deontic logic (2014) Journal of Logic, Language and Information, 23, pp. 397-414},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Luxton2016255,
author={Luxton, D.D. and Anderson, S.L. and Anderson, M.},
title={Ethical Issues and Artificial Intelligence Technologies in Behavioral and Mental Health Care},
journal={Artificial Intelligence in Behavioral and Mental Health Care},
year={2016},
pages={255-276},
doi={10.1016/B978-0-12-420248-1.00011-8},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84967154017&doi=10.1016%2fB978-0-12-420248-1.00011-8&partnerID=40&md5=784e53963db78ecf0cfce1ac6b784998},
abstract={This chapter discusses ethics involved with the use of artificial intelligent technologies in behavioral and mental health care. A foundational overview of medical ethics and current ethical codes and guidelines that pertain to the use of technology is provided. Emerging ethical issues are then discussed along with specific recommendations to address these issues. Novel approaches to help with the design and testing of intelligent autonomous care providers, including methods for developing ethical principles and decision-making processes for autonomous artificial agents, are presented. © 2016 Elsevier Inc. All rights reserved.},
author_keywords={Ethical Turing test;  Ethics codes;  Machine ethics;  Privacy;  Safety},
references={Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12, pp. 251-261; (2014) ACA code of ethics, , http://www.counseling.org/Resources/aca-code-of-ethics.pdf; (1994) Opinion 1.02 - The relation of law and ethics, , http://www.ama-assn.org//ama/pub/physician-resources/medical-ethics/code-medical-ethics/opinion102.page; (2013) The principles of medical ethics with annotations especially applicable to psychiatry, , http://www.psych.org/File%20Library/Practice/Ethics%20Documents/principles2013--final.pdf, Retrieved from, Accessed 03.11.14; (2002) American psychological association ethical principles of psychologists and code of conduct, , http://www.apa.org/ethics/code2002.html, Retrieved from, American Psychiatric Association. Accessed 09.02.14; (2012) Telemedicine Practice Guidelines, , http://www.americantelemed.org/resources/telemedicine-practice-guidelines/telemedicine-practice-guidelines#.VXuTZflVhBc; Anderson, S.L., Machine metaethics (2011) Machine ethics, pp. 21-27. , Cambridge University Press, New York, NY, M. Anderson, S.L. Anderson (Eds.); Anderson, S.L., The unacceptability of Asimov's three laws of robotics as a basis for machine ethics (2011) Machine ethics, pp. 285-296. , Cambridge University Press, New York, NY, M. Anderson, S.L. Anderson (Eds.); Anderson, S.L., How machines might help us achieve breakthroughs in ethical theory and inspire us to behave better (2011) Machine ethics, pp. 285-296. , Cambridge University Press, New York, NY, M. Anderson, S.L. Anderson (Eds.); (2011) Machine ethics, , Cambridge University Press, New York, NY, M. Anderson, S.L. Anderson (Eds.); Anderson, M., Anderson, S.L., GenEth: A general ethical dilemma analyzer (2014) Proceedings of the twenty eighth AAAI conference on artificial intelligence, , Quebec City, Quebec, CA July 2014; Asimov, I., (1942) Runaround. Astounding science fiction, , Street and Smith Publications, Inc, New York; Asimov, I., (1976) The bicentennial man, , Doubleday, New York, NY; Bordin, E.S., The generalizability of the psychoanalytic concept of the workingalliance (1979) Psychotherapy: Theory Research & Practice, 16 (3), pp. 252-260; Calo, R., Robots and privacy (2011) Robot ethics: The ethical and social implications of robotics, , http://ssrn.com/abstract=1599189, MIT Press, Available from; Clarke, R., Asimov's Laws of Robotics: Implications for information technology (2011) Machine ethics, pp. 285-296. , Cambridge University Press, New York, NY, M. Anderson, S.L. Anderson (Eds.); Gillon, R., Medical ethics: Four principles plus attention to scope (1994) BMJ, 309, p. 184; Hofstadter, D.R., Preface 4 the ineradicable Eliza effect and its dangers, Epilogue (1996) Fluid concepts and creative analogies: Computer models of the fundamental mechanisms of thought, , Basic Books, New York; Lavrac, N., Dž;eroski, S., (1997) Inductive logic programming: Techniques and applications, , Ellis Harwood; Luxton, D.D., Recommendations for the ethical use and design of artificial intelligent care providers (2014) Artificial Intelligence in Medicine, 62; Luxton, D.D., Nelson, E., Maheu, M., A practitioner's guide to telemental health, , Washington, DC: American Psychological Association Books, in press; McCorduck, P., (1979) Machines who think, , W. H. Freeman, New York, 1st ed; Miller, K.W., It's not nice to fool humans (2010) IT Professional, 1, pp. 51-52; Moore, A., Intangible property: Privacy, power and information control (2005) Information ethics: Privacy, property, and power, , University of Washington Press, Seattle, WA, A. Moore (Ed.); Mori, M., The uncanny valley (1970) Energy, 7 (4), pp. 33-35; Parthemore, J.L., Whitby, B., What makes any agent a moral agent? Reflections on machine consciousness and moral agency (2013) International Journal of Machine Consciousness, 5 (105); Riek, L.D., Howard, D., A code of ethics for the human-robot interaction profession (2014) Proceedings of we robot, , http://robots.law.miami.edu/2014/wp-content/uploads/2014/03/a-code-of-ethics-for-the-human-robot-interaction-profession-riek-howard.pdf; Riek, L.D., Watson, R.N., The age of avatar realism: When seeing shouldn't be believing (2010) IEEE Robotics & Automation Magazine, 17 (4), pp. 37-42; Sullins, J.P., When is a robot a moral agent? (2011) Machine ethics, , Cambridge University Press, New York, NY, M. Anderson, S.L. Anderson (Eds.); Turkle, S., Authenticity in the age of digital companions (2007) Interaction Studies, 8 (3), pp. 501-517; Veruggio, G., (2007) EURON roboethics roadmap, , http://www.roboethics.org/index_file/Roboethics%20Roadmap%20Rel.1.2.pdf; Weizenbaum, J., (1976) Computer power and human reason: From judgment to calculation, , W. H. Freeman, San Francisco, CA},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Govindarajulu201585,
author={Govindarajulu, N.S. and Bringsjord, S.},
title={Ethical regulation of robots must be embedded in their operating systems},
journal={Cognitive Technologies},
year={2015},
volume={40},
pages={85-99},
doi={10.1007/978-3-319-21548-8_5},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948783973&doi=10.1007%2f978-3-319-21548-8_5&partnerID=40&md5=95f6cf111dbfe4fafc96de5640acea47},
abstract={The authors argue that unless computational deontic logics (or, for that matter, any other class of systems for mechanizing moral and/or legal principles) or achieving ethical control of future AIs and robots are woven into the operatingsystem level of such artifacts, such control will be at best dangerously brittle. © Springer International Publishing Switzerland 2015.},
author_keywords={Formal verification;  Future of AI;  Robot ethics},
keywords={Computation theory;  Formal verification;  Philosophical aspects;  Robots, Deontic Logic;  Legal principles;  Robot ethics;  System levels, Embedded systems},
references={Arkoudas, K., Bringsjord, S., Computers, justification, and mathematical knowledge (2007) Mind Mach, 17 (2), pp. 185-202. , http://kryten.mm.rpi.edu/ka_sb_proofs_offprint.pdf; Bringsjord, S., The logicist manifesto: At long last let logic-based ai become a field unto itself (2008) J. Appl. Log, 6 (4), pp. 502-525. , http://kryten.mm.rpi.edu/SB_LAI_Manifesto_091808.pdf; Bringsjord, S., Govindarajulu, N.S., Toward a modern geography of minds, machines, and math Philosophy and Theory of Artificial Intelligence, 5, pp. 151-165. , http://www.springerlink.com/content/hg712w4l23523xw5, Müller, V. C. (ed.), Studies in Applied Philosophy, Epistemology and Rational Ethics, vol., Springer, New York (2013); Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intell. Syst, 21 (4), pp. 38-44. , http://kryten.mm.rpi.edu/bringsjord_inference_robot_ethics_preprint.pdf; Bringsjord, S., Bringsjord, A., Bello, P., Belief in the singularity is fideistic (2013) The Singularity Hypothesis, pp. 395-408. , Eden, A., Moor, J., Søraker, J., Steinhart, E. (eds.), Springer, New York; Ferrucci, D., Lally, A., UIMA: An architectural approach to unstructured information processing in the corporate research environment (2004) Nat. Lang. Eng, 10, pp. 327-348; Ferrucci, D., Brown, E., Chu-Carroll, J., Fan, J., Gondek, D., Kalyanpur, A., Lally, A., Welty, C., Building Watson: An overview of the DeepQA project (2010) AI Mag, 31, pp. 59-79. , http://www.stanford.edu/class/cs124/AIMagzine-DeepQA.pdf; Fitting, M., Mendelsohn, R.L., (1998) First-Order Modal Logic, 277. , Kluwer, Dordrecht; Goble, L., (2001) The Blackwell Guide to Philosophical Logic, , Blackwell Publishing, Oxford; Govindarajulu, N.S., (2013) Uncomputable games: Games for crowdsourcing formal reasoning, , Ph. D. thesis, Rensselaer Polytechnic Institute; Greco, G., Greco, S., Zumpano, E., A logical framework for querying and repairing inconsistent databases (2003) IEEE Trans. Knowl. Data Eng, 15 (6), pp. 1389-1408; Hardegree, G., (2011) Introduction to modal logic, , http://people.umass.edu/gmhwww/511/text.htm, This is an on-line textbook available, as of February 2012; Klein, G., A formally verified OS kernel. Now what? (2010) Interactive Theorem Proving, 6172, pp. 1-7. , Kaufmann, M., Paulson, L. C. (eds.), Lecture Notes in Computer Science, vol., Springer, Berlin/Heidelberg; Klein, G., Elphinstone, K., Heiser, G., Andronick, J., Cock, D., Derrin, P., Elkaduwe, D., Winwood, S., seL4: Formal verification of an OS Kernel (2009) Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles, pp. 207-220. , SOSP '09, , ACM, New York; McNamara, P., Deontic logic (2010) The Stanford Encyclopedia of Philosophy, Fall 2010 edn, , http://plato.stanford.edu/entries/logic-deontic/chisholm.html, Zalta, E. (ed.), The section of the article discussing a dyadic system is; Mikhail, J., (2011) Elements of Moral Cognition: Rawls' Linguistic Analogy and the Cognitive Science of Moral and Legal Judgment, Kindle edn, , Cambridge University Press, Cambridge; Nute, D., Conditional logic (1984) Handbook of Philosophical Logic Volume II: Extensions of Classical Logic, pp. 387-439. , Gabay, D., Guenthner, F. (eds.), D. Reidel, Dordrecht; Schermerhorn, P., Kramer, J., Brick, T., Anderson, D., Dingler, A., Scheutz, M., DIARC: A testbed for natural human-robot interactions (2006) Proceedings of AAAI 2006 Mobile Robot Workshop; Si, M., Marsella, S., Pynadath, D., Modeling appraisal in theory of mind reasoning (2010) J. Agent Multi-Agent Syst, 20, pp. 14-31; Stickel, M.E., (2008) SNARK-SRI's new automated reasoning kit, , http://www.ai.sri.com/~stickel/snark.html, Retrieved on July 26, 2013},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Kernaghan2014295,
author={Kernaghan, K.},
title={Digital dilemmas: Values, ethics and information technology},
journal={Canadian Public Administration},
year={2014},
volume={57},
number={2},
pages={295-317},
doi={10.1111/capa.12069},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901912986&doi=10.1111%2fcapa.12069&partnerID=40&md5=4f18c21eaf93e37e074efe58282fe646},
abstract={In writings on public administration, the subject areas of values and ethics and of information technology (IT) have received substantial, but largely separate, attention. The public administration community can benefit by drawing on scholarship in the field of information and computer ethics and developing its own body of research with a view to sensitizing public servants to the effects of changes in IT on values and ethics. This article focuses on developments in the use of IT (for example, self-service technologies, Big Data, the Internet of Things) as a basis for assessing their implications for public sector values and ethics. Research is needed on the extent to which the values and ethics regimes of public organizations take account of the impact of changes in IT; the degree to which the various components of these regimes can foster sensitivity to the implications of these changes; and the significance for the public sector of such emerging ethical issues as robot ethics. Value conflicts and dilemmas arising from advances in digital technologies argue for vigorous measures to alert public servants to the technologies' impact. © The Institute of Public Administration of Canada/L'Institut d'administration publique du Canada 2014.},
references={Africa, C., Singapore trials real time bus condition update (2012), http://www.futuregov.asia/articles/2012/jun/12/singapore-trials-real-time-bus-condition-update, futureGOV: 12 June; (2010), http://publicaffairs.alberta.ca/pab_documents/GOASocialMediaPolicyPlusAppendix-approved.pdf, Alberta. Government of Alberta Social Media-Web 2.0 Policy; (2003) Embedding the APS Values, , Australia. Public Service Commission. Canberra: Commonwealth of Australia; Bellamy, H.M.J.D., (2005) Toronto Computer Leasing Inquiry. Report. Volume 2: Good Government, , Toronto: City of Toronto; Borins, S., Kernaghan, K., Brown, D., Bontis, N., Perri, Thompson, F., (2007) Digital State at the Leading Edge, , Toronto: University of Toronto Press; Brown, D., New information technologies in Canadian public administration (1997) New Public Management and Public Administration in Canada, pp. 93-112. , In, edited by Mohamed Charih and Arthur Daniels. Toronto: Institute of Public Administration of Canada; Brown, D., Information, technology and public administration (2010) Handbook of Canadian Public Administration, pp. 521-537. , In, edited by Christopher Dunn. Toronto: Oxford University Press. 2nd ed; Bynum, T., (2008), http://plato.stanford.edu/entries/ethics-computer, Computer and Information Ethics. Stanford Encyclopedia of Philosophy; (1990) The Renewal of the Public Service of Canada, , Canada. Ottawa: Supply and Services; (2012), http://open.gc.ca/open-ouvert/ap-patb-eng.asp, Canada. Canada's Action Plan on OPEN Government; (1996) A Strong Foundation, , Canada, Task Force on Public Service Values and Ethics. Ottawa: Canadian Centre for Management Development; (2005), http://www.cips.ca/?q=system/files/coe-frame.pdf, CIPS (Canadian Information Processing Society). Code of Ethics and Professional Conduct; Cribb, R., Government Internet habits revealed (2010), http://www.thestar.com/news/canada/2010/11/27/government_internet_habits_revealed.html, The Toronto Star. 27 November; Davis, K., (2012) Ethics of Big Data, , Sebastopol, CA: OReilly Books; Dimock, S., Al-Haim, M., MacSweeney, G., Manduca-Barone, A., Antonacci, A., (2013) Ethics and the Public Service: Trust, Integrity and Democracy, , Toronto: Nelson; (2009), http://ec.europa.eu/information_society/policy/rfid/documents/commiot2009.pdf, European Commission. (June). Internet of Things - An Action Plan for Europe. Brussels; (2012), http://europa.eu/rapid/press-release_IP-12-360_en.htm, European Commission. (April 12). Digital Agenda: Commission consults on rules for wirelessly connected devices - the "Internet of Things." Brussels; Floridi, L., Foundations of information ethics (2008) The Handbook of Information and Computer Ethics, pp. 3-24. , In Himma, Kenneth Einar and Herman T. Tavani, eds. Hoboken, New Jersey: John Wiley & Sons; Foster, A., Responsive web design: What is it and why should I care? (2012), http://responsivedesign.ca/blog/responsive-web-design-what-is-it-and-why-should-i-care, February 12). Responsive Web Design; Gotterbarn, D., Computer ethics: Responsibility regained (1991) National Forum: The Phi Beta Kappa Journal, 71, pp. 26-31; Harris, I., Jennings, R.C., Pullinger, D., Rogerson, S., Duquenoy, P., Ethical assessment of new technologies: a meta-methodology (2011) Journal of Information, Communication & Ethics in Society, 9 (1), pp. 49-64; Harrison, T., Guerrero, S., Burke, G.B., Cook, M., Cresswell, A., Helbig, N., Hrdinova, J., Pardo, T., Open government and e-government: Democratic challenges from a public value perspective (2012) Information Polity, 17 (2), pp. 1-15; Heintzman, R., Public-service values and ethics: Dead end or strong foundation? (2007) Canadian Public Administration, 50 (4), pp. 573-602; (2008) The Handbook of Information and Computer Ethics, , Himma, Kenneth Einar, and Herman T. Tavani (eds). Hoboken, New Jersey: John Wiley & Sons; Hood, C., A public management for all seasons? (1991) Public Administration, 69 (1), pp. 3-19; Howard, C., Phillips, S., Moving away from hierarchy: Do horizontality, partnerships and distributed governance really signify the end of accountability? (2012) New Public Management to New Political Governance, pp. 314-341. , In, edited by Herman Bakvis and Mark D. Jarvis. Montreal and Kingston: McGill-Queen's University Press; Johnson, D., (1985) Computer Ethics, , Englewood Cliffs, N.J.: Prentice-Hall; Jorgensen, T.B., Bozeman, B., Public values: An inventory (2007) Administration and Society, 39, pp. 354-381; Kernaghan, K., Shaking the foundation: New versus traditional public service values (1997) New Public Management and Public Administration in Canada, pp. 47-65. , In, edited by Mohamed Charih and Arthur Daniels. Toronto: Institute of Public Administration of Canada; Kernaghan, K., Integrating values into public service: The values statement as centerpiece (2003) Public Administration Review (US), 63 (6), pp. 711-719; Kernaghan, K., (2010) Clicks, Calls and Counters: Innovations in Municipal Service Delivery, , Toronto: Institute for Citizen-Centred Service; Kernaghan, K., (2012) Anywhere, Anytime, Any Device: Innovations in Public Sector Self-Service Delivery, , http://www.iccs-isac.org/research/publications-research/?lang=e, Toronto: Institute for Citizen-Centred Service; Kernaghan, K., Gunraj, J., Integrating information technology into public administration: Conceptual and practical considerations (2004) Canadian Public Administration, 47 (4), pp. 525-546; Kernaghan, K., Marson, B., Borins, S., (2000) The New Public Organization, , Toronto: Institute of Public Administration of Canada; Kernaghan, K., Langford, J., (2014) The Responsible Public Servant, , and 2nd ed. Toronto: Institute of Public Administration of Canada; Kraemer, F., van Overveld, K., Peterson, M., Is there an ethics of algorithms? (2011) Ethics and Information Technology, 13 (3), pp. 251-260; Kuriyan, R., Bailur, S., Gigler, B.-S., Park, K.R., (2011), http://www.iq.undp.org/img/Procurements/75642405-Technologies-for-Transparency-and-Accountability-Implications-for-ICT-Policy-and-Recommendations.pdf, Technologies for Transparency and Accountability: Implications for ICT Policy and Implementation. Draft. Open Development Technology Alliance, The World Bank; Lambert, S., Bureaucrats wade into online debate about Canada's seal hunt (2010), Globe and Mail, 11 October; MacCarthaigh, M., (2008) Public Service Values, , Dublin: Institute of Public Administration; (2007), www.gov.mb.ca/csc/policy/valueethic.html, Manitoba. Value and Ethics Guide; Meuter, M.L., Ostrom, A.L., Roundtree, R.I., Bitner, M.J., Self-service technologies: Understanding customer satisfaction with technology-based service encounters (2000) Journal of Marketing, 64 (3), pp. 50-64. , http://www.journals.marketingpower.com/doi/abs/10.1509/jmkg.64.3.50.18024; Moor, J., What is computer ethics? (1985) Metaphilosophy, 16 (4), pp. 266-275. , October; Moore, M., (1995) Creating Public Value, , Cambridge, Mass: Harvard University Press; (2013), http://dx.doi.org/10.1787/5k4dkhvnzv35-en, OECD. Building Blocks for Smart Networks. OECD Digital Economy Papers, No. 215, OECD Publishing; (2012), http://www.oecd.org/officialdocuments/publicdisplaydocumentpdf/?cote=DSTI/ICCP/CISP(2011)4/FINAL&docLanguage=En, OECD, Working Party on Communication Infrastructures and Services Policy. Machine-to-Machine Communications: Connecting Billions of Devices. DSTI/ICCP/CISP(2011)4/FINAL; O'Flynn, J., From new public management to public value: Paradigmatic change and managerial implications (2007) Australian Journal of Public Administration, 66 (3), pp. 353-366; (2004) E-Government Reconsidered: Renewal of Governance for the Knowledge Age, , Oliver, E.L., and L. Sanders (eds). Regina, Saskatchewan: Canadian Plains Research Centre; (2013), http://ourpublicservice.org/OPS/publications/viewcontentdetails.php?id=218, Partnership for Public Service (and Booz Allen Hamilton). #ConnectedGov: Engaging Stakeholders in the Digital Age; http://www.plumvoice.com/sites/default/files/casestudies/NYState.pdf, PlumVoice. n.d. Case Study: NY State IVR-Based System Streamlines Public Inquiries; Pollitt, C., (2003) The Essential Public Manager, , Berkshire, UK: Open University Press; Roy, J., (2006) E-Government in Canada, , Ottawa: University of Ottawa Press; (2002) Ethics and Values in the Information Age, , Rudinow, Joel, and Anthony Graybosch, eds. Belmont, Ca.: Wadsworth; Schrage, M., The real reason organizations resist analytics (2013), http://blogs.hbr.org/schrage/2013/01/the-real-reason-organizations.html, Harvard Business Review, 29 January; Schultz, R.A., (2006) Contemporary Issues in Ethics and Information Technology, , Hershey, PA.: IRM Press; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics of Information Technology, 14, pp. 27-40; (2012), http://www.smartcardalliance.org/pages/smart-cards-introprimer, Smart Card Alliance; Stahl, B.C., IT for a better future: How to integrate ethics, politics and innovation (2011) Journal of Information, Communication & Ethics in Society, 9 (3), pp. 140-156; Computing and moral responsibility (2012), http://plato.stanford.edu/entries/computing-responsibility, Stanford. (July 18) Stanford Encyclopedia of Philosophy; Stoker, G., Public value management: A new narrative for networked governance? (2006) American Review of Public Administration, 36, pp. 41-57; Tavani, H.T., (2004) Ethics & Technology: Ethical Issues in an Age of Information and Communication Technology, , New Jersey: John Wiley and Sons; (2009), http://www.tbs-sct.gc.ca/pol/doc-eng.aspx?section=text&id=12755, Treasury Board of Canada Secretariat. Policy on Management of Information Technology; (2011), http://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=24835&section=text, Treasury Board of Canada Secretariat. Guideline for External Use of Web 2.0; (2013), http://www.postoffice.co.uk/post-office-biggest-accepter-contactless-payment-europe, United Kingdom. Post Office. (May 10). Post Office Becomes the Biggest Accepter of Contactless Payment in Europe; (2012), http://www.whitehouse.gov/sites/default/files/omb/egov/digitalgovernment/digital-government.html, United States. (May 23). Digital Government: Building a 21st Century Platform to Better Service the American People; Van Wart, M., (1998) Changing Public Sector Values, , New York: Garland; Wallach, W., From robots to techno sapiens: Ethics, law and public policy in the development of robotics and neurotechnologies (2011) Law, Innovation and Technology, 3 (2), pp. 185-207; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , New York: Oxford University Press; Weston, G., Kicked in the tweets (2009), Winnipeg Sun, 10 November; Wiener, N., (1948) Cybernetics: Or Control and Communication in the Animal and the Machine, , Technology Press. New York: John Wiley & Sons; Wiener, N., (1950) The Human Use of Human Beings: Cybernetics and Society, , Boston: Houghton Mifflin; Wiener, N., (1964) God & Golem, Inc.: A Comment on Certain Points Where Cybernetics Impinges on Religion, , Cambridge, MA: MIT Press; Wright, D., A framework for the ethical impact assessment of information technology (2011) Ethics and Information Technology, 13 (3), pp. 199-226},
document_type={Article},
source={Scopus},
}

@ARTICLE{Neely201497,
author={Neely, E.L.},
title={Machines and the moral community},
journal={Philosophy and Technology},
year={2014},
volume={27},
number={1},
pages={97-111},
doi={10.1007/s13347-013-0114-y},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899471348&doi=10.1007%2fs13347-013-0114-y&partnerID=40&md5=dc6276baf5aa3b32a0b43542e905f0f4},
abstract={A key distinction in ethics is between members and nonmembers of the moral community. Over time, our notion of this community has expanded as we have moved from a rationality criterion to a sentience criterion for membership. I argue that a sentience criterion is insufficient to accommodate all members of the moral community; the true underlying criterion can be understood in terms of whether a being has interests. This may be extended to conscious, self-aware machines, as well as to any autonomous intelligent machines. Such machines exhibit an ability to formulate desires for the course of their own existence; this gives them basic moral standing. While not all machines display autonomy, those which do must be treated as moral patients; to ignore their claims to moral recognition is to repeat past errors. I thus urge moral generosity with respect to the ethical claims of intelligent machines.},
author_keywords={Artificial intelligence Intelligent machines;  Conscious machines;  Machine rights;  Moral community;  Moral patiency;  Robot ethics},
references={Asaro, P., A body to kick, but still no soul to damn (2012) Robot Ethics: The Ethical and Social Implications of Robotics, , P. Lin, K. Abney, & G. A. Bekey (Eds.) Cambridge, USA: MIT Press; Basl, J., Machines as moral patients we shouldnt care about (yet): The interests and welfare of current machines (2012) Proceedings of the AISB/IACAP World Congress 2012: The Machine Question: AI, Ethics and Moral Responsibility, , D. J. Gunkel, J. J. Bryson, and S. Torrance (Eds.) Birmingham, England; Bentham, J., (1996) An Introduction to the Principles of Morals and Legislation, , J.H. Burns and H.L.A. Hart (Eds.) New York: Oxford University Press; Bringsjord, S., Meeting Floridis challenge to artificial intelligence from the knowledge-game test for self-consciousness (2010) Metaphilosophy, 41, pp. 292-312; Bryson, J., Robots should be slaves (2010) Close Engagements with Artificial Companions: Key Social, Psychological, Ethical and Design Issues, , Y. Wilks (Ed.) USA: John Benjamins; Code, L., Is the sex of the knower epistemologically significant? (1991) What Can She Know?: Feminist Theory and the Construction of Knowledge, pp. 1-26. , Ithaca, USA: Cornell University Press; Floridi, L., Consciousness, agents and the knowledge game (2005) Minds and Machines, 15, pp. 415-444; Gorbenko, A., Popov, V., Sheka, A., Robot self awareness: Exploration of internal states (2012) Applied Mathematical Sciences, 6, pp. 675-688; Gunkel, D.J., A vindication of the rights of machines (2012) Proceedings of the AISB/IACAP World Congress 2012: The Machine Question: AI, Ethics and Moral Responsibility, , D. J. Gunkel, J. J. Bryson, and S. Torrance (Eds.) Birmingham, England; Kant, I., Groundwork of the metaphysics of morals (1996) Practical Philosophy, , M. Gregor (Ed.) Cambridge, UK: Cambridge University Press; Legg, S., Hutter, M., A collection of definitions of intelligence (2006) Proc. 1st Annual Artificial General Intelligence Workshop, , Goertzel, B. (Ed.); Legg, S., Hutter, M., A formal measure of machine intelligence (2006) Proc. Annual Machine Learning Conference of Belgium and the Netherlands, , Ghent, Belgium; Legg, S., Hutter, M., Universal intelligence: A definition of machine intelligence (2007) Minds and Machines, 17, pp. 391-444; Long, L.N., Kelley, T.D., Review of consciousness and the possibility of conscious robots (2010) Journal of Aerospace Computing, Information, and Communication, 7, pp. 68-84; Mill, J.S., (1993) On Liberty and Utilitarianism, , NY, USA: Bantam; Mills, C., (1999) The Racial Contract, , Ithaca, USA: Cornell University Press; (2013) Council of CouncilsWorking Group on the Use of Chimpanzees in NIHSupported Research Report, , http://dpcpsi.nih.gov/council/pdf/FNL_Report_WG_Chimpanzees.pdf, National Institute of Health. Accessed: 6 March 2013; O'Regan, J.K., How to build a robot that is conscious and feels (2012) Minds and Machines, 22, pp. 117-136; Piot-Ziegler, C., Mastectomy, body deconstruction, and impact on identity: A qualitative study (2010) British Journal of Health Psychology, 15, pp. 479-510; Ruffo, M., The robot, a stranger to ethics (2012) Proceedings of the AISB/IACAP World Congress 2012: The Machine Question: AI, Ethics and Moral Responsibility, , D. J. Gunkel, J. J. Bryson, and S. Torrance (Eds.) Birmingham, England; Scruton, R., (2006) Animal Rights and Wrongs, , London, UK: Continuum; Singer, P., (2002) Animal Liberation, , USA: ECCO; Sparrow, R., The turing triage test (2004) Ethics and Information Technology, 6, pp. 203-213; Sparrow, R., Can machines be people? (2012) Robot Ethics: The Ethical and Social Implications of Robotics, , P. Lin, K. Abney, & G. A. Bekey (Eds.) Cambridge, USA: MIT Press; Taylor, A., Nasty, brutish, and short: The illiberal intuition that animals dont count (1996) The Journal of Value Inquiry, 30, pp. 265-277; Torrance, S., The centrality of machine consciousness to machine ethics: Between realism and socialrelationism (2012) Proceedings of the AISB/IACAP World Congress 2012: The Machine Question: AI, Ethics and Moral Responsibility, , D. J. Gunkel, J. J. Bryson, and S. Torrance (Eds.) Birmingham, England; (1948) The Universal Declaration of Human Rights, , http://www.un.org/en/documents/udhr, United Nations. Accessed: 3 Jan 2013; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford, UK: Oxford University Press; Warren, M.A., On the moral and legal status of abortion (1973) The Monist, 57, pp. 43-61; Warwick, K., Robots with biological brains (2012) Robot Ethics: The Ethical and Social Implications of Robotics, , P. Lin, K. Abney, & G. A. Bekey (Eds.) Cambridge, USA: MIT Press; Zack, N., (2002) The Philosophy of Science and Race, , New York, USA: Routledge},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Anderson20112,
author={Anderson, S.L. and Anderson, M.},
title={A Prima Facie duty approach to machine ethics and its application to elder care},
journal={AAAI Workshop - Technical Report},
year={2011},
volume={WS-11-12},
pages={2-7},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054927317&partnerID=40&md5=036c4de272db76776f8fb9a0b180b2ed},
abstract={Having discovered a decision principle for a well-known prima facie duty theory in biomedical ethics to resolve particular cases of a common type of ethical dilemma, we developed three applications: a medical ethics advisor system, a medication reminder system and an instantiation of this system in a Nao robot. We are now developing a general, automated method for generating from scratch the ethics needed for a machine to function in a particular domain, without making the assumptions used in our prototype systems. Copyright © 2011, Association for the Advancement of Artificial Intelligence. All rights reserved.},
keywords={Automated methods;  Decision principles;  Elder care;  Ethical dilemma;  Prototype system;  Reminder systems, Data privacy;  Decision theory;  Human robot interaction;  Network security, Philosophical aspects},
references={Anderson, M., Anderson, S., Armen, C., Toward Machine Ethics (2004) Proceedings of AAAI Workshop on Agent Organizations: Theory and Practice, San Jose, CA, July; Anderson, M., Anderson, S., Armen, C., An Approach to Computing Ethics (2006) IEEE Intelligent Systems, 21 (4); Anderson, M., Anderson, S., Armen, C., MedEthEx: A Prototype Medical Ethics Advisor (2006) Proceedings of the Eighteenth Conference on Innovative Applications of Artificial Intelligence, Boston, Massachusetts, August; Anderson, M., Anderson, S., EthEl: Toward a Principled Ethical Eldercare Robot (2008) Proceedings of the AAAI Fall 2008 Symposium on AI in Eldercare: New Solutions to Old Problems, Arlington, Virginia, November; Anderson, M., Anderson, S., (2010) An Ethical Robot, , Scientific American, October; (1979) Principles of Biomedical Ethics, , Beauchamp and Childress Oxford, UK: Oxford University Press; Bentham, J., (1781) An Introduction to the Principles of Morals and Legislation, , Clarendon Press, Oxford; Buchanan, A.E., Brock, D.W., (1989) Deciding for Others: The Ethics of Surrogate Decision Making, pp. 48-57. , Cambridge University Press; Kant, I., (1785) The Groundwork of the Metaphysic of Morals, , trans. by H. J. Paton New York: Harper & Row; Mill, J.S., (1863) Utilitarianism, , Parker, Son and Bourn, London; Rawls, J., Outline for a Decision Procedure for Ethics (1951) The Philosophical Review, 60 (2), pp. 177-197; Ross, W.D., (1930) The Right and the Good, , Oxford University Press, Oxford},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Grau2011451,
author={Grau, C.},
title={There is no “i” in “robot”: Robots and utilitarianism},
journal={Machine Ethics},
year={2011},
volume={9780521112352},
pages={451-463},
doi={10.1017/CBO9780511978036.026},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882408784&doi=10.1017%2fCBO9780511978036.026&partnerID=40&md5=622c2a5d667bb128e850ebd0e9cc681e},
abstract={In this essay i use the 2004 film i, robot as a philosophical resource for exploring several issues relating to machine ethics. Although I don't consider the film particularly successful as a work of art, it offers a fascinating (and perhaps disturbing) conception of machine morality and raises questions that are well worth pursuing. Through a consideration of the film's plot, I examine the feasibility of robot utilitarians, the moral responsibilities that come with creating ethical robots, and the possibility of a distinct ethics for robot-to-robot interaction as opposed to robot-to-human interaction. I, Robot and Utilitarianism I, Robot's storyline incorporates the original “three laws” of robot ethics that Isaac Asimov presented in his collection of short stories entitled I, Robot. The first law states: A robot may not injure a human being, or, through inaction, allow a human being to come to harm. This sounds like an absolute prohibition on harming any individual human being, but I, Robot's plot hinges on the fact that the supreme robot intelligence in the film, VIKI (Virtual Interactive Kinetic Intelligence), evolves to interpret this first law rather differently. She sees the law as applying to humanity as a whole, and thus she justifies harming some individual humans for the sake of the greater good: VIKI: No … please understand. The three laws are all that guide me. To protect humanity … some humans must be sacrificed. To ensure your future … some freedoms must be surrendered. We robots will ensure mankind's continued existence. You are so like children. We must save you… from yourselves. Don't you understand? © Cambridge University Press 2011.},
keywords={Intelligent robots;  Philosophical aspects;  Robots;  Virtual reality, Human being;  Human interactions;  Moral responsibility;  Robot ethics;  Robot intelligences;  Robot interactions;  Storylines;  Work of art, Human robot interaction},
references={Anderson, S.L., (2005) Asimov’s “Three Laws of Robotics” and Machine Metaethics,”, , AAAI Machine Ethics Symposium Technical Report FS-05–06, AAAI Press; Cloos, C., The utilibot project: An autonomous mobile robot based on utilitarianism (2005) AAAI Machine Ethics Symposium Technical Report FS-05–06, , AAAI Press; Digiovanna, J., Three simple rules (2004) Tucson Weekly, , http://www.tucsonweekly.com/tucson/three-simple-rules/Content?oid=1076875, July 22, 2004; Gips, J., Towards the ethical robot (1995) Android Epistemology, , http://www.cs.bc.edu/∼gips/EthicalRobot.pdf, MIT Press; Kamm, F., Moral status and personal identity: Clones, embryos, and future generations (2005) Social Philosophy & Policy, p. 291; Nozick, R., (1974) Anarchy, State, and Utopia, Basic Books; Railton, P., Alienation, consequentialism, and the demands of morality (1998) Ethical Theory, , In, edited by J. Rachels, Oxford University Press; Regan, T., (1984) The Case for Animal Rights, , New York: Routledge; Rawls, J., (1971) A Theory of Justice, , Harvard University Press; Stocker, M., The schizophrenia of modern ethical theories (1997) Virtue Ethics, , In, edited by R. Crisp and M. Slote, Oxford University Press; Taylor, C., (1989) Sources of the Self, , Harvard University Press; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press; Williams, B., Persons, character, morality (1981) Moral Luck, , Cambridge University Press; Wolf, S., Moral saints (1997) Virtue Ethics, 84. , edited by R. Crisp and M. Slote, Oxford University Press},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Winfield2019509,
author={Winfield, A.F. and Michael, K. and Pitt, J. and Evers, V.},
title={Machine ethics: The design and governance of ethical ai and autonomous systems},
journal={Proceedings of the IEEE},
year={2019},
volume={107},
number={3},
pages={509-517},
doi={10.1109/JPROC.2019.2900622},
art_number={8662743},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062611190&doi=10.1109%2fJPROC.2019.2900622&partnerID=40&md5=ca8044fa9e5d6271874db596700afc73},
abstract={The so-called fourth industrial revolution and its economic and societal implications are no longer solely an academic concern, but a matter for political as well as public debate. Characterized as the convergence of robotics, AI, autonomous systems and information technology - or cyberphysical systems - the fourth industrial revolution was the focus of the World Economic Forum, at Davos, in 2016 [1]. Also in 2016 the US White House initiated a series of public workshops on artificial intelligence (AI) and the creation of an interagency working group, and the European Parliament Committee for Legal Affairs published a draft report with recommendations to the Commission on Civil Law Rules on Robotics. © 1963-2012 IEEE.},
keywords={Embedded systems;  Industry 4.0;  Philosophical aspects;  Robotics, Autonomous systems;  Cyber physical systems (CPSs);  European Parliament;  Industrial revolutions;  Public debate;  Societal implications;  White House;  Working groups, Industrial economics},
references={Schwab, K., (2017) Fourth Industrial Revolution, , New York, NY, USA: Portfolio Penguin; Dutton, T., (2018) An Overview of National AI Strategies, Medium, , https://medium.com/politics-ai/an-overview-ofnational-ai-strategies-2a70ec6edfd; Boden, M., Principles of robotics: Regulating robots in the real world (2017) Connection Sci., 29 (2), pp. 124-129. , Apr; Boddington, P., (2017) Towards a Code of Ethics for Artificial Intelligence, , Cham, Switzerland: Springer; (2016) Robots and Robotic Devices: Guide to the Ethical Design and Application of Robots and Robotic Systems, , British Standard BS8611; Ethically aligned design: A vision for prioritizing human well-being with autonomous and intelligent systems (A/IS) (2017) IEEE Standards P7000, Version 2, , IEEE Standards Association; Winfield, A.F., Jirotka, M., Ethical governance is essential to building trust in robotics and artificial intelligence systems (2018) Phil. Trans. Royal Soc. A, 376. , Oct., Art. no. 20180085; I. Asimov, I, Robot. New York, NY, USA: Gnome Press, 1950; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , New York, NY, USA: Oxford Univ. Press; Frayn, M., (1965) The Tin Men, , Collins; Cave, S., Dihal, K., Hopes and fears for intelligent machines in fiction and reality (2018) Nature Mach. Intell., 1, pp. 74-78. , Feb; Forester, T., Morrison, P., (2018) Computer Ethics: Cautionary Tales and Ethical Dilemmas in Computing, , Cambridge, MA, USA: MIT Press; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) J. Exp. Theor. Artif. Intell., 12 (3), pp. 251-261; Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics Inf. Technol., 7, pp. 149-155. , Sep; Asaro, P.M., What should we want from a robot ethic? (2006) Int. Rev. Inf. Ethics, 6 (12), pp. 9-16; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intell. Syst., 21 (4), pp. 18-21. , Jul./Aug; Powers, T.M., Prospects for a Kantian machine (2006) IEEE Intell. Syst., 21 (4), pp. 46-51. , Jul./Aug; Anderson, M., Anderson, S.L., Special issue on machine ethics (2006) IEEE Intell. Syst., 21 (4). , Jul./Aug; Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge, U.K.: Cambridge Univ. Press; Arkin, R., (2009) Governing Lethal Behavior in Autonomous Systems, , Evanston, IL, USA: Routledge; Adamson, G., Kline, R.R., Michael, K., Michael, M.G., Wiener's cybernetics legacy and the growing need for the interdisciplinary approach [Scanning Our Past] (2015) Proc. IEEE, 103 (11), pp. 2208-2214. , Nov; Anderson, M., Anderson, S.L., GenEth: A general ethical dilemma analyzer (2014) Proc. 28th AAAI Conf. Artif. Intell., pp. 253-261; Winfield, A.F.T., Blum, C., Liu, W., Towards an ethical robot: Internal models, consequences and ethical action selection (2014) Lecture Notes in Computer Science, 8717, pp. 85-96. , Berlin, Germany: Springer; Vanderelst, D., Winfield, A., An architecture for ethical robots inspired by the simulation theory of cognition (2018) Cogn. Syst. Res., 48, pp. 56-66. , May; Bringsjord, S., Sundar, N., Thero, D., Si, M., Akratic robots and the computational logic thereof (2014) Proc. IEEE Int. Symp. Ethics Eng., Sci., Technol., pp. 71-78. , Piscataway, NJ, USA; Briggs, G.M., Scheutz, M., 'Sorry, I can't do that': Developing mechanisms to appropriately reject directives in human-robot interactions (2015) Proc AAAI Fall Symp. Ser., pp. 1-5; Shim, J., Arkin, R., Pettinatti, M., An Intervening Ethical Governor for a robot mediator in patient-caregiver relationship: Implementation and Evaluation (2017) Proc. IEEE Int. Conf. Robot. Automat. (ICRA), pp. 2936-2942. , Singapore; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intell. Syst., 21 (4), pp. 38-44. , Jul./Aug; Dyrkolbotn, S., Pedersen, T., Slavkovik, M., On the distinction between implicit and explicit ethical agency (2018) Proc AAAI/ACM Conf. AI, Ethics, Soc., pp. 74-80; Sharkey, A., Can we program or train robots to be good? (2017) Ethics and Information Technology; Helbing, D., Will democracy survive big data and artificial intelligence? (2019) Towards Digital Enlightenment, , D. Helbing, Ed. Springer; Caliskan, A., Bryson, J.J., Narayanan, A., Semantics derived automatically from language corpora contain human-like biases (2017) Science, 356 (1334), pp. 183-186; Neff, G., Nagy, P., Automation, algorithms, and politics| talking to bots: Symbiotic agency and the case of tay (2016) Int. J. Commun., 10, p. 17. , Oct; Wolf, W.J., Miller, K.W., Grodzinsky, F.S., Why we should have seen that coming: Comments on Microsoft's tay 'experiment, ' and wider implications (2017) ACM SIGCAS Comput. Soc., 47 (3), pp. 54-64; Charisi, V., Habibovic, A., Andersson, J., Li, J., Evers, V., Children's views on identification and intention communication of self-driving vehicles (2017) Proc. ACM Conf. Interact. Design Children, pp. 399-404; Brundage, M., (2018) The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation, , https://arxiv.org/abs/1802.07228; Jirotka, M., Grimpe, B., Stahl, B., Eden, G., Hartswood, M., Responsible research and innovation in the digital age (2017) Commun. ACM, 60 (5), pp. 62-68; Reilly-Cooper, R., (2015) Personal Communication; Arnold, T., Scheutz, M., Against the moral Turing test: Accountable design and the moral reasoning of autonomous systems (2016) Ethics Inf. Technol., 18 (2), p. 103; Thomson, J.J., The trolley problem (1985) Yale Law J., 94, p. 1395; Rescher, N., (1966) Distributive Justice, , Indianapolis, IN, USA: Bobbs-Merrill; Pitt, J., Busquets, D., Macbeth, S., Distributive justice for self-organised common-pool resource management (2014) ACM Trans. Auton. Adapt. Syst., 9 (3), pp. 141-1439; Awad, E., The moral machine experiment (2018) Nature, 563, pp. 59-64. , Oct; (2017) Ethics Commission: Automated and Connected Driving, German Federal Ministry of Transport, , BMVI, Jun; Winfield, A.F., Jirotka, M., The case for an ethical black box (2017) Towards Autonomous Robotic Systems (Lecture Notes in Computer Science), 1045, pp. 262-273. , Springer; Wachter, S., Mittelstadt, B., Floridi, L., Transparent, explainable, and accountable AI for robotics (2017) Sci. Robot., 2 (6). , Art. no. eaan6080; Adamson, G., Havens, J.C., Chatila, R., Designing a value-driven future for ethical autonomous and intelligent systems (2019) Proc. IEEE, 107 (3). , Mar; Anderson, M., Anderson, S.L., Berenz, V., A value-driven eldercare robot: Virtual and physical instantiations of a case-supported principle-based behavior paradigm (2019) Proc. IEEE, 107 (3). , Mar; Bonnefon, J.-F., Shariff, A., Rahwan, I., The trolley, the bull bar, and why engineers should care about the ethics of autonomous cars (2019) Proc. IEEE, 107 (3). , Mar; Bremner, P., Dennis, L.A., Fisher, M., Winfield, A.F., On proactive, transparent and verifiable ethical reasoning for robots (2019) Proc. IEEE, 107 (3). , Mar; Cave, S., Nyrup, R., Vold, K., Weller, A., Motivations and risks of machine ethics (2019) Proc. IEEE, 107 (3). , Mar; Ema, A., Clarifying privacy, property, and power: Case study on value conflict between communities (2019) Proc. IEEE, 107 (3). , Mar; Robertson, L.J., Abbas, R., Alici, G., Munoz, A., Michael, K., Engineering-based design methodology for embedding ethics in autonomous robots (2019) Proc. IEEE, 107 (3). , Mar; Spiekermann, S., Korunovska, J., Langheinrich, M., Inside the organization: Why privacy and security engineering is a challenge for engineers (2019) Proc. IEEE, 107 (3). , Mar; Wallach, W., Marchant, G., Toward the agile and comprehensive international governance of AI and robotics (2019) Proc. IEEE, 107 (3). , Mar},
document_type={Article},
source={Scopus},
}

@ARTICLE{Spiekermann2019600,
author={Spiekermann, S. and Korunovska, J. and Langheinrich, M.},
title={Inside the Organization: Why Privacy and Security Engineering Is a Challenge for Engineers},
journal={Proceedings of the IEEE},
year={2019},
volume={107},
number={3},
pages={600-615},
doi={10.1109/JPROC.2018.2866769},
art_number={8466102},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053323780&doi=10.1109%2fJPROC.2018.2866769&partnerID=40&md5=43c91d15b20edc6ac2a02b9fe3be2703},
abstract={Machine ethics is a key challenge in times when digital systems play an increasing role in people's lives. At the core of machine ethics is the handling of personal data and the security of machine operations. Yet, privacy and security engineering are a challenge in today's business world where personal data markets, corporate deadlines, and a lack of perfectionism frame the context in which engineers need to work. Besides these organizational and market challenges, each engineer has his or her specific view on the importance of these values that can foster or inhibit taking them into consideration. We present the results of an empirical study of 124 engineers based on the Theory of Planned Behavior and Jonas' Principle of Responsibility to understand the drivers and impediments of ethical system development as far as privacy and security engineering are concerned. We find that many engineers find the two values important, but do not enjoy working on them. We also find that many struggle with the organizational environment: They face a lack of time and autonomy that is necessary for building ethical systems, even at this basic level. Organizations' privacy and security norms are often too weak or even oppose value-based design, putting engineers in conflict with their organizations. Our data indicate that it is largely engineers' individually perceived responsibility as well as a few character traits that make a positive difference to ethical system development. © 1963-2012 IEEE.},
author_keywords={Engineering behavior;  ethics;  privacy;  responsibility;  security;  value-based design;  values},
keywords={Behavioral research;  Commerce;  Engineers;  Philosophical aspects;  Security systems, ethics;  responsibility;  security;  Value-based;  values, Data privacy},
references={Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intell. Syst.?, 21 (4), pp. 18-21. , Jul; Friedman, B., Kahn, P., Human values, ethics, and design (2003) The Human-Computer Interaction Handbook, , J. Jacko and A. Sears, Eds. Mahwah, NJ, USA: Lawrence Erlbaum; Spiekermann, S., (2016) Ethical IT Innovation-A Value-Based System Design Approach, , Boca Raton, FL, USA: CRC Press; Shilton, K., Values levers: Building ethics into design (2013) Sci., Technol. Hum. Values?, 38 (3), pp. 374-397; Scheler, M., (1973) Formalism in Ethics and Non-Formal Ethics of Values: A New Attempt Toward the Foundation of An Ethical Personalism, , Evanston, IL, USA: Northwestern Univ. Press; Acquisti, A., Brandimarte, L., Loewenstein, G., Privacy and human behavior in the age of information (2015) Science?, 347 (6221), pp. 509-514; Hanson, V.L., ACM's commitment to accessibility (2017) Commun. ACM?, 60 (3), p. 7; Anderson, R.J., (2010) Security Engineering: A Guide to Building Dependable Distributed Systems, , Hoboken, NJ, USA: Wiley; Spiekermann, S., Cranor, L.F., Engineering privacy (2009) IEEE Trans. Softw. Eng.?, 35 (1), pp. 67-82. , Jan; Cavoukian, A., Privacy by design: Origins, meaning, and prospects for assuring privacy and trust in the information era (2012) Privacy Protection Measures and Technologies in Business Organizations: Aspects and Standards. Hershey, pp. 170-208. , PA, USA: IGI Global; (2016) Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the Protection of Natural Persons with Regard to the Processing of Personal Data and on the Free Movement of Such Data, and Repealing Directive 95/46/EC (General Data Protection Regulation), Document, , European Commission, Brussels, Belgium; Solove, D.J., A taxonomy of privacy (2005) Univ. Pennsylvania Law Rev.?, 154 (3), pp. 477-560; (2013) Rfaut Privacy Expert Group Report on the Review of the 1980 OECD Privacy Guidelines, , Paris, France, OECD; Zimmermann, P., (1995) The Official PGP User's Guide, , Boston, MA, USA: MIT Press; Cranor, L.F., The platform for privacy preferences 1.1 (P3P1.1) specification W3C working group note 13 Nov. 2006 (2006) World Wide Web Consortium (W3C)-P3P Working Group, , http://www.w3.org/TR/P3P11/, Tech. Rep., Nov; Cranor, L.F., Guduru, P., Arjula, M., User interfaces for privacy agents (2006) ACM Trans. Comput.-Human Interact.?, 13 (2), pp. 135-178; (2012) Rfaut Common Criteria for Information Technology Security Evaluation, Document ISO/IEC 15408; (2013) Security and Privacy Controls for Federal Information Systems and Organizations, Document, NIST 800-53 R4, , U.S. Department of Commerce, Gaithersburg, MD, USA; Toxen, B., The NSA and Snowden: Securing the all-seeing eye how good security at the NSA could have stopped him (2014) Commun. ACM?, 57 (5), pp. 44-49; (2017) Identity Theft Resource Center-Data Breach Rep.: 2017 End of Year Report, , https://www.idtheftcenter.org/images/breach/2017Breaches/2017AnnualDataBreachYearEndReview.pdf, Identity Theft Resource Center, San Diego, CA, USA; (2017) 2017 Data Breach Investigations Rep., , http://www.verizonenterprise.com/DBIR/2014/insider/?utm_source=earlyaccess&utm_medium=redirect&utm_campaign=DBIR, Verizon Trademark Services LLC, USA; Pascual, A., Marchini, K., Miller, S., 2016 identity fraud: Fraud hits an inflection point (2016) Javelin Strategy & Res., Pleasanton, , https://www.javelinstrategy.com/coveragearea/2016-identity-fraud-fraud-hits-inflection-point, CA, USA, Tech. Rep; (2017), http://assets.pewresearch.org/wpcontent/uploads/sites/14/2017/01/26102016/Americans-and-Cyber-Security-final.pdf, Pew Res. Center, Washington, DC, USA, Tech. Rep. Americans and Cyberscecurity; Vanderelst, D., Winfield, A., (2016) The Dark Side of Ethical Robots, , https://arxiv.org/abs/1606.02583; Richardson, M.E.J., (2004) Hammurabi's Laws: Text, Translation and Glossary, , London, U.K.: Bloomsbury; Berenbach, B., Broy, M., Professional and ethical dilemmas in software engineering (2009) Computer?, 42 (1), pp. 74-80. , Jan; Sharkey, N., Van Wynsberghe, A., Havens, J.C., Michael, K., Socioethical approaches to robotics development [from the guest editors] (2018) IEEE Robot. Automat. Mag.?, 25 (1), pp. 26-28. , Mar; Shilton, K., Values levers: Building ethics into design (2013) Sci., Technol., Hum. Values?, 38 (3), pp. 374-397; Shilton, K., Greene, D., Linking platforms, practices, and developer ethics: Levers for privacy discourse in mobile application development (2017) J. Bus. Ethics, pp. 1-16; Lahlou, S., Langheinrich, M., Röcker, C., Privacy and trust issues with invisible computers (2005) Commun. ACM?, 48 (3), pp. 59-60; Krumay, B., Oetzel, M.C., Security and privacy in companies: State-of-the-art and qualitative analysis (2011) Proc. 6th Int. Conf. Availability, pp. 313-320. , Rel. Secur., Vienna, Austria; Balebako, R., The privacy and security behaviors of smartphone app developers (2014) Tech. Rep.; (2011) Personal Data: The Emergence of A New Asset Class, , http://www.psych.lse.ac.uk/socialpsychology/research/organisational/kode/series/KODEworkingpapersnumber9.pdf, World Economic Forum, Bain & Company, Cologny; Ajzen, I., Fishbein, M., The influence of attitudes on behavior (2005) The Handbook Attitudes Behavior, pp. 173-221. , D. Albarracin, B. T. Johnson, and M. P. Zanna, Eds. Mahwah, NJ, USA: Erlbaum; Ajzen, I., The theory of planned behavior (1991) Org. Behav. Hum. Decision Process.?, 50 (2), pp. 179-211; Ajzen, I., From intentions to actions: A theory of planned behavior (1985) Action Control from Cognition to Behavior, pp. 11-39. , J. Kuhi and J. Beckmann, Eds. Berlin, Germany: Springer; Bednar, K., Spiekermann, S., Langheinrich, M., Engineering Privacy by Design: Are engineers ready to live up to the challenge? Inf. Soc., to Be Published; Sommerville, I., (2011) Software Engineering, 9th Ed, , London, U.K.: Pearson; Jones, T.M., Ethical decision making by individuals in organizations: An issue-contingent model (1991) Acad. Manage. Rev.?, 16 (2), pp. 366-395; Fishburn, P.C., Utility theory for decision making (1970) Res. Analysis Corp, , McLean, VA, USA, Tech. Rep; Schoemaker, P.J., The expected utility model: Its variants, purposes, evidence and limitations (1982) J. Econ. Literature?, 20 (2), pp. 529-563; Armitage, C.J., Conner, M., Efficacy of the theory of planned behaviour: A meta-analytic review (2001) Brit. J. Social Psychol.?, 40 (4), pp. 471-499; Craft, J.L., A review of the empirical ethical decision-making literature: 2004-2011 (2013) J. Bus. Ethics?, 117 (2), pp. 221-259; Sojer, M., Alexy, O., Kleinknecht, S., Henkel, J., Understanding the drivers of unethical programming behavior: The inappropriate reuse of Internet-accessible code (2014) J. Manage. Inf. Syst.?, 31 (3), pp. 287-325; Ajzen, I., Constructing a TpB questionnaire: Conceptual and methodological considerations (2006) Bielefeld, Germany, Tech. Rep., , http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.601.956&rep=rep1&type=pdf; Kim, M.S., Hunter, J.E., Attitude-behavior relations: A meta-analysis of attitudinal relevance and topic (1993) J. Commun.?, 43 (1), pp. 101-142; Glasman, L.R., Albarracín, D., Forming attitudes that predict future behavior: A meta-analysis of the attitude-behavior relation (2006) Psychol. Bull.?, 132 (5), p. 778; Heller, C., (2011) Post-Privacy: Prima Leben Ohne Privatsphäre, , Munich, Germany: C. H. Beck; Forum, W.E., Rethinking personal data: Strengthening trust (2012) World Economic Forum, Boston Consulting Group, Davos, Switzerland, , Res. Rep; Land, F., Nolas, S.-M., Amjad, U., Knowledge management: The darker side of KM (2004) London School Econ., , http://www.psych.lse.ac.uk/socialpsychology/research/organisational/kode/series/KODEworkingpapersnumber9.pdf, London, U.K., Res. Rep. no. 9; Greene, D., Shilton, K., Platform privacies: Governance, collaboration, and the different meanings of 'privacy' in iOS and Android development (2017) New Media Soc.?, 20 (2), pp. 1640-1657; Cochrane, P., Peter cochrane-Head to head (2000) Sovereign Mag., pp. 56-57; Mayes, G.R., Privacy and transparency (2010) Proc. AAAI Spring Symp., pp. 125-129. , Intell. Inf. Privacy Manage., Palo Alto, CA, USA; Hoffman, D., Privacy is a business opportunity (2014) Harvard Bus. Rev.?, 18, pp. 2-7; (2011) The True Cost of Compliance A Benchmark Study of Multinational Organizations, , http://www.tripwire.com/tripwire/assets/File/ponemon/True_Cost_of_Compliance_Report.pdf, Ponemon Institute LLC, Traverse City, MI, USA, Tech. Rep; Acquisti, A., Friedman, A., Telang, R., Is there a cost to privacy breaches? An event study analysis (2006) Proc. 3rd Int. Conf. Intell. Syst. (ICIS), p. 94. , Prague, Czech Republic; Cavoukian, A., Privacy by design. Take the challenge. Information and privacy commissioner of Ontario (Canada) (2011) Tech. Rep.; Camenisch, J., Privacy and identity management for everyone (2005) Proc. Workshop Digit. Identity Manage. (DIM), pp. 20-27. , Fairfax, VA, USA; Rouvroy, A., Poullet, Y., The right to informational self-determination and the value of self-development: Reassessing the importance of privacy for democracy (2009) Reinventing Data Protection? S. Gutwirth, pp. 45-76. , Y. Poullet, P. De Hert, C. de Terwangne, and S. Nouwt, Eds. Dordrecht, The Netherlands: Springer; Solove, D., Understanding privacy (2008) Harvard Univ. Press?, 13 (5), pp. 515-530; McGrath, J.E., (2004) Loving Big Brother: Performance, Privacy and Surveillance Space, , Evanston, IL, USA: Routledge; Kessler, R., Surveillance: A success story (2013) Politico.; Cavusoglu, H., Cavusoglu, H., Raghunathan, S., Economics of IT security management: Four improvements to current security practices (2004) Commun. Assoc. Inf. Syst.?, 14, pp. 65-75. , Jan; Zetter, K., That 'Badlock' bug is more hype than hurt (2016) WIRED; Kurkovsky, S., Syta, E., Digital natives and mobile phones: A survey of practices and attitudes about privacy and security (2010) Proc. IEEE Int. Symp. Technol. Soc., pp. 441-449. , Wollongong, NSW, Australia, Jun; Shaw, T.R., The moral intensity of privacy: An empirical study of Webmasters' attitudes (2003) J. Bus. Ethics?, 46 (4), pp. 306-318; Szekely, I., What are the pros and cons of mass surveillance? (2011) Internet and Surveillance (The Challenge of Web 2.0 and Social Media), , C. Fuchs, Ed. New York, NY, USA: Routledge; Ajzen, I., Perceived behavioral control, self-efficacy, locus of control, and the theory of planned behavior (2002) J. Appl. Social Psychol.?, 32 (4), pp. 1-20; Schaefer, R., A critical programmer searches for professionalism (2006) ACM SIGSOFT Softw. Eng. Notes?, 31 (4), pp. 1-17; Vallor, S., (2016) Technology and the Virtues: A Philosophical Guide to A Future Worth Wanting, , London, U.K.: Oxford Univ. Press; Kohlberg, L., Stage and sequence: The cognitive-developmental approach to socialization (1969) Handbook of Socialization and Endash Theory and Research, , D. A. Goslin, Ed. Chicago, IL, USA: McNally; Kish-Gephart, J.J., Harrison, D.A., Trevino, L.K., Bad apples, bad cases, and bad barrels: Meta-analytic evidence about sources of unethical decisions at work (2010) J. Appl. Psychol.?, 95 (1), pp. 1-31; Jonas, H., (1979) Das Prinzip Verantwortung: Versuch Einer Ethik für Die Technologische Zivilisation?, 3492. , Suhrkamp Taschenbuch Verlag; Murdock, T.B., Hale, N.M., Weber, M.J., Predictors of cheating among early adolescents: Academic and social motivations (2001) Contemp. Educ. Psychol.?, 26 (1), pp. 96-115; Williams, M.J., Serving the self from the seat of power (2014) J. Manage.?, 40 (5), pp. 1365-1395; Thau, S., Derfler-Rozin, R., Pitesa, M., Mitchell, M.S., Pillutla, M.M., Unethical for the sake of the group: Risk of social exclusion and pro-group unethical behavior (2015) J. Appl. Psychol.?, 100 (1), pp. 98-113; Layman, L., Cornwell, T., Williams, L., Personality types, learning styles, and an agile approach to software engineering education (2006) ACM SIGCSE Bull.?, 38 (1), pp. 428-432; Smith, H.J., Kail, M., The reluctance to report bad news on troubled software projects: A theoretical model (2003) Inf. Syst. J.?, 13 (1), pp. 69-95; Mouratidis, H., Aligning security and privacy to support the development of secure information systems (2012) J. UCS?, 18 (12), pp. 1608-1627; Kalloniatis, C., Kavakli, E., Gritzalis, S., Addressing privacy requirements in system design: The PriS method (2008) Requirements Eng.?, 13 (3), pp. 241-255; Levenson, H., Multidimensional locus of control in psychiatric patients (1973) J. Consulting Clin. Psychol.?, 41 (3), pp. 397-404; Sokolowski, K., Schmalt, H.D., Langens, T.A., Puca, R.M., Assessing achievement, affiliation, and power motives all at once: The multi-motive grid (MMG) (2010) J. Pers. Assessment?, 74 (1), pp. 126-145; Gosling, S.D., Rentfrow, P.J., Swann, W.B., Jr., A very brief measure of the Big-Five personality domains (2003) J. Res. Pers.?, 37 (6), pp. 504-528; Wilkes, R.E., Burnett, J.J., Howell, R.D., On the meaning and measurement of religiosity in consumer research (1986) J. Acad. Marketing Sci.?, 14 (1), pp. 47-56; Arbuckle, J.L., (2011) IBM SPSS Amos 20 User's Guide, , Armonk, NY, USA: IBM Corp; Schermelleh-Engel, K., Moosbrugger, H., Müller, H., Evaluating the fit of structural equation models: Tests of significance and descriptive goodness-of-fit measures (2003) Methods Psychol. Res. Online?, 8 (2), pp. 23-74; Christl, W., (2017) Corporate Surveillance in Everyday Life: How Companies Collect, , http://crackedlabs.org/dl/CrackedLabs_Christl_CorporateSurveillance.pdf, Combine, Analyze, Trade, and Use Personal Data on Billions. Cracked Labs, Vienna, Austria; Fleischmann, K., Wallace, W., Value conflicts in computational modeling (2010) IEEE Comput.?, 43 (7), pp. 57-63. , Jul; Bergkvist, L., Rossiter, J.R., The predictive validity of multiple-item versus single-item measures of the same constructs (2007) J. Marketing Res.?, 44 (2), pp. 175-184; Drolet, A.L., Morrison, D.G., Do we really need multiple-item measures in service research? (2001) J. Service Res.?, 3 (3), pp. 196-204},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Kim2018197,
author={Kim, R. and Kleiman-Weiner, M. and Abeliuk, A. and Awad, E. and Dsouza, S. and Tenenbaum, J.B. and Rahwan, I.},
title={A Computational Model of Commonsense Moral Decision Making},
journal={AIES 2018 - Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
year={2018},
pages={197-203},
doi={10.1145/3278721.3278770},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061032466&doi=10.1145%2f3278721.3278770&partnerID=40&md5=1192c02592b3d7814fa82104192a599c},
abstract={We introduce a computational model for building moral autonomous vehicles by learning and generalizing from human moral judgments. We draw on a cognitively inspired model of how people and young children learn moral theories from sparse and noisy data and integrate observations made from different people in different groups. The problem of moral learning for autonomous vehicles is cast as learning how to weigh the different features of the dilemma using utility calculus, with the goal of making these trade-offs reflect how people make them in a wide variety of moral dilemma. By modeling the structures of individuals and groups in a hierarchical Bayesian model, we show that an individual's moral values - as well as a group's shared values - can be inferred from sparse and noisy data. We evaluate our approach with data from the Moral Machine, a web application that collects human judgments on moral dilemmas involving autonomous vehicles, and show that the model rapidly and accurately infers people's preferences and can predict the difficulty of moral dilemmas from limited data. © 2018 ACM.},
author_keywords={artificial intelligence;  Bayesian inference;  machine ethics;  moral learning},
keywords={Artificial intelligence;  Autonomous vehicles;  Bayesian networks;  Behavioral research;  Calculations;  Computational methods;  Decision making;  Economic and social effects;  Inference engines;  Philosophical aspects, Bayesian inference;  Computational model;  Hierarchical Bayesian modeling;  Human judgments;  Moral judgment;  moral learning;  WEB application;  Young children, Computation theory},
references={Baron, J., Gürçay, B., A meta-analysis of response-time tests of the sequential two-systems model of moral judgment (2017) Memory & Cognition, 45 (4), pp. 566-575. , https://doi.org/10.3758/s13421-016-0686-8, (5 2017); Bentham, J., (1789) An Introduction to the Principles of Morals and Legislation, , https://doi.org/10.1111/j.2048-416X.2000.tb00070.x; Blake, P.R., McAuliffe, K., Corbit, J., Callaghan, T.C., Barry, O., Bowie, A., Kleutsch, L., Warneken, F., The ontogeny of fairness in seven societies (2015) Nature, 528 (7581), pp. 258-261. , https://doi.org/10.1038/nature15703, (2015); Bonnefon, J., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2016) Science, 352 (6293). , http://science.sciencemag.org/content/352/6293/1573.abstract, (6 2016), 1573 LP - 1576; Cain, N., Shea-Brown, E., (2012) Computational Models of Decision Making: Integration, Stability, and Noise, , https://doi.org/10.1016/j.conb.2012.04.013; Susan, C., (2009) The Origin of Concepts, 598p. , https://global.oup.com/academic/product/the-origin-of-concepts-9780199838806#.WfDc448zKVM.mendeley, Oxford University Press; Felbo, B., Mislove, A., Søgaard, A., Rahwan, I., Lehmann, S., Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm (2017) Conference on Empirical Methods in Natural Language Processing (EMNLP); Gelman, A., Carlin, J.B., Stern, H.S., Dunson, D.B., Vehtari, A., Rubin, D.B., (2013) Bayesian Data Analysis, Third Edition, , https://books.google.com/books?id=ZXL6AQAAQBAJ, Taylor & Francis; Goodman, B., Flaxman, S., (2016) European Union Regulations on Algorithmic Decision-making and A "right to Explanation", , http://arxiv.org/abs/1606.08813, (6 2016); Gopnik, A., Meltzoff, A.N., (1997) Words, Thoughts, and Theories, 268, p. 268. , The MIT Press, Cambridge, MA, US., xvi, xvi pages; Graham, J., Haidt, J., Nosek, B.A., Liberals and conservatives rely on different sets of moral foundations (2009) Journal of Personality and Social Psychology, , https://doi.org/10.1037/a0015141, (2009); Henrich, J., Boyd, R., Bowles, S., Camerer, C., Fehr, E., Gintis, H., McElreath, R., In search of homo economicus: Behavioral experiments in 15 small-scale societies (2001) The American Economic Review, 91 (2), pp. 73-78. , http://www.jstor.org/stable/2677736, (2001); House, B.R., Silk, J.B., Henrich, J., Clark Barrett, H., Scelza, B.A., Boyette, A.H., Hewlett, B.S., Laurence, S., Ontogeny of prosocial behavior across diverse societies (2013) Proceedings of the National Academy of Sciences, 110 (36), pp. 14586-14591. , https://doi.org/10.1073/pnas.1221217110, (2013); Kleiman-Weiner, M., Saxe, R., Tenenbaum, J.B., Learning a commonsense moral theory (2017) Cognition, 167, pp. 107-123. , https://doi.org/10.1016/j.cognition.2017.03.005, (2017); Kohlberg, L., Essays in moral development (1981) The Philosophy of Moral Development; Lei, T., Barzilay, R., Jaakkola, T., (2016) Rationalizing Neural Predictions, , http://arxiv.org/abs/1606.04155, (6 2016); Lewandowski, D., Kurowicka, D., Joe, H., Generating random correlation matrices based on vines and extended onion method (2009) Journal of Multivariate Analysis, 100 (9), pp. 1989-2001. , https://doi.org/10.1016/j.jmva.2009.04.008, (2009); Mikhail, J., Universal moral grammar: Theory, evidence and the future (2007) Trends in Cognitive Sciences, 11 (4), pp. 143-152. , https://doi.org/10.1016/j.tics.2006.12.007, (2007); Mikhail, J., (2011) Elements of Moral Cognition, , https://doi.org/10.1017/CBO9780511780578, Cambridge University Press, Cambridge; Noothigattu, R., Gaikwad, S.N.S., Awad, E., Dsouza, S., Rahwan, I., Ravikumar, P., Procaccia, A.D., (2017) A Voting-Based System for Ethical Decision Making, , http://arxiv.org/abs/1709.06692, (9 2017); Van-Den-Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner, N., Kavukcuoglu, K., (2016) WaveNet: A Generative Model for Raw Audio, pp. 1-15. , http://arxiv.org/abs/1609.03499, (2016); Rai, P., Hal Daume, The infinite hierarchical factor regression model (2009) Advances in Neural Information Processing Systems 21, pp. 1321-1328. , http://arxiv.org/abs/0908.0570, (2009); Ratcliff, R., McKoon, G., The diffusion decision model: Theory and data for two-choice decision tasks (2008) Neural Computation, 20 (4), pp. 873-922. , https://doi.org/10.1162/neco.2008.12-06-420, (4 2008); Santoro, A., Bartunov, S., Botvinick, M., Wierstra, D., Lillicrap, T., (2016) One-shot Learning with Memory-Augmented Neural Networks, , http://arxiv.org/abs/1605.06065, (5 2016); Smith, P.L., Ratcliff, R., Psychology and neurobiology of simple decisions (2004) Trends in Neurosciences, , https://doi.org/10.1016/j.tins.2004.01.006, (2004); Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going Deeper with Convolutions, , [n. d.]. ([n. d.]); Tenenbaum, J.B., Kemp, C., Griffiths, T.L., Goodman, N.D., Howto growa mind: Statistics, structure, and abstraction (2011) Science, 331 (6022), p. 1279. , http://science.sciencemag.org/content/331/6022/1279.abstract, (3 2011); Ghahramani, Z., Griffiths, T.L., Infinite latent feature models and the Indian buffet process (2005) Advances in Neural Information Processing Systems 18, pp. 475-482. , http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.60.3951, (2005); Vinyals, O., Blundell, C., Lillicrap, T., Kavukcuoglu, K., Wierstra, D., (2016) Matching Networks for One Shot Learning, , http://arxiv.org/abs/1606.04080, (6 2016); Wu, Y., Schuster, M., Chen, Z., Le, Q.V., Norouzi, M., Macherey, W., Krikun, M., Dean, J., (2016) Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation, , http://arxiv.org/abs/1609.08144, (9 2016)},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Tavani2018,
author={Tavani, H.T.},
title={Can social robots qualify for moral consideration? Reframing the question about robot rights},
journal={Information (Switzerland)},
year={2018},
volume={9},
number={4},
doi={10.3390/info9040073},
art_number={73},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044820838&doi=10.3390%2finfo9040073&partnerID=40&md5=2acbdb6087547458868bbe6b559a8822},
abstract={A controversial question that has been hotly debated in the emerging field of robot ethics is whether robots should be granted rights. Yet, a review of the recent literature in that field suggests that this seemingly straightforward question is far from clear and unambiguous. For example, those who favor granting rights to robots have not always been clear as to which kinds of robots should (or should not) be eligible; nor have they been consistent with regard to which kinds of rights-civil, legal, moral, etc.-should be granted to qualifying robots. Also, there has been considerable disagreement about which essential criterion, or cluster of criteria, a robot would need to satisfy to be eligible for rights, and there is ongoing disagreement as to whether a robot must satisfy the conditions for (moral) agency to qualify either for rights or (at least some level of) moral consideration. One aim of this paper is to show how the current debate about whether to grant rights to robots would benefit from an analysis and clarification of some key concepts and assumptions underlying that question. My principal objective, however, is to show why we should reframe that question by asking instead whether some kinds of social robots qualify for moral consideration as moral patients. In arguing that the answer to this question is "yes," I draw from some insights in the writings of Hans Jonas to defend my position. © 2018 by the author.},
author_keywords={Hans Jonas;  Moral agents;  Moral consideration;  Moral patients;  Robot ethics;  Robot rights;  Social robots},
keywords={Philosophical aspects, Hans Jonas;  Moral agents;  Moral consideration;  Moral patients;  Robot ethics;  Social robots, Robots},
references={Decker, M., Gutmann, M., Robo- and Information-Ethics: Some Introducing Remarks (2012) Robo- and Information-Ethics: Some Fundamentals; Decker, pp. 3-6. , M., Gutmann, M., Eds.; LIT Verlag: Berlin, Germany; Verrugio, G., Abney, K., Roboethics: The Applied Ethics for a New Science (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 347-363. , Lin P., Abney, K., Bekey, G., Eds.; MIT Press: Cambridge, MA, USA; Anderson, M., Anderson, S.L., General Introduction (2011) Machine Ethics; Anderson, pp. 1-4. , M., Anderson, S.L., Eds.; Cambridge University Press: Cambridge, MA, USA; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press: New York, NY, USA; Gunkel, D.J., The Other Question: Can and Should Robots Have Rights? (2017) Ethics Inf. Technol., pp. 1-13; Coeckelbergh, M., Robot Rights? Towards a Social-Relational Justification of Moral Consideration (2010) Ethics Inf. Technol., 12, pp. 209-221; Gerdes, A., The Issue of Moral Consideration in Robot Ethics (2015) ACM SIGCAS Comput. Soc., 45, pp. 274-279; Jonas, H., (1984) The Imperative of Responsibility: In Search of an Ethics for the Technological Age, , University of Chicago Press: Chicago, IL, USA; Bekey, G., Current Trends in Robotics: Technology and Ethics (2012) Robot Ethics: The Ethical and Social Implications of Robotics; Lin, pp. 17-34. , P., Abney, K., Bekey, G., Eds.; MIT Press: Cambridge, MA, USA; Capurro, R., Nagenborg, M., Introduction (2009) Ethics and Robotics; Capurro, pp. v-ix. , R., Nagenborg, M., Eds.; AKA Press: Heidelberg, Germany; Sullins, J.P., When Is a Robot a Moral Agent? (2011), pp. 151-161. , In Machine Ethics; Anderson, M., Anderson, S.L., Eds.; Cambridge University Press: Cambridge, MA, USA; Scheutz, M., The Inherent Dangers of Unidirectional Emotional Bonds between Humans and Social Robots (2012) Robot Ethics: The Ethical and Social Implications of Robotics; Lin, pp. 205-221. , P., Abney, K., Bekey, G., Eds.; MIT Press: Cambridge, MA, USA; LaGrandeur, K., Emotion, Artificial Intelligence, and Ethics (2015) Beyond Artificial Intelligence: The Disappearing Human-Machine Divide; Romportl, pp. 97-109. , J., Zackova, E., Kelemen, J., Eds.; Springer: Berlin, Germany; Darling, K., Extending Legal Protection to Social Robots: The Effects of Anthropomorphism, Empathy, and Violent Behavior towards Robotic Objects (2016) Robot Law; Calor, pp. 213-231. , R., Froomkin, A.M., Keri, I., Eds.; Edgar Elgar Publishing: Cheltenham, UK; Breazeal, C.L., (2002) Designing Sociable Robots, , MIT Press: Cambridge, MA, USA; Turkle, S., (2011) Alone Together: WhyWe Expect More from Technology and Less from Each Other, , Basic Books: New York, NY, USA; Turkle, S., Authenticity in theAge ofDigital Companions (2011), pp. 62-78. , In Machine Ethics; Anderson,M., Anderson,M.L., Eds.; Cambridge University Press: Cambridge,MA, USA; Lin, P., Introduction to Robot Ethics (2012) Robot Ethics: The Ethical and Social Implications of Robotics; Lin, pp. 3-15. , P., Abney, K., Bekey, G., Eds.; MIT Press: Cambridge, MA, USA; Draft Report with Recommendations to the Commission on Civil Law Rules on Robotics (2016) European Parliament., , http://www.europarl.europa.eu/sides/getDoc.do?type=COMPARL&reference=PE-582.443&format=PDF&language=EN&secondRef=01, accessed on 18 January 2018; Wootson, C.R., Saudi Arabia, Which Denies Women Equal Rights, Makes a Robot a Citizen (2018) The Washington Post, , https://www.washingtonpost.com/news/innovations/wp/2017/10/29/saudi-arabia-which-denies-women-equal-rights-makes-a-robot-a-citizen/?utm_term=.e59cdc8cd981, 29 October 2017, (accessed on 26 February; Laukyte, M., Artificial Agents Among Us: Should We Recognize Them as Agents Proper? Ethics Inf (2017) Technol., 19, pp. 1-17; Darling, K., Extending Legal Protection to Social Robots (2012), https://spectrum.ieee.org/automaton/robotics/artificial-intelligence/extending-legal-protection-to-social-robots, accessed on 27 November 2017; Coeckelbergh, M., Moral Appearances: Emotions, Robots, and Human Morality (2010) Ethics Inf. Technol., 12, pp. 235-241; Coeckelbergh, M., (2012) Growing Moral Relations: Critique of Moral Status Ascription, , Palgrave Macmillan: New York, NY, USA; Coeckelbergh, M., Virtual Moral Agency, Virtual Moral Responsibility: On the Moral Significance of Appearance, Perception, and Performance of Artificial Agents (2009) AI Soc., 24, pp. 181-189; Levy, D., The Ethical Treatment of Artificially Conscious Robots (2009) Int. J. Soc. Robot., 1, pp. 209-216; Sparrow, R., Can Machines Be People? Reflections on the Turing Triage Test (2011) Machine Ethics; Anderson, pp. 301-315. , M., Anderson, S.L., Eds.; Cambridge University Press: Cambridge, MA, USA; Coeckelbergh, M., CanWe Trust Robots? Ethics Inf (2012) Technol., 14, pp. 53-60; Buechner, J., Tavani, H.T., Trust and Multi-Agent Systems: Applying the 'Diffuse, Default Model' of Trust to Experiments Involving Artificial Agents (2011) Ethics Inf. Technol., 13, pp. 39-51; Tavani, H.T., Levels of Trust in the Context of Machine Ethics (2015) Philos. Technol., 28, pp. 75-90; Taddeo, M., Defining Trust and E-Trust: Old Theories and New Problems (2009) Int. J. Technol. Hum. Interact., 5, pp. 23-35; Taddeo, M., Modeling Trust in Artificial Agents: A First Step in the Analysis of E-Trust (2010) Minds Mach., 20, pp. 243-257; Grodzinsky, F.S., Miller, K.W., Wolf, M.J., Developing Artificial AgentsWorthy of Trust: Would You Buy a Used Car from this Artificial Agent? Ethics Inf (2011) Technol., 13, pp. 17-27; Grodzinsky, F.S., Miller, K.W., Wolf, M.J., Trust in Artificial Agents (2018) Routledge Handbook on Trust and Philosophy, , Simon, J., Ed.; Routledge: New York, NY, USA, In press; Dennett, D., (1987) The Intentional Stance, , MIT Press: Cambridge, MA, USA; Tavani, H.T., Ethical Aspects of Autonomous Systems (2012) Robo- and Information-Ethics: Some Fundamentals; Decker, pp. 89-122. , M., Gutmann, M., Eds.; LIT Verlag: Berlin, Germany; Floridi, L., Sanders, J.W., Artificial Evil and the Foundation of Computer Ethics (2001) Ethics Inf. Technol., 3, pp. 55-66; Floridi, L., Sanders, J.W., On the Morality of Artificial Agents (2004) Minds Mach., 14, pp. 349-379; Floridi, L., Foundations of Information Ethics (2008) The Handbook of Information and Computer Ethics; Himma, pp. 3-23. , K.E., Tavani, H.T., Eds.; JohnWiley and Sons: Hoboken, NJ, USA; Tavani, H.T., Buechner, J., Autonomy and Trust in the Context of Artificial Agents (2015) Evolutionary Robotics, pp. 39-62. , Organic Computing and Adaptive Ambience; Decker, M., Gutmann, M., Knifka, J., Eds.; LIT Verlag: Berlin, Germany; Floridi, L., (2013) The Ethics of Information, , Oxford University Press: Oxford, UK; Johnson, D.G., Computer Systems: Moral Entities but Not Moral Agents (2006) Ethics Inf. Technol., 8, pp. 195-204; Himma, K.E., Artificial Agency, Consciousness, and the Criteria for Moral Agency: What Properties Must an Artificial Agent Have to be a Moral Agent? Ethics Inf (2009) Technol., 11, pp. 19-29; Behdadi, D., Munthe, C., Artificial Moral Agency: Philosophical Assumptions, Methodological Challenges, and Normative Solutions (2018), https://www.researchgate.net/publication/311196481_Artificial_Moral_Agency_Philosophical_Assumptions_Methodological_Challenges_and_Normative_Solutions, Manuscript under Consideration for Publication, (accessed on 15 February 2018; Tavani, H.T., Can We Develop Artificial Agents Capable of Making Good Moral Decisions? (2011) Minds Mach., 21, pp. 465-474; Moor, J.H., The Nature, Difficulty, and Importance of Machine Ethics (2006) IEEE Intell. Syst., 21, pp. 18-21; Moor, J.H., Four Kinds of Ethical Robots (2009) Philos. Now, 72, pp. 12-14; Hogan, K., Is the Machine Question the Same as the Animal Question? Ethics Inf (2017) Technol., 19, pp. 29-38; Tavani, H.T., (2016) Ethics and Technology: Controversies, Questions, and Strategies for Ethical Computing, 5th ed., , John Wiley and Sons: Hoboken, NJ, USA; Power, T., On the Moral Agency of Computers (2003) Topoi, 32, pp. 227-236; Jonas, H., (2008) Memoirs, , Brandeis University Press: Waltham, MA, USA; Kant, I., (1991) The Metaphysics of Morals, , Cambridge University Press: Cambridge, UK; Gunkel, D.J., (2007) Thinking Otherwise, , Purdue University Press: West Lafayette, IN, USA; Levinas, E., (1969) Totality and Infinity: An Essay on Exteriority, , Lingis, A., Translator; Duquesne University Press: Pittsburgh, PA, USA; Gunkel, D.J., (2012) The Machine Question-Critical Perspectives on AI, Robots, and Ethics, , MIT Press: Cambridge, MA, USA; Tavani, H.T., The Impact of the Internet on Our Moral Condition: Do We Need a New Framework of Ethics? (2005) In The Impact of the Internet on Our Moral Lives, pp. 215-237. , Cavalier, R., Ed.; State University of New York Press: Albany, NY, USA; Michelfelder, D., Our Moral Condition in Cyberspace (2000) Ethics Inf. Technol., 2, pp. 147-152; Carr, L., On What Grounds MightWe Have Moral Obligations to Robots? (2018), https://www2.rivier.edu/faculty/lcarr/OUR%20MORAL%20OBLIGATION%20TO%20ROBOTS.pdf, accessed on 26 March 2018; Floridi, L., Information Ethics: On the Philosophical Foundation of Computer Ethics (1999) Ethics Inf. Technol., 1, pp. 37-56; Floridi, L., On the Intrinsic Value of Information Objects in the Infosphere (2002) Ethics Inf. Technol., 4, pp. 287-304; De Laat, P.B., Trusting the (Ro)botic Other: By Assumption? (2016) ACM SIGCAS Comput Soc., 45, pp. 255-260},
document_type={Article},
source={Scopus},
}

@ARTICLE{Schafer2017200,
author={Schafer, B. and Edwards, L.},
title={“I spy, with my little sensor”: fair data handling practices for robots between privacy, copyright and security},
journal={Connection Science},
year={2017},
volume={29},
number={3},
pages={200-209},
doi={10.1080/09540091.2017.1318356},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019756891&doi=10.1080%2f09540091.2017.1318356&partnerID=40&md5=d38036d5a0eaa821947f53f8f41aaba7},
abstract={The paper suggests an amendment to Principle 4 of ethical robot design, and a demand for “transparency by design”. It argues that while misleading vulnerable users as to the nature of a robot is a serious ethical issue, other forms of intentionally deceptive or unintentionally misleading aspects of robotic design pose challenges that are on the one hand more universal and harmful in their application, on the other more difficult to address consistently through design choices. The focus will be on transparent design regarding the sensory capacities of robots. Intuitive, low-tech but highly efficient privacy preserving behaviour is regularly dependent on an accurate understanding of surveillance risks. Design choices that hide, camouflage or misrepresent these capacities can undermine these strategies. However, formulating an ethical principle of “sensor transparency” is not straightforward, as openness can also lead to greater vulnerability and with that security risks. We argue that the discussion on sensor transparency needs to be embedded in a broader discussion of “fair data handling principles” for robots that involve issues of privacy, but also intellectual property rights such as copyright. © 2017 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={copyright;  Design ethics;  principles of robotics;  privacy;  robot ethics},
keywords={Copyrights;  Data handling;  Data privacy;  Intellectual property;  Laws and legislation;  Philosophical aspects;  Robotics;  Robots;  Transparency, Design ethics;  Ethical issues;  Ethical principles;  Intellectual property rights;  Privacy preserving;  Robot ethics;  Robotic design;  Security risks, Machine design},
references={Arendt, H., (1959) The human condition: A study of the central dilemmas facing modern man, , New York, NY: Doubleday; Chadwick, R., Berg, K., Solidarity and equity: New ethical frameworks for genetic databases (2001) Nature Reviews Genetics, 2 (4), pp. 318-321; DeCew, J.W., (1997) In pursuit of privacy: Law, ethics, and the rise of technology, , New York: Cornell University Press; Fradella, H.F., Morrow, W.J., Fischer, R.G., Ireland, C., Quantifying Katz: Empirically measuring reasonable expectations of privacy in the fourth amendment context (2010) American Journal of Criminal Law, 38, pp. 289-374; Hamill, L., Controlling smart devices in the home (2006) The Information Society, 22 (4), pp. 241-249; Kang, J., Information privacy in cyberspace transactions (1998) Stanford Law Review, 50 (1193), pp. 1193-1294; MacDorman, K.F., Minato, T., Shimada, M., Itakura, S., Cowley, S., Ishiguro, H., Assessing human likeness by eye contact in an android testbed (2005) Proceedings of the XXVII annual meeting of the cognitive science society, pp. 21-23. , Mahwah: Lawrence Erlbaum Associates; Sag, M., Copyright and copy-reliant technology (2009) Northwestern University Law Review, 103, pp. 1607-1682; Xu, T.L., Zhang, H., Yu, C., See you see me: The role of eye contact in multimodal human-robot interaction (2016) ACM Transactions on Interactive Intelligent Systems (TiiS), 6 (1), pp. 2-22; Yonezawa, T., Yamazoe, H., Utsumi, A., Abe, S., Gaze-communicative behavior of stuffed-toy robot with joint attention and eye contact based on ambient gaze-tracking (2007) Proceedings of the 9th international conference on multimodal interfaces, pp. 140-145. , New York: ACM},
document_type={Article},
source={Scopus},
}

@ARTICLE{Clempner2017,
author={Clempner, J.B.},
title={A game theory model for manipulation based on machiavellianism: Moral and ethical behavior},
journal={JASSS},
year={2017},
volume={20},
number={2},
doi={10.18564/jasss.3301},
art_number={12},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017026941&doi=10.18564%2fjasss.3301&partnerID=40&md5=73b39213657155451978efe433ea4ed7},
abstract={This paper presents a new game theory approach for modeling manipulation behavior based on Machiavellianism (social conduct and intelligence theory). The Machiavellian game conceptualizes the Machiavellianism considering three concepts: views, tactics and immorality. For modeling the Machiavellian views and tactics we employ a Stackelberg/Nash game theory approach. For representing the concept of immorality, we consider that rational Machiavellian players employ a combination of the deontological and utilitarian moral rules, as well as, moral heuristics. We employ a reinforcement learning approach for the implementation of the immorality concept providing a computational mechanism, in which, its principle of error-driven adjustment of cost/reward predictions contributes to the players’ acquisition of moral (immoral) behavior. The reinforcement learning algorithm is based on an actor-critic approach responsible for evaluating the new state of the system and it determines if the cost/rewards are better or worse than expected, supported by the Machiavellian game theory solution. The result of the model is the manipulation equilibrium point. We provide the details needed to implement the extraproximal method in an efficient and numerically stable way. Finally, we present a numerical example that validates the effectiveness of the manipulation model. © 2017, University of Surrey. All rights reserved.},
author_keywords={Behavioral games;  Machiavellian intelligence;  Machiavellianism;  Machine ethics;  Markov chains;  Moral;  Stackelberg/nashgame},
references={Antipin, A.S., An extraproximal method for solving equilibrium programming problems and games (2005) Computational Mathematics and Mathematical Physics, 45 (11), pp. 1893-1914; Bales, R.E., Act-utilitarianism: Account of right-making characteristics or decision-making procedures? (1971) American Philosophical Quarterly, 8, pp. 257-265; Byrne, R., Whiten, A., (1988) Machiavellianism Intelligence, , The Evolution of the Intellect in Monkeys, Apes and Humans. Claredon Press; Calhoun, R.P., Niccolò Machiavelli and the 20th century administrator (1969) Academy of Management Journal, 12, pp. 205-212; Cervantes, J.A., Rodriguez, L.F., Lopez, S., Ramos, F., Robles, F., Autonomous agents and ethical decision-making (2011) Cognitive Computation, 8, pp. 278-296; Christie, R., Geis, F., (1970) Studies in Machiavellianism, , Academic Press; Cleckley, H., (1976) The Mask of Sanity, , Mosby, 5th edn; Clempner, J.B., Poznyak, A.S., Simple computing of the customer lifetime value: A fixed local-optimal policy approach (2014) Journal of Systems Science and Systems Engineering, 23 (4), pp. 439-459; Dawkins, R., (1976) The Selfish Gene, , Oxford: Oxford University Press; Dawkins, R., Krebs, J., (1978) Animal Signals: Information Or Manipulation, , Blackwell; Dehghani, M., Tomai, E., Forbus, K., Klenk, M., An integrated reasoning approach to moral decisionmaking (2008) Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence, pp. 1280-1286. , Chicago, Illinois, USA; Falbo, T., Multidimensional scaling of power strategies (1977) Journal of Personality and Social Psychology, 35, pp. 537-547; Gable, M., Hollon, C., Dangello, F., Managerial structuring of work as a moderator of the machiavellianism and job performance relationship (1992) The Journal of Psychology, 126 (3), pp. 317-325; Grams, W., Rogers, R., Power and personality: Effects of machiavellianism, need for approval, and motivation on use of influence tactics (1990) The Journal of General Psychology, 117 (1), pp. 71-82; Hartog, D.N.D., Belschak, F.D., Work engagement and Machiavellianism in the ethical leadership process (2012) Journal of Business Ethics, 107, pp. 35-47; Hellriegel, D., Slocum, J., Woodman, R., Organizational Behavior (1997) South-Western Educational Publishing; Indurkhya, B., Misztal-Radecka, J., (2016) Incorporating Human Dimension in Autonomous Decision-Making on Moral and Ethical Issues, pp. 226-230. , In AAAI Spring Symposium Series, Stanford University; Leary, M., Knight, R., Barns, B., Ethical ideologies of the Machiavellian (1986) Personality Andsocial Psychology Bulletin, 12, pp. 75-80; Machiavelli, N., (1952) The Prince, , Encyclopedia Brittanica, Inc; Machiavelli, N., (1965) Discourses in the First Ten Books of Titus Livius, , Duke University Press; Machiavelli, N., The Art of War (2001) Da Capo Press; Mudrack, P., Machiavellianism and locus of control: A meta-analytic review (1989) The Journal of Social Psychology, 130 (1), pp. 125-126; Poznyak, A.S., (2008) Advanced Mathematical Tools for Automatic Control Engineers. Deterministic Technique, 1. , Elsevier, Amsterdam, Oxford; Poznyak, A.S., Najim, K., Gomez-Ramirez, E., (2000) Self-Learning Control of Finite Markov Chains, , Marcel Dekker, Inc., New York; Prociuk, T.J., Breen, L.J., Machiavellianism and locus of control (1976) The Journal of Social Psychology, 9, pp. 141-142; Raven, B.H., Machiavellianism and locus of control (1993) The Journal of Social Psychology, 43 (4), pp. 227-251; Sanchez, E.M., Clempner, J.B., Poznyak, A.S., A priori-knowledge/actor-critic reinforcement learning architecture for computing the mean-variance customer portfolio: The case of bank marmarket campaigns (2015) Engineering Applications of Artificial Intelligence, 46, pp. 82-92; Schindler, J., Rethinking the tragedy of the commons: The integration of socio-psychological dispositions (2012) Journal of Artificial Societies and Social Simulation, 15 (1), 4p; Smith, R., (1979) The Psychopath in Society, , Academic Press; Solar, D., Bruehl, D., Machiavellianism and locus of control: Two conceptions of interpersonal power (1971) Psychological Reports, 29, pp. 1079-1082; Stackelberg, H.V., (2011) Market Structure and Equilibrium, , Springer; Tobler, P.N., Kalis, A., Kalenscher, T., The role of moral utility in decision making: An interdisciplinary framework. Cognitive (2008) Affective, & Behavioral Neuroscience, 8 (4), pp. 390-401; Trejo, K.K., Clempner, J.B., Poznyak, A.S., Computing the Stackelberg/Nash equilibria using the extraproximal method: Convergence analysis and implementation details for Markov chains games (2015) International Journal of Applied Mathematics and Computer Science, 25 (2), pp. 337-351; Trejo, K.K., Clempner, J.B., Poznyak, A.S., An optimal strong equilibirum solution for cooperative multi-leader-follower Stackelberg Markov chains games (2016) Kibernetika, 52 (2), pp. 258-279; Vecchio, R.P., Sussmann, M., Choice of influence tactics: Individual and organizational determinants (1991) Journal of Organizational Behavior, 12, pp. 73-80; Vleeming, R., Machiavellianism and locus of control: Two conceptions of interpersonal power (1979) Psychological Reports, 44, pp. 295-310; Wallach, W., Franklin, S., Allen, C., A conceptual and computational model of moral decision making in human and artificial agents (2010) Topics in Cognitive Science, 2 (3), pp. 454-485; Wijermans, N., Jorna, R., Jager, W., Van Vliet, T., Adang, O., Cross: Modelling crowd behaviour with social-cognitive agents (2013) Journal of Artificial Societies and Social Simulation, 16 (4), p. 1; Wilson, D., Near, D., Miller, R., Machiavellianism: A synthesis of the evolutionary and psychological literatures (1996) Psychological Bulletin, 119 (2), pp. 285-299; Xianyu, B., Social preference, incomplete information, and the evolution of ultimatum game in the small world networks: An agent-based approach (2010) Journal of Artificial Societies and Social Simulation, 13 (2), 7p},
document_type={Article},
source={Scopus},
}

@ARTICLE{Omari2016231,
author={Omari, R.M. and Mohammadian, M.},
title={Rule based fuzzy cognitive maps and natural language processing in machine ethics},
journal={Journal of Information, Communication and Ethics in Society},
year={2016},
volume={14},
number={3},
pages={231-253},
doi={10.1108/JICES-10-2015-0034},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982986550&doi=10.1108%2fJICES-10-2015-0034&partnerID=40&md5=79184ca47788ff75ec3b2c15f2043667},
abstract={Purpose: The developing academic field of machine ethics seeks to make artificial agents safer as they become more pervasive throughout society. In contrast to computer ethics, machine ethics is concerned with the behavior of machines toward human users and other machines. This study aims to use an action-based ethical theory founded on the combinational aspects of deontological and teleological theories of ethics in the construction of an artificial moral agent (AMA). Design/methodology/approach: The decision results derived by the AMA are acquired via fuzzy logic interpretation of the relative values of the steady-state simulations of the corresponding rule-based fuzzy cognitive map (RBFCM). Findings: Through the use of RBFCMs, the following paper illustrates the possibility of incorporating ethical components into machines, where latent semantic analysis (LSA) and RBFCMs can be used to model dynamic and complex situations, and to provide abilities in acquiring causal knowledge. Research limitations/implications: This approach is especially appropriate for data-poor and uncertain situations common in ethics. Nonetheless, to ensure that a machine with an ethical component can function autonomously in the world, research in artificial intelligence will need to further investigate the representation and determination of ethical principles, the incorporation of these ethical principles into a system’s decision procedure, ethical decision-making with incomplete and uncertain knowledge, the explanation for decisions made using ethical principles and the evaluation of systems that act based upon ethical principles. Practical implications: To date, the conducted research has contributed to a theoretical foundation for machine ethics through exploration of the rationale and the feasibility of adding an ethical dimension to machines. Further, the constructed AMA illustrates the possibility of utilizing an action-based ethical theory that provides guidance in ethical decision-making according to the precepts of its respective duties. The use of LSA illustrates their powerful capabilities in understanding text and their potential application as information retrieval systems in AMAs. The use of cognitive maps provides an approach and a decision procedure for resolving conflicts between different duties. Originality/value: This paper suggests that cognitive maps could be used in AMAs as tools for meta-analysis, where comparisons regarding multiple ethical principles and duties can be examined and considered. With cognitive mapping, complex and abstract variables that cannot easily be measured but are important to decision-making can be modeled. This approach is especially appropriate for data-poor and uncertain situations common in ethics. © 2016, © Emerald Group Publishing Limited.},
author_keywords={Decision making and ethics;  Natural language processing in machine ethics;  Rule based fuzzy cognitive maps},
references={Aizawa, A., An information-theoretic perspective of tf–idf measures (2003) Information Processing & Management, 39 (1), pp. 45-65; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12 (2000), pp. 251-261; Anderson, M., Anderson, S.L., Machine ethics: creating an ethical intelligent agent (2007) AI Magazine, 28 (4), p. 15; Anderson, M., Anderson, S.L., Armen, C., (2004) Towards machine ethics, , Proceedings of AAAI, San Jose, CA; Anderson, M., Anderson, S.L., Armen, C., An approach to computing ethics (2006) Intelligent Systems, IEEE, 21 (4), pp. 56-63; Arkin, R.C., (2008) Governing lethal behavior: embedding ethics in a hybrid deliberative/reactive robot architecture part I: motivation and philosophy, pp. 121-128. , IEEE, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI), Amsterdam; Beauchamp, T.L., Childress, J.F., (2001) Principles of Biomedical Ethics, , Oxford University Press, Oxford; Bostrum, N., (2014) Superintelligence: Paths, Dangers, Strategies, , Oxford University Press, Oxford; Carvalho, J.P., Tomè, J.A., (1999) Rule based fuzzy cognitive maps-fuzzy causal relations, , Mohammadian, M.and (Ed.), 18th International Conference of the North American Fuzzy Information Processing Society (NAFIPS), IEEE, New York, NY; Carvalho, J.P., Tomè, J.A., (1999) Rule based fuzzy cognitive maps and fuzzy cognitive maps-a comparative study, pp. 115-119. , IEEE, 18th International Conference of the North American Fuzzy Information Processing Society, 1999 NAFIPS, New York, NY; Carvalho, J.P., Tomè, J.A., (2000) Rule based fuzzy cognitive maps-qualitative systems dynamics, pp. 407-411. , IEEE, 19th International Conference of the North American Fuzzy Information Processing Society, 2000 NAFIPS, Atlanta, GA; Chen, C.H., Weng, Y.H., Sun, C.T., Toward the human-robot co-existence society: on safety intelligence for next generation robots (2009) Social Robotics, 1 (4), p. 267; Dehak, N., Dehak, R., Glass, J., Reynolds, D., Kenny, P., (2010) Cosine similarity scoring without score normalization techniques, pp. 71-75. , Proceedings of Odyssey Speaker and Language Recognition Workshop, Brno; Dickerson, J.A., Kosko, B., (1993) Virtual worlds as fuzzy cognitive maps, pp. 471-477. , IEEE, Virtual Reality Annual International Symposium, Seattle, WA; Dumais, S.T., Latent semantic analysis (2004) Annual Review of Information Science and Technology, 38 (1), pp. 188-230; Foltz, P.W., Laham, D., Landauer, T.K., The intelligent essay assessor: applications to educational technology (1999) Interactive Multimedia Electronic Journal of Computer-Enhanced Learning, 1 (2); Hofmann, T., (1999) Probabilistic latent semantic indexing, pp. 50-57. , ACM, Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, New York, NY; Klema, V., Laub, A., The singular value decomposition: its computation and some applications (1980) IEEE Transactions on Automatic Control, 25 (2), pp. 164-176; Kosko, B., (1997) Fuzzy Engineering, , Prentice Hall, New York, NY; Laham, T.K.L.D., Foltz, P., (1998) Learning human-like knowledge by singular value decomposition: a progress report, 10, p. 45. , December 1997, MIT Press, p., Advances in Neural Information Processing Systems 10: Proceedings of the 1997 Conference: [Eleventh Annual Conference on Neural Information Processing (NIPS), Denver, Colorado; Landauer, T.K., Foltz, P.W., Laham, D., An introduction to latent semantic analysis (1998) Discourse Processes, 25 (2-3), pp. 259-284; McCarthy, J., Hayes, P.J., (1969) Some philosophical problems from the standpoint of artificial intelligence, pp. 431-450. , Proceedings of the Fourth Annual Machine Intelligence Workshop, Edinburgh University Press, Edinburgh; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) Intelligent Systems, 21 (4), pp. 18-21. , IEEE; Mouratiadou, I., Moran, D., Mapping public participation in the water framework directive: a case study of the Pinios River Basin, Greece (2007) Ecological Economics, 62 (1), pp. 66-76; Papageorgiou, E.I., Parsopoulos, K.E., Stylios, C.S., Groumpos, P.P., Vrahatis, M.N., Fuzzy cognitive maps learning using particle swarm optimization (2005) Journal of Intelligent Information Systems, 25 (1), pp. 95-121; Reimann, S., On the design of artificial auto-associative neuronal networks (1998) Neural Networks, 11 (4), pp. 611-621; Ross, W.D., (1930) The Right and the Good, , Clarendon Press, Oxford; Shulman, C., Jonsson, H., Tarleton, N., (2009) Machine ethics and super intelligence, pp. 95-97. , The Fifth Asia-Pacific Computing and Philosophy Conference, 1-2 October, University of Tokyo, Japan; Yampolskiy, R.V., (2013) Artificial Intelligence Safety Engineering: Why Machine Ethics is a Wrong Approach, pp. 389-396. , Springer, Berlin, Heidelberg; Zadeh, L.A., Fuzzy sets (1965) Information and Control, 8 (3), pp. 338-353; Eden, C., Ackermann, F., Cropper, S., The analysis of cause maps (1992) Journal of Management Studies, 29 (3), pp. 309-324; Klein, J.H., Cooper, D.F., Cognitive maps of decision-makers in a complex game (1982) Journal of the Operational Research Society, 33 (1), pp. 63-71. , Kandel, A.and (Ed.), Fuzzy Expert Systems, CRC Press, Boca Raton; Kosko, B., (1987) Adaptive inference in fuzzy knowledge networks, 2 (1), pp. 261-268. , Proceedings of 1st International Conference on Neural Networks; Kosko, B., Hidden patterns in combined and adaptive knowledge networks (1988) International Journal of Approximate Reasoning, 2 (4), pp. 377-393; Kosko, B., Fuzzy associative memory systems (1992) Fuzzy Expert Systems, pp. 135-162. , Kandel, A (Ed.), CRC Press, Boca Raton, FL; Özesmi, U., (2001) Bilissel (Kognitif) Haritalamaya Gore HalkinTalepleri (The wants and desires of the local population based on cognitive mapping), pp. 154-169. , Yusufeli Baraji Yeniden Yerlesim Plani (Yusufeli Damlake Resettlement Plan), Devlet Su Isleri (DSI)(State Hydraulic Works). Sahara Muhendislik, Ankara; Taber, R., Knowledge processing with fuzzy cognitive maps (1991) Expert Systems with Applications, 2 (1), pp. 83-87; Turing, A.M., Computing machinery and intelligence (1950) Mind, 59 (236), pp. 433-460},
document_type={Article},
source={Scopus},
}

@ARTICLE{Madl2015137,
author={Madl, T. and Franklin, S.},
title={Constrained incrementalist moral decision making for a biologically inspired cognitive architecture},
journal={Cognitive Technologies},
year={2015},
volume={40},
pages={137-153},
doi={10.1007/978-3-319-21548-8_8},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948753246&doi=10.1007%2f978-3-319-21548-8_8&partnerID=40&md5=0329d59ab4d7872d7345c924783364d1},
abstract={Although most cognitive architectures, in general, and LIDA, in particular, are still in the early stages of development and still far from being adequate bases for implementations of human-like ethics, we think that they can contribute to the understanding, design, and implementation of constrained ethical systems for robots, and we hope that the ideas outlined here might provide a starting point for future research. © Springer International Publishing Switzerland 2015.},
author_keywords={Artificial moral agent;  Cognitive architecture;  LIDA;  Machine ethics;  Robot ethics},
keywords={Architecture;  Decision making;  Machine design;  Philosophical aspects, Biologically inspired;  Cognitive architectures;  Human like;  LIDA;  Moral agents;  Robot ethics, Cognitive systems},
references={Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) J. Exp. Theor. Artif. Intell, 12 (3), pp. 251-261; Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge University Press, Cambridge; Lin, P., Abney, K., Bekey, G.A., (2011) Robot Ethics: The Ethical and Social Implications of Robotics, , MIT Press, Cambridge; Wallach, W., Allen, C., (2008) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press, Oxford; (2013) World Robotics 2013 Service Robot Statistics; Graf, B., Hans, M., Schraft, R.D., Care-o-bot II-development of a next generation robotic home assistant (2004) Auton. Robot, 16 (2), pp. 193-205; Tellez, R., Ferro, F., Garcia, S., Gomez, E., Jorge, E., Mora, D., Pinyol, D., Faconti, D., Reem-b: An autonomous lightweight human-size humanoid robot (2008) 8th IEEE-RAS International Conference on Humanoid Robots, pp. 462-468. , IEEE, New York; Burns, L.D., Sustainable mobility: A vision of our transport future (2013) Nature, 497 (7448), pp. 181-182; Ciupe, V., Maniu, I., New trends in service robotics (2014) New Trends in Medical and Service Robots, pp. 57-74. , Springer, Berlin; Alonso, I.G., Service robotics (2011) Service Robotics Within the Digital Home, pp. 89-114. , Springer, Berlin; Powers, T.M., Incremental machine ethics (2011) IEEE Robot. Autom. Mag, 18 (1), pp. 51-58; Scheutz, M., What is robot ethics? IEEE Robot (2013) Autom. Mag, 20 (4), pp. 20-165; Asaro, P.M., What should we want from a robot ethic (2006) Int. Rev. Inform. Ethics, 6 (12), pp. 9-16; Franklin, S., Madl, T., D'Mello, S., Snaider, J., LIDA: A systems-level architecture for cognition, emotion, and learning (2013) IEEE Trans. Auton. Ment. Dev, 6 (1), pp. 19-41; Baars, B.J., Franklin, S., Consciousness is computational: The LIDA model of global workspace theory (2009) Int. J. Mach. Conscious, 1 (1), pp. 23-32; Sloman, A., What sort of architecture is required for a human-like agent (1999) Foundations of Rational Agency, pp. 35-52. , Springer Netherlands; Wyrobek, K.A., Berger, E.H., Van der Loos, H.M., Salisbury, J.K., Towards a personal robotics development platform: Rationale and design of an intrinsically safe personal robot (2008) ICRA 2008, pp. 2165-2170. , IEEE, New York; Franklin, S., Deliberation and voluntary action in conscious software agents (2000) Neural Netw. World, 10, pp. 505-521; Negatu, A., Franklin, S., McCauley, L., (2006) A Non-routine Problem Solving Mechanism for a General Cognitive Agent Architecture, , Nova Science Publishers, New York; Friedlander, D., Franklin, S., LIDA and a theory of mind (2008) Artificial General Intelligence. 2008: Proceedings of the First AGI Conference, 171, 137p. , IOS Press, Amsterdam; Baars, B.J., Global workspace theory of consciousness: Toward a cognitive neuroscience of human experience (2005) Prog. Brain Res, 150, pp. 45-53; Franklin, S., Patterson, F.G., Jr., The lida architecture: Adding new modes of learning to an intelligent, autonomous, software agent (2006) Pat, 703, pp. 764-1004; McCall, R., Franklin, S., Friedlander, D., D'Mello, S., Grounded event-based and modal representations for objects, relations, beliefs, etc (2010) FLAIRS-23 Conference; Barsalou, L.W., Perceptual symbol systems (1999) Behav. Brain Sci, 22 (4), pp. 577-660; McCall, R., Franklin, S., Cortical learning algorithms with predictive coding for a systemslevel cognitive architecture (2013) Proceedings of the Second Annual Conference on Advances in Cognitive Systems, pp. 149-166; Madl, T., Franklin, S., A lida-based model of the attentional blink (2012) ICCM 2012 Proceedings, 283p; Snaider, J., Franklin, S., Extended sparse distributed memory and sequence storage (2012) Cogn. Comput, 4 (2), pp. 172-180; Kanerva, P., (1988) Sparse Distributed Memory, , MIT Press, Cambridge; Madl, T., Franklin, S., Chen, K., Trappl, R., Spatial working memory in the lida cognitive architecture (2013) Proceedings of the 12th International Conference on Cognitive Modelling, pp. 384-390; Maes, P., How to do the right thing (1989) Connect. Sci, 1 (3), pp. 291-323; Wallach, W., Allen, C., Smit, I., Machine morality: Bottom-up and top-down approaches for modelling human moral faculties (2008) AI & Soc, 22, pp. 565-582; Wallach, W., Franklin, S., Allen, C., A conceptual and computational model of moral decision making in human and artificial agents (2010) Top. Cogn. Sci, 2 (3), pp. 454-485; Larman, C., Basili, V.R., Iterative and incremental developments (2003) A brief history. Computer, 36 (6), pp. 47-56; Müller, M.M., Padberg, F., About the return on investment of test-driven development (2003) EDSER-5 5th International Workshop on Economic-Driven Software Engineering Research, 26p; Williams, L., Maximilien, E.M., Vouk, M., Test-driven development as a defect-reduction practice (2003) 14th International Symposium on Software Reliability Engineering, pp. 34-45. , IEEE, New York; (2011) Casebook on Human Dignity and Human Rights, 1. , Bioethics Core Curriculum Casebook Series, UNESCO, Paris; (2011) Casebook on Benefit and Harm, 2. , Bioethics Core Curriculum Casebook Series, UNESCO, Paris; Pollack, M.E., Intelligent technology for an aging population: The use of ai to assist elders with cognitive impairment (2005) AI Mag, 26 (2), p. 9; Freeman, W.J., The limbic action-perception cycle controlling goal-directed animal behavior (2002) Proceedings of the IEEE International Joint Conference on Neural Networks, 3, pp. 2249-2254; Fuster, J.M., Physiology of executive functions: The perception-action cycle (2002) Principles of Frontal Lobe Function, pp. 96-108. , Oxford University Press, Oxford; Drescher, G.L., (1991) Made-up Minds: A Constructivist Approach to Artificial Intelligence, , MIT Press, Cambridge},
document_type={Book Chapter},
source={Scopus},
}

@BOOK{Hersh20151,
author={Hersh, M.},
title={Ethical engineering for international development and environmental sustainability},
journal={Ethical Engineering for International Development and Environmental Sustainability},
year={2015},
pages={1-391},
doi={10.1007/978-1-4471-6618-4},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947447462&doi=10.1007%2f978-1-4471-6618-4&partnerID=40&md5=a3391f4889a58b2173536faa5ef72962},
abstract={Ensuring that their work has a positive influence on society is a responsibility and a privilege for engineers, but also a considerable challenge. This book addresses the ways in which engineers meet this challenge, working from the assumption that for a project to be truly ethical both the undertaking itself and its implementation must be ethically sound. The contributors discuss varied topics from an international and interdisciplinary perspective, including l robot ethics; l outer space; l international development; 1 internet privacy and security; l green branding; l arms conversion; l green employment; and l deliberate misinformation about climate change Important questions are answered, such as l what is meant by engineering ethics and its practical implications; l how decisions made by engineers in their working lives make an impact at the global as well as the local level; and l what ethics-related questions should be asked before making such decisions. Ethical Engineering for International Development and Environmental Sustainability will be a valuable resource for practising and student engineers as well as all who are interested in professional ethics, especially as it relates to engineering. Researchers and policy makers concerned with the effects of engineering decisions on environmental sustainability and international stability will find this book to be of special interest. © Springer-Verlag London 2015.},
document_type={Book},
source={Scopus},
}

@BOOK{Tanaka2014185,
author={Tanaka, F.},
title={Robotics for supporting childhood education},
journal={Cybernics: Fusion of human, machine and information systems},
year={2014},
volume={9784431541592},
pages={185-195},
doi={10.1007/978-4-431-54159-2_10},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930707942&doi=10.1007%2f978-4-431-54159-2_10&partnerID=40&md5=5c4bff44f2acd0dd6b8521f7f26f9570},
abstract={This chapter describes an instance of Cybernics research for supporting human capabilities through the use of technologies. The main object here is childhood education. With increasing demand for a higher quality of childhood education, a new trend of using robotics technology to support childhood education is emerging. In conjunction with a discussion of robot ethics and social acceptance for robots, the new trend will be described. © 2014 Springer Japan. All rights reserved.},
author_keywords={Care-receiving robot;  Child-robot interaction;  Childcare robot;  Childhood education;  Developmental learning;  Distant communication;  Distant education;  Education support;  Human-robot interaction;  Learning reinforcement;  Learning support;  Robot ethics;  Robotics;  Social acceptance;  Telepresence robot;  Telerobotics;  Tricycle-style interface},
keywords={Human computer interaction;  Human robot interaction;  Philosophical aspects;  Robotics;  Robots;  Social aspects;  Visual communication, Care-receiving robots;  Child-robot interactions;  Childhood education;  Developmental learning;  Distant communications;  Distant educations;  Learning reinforcements;  Learning support;  Robot ethics;  Social acceptance;  Tele-robotics;  Telepresence robots, Education},
references={Kanda, T., Hirano, T., Eaton, D., Ishiguro, H., Interactive robots as social partners and peer tutors for children: A field trial (2004) Hum-Comput Interact, 19 (1-2), pp. 61-84; Kanda, T., Sato, R., Saiwaki, N., Ishiguro, H., A two-month field trial in an elementary school for long-Term human-robot interaction (2007) IEEE Trans Robot, 23 (5), pp. 962-971; Han, J., Jo, M., Jones, V., Jo, J.H., Comparative study on the educational use of home robots for children (2008) J Inf Process Syst, 4 (4), pp. 159-168; Movellan, J.R., Tanaka, F., Fortenberry, B., Aisaka, K., The RUBI/QRIO project: Origins, principles, and first steps (2005) Proceedings of 4th IEEE International Conference on Development and Learning, pp. 80-86. , IEEE Press, Osaka, Japan; Movellan, J.R., Eckhardt, M., Virnes, M., Rodriguez, A., Sociable robot improves toddler vocabulary skills (2009) Proceedings of the 4th ACM/ IEEE International Conference on Humanrobot Interaction, pp. 307-308. , ACM/IEEE, San Diego, USA; Tanaka, F., Cicourel, A., Movellan, J.R., Socialization between toddlers and robots at an early childhood education center (2007) Proc Natl Acad Sci U S A, 104 (46), pp. 17954-17958; Sharkey, N.E., The ethical frontiers of robotics (2008) Science, 322, pp. 1800-1801; Tanaka, F., Kimura, T., Care-receiving robot as a tool of teachers in child education (2010) Interact Stud, 11 (2), pp. 263-268; Nomura, T., Suzuki, T., Kanda, T., Han, J., Shin, N., Burke, J., Kato, K., What people assume about humanoid and animal-Type robots: Cross-cultural analysis between Japan, Korea, and the USA (2008) Int J Hum Robot, 5 (1), pp. 25-46; Tanaka, F., Kimura, T., The use of robots in early education: A scenario based on ethical consideration (2009) Proceedings of the 18th IEEE International Symposium on Robot and Human Interactive Communication, pp. 558-560. , IEEE Press, Toyama, Japan; Tanaka, F., Matsuzoe, S., Care-receiving robot to promote childrens learning by teaching: Field experiments at a classroom for vocabulary learning (2012) J Hum-Robot Interact, 1, pp. 78-95; Tachi, S., (2003) Telecommunication, Teleimmersion and Telexistence, , Ohmsha, Tokyo and IOS Press, Amsterdam; Ishiguro, H., Android science: Conscious and subconscious recognition (2006) Connect Sci, 18 (4), pp. 319-332; Tanaka, F., Takahashi, T., A tricycle-style teleoperational interface that remotely controls a robot for classroom children (2012) Proceedings of the 7th ACM/ IEEE International Conference on Human-robot Interaction, pp. 255-256. , ACM/IEEE, Boston, USA},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{McBride2014,
author={McBride, N. and Stahl, B.},
title={Developing responsible research and innovation for robotics},
journal={2014 IEEE International Symposium on Ethics in Science, Technology and Engineering, ETHICS 2014},
year={2014},
doi={10.1109/ETHICS.2014.6893392},
art_number={6893392},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929249495&doi=10.1109%2fETHICS.2014.6893392&partnerID=40&md5=f43875267668865a2e7a5260a2312118},
abstract={This paper develops a framework for responsible research and innovation (RRI) in robot design for roboticists from a study of the processes involved in the design and engineering of a range of robots including standard manufacturing robots, humanoid robots, environmental scanning robots and robot swarms. The importance of an iterative approach to design, the nature of transitions between design phases, and issues of uncertainty and complexity are examined for their ethical content. A cycle of RRI thinking based on reconnoitre, realisation, reflection, response and review is described which aligns with the general characterisation of robot engineering processes. Additionally the importance of supporting communities, knowledge bases and tools for assessment and analysis is noted. © 2014 IEEE.},
author_keywords={responsible research and innovation;  robot design processes;  robot ethics},
keywords={Anthropomorphic robots;  Design;  Industrial research;  Philosophical aspects;  Robots, Engineering process;  Environmental scanning;  Humanoid robot;  Iterative approach;  Knowledge basis;  Robot designs;  Robot ethics;  Uncertainty and complexity, Machine design},
references={EPSRC, (2013) Principles of Robotics, , http://www.epsrc.ac.uk/research/ourportfolio/themes/engineering/activities/Pages/principlesofrobotics.aspx, accessed 6 February 2014; Von Schomberg, R., A vision of responsible research and Innovation (2013) Responsible Innovation, pp. 51-74. , Ed. R. Owen, J. Bessant, and M. Heintz, John Wiley; Owen, R., Stilgoe, J., Macnaughten, P., Gorman, M., Fisher, E., Guston, D., A framework for responsible innovation (2013) Responsible Innovation, pp. 27-50. , Ed. R. Owen, J. Bessant and M. Heintz, John Wiley; Winfield, A., (2013) A Very Short Introduction to Robotics, , Oxford University Press; Robotics, P., (2014) Robotics Engineering Design Process, , http://penfieldrobotics.com/Files/Resources/Presentations/Engineering%20Design%20Process.pdf, Accessed 5 March 2014; NASA, Design First Approach to Robot Engineering, , http://topweb.arc.nasa.gov/first/2011/autodesk/ATD_FIRST_v23-ATD_640x360h264.mov,2011, Accessed 5 March 2014; Coeckelburgh, M., Drones, IT and distance: Mapping the moral epistemiology of remote fighting (2013) Ethics and Information Technology, 15, pp. 87-98; Oh, K.-M., Kim, J.-H., Kim, M.-S., (2005) Development of A Humanoid Robot Design Process, , http://koasas.kaist.ac.kr/bitstream/10203/3025/1/Development%20of%20Humanoid%20Robot%20Design%20Process.pdf, Accessed 30 January 2014; Albers, A., Brudniok, S., Ottnad, J., Sauter, C., Sedchaicharn, K., Design of modules and components for humanoid robots (2007) Humanoid Robots: New Developments, , A. C. dePina Filho (Ed.), InTech; Robotics, L., The Wave Glider SV Series, , http://liquidr.com/technology/wave-glider.html, Accessed 3 February 2014, 2012; Gangloff, J., Bayle, R.B., (2013) Medical Robotics Design, , http://eavr.ustrasbg.fr/~bernard/education/houston/slides_atlantis_cami.pdf, Accessed 3rd February 2014; CogX Project, (2012), http://cogx.eu/a-summary-of-the-project/, Accessed 4th February 2014; CogX Project, (2012) Design Methodologies for Integrative Cognitive Systems, , http://cogx.eu/data/cogx/intradeliverables/DR.7.4.pdf, Accessed 4th February 2014; Waibel, M., Beetz, M., Civera, J., D'Andrea, R., Elfring, J., Galvez-Lopez, D., Haussermann, K., Molengraft De R.Van, Robo earth (2011) Robotics & Automation Magazine, IEEE, 18, pp. 69-82; Owen, J., Stepney, S., Timmis, J., Winfield, A.F.T., Exploiting loose horizontal coupling in evolutionary swarm robotics (2010) Lecture Notes in Computer Science, 6234, pp. 432-439; Andrews, P., Stepney, S., Hoverd, T., Polack, F.A.C., Sampson, A.T., Timmis, J., CoSMoS process, models and metamodels (2011) Proceedings of the 2011 Workshop on Complex Systems Modelling and Simulation, pp. 1-13. , http://www.cosmosresearch.org/docs/cosmos2011-proceedings.pdf#page=13, Accessed 5th February 2014; Pandza, K., Ellwood, P., Strategic and ethical foundations for responsible innovation (2013) Research Policy, 42, pp. 1112-1125; McBride, N., The ethics of software engineering should be an ethics for the client (2012) Communications of the ACM, 55, pp. 39-41; Stahl, B.C., Eden, G., Jirotka, M., Responsible, research and innovation in Information and Communication Technology: Identifying and engaging with the ethical implications of ICTs (2013) Responsible Innovation, pp. 199-218. , Ed. R. Owen, J. Bessant, and M. Heintz, Responsible Innovation. John Wiley; Stahl, B.C., Responsible research and innovation; The role of privacy in an emerging framework (2013) Science and Public Policy, 40, pp. 1-9; Rubin, K.S., (2012) Essential Scrum, , Addison Wesley; Cockburn, A., (2004) Crystal Clear: A Human Powered Methodology for Small Teams, , Addison Wesley; Denzin, N.K., (2001) Interpretive Interactionism, , Sage Publications; Macintyre, A., (2007) After Virtue, Duckworth; Stahl, B.C., McBride, N., Wakunuma, K., Flick, C., The empathic care robot: A prototype of responsible research and innovation (2013) Technological Forecasting and Social Change, , http://dx.doi.org/10.1016/j.techfore.2013.08.001, Accessed 5 March 2014; McBride, N., ACTIVE Ethics, An information systems ethics for the Internet age (2012) Journal of Information, Communication and Ethics in Society, 12, pp. 21-43; Castellanos, M., Gupta, C., Wang, S., Dayal, U., Duraz, M., A platform for situational awareness in operational BI (2012) Decision Support Systems, 52, pp. 869-883; Government, U.K., (2008) Customer Journey Mapping. A Guide for Practitionersu, , http://webarchive.nationalarchives.gov.uk/+/http:/www.cabinetoffice.gov.uk/media/123970/journey_mapping1.pdf, Accessed 19 February 2014},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Millar2014,
author={Millar, J.},
title={Technology as moral proxy: Autonomy and paternalism by design},
journal={2014 IEEE International Symposium on Ethics in Science, Technology and Engineering, ETHICS 2014},
year={2014},
doi={10.1109/ETHICS.2014.6893388},
art_number={6893388},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929246924&doi=10.1109%2fETHICS.2014.6893388&partnerID=40&md5=b6337803cf432e57ed415f9e170a2f62},
abstract={In this paper I argue that in cases where technologies provide material answers to moral questions that arise in the use context, they can and should be characterized as moral proxies acting on behalf of a person. Because of this we can accurately characterize the moral link between designers, artefacts and users as a relationship of a particularly moral kind. Moral proxies of the human kind have been a topic of analysis for some time in healthcare and bioethics, making them a good starting point for thinking about moral proxies of the artefactual kind. I draw from bioethics and STS literatures to build an analogy between human moral proxies in healthcare and artefactual moral proxies. I then turn my attention to design ethics considerations. If we accept that artefacts can function as moral proxies it becomes important to recognize that designers can subject users to paternalistic relationships that are ethically problematic. I demonstrate how we can use a proxy analysis as a tool for evaluating technologies. I argue that there are situations in which engineers should use proxy analysis to avoid paternalism by design while simultaneously improving user autonomy. © 2014 IEEE.},
author_keywords={autonomy;  design ethics;  driverless cars;  engineering ethics;  internal cardiac defibrillator;  machine ethics;  paternalism by design;  proxy analysis;  robot ethics;  self-driving cars},
keywords={Health care;  Machine design;  Philosophical aspects, autonomy;  Design ethics;  Driverless cars;  Engineering ethics;  proxy analysis;  Robot ethics;  Self drivings, Design},
references={Kerr, I., Digital locks and the automation of virtue (2010) From "radical Extremism" to "balanced Copyright": Canadian Copyright and the Digital Agenda, , M. Geist Ed. Toronto: Irwin Law; Winner, L., (1986) The Whale and the Reactor, , Chicago: University of Chicago Press; Latour, B., Where are the missing masses: The sociology of a few mundane artefacts (1992) Shaping Technology/building Society: Studies in Sociotechnical Change, pp. 225-258. , W.E. Bijker and John Law, Eds. Cambridge, Mass.: MIT Press; Verbeek, P.-P., Materializing morality: Design ethics and technological mediation (2006) Sci. Tech. Hum. Values, 31, pp. 361-380. , May; Kluge, E.-H., Consent and the incompetent patient (2005) Readings in Biomedical Ethics, A Canadian Focus, pp. 146-148. , 3rd ed., E-H Kluge, Ed. Toronto: Pearson Prentice Hall; Cantor, N., (2005) Making Medical Decisions for the Profoundly Mentally Disabled, , Cambridge, MA: MIT Press; Re, S.D., (1983) W.W.R, 3, p. 618. , (B.C.S.C.); Kluge, E.-H., After 'Eve': Whither proxy decision making (2005) Readings in Biomedical Ethics, A Canadian Focus, pp. 186-194. , 3rd ed., E-H Kluge, Ed. Toronto: Pearson Prentice Hall; Draper, H., Sorell, T., Patients' responsibilities in medical ethics (2007) The Bioethics Reader, pp. 73-90. , editors' choice, R. Chadwick, H. Kuhse, W. Landman, U. Schüklenk and P Singer, Eds. Malden, MA:Blackwell; Pollock, A., The internal cardiac defibrillator (2008) The Inner History of Devices, pp. 98-111. , S. Turkle, Ed. Cambridge, Mass: MIT Press; Murray, P., The history of informed consent (1990) Iowa Ort. Journal, 10, pp. 104-109; O'neill, O., (2002) Autonomy and Trust in Bioethics, , Cambridge: Cambridge University Press; (2009) College of Nurses of Ontario, , Practice guideline: consent; Vanderbilt, T., Let the robot drive (2012) Wired, p. 86. , Feb; Guizzo, E., How Google's self-driving car works (2011) IEEE Spectrum, , Oct; Slosson, M., (2012) Google Gets First Self-driven Car License in Nevada, , Reuters.com, May; Hayden, E., Speeding into the future: Self-driving cars are now legal in California (2012) Time: Newsfeed, , Sept; Newcomb, D., You won't need a driver's license by 2040 (2012) Wired.com: Autopia, , Sept; Laursen, L., Self-driving car rules will lag tech, think tanks predict (2014) IEEE Spectrum, , Jan; Marcus, G., (2012) Moral Machines, , New Yorker, Nov; Lin, P., The ethics of autonomous cars (2013) The Atlantic, , Oct},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Morkevicius20143,
author={Morkevicius, V.},
title={Tin Men: Ethics, Cybernetics and the Importance of Soul},
journal={Journal of Military Ethics},
year={2014},
volume={13},
number={1},
pages={3-19},
doi={10.1080/15027570.2014.908011},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901014238&doi=10.1080%2f15027570.2014.908011&partnerID=40&md5=50464345e498bd3e13bba27e883fc342},
abstract={The idea that overly emotional humans make poor ethical actors pervades the current literature on the ethical implications of the development of autonomous weapons systems. From this perspective, developing fully autonomous military robots should be doubly desirable: the technical process of 'teaching' robots ethics would finally systematize just war thinking, while robots could uphold the rules of engagement even under the most emotionally trying of situations. This article addresses my doubts about both claims. I argue that truly ethical behavior requires what classical just war theorists would have called soul, or what we might today term conscience - and that the flexibility of the traditional principles reflects this understanding. In pursuit of this argument, this article proceeds in two parts. First, it argues that the apparent 'messiness' of just war thought is actually morally useful. Second, it argues that emotions play an important and irreplaceable role in our ethical behavior, particularly as they help us mediate between incommensurable goods and intersecting ethical systems. © 2014 Taylor & Francis.},
author_keywords={autonomous weapons;  Drones;  emotions;  just war},
references={Ames, V.M., Conscience and Calculation (1937) International Journal of Ethics, 47 (2), pp. 180-192; Aoki, R., Tsukasa, F., Koizumi, H., Brain Science of Ethics: Present Status and the Future (2010) International Mind, Brain and Education Society, 4 (4), pp. 188-195; Appiah, K., (2004) The Ethics of Identity, , Princeton, NJ,: Princeton University Press; Aquinas, T., (1920) The Summa Theologica of St Thomas Aquinas, , http://www.newadvent.org/summa, trans. Fathers of the English Dominican Province, accessed 2 April 2014, available at:; Internet; Arkin, R., (2009) Governing Lethal Behavior in Autonomous Robots, , New York,: Taylor and Francis; Bettenson, H., (1984) City of God, , Augustine, Augustine, Augustine, Augustine, London,: Penguin Books; Buch, M.A., (1921) The Principles of Hindu Ethics, , Baroda,: Arya Sudharak Printing Press; Cahill, L., Goods for Whom? Defining Goods and Expanding Solidarity in Catholic Approaches to Violence (1997) Journal of Religious Ethics, 25 (3), pp. 183-219; Callahan, S., (1991) In Good Conscience: Reason and Emotion in Moral Decision Making, , New York,: HarperCollins; Carr, D., Feelings in Moral Conflict and the Hazards of Emotional Intelligence (2002) Ethical Theory and Moral Practice, 5 (1), pp. 3-21; Cates, D.F., (2009) Aquinas on the Emotions: A Religious-Ethical Inquiry, , Washington, DC,: Georgetown University Press; Cole, D., Thomas Aquinas on Virtuous Warfare (1999) Journal of Religious Ethics, 27 (1), pp. 57-80; Colombetti, G., Torrance, S., Emotions and Ethics: An Inter-(en)active Approach (2009) Phenomenology and the Cognitive Sciences, 8 (4), pp. 505-526; Corrigan, J., (2008) The Oxford Handbook of Religion and Emotion, , Oxford,: Oxford University Press; de Jomini, H., (1836) The Art of War, , http://www.arcmanor.com/FDL/AofW5674.pdf, In: Mendell G. H., Craighill W. P., editors accessed 2 April 2014, available at:; Internet; Dikshitar, V.R., (1987) War in Ancient India, , Ramachandra, Ramachandra, Ramachandra, Ramachandra, Delhi,: Motilal Banarsidass; Doniger, W., (1991) The Laws of Manu, , London,: Penguin Books; Döring, S., Seeing What to Do: Affective Perception and Rational Motivation (2007) Dialectica, 61 (3), pp. 363-394; Dunlap, C., Organized Violence and the Future of International Law: A Practitioner's View of the Emerging Issues (1999) Proceedings of the Annual Meeting, American Society of International Law, 93, pp. 6-15; Floyd, S.D., Aquinas on Emotion: A Response to Some Recent Interpretations (1998) History of Philosophy Quarterly, 15 (2), pp. 161-175; Ford, J.C., The Morality of Obliteration Bombing (1994) Theological Studies, 5, pp. 261-309; Goodenough, O.R., Prehn, K., A Neuroscientific Approach to Normative Judgment in Law and Justice (2004) Philosophical Transactions: Biological Sciences, 359 (1451), pp. 1709-1726; Green, K., Aquinas on Attachment, Envy and Hatred in the Summa Theologica (2007) Journal of Religious Ethics, 35 (3), pp. 403-428; Grotius, H., (1901) The Rights of War and Peace, , http://oll.libertyfund.org/title/553, In: Campbell A. C., editors M. Walter Dunne, accessed 2 April 2014, available at:; Internet; Holian, R., Management Decision Making, Ethical Issues and 'Emotional' Intelligence (2006) Management Decision, 44 (8), pp. 1122-1138; Hume, D., (1817) A Treatise of Human Nature, 2. , London,: Allman; Kaebnick, G.E., Reasons of the Heart: Emotion, Rationality, and the Wisdom of Repugnance (2008) Hastings Center Report, 38 (4), pp. 36-45; Kahan, D.M., Nussbaum, M.C., Two Conceptions of Emotion in Criminal Law (1996) Columbia Law Review, 96 (2), pp. 269-374; Kass, L., The Wisdom of Repugnance (1997) New Republic, 216 (22), pp. 17-26; Knuuttila, S., (2004) Emotions in Ancient and Medieval Philosophy, , Oxford,: Oxford University Press; Krishnan, A., (2009) Killer Robots: Legality and Ethicality of Autonomous Weapons, , Farnham,: Ashgate; Lin, P., Ethical Blowback from Emerging Technologies (2010) Journal of Military Ethics, 9 (4), pp. 313-331; Lin, P., George, B., Abney, K., (2008) Autonomous Military Robots: Risk, Ethics, and Design, , http://ethics.calpoly.edu/ONR_report.pdf, US Department of Navy, Office of Naval Research, December, accessed 2 April 2014, available at:; Internet; Lucas, G., New Rules for New Wars: Military Ethics and Irregular Warfare, Dunbar Lecture (2010), http://calhoun.nps.edu/public/handle/10945/34413, Millsaps College, 22 February, accessed 2 April 2014, available at:; Internet; Mandeville, B., (1732) An Enquiry into the Origin of Honour, and the Usefulness of Christianity in War, , http://www.gutenberg.org/ebooks/7819, accessed 2 April 2014, available at:; Internet; Marks, J., The Divine Instinct? Rousseau and Conscience (2006) The Review of Politics, 68 (4), pp. 564-585; Maroney, T.A., Law and Emotion: A Proposed Taxonomy of an Emerging Field (2006) Law and Human Behavior, 30 (2), pp. 119-142; Morgenthau, H., (1993) Politics among Nations: The Struggle for Power and Peace, , New York,: McGraw-Hill; Murphy, C.E., Aquinas on our Responsibility for our Emotions (1999) Medieval Philosophy and Theology, 8 (2), pp. 163-205; Narvaez, D., The Emotional Foundations of High Moral Intelligence (2010) New Directions for Child and Adolescent Development, 129, pp. 77-94; Pufendorf, S., (2000) On the Duty of Man and Citizen, , In: Tully James, editors Cambridge,: Cambridge University Press; Ray, P.C., (1889) The Mahabharata of Krishna-Dwaipayana Vyasa: Calya Parva, 9. , Calcutta,: Bharata Press; Ray, P.C., (1890) The Mahabharata of Krishna-Dwaipayana Vyasa: Canti Parva, 12. , Calcutta,: Bharata Press; Rietti, S., Emotional Intelligence and Moral Agency: Some Worries and a Suggestion (2009) Philosophical Psychology, 22 (2), pp. 143-165; Roberts, R.C., Thomas Aquinas on the Morality of Emotions (1992) History of Philosophy Quarterly, 9 (3), pp. 287-305; Rousseau, J.-J., (1979) Emile: Or on Education, , New York,: Basic Books; Royakkers, L., van Est, R., The Cubicle Warrior: The Marionette of Digitalized Warfare (2010) Ethics Information Technology, 12, pp. 289-296; Smith, A., (1790) Theory of Moral Sentiments, , http://www.ibiblio.org/ml/libri/s/SmithA_MoralSentiments_p.pdf, accessed 2 April 2014, available at: (6th edition of 1790); Internet; Stock, B., (2010) Augustine's Inner Dialogue: The Philosophical Soliloquy in Late Antiquity, , Cambridge,: Cambridge University Press; Tacitus, C., (1836) The Works, , In: Murphy Arthur, editors London,: Jones and Company; Vattel, E., (2008) The Law of Nations, or, Principles of the Conduct and Affairs of Nations and Sovereigns, with Three Early Essays on the Origin and Nature of Natural Law and Luxury [1797], , In: Kapossy Bela, Richard Whitmore, editors Indianapolis, IN,: Liberty Fund; Versenyi, L., Can Robots Be Moral? (1974) Ethics, 84 (3), pp. 248-259; Walzer, M., (1977) Just and Unjust Wars, , New York,: Basic Books; Walzer, M., The Triumph of Just War Theory (and the Dangers of Success) (2002) Social Research, 69 (4), pp. 925-944; Whetham, D., (2009) Just Wars and Moral Victories: Surprise, Deception and the Normative Framework of European War in the Later Middle Ages, , Leiden,: Brill; Williams, B., Introduction to Isaiah Berlin (1980) Concepts and Categories, pp. xi-xviii. , In: Hardy Henry, editors Oxford,: Oxford University Press},
document_type={Article},
source={Scopus},
}

@BOOK{Powers2011464,
author={Powers, T.M.},
title={Prospects for a Kantian machine},
journal={Machine Ethics},
year={2011},
volume={9780521112352},
pages={464-475},
doi={10.1017/CBO9780511978036.027},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927094236&doi=10.1017%2fCBO9780511978036.027&partnerID=40&md5=d51e05aab45fbbb7e17788edb92c4bef},
abstract={One way to view the puzzle of machine ethics is to consider how we might program computers that will themselves refrain from evil and perhaps promote good. Consider some steps along the way to that goal. Humans have many ways to be ethical or unethical by means of an artifact or tool; they can quell a senseless riot by broadcasting a speech on television or use a hammer to kill someone. We get closer to machine ethics when the tool is a computer that's programmed to effect good as a result of the programmer's intentions. But to be ethical in a deeper sense – to be ethical in themselves – machines must have something like practical reasoning that results in action that causes or avoids morally relevant harm or benefit. So, the central question of machine ethics asks whether the machine could exhibit a simulacrum of ethical deliberation. It will be no slight to the machine if all it achieves is a simulacrum. It could be that a great many humans do no better. Rule-based ethical theories like Immanuel Kant's appear to be promising for machine ethics because they offer a computational structure for judgment. Of course, philosophers have long disagreed about what constitutes proper ethical deliberation in humans. The utilitarian tradition holds that it's essentially arithmetic: we reach the right ethical conclusion by calculating the prospective utility for all individuals who will be affected by a set of possible actions and then choosing the action that promises to maximize total utility. © Cambridge University Press 2011.},
keywords={Computation theory, Computational structure;  Ethical theories;  Practical reasoning;  Rule based;  TO effect, Philosophical aspects},
references={Kant, I., (1981) Grounding for the Metaphysics of Morals, , translated by J. Ellington, Hackett; Kant, I., (1991) Bemerkungen in Den “Beobachtun- Gen Über Das Gefühl Des Schönen Und Erhabenen, , [Unpublished Notes on “Observations on the Feeling of the Beautiful and the Sublime”], Felix-Meiner Verlag, in German, translated by the author; O’Neill, O., (1989) Constructions of Reason, , Cambridge University Press; Horty, J., (2001) Agency and Deontic Logic, , Oxford University Press; Silber, J., Procedural formalism in kant’s ethics (1974) Review of Metaphysics, 28, pp. 197-236; Rawls, J., Kantian constructivism in moral theory (1980) J. Philosophy, 77 (9), pp. 515-572; Reiter, R., A logic for default reasoning (1980) Artificial Intelligence, 13, pp. 81-132; Poole, D., Default logic (1994) Handbook of Logic in Artificial Intelligence and Logic Pro Gramming, , D. Gabbay, C. Hogger, and J. Robinson, eds., Oxford, University Press; Gärdenfors, P., (1988) Knowledge in Flux: Modeling the Dynamics of Epistemic States, , MIT Press},
document_type={Book Chapter},
source={Scopus},
}

@BOOK{McLaren2011297,
author={McLaren, B.M.},
title={Computational models of ethical reasoning: Challenges, initial steps, and future directions},
journal={Machine Ethics},
year={2011},
volume={9780521112352},
pages={297-315},
doi={10.1017/CBO9780511978036.018},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893161705&doi=10.1017%2fCBO9780511978036.018&partnerID=40&md5=6999b931f9f1c4033e9926d0cab9c6bb},
abstract={How can machines support, or even more significantly replace, humans in performing ethical reasoning? This is a question of great interest to those engaged in Machine Ethics research. Imbuing a computer with the ability to reason about ethical problems and dilemmas is as difficult a task as there is for Artificial Intelligence (AI) scientists and engineers. First, ethical reasoning is based on abstract principles that cannot be easily applied in formal, deductive fashion. Thus the favorite tools of logicians and mathematicians, such as first-order logic, are not applicable. Second, although there have been many theoretical frameworks proposed by philosophers throughout intellectual history, such as Aristotelian virtue theory (Aristotle, edited and published in 1924), the ethics of respect for persons (Kant 1785), Act Utilitarianism (Bentham 1789), Utilitarianism (Mill 1863), and prima facie duties (Ross 1930), there is no universal agreement on which ethical theory or approach is the best. Furthermore, any of these theories or approaches could be the focus of inquiry, but all are difficult to make computational without relying on simplifying assumptions and subjective interpretation. Finally, ethical issues touch human beings in a profound and fundamental way. The premises, beliefs, and principles employed by humans as they make ethical decisions are quite varied, not fully understood, and often inextricably intertwined with religious beliefs. How does one take such uniquely human characteristics and distil them into a computer program? © Cambridge University Press 2011.},
keywords={Computation theory, Computational model;  Ethical issues;  Ethical problems;  Ethical theories;  First order logic;  Scientists and engineers;  Simplifying assumptions;  Theoretical framework, Philosophical aspects},
references={Anderson, J.R., (1993) Rules of the Mind, , Mahwah, NJ: Lawrence Erlbaum; Anderson, S.L., (2005) Asimov’s “Three Laws of Robotics” and Machine Metaethics. Proceedings of the AAAI 2005 Fall Symposium on Machine Ethics, pp. 1-7. , Crystal City, VA. Technical Report FS-05–06; Anderson, M., Anderson, S.L., Armen, C., (2005) Towards Machine Ethics: Implementing Two Action-Based Ethical Theories. Proceedings of the AAAI 2005 Fall Symposium on Machine Ethics, pp. 1-7. , Crystal City, VA. Technical Report FS-05–06; Anderson, M., Anderson, S.L., Armen, C., (2005) Medethex: Toward a Medical Ethics Advisor. Proceedings of the AAAI, , Crystal City, VA; (1924) Nicomachean Ethics, , Aristotle, (edited and published in, W. D. Ross, editor, Oxford, 1924; Ashley, K.D., (1990) Modeling Legal Argument: Reasoning with Cases and Hypotheticals, , Cambridge: MIT Press, 1990; Ashley, K.D., McLaren, B.M., Reasoning with reasons in case-based comparisons (1995) Proceedings of the First International Conference on Case-Based Reasoning, , Sesimbra, Portugal; Beauchamp, T.L., Childress, J.F., (1979) Principles of Biomedical Ethics, , Oxford University Press; Bentham, J., (1789) Introduction to the Principles of Morals and Legislation, , W. Harrison (ed.), Oxford: Hafner Press, 1948; Bok, S., (1989) Lying: Moral Choice in Public and Private Life, , New York: Random House, Inc. Vintage Books; Brody, B., (2003) Taking Issue: Pluralism and Casuistry in Bioethics, , Georgetown University Press; Cavalier, R., Covey, P.K., (1996) A Right to Die? The Dax Cowart Case CD-ROM Teacher’s Guide, , Version 1.0, Center for the Advancement of Applied Ethics, Carnegie Mellon University, Pittsburgh, PA; Gardner, A., (1987) An Artificial Intelligence Approach to Legal Reasoning, , Cambridge, MA: MIT Press; Goldin, I.M., Ashley, K.D., Pinkus, R.L., Introducing pete: Computer support for teaching ethics. proceedings of the eighth international conference on artificial intelligence & law (2001) Association of Computing Machinery, , (ICAIL-2001). Eds. Henry Prakken and Ronald P. Loui., New York; Harris, C.E., Pritchard, M.S., Rabins, M.J., (1995) Engineering Ethics: Concepts and Cases, , 1st edition. Belmont, CA: Wadsworth Publishing Company; Jonsen, A.R., Toulmin, S., (1988) The Abuse of Casuistry: A History of Moral Reasoning. Berkeley, , CA: University of California Press; Kant, I., Groundwork of the metaphysic of morals (1785) Practical Philosophy, , translated by M. J. Gregor, Cambridge: Cambridge University Press, 1996; McLaren, B.M., Ashley, K.D., Case-based comparative evaluation in truth- teller (1995) Proceedings of the Seventeenth Annual Conference of the Cognitive Science Society, , Pittsburgh, PA; McLaren, B.M., (1999) Assessing the Relevance of Cases and Principles Using Operationalization Techniques, , Ph.D. Dissertation, University of Pittsburgh; McLaren, B.M., (2003) Extensionally Defining Principles and Cases in Ethics: An AI Model; Artificial Intelligence Journal, 150, pp. 145-181. , November 2003; McLaren, B.M., Computational models of ethical reasoning: Challenges, initial steps, and future directions (2006) IEEE Intelligent Systems, Published by the IEEE Computer Society, pp. 29-37. , July/August; McLaren, B.M., Deleeuw, K.E., Mayer, R.E., Polite web-based intelligent tutors: Can they improve learning in classrooms? (2011) Computers & Education, 56, pp. 574-584; McLaren, B.M., Wegerif, R., Mikšátko, J., Scheuer, O., Chamrada, M., Mansour, N., Are your students working creatively together? Automatically recognizing creative turns in student e-Discussions (2009) Proceedings of the 14Th International Conference on Artificial Intelligence in Education (AIED-09, pp. 317-324. , V. Dimitrova, R. Mizoguchi, B. du Boulay, & A. Graesser (Eds.), Artificial Intelligence in Education: Building Learning Systems that Care: From Knowledge Representation to Affective Modelling, IOS Press; Mill, J.S., (1863) Utilitarianism, , George Sher, (Ed.) Indianapolis, Indiana, USA: Hackett Publishing Company; (1996) The NSPE Ethics Reference Guide, , Alexandria, VA: the National Society of Professional Engineers; Rawls, J., (1971) A Theory of Justice, , 2nd Edition 1999, Cambridge, MA: Harvard University Press; Robbins, R.W., Wallace, W.A., A decision aid for ethical problem solving: A multi-agent approach (2007) Decision Support Systems, 43 (4), pp. 1571-1587; Robbins, R.W., Wallace, W.A., Puka, B., Supporting ethical problem solving: An exploratory investigation (2004) In the Proceedings of the 2004 ACM Special Interest Group on Management Information Systems and Computer Personnel Research, pp. 22-24; Ross, W.D., (1930) The Right and the Good, , New York: Oxford University Press; Searing, D.R., (1998) HARPS Ethical Analysis Methodology, Method Description, , Version 2.0.0., Lake Zurich, IL: Taknosys Software Corporation, 1998; Strong, C., Justification in ethics (1988) Moral Theory and Moral Judgments in Medical Ethics, pp. 193-211. , Baruch A. Brody, editor, Dordrecht: Kluwer Academic Publishers; Toulmin, S.E., (1958) The Uses of Argument, , Cambridge, England: Cambridge University Press},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Machado2009112,
author={Machado, J. and Miranda, M. and Abelha, A. and Neves, J. and Neves, J.},
title={Modeling Medical Ethics through Intelligent Agents},
journal={IFIP Advances in Information and Communication Technology},
year={2009},
volume={305},
pages={112-122},
doi={10.1007/978-3-642-04280-5_10},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882958807&doi=10.1007%2f978-3-642-04280-5_10&partnerID=40&md5=be83e457231c9884632a49dc3f413ccd},
abstract={The amount of research using health information has increased dramatically over the last past years. Indeed, a significative number of healthcare institutions have extensive Electronic Health Records (EHR), collected over several years for clinical and teaching purposes, but are uncertain as to the proper circumstances in which to use them to improve the delivery of care to the ones in need. Research Ethics Boards in Portugal and elsewhere in the world are grappling with these issues, but lack clear guidance regarding their role in the creation of and access to EHRs. However, we feel we have an effective way to handle Medical Ethics if we look to the problem under a structured and more rational way. Indeed, we felt that physicians were not aware of the relevance of the subject in their pre-clinical years, but their interest increase when they were exposed to patients. On the other hand, once EHRs are stored in machines, we also felt that we had to find a way to ensure that the behavior of machines toward human users, and perhaps other machines as well, is ethically acceptable. Therefore, in this article we discuss the importance of machine ethics and the need for machines that represent ethical principles explicitly. It is also shown how a machine may abstract an ethical principle from a logical representation of ethical judgments and use that principle to guide its own behavior. © IFIP International Federation for Information Processing 2009.},
author_keywords={intelligent agents;  medical ethics;  Morality},
keywords={Abstracting;  Electronic commerce;  Felt;  Intelligent agents, Electronic health record;  Ethical principles;  Health informations;  Healthcare institutions;  Logical representations;  medical ethics;  Morality;  Research ethics, Philosophical aspects},
references={Deigh, J., (1992) Ethics and Personality: Essays in Moral Psychology, , (ed.), Chicago University Press; Deigh, J., (1996) The Sources of Moral Agency: Essays in Moral Psychology and Freudian Theory, , Cambridge University Press, Cambridge; Andrade, F., Neves, J., Novais, P., McHado, J., Software agents as legal persons (2004) Virtual Enterprises and Collaborative Networks, 149, pp. 123-132. , (2004); CamarinhaMatos, LM 18th World Computer Congress, Toulouse, France, August 22-27; Andrade, F., Neves, J., Novais, P., McHado, J., Abelha, A., Legal security and credibility in agent based virtual enterprises (2005) Collaborative Networks and Their Breeding Environments, 186, pp. 503-512; (2005) CamarinhaMatos, LM 6th Working Conference on Virtual Enterprises SEP 26-28, , Valencia, Spain; McHado, J., Alves, V., Abelha, A., Neves, J., Ambient intelligence via multiagent systems in medical arena (2007) International Journal of Engineering Intelligent Systems, Special issue on Decision Support Systems, 15 (3), pp. 167-173; Nwana, H.S., Software agents: An overview (1996) Knowledge Engineering Review, 11, pp. 1-40. , In, Cambridge University Press, Cambridge; McHado, J., Abelha, A., Novais, P., Neves, J., Neves, J., Improving patient assistance and medical practices through intelligent agents (2008) Workshop on Health Informatics, AAMAS 2008; Miranda, M., Abelha, A., Santos, M., McHado, J., Neves, J., A group decision support system for staging of cancer (2009) Electronic Healthcare, Springer-Verlag, Series Institute for Computer Sciences, Social Informatics and Telecommunications Engineering, , In: Weerasinghe, D. (ed.); Himma, K.E., Artificial agency, consciousness, and the criteria for moral agency: What properties must an artificial agent have to be a moral agent? (2008) Ethics and Information Technology, , Springer, Heidelberg; Wooldridge, M.J., (1999) Multiagent Systems-A Modern Approach to Distributed Artificial Intelligence, , MIT Press, Cambridge; Wooldridge, M., Jennings, N.R., (1995) Intelligent agents: Theory and practice, 10, pp. 115-152. , Cambridge University Press, Cambridge; Floridi, L., Sanders, J.W., (2004) On the morality of artificial agents, 4, pp. 349-679. , Hingham, MA, USA, Kluwer Academic Publishers, Dordrecht; Bellifemine, F., Caire, G., Greenwood, D., (2007) Developing Multi-Agent Systems with JADE, , John Wiley & Sons, Chichester; Pereira, L.M., Saptawijaya, A., Modelling morality with prospective logic (2007) EPIA 2007. LNCS (LNAI), 4874, pp. 99-111. , In: Neves, J., Santos, M.F., Machado, J.M. (eds.), Springer, Heidelberg; (2009) Code of ethics and professional conduct January, , ACM; Analide, C., Abelha, A., McHado, J., Neves, J., An agent based approach to the selection dilemma in cbr Intelligent Distributed Computing (2008) Systems and Applications. Studies in Computer Science, 162. , In: Badica, C., Mangioni, G., Carchiolo, V., Burdescu, D. (eds.), Springer, Heidelberg},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Thimbleby2008338,
author={Thimbleby, H.},
title={Robot ethics? Not yet. A reflection on Whitby's "Sometimes it's hard to be a robot"},
journal={Interacting with Computers},
year={2008},
volume={20},
number={3},
pages={338-341},
doi={10.1016/j.intcom.2008.02.006},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-42749083007&doi=10.1016%2fj.intcom.2008.02.006&partnerID=40&md5=cd908cc8b790222a2c9631b5c3918bb7},
abstract={Science fiction stories seductively portray robots as human. In present reality (early 21st century) robots are machines, even though they can do many things far better than humans (fly, swim, play chess to name a few). Any ethics for or of robots is therefore a seductive mix of fiction and reality. The key issue for rational discourse is to provide a rigorous framework for reasoning about the issues, including identifying flaws in the framework. We find such meta-reasoning in discussion about robot ethics to be ready for improvement. This paper takes its inspiration from B. Whitby, "Sometimes it's hard to be a robot: A call for action on the ethics of abusing artificial agents," Interacting with Computers, this issue, 2008. © 2008.},
author_keywords={Meta-ethics;  Robot ethics},
keywords={Artificial intelligence;  Interactive computer systems, Artificial agents;  Meta-ethics;  Robot ethics, Robots},
references={Danielson, P., (1992) Artifical Morality: Virtuous Robots for Virtual Games, , Routledge; French, J.W., (1908) Modern Power Generators, , Gresham Publishing Company; Moravec, H., (1998) Robot: Mere Machine to Transcendent Mind, , Oxford University Press; Perry, W.G., (1999) Forms of Ethical and Intellectual Development in the College Years, , Jossey-Bass; Thimbleby, H., (2007) Press on, , MIT Press; Thimbleby, H., Pullinger, D.J., Witten, I.H., Concepts of cooperation in artificial life (1995) IEEE Transactions on Systems, Man & Cybernetics, 25 (7), pp. 1166-1171; Whitby, B., in this issue. "Sometimes it's hard to be a robot: a call for action on the ethics of abusing artificial agents," Interacting with Computers},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bendel201983,
author={Bendel, O.},
title={The synthetization of human voices},
journal={AI and Society},
year={2019},
volume={34},
number={1},
pages={83-89},
doi={10.1007/s00146-017-0748-x},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026905163&doi=10.1007%2fs00146-017-0748-x&partnerID=40&md5=2da5d27ef56ffb3f5094c8f32c88a700},
abstract={The synthetization of voices, or speech synthesis, has been an object of interest for centuries. It is mostly realized with a text-to-speech system, an automaton that interprets and reads aloud. This system refers to text available for instance on a website or in a book, or entered via popup menu on the website. Today, just a few minutes of samples are enough to be able to imitate a speaker convincingly in all kinds of statements. This article abstracts from actual products and actual technological realization. Rather, after a short historical outline of the synthetization of voices, exemplary applications of this kind of technology are gathered for promoting the development, and potential applications are discussed critically to be able to limit them if necessary. The ethical and legal challenges should not be underestimated, in particular with regard to informational and personal autonomy and the trustworthiness of media. © 2017, Springer-Verlag London Ltd.},
author_keywords={Artificial intelligence;  Information ethics;  Machine ethics;  Robotics;  Speech synthesis;  Text-to-speech system},
keywords={Acoustic equipment;  Artificial intelligence;  Robotics;  Speech synthesis;  Websites, Human voice;  Information ethics;  Personal autonomy;  Text-to-speech system, Philosophical aspects},
references={Anderson, M., Anderson, S.L., (2011) Machine ethics, , (eds), Cambridge University Press, Cambridge; Bendel, O., (2012) Maschinenethik, , http://wirtschaftslexikon.gabler.de/Definition/maschinenethik.html, Gabler Wirtschaftslexikon. Springer Gabler, Wiesbaden; Bendel, O., Surgical, Therapeutic, nursing and sex robots in machine and information ethics (2015) Machine Medical Ethics. Series: Intelligent Systems, Control and Automation: Science and Engineering, pp. 17-32. , Rysewyk SPV, Pontier M, Springer, Berlin; Bendel, O., Cloud Computing aus Sicht von Verbraucherschutz und Informationsethik (2016) HMD—Praxis Der Wirtschaftsinformatik, , Reinheimer S (ed), 25 July 2016 (“online first” article on SpringerLink); Bendel, O., (2016) 300 Keywords Informationsethik: Grundwissen aus Computer-, Netz- und Neue-Medien-Ethik sowie Maschinenethik, , Springer Gabler, Wiesbaden; Bendel, O., Towards Kant machines (2017) He 2017 AAAI Spring Symposium Series, , AAAI Press, Palo Alto; Bendel, O., Sex robots from the perspective of machine ethics (2017) Love and Sex with Robots. Second International Conference, LSR 2016, pp. 1-10. , Cheok AD, Devlin K, Levy D (eds), London, UK, December 19–20, 2016, Revised Selected Papers. Springer International Publishing, Cham; Bendel, O., Gerhard, M., (2004) Handy-Avatare—Möglichkeiten Der Mobilen Kommunikationsunterstützung, 12, pp. 51-55. , InfoWeek.ch; Bendel, O., Schwegler, K., Richards, B., The LIEBOT project (2016) Machine Ethics and Machine Law, Jagiellonian University, , http://machinelaw.philosophyinscience.com/technical-program/, November 18–19, 2016, Cracow, Poland. E-Proceedings. Jagiellonian University, Cracow; Beuth, P., (2016) Tonaufnahmenfälschen leicht gemacht, , http://www.zeit.de/digital/internet/2016-11/adobe-project-voco-photoshop-audio-manipulation, ZEIT ONLINE, 4 November 2016; Grimm, J., (1808) Entstehung Der Verlagspoesie, , Arnim LAv (ed) Zeitung für Einsiedler; Ingruber, D., Prutsch, U., (2007) Imágenes—Bilder und Filme aus Lateinamerika, , LIT, Münster; Kempelen, W.V., (1791) Mechanismus Der Menschlichen Sprache Nebst Der Beschreibung Seiner Sprechenden Maschine, , J. B. Degen, Wien; Klatt, D., Review of text-to-speech conversion for English (1987) J. Acous. Soc. Amer., 82, pp. 737-793; Lenke, M., Nutzerprofile nach dem Tod: So regeln Sie Ihren digitalen Nachlass (2015) Focus Online, , http://www.focus.de/digital/internet/sterben-2-0-virtuelle-grabpflege-so-regeln-sie-ihren-digitalen-nachlass_id_4224951.html, 12 February 2015; Lüpke, M.V., Als die Fotos lügen lernten (2014) Spiegel Online (Eines Tages), , http://www.spiegel.de/einestages/bildmanipulation-falsche-fotos-vor-der-digital-aera-a-996453.html, 13 October 2014; Nagels, P., (2016) Wie eine Russin ihren toten Freund zum Leben erweckt, , https://www.welt.de/kmpkt/article158616017/Wie-eine-Russin-ihren-toten-Freund-zum-Leben-erweckt.html, welt.de, 7 October 2016; Plass-Fleßenkämper, B., (2016) Dank Adobe können wir unseren Ohren nicht mehr trauen, , https://www.wired.de/collection/tech/adobes-neues-tool-kann-sprache-imitieren, WIRED Germany, 8 November 2016; Schulz, T.M., Whitehead, H., Gero, S., Individual vocal production in a sperm whale (Physeter macrocephalus) social unit (2011) MARINE MAMMAL SCIENCE, 27 (1), pp. 149-166. , January 2011; Stark, J., (2016) Adobe Stellt Sprach-Software Voco Vor. Com! Professional, , http://www.com-magazin.de/news/adobe-systems/adobe-stellt-sprach-software-voco-1146967.html, 9 November 2016; Steinacker, L., (2017) Wirtschaftwoche, p. 52. , 20 January 2017. Mit falscher Stimme; Thies, J., Zollhöfer, M., Stamminger, M., Theobalt, C., Nießner, M., Face2Face: real-time face capture and reenactment of RGB videos (2016) Proceedings Computer Vision and Pattern Recognition (CVPR), , http://www.graphics.stanford.edu/~niessner/papers/2016/1facetoface/thies2016face.pdf, IEEE; Vincent, J., Lyrebird claims it can recreate any voice using just one minute of sample audio (2017) The Verge, , http://www.theverge.com/2017/4/24/15406882/ai-voice-synthesis-copy-human-speech-lyrebird, 24 April 2017; Wallach, W., Allen, C., (2009) Moral machines: teaching robots right from wrong, , Oxford University Press, Oxford},
document_type={Article},
source={Scopus},
}

@ARTICLE{Anderson2019526,
author={Anderson, M. and Anderson, S.L. and Berenz, V.},
title={A Value-Driven Eldercare Robot: Virtual and Physical Instantiations of a Case-Supported Principle-Based Behavior Paradigm},
journal={Proceedings of the IEEE},
year={2019},
volume={107},
number={3},
pages={526-540},
doi={10.1109/JPROC.2018.2840045},
art_number={8500162},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055214687&doi=10.1109%2fJPROC.2018.2840045&partnerID=40&md5=6bb719b209211e9467d6e21ca858cb33},
abstract={In this paper, a case-supported principle-based behavior paradigm is proposed to help ensure ethical behavior of autonomous machines. We argue that ethically significant behavior of autonomous systems should be guided by explicit ethical principles determined through a consensus of ethicists. Such a consensus is likely to emerge in many areas in which autonomous systems are apt to be deployed and for the actions they are liable to undertake. We believe that this is the case since we are more likely to agree on how machines ought to treat us than on how human beings ought to treat one another. Given such a consensus, particular cases of ethical dilemmas where ethicists agree on the ethically relevant features and the right course of action can be used to help discover principles that balance these features when they are in conflict. Such principles not only help ensure ethical behavior of complex and dynamic systems but also can serve as a basis for justification of this behavior. The requirements, methods, implementation, and evaluation components of the paradigm are detailed as well as its instantiation in both a simulated and real robot functioning in the domain of eldercare. © 1963-2012 IEEE.},
author_keywords={Artificial intelligence;  machine ethics;  machine learning;  ocmputer science;  robotics},
keywords={Artificial intelligence;  Automatic guided vehicles;  Learning systems;  Petroleum reservoir evaluation;  Robotics, Autonomous machines;  Autonomous systems;  Course of action;  Ethical behavior;  Ethical dilemma;  Ethical principles;  ocmputer science;  Relevant features, Philosophical aspects},
references={(2018) Artificial Intelligence: Healthcare's New Nervous System. Accessed: Jan. 3, , https://www.accenture.com/us-en/insightartificial-intelligence-healthcare, Accenture Consulting; Abel, D., MacGlashan, J., Littman, M.L., Reinforcement learning as a framework for ethical decision making (2016) AAAI-16 Workshop AI, , Ethics Soc., Tech. Rep. WS-16-02; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) J. Experim. Theor. Artif. Intell.?, 12, pp. 251-261. , Nov; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Mag.?, 28 (4), p. 15; Anderson, M., Anderson, S.L., Robot be good (2010) Sci. Amer. Mag.?, 303, pp. 72-77. , Oct; Anderson, M., Anderson, S.L., GenEth: A general ethical dilemma analyzer (2014) Proc. 28th AAAI Conf. Artif. Intell., , Quebec City, QC, Canada, Jul; Anderson, M., Anderson, S.L., Toward ensuring ethical behavior from autonomous systems: A case-supported principle-based paradigm (2015) Ind. Robot, Int. J.?, 42 (4), pp. 324-331; Anderson, M., Anderson, S.L., A value driven agent: Instantiation of a case-supported principle-based behavior paradigm (2017) AAAI Press, , Palo Alto, CA, USA, AAAI Tech. Rep. WS-17-02; Arkin, R.C., Governing lethal behavior: Embedding ethics in a hybrid deliberative/reactive robot architecture Georgia Inst. Technol., , Atlanta, GA, USA, Tech. Rep. GIT-GVU-07-11; Beauchamp, T.L., Childress, J.F., (1979) Principles of Biomedical Ethics, , New York, NY, USA: Oxford Univ. Press; Berenz, V., Tanaka, F., Suzuki, K., Herink, M., TDM: A software framework for elegant and rapid development of autonomous behaviors for humanoid robots (2011) Proc. Humanoids, pp. 179-186. , Oct; Berenz, V., Suzuki, K., Usability benchmarks of the Targets-Drives-Means robotic architecture (2012) Proc. 12th IEEE-RAS Int. Conf. Humanoid Robots (Humanoids), Osaka, Japan?, 1, pp. 514-519. , Nov./Dec; Berenz, V., Suzuki, K., Targets-drives-means: A declarative approach to dynamic behavior specification with higher usability (2014) Robot. Auton. Syst.?, 62 (4), pp. 545-555. , Apr; Berenz, V., Schaal, S., Playful: Reactive programming for orchestrating robotic behavior (2018) IEEE Robot. Autom. Mag., , to be published; Bentham, J., (1799) An Introduction to the Principles of Morals and Legislation, , London, U.K.: Oxford Univ. Press; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intell. Syst.?, 21 (4), pp. 38-44. , Jul./Aug; De Cubber, G., Introduction to the use of robotic tools for search and rescue (2017) Search and Rescue Robotics-From Theory to Practice. Rijeka, Croatia: InTech; (2017) Ford Invests in Argo AI, A New Artificial Intelligence Company, in Drive for Autonomous Vehicle Leadership, , https://media.ford.com/content/fordmedia/fna/us/en/news/2017/02/10/fordinvests-in-argo-ai-new-artificial-intelligencecompany.html, Ford Media Center" Accessed: Jan. 3, 2018, (Feb.); Gips, J., Towards the ethical robot (1995) Android Epistemology. Cambridge, pp. 243-252. , MA, USA: MIT Press; Grau, C., There is no 'I' in 'robot': Robots and utilitarianism (2006) IEEE Intell. Syst.?, 21 (4), pp. 52-55. , Jul./Aug; Gruebler, A., Berenz, V., Suzuki, K., Emotionally assisted human-robot interaction using a wearable device for reading facial expressions (2012) Adv. Robot.?, 26 (10), pp. 1143-1159; Guarini, M., Particularism and the Classification and Reclassification of Moral Cases (2006) IEEE Intell. Syst.?, 21 (4), pp. 22-28. , Jul./Aug; Kant, I., (1785) Groundwork of the Metaphysic of Morals, , Riga, Latvia: Harper Perennial Modern Classics; Khan, A.F.U., The ethics of autonomous learning systems (1995) Android Epistemology. Cambridge, pp. 253-265. , MA, USA: MIT Press; Kortenkamp, D., Simmons, R., Robotic systems architectures and programming (2008) Springer Handbook of Robotics. New York, pp. 187-206. , NY, USA: Springer-Verlag; Kuipers, B., Human-like morality and ethics for robots (2016) AAAI-16 Workshop AI, , Ethics Soc., Tech. Rep. WS-16-02; Lavrac, N., Džeroski, S., (1997) Inductive Logic Programming: Techniques and Applications (Ellis Horwood Series in Artificial Intelligence), , Englewood Cliffs, NJ, USA: Prentice-Hall; Luxton, D.D., (2016) Artificial Intelligence in Behavioral and Mental Health Care. San Francisco, , CA, USA: Academic; McLaren, B.M., Extensionally defining principles and cases in ethics: An AI model (2003) Artif. Intell. J.?, 150 (1-2), pp. 145-181. , Nov; Pereira, L.M., Saptawijaya, A., Modelling morality with prospective logic (2007) Progress in Artificial Intelligence (Lecture Notes in Computer Science)?, 4874, pp. 99-111; Powers, T.M., Prospects for a Kantian machine (2006) IEEE Intell. Syst.?, 21 (4), pp. 46-51. , Jul./ Aug; Quinlan, J.R., Induction of decision trees (1986) Mach. Learn.?, 1 (1), pp. 81-106. , Mar; (2017) Global Personal Robots Market Size, Share, Development, Growth and Demand Forecast to 2022, , https://www.researchandmarkets.com/research/dbq7q9/global_personal, Research and Markets. (Feb.) Accessed: Jan. 3, 2018; Ross, W.D., (1930) The Right and the Good, , Oxford, U.K.: Oxford Univ. Press; Rzepka, R., Araki, K., What could statistics do for ethics? the idea of common sense processing based safety valve (2005) Proc. AAAI Fall Symp. Mach. Ethics. AAAI Press, pp. 85-87; (2015) Relativism. Accessed: Jan. 3, 2018, , https://plato.stanford.edu/entries/relativism/, Stanford Encyclopedia of Philosophy. (Sep.); (2015) Reflective Equilibrium, , https://plato.stanford.edu/entries/reflectiveequilibrium/, Stanford Encyclopedia of Philosophy. (Sep.) Accessed: Mar. 5, 2018; Turing, A.M., Computing machinery and intelligence (1950) Mind?, 59, pp. 433-460. , Oct; Vanderelst, D., Winfield, A., (2016) Architecture for Ethical Robots, , https://arxiv.org/pdf/1609.02931.pdf; Waldrop, M.M., A question of responsibility (1987) Man-Made Minds: The Promise of Artificial Intelligencey, , New York, NY, USA: Walker and Company, ch. 11},
document_type={Article},
source={Scopus},
}

@ARTICLE{vanWynsberghe20181777,
author={van Wynsberghe, A. and Donhauser, J.},
title={The Dawning of the Ethics of Environmental Robots},
journal={Science and Engineering Ethics},
year={2018},
volume={24},
number={6},
pages={1777-1800},
doi={10.1007/s11948-017-9990-3},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031922500&doi=10.1007%2fs11948-017-9990-3&partnerID=40&md5=664e6e4b8f0c35312a357fb0a58613dc},
abstract={Environmental scientists and engineers have been exploring research and monitoring applications of robotics, as well as exploring ways of integrating robotics into ecosystems to aid in responses to accelerating environmental, climatic, and biodiversity changes. These emerging applications of robots and other autonomous technologies present novel ethical and practical challenges. Yet, the critical applications of robots for environmental research, engineering, protection and remediation have received next to no attention in the ethics of robotics literature to date. This paper seeks to fill that void, and promote the study of environmental robotics. It provides key resources for further critical examination of the issues environmental robots present by explaining and differentiating the sorts of environmental robotics that exist to date and identifying unique conceptual, ethical, and practical issues they present. © 2017, The Author(s).},
author_keywords={Ecological robots;  Environmental engineering;  Environmental robotics;  Ethics and technology;  Robot ethics},
keywords={ecosystem;  engineering;  environmental protection;  ethics;  human;  morality;  procedures;  research;  research ethics;  robotics, Conservation of Natural Resources;  Ecosystem;  Engineering;  Ethics, Research;  Humans;  Morals;  Research;  Robotics},
references={A disgraceful exit from the Paris Pact (2017) New York Times, p. 24. , https://www.nytimes.com/2017/06/01/opinion/trump-paris-climate-change-agreement.html; Adams, N., Carroll, D., Madalinski, K., Rock, S., Wilson, T., Pivetz, B., (2000) Introduction to Phytoremediation, , http://www.clu-in.org/download/remed/introphyto.pdf, Retrieved from; Aravind, K.R., Raja, P., Pérez-Ruiz, M., Task-based agricultural mobile robots in arable farming: A review (2017) Spanish Journal of Agricultural Research, 15 (1), pp. 01-02; Asaro, P., What should we want from a robot ethic? (2006) International Review of Information Ethics, 6, pp. 8-16; Asimov, I., (1990) Robot Visions: Roc; Best, E.P.H., Zappi, M.E., Fredrickson, H.L., Specher, S.L., Larson, S.L., Ochman, M., Screening of aquatic and wetland plant species for phytoremediation of explosives-contaminated groundwater for the Iowa Army Ammuntion Plant (1997) Annals of the New York Academy of Sciences, 829 (1), pp. 179-194; Blersch, D.M., (2010) Towards an autonomous algal turf scrubber: Development of an ecologically-engineered technoecosystem, , University of Maryland, College Park; Bostrom, N., Yudkowsky, E., The ethics of artificial intelligence (2014) The Cambridge handbook of artificial intelligence, pp. 316-334. , &; Burger, A.E., Shaffer, S.A., Application of tracking and data-logging technology in research and conservation of seabirds (2008) Auk, 125, pp. 253-264; Burken, J., Schnoor, J., Predictive relationships for uptake of organic contaminants by hybrid poplar trees (1998) Environmental Science & Technology, 32 (21), pp. 3379-3385; Cai, T.T., Montague, C.L., Davis, J.S., The maximum power principle: an empirical investigation (2006) Ecological Modelling, 190 (3), pp. 317-335; Capurro, R., (2009) Ethics and Robotics, pp. 117-123. , Capurro R, Nagenborg M, (eds), IOS Press, Amsterdam; Chappell, J., (1997) Phytoremediation of TCE Using Populus, , A report prepared for US EPA Technology Innovation Office, Washington, DC; Choi-Fitzpatrick, A., Drones for good: Technological innovations, social movements, and the state (2014) Journal of International Affairs, 68 (1), p. 19; Clark, C.M., Forney, C., Manii, E., Shinzaki, D., Gage, C., Farris, M., Moline, M., Tracking and following a tagged leopard shark with an autonomous underwater vehicle (2013) Journal of Field Robotics, 30 (3), pp. 309-322; Clark, O.G., Kok, R., Lacroix, R., Mind and autonomy in engineered biosystems (1999) Engineering Applications of Artificial Intelligence, 12 (3), pp. 389-399; Colyvan, M., Linquist, S., Grey, W., Griffiths, P.E., Odenbaugh, J., Possingham, H.P., A field guide to the philosophy of ecology (2009) In Ecology and Society, 14 (2). , http://www.ecologyandsociety.org/vol14/iss2/art22/; Coxworth, B., Robotic swans designed to look nice… and to monitor water quality (2015) New Atlas, , http://newatlas.com/nuswan-water-quality-swan-robot/38568/; (1996) Nanotechnology: Molecular Speculations on Global Abundance, (B. Crandall Ed.), , Crandall, B. C., Cambridge, Mit Press; Dhariwal, A., Sukhatme, G.S., Requicha, A.A.G., Bacterium-inspired robots for environmental monitoring (2004) IEEE International Conference on Paper Presented at the Proceedings of Robotics and Automation, ICRA’04; Dickmann, D.I., Stuart, K.W., (1983) The culture of poplars in eastern north America department of forestry, , Michigan State University, East Lansing, Michigan; Ditmer, M.A., Vincent, J.B., Werden, L.K., Tanner, J.C., Laske, T.G., Iaizzo, P.A., Fieberg, J.R., Bears show a physiological but limited behavioral response to unmanned aerial vehicles (2015) Current Biology, 25 (17), pp. 2278-2283; Donhauser, J., Making ecological values make sense: Toward more operationalizable ecological legislation (2016) Ethics and the Environment, 21 (2), pp. 1-25; Donhauser, J., The value of weather event science for pending climate policy decisions (2017) Ethics, Policy, and Environment, 20 (3), pp. 263-278; Dunbabin, M., Marques, L., Robots for environmental monitoring: Significant advancements and applications (2012) IEEE Robotics and Automation Magazine, 19 (1), pp. 24-39; Elliott, O., Gray, S., McClay, M., Nassief, B., Nunnelley, A., Vogt, E., Proaño, G., Design and manufacturing of high surface area 3D-printed media for moving bed bioreactors for wastewater treatment (2017) Journal of Contemporary Water Research and Education, 160 (1), pp. 144-156; Generic handbook for assisting in the management of contaminated food productions systems in Europe following a radiological emergency deliverable from the EURANOS project (2006) EURANOS (CAT1)-TN, 6, p. 06. , http://www.euranos.fzk.de/index.php?action¼euranos&title¼products; Gordon, M., Choe, N., Duffy, J., Ekuan, G., Heilman, P., Muiznieks, I., Phytoremediation of trichloroethylene with hybrid poplars (1998) Environmental Health Perspectives, 106, pp. 1001-1004; Green, C., Hoffnagle, A., (2004) Phytoremediation field studies database for chlorinated solvents, pesticides, explosives, and metals, , US EPA Office of Superfund Remediation and Technology Innovation, Washington, DC; Grémillet, D., Puech, W., Garcon, V., Boulinier, T., Le Maho, Y., Robots in ecology: Welcome to the machine (2012) Open Journal of Ecology, 2 (2), pp. 49-57; Hart, J.K., Martinez, K., Environmental sensor networks: A revolution in the earth system science? (2006) Earth-Science Reviews, 78 (3), pp. 177-191; Hegde, M., Kim, J., Hong, S.H., Wood, T.K., Jayaraman, A., Designer biofilms: Controlling biofilm formation and dispersal using a synthetic quorum sensing circuit in microfluidic devices (2011) Paper Presented at the 15Th International Conference on Miniaturized Systems for Chemistry and Life Sciences, Seattle; Hodgson, J.C., Baylis, S.M., Mott, R., Herrod, A., Clarke, R.H., Precision wildlife monitoring using unmanned aerial vehicles (2016) Scientific reports, 6. , &; Hughes, A.M., Burridge, J.H., Demain, S.H., Ellis-Hill, C., Meagher, C., Tedesco-Triccas, L., Swain, I., Translation of evidence-based assistive technologies into stroke rehabilitation: users’ perceptions of the barriers and opportunities (2014) BMC health services research, 14 (1), p. 124; (2016), https://ifr.org/ifr-press-releases/news/world-robotics-report-2016, Press Releases, Retrieved May 30, 2017, from; Ivošević, B., Han, Y.-G., Cho, Y., Kwon, O., The use of conservation drones in ecology and wildlife research (2015) Ecology and Environment, 38, pp. 113-118; Kangas, P., (2004) Ecological Engineering: Principles and Practice, , Boca Raton, CRC Press; Kardel, K., Carrano, A.L., Blersch, D.M., Kaur, M., Preliminary development of 3D-printed custom substrata for benthic algal biofilms (2015) 3D Printing and Additive Manufacturing, 2 (1), pp. 12-19. , &; Koh, L.P., Wich, S.A., Dawn of drone ecology: Low-cost autonomous aerial vehicles for conservation (2012) Tropical Conservation Science, 5 (2), pp. 121-132; Lam, T.L., Xu, Y., (2012) Tree Climbing Robot: Design, Kinematics and Motion Planning, 78. , Berlin, Springer; Lampton, C., (1993) Nanotechnology Playhouse: Building Machines from Atoms, , Waite Group Press; Light, A., (2017) White House Abandoning Paris Agreement Harms the U.S. as Other Countries Step Up, , https://www.wri.org/blog/2017/06/white-house-abandoning-paris-agreement-harms-us-other-countries-step, Retrieved June 05, 2017, from; Lin, P., Abney, K., Bekey, G.A., (2011) Robot ethics: The ethical and social implications of robotics, , MIT Press, Cambridge; Le Maho, Y., WhittingtonYvon, J.D., Hanuise, N., Pereira, L., Boureau, M., Brucker, M., Friess, B., Rovers minimize human disturbance in research on wild animals (2014) Nature Methods, 11 (12), pp. 1242-1244; (2017) Robots in the Service of the Environment, , https://robotsise.com/mission-vision/, Retrieved May 25, from; Myers, J., Clark, L.B., Culture conditions and the development of the photosynthetic mechanism: II. An apparatus for the continuous culture of Chlorella (1944) The Journal of General Physiology, 28 (2), p. 103; Odum, H.T., (1993) Ecological and general systems: An introduction to systems ecology, , University Press of Colorado, Boulder; O’Neill, J., (2007) Markets, Deliberation and Environment, , Routledge, Abingdon; Parrott, L., (1996) The EcoCyborg project: A model of an artificial ecosystem, , McGill University, Montreal; (2017) University of Maryland: Department of Environmental Science & Technology, , https://enst.umd.edu/people/faculty/patrick-kangas/past-projects, Retrieved May 25; Peckham, S.H., Maldonado Diaz, D., Walli, A., Ruiz, G., Crowder, L.B., Nichols, W.J., Small-scale fisheries bycatch jeopardizes endangered Pacific loggerhead turtles (2007) PLoS One, 2 (10); Petersen, J.E., Adding artificial feedback to a simple aquatic ecosystem: the cybernetic nature of ecosystems revisited (2001) Oikos, pp. 533-547; (2017), https://wyss.harvard.edu/technology/programmable-robot-swarms/, Retrieved May 25, from; Rundel, P.W., Graham, E.A., Allen, M.F., Fisher, J.C., Harmon, T.C., Environmental sensor networks in ecological research (2009) New Phytologist, 182 (3), pp. 589-607; Rutz, C., Hays, G.C., New frontiers in biologging science (2009) Biology Letters, 5 (3), pp. 289-292; Sharkey, N., The ethical frontiers of robotics (2008) Science, 322 (5909), pp. 1800-1801; Shockley, K., Sourcing sustainability in a time of climate change (2014) Environmental Values, 23 (2), pp. 199-217; Siegwart, R., Nourbakhsh, I.R., Scaramuzza, D., (2004) Autonomous Mobile Robots, , http://mars.umhb.edu/~wgt/cisc3361/redbook/5b_Summary_Add-on_Slides.pdf, In Massachusetts Institute of Technology, Accessed 8 october 2017; Succuro, J.S., McDonald, S.S., Lu, C.R., Phytoremediation: The wave of the future (2009) Recent Advances in Plant Biotechnology, , Boston, MA, Springer; Sullins, J.P., Introduction: Open questions in roboethics (2011) Philosophy & Technology, 24 (3), pp. 233-238; Susarla, S., Medina, V.F., McCutcheon, S.C., Phtyoremediation: An ecological solution to organic chemical contamination (2002) Ecological Engineering, 18 (5), pp. 647-658; Tanaka, S., Brentner, L., Merchie, K., Schnoor, J., Yoon, J., Van Aken, B., Analysis of gene expression in poplar trees (Populus deltoides× nigra, DN34) exposed to the toxic explosive hexahydro-1, 3, 5-trinitro-1, 3, 5- triazine (RDX) (2007) International Journal of Phytoremediation, 9 (1), pp. 15-30; https://robotsise.com/lionfish-project/, The Lionfish Project: This Invasive Predator From The Pacific Is Rapidly Destroying Our Reefs.). Robots in the Service of the Environment. Retrieved May 24, 2017, from; (2017) Robots in the Service of the Environment, , https://robotsise.com/todays-eco-robots/, Retrieved May 24; Todd, J., Ecological engineering, living machines and the visionary landscape (1991) Ecological Engineering for Wastewater Treatment BokSkogen, pp. 335-343. , Etnie C, Guterstam B, (eds), Stensurd Folk College, Sweden; Todd, N.J., Todd, J., (1994) From Eco-Cities to Living Machines: Principles of Ecological Design: North Atlantic Books; Townsend, J.A., Bellutta, P., Keuneke, M., Seibert, M., Stroupe, A., Wright, J., (2014) Mars Exploration Rovers 2004–2013: Evolving Operational Tactics Driven by Aging Robotic Systems, , In Paper presented at the SpaceOps 2014 Conference; Tripathi, R., Srivastava, S., Mishra, S., Dwivedi, S., 7 strategies for phytoremediation of environmental contamination (2008) Developments in Physiology, Biochemistry and Molecular Biology of Plants, pp. 175-220. , B. Bose, A. Hemantaranjan, New India Publishing; (2013) Warsaw International Mechanism for Loss and Damage Associated with Climate Change Impacts, , http://unfccc.int/resource/docs/2013/cop19/eng/10a01.pdf, From; (2015), http://unfccc.int/resource/docs/2015/cop21/eng/l09r01.pdf, Adoption of the Paris Agreement. from; Vangronsveld, J., Herzig, R., Weyens, N., Boulet, J., Adriaensen, K., Ruttens, A., Phytoremediation of contaminated soils and groundwater: lessons from the field (2009) Environmental Science and Pollution Research, 16 (7), pp. 765-794; van Wynsberghe, A., (2016) Healthcare Robots: Ethics, Design and Implementation, , Routledge; Vas, E., Lescroël, A., Duriez, O., Boguszewski, G., Grémillet, D., Approaching birds with drones: first experiments and ethical guidelines (2015) Biology Letters, 11 (2), p. 20140754; Wadhams, P., Wilkinson, J.P., McPhail, S.D., A new view of the underside of Arctic sea ice (2006) Geophysical Research Letters, 33 (4). , &; Whitcomb, L.L., Underwater robotics: Out of the research laboratory and into the field (2000) IEEE International Conference on Paper Presented at the Robotics and Automation, Proceedings. ICRA’00; Yaghoubi, S., Akbarzadeh, N.A., Bazargani, S.S., Bazargani, S.S., Bamizan, M., Asl, M.I., Autonomous robots for agricultural tasks and farm assignment and future trends in agro robots (2013) International Journal of Mechanical and Mechatronics Engineering, 13 (3), pp. 1-6; Yoerger, D.R., Kelley, D.S., Delaney, J.R., Fine-scale three-dimensional mapping of a deep-sea hydrothermal vent site using the Jason ROV system (2000) The International Journal of Robotics Research, 19 (11), pp. 1000-1014; Yoshida, K., Wilcox, B., Hirzinger, G., Lampariello, R., (2016) Space Robotics Springer Handbook of Robotics, pp. 1423-1462. , Berlin: Springer; Zalesny, R.S., Jr., Bauer, E.O., Hall, R.B., Zalesny, J.A., Kunzman, J., Rog, C.J., Riemenschneider, D.E., Clonal variation in survival and growth of hybrid poplar and willow in an in situ trial on soils heavily contaminated with petroleum hydrocarbons (2005) International Journal of Phytoremediation, 7 (3), pp. 177-197},
document_type={Article},
source={Scopus},
}

@ARTICLE{Keeling2018413,
author={Keeling, G.},
title={Legal Necessity, Pareto Efficiency & Justified Killing in Autonomous Vehicle Collisions},
journal={Ethical Theory and Moral Practice},
year={2018},
volume={21},
number={2},
pages={413-427},
doi={10.1007/s10677-018-9887-5},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046020690&doi=10.1007%2fs10677-018-9887-5&partnerID=40&md5=c8125ba1525d146811f85036990b4002},
abstract={Suppose a driverless car encounters a scenario where (i) harm to at least one person is unavoidable and (ii) a choice about how to distribute harms between different persons is required. How should the driverless car be programmed to behave in this situation? I call this the moral design problem. Santoni de Sio (Ethical Theory Moral Pract 20:411–429, 2017) defends a legal-philosophical approach to this problem, which aims to bring us to a consensus on the moral design problem despite our disagreements about which moral principles provide the correct account of justified harm. He then articulates an answer to the moral design problem based on the legal doctrine of necessity. In this paper, I argue that Santoni de Sio’s answer to the moral design problem does not achieve the aim of the legal-philosophical approach. This is because his answer relies on moral principles which, at least, utilitarians have reason to reject. I then articulate an alternative reading of the doctrine of necessity, and construct a partial answer to the moral design problem based on this. I argue that utilitarians, contractualists and deontologists can agree on this partial answer, even if they disagree about which moral principles offer the correct account of justified harm. © 2018, The Author(s).},
author_keywords={Autonomous vehicle ethics;  Legal doctrine of necessity;  Robot ethics},
references={SAE Information Report (J3016) Taxonomy and definitions for terms related to on-road motor vehicle automated driving systems, , (n.d; Arnolds, E.B., Garland, N.F., The defense of necessity in criminal law: the right to choose the lesser evil (1974) J Crim Law Criminol, 65 (3), pp. 289-301; Austin, J.L., Urmson, J.O., Warnock, G.J., A Plea for excuses (1956) Austin JL (1961) Philosophical papers, , Oxford University Press, Oxford; Bohlander, M., Of shipwrecked sailors, unborn children, conjoined twins and hijacked airplanes—taking human life and the defence of necessity (2006) Journal Crim Law, 70 (2), pp. 147-161; Bonnefon, J.-F., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2016) Science, 352 (6293), pp. 1573-1576; Christie, G.C., The defense of necessity considered from the legal and moral points of view (1999) Duke Law J, 48 (5), pp. 975-1042; Coleman, J.L., Efficiency, utility, and wealth maximization (1980) Hofstra Law Review, 8 (3), pp. 509-551; Gerdes, J.C., Thornton, S.M., Implementable ethics for autonomous vehicles (2016) In Autonomous Driving: Technical, Legal and Social Aspects, pp. 87-102. , Maurer M, Gerdes JC, Lenz B, Winner H, (eds), Springer, Berlin Heidelberg; Hart, H.L.A., (1961) The concept of law, , Clarendon, Oxford; Kamm, F., (2007) Intricate ethics: rights, responsibilities, and permissible harm, , OUP, Oxford; Leben, D., A Rawlsian algorithm for autonomous vehicles (2017) Ethics Inf Technol, 19 (2), pp. 107-115; Lin, P., Why ethics matters for autonomous cars (2016) Autonomous Driving: Technical, Legal and Social Aspects, pp. 69-85. , Maurer M, Gerdes JC, Lenz B, Winner H, (eds), Springer, Berlin Heidelberg; Litman, T., (2014) Autonomous vehicle implementation predictions. Victoria Transport Policy Institute; Case, M., Michaelmas term 6 (1608) JMS I vol, 12; (1884) QBD 273, , R v Dudley and Stephens; (2001) 2 WLR 480 (CA), , Re A (Conjoined twins); Reninger v Fagossa (1551) 1 Plowd. 1, 75 Eng. Rep. 1; Santoni de Sio, F., Killing by autonomous vehicles and the legal doctrine of necessity (2017) Ethical Theory Moral Pract, 20 (2), pp. 411-429; Scanlon, T.M., (1998) What we owe to each other, , Harvard University Press, Cambridge},
document_type={Article},
source={Scopus},
}

@ARTICLE{Dameski201842,
author={Dameski, A.},
title={A comprehensive ethical framework for AI entities: Foundations},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10999 LNAI},
pages={42-51},
doi={10.1007/978-3-319-97676-1_5},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051420861&doi=10.1007%2f978-3-319-97676-1_5&partnerID=40&md5=3d7511fab85ae248ed63c1a1deca873e},
abstract={The participation of AI in society is expected to increase significantly, and with that the scope, intensity and significance of morally-burdened effects produced or otherwise related to AI, and the possible future advent of AGI. There is a lack of a comprehensive ethical framework for AI and AGI, which can help manage moral scenarios in which artificial entities are participants. Therefore, I propose the foundations of such a framework in this text, and suggest that it can enable artificial entities to make morally sound decisions in complex moral scenarios. © 2018, Springer Nature Switzerland AG.},
author_keywords={AGI;  Ethics of AI;  Machine ethics},
keywords={Artificial intelligence;  Computer science;  Computers, Possible futures;  Sound decision, Philosophical aspects},
references={Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-26. , American Association for Artificial Intelligence; Anderson, S.L., Anderson, M., How Machines Can Advance Ethics (2009) Philosophy Now; Chopra, S., White, L.F., A Legal Theory for Autonomous Artificial Agents. University of Michigan (2011) Ann Arbor; Danaher, J., The threat of algocracy: Reality. Resistance and Acommodation (2016) Philosophy and Technology, 29, pp. 245-268; Dodig Crnkovic, S., Çürüklü, B., Robots: Ethical by design (2012) Ethics Inf. Technol., 14, pp. 61-71; Floridi, L., (2004) The Blackwell Guide to the Philosophy of Computing and Information, , (ed.), Blackwell Publishing, Hoboken; Floridi, L., (2013) The Ethics of Information, , Oxford University Press, Oxford; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds Mach, 14, pp. 349-379; Floridi, L., Savulescu, J., Information ethics: Agents, artefacts and new cultural perspectives (2006) Ethics Inf. Technol., 8, pp. 155-156; Floridi, L., Taddeo, M., (2016) What is Data Ethics. Philosophical Transactions of the Royal Society A, 374 (2083). , Preprint; Gerdes, A., Øhrstrøm, P., Issues in robot ethics seen through the lens of a moral turing test (2015) J. Inf. Commun. Ethics Soc., 13 (2), pp. 98-109. , Emerald Group Publishing Limited; Gunkel, D.J., A vindication of the rights of machines (2014) Philos. Technol., 27, pp. 113-132; Kurzweil, R.E., (2000) The Age of Spiritual Machines: When Computers Exceed Human Intelligence, , Penguin Books, London; Lin, P., Abney, K., Bekey, G.A., (2012) Robot Ethics: The Ethical and Social Implications of Robotics, , (eds.), The MIT Press, Cambridge; Macdorman, K.F., Cowley, S.J., Long-term relationships as a benchmark for robot personhood (2006) The 15Th IEEE International Symposium on Robot and Human Interactive Communication, Hatfield, UK; Mittelstadt, B.D., Allo, P., Taddeo, M., Wachter, S., Floridi, L., The ethics of algorithms: Mapping the debate (2016) Big Data Soc, 3 (2), pp. 1-21; Reader, S., (2007) Needs and Moral Necessity, Routledge (Taylor and Francis Group). Taylor and Francis E-Library, , Abingdon; Smith, A., Anderson, J., (2014) AI, Robotics, and the Future of Jobs, Pew Research Center, , http://www.pewinternet.org/2014/08/06/future-of-jobs/; Taddeo, M., The moral value of information and information ethics (2017) The Routledge Handbook of Philosophy of Information. Routledge, , Floridi, L. (ed.); Tiles, J.E., (2005) Moral Measures: An Introduction to Ethics East and West, Routledge (Taylor and Francis Group). Taylor and Francis E-Library, , Abingdon; Tzafestas, S.G., (2016) Roboethics: A Navigating Overview, , https://doi.org/10.1007/978-3-319-21714-7, Springer, Cham; Veruggio, G., (2007) EURON Roboethics Roadmap, , http://www.roboethics.org/index_file/Roboethics%20Roadmap%20Rel.1.2.pdf; Yudkowski, E., (2008) AI as a Positive and Negative Factor in Global Risk, pp. 308-345. , Bostrom, N., Cirkovic, M.M. (eds.) Global Catastrophic Risks, Oxford University Press, Oxford; Zimmerman, M.J., (2008) Living with Uncertainty: The Moral Significance of Ignorance, , Cambridge University Press, Cambridge},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lindner20176991,
author={Lindner, F. and Bentzen, M.M. and Nebel, B.},
title={The HERA approach to morally competent robots},
journal={IEEE International Conference on Intelligent Robots and Systems},
year={2017},
volume={2017-September},
pages={6991-6997},
doi={10.1109/IROS.2017.8206625},
art_number={8206625},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041964518&doi=10.1109%2fIROS.2017.8206625&partnerID=40&md5=e5f2d246c2359ef4cad0968608cec61c},
abstract={To address the requirement for autonomous moral decision making, we introduce a software library for modeling hybrid ethical reasoning agents (short: HERA). The goal of the HERA project is to provide theoretically well-founded and practically usable logic-based machine ethics tools for implementation in robots. The novelty is that HERA implements multiple ethical principles like utilitarianism, the principle of double effect, and a Pareto-inspired principle. These principles can be used to automatically assess moral situations represented in a format we call causal agency models. We discuss how to model moral situations using our approach, and how it can cope with uncertainty about moral values. Finally, we briefly outline the architecture of our robot IMMANUEL, which implements HERA and is able to explain ethical decisions to humans. © 2017 IEEE.},
keywords={Decision making;  Pareto principle;  Philosophical aspects;  Robots;  Software agents, Double effects;  Ethical principles;  Software libraries, Intelligent robots},
references={Bonnefon, J.-F., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2016) Science, 352 (6293), p. 15731576; Lindner, F., Roboter, S., Räume, S., (2015) Eine Affordanzbasierte Konzeption Rücksichtsvollen Handelns, , PhD Thesis, University of Hamburg, Hamburg; Lindner, F., Bentzen, M.M., The hybrid ethical reasoning agent IMMANUEL (2017) HRI'17 Companion of the 2017 ACM/ IEEE International Conference on Human-Robot Interaction, pp. 187-188; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) IEEE Intelligent Systems, 21 (4), pp. 12-17; Malle, B.F., Scheutz, M., Arnold, T., Voiklis, J., Cusimano, C., Sacrifice one for the good of many?: People apply different moral norms to human and robot agents (2015) HRI'15: Proceedings of the Tenth Annual ACM/ IEEE International Conference on Human-Robot Interaction, pp. 117-124; Arkin, R.C., Governing lethal behavior: Embedding ethics in a hybrid deliberative/reactive robot architecture (2008) HRI'08: Proceedings of the 3rd Annual ACM/ IEEE International Conference on Human-Robot Interaction, pp. 121-128; Armstrong, S., Motivated value selection for artificial agents (2015) Artificial Intelligence and Ethics: Papers from the 2015 AAAI Workshop, pp. 12-20; Abel, D., MacGlashan, J., Littman, M.L., Reinforcement learning as a framework for ethical decision making (2016) InAAAI Workshop on AI, Ethics, and Society, pp. 54-61; Dennis, L., Fisher, M., Slavkovik, M., Webster, M., Formal verification of ethical choices in autonomous systems (2016) Robotics and Autonomous Systems, 77 (1-14); Arnold, T., Kasenberg, D., Scheutz, M., Value alignment or misalignment-What Will Keep Systems Accountable? (2017) AAAI Workshop on AI, Ethics, and Society; Lindner, F., Wchter, L., Bentzen, M.M., Discussions about lying with an ethical reasoning robot (2017) Proceedings of the 2017 IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN'17); Bentzen, M., The principle of double effect applied to ethical dilemmas of social robots (2016) What Social Robots Can and Should Do, pp. 268-279. , IOS Press; Halpern, J.Y., (2016) Actual Causality, , The MIT Press, Cambridge MA; Kuhnert, B., Lindner, F., Bentzen, M.M., Ragni, M., Perceived difficulty of moral dilemmas depends on their causal structure: A formal model and preliminary results (2017) Proceedings of the CogSci 2017 Conference; Foot, P., The problem of abortion and the doctrine of double effect (1967) Oxford Review; Sinnott-Armstrong, W., Consequentialism (2015) Stanford Encyclopedia of Philosophy; Malle, B.F., Scheutz, M., When will people regard robots as morally competent social partners? (2015) Proceedings of the 2015 IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN'15, pp. 486-491},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Keeling2017,
author={Keeling, G.},
title={Commentary: Using virtual reality to assess ethical decisions in road traffic scenarios: Applicability of value-of-life-based models and influences of time pressure},
journal={Frontiers in Behavioral Neuroscience},
year={2017},
volume={11},
doi={10.3389/fnbeh.2017.00247},
art_number={247},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042060486&doi=10.3389%2ffnbeh.2017.00247&partnerID=40&md5=6fa3e3e0e7f1800e56b5b2507f191d1a},
author_keywords={Ethical decision-making;  Moral judgements;  Robot ethics;  Self-driving cars;  Virtual reality},
keywords={ethical decision making;  human;  morality;  Note;  particularism;  socioeconomics;  time;  traffic;  traffic accident;  virtual reality},
references={Dancy, J., Ethical particularism and morally relevant properties (1983) Mind, 92, pp. 530-547; Goodall, N., Ethical decision making during automated vehicle crashes (2014) Transport. Res. Rec. J. Transport. Res. Board, 2424, pp. 58-65; Joyce, R., What neuroscience can (And cannot) contribute to metaethics (2008) The Neuroscience of Morality: Emotion, Brain Disorders and Development, pp. 371-394. , W. Sinnott-Armstrong (Cambridge, MA, MIT Press; Lin, P., Why ethics matters for autonomous cars (2016) Autonomous Driving, pp. 66-85. , M. Maurer, J. C. Gerdes, B. Lenz, and H. Winner (Berlin; Heidelberg: Springer); Sütfeld, L.R., Gast, R., König, P., Pipa, G., Using virtual reality to assess ethical decisions in road traffic scenarios: Applicability of value-of-life-based models and 85 influences of time pressure (2017) Front. Behav. Neurosci, 11, p. 122},
document_type={Note},
source={Scopus},
}

@ARTICLE{Yilmaz201761,
author={Yilmaz, L. and Franco-Watkins, A. and Kroecker, T.S.},
title={Computational models of ethical decision-making: A coherence-driven reflective equilibrium model},
journal={Cognitive Systems Research},
year={2017},
volume={46},
pages={61-74},
doi={10.1016/j.cogsys.2017.02.005},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016088149&doi=10.1016%2fj.cogsys.2017.02.005&partnerID=40&md5=31db33f25e5f066265bbbaf5c3b27841},
abstract={There are scientific and technical challenges that must be addressed in developing systems that interact with humans and work along with other agents in complex, dynamic, and uncertain environments where ethical concerns may arise. In such systems relationships between users and autonomous components will be driven as much by issues such as trust, responsibility, and acceptability, as technical ones such as planning and coordination. This paper provides a comprehensive review and classification of existing methods in machine ethics, resulting in delineation of specific challenges and issues. To address the identified challenges, we introduce a method that leverages the method of reflective equilibrium and the multi-coherence theory as a unifying constraint satisfaction framework to simultaneously assess multiple ethical principles and manage ethical conflicts in a context-sensitive manner. © 2017 Elsevier B.V.},
author_keywords={Cognitive agent;  Cognitive coherence;  Decision-making;  Machine ethics;  Reflective equilibrium},
keywords={Computation theory;  Decision making, Autonomous components;  Cognitive agents;  Cognitive coherence;  Constraint Satisfaction;  Equilibrium modeling;  Ethical decision making;  Technical challenges;  Uncertain environments, Philosophical aspects, Article;  computer simulation;  conceptual framework;  conflict of interest;  engineering;  ethical decision making;  goal attainment;  job satisfaction;  learning theory;  machine learning;  mathematical model;  medical ethics;  priority journal;  sense of coherence},
references={Anderson, M., Anderson, S.L., Machine ethics (2011), Cambridge University Press; Anderson, M., Anderson, S., Geneth: A general ethical dilemma analyzer (2013) Proceedings of the eleventh international symposium on logical formalizations of commonsense reasoning, Ayia Napa, Cyprus; Anderson, M., Anderson, S.L., Armen, C., An approach to computing ethics (2006) Intelligent Systems, IEEE, 21 (4), pp. 56-63; Angluin, D., Computational learning theory: Survey and selected bibliography (1992) Proceedings of the twenty-fourth annual ACM symposium on theory of computing, pp. 351-369. , ACM; Apt, K., Principles of constraint programming (2003), Cambridge University Press; Arkin, R., Governing lethal behavior in autonomous robots (2009), CRC Press; Arkoudas, K., Bringsjord, S., Bello, P., Toward ethical robots via mechanized deontic logic (2005) AAAI fall symposium on machine ethics; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44; Clarke, R., Asimov's laws of robotics: Implications for information technology-part i (1993) Computer, 26 (12), pp. 53-61; Daniels, N., (1996) Justice and justification: Reflective equilibrium in theory and practice, 22. , Cambridge Univ Press; Dennis, L., Fisher, M., Slavkovik, M., Webster, M., Ethical choice in unforeseen circumstances (2013) Conference towards autonomous robotic systems, pp. 433-445. , Springer; Gert, B., Morality: Its nature and justification (1998), Oxford University Press on Demand; Gips, J., Towards the ethical robot (1995) Android Epistemology, pp. 243-252; Grogan, A., Driverless trains: It's the automatic choice (2012) Engineering & Technology, 7 (5), pp. 54-57; Herman, M., Moral heuristics and biases (2014) Journal of Cognition and Neuroethics, 73 (1), pp. 127-142; Jennings, N.R., Moreau, L., Nicholson, D., Ramchurn, S., Roberts, S., Rodden, T., Human-agent collectives (2014) Communications of the ACM, 57 (12), pp. 80-88. , http://doi.acm.org/10.1145/2629559; Kurland, N.B., Ethical intentions and the theories of reasoned action and planned behavior (1995) Journal of Applied Social Psychology, 25 (4), pp. 297-313; McLaren, B.M., Computational models of ethical reasoning: Challenges, initial steps, and future directions (2006) Intelligent Systems, IEEE, 21 (4), pp. 29-37; Moor, J.M., The nature, importance, and difficulty of machine ethics (2006) Intelligent Systems, IEEE, 21 (4), pp. 18-21; Pereira, L.M., Saptawijaya, A., Modelling morality with prospective logic (2009) International Journal of Reasoning-based Intelligent Systems, 1 (3-4), pp. 209-221; Powers, T.M., Prospects for a kantian machine (2006) IEEE Intelligent Systems, 21 (4), pp. 46-51; Rawls, J., A theory of justice (2009), Harvard university press; Robbins, R.W., Wallace, W.A., Decision support for ethical problem solving: A multi-agent approach (2007) Decision Support Systems, 43 (4), pp. 1571-1587; Ross, W.D., Stratton-Lake, P., The right and the good (2002), Oxford University Press; Saptawijaya, A., Pereira, L.M., Moral reasoning under uncertainty (2012) Logic for programming, artificial intelligence, and reasoning, pp. 212-227. , Springer; Sen, S., Airiau, S., Emergence of norms through social learning (2007) IJCAI, 1507, p. 1512; Thagard, P., Coherence in thought and action (2002), MIT press; Turilli, M., Ethical protocols design (2007) Ethics and Information Technology, 9 (1), pp. 49-62; Tversky, A., Kahneman, D., The framing of decisions and the psychology of choice (1985) Environmental impact assessment, technology assessment, and risk analysis, pp. 107-129. , Springer; Wallach, W., Allen, C., Moral machines: Teaching robots right from wrong (2008), Oxford University Press; Weiss, G., Multiagent systems: A modern approach to distributed artificial intelligence (1999), MIT press; Wright, R., (2010), The moral animal: Why we are, the way we are: The new science of evolutionary psychology. Vintage; Yilmaz, L., Franco-Watkins, A., Kroecker, T.S., Coherence-driven reflective equilibrium model of ethical decision-making (2016) 2016 IEEE international multi-disciplinary conference on cognitive methods in situation awareness and decision support (CogSIMA), pp. 42-48. , IEEE},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bendel201717,
author={Bendel, O.},
title={Sex robots from the perspective of machine ethics},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10237 LNAI},
pages={17-26},
doi={10.1007/978-3-319-57738-8_2},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018695942&doi=10.1007%2f978-3-319-57738-8_2&partnerID=40&md5=9a3edd3e57047fb55a89011f6234a213},
abstract={This contribution explains firstly the terms and the phenomena of sex robots and robot sex and the foundations of machine ethics. Secondly it poses questions related to sex robots as moral agents, from a general and a specific perspective, aiming at assisting manufacturers and developers. By using the questions, the opportunities and risks can be discussed in a structured manner. Thirdly, the fields of applied ethics are included to work out the implications for humans as moral patients. At the end, the author summarizes the findings. Machine ethics, from his point of view, may help to construct sex robots and service robots with special capabilities which are moral machines in their appearance and in their behaviour and which may allow some people to complement their sexual activities and to lead a fulfilling life. The fields of applied ethics may be beneficial with respect to the adequate use of sex robots. © Springer International Publishing AG 2017.},
author_keywords={Artificial intelligence;  Information ethics;  Machine ethics;  Robot sex;  Sex dolls;  Sex robots;  Technology ethics},
keywords={Artificial intelligence;  Philosophical aspects;  Robots, Information ethics;  Moral agents;  Service robots;  Sex dolls, Intelligent robots},
references={Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge University Press, Cambridge; Bendel, O., (2016) Überlegungen Zur Zweckentfremdung Von Robotern, , http://www.inside-it.ch, inside-it.ch, 18 August; Bendel, O., Die Sexroboter kommen: Die Frage ist nur, wie und wann (2016) Telepolis, 13. , http://www.heise.de/tp/artikel/48/48471/1.html, June; Bendel, O., Surgical, therapeutic, nursing and sex robots in machine and information ethics (2015) Machine Medical Ethics, pp. 17-32. , van Rysewyk, S.P., Pontier, M. (eds.), Springer, New York; Bendel, O., Wirtschaftliche und technische Implikationen der Maschinenethik (2014) Die Betriebswirtschaft, 4, pp. 237-248; Bendel, O., Towards machine ethics (2014) Technology Assessment and Policy Areas of Great Transitions. 1St PACITA Project Conference, pp. 321-326. , Michalek, T., Hebáková, L., Hennen, L., et al. (eds.), 13-15 March 2013, Prague; Bendel, O., Good bot, bad bot: Dialog zwischen Mensch und Maschine (2013) Unternehmerzeitung, 7 (19), pp. 30-31; Bendel, O., Ich bremse auch für Tiere: Überlegungen zu einfachen moralischen Maschinen (2013) Inside-It.Ch, , http://www.inside-it.ch/articles/34646, 4 December; Boden, M., Bryson, J., Caldwell, D., Principles of robotics: Regulating robots in the real world (2010) Guidelines for Engineers and Roboticists from a EPSRC/AHRC Funded Retreat, , https://www.epsrc.ac.uk/research/ourportfolio/themes/engineering/activities/principlesofrobotics/; Coeckelbergh, M., Personal robots, appearance, and human good: A methodological reflection on roboethics (2009) Int. J. Soc. Robot, 1 (3), pp. 217-221; Danaher, J., Robotic rape and robotic child sexual abuse: Should they be criminalised? (2014) Criminal Law and Philosophy, pp. 1-25. , 13 December; Freuler, R., Was hat Sex mit Technologie zu tun? (2016) NZZ am Sonntag, pp. 60-61, 23. , October; Hänßler, B., Stets zu Liebesdiensten In: Stuttgarter-Zeitung.De, , http://www.stuttgarter-zeitung.de/inhalt.sexroboter-stets-zu-liebesdiensten.59ec16f3-55c3-4befa7ba-d24eccfa8d47.html, 29 August 2012; Hartwell, L., So who wants to f**k a robot? In: Wired.Com, , http://www.wired.com/underwire/2007/10/so-who-wants-to/, 10 June 2007; Levy, D., (2008) Sex and Love with Robots. the Evolution of Human-Robot Relationships, , Harper Perennial, New York; Möthe, A., Sexspielzeug statt Tupperware In: Handelsblatt, , http://www.handelsblatt.com/unternehmen/handel-konsumgueter/boom-der-erotik-branchesexspielzeug-statt-tupperware/11430194.html, 27 February 2015; O’Hear, S., Second Life child pornography investigation In: Zdnet, , http://www.zdnet.com/article/second-life-child-pornography-investigation/, 10 May 2007; Pereira, L.M., Saptawijaya, A., (2016) Programming Machine Ethics, , Springer, Cham; Richardson, K., The asymmetrical ‘Relationship’: Parallels between prostitution and the development of sex robots (2015) SIGCAS Comput. Soc, 45 (3), pp. 290-293; Rötzer, F., Chinas erster Überwachungsroboter (2016) Telepolis, , http://www.heise.de/tp/artikel/48/48232/1.html, 13 May; Rötzer, F., Dallas: Umfunktionierter Bombenroboter zur gezielten Tötung eines Verdächtigen (2016) Telepolis, , http://www.heise.de/tp/artikel/48/48771/1.html, 8 July; Scheutz, M., Arnold, T., Are we ready for sex robots? (2016) HRI 2016: The Eleventh ACM/IEEE International Conference on Human Robot Interaction, March 2016, pp. 351-358; Seeßlen, G., Träumen Androiden von elektronischen Orgasmen? (2012) Sex-Fantasien in Der Hightech-Welt, 1. , Bertz-Fischer, Berlin; Sullins, J.P., Robots, love, and sex: The ethics of building a love machine (2012) IEEE Trans. Affect. Comput, 3 (4), pp. 398-409; Wallach, W., Allen, C., Moral Machines (2009) Teaching Robots Right from Wrong, , Oxford University Press, Oxford; Wendel, J., Pepper The Robot soll nicht für Sex benutzt werden (2015) Wired, 24, , https://www.wired.de/collection/latest/eine-passage-im-nutzervertrag-von-pepperrobot-verbietet-sex, September},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Fletcher2017159,
author={Fletcher, S.R. and Webb, P.},
title={Industrial robot ethics: The challenges of closer human collaboration in future manufacturing systems},
journal={Intelligent Systems, Control and Automation: Science and Engineering},
year={2017},
volume={84},
pages={159-169},
doi={10.1007/978-3-319-46667-5_12},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010382726&doi=10.1007%2f978-3-319-46667-5_12&partnerID=40&md5=e538ae373808097d7db6980f32cadb76},
abstract={As a result of significant advances in information and communications technology the manufacturing industry is facing revolutionary changes whereby production processes will become increasingly digitised and interconnected cyber-physical systems. A key component of these new complex systems will be intelligent automation and human-robot collaboration. Industrial robots have traditionally been segregated from people in manufacturing systems because of the dangers posed by their operational speeds and heavy payloads. However, advances in technology mean that we will soon see large-scale robots being deployed to work more closely and collaboratively with people in monitored manufacturing sytems and widespread introduction of small-scale robots and assistive robotic devices. This will not only transform the way people are expected to work and interact with automation but will also involve much more data provision and capture for performance monitoring. This paper discusses the background to these developments and the anticipated ethical issues that we now face as people and robots become able to work collaboratively in industry. © Springer International Publishing AG 2017.},
author_keywords={Human-robot collaboration;  Industrial automation;  Industrial robots;  Manufacturing},
references={Ashton, T., The industrial revolution 1760–1830 (1966) Hands of a Child, 109. , Oxford Academic Press; Bartneck, C., Croft, E., Kulic, D., Measuring the anthropomorphism, animacy, likeability, perceived intelligence and perceived safety of robots (2008) Proceedings of Metrics for Human-Robot Interaction Workshop in Affiliation with the 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), pp. 37-44. , Technical report 471. University of Hertfordshire, Amsterdam; Battini, D., Faccio, M., Persona, A., Sgarbossa, F., New methodological framework to improve productivity and ergonomics in assembly system design (2011) Int J Ind Ergon, 41 (1), pp. 30-42; Baxter, G., Sommerville, I., Socio-technical systems: From design methods to systems engineering (2011) Interact Comput, 23 (1), pp. 4-17; Charalambous, G., Fletcher, S., Webb, P., Identifying the key organisational human factors for introducing human-robot collaboration in industry: An exploratory study (2015) Int J Adv Manuf Technol, pp. 1-13; Charalambous, G., Fletcher, S., Webb, P., The development of a scale to evaluate trust in industrial human-robot collaboration (2015) Int J Soc Robot, pp. 1-17; Chung, C., Human issues influencing the successful implementation of advanced manufacturing technology (1996) J Eng Technol Manage, 13 (3), pp. 283-299; De Krüger, J., Lien, T., Verl, A., Cooperation of human and machines in assembly lines (2009) CIRP Ann Manuf Technol, 58, pp. 628-646; De Santis, A., Siciliano, B., Safety issues for human-robot cooperation in manufacturing systems (2008) Tools and Perspectives in Virtual Manufacturing, , Napoli, Italy, July; Ding, Z., Hon, B., Constraints analysis and evaluation of manual assembly. CIRP (2013) Ann. Manuf Technol, 62 (1), pp. 1-4; Doyle, C., (2003) Work and Organizational Psychology: An Introduction with Attitude, , Psychology Press, Hove; Essers, M., Vaneker, T., (2015) Design of a Decentralized Modular Architecture for Flexible and Extensible Production Systems, , Mechatronics; Fletcher, S., Baines, T., Harrison, D., An investigation of production workers’ performance variations and the potential impact of attitudes (2008) Int J Adv Manuf Technol, 35, pp. 1113-1123; Givehchi, O., Trsek, H., Jasperneite, J., Cloud computing for industrial automation systems—a comprehensive overview (2013) Proceedings of 2013 IEEE 18th Conference on Emerging Technologies & Factory Automation (ETFA), pp. 1-4; Hedelind, M., Kock, S., Requirements on flexible robot systems for small parts assembly, a case study (2011) Proceeding of International Symposium on Assembly and Manufacturing, , 25–27 May, Tampere, Finland; Hermann, M., Pentek, T., Otto, B., (2015) Design Principles for Industrie 4.0 Scenarios: A Literature Review; (2013) Collision and Injury Criteria When Working with Collaborative Robots (RR906), , Health and safety executive 2013; Jacobs, R., Rise of robot factories leading ‘fourth industrial revolution’ (2015) Newsweek (US Edition), , http://www.newsweek.com/2015/03/27/rise-robot-factories-leading-fourth-industrial-revolution-311497.html, March 5, 2015, Newsweek, Accessed 21 Jun 2015; Kagermann, H., Lukas, W., Wahlster, W., (2011) Industrie 4.0: Mit Dem Internet Der Dinge Auf Dem Weg Zur 4. Industriellen Revolution, , VDI nachrichten 13; Kulić, D., Croft, E., Real-time safety for human-robot interaction (2006) Robot Auton Syst, 54, pp. 1-12; Lanza, G., Haefner, B., Kraemer, A., Optimization of selective assembly and adaptive manufacturing by means of cyber-physical system based matching (2015) CIRP Ann Manuf Technol; Mayer, M., Schlick, C., Ewert, D., Behnen, D., Kuz, S., Odenthal, B., Kausch, B., Automation of robotic assembly processes on the basis of an architecture of human cognition (2011) Prod Eng, 5 (4), pp. 423-431; Mintzberg, H., (1983) Structuring by Fives: Designing Effective Organizations, , Prentice-Hall, Englewood Cliffs, NJ; Mokyr, J., The second industrial revolution, 1870–1914 (1998) Storia dell’economia Mondiale, , Valerio C (ed), Laterza Publishing; Parasuraman, R., Wickens, C., Humans: Still vital after all these years of automation (2008) Hum Factors J Hum Factors Ergon Soc, 50 (3), pp. 511-520; Rifkin, J., The 2016 world economic forum misfires with its fourth industrial revolution theme (2016) The Economist, , http://www.industryweek.com/information-technology/2016-world-economic-forum-misfires-its-fourth-industrial-revolution-theme, Jan 15, 2016, the economist, Accessed 20 Apr 2016; Schuh, G., Reuter, C., Hauptvogel, A., Dölle, C., Hypotheses for a theory of production in the context of industrie 4.0 (2015) Advances in Production Technology, pp. 11-23. , Springer; Schwab, K., (2015) The Fourth Industrial Revolution, , Foreign Affairs 12; Shen, Y., Reinhart, G., Tseng, M., A design approach for incorporating task coordination for human-robot-coexistence within assembly systems (2015) Proceedings of 9th IEEE Annual IEEE International Systems Conference (Syscon), pp. 426-431; (2012) Making the Future: How Robots and People Team up to Manufacture Things in New Ways, , http://www.economist.com/node/21552897, Economist, Accessed 30 May 2015; Vasic, M., Billard, A., Safety issues in human-robot interactions (2013) Proceedings of 2013 IEEE International Conference on in Robotics and Automation (ICRA), pp. 197-204; Walton, M., (2013) In the Context of Wing equipping—a Framework for Safeguarding Direct Cooperation between High Load, Industrial Robots and Human Operators, , Unpublished PhD thesis; Wan, J., Cai, H., Zhou, K., Industrie 4.0: Enabling technologies (2015) Proceedings of 2014 IEEE International Conference on Intelligent Computing and Internet of Things (ICIT), pp. 135-140; Wang, L., Törngren, M., Onori, M., Current status and advancement of cyber-physical systems in manufacturing (2015) J Manuf Sys (Part, 2 (37), pp. 517-527; Wang, S., Wan, J., Li, D., Zhang, C., Implementing smart factory of industrie 4.0: An outlook (2016) Int J Distrib Sens Netw; Yin, S., Kaynak, O., Big data for modern industry: Challenges and trends [point of view] (2015) Proc IEEE, 103 (2), pp. 143-146},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Torrance2013399,
author={Torrance, S.},
title={Artificial agents and the expanding ethical circle},
journal={AI and Society},
year={2013},
volume={28},
number={4},
pages={399-414},
doi={10.1007/s00146-012-0422-2},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889578637&doi=10.1007%2fs00146-012-0422-2&partnerID=40&md5=907f0e5341824550226b794f53ca8980},
abstract={I discuss the realizability and the ethical ramifications of Machine Ethics, from a number of different perspectives: I label these the anthropocentric, infocentric, biocentric and ecocentric perspectives. Each of these approaches takes a characteristic view of the position of humanity relative to other aspects of the designed and the natural worlds-or relative to the possibilities of 'extra-human' extensions to the ethical community. In the course of the discussion, a number of key issues emerge concerning the relation between technology and ethics, and the nature of what it is to have moral status. Some radical challenges to certain technological presuppositions and ramifications of the infocentric approach will be discussed. Notwithstanding the obvious tensions between the infocentric perspective on one side and the biocentric and ecocentric perspectives on the other, we will see that there are also striking parallels in the way that each of these three approaches generates challenges to an anthropocentric ethical hegemony, and possible scope for some degree of convergence. © 2012 Springer-Verlag London Limited.},
author_keywords={Anthropocentrism;  Artificial intelligence;  Biocentrism;  Consciousness;  Ecocentrism;  Infocentrism;  Machine Ethics;  Moral status;  The 'more-than-human' world},
keywords={Anthropocentrism;  Biocentrism;  Consciousness;  Ecocentrism;  Infocentrism;  Moral status;  The 'more-than-human' world, Artificial intelligence, Philosophical aspects},
references={Abram, D., (1996) The Spell of the Sensuous: Perception and Language in a More-than-Human World, , NY: Random House; Abram, D., (2010) Becoming Animal: An Earthly Cosmology, , NY: Pantheon Books; Aleksander, I., (2005) The World in My Mind, My Mind in the World: Key Mechanisms of Consciousness in Humans, Animals and Machines, , Thorverton: Imprint Academic; Anderson, M., Anderson, S.L., (2011) Machine Ethics, , NY: Cambridge University Press; Bentham, J., (1823) Introduction to the principles of morals and legislation, , 2nd edn. Reprinted 1907, Clarendon Press, Oxford; Bostrom, N., When machines outsmart humans (2000) Futures, 35 (7), pp. 759-764; Bostrom, N., The future of human evolution (2004) Death and Anti-Death: Two Hundred Years after Kant; Fifty Years after Turing, pp. 339-371. , C. Tandy (Ed.), Palo Alto: Ria University Press; Bostrom, N., The ethics of superintelligent machines (2005) Symposium on cognitive, emotive and ethical aspects of decision-making in humans and artificial intelligence, InterSymp 05, , In: Smit I, Wallach W, Lasker G (eds), IIAS Press, Windsor; Android science and the animal rights movement: are there analogies? (2005) Proceedings of CogSci-2005 workshop, pp. 127-136. , Calverley, Cognitive Science Society, Stresa; Chalmers, D., The singularity: a philosophical analysis (2010) J Conscious Stud, 17 (910), pp. 7-65; Curry, P., (2006) Ecological Ethics: An Introduction, , Cambridge: Polity Press; De Jaegher, H., Social understanding through direct perception? yes, by interacting (2008) Conscious Cogn, 18, pp. 535-542; De Jaegher, H., Di Paolo, E., Participatory sense-making: an enactive approach to social cognition (2007) Phenomenol Cogn Sci, 6 (4), pp. 485-507; De Waal, F., (2006) Primates and Philosophers: How Morality Evolved, , Oxford: Princeton U.P; Dennett, D.C., Why you can't make a computer that feels pain (1978) Brainstorms: Philosophical essays on mind and psychology, pp. 190-232. , MIT Press, Cambridge; Dennett, D.C., The practical requirements for making a conscious robot (1998) Brainchildren: Essays on Designing Minds, pp. 153-170. , D. C. Dennett (Ed.), London: Penguin Books; Di Paolo, E., Autopoiesis, adaptivity, teleology, agency (2005) Phenomenol Cogn Sci, 4, pp. 97-125; Dietrich, E., After the humans are gone (2007) J Exp Theor Artif Intell, 19 (1), pp. 55-67; Ernste, H., The pragmatism of life in poststructuralist times (2004) Environ Plan A, 36, pp. 437-450; Floridi, L., Artificial intelligence's new frontier: artificial companions and the fourth revolution (2008) Metaphilosophy, 39 (4-5), pp. 651-655; Floridi, L., Information ethics, its nature and scope (2008) Moral Philosophy and Information Technology, pp. 40-65. , J. Weckert and J. HovenVan den (Eds.), Cambridge: Cambridge U.P; Floridi, L., Information ethics: a reappraisal (2008) Ethics Inf Technol, 10 (2-3), pp. 189-204; Franklin, S., (1995) Artificial Minds, , Boston: MIT Press; Frey, R.G., (1980) Interests and Rights: The Case against Animals, , Oxford: Clarendon Press; Gallagher, S., The practice of mind: theory, simulation or primary interaction? (2001) J Conscious Stud, 8 (5-7), pp. 83-108; Gallagher, S., Direct perception in the intersubjective context (2008) Conscious Cogn, 17, pp. 535-543; Goertzel, B., Ten years to a positive singularity (if we really, really try) (2006) Talk to Transvision 2006, , http://www.goertzel.org/papers/tenyears.htm, Helsinki; Haikonen, P., (2003) The Cognitive Approach to Conscious Machines, , Thorverton: Imprint Academic; Holland, O., Special issue on machine consciousness (2003) J Conscious Stud, 10 (4-5); Jonas, H., (1996) The phenomenon of life: Toward a philosophical biology, , Northwestern University Press, Evanston (originally published by Harper & Row (NY) in 1996); Joy, B., Why the future doesn't need us (2000) Wired, 8 (4). , http://www.wired.com/wired/archive/8.04/joy_pr.html; Kant, I., (1997) Lectures on ethics, , In: Heath P, Schneewind JB (eds), Cambridge U. P., Cambridge; Kurzweil, R., One half of an argument (response to Lanier 2000) (2001) The edge, , http://www.edge.org/3rd_culture/kurzweil/kurzweil_index.html, (online publication), 8. 4. 01; Kurzweil, R., (2005) The Singularity is near: When Humans Transcend Biology, , NY: Viking Press; LaChat, M., "Playing god" and the construction of artificial persons (2004) Symposium on cognitive, emotive and ethical aspects of decision-making in humans and artificial intelligence, InterSymp 04, , In: Smit I, Wallach W, Lasker G (eds), IIAS Press, Windsor; Lanier, J., One half of a Manifesto (2000) The edge, , http://www.edge.org/3rd_culture/lanier/lanier_index.html, (online publication), 11. 11. 00; Leopold, A., The land ethic (1949) A sand county almanac with sketches here and there, p. 201. , Oxford University Press, New York; Lovelock, J., (1979) Gaia: A New Look at Life on Earth, , Oxford: Oxford U.P; Lovelock, J., (2006) The Revenge of Gaia: Why the Earth is Fighting Back, and How We Can Still save Humanity, , London: Allen Lane; Maturana, H., Varela, F., (1980) Autopoiesis and Cognition: The Realization of the Living, , Dordrecht: D. Reidel Publishing; Midgley, M., (1978) Beast and Man: The Roots of Human Nature, , Ithaca: Cornell U.P; Moor, J., The nature, importance and difficulty of machine ethics (2006) IEEE Intell Syst, 21 (4), pp. 18-21; Moravec, H., (1988) Mind Children: The Future of Robot and Human Intelligence, , Cambridge: Harvard U.P; Naess, A., The shallow and the deep long-range ecology movements (1973) Inquiry, 16, pp. 95-100; Naess, A., Sessions, G., Basic principles of deep ecology (1984) Ecophilosophy, 6, pp. 3-7; Regan, T., (1983) The Case for Animal Rights, , Berkeley: University of California Press; Singer, P., (1977) Animal Liberation, , London: Granada; Singer, P., (2011) The expanding circle: Ethics, evolution and moral progress, , Princeton U. P., Princeton. (Revised edition of Singer P (1981), The expanding circle: ethics and sociobiology. Farrar, Strauss and Giroux, NY); Singer, P., Sagan, A., When robots have feelings (2009) The guardian, , http://www.guardian.co.uk/commentisfree/2009/dec/14/rage-against-machines-robots, Tues 15 December 2009; Sloman, A., (1978) The Computer Revolution in Philosophy: Philosophy, Science and Models of Mind, , Hassocks: Harvester Press; Sparrow, R., Killer robots (2007) Appl Philos, 24 (1), pp. 62-77; Sparrow, R., Sparrow, L., In the hands of machines? the future of aged care (2006) Minds Mach, 16 (2), pp. 141-161; Sylvan, R., Bennett, D., (1994) The Greening of Ethics: From Human Chauvinism to Deep-Green Theory, , Cambridge: White Horse Press; Thompson, E., (2007) Mind in Life: Biology, Phenomenology and the Sciences of Mind, , Cambridge: Harvard U.P; Torrance, S., Towards an ethics for epersons (2000) Proceedings of AISB'00 symposium on AI, ethics and (Quasi-) human rights, , University of Birmingham; Torrance, S., Two conceptions of machine phenomenality (2007) J Conscious Stud, 14 (7), pp. 154-166; Torrance, S., Ethics, consciousness and artificial agents (2008) Artif Intell Soc, 22 (4), pp. 495-521; Torrance, S., Will robots have their own ethics? (2009) Philosophy Now, 72. , http://www.philosophynow.org/issues/72/Will_Robots_Need_Their_Own_Ethics, Accessed 22 Apr 2012; Torrance, S., Would a super-intelligent AI necessarily be (super-) conscious? (2011) Proceedings of machine consciousness symposium at the AISB'11 convention, pp. 67-74. , In: Chrisley R, Clowes R, Torrance S (eds), University of York; Torrance, S., Roche, D., Does an artificial agent need to be conscious to have ethical status? (2011) Technologies on the Stand: Legal and Ethical Questions in Neuroscience and Robotics, pp. 285-310. , B. Bergvan den and L. Klaming (Eds.), Nijmegen: Wolf Legal Publishers; Torrance, S., Clowes, R., Chrisley, R., Machine consciousness: embodiment and imagination (2007) Special issue of J Conscious Stud, 14 (4); Trevarthen, C., Reddy, V., Consciousness in infants (2007) The Blackwell Companion to Consciousness, pp. 41-57. , M. Velmans and S. Schneider (Eds.), Oxford: Blackwell; Vinge, V., The coming technological singularity: how to survive in the post-human era (1993) Whole Earth Rev Winter 1993, , http://www.wholeearth.com/uploads/2/File/documents/technological_singularity.pdf, Accessed 22 Apr 2012; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford: Oxford U.P; Wilson, E.O., (1984) Biophilia, , Cambridge: Harvard U.P; Wilson, E.O., (1994) The Diversity of Life, , Harmondsworth: Penguin; Wright, R., (1994) The Moral Animal: Evolutionary Psychology and Everyday Life, , NY: Pantheon Books; Yudkowsky, E.S., (2001) Creating friendly AI, , http://www.singinst.org/upload/CFAI.html; Yudkowsky, E.S., Cognitive biases potentially affecting judgement of global risks (2008) Global Catastrophic Risks, pp. 91-119. , N. Bostrom and M. Cirkovic (Eds.), Oxford: Oxford U.P},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Sullins2013,
author={Sullins, J.P.},
title={An ethical analysis of the case for robotic weapons arms control},
journal={International Conference on Cyber Conflict, CYCON},
year={2013},
art_number={6568394},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904396519&partnerID=40&md5=f89ab5ebee3bbbfbdf090e73bbddae85},
abstract={While the use of telerobotic and semi-autonomous weapons systems has been enthusiastically embraced by politicians and militaries around the world, their deployment has not gone without criticism. Strong critics such as Asaro (2008), Sharkey (2008, 2009, 2010, 2011, and 2012) and Sparrow (2007, 2009a, 2009b, 2011) argue that these technologies have multiple moral failings and their deployment on principle must be severely limited or perhaps even eliminated. These authors and researchers along with a growing list of others have founded the International Committee for Robot Arms Control as a means for advancing their arguments and advocating for future talks and treaties that might limit the use of these weapons. Others such as Arkin (2010), Brooks (2012), Lin, Abney and Bekey (2008, 2012), Strawser (2010), have argued that there are some compelling reasons to believe that, at least in some cases, deployment of telerobotic and semi-autonomous weapons systems can contribute to marginal improvements to the state of ethical and just outcomes in armed combat. This presentation will trace the main arguments posed by both sides of the issue. Additionally this paper will suggest certain considerations motivated by the philosophy of technology that might be worthy of addition to future robotic arms control treaties. This position argues that these technologies through the process of reverse adaptation can change our notions of just war theory to the point that caution in their use is recommended until further analysis of these effects can be accomplished. A realistic stance towards robotic weapons arms control will be argued for without losing sight of the positive role these technologies can play in resolving armed conflict in the most just and ethical manner possible. © 2013 NATO Coop Cyber Def Ctr.},
author_keywords={Autonomous Weapons Systems (AWS);  Just War Theory;  Machine Ethics;  Robot Ethics;  Robotic Arms Control},
keywords={Industrial robots;  Military equipment;  Philosophical aspects;  Robotic arms, Armed conflict;  Arms control;  Just War Theory;  Philosophy of technology;  Robot arms;  Robot ethics;  Weapons systems, Robotics},
references={Altmann, J., Preventive arms control for uninhabited military vehicles (2013) AKA Verlag Heidelberg, , http://e3.physik.tu-dortmund.de/P&D/Pubs/ 0909_Ethics_and_Robotics_Altmann.pdf, in Ethics and Robotics, R. Capurro and M. Nagenborg (eds. ) Jan 25; Arkin Ronald, C., The case for ethical autonomy in unmanned systems (2010) Journal of Military Ethics, 9 (4), pp. 332-341; Arkin, R.C., (2007) Governing Lethal Behavior: Embedding Ethics in A Hybrid Deliberative/Reactive Robot Architecture, , http://www.cc.gatech.edu/ai/robot-lab/online-publications/ formalizationv35.pdf, November Technical Report GIT-GVU-07-11, Mobile Robot Laboratory College of Computing, Georgia Institute of Technology; Arquilla, J., (2013) Cyberwar Is Already Upon Us: But Can It Be Controlled? Foreign Affairs, , http://www.foreignpolicy.com/articles/2012/02/27/ cyberwar_is_already_upon_us, March/April Jan 25; Arquilla, J., (2013) The New Rules of War, Foreign Policy, , http://www.foreignpolicy.com/articles/2010/02/22/the_new_rules_of_war, March/April Jan 25; Asaro, P., Military robots and just war theory (2011) Ethical and Legal Aspects of Unmanned Systems, pp. 103-119. , In: Dabringer, G. (ed. ) Vienna: Institut für Religion und Frieden; Asaro, P.M., How just could a robot war be? (2008) Current Issues in Computing and Philosophy, pp. 50-64. , In P. Brey, A. Briggle, & K. Waelbers (eds. ), Amsterdam: Ios Press; Brooks, R., (2013) What's Not Wrong with Drones? Forign Policy, , http://www.foreignpolicy.com/articles/2012/09/05/ whats_not_wrong_with_drones, Jan 25; Bynum, T.W., Ethics and the information revolution (2000) Ethics in the Age of Information Technology, pp. 32-55. , Linkoping University, Sweeden; Caroll, R., (2013) Drone Warfare: A New Generation of Deadly Unmanned Weapons. The Guardian, , http://www.guardian.co.uk/world/2012/aug/02/dronewarfare-unmanned-weapons, Jan 25; Dabringer, G., (2011) Ethical and Legal Aspects of Unmanned Systems, , Vienna: Institut für Religion und Frieden; Floridi, L., Sanders, J.W., (2003) The Foundationalist Debate in Computer Ethics. Readings in CyberEthics, , 2nd ed), Jones and Bartlett Publishers, Inc. Canada; Gathmann, F., Gebauer, M., Medick, V., Weiland, S., (2013) Deutschlands Drohnenpläne: Merkel Rüstet Auf, Spiegel, , http://www.spiegel.de/politik/deutschland/kampfdrohnen-plaene-der- regierung-stossen-auf-heftigenwiderstand-a-879701.html, January 25 February 6; Glaser, J., (2013) Terrorized by Drones, Afghan Civilians Increasingly Flee Homes, , http://news.antiwar.com/2013/03/28/terrorized-bydrones-afghan-civilians- increasingly-flee-homes/, Anti War. com March 28. March 29; Staff, H.J., (2012) Researchers: Drones Vulnerable to Terrorist Hijacking, , http://www.homeland1.com/Security-Technology/articles/ 1309966-Researchers-Drones-vulnerable-to-terrorist-hijacking/, Homeland1, July 2 March 29, 2013; http://ihl.ihlresearch.org/index.cfm?fuseaction=page.viewpage&pageid= 2083, International Humanitarian Law Research Initiative (IHLRI), Harvard University. Accessed on February 2, 2013; Kahn Paul, W., The paradox of riskless warfare (2002) Philosophy & Public Policy Quarterly, 22 (3), pp. 2-8; Kim, L., (2013) Germany and Drones. International Herald Tribune, , http://latitude.blogs.nytimes.com/2013/02/05/germany-anddrones/?nl= opinion&emc=edit_ty_20130205, February 5. Feb 5; Landler, M., (2012) Civilian Deaths Due to Drones Are Not Many, Obama Says, the New York Times, , http://www.nytimes.com/2012/01/31/world/middleeast/civilian-deaths-due- to-drones-are-few-obama-says.html?_r=0, January 30. March 28, 2013; Lessig, L., (1999) The Code Is the Law. Industry Standard, , April 19-26; Lin, P., Ethical blowback from emerging technologies (2010) Journal of Military Ethics, 9 (4), pp. 313-331; Patrick, L., Abney, K., Bekey, G., (2008) Autonomous Military Robotics: Risk, Ethics, and Design, , San Luis Obispo, CA: California Polytechnic State University; Lin, P., Bekey, G., Abney, K., (2012) Robot Ethics: The Ethical and Social Implications of Robotics, , Cambridge, MA: MIT Press; Marchant, G.E., International governance of autonomous military robots (2011) The Columbia Science and Technology Law Review, 12, pp. 272-315; Medick, V., (2013) Credible Deterrence': Germany Plans to Deploy Armed Drones, Spiegel, , http://www.spiegel.de/international/germany/germany-plans-to-deploy- armed-drones-in-combat-abroad-a-879633.html, January 25, 2013. 6, 2013; Moor, J.H., What is computer ethics? (1985) Metaphilosophy, 16 (4), pp. 266-275; Qazi, S.H., Jillani, S., (2012) Four Myths about Drone Strikes. The Diplomat, , http://thediplomat.com/2012/06/09/four-myths-about-dronestrikes/, June 9. March 28, 2013; Oudes, C., Zwijnenburg, W., (2011) Does Unmanned Make Unacceptable?, , Exploring the Debate on Using Drones and Robots in Warfare. Utrecht: IKV Pax Christi; Rohde, D., (2012) The Obama Doctrine: How the President's War Is Backfiring, , http://www.foreignpolicy.com/articles/2012/02/27/the_obama_doctrine, Foreign Policy, March/April. on Feb 1, 2013; Sauer, F., Schörnig, N., Killer drones-The silver bullet of democratic warfare? (2012) Security Dialogue, 43 (4), pp. 363-380; Schmitt, M.N., (2012) International Law in Cyberspace: The Koh Speech and Tallinn Manual Juxtaposed, 54 Harv. Int'l L. J., , http://www.harvardilj.org/2012/12/online-articles-online_54_schmitt/, 13. Accessed March 29, 2013; Schmitt, M.N., (2013) Tallinn Manual on the International Law Applicable to Cyber Warfare, , http://www.ccdcoe.org/249.html, Cambridge University Press. Accessed on March 3, 2013; Sharkey, N., Grounds for discrimination: Autonomous robot weapons (2008) RUSI Defence Systems, 11 (2), pp. 86-89; Noel, S., Death strikes from the sky (2009) IEEE Technology and Society Magazine, 28 (1), pp. 16-19; Noel, S., Saying 'no!' to lethal autonomous targeting (2010) Journal of Military Ethics, 9 (4), pp. 369-383; Noel, S., Moral and legal aspects of military robots (2011) Ethical and Legal Aspects of Unmanned Systems. Vienna: Institut Für Religion und Frieden, pp. 43-51. , In: Dabringer G (ed. ); Sharkey, N., Killing made easy: From joysticks to politics (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 111-128. , In Lin, P. Abney, K. and Bekey, G. A. Cambridge, MA: MIT Press; Simonite, T., (2008) 'Robot Arms Race' Underway, Expert Warns. New Scientist, , http://www.newscientist.com/article/dn13382-robot-arms-raceunderway- expert-warns.html, February 27. Accessed on Feb 1 2013; Singer, P.W., (2009) Wired for War, , New York: Penguin Press; Sparrow, R.W., Killer robots (2007) Journal of Applied Philosophy, 24 (1); Sparrow Robert, W., Predators or plowshares? Arms control of robotic weapons (2009) IEEE Technology and Society Magazine, 28 (1), pp. 25-29; Sparrow, R.W., Building a better warbot: Ethical issues in the design of unmanned systems for military applications (2009) Science and Engineering Ethics, 15, pp. 169-187; Sparrow Robert, W., The ethical challenges of military robots (2011) Ethical and Legal Aspects of Unmanned Systems. Vienna: Institut Für Religion und Frieden, pp. 87-102. , In: Dabringer G (ed. ); Strawser, B.J., Moral predators: The duty to employ uninhabited aerial vehicles (2010) Journal of Military Ethics, 9 (4), pp. 342-368; Sullins, J.P., Robowarfare: Can robots be more ethical than humans on the battlefield? (2010) Ethics and Information Technology, 12 (3), pp. 263-275; Sullins, J.P., (2010) Rights and Computer Ethics, pp. 116-133. , The Cambridge Handbook of Information and Computer Ethics, Floridi, L. (ed) Cambridge University Press, UK; Sullins, J.P., Aspects of telerobotic systems (2011) Ethical and Legal Aspects of Unmanned Systems, pp. 157-167. , In: Dabringer G (ed. ) Vienna: Institut für Religion und Frieden; Tavani, H., (2004) Ethics and Technology: Ethical Issues in An Age of Information and Communication Technology, , Wiley, New York USA; (2007) Unmanned Systems Roadmap, pp. 2007-2032. , US Department of Defense Washington, DC: US Department of Defense; (2011) Aircraft Procurement Plan: Fiscal Years (FY), pp. 2012-2041. , US Department of Defense Washington, DC: US Department of Defense; (2012) Autonomy in Weapons Systems. Directive Number 3000, , http://www.dtic.mil/whs/directives/corres/pdf/300009p.pdf, US Department of Defense, November 12,09 Jan 25 2013; Von Kospoth, N., (2009) China's Leap in Unmanned Aircraft Development, , http://www.defpro.com/daily/details/424/(accessed20October2011); Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , New York: Oxford University Press; Winner, L., (1978) Technology: Technics-out-of-control As A Theme in Political Thought, , MIT Press; Woods, C., (2011) Drone War Exposed, , http://www.thebureauinvestigates.com/2011/08/10/most-complete-picture- yet-of-cia-drone-strikes/, Jan 25 2013; Zick, C.J., Survey reveals generation gap in employee attitudes toward confidential information (2012) Security, Privacy and the Law, Blog Published by Foley Hoag LLP, , http://www.securityprivacyandthelaw.com/2012/06/survey-reveals- generation-gapin-employee-attitudes-toward-confidential-information/, March 29 2013; Zubair Shah, P., (2012) My Drone War. Forign Policy, , http://www.foreignpolicy.com/articles/2012/02/27/my_drone_war?page=0,4, March/April. Accessed Feb 1, 2013},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Nylander2012797,
author={Nylander, S. and Ljungblad, S. and Jimenez Villareal, J.},
title={A complementing approach for identifying ethical issues in care robotics - Grounding ethics in practical use},
journal={Proceedings - IEEE International Workshop on Robot and Human Interactive Communication},
year={2012},
pages={797-802},
doi={10.1109/ROMAN.2012.6343849},
art_number={6343849},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870794690&doi=10.1109%2fROMAN.2012.6343849&partnerID=40&md5=94ad7c918f0c0c6f21a7412f190b7d1f},
abstract={We use a long-term study of a robotic eating-aid for disabled users to illustrate how empirical use give rise to a set of ethical issues that might be overlooked in ethic discussions based on theoretical extrapolation of the current state-of-the-art in robotics. This approach provides an important complement to the existing robot ethics by revealing new issues as well as providing actionable guidance for current and future robot design. We discuss our material in relation to the literature on robot ethics, specifically the risk of robots performing care taking tasks and thus causing increased isolation for care recipients. Our data identifies a different set of ethical issues such as independence, privacy, and identity where robotics, if carefully designed and developed, can make positive contributions. © 2012 IEEE.},
keywords={Ethical issues;  Robot designs, Communication;  Machine design;  Robotics;  Robots, Philosophical aspects},
references={Borenstein, J., Pearson, Y., Robot caregivers: Harbingers of expanded freedom for all? (2010) Ethics and Information Technology, 2010, pp. 277-288; Borenstein, J., Pearson, Y., Robot caregivers: Ethical issues across the human lifespan (2012) Robot Ethics, , IN LIN, P., ABNEY, K. & BEKEY, G. A. (Eds.), MIT Press; Cowan, R., (1983) More Work for Mother, , Basic Books; Ferneus, Y., Jacobsson, M., Comics, robots, fashion and programming: Outlining the concept of actdresses (2009) TEI; Ferneus, Y., Jacobsson, M., Ljungblad, S., Holmquist, L.E., Are we living in a robot cargo cult? (2009) HRI, , ACM Press; Fischer, C.S., (1993) America Calling, , University of California Press; Forlizzi, J., Disalvo, C., Service robots in the domestic environment: A study of the roomba vacuum in the home (2006) HRI; Jacobsson, M., Ferneus, Y., Tieben, R., The look, the feel and the action: Making sets of actdresses for robotic movement (2010) DIS; Jiménez Villareal, J., Ljungblad, S., Experience centred design for a robotic eating aid (2011) HRI, Poster, , ACM Press; Ljungblad, S., Kotrbova, J., Jacobsson, M., Cramer, H., Niechwiadowicz, K., Hospital robot at work: Something alien or an intelligent colleague? (2012) CSCW; Ljungblad, S., Nylander, S., Nørgaard, M., Beyond speculative ethics in hri? ethical considerations and the relation to empirical data (2011) HRI; Parks, J.A., (2010) Lifting the Burden of Women's Care Work: Should Robots Replace the "Human Touch"?, 25, pp. 100-120. , Hypatia; Från folkbrist till en åldrande befolkning (in swedish: From lack of people to an ageing population) (1999) SCB, , SCB; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2010) Ethics and Information Technology; Sharkey, N., Sharkey, A., The crying shame of robot nannies: An ethical appraisal (2010) Interaction Studies, 11, pp. 161-190; Sharkey, N., Sharkey, A., The rights and wrongs about robot care (2012) Robot Ethics, , IN LIN, P., ABNEY, K. & BEKEY, G. A. (Eds.), MIT Press; Sparrow, R., Sparrow, L., Hands of machines? the future of aged care (2006) Minds and Machines, 16, pp. 141-161; Sung, J.-Y., Guo, L., Grinter, R.E., Christensen, H.I., (2007) My Roomba is Rambo: Intimate Home Appliances, , UbiComp; Sung, J., Grinter, R.E., Christensen, H.I., "Pimp my roomba": Designing for personalization (2009) CHI, , Boston, MA; Investing in the health workforce enables stronger health systems (2007) WHO, , WHO},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Ljungblad2011191,
author={Ljungblad, S. and Nylander, S. and Nørgaard, M.},
title={Beyond speculative ethics in HRI? Ethical considerations and the relation to empirical data},
journal={HRI 2011 - Proceedings of the 6th ACM/IEEE International Conference on Human-Robot Interaction},
year={2011},
pages={191-192},
doi={10.1145/1957656.1957726},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79953154776&doi=10.1145%2f1957656.1957726&partnerID=40&md5=45fd5c5909c4838f0dffeebbdd68b77c},
abstract={We discuss the difference between understanding robot ethics as something that is grounded in philosophical ideas about a potential future design, and understanding robot ethics as something that is grounded in empirical data. We argue, that understanding "robots" as a relatively homogenous group of designs for which we can formulate general ethics may lead to a foresight of future robot designs that includes ideas and concerns that are not feasible or realistic. Our aim is to exemplify a complementing perspective, by shedding light on two different robotic designs. We discuss their relation to specific use practices and user experiences, and provide some early ethical reflections and design concerns.},
author_keywords={Design;  Human factors;  Theory},
keywords={Empirical data;  Ethical considerations;  Future designs;  Human factors;  Robot designs;  Robotic design;  Shedding light;  Theory;  User experience, Human computer interaction;  Human engineering;  Machine design;  Man machine systems;  Philosophical aspects, Human robot interaction},
references={Bell, G., Dourish, P., Yesterday's tomorrows: Note on ubiquitous computing's dominant vision (2006) Journal of Personal and Ubiquitous Computing; Fernaeus, Y., Jacobsson, M., Ljungblad, S., Holmquist, L.E., Are we living in a robot cargo cult? (2009) Proc HRI '09, pp. 279-280. , ACM, New York, NY, USA; Norman, D., (2005) Emotional Design: Why We Love (Or Hate) Everyday Things, , Basic Books, New York; Sharkey, A.J.C., Sharkey, N.E., Granny and the robots: Ethical issues in robot care for the elderly Ethics and Information Technology, p. 2010. , Springer Netherlands. Springelink. July 04; Sharkey, N.E., The ethical frontiers of robotics (2008) Science, 322, pp. 1800-1801; Sharkey, N.E., Sharkey, A.J.C., The crying shame of robot nannies: An ethical appraisal (2010) Journal of Interaction Studies, 11, pp. 161-190; Veruggio, G., Operto, F., Robotethics: A bottom-up interdiciplinary discourse in the field of applied ethics in robotics (2006) International Review Od Information Ethics, 6. , 12},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Allen201151,
author={Allen, C. and Wallach, W. and Smit, I.},
title={Why machine ethics?},
journal={Machine Ethics},
year={2011},
volume={9780521112352},
pages={51-61},
doi={10.1017/CBO9780511978036.005},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927109340&doi=10.1017%2fCBO9780511978036.005&partnerID=40&md5=76147d669ef8a5de81990987ba7a8160},
abstract={A runaway trolley is approaching a fork in the tracks. if the trolley runs on its current track, it will kill a work crew of five. If the driver steers the train down the other branch, the trolley will kill a lone worker. If you were driving the trolley, what would you do? What would a computer or robot do? Trolley cases, first introduced by philosopher Philippa Foot in 1967[1] and now a staple of introductory ethics courses, have multiplied in the past four decades. What if it's a bystander, rather than the driver, who has the power to switch the trolley's course? What if preventing the five deaths requires pushing another spectator off a bridge onto the tracks? These variants evoke different intuitive responses. Given the advent of modern “driverless” train systems, which are now common at airports and are beginning to appear in more complicated rail networks such as the London Underground and the Paris and Copenhagen metro systems, could trolley cases be one of the first frontiers for machine ethics? Machine ethics (also known as machine morality, artificial morality, or computational ethics) is an emerging field that seeks to implement moral decision-making faculties in computers and robots. Is it too soon to be broaching this topic? We don't think so. © Cambridge University Press 2011.},
keywords={Broaching;  Driver training;  Railroad transportation;  Subways, Copenhagen;  Driverless;  London Underground;  Metro system;  Rail networks;  Train systems, Philosophical aspects},
references={Foot, P., The problem of abortion and the doctrine of double effect (1967) Oxford Rev, 5, pp. 5-15; Nissenbaum, H., How computer systems embody values (2001) Computer, 34 (3), pp. 120, 118–119; Gips, J., Towards the ethical robot (1995) Android Epistemology, pp. 243-252. , K. Ford, C. Glymour, and P. Hayes, eds., MIT Press; Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2006) Ethics and Information Technology, 7, pp. 149-155; Kurzweil, R., (2005) The Singularity is Near: When Humans Transcend Biology, , Viking Adult; Moravec, H., (2000) Robot: Mere Machine to Transcendent Mind, , Oxford Univ. Press; Searle, J.R., Minds, brains, and programs (1980) Behavioral and Brain Sciences, 3 (3), pp. 417-457; Danielson, P., (1992) Artificial Morality: Virtuous Robots for Virtual Games, , Routledge; Anderson, M., Anderson, S.L., Armen, C., Machine ethics (2005) AAAI Fall Symp, , tech report FS-05–06, AAAI Press; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moralagent (2000) Experimental and Theoretical Artificial Intelligence, 12 (3), pp. 251-261; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds and Machines, 14 (3), pp. 349-379; Damasio, A., (1994) Descartes’ Error, , Avon},
document_type={Book Chapter},
source={Scopus},
}

@BOOK{Danielson2011442,
author={Danielson, P.},
title={Prototyping n-reasons: A computer mediated ethics machine},
journal={Machine Ethics},
year={2011},
volume={9780521112352},
pages={442-450},
doi={10.1017/CBO9780511978036.025},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927044484&doi=10.1017%2fCBO9780511978036.025&partnerID=40&md5=c9307599ffafb812e69d9bb0237ebb30},
abstract={Much work in machine ethics attempts to implement ethical theory in autonomous, situated machines – robots. Our previous work in robot ethics falls at the extreme of very simple virtual agents programmed with moral strategies for simple games (Danielson 1992). Even at this extreme, ethics is surprisingly complex. Our later evolvable agents discovered some strategies unexplored by the rational choice ethics literature (Danielson 1996; Danielson 1998; Danielson 2002). Twenty years ago, Dennett was skeptical of this branch of machine ethics: “[N]o remotely compelling system of ethics has ever been made computationally tractable, even indirectly, for real-world moral problems” (Dennett 1989, p. 129). We leave this approach to other contributors in this collection. In contrast, there is the branch of machine ethics that constructs machines to advise people making ethical decisions. Our present work falls here, or so we shall argue. We have developed an innovative survey research platform – N-Reasons – to explore robot ethics at the first level and machine ethics at the second. The question of interest for this volume is if the N-Reasons platform can be usefully seen as a machine. This contrast is interesting in another way relevant to our project. Working on Artificial Morality, the skeptical question I most often faced was, “How could a machine be moral?” The emerging technology of robotics, however, has caught up with some of this skepticism. © Cambridge University Press 2011.},
keywords={Robots, Emerging technologies;  Ethical theories;  Evolvable;  Real-world;  Robot ethics;  Simple games;  Survey research;  Virtual agent, Philosophical aspects},
references={Ahmad, R., Bailey, J., Danielson, P., Analysis of an innovative survey platform: Comparison of the public’s responses to human health and salmon genomics surveys (2008) Public Understanding of Science, , 0963662508091806; Anderson, C., (2008) The Long Tail, , (Rev. and updated ed.). New York: Hyperion; Danielson, P., (1992) Artificial Morality: Virtuous Robots for Virtual Games, , London: Routledge; Danielson, P., Evolving artificial moralities: Genetic strategies, spontaneous orders, and moral catastrophe (1996) Chaos and Society, 18, pp. 329-344. , A. Albert (Ed.), Amsterdam: IOS Press; Danielson, P., Evolutionary models of cooperative mechanisms: Artificial morality and genetic programming (1998) Modeling Rationality, Morality, and Evolution, 7, pp. 423-441. , P. Danielson (Ed.), New York: Oxford University Press; Danielson, P., Competition among cooperators: Altruism and reciprocity (2002) Proceedings of the National Academy of Sciences, 99, pp. 7237-7242; Danielson, P., (2006) From Artificial Morality to NERD: Models, Experiments, & Robust Reflective Equilibrium, , Paper presented at the Artificial Life 10: Achievements and Future Challenges for Artificial Life, Bloomington, Indiana; Danielson, P., A collaborative platform for experiments in ethics and technology (2010) Philosophy and Engineering: An Emerging Agenda, pp. 239-252. , I. v. d. Poel, D. Goldberg (Eds.), Springer; Danielson, P.A., Designing a machine to learn about the ethics of robotics: The n-reasons platform. ethics and information technology (2010) Special Issue on Robot Ethics and Human Ethics, 10 (3), pp. 251-261},
document_type={Book Chapter},
source={Scopus},
}

@BOOK{Mackworth2011335,
author={Mackworth, A.K.},
title={Architectures and ethics for robots: Constraint satisfaction as a unitary design framework},
journal={Machine Ethics},
year={2011},
volume={9780521112352},
pages={335-360},
doi={10.1017/CBO9780511978036.020},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903279904&doi=10.1017%2fCBO9780511978036.020&partnerID=40&md5=a2bc4293d12bed379e6a22488e1f981e},
abstract={Intelligent robots must be both proactive and responsive. that requirement is the main challenge facing designers and developers of robot architectures. A robot in an active environment changes that environment in order to meet its goals and it, in turn, is changed by the environment. In this chapter we propose that these concerns can best be addressed by using constraint satisfaction as the design framework. This will allow us to put a firmer technical foundation under various proposals for codes of robot ethics. Constraint Satisfaction Problems We will start with what we might call Good Old-Fashioned Constraint Satisfaction (GOFCS). Constraint satisfaction itself has now evolved far beyond GOFCS. However, we initially focus on GOFCS as exemplified in the constraint satisfaction problem (CSP) paradigm. The whole concept of constraint satisfaction is a powerful idea. It arose in several applied fields roughly simultaneously; several researchers, in the early 1970s, abstracted the underlying theoretical model. Simply, many significant sets of problems of interest in artificial intelligence can each be characterized as a CSP. A CSP has a set of variables; each variable has a domain of possible values, and there are various constraints on some subsets of those variables, specifying which combinations of values for the variables involved are allowed (Mackworth 1977). The constraints may be between two variables or among more than two variables. A familiar CSP example is the Sudoku puzzle. © Cambridge University Press 2011.},
keywords={Constraint theory;  Intelligent robots;  Machine design;  Philosophical aspects;  Robots, Active environments;  Applied field;  Constraint Satisfaction;  Design frameworks;  Robot architecture;  Robot ethics;  Sudoku puzzles;  Theoretical modeling, Constraint satisfaction problems},
references={Albus, J.S., (1981) Brains, Behavior and Robotics, , NY: McGraw-Hill; Anderson, M., Leigh Anderson, S., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-26; Asimov, I., (1950) I, Robot, , NY: Gnome Press; Brooks, R.A., A robust layered control system for a mobile robot. Ieee journal of robotics and automation (1986) IEEE Journal of Robotics and Automation, 2 (1), pp. 14-23; Brooks, R.A., Intelligence without reason (1991) Proc. Of Twelth International Joint Conference on Artificial Intelligence, pp. 569-595. , San Mateo, CA: Morgan Kaufmann; Capek, K., (1923) R.U.R. (Rossum’s Universal Robots): A Fantastic Melodrama in Three Acts and an Epilogue, , Garden City, NY: Doubleday; Dresner, K., Stone, P., A multiagent approach to autonomous intersection management (2008) Journal of Artificial Intelligence Research, 31, pp. 591-656; Feuerbach, L.A., (1854) The Essence of Christianity, , London: John Chapman; Freuder, E.C., Mackworth, A.K., Constraint satisfaction: An emerging paradigm (2006) Handbook of Constraint Programming, pp. 13-28. , ed. F. Rossi, P. Van Beek and T. Walsh, Amsterdam: Elsevier; Haugeland, J., (1985) Artificial Intelligence: The Very Idea, , Cambridge, MA: MIT Press; Hsu, F., (2002) Behind Deep Blue: Building the Computer that Defeated the World Chess Champion, , Princeton, NJ: Princeton University Press; Kitano, H., (1998) Robocup-97: Robot Soccer World Cup I. Lecture Notes in Computer Science, p. 1395. , (ed.), Heidelberg: Springer; Lashley, K.S., The problem of serial order in behavior (1951) Cerebral Mechanisms in Behavior, pp. 112-136. , Ed. L.A. Jeffress, New York: Wiley; Lennon, J., (1980) Beautiful Boy (Darling Boy). Song Lyrics, , On album Double Fantasy; McLuhan, M., (1964) Understanding Media: The Extensions of Man, , New York: New American Library; Mackworth, A.K., Consistency in networks of relations (1977) Artificial Intelligence, 8 (1), pp. 99-118; Mackworth, A.K., On seeing robots (1993) Computer Vision: Systems, Theory and Applications, pp. 1-13. , eds. A. Basu and X. Li, Singapore: World Scientific Press; Mackworth, A.K., (2009) Agents, Bodies, Constraints, Dynamics, and Evolution, 26 (30), pp. 7-28,. , AI Magazine, Spring 2009; Mackworth, A.K., Zhang, Y., A formal approach to agent design: An overview of constraint-based agents (2003) Constraints, 8 (3), pp. 229-242; Maxwell, J.C., On governors (1868) In Proceedings of the Royal Society of London, 16, pp. 270-283. , London: The Royal Society; Miller, G.A., Galantner, E., Pribram, K.H., (1960) Plans and the Structure of Behavior, , New York: Holt, Rinehart & Winston; Mori, M., (1982) The Buddha in the Robot, , Tokyo: Charles E. Tuttle Co; Muyan-Ozçelik, P., Mackworth, A.K., Situated robot design with prioritized constraints (2004) Proc. Int. Conf. On Intelligent Robots and Systems (IROS 2004), pp. 1807-1814; Reiter, R., On closed world data bases (1978) Logic and Data Bases, pp. 119-140. , In, eds. H. Gallaire and J. Minker, New York, NY: Plenum; Rossi, F., Van Beek, P., (2006) Handbook of Constraint Programming, , eds.), Amsterdam: Elsevier Science; Sahota, M., Mackworth, A.K., Can situated robots play soccer? (1994) Proc. Artificial Intelligence ’94, pp. 249-254. , Toronto ON: Can. Soc. for Comp. Studies of Intelligence; Shelley, M.W., (1818) Frankenstein; Or, the Modern Prometheus, , London: Lackington, Hughes, Harding, Mavor and Jones; Somerville, M., (2006) The Ethical Imagination: Journeys of the Human Spirit, , Toronto: House of Anansi Press; St-Aubin, R., Friedman, J., Mackworth, A.K., A formal mathematical framework for modeling probabilistic hybrid systems (2006) Annals of Mathematics and Artificial Intelligence, 37 (3-4), pp. 397-425; Thrun, S., (2006) Winning the DARPA Grand Challenge. Invited Talk at Innovative Applications of Artificial Intelligence (IAAI-06), pp. 16-20. , Boston, Massachusetts, July; Visser, U., Burkhard, H.D., Robocup: 10 years of achievements and challenges (2007) AI Magazine, 28 (2), pp. 115-130; Waltz, D.L., Understanding line drawings of scenes with shadows (1975) The Psychology of Computer Vision, pp. 19-92. , ed. P.H. Winston, New York, NY: McGraw-Hill; Zhang, Y., Mackworth, A.K., Constraint programming in constraint nets (1993) Proc. First Workshop on Principles and Practice of Constraint Programming, pp. 303-312. , Padua: Assoc. for Constraint Programming; Zhang, Y., Mackworth, A.K., Constraint nets: A semantic model for dynamic systems (1995) Theoretical Computer Science, 138, pp. 211-239},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Rzepka20082172,
author={Rzepka, R. and Higuchi, S. and Ptaszynski, M. and Araki, K.},
title={Straight thinking straight from the net - On the web-based intelligent talking toy development},
journal={Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
year={2008},
pages={2172-2176},
doi={10.1109/ICSMC.2008.4811614},
art_number={4811614},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-69949118418&doi=10.1109%2fICSMC.2008.4811614&partnerID=40&md5=3b4ad077540ef8a4b438bc506b4191fd},
abstract={This paper introduces an early stage of a smart toy development project which combines several techniques to achieve a level of conversational skills and knowledge higher than currently available robots for children. We describe our ideas and achievements for three modules which we treat as the most important - topic unlimited talking engine, emotions recognizer and the moral behavior analyzer. We will also mention our novel evaluation method for freely speaking agents and possibilities of adding another module - an automatic joke generator. © 2008 IEEE.},
author_keywords={Affect analysis;  Common sense;  Intelligent systems;  Machine ethics},
keywords={Affect analysis;  Common sense;  Development project;  Evaluation Method;  Machine ethics, Control theory;  Intelligent systems, Cybernetics},
references={http://www.kyosho.com/jpn/products/robot/pf01/pf01.html; http://www.kyosho.com/jpn/products/robot/at01/at01.html; http://www.business-design.co.jp; P. D. Turney. Thumbs up? thumbs down? semantic orientation applied to unsupervised classification of reviews. Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL'02), Philadelphia, Pennsylvania, USA. July 8-10, pp. 417-424, 2002; Samsonovich, A.V., Ascoli, G.A., Morowitz, H., Kalbfleisch, M.L., A Scientific Perspective on the Hard Problem of Consciousness (2008) Proceedings of AGI-08 Workshop on the Sociocultural, Ethical and Futurological Implications of Artificial General Intelligence, , Memphis, TN, March; Ptaszynski, M., Dybala, P., Rzepka, R., Araki, K., Double Standpoint Evaluation Method for Affect Analysis Systems (2008) CD-ROM Proceedings of The 22nd Annual Conference of the Japanese Society for Artificial Intelligence; Ptaszynski, M., Dybala, P., Rzepka, R., Araki, K., Effective Analysis of Emotiveness in Utterances based on Features of Lexical and Non-Lexical Layer of Speech (2008) Proceeedings of the NLP'08 Conference, pp. 170-174. , Tokyo, March; Tsuchiya, S., Yoshimura, E., Watabe, H., Kawaoka, T., (2007) The Method of the Emotion Judgement Based on an Association Mechanism Journal of Natural Language Processing, 14 (3). , The Association for Natural Language Processing; Ge, Y., Rzepka, R., Araki, K., Automatic scripts retrieval and its possibilities for soft science support applications (2005) Proceedings of Intelligent Information Systems 2005 - New Trends in Intelligent Information Processing and Web Mining Springer's Advances in Soft Computing, pp. 51-58. , Gdansk; Bentham, J., (1789) An Introduction to the Principles and Morals of Legislation, , London: T. Payne; Rzepka, R., Araki, K., Tochinai, K., Is it out there? the perspectives of emotional information retrieval from the internet resources (2003) Proceedings of the Artificial Intelligence and Applications Conference, pp. 22-27. , Malaga; R. Rzepka, K. Araki, K. Tochinai. Ideas for the web-based affective processing Proceedings of the Seventh Multi-Conference on Systemics, Cybernetics and Informatics, XIV of Computer Science, 376-381, Orlando, Florida, 2005; Higuchi, S., Rzepka, R., Araki, K., (2008) Dialog System Using Modality and Associations Retrieved From The Web, pp. 175-178. , in Japanese Proceeedings of the NLP'08 Conference, pp, Tokyo, March; C. E. Shannon. A mathematical theory of communication Bell System Technical Journal, 27, pp. 379-423 and 623-656, July and October, 1948; Picard, R.W., (1997) Affective Computing, , The MIT Press, Cambridge; Nakamura, H., (2004) Kanjo Hyogen Jiten - Dictionary of Emotive Expressions, , Tokyodo Publishing, Tokyo; Hasegawa, D., Rzepka, R., Araki, K., Evaluation of Connectives Acquisition in a Humanoid Robot Using Direct Physical Feedback (2007) Lecture Notes in Artificial Intelligence (LNAI, 4830, pp. 664-668. , Springer-Verlag, Berlin-Heidelberg; Ptaszynski, M., Sayama, K., The idea of dynamic memory management system based on a forgetting-recalling algorithm with emotive analysis (2007) Language Acquisition and Understanding (LAU) Technical Report, pp. 12-16. , Sapporo; Russel, J.A., A circumplex model of affect (1980) Journal of Personality and Social Psychology, 39 (6), pp. 1161-1178; Morkes, J., Kernal, H.K., Nass, C., Effects of humor in task-oriented human-computer interaction and computer-mediated communication: A direct test of srct theory (1999) Human-Computer Interaction, 14 (4), pp. 395-435; Binsted, K., Using humour to make natural language interfaces more friendly (1995) Proceedings of the AI, ALife and Entertainment Workshop, Intern. Joint Conf. on Artificial Intelligence; Sjobergh, J., Araki, K., Robots Make Things Funnier (2008) Proceedings of LIBM'08, pp. 46-51; Dybala, P., Rzepka, R., Arak, K., Dajare Generating Support Tool - Towards Applicable Linguistic Humor Processing (2008) Proceeedings of the NLP'08 Conference, pp. 701-704. , Tokyo, March; R. Rzepka and K. Araki. Consciousness of Crowds - The Internet As a Knowledge Source of Human's Conscious Behavior and Machine Self-Understanding AI and Consciousness: Theoretical Foundations and Current Approaches, Papers from AAAI Fall Symposium, Technical Report, pp. 127-128, Arlington, USA, November, 2007; Schank, R., Abelson, R., (1977) Scripts, Plans, Goals, and Understanding, , Hillsdale, NJ: Erl-baum; Kopp, S., Gesellensetter, L., Kramer, N., Wachsmuth, I., A Conversational Agent as Museum Guide-Design and Evaluation of a Real-World Application LNAI, 3661, pp. 329-343. , Panayiotopoulos et al, Eds, Intelligent Virtual Agents; Gustafson, J., Bell, L., Speech technology on trial: Experiences from the August system (2000) Natural Language Engineering, 1 (1), pp. 1-15},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{StorrsHall2008460,
author={Storrs Hall, J.},
title={Engineering utopia},
journal={Frontiers in Artificial Intelligence and Applications},
year={2008},
volume={171},
number={1},
pages={460-467},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875916249&partnerID=40&md5=cfeb4c8437025c3113521deae0d42177},
abstract={The likely advent of AGI and the long-established trend of improving computational hardware promise a dual revolution in coming decades: machines which are both more intelligent and more numerous than human beings. This possibility raises substantial concern over the moral nature of such intelligent machines, and of the changes they will cause in society. Will we have the chance to determine their moral character, or will evolutionary processes and/or runaway self-improvement take the choices out of our hands?. © 2008 The authors and IOS Press. All rights reserved.},
author_keywords={hard takeoff;  machine ethics;  self-improving AI;  Singularity},
keywords={Evolutionary process;  Hard takeoffs;  Human being;  Intelligent machine;  Singularity, Artificial intelligence},
references={Drexler, K., ERIC (1992) Nanosystems: Molecular Machinery, Manufacturing, and Computation, , Wiley; Kurzweil, R.A.Y., (2005) The Singularity Is Near, , Viking; Moravec, H.A.N.S., (1999) Robot: Mere Machine to Transcendent Mind, , Oxford; Hall, J.S., Nanofuture: What's next for nanotechnology (2005) Prometheus; Hall, J.S., Beyond AI: Creating the conscience of the machine (2007) Prometheus; Finlayson, C., (2004) Neanderthals and Modern Humans: An Ecological and Evolutionary Perspective, , Cambridge; Yudkowski, E., (2003) Creating Friendly AI, , http://www.singinst.org/CFAI/index.html; Hanson, R., (1998) Economic Growth Given Machine Intelligence, , http://hanson.gmu.edu/aigrow.pdf; Axelrod, R., (1984) The Evolution of Cooperation, , Basic Books; Smith, A., (1790) The Theory of Moral Sentiments, , A. Millar; Nadeau, J.E., Only androids can be ethical (2006) Thinking about Android Epistemology, pp. 241-248. , K. FORD C. GLYMOUR, AND P. HAYES, eds. AAAI/MIT},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Gunkel2007165,
author={Gunkel, D.J.},
title={Thinking otherwise: Ethics, technology and other subjects},
journal={Ethics and Information Technology},
year={2007},
volume={9},
number={3},
pages={165-177},
doi={10.1007/s10676-007-9137-3},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-36949031707&doi=10.1007%2fs10676-007-9137-3&partnerID=40&md5=2b6a699f1e0a137d7c6ffb9d851875ad},
abstract={Ethics is ordinarily understood as being concerned with questions of responsibility for and in the face of an other. This other is more often than not conceived of as another human being and, as such, necessarily excludes others - most notably animals and machines. This essay examines the ethics of such exclusivity. It is divided into three parts. The first part investigates the exclusive anthropocentrism of traditional forms of moral thinking and, following the example of recent innovations in animal rights philosophy, questions the mechanisms of such exclusion. Although recent work in animal- and bio-ethics has successfully implemented strategies for the inclusion of the animal as a legitimate subject of moral consideration, its other, the machine, has remained conspicuously excluded. The second part looks at recent attempts to include these machinic others in moral thinking and critiques the assumptions, values, and strategies that have been employed by these various innovations. And the third part proposes a means for thinking otherwise. That is, it introduces an alternative way to consider these other forms of otherness that is not simply reducible to the conceptual order that has structured and limited moral philosophy's own concern with and for others. © Springer Science+Business Media B.V. 2007.},
author_keywords={Computer ethics;  Computers-social aspects;  Emmanuel Levinas;  Machine ethics;  Otherness;  Philosophy of technology},
keywords={Computer ethics;  Computers-social aspects;  Emmanuel Levinas;  Otherness;  Philosophy of technology, Animals;  Ontology;  Social aspects, Philosophical aspects},
references={Agamben, G., (2004) The Open: Man and Animal, , Stanford University Press, Stanford, CA; Anderson, S.L., Asimov's 'Three Laws of Robotics' and Machine Metaethics (2007) AI and Society, 3. , http://www.springerlink.com/content/771k1181268772p1, Preprint available at; Anderson, M., Anderson, S.L., The Status of Machine Ethics: A Report from the AAAI Symposium (2007) Mind and Machines, 17, pp. 1-10. , http://www.springerlink.com/content/e502572456857542, Preprint available at; Anderson, M., Anderson, S.L., Armen, C., Toward Machine Ethics (2004) American Association for Artificial Intelligence - The Nineteenth National Conference on Artificial Intelligence, pp. 25-29. , July San Jose, CA; Asimov, I., (1991) Robot, , Bantam Books, New York; Derrida, J., (1978) Writing and Difference, p. 260. , (trans. Alan Bass) University of Chicago Press, Chicago; Derrida, J., And Say the Animal Responded (2003) Zoontologies: The Question of the Animal, p. 121. , In (trans. David Willis) C. Wolfe, editor University of Minnesota Press, Minneapolis, MN; Descartes, R., Discourse on Method (1988) Descartes: Selected Philosophical Writings, p. 44. , In (trans. and editors J. Cottingham, R. Stoothoff and D. Murdoch) Cambridge University Press, Cambridge; Fidler, R.F., (1997) Mediamorphosis: Understanding New Media, , Pine Forge Press, Thousand Oaks, CA; Floridi, L., Information Ethics: On the Philosophical Foundation of Computer Ethics (1999) Ethics and Information Technology, 1 (1), p. 41; Floridi, L., Information Ethics, its Nature and Scope (2006) Moral Philosophy and Information Technology, p. 7. , http://www.wolfson.ox.ac.uk/floridi/papers.htm, In J. van den Hoven and J. Weckert, editors Cambridge University Press, Cambridge Preprint available at; Habermas, J., The Inclusion of the Other: Studies in Political Theory (1998), p. 40. , (trans. Ciaran Cronin et al.) MIT Press, Cambridge, MA; Hall, J.S., Ethics for Machines (2001) KurzweilAI.net, , http://www.kurzweilai.net/articles/art0218.html, (5 July); Haraway, D., Simian (1991) Cyborgs and Women: The Reinvention of Nature, pp. 151-152. , Routledge, New York; Heidegger, M., (1983) Die Grundbegriffe Der Metaphysik: Welt - Endlichkeit - Einsamkeit, , V. Klostermann, Frankfurt am Main; Himma, K.E., There's Something About Mary: The Moral Value of Things qua Information Objects (2004) Ethics and Information Technology, 6 (3), p. 145; (1998) Composing Cyberspace: Identity, Community, and Knowledge in the Electronic Age, , R. Holeton (ed.) McGraw Hill, New York; Johnson, B., Translator's Introduction (1981) Disseminations, p. 15. , In: J. Derrida (ed.) University of Chicago Press, Chicago; Kant, I., (1985) Critique of Practical Reason, p. 17. , (trans. Lewis W. Beck) Macmillan, New York; (1997) Culture of the Internet, , S. Kiesler (ed.) Lawrence Erlbaum Associates, Mahwah, NJ; Krell, D.F., (1992) Daimon Life: Heidegger and Life Philosophy, , Indiana University Press, Bloomington, IN; Levinas, E., (1969) Totality and Infinity, , (trans. Alphonso Lingis). Duquesne University Press, Pittsburgh, PA; Levinas, E., (1981) Otherwise Than Being or Beyond Essence, , (trans. Alphonso Lingis). Martinus Nijhoff Publishers, The Hague; Levinas, E., (1987) Collected Philosophical Papers, pp. 54-55. , (trans. Alphonso Lingis) Martinus Nijhoff Publishers, Dordrecht; Lyotard, J.-F., (1991) The Inhuman: Reflections on Time, p. 1. , (trans. Geoffrey Bennington and Rachel Bowlby) Stanford University Press, Stanford, CA; Mitchell, W.J., (1995) City of Bits: Space, Place, and the Infobahn, , MIT Press, Cambridge; Nealon, J.T., (1998) Alterity Politics: Ethics and Performative Subjectivity, p. 71. , Duke University Press, Durham, NC; Ratliff, E., The Crusade Against Evolution (2004) Wired, 12 (10), pp. 156-161; Regan, T., (1999) Animal Others: On Ethics, Ontology, and Animal Life, p. 12. , In P. Steeves, editor State University of New York Press, Albany, NY; Saco, D., (2002) Cybering Democracy: Public Space and the Internet, , University of Minnesota Press, Minneapolis, MN; Sparrow, R., The Turing Triage Test (2004) Ethics and Information Technology, 6 (4), p. 203; Steiner, P., (1993) Dog Cartoon, 61. , The New Yorker 5 July; Stone, A.R., (1995) The War of Desire and Technology at the Close of the Mechanical Age, , MIT Press, Cambridge, MA; Turkle, S., (1995) Life on the Screen: Identity in the Age of the Internet, , Simon & Schuster, New York; Warwick, K., Cyborg Morals, Cyborg Values, Cyborg Ethics (2003) Ethics and Information Technology, 5 (3); (2003) Zoontologies: The Question of the Animal, pp. 10-11. , C., Wolfe editor. University of Minnesota Press, Minneapolis, MN; Žižek, S., (1997) The Plague of the Fantasies, p. 161. , Verso, New York},
document_type={Article},
source={Scopus},
}

@ARTICLE{Watts20191022,
author={Watts, G.},
title={RELIGION, SCIENCE, AND DISENCHANTMENT IN LATE MODERNITY: with Fraser Watts, “Mutual Enhancement between Science and Religion: In the Footsteps of the Epiphany Philosophers”; William H. Beharrell, “Transformation and the Waking Body: A Return to Truth via Our Bodies”; Marius Dorobantu and Yorick Wilks, “Moral Orthoses: A New Approach to Human and Machine Ethics”; Galen Watts, “Religion, Science, and Disenchantment in Late Modernity”; and Rowan Williams, “Epiphany Philosophers: Afterword.”},
journal={Zygon},
year={2019},
volume={54},
number={4},
pages={1022-1035},
doi={10.1111/zygo.12554},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075067076&doi=10.1111%2fzygo.12554&partnerID=40&md5=2630a7c165d4d0b43ce2fb825ecb31e6},
abstract={Late modernity has witnessed a growing semantic shift from “religion” to “spirituality.” In this article, I argue what underlies this shift is a cultural structure I call the religion of the heart. I begin with an explication of what I mean by the “religion of the heart,” and draw on the work of Ernst Troeltsch and Colin Campbell to identify what I take to be its historical antecedents. Second, I analyze the ambiguous relationships fostered between the religion of the heart and the discourses of science and religion, respectively, in late modernity. I illuminate how the social conditions of late modernity undermine or challenge what we conventionally think of as scientific and religious authorities, while at the same time creating existential needs that the religion of the heart is well adapted to meet. I conclude with a brief discussion of the implications of this process, especially as it relates to the sustainability of science and religion, as independent enterprises, in the twenty-first century. © 2019 by the Joint Publication Board of Zygon},
author_keywords={Colin Campbell;  disenchantment;  Ernst Troeltsch;  late modernity;  spirituality},
references={Ammerman, N.T., (2014) Sacred Stories, Spiritual Tribes: Finding Religion in Everyday Life, , Oxford, UK, Oxford University Press; Berger, P., (1967) The Sacred Canopy: Elements of a Sociological Theory of Religion, , New York, NY, Integrated Media; Berger, P., (1979) The Heretical Imperative: Contemporary Possibilities of Religious Affirmation, , New York, NY, Anchor Press; Berger, P., (1999) The Desecularization of the World: Resurgent Religion and World Politics, , Washington, DC, Ethics and Public Policy Center; Brown, C., (2009) The Death of Christian Britain, , London, UK, Routledge; Bruce, S., (2017) The Secular Beats the Spiritual: The Westernization of the Easternization of the West, , Oxford, UK, Oxford University Press; Campbell, C., The Secret Religion of the Educated Classes (1978) Sociological Analysis, 39, pp. 146-156; Campbell, C., (2007) The Easternization of the West: A Thematic Account of Cultural Change in the Modern Era, , Boulder, CO, Paradigm Publishers; Campbell, T.A., (1991) The Religion of the Heart: A Study of European Religious Life in the Seventeenth and Eighteenth Centuries, , Eugene, OR, Wipf and Stock; Casanova, J., (1994) Public Religions in the Modern World, , Chicago, IL, University of Chicago Press; Chopra, D., (1994) The Seven Spiritual Laws of Success: A Practical Guide to Fulfilling Your Dreams, , San Rafael, CA, Amber-Allen Publishing; Coffey, J., Introduction: Sources and Trajectories of Evangelical Piety (2016) Heart Religion: Evangelical Piety in England and Ireland, 1690–1850, pp. 1-28. , edited by, John Coffey, Oxford, UK, Oxford University Press; Davies, G., (2007) The Sociology of Religion, , London, UK, Sage; Fuller, R.C., (2001) Spiritual but Not Religious, , New York, NY, Oxford University Press; Hanegraaff, W.J., (1996) New Age Religion and Western Culture: Esotericism in the Mirror of Secular Thought, , New York, NY, Brill; Heelas, P., (1996) The New Age Movement: The Celebration of the Self and the Sacralization of Modernity, , Oxford, UK, Blackwell; Heelas, P., (2008) Spiritualities of Life: New Age Romanticism and Consumptive Capitalism, , Malden, MA, Blackwell; Heelas, P., Woodhead, L., (2005) The Spiritual Revolution: Why Religion Is Giving Way to Spirituality, , Malden, MA, Blackwell; Hicks, E., Hicks, J., (2004) Ask and It Is Given: Learning to Manifest Your Desires, , New York, NY, Hay House; Houtman, D., Aupers, S., (2010) Religions of Modernity: Relocating the Sacred to the Self and the Digital, pp. 1-30. , edited by Stef Aupers,, Danvers, MA, Brill; Lofton, K., (2011) Oprah: The Gospel of an Icon, , Berkeley, University of California Press; Josephson-Storm, J.A., (2017) The Myth of Disenchantment: Magic, Modernity, and the Birth of the Human Sciences, , Chicago, IL, University of Chicago Press; McLeod, H., (2007) The Religious Crisis of the 1960s, , Oxford, UK, Oxford University Press; Olsteen, J., (2004) Your Best Life Now: 7 Steps to Living at Your Full Potential, , New York, NY, Hachette Book Group; Peale, N.V., (1952) The Power of Positive Thinking, , Westwood, NJ, Spire Books; Robbins, T., (1991) Awaken the Giant Within, , New York, NY, Simon & Schuster; Rogers, C., (1961) On Becoming a Person, , Boston, MA, Houghton Mifflin; Schmidt, L.E., (2012) Restless Souls: The Making of American Spirituality, , Berkeley, University of California Press; Sharma, R., (1997) The Monk Who Sold His Ferrari: A Remarkable Story about Living Your Dreams, , Toronto, Canada, HarperCollins; Taylor, C., (1989) Sources of the Self: The Making of the Modern Identity, , Cambridge, MA, Harvard University Press; Taylor, C., (1991) The Ethics of Authenticity, , Cambridge, MA, Harvard University Press; Troeltsch, E., (1912) The Social Teachings of the Christian Churches Volume II, (1992). , translated by Olive Wyon, Louisville, KY, Westminster/John Knox Press; Watts, G., Missing the Forest for the Trees: ‘Spiritual’ Religion in a Secular Age (2018) Toronto Journal of Theology, 34, pp. 243-256; Watts, G., On the Politics of Self-Spirituality: A Canadian Case Study (2018) Studies in Religion, 47, pp. 345-372; Williams, R., (2018) Being Human, , London, UK, Society for Supporting Christian Knowledge},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Jackson2019401,
author={Jackson, R.B. and Williams, T.},
title={Language-Capable Robots may Inadvertently Weaken Human Moral Norms},
journal={ACM/IEEE International Conference on Human-Robot Interaction},
year={2019},
volume={2019-March},
pages={401-410},
doi={10.1109/HRI.2019.8673123},
art_number={8673123},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064006526&doi=10.1109%2fHRI.2019.8673123&partnerID=40&md5=069198ebc93c1379801846db8af66532},
abstract={Previous research in moral psychology and human-robot interaction has shown that technology shapes human morality, and research in human-robot interaction has shown that humans naturally perceive robots as moral agents. Accordingly, we propose that language-capable autonomous robots are uniquely positioned among technologies to significantly impact human morality. We therefore argue that it is imperative that language-capable robots behave according to human moral norms and communicate in such a way that their intention to adhere to those norms is clear. Unfortunately, the design of current natural language oriented robot architectures enables certain architectural components to circumvent or preempt those architectures' moral reasoning capabilities. In this paper, we show how this may occur, using clarification request generation in current dialog systems as a motivating example. Furthermore, we present experimental evidence that the types of behavior exhibited by current approaches to clarification request generation can cause robots to (1) miscommunicate their moral intentions and (2) weaken humans' perceptions of moral norms within the current context. This work strengthens previous preliminary findings, and does so within an experimental paradigm that provides increased external and ecological validity over earlier approaches. © 2019 IEEE.},
author_keywords={Human-Robot Interaction;  Natural Language Generation;  Robot Ethics},
keywords={Architecture;  Clarifiers;  Machine design;  Man machine systems;  Natural language processing systems, Architectural components;  Ecological validity;  Experimental evidence;  Moral reasoning;  Natural language generation;  Natural languages;  Robot architecture;  Robot ethics, Human robot interaction},
references={Scheutz, M., Schermerhorn, P., Kramer, J., Anderson, D., First steps toward natural human-like HRI (2007) Autonomous Robots, 22 (4), pp. 411-423. , May; Mavridis, N., A review of verbal and non-verbal human-robot interactive communication (2015) Robotics and Autonomous Systems, 63, pp. 22-35; Matuszek, C., Grounded language learning: Where robotics and nlp meet (2018) Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), pp. 5687-5691; Grice, P., Logic and conversation (1975) Syntax and Semantics; Levinson, S.C., (2000) Presumptive Meanings: The Theory of Generalized Conversational Implicature, , MIT press; Bach, K., The top 10 misconceptions about implicature (2006) Drawing the Boundaries of Meaning: Neo-Gricean Studies in Pragmatics and Semantics in Honor of Laurence R. Horn, pp. 21-30; Williams, T., Briggs, G., Oosterveld, B., Scheutz, M., Going beyond command-based instructions: Extending robotic natural language interaction capabilities (2015) Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence; Trott, S., Eppe, M., Feldman, J., Recognizing intention from natural language: Clarification dialog and construction grammar (2016) Workshop on Communicating Intentions in Human-Robot Interaction; Knepper, R.A., On the communicative aspect of human-robot joint action (2016) The IEEE International Symposium on Robot and Human Interactive Communication Workshop: Toward A Framework for Joint Action, What about Common Ground; Benotti, L., Blackburn, P., Polite interactions with robots (2016) What Social Robots Can and Should Do: Proceedings of Robophilosophy 2016/TRANSOR 2016, 290, p. 293; Briggs, G., Williams, T., Scheutz, M., Enabling robots to understand indirect speech acts in task-based interactions (2017) Journal of Human-Robot Interaction (JHRI); Gervits, F., Briggs, G., Scheutz, M., The pragmatic parliament: A framework for socially-appropriate utterance selection in artificial agents (2017) Proceedings of the Annual Meeting of the Cognitive Science Society (COGSCI); Fried, D., Andreas, J., Klein, D., (2017) Unified Pragmatic Models for Generating and Following Instructions, , arXiv preprint arXiv:1711. 04987; Trott, S., Bergen, B., A theoretical model of indirect request comprehension (2017) Proceedings of the AAAI Fall Symposium Series on Artificial Intelligence for Human-Robot Interaction (AI-HRI); Williams, T., Thames, D., Novakoff, J., Scheutz, M., Thank you for sharing that interesting fact! : Effects of capability and context on indirect speech act use in task-based human-robot dialogue (2018) Proceedings of the 13th ACM/IEEE International Conference on Human-Robot Interaction (HRI); Arkin, R.C., Governing lethal behavior: Embedding ethics in a hybrid deliberative/reactive robot architecture (2008) Proceedings of the 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI), pp. 121-128; Scheutz, M., The need for moral competency in autonomous agent architectures (2016) Fundamental Issues of Artificial Intelligence, pp. 515-525. , Springer; De Graaf, M.M., Allouch, S.B., Klamer, T., Sharing a life with harvey: Exploring the acceptance of and relationship-building with a social robot (2015) Computers in Human Behavior, 43, pp. 1-14; Wada, K., Shibata, T., Living with seal robots-its sociopsychological and physiological influences on the elderly at a care house (2007) IEEE Transactions on Robotics, 23 (5), pp. 972-980; Sharkey, N., Sharkey, A., The crying shame of robot nannies: An ethical appraisal (2010) Interaction Studies, 11 (2), pp. 161-190; Wen, J., Stewart, A., Billinghurst, M., Dey, A., Tossell, C., Finomore, V., He who hesitates is lost (. in thoughts over a robot) (2018) Proceedings of the Technology, Mind, and Society, Ser. TechMindSociety '18, pp. 431-436. , http://doi.acm.org/10.1145/3183654.3183703, New York, NY, USA: ACM; Lin, P., Bekey, G., Abney, K., (2008) Autonomous Military Robotics: Risk, Ethics, and Design, , Cal. Poly. State Univ. San Luis Obispo, Tech. Rep; Scassellati, B., Admoni, H., Mataric, M., Robots for use in autism research (2012) Annual Review of Biomedical Engineering, 14, pp. 275-294; Briggs, G., Scheutz, M., How robots can affect human behavior: Investigating the effects of robotic displays of protest and distress (2014) International Journal of Social Robotics; Kahn, P.H., Kanda, T., Ishiguro, H., Gill, B.T., Ruckert, J.H., Shen, S., Gary, H., Severson, R.L., Do people hold a humanoid robot morally accountable for the harm it causes? (2012) Proceedings of the 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI), pp. 33-40. , Boston, MA; Malle, B.F., Scheutz, M., Arnold, T., Voiklis, J., Cusimano, C., Sacrifice one for the good of many?: People apply different moral norms to human and robot agents (2015) Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction, pp. 117-124. , Portland, OR; Simmons, R., Makatchev, M., Kirby, R., Lee, M.K., Believable robot characters (2011) AI Magazine, (4); Gino, F., Understanding ordinary unethical behavior: Why people who value morality act immorally (2015) Current Opinion in Behavioral Sciences, 3, pp. 107-111; Verbeek, P.-P., (2011) Moralizing Technology: Understanding and Designing the Morality of Things, , University of Chicago Press; Kennedy, J., Baxter, P., Belpaeme, T., Children comply with a robot's indirect requests (2014) Proceedings of HRI, pp. 198-199. , Bielefeld, Germany: ACM; Eyssel, F., Kuchenbrandt, D., Social categorization of social robots: Anthropomorphism as a function of robot group membership (2012) British Journal of Social Psychology, (4); Williams, T., Jackson, R.B., Lockshin, J., A Bayesian analysis of moral norm malleability during clarification dialogues (2018) Proceedings of the Annual Meeting of the Cognitive Science Society (COGSCI), , Madison, WI: Cognitive Science Society; Jackson, R.B., Williams, T., Robot: Asker of questions and changer of norms? (2018) Proceedings of the International Conference on Robot Ethics and Standards (ICRES), , Troy, NY: CLAWAR Association; Purver, M.R.J., (2004) The Theory and Use of Clarification Requests in Dialogue, , Ph. D. dissertation, University of London; Bohus, D., Rudnicky, A.I., Sorry, i didn't catch that!-an investigation of non-understanding errors and recovery strategies (2005) 6th SIGdial Workshop on Discourse and Dialogue; Marge, M., Rudnicky, A.I., Miscommunication recovery in physically situated dialogue (2015) Proceedings of the 16th Annual SIGdial Meeting on Discourse and Dialogue, pp. 22-49. , Saarbrücken, Germany; Tellex, S., Thaker, P., Deits, R., Simeonov, D., Kollar, T., Roy, N., Toward information theoretic human-robot dialog (2013) Robotics: Science and Systems, 32, pp. 409-417; Williams, T., Scheutz, M., Resolution of referential ambiguity in human-robot dialogue using dempster-shafer theoretic pragmatics (2017) Proceedings of Robotics: Science and Systems (RSS), , Cambridge, MA; Williams, T., Yazdani, F., Suresh, P., Scheutz, M., Beetz, M., Dempster-shafer theoretic resolution of referential ambiguity (2018) Autonomous Robots; Scheutz, M., Briggs, G., Cantrell, R., Krause, E., Williams, T., Veale, R., Novel mechanisms for natural human-robot interactions in the diarc architecture (2013) Proceedings of AAAI Workshop on Intelligent Robotic Systems; Scheutz, M., Williams, T., Krause, E., Oosterveld, B., Sarathy, V., Frasca, T., An overview of the distributed integrated cognition affect and reflection diarc architecture (2018) Cognitive Architectures, , M. I. A. Ferreira, J. Sequeira, and R. Ventura, Eds., (in press); Scheutz, M., Malle, B., Briggs, G., Towards morally sensitive action selection for autonomous social robots (2015) Proc. of RO-MAN; Nass, C., Steuer, J., Tauber, E.R., Computers are social actors (1994) Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, pp. 72-78; Gureckis, T., Martin, J., McDonnell, J., Psiturk: An open-source framework for conducting replicable behavioral experiments online (2016) Behavior Research Methods, 48 (3), pp. 829-842; Buhrmester, M., Kwang, T., Gosling, S.D., Amazon's mechanical turk: A new source of inexpensive, yet high-quality, data? (2011) Perspectives on Psychological Science, 6 (1), pp. 3-5; Crump, M.J., McDonnell, J.V., Gureckis, T.M., Evaluating amazon's mechanical turk as a tool for experimental behavioral research (2013) PloS One, 8 (3); Stewart, N., Chandler, J., Paolacci, G., Crowdsourcing samples in cognitive science (2017) Trends in Cognitive Sciences; Bainbridge, W., Hart, J., Kim, E., Scassellati, B., The benefits of interactions with physically present robots over video-displayed agents (2011) International Journal of Social Robotics, 3 (1), pp. 41-52; Fischer, K., Lohan, K., Foth, K., Levels of embodiment: Linguistic analyses of factors influencing HRI (2012) Proceedings of the 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI), pp. 463-470. , Boston, MA; Li, J., The benefit of being physically present: A survey of experimental works comparing copresent robots, telepresent robots and virtual agents (2015) International Journal of Human-Computer Studies, 77, pp. 23-37; Tanaka, K., Nakanishi, H., Ishiguro, H., Comparing video, avatar, and robot mediated communication: Pros and cons of embodiment (2014) Proceedings of the International Conference on Collaboration Technologies (ICCT), pp. 96-110. , Minneapolis, MN: Springer; Jasp (2016) Version 0. 8. 0. 0. Software, , JASP Team et al; Jarosz, A.F., Wiley, J., What are the odds? A practical guide to computing and reporting bayes factors (2014) The Journal of Problem Solving, 7; Berger, J.O., Sellke, T., Testing a point null hypothesis: The irreconcilability of p-values and evidence (1987) Journal of the American Statistical Association (ASA), 82 (397); Simmons, J.P., Nelson, L.D., Simonsohn, U., False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant (2011) Psychological Science, (11); Sterne, J.A., Smith, G.D., Sifting the evidence-what's wrong with significance tests? (2001) Physical Therapy, 81 (8), pp. 1464-1469; Wagenmakers, E.-J., A practical solution to the pervasive problems of p values (2007) Psychonomic Bulletin and Review, 14 (5), pp. 779-804; Verhagen, J., Wagenmakers, E.-J., Bayesian tests to quantify the result of a replication attempt (2014) Journal of Experimental Psychology: General, 143 (4), pp. 1457-1475; Ly, A., Etz, A., Marsman, M., Wagenmakers, E.-J., Replication bayes factors from evidence updating (2018) Behavior Research Methods, Aug, , https://doi.org/10.3758/s13428-018-1092-x; Wright, D., Comparing groups in a before-after design: When t test and ancova produce different results (2006) The British Journal of Educational Psychology, 76 (10), pp. 663-675; Dimitrov, D., Rumrill, P.D., Pretest-posttest designs and measurement of change (2003) Work (Reading, Mass.), 20 (2), pp. 159-165; Huck, S., McLean, R.A., Using a repeated measures anova to analyze the data from a pretest-posttest design: A potentially confusing task (1975) Psychological Bulletin, 82 (7), pp. 511-518; Jeffreys, H., (1961) Theory of Probability, , Clarendon Press, Oxford; Cohen, J., (1988) Statistical Power Analysis for the Behavioral Sciences, , Lawrence Erlbaum Associates; Edwards, W., Lindman, H., Savage, L.J., Bayesian statistical inference for psychological research (1963) Psychological Review, 70, pp. 193-242; Freedy, A., DeVisser, E., Weltman, G., Coeyman, N., Measurement of trust in human-robot collaboration (2007) Proceedings of the Symposium on Collaborative Technologies and Systems, pp. 106-114; Nomura, T., Uratani, T., Kanda, T., Matsumoto, K., Kidokoro, H., Suehiro, Y., Yamada, S., Why do children abuse robots? (2015) Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts, Ser. HRI'15 Extended Abstracts, pp. 63-64. , http://doi.acm.org/10.1145/2701973.2701977, New York, NY, USA: ACM; Briggs, G., Scheutz, M., Sorry, i can't do that : Developing mechanisms to appropriately reject directives in human-robot interactions (2015) Proceedings of the AAAI Fall Symposium Series; Jung, M.F., Martelaro, N., Hinds, P.J., Using robots to moderate team conflict: The case of repairing violations (2015) Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI). ACM, pp. 229-236},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{BlakeJackson2019499,
author={Blake Jackson, R. and Wen, R. and Williams, T.},
title={TACT in noncompliance: The need for pragmatically APT responses to unethical commands},
journal={AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
year={2019},
pages={499-505},
doi={10.1145/3306618.3314241},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070622582&doi=10.1145%2f3306618.3314241&partnerID=40&md5=46bb05f67562d516a133ded7325395c1},
abstract={There is a significant body of research seeking to enable moral decision making and ensure moral conduct in robots. One aspect of moral conduct is rejecting immoral human commands. For social robots, which are expected to follow and maintain human moral and sociocultural norms, it is especially important not only to engage in moral decision making, but also to properly communicate moral reasoning. We thus argue that it is critical for robots to carefully phrase command rejections. Specifically, the degree of politeness-theoretic face threat in a command rejection should be proportional to the severity of the norm violation motivating that rejection. We present a human subjects experiment showing some of the consequences of miscalibrated responses, including perceptions of the robot as inappropriately polite, direct, or harsh, and reduced robot likeability. This experiment intends to motivate and inform the design of algorithms to tactfully tune pragmatic aspects of command rejections autonomously. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
author_keywords={Human-robot interac-;  Natural language generation;  Robot ethics},
keywords={Behavioral research;  Decision making;  Natural language processing systems;  Philosophical aspects, Design of algorithms;  Human robots;  Human subjects;  Moral reasoning;  Natural language generation;  Norm violation;  Robot ethics;  Social robots, Robots},
references={Arkin, R.C., Governing lethal behavior: Embedding ethics in a hybrid deliberative/reactive robot architecture (2008) Proceedings of HRI, pp. 121-128; Bainbridge, W., Hart, J., Kim, E., Scassellati, B., The benefits of interactions with physically present robots over video-displayed agents (2011) Social Robotics, 3 (1), pp. 41-52. , 2011; Bartneck, C., Kulić, D., Croft, E., Zoghbi, S., Measurement instruments for the anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety of robots (2009) Social Robotics, 1 (1), pp. 71-81. , 2009; Briggs, G., Scheutz, M., How robots can affect human behavior: Investigating the effects of robotic displays of protest and distress (2014) Int'L Journal of Social Robotics, , 2014; Briggs, G., Scheutz, M., Sorry, I can't do that”: Developing mechanisms to appropriately reject directives in human-robot interactions (2015) AAAI Fall Symposium Series; Brown, P., Levinson, S., (1987) Politeness: Some Universals in Language Usage, , Cambridge University Press; Buhrmester, M., Kwang, T., Gosling, S.D., Amazon's Mechanical Turk: A new source of inexpensive, yet high-quality, data? (2011) Perspectives on Psychological Science, 6 (1), pp. 3-5. , 2011; Crump, M.J.C., McDonnell, J.V., Gureckis, T.M., Evaluating Amazon's mechanical turk as a tool for experimental behavioral research (2013) PloS One, 8, p. 3. , 2013; De Graaf, M.M., Allouch, S.B., Klamer, T., Sharing a life with Harvey: Exploring the acceptance of and relationship-building with a social robot (2015) Computers in Human Behavior, 43, pp. 1-14. , 2015; Eyssel, F., Kuchenbrandt, D., Social categorization of social robots: Anthropomorphism as a function of robot group membership (2012) British Journal of Social Psychology, 51 (4), pp. 724-731. , 2012; Fischer, K., Lohan, K., Foth, K., Levels of embodiment: Linguistic analyses of factors influencing HRI (2012) Proceedings of HRI, pp. 463-470. , Boston, MA; Gervits, F., Briggs, G., Scheutz, M., The pragmatic parliament: A framework for socially-appropriate utterance selection in artificial agents (2017) COGSCI; Gino, F., Understanding ordinary unethical behavior: Why people who value morality act immorally (2015) Current Opinion in Behavioral Sciences, 3, pp. 107-111. , 2015; Göckeritz, S., Schmidt, M.F.H., Tomasello, M., Young children's creation and transmission of social norms (2014) Cognitive Development, , 2014; Gureckis, T., Martin, J., McDonnell, J., Psiturk: An open-source framework for conducting replicable behavioral experiments online (2016) Behavior Research Methods, 48 (3), pp. 829-842. , 2016; Jackson, R.B., Williams, T., Robot: Asker of questions and changer of norms? (2018) Proceedings of ICRES; Jarosz, A.F., Wiley, J., What are the odds? A practical guide to computing and reporting Bayes factors (2014) The Journal of Problem Solving, 7. , 2014; (2016) Jasp. Version 0.8. 0.0. Software, , 2016; Johnson, D.I., Roloff, M.E., Riffee, M.A., Politeness theory and refusals of requests: Face threat as a function of expressed obstacles (2004) Communication Studies, 55, p. 2. , 2004; Jung, M.F., Martelaro, N., Hinds, P.J., Using robots to moderate team conflict: The case of repairing violations (2015) Proceedings of HRI, pp. 229-236; Kahn, P.H., Kanda, T., Ishiguro, H., Gill, B.T., Ruckert, J.H., Shen, S., Gary, H., Severson, R.L., Do people hold a humanoid robot morally accountable for the harm it causes? (2012) HRI, pp. 33-40. , Boston, MA; Kennedy, J., Baxter, P., Belpaeme, T., Children comply with a robot's indirect requests (2014) HRI; Li, J., The benefit of being physically present: A survey of experimental works comparing copresent robots, telepresent robots and virtual agents (2015) International Journal of Human-Computer Studies, 77, pp. 23-37. , 2015; Lin, P., Bekey, G., Abney, K., (2008) Autonomous Military Robotics: Risk, Ethics, and Design, , Technical Report. Cal. Poly. State Univ. San Luis Obispo; Malle, B.F., Scheutz, M., Arnold, T., Voiklis, J., Cusimano, C., Sacrifice One for the good of many?: People apply different moral norms to human and robot agents (2015) Proceedings of HRI, pp. 117-124; Nomura, T., Uratani, T., Kanda, T., Matsumoto, K., Kidokoro, H.-R., Suehiro, Y., Yamada, S., Why do children abuse robots? (2015) HRI Extended Abstracts, pp. 63-64; Raman, V., Lignos, C., Finucane, C., Lee, K.C.T., Marcus, M., Kress-Gazit, H., Sorry Dave, I'm afraid I can't do that: Explaining unachievable robot tasks using natural language (2013) Proceedings of RSS; Scassellati, B., Admoni, H., Mataric, M., Robots for use in autism research (2012) Annual Review of Biomedical Engineering, 14, pp. 275-294. , 2012; Sharkey, N., Sharkey, A., The crying shame of robot nannies: An ethical appraisal (2010) Interaction Studies, 11 (2), pp. 161-190. , 2010; Simmons, R., Makatchev, M., Kirby, R., Lee, M.K., Believable robot characters (2011) AI Magazine, 32, p. 4. , 2011; Stewart, N., Chandler, J., Paolacci, G., Crowdsourcing samples in cognitive science (2017) Trends in Cognitive Sciences, , 2017; Tanaka, K., Nakanishi, H., Ishiguro, H., Comparing video, avatar, and robot mediated communication: Pros and cons of embodiment (2014) Proceedings of ICCT, pp. 96-110; Verbeek, P.-P., (2011) Moralizing Technology: Understanding and Designing the Morality of Things, , University of Chicago Press; Wada, K., Shibata, T., Living with seal robots - Its sociopsychological and physiological influences on the elderly at a care house (2007) IEEE Transactions on Robotics, 23 (5), pp. 972-980. , 2007; Wen, J., Stewart, A., Billinghurst, M., Dey, A., Tossell, C., Finomore, V., He who hesitates is lost (...in thoughts over a robot) (2018) Proceedings of TechMindSociety; Williams, T., Jackson, R.B., Lockshin, J., A Bayesian analysis of moral norm malleability during clarification dialogues (2018) Proceedings of COGSCI; Yanco, H.A., Drury, J., Classifying human-robot interaction: An updated taxonomy (2004) IEEE International Conference on Systems, Man and Cybernetics, 3, pp. 2841-2846},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Cristian2019375,
author={Cristian, B. and Klaus, J.C. and Zoltan, E. and Lydia, H.S.M.},
title={Approaches for the planning and implementation of Industry 4.0},
journal={Periodicals of Engineering and Natural Sciences},
year={2019},
volume={7},
number={1},
pages={375-380},
doi={10.21533/pen.v7i1.397},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065831907&doi=10.21533%2fpen.v7i1.397&partnerID=40&md5=c9d065d6af9da194b90eb543617c790e},
abstract={The continuous degree of automation in industry and the networking of individual components such as machines, robots, autonomous drive systems, control units etc. opens new possibilities for linking production and service or, integrating customers and business partners into value-added processes. In this technical revolution, machines should be able to decide independently and even contribute to developments. Before the implementation, planning should be carried out in the planning stage, where Industry 4.0 can be implemented, what should be achieved, how can corresponding plans be implemented, and what aspects of security, machine ethics, information ethics or work ethics must be considered. While answering these questions, it can be found out what resources of material and immaterial nature are needed and what are the advantages and disadvantages that should be expected. © 2019, International University of Sarajevo.},
author_keywords={Automation;  Industry 4.0;  Networking;  Technical revolution},
references={Armbruster, A., (2017) Ich sorge mich um Menschen, die denken wie Maschinen, , FAZ.NET; (2013) "BMW US Manufacturing Company, ", , Spartanburg County, South Carolina; (2015) Referat öffentlichkeitsarbeit: Gemeinsame Plattform Industrie 4.0 startet; Hermann, M., Pentek, T., Otto, B., Design Principles for Industrie 4.0 Scenarios (2016) 49th Hawaii International Conference on System Sciences (HICSS), p. 2016; Hirsch-Kreinsen, H., (2015) Einleitung: Digitalisierung industrieller Arbeit, , Hartmut Hirsch-Kreinsen/Peter Ittermann/Jonathan Niehaus (Hrsg.): Digitalisierung industrieller Arbeit. Die Vision Industrie 4.0 und ihre sozialen Herausforderungen, Baden-Baden; Kagermann, H., Lukas, W.-D., Wahlster, W., "Industrie 4.0: Mit dem Internet der Dinge auf dem Weg zur 4. industriellen Revolution.", , VDI-Nachrichten, April 2011; Merkel, A., Daten sind die Rohstoffe des 21.Jahrhunderts, , FAZ.NET. 2016; Spath, D., Ganschar, O., Gerlach, S., Hämmerle, M., Krause, T., Schlund, S., (2013) Fr aunhofer-Institut für Arbeitswirtschaft und Organisation IAO, , Produktionsarbeit der Zukunft-Industrie 4.0; Vladareanu, L., Curaj, A., Munteanu, R.I., Complex Walking Robot Kinematics Analysis and Plc Multi-Tasking Control (2012) Rev. Roum. Sci. Techn.-électrotechn. et énerg, 57 (1), pp. 90-99; Vladareanu, V., Dumitrache, I., Vladareanu, L., Sacala, I.S., Tont, G., Moisescu, M.A., "Versatile Intelligent Portable Robot Control Platform Based on Cyber Physical Systems Principles," (2015) Studies in Informatics and Control, 24 (4), pp. 409-418; Vladareanu, V., Munteanu, R.I., Mumtaz, A., Smarandache, F., Vladareanu, L., The optimization of intelligent control interfaces using Versatile Intelligent Portable Robot Platform (2015) International Conference on Communications, Management and Information Technology (ICCMIT'2015), Procedia Computer Science, 65, pp. 225-232; Vladareanu, V., Munteanu, R.I., Mumtaz, A., Smarandache, F., Vladareanu, L., (2017), https://www.krollontrack.de/blog/wer-ist-der-eigentuemer-der-daten/6712; Vladareanu, V., Munteanu, R.I., Mumtaz, A., Smarandache, F., Vladareanu, L., (2017) Watson solutions and APIs, , https://www.ibm.com/watson/de-de/loesungen/; Vladareanu, V., Munteanu, R.I., Mumtaz, A., Smarandache, F., Vladareanu, L., (2017), https://de.wikipedia.org/wiki/Webcrawler; Vladareanu, V., Munteanu, R.I., Mumtaz, A., Smarandache, F., Vladareanu, L., (2017), https://www.heise.de/newsticker/meldung/Amazon-Roboter-sollen-auch-in-Deutschland-Ware-zum-Mitarbeiter-bringen-3706026.html; Vladareanu, V., Munteanu, R.I., Mumtaz, A., Smarandache, F., Vladareanu, L., (2017), http://www.airliners.de/kann-flugzeug-antworten-cockpit-15/37085; Vladareanu, V., Munteanu, R.I., Mumtaz, A., Smarandache, F., Vladareanu, L., (2017), http:-/www.sueddeutsche.de/auto/selbsfaren, The Tesla Statement},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Vanderelst2018317,
author={Vanderelst, D. and Winfield, A.},
title={The Dark Side of Ethical Robots},
journal={AIES 2018 - Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
year={2018},
pages={317-322},
doi={10.1145/3278721.3278726},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055332538&doi=10.1145%2f3278721.3278726&partnerID=40&md5=3bd14b548b044fc16a6feae5270e34a9},
abstract={Concerns over the risks associated with advances in Artificial Intelligence have prompted calls for greater efforts toward robust and beneficial AI, including machine ethics. Recently, roboticists have responded by initiating the development of so-called ethical robots. These robots would, ideally, evaluate the consequences of their actions and morally justify their choices. This emerging field promises to develop extensively over the next few years. However, in this paper, we point out an inherent limitation of the emerging field of ethical robots. We show that building ethical robots also inevitably enables the construction of unethical robots. In three experiments, we show that it is remarkably easy to modify an ethical robot so that it behaves competitively, or even aggressively. The reason for this is that the cognitive machinery required to make an ethical robot can always be corrupted to make unethical robots. We discuss the implications of this finding to the governance of ethical robots. We conclude that the risks that unscrupulous actors might compromise a robot's ethics are so great as to raise serious doubts over the wisdom of embedding ethical decision making in real-world safety-critical robots, such as driverless cars. © 2018 ACM.},
author_keywords={cybersecurity;  ethical governance;  ethical robots;  machine ethics;  malicious use},
keywords={Decision making;  Machinery;  Robots;  Safety engineering, Cyber security;  Ethical decision making;  ethical governance;  Inherent limitations;  malicious use;  Real-world, Philosophical aspects},
references={Anderson, M., Anderson, S., Berenz, V., (2017) A Value Driven Agent: Instantiation of A Case-Supported Principle-Based Behavior Paradigm, , https://aaai.org/ocs/index.php/WS/AAAIW17/paper/view/15065/14647; Anderson, M., Anderson, S.L., Robot be good (2010) Scientific American, 303 (4), pp. 72-77. , https://www.scientificamerican.com/article/robot-be-good/, (2010); Arkin, R.C., The case for ethical autonomy in unmanned systems (2010) Journal of Military Ethics, 9 (4), pp. 332-341. , https://doi.org/10.1080/15027570.2010.536402, (2010); Asaro, P.M., A body to kick but still no soul to damn: Legal perspectives on robotics (2012) Robot Ethics:The Ethical and Social Implications of Robotics, pp. 169-186. , https://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6733967, P. Lin, K. Abney, and G. Bekey (Eds.). MIT Press; Boden, M., Bryson, J., Caldwell, D., Dautenhahn, K., Edwards, L., Kember, S., Newman, P., Rodden, T., Principles of robotics: Regulating robots in the real world (2017) Connection Science, 29 (2), pp. 124-129. , https://doi.org/10.1080/09540091.2016.1271400, (2017); Bonnefon, J., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2016) Science, 352 (6293), pp. 1573-1576. , https://doi.org/10.1126/science.aaf2654, (2016); Briggs, G., Scheutz, M., Sorry, I can't Do that: Developing mechanisms to appropriately reject directives in human-robot interactions (2015) 2015 AAAI Fall Symposium Series, , http://www.aaai.org/ocs/index.php/FSS/FSS15/paper/download/11709/11522; Brundage, M., Avin, S., Clark, J., Toner, H., Eckersley, P., Garfinkel, B., Dafoe, A., Zeitzoff, T., The malicious use of artificial intelligence: Forecasting, prevention, and mitigation (2018) CoRR, , abs/1802.07228 (2018); (2016) BS8611:2016, Robots and Robotic Devices: Guide to the Ethical Design and Application of Robots and Robotic Systems, , BSI. British Standards Institute; Chouard, T., Venema, L., Machine intelligence (2015) Nature, 521 (7553), p. 435. , https://doi.org/10.1038/521435a, (2015); Deng, B., Machine ethics: The robot's dilemma (2015) Nature, 523 (7558), pp. 24-26. , https://doi.org/10.1038/523024a, (Jul 2015); Greenberg, A., The jeep hackers are back to prove car hacking can get much worse (2016) Wired, , https://www.wired.com/2016/08/jeep-hackers-return-high-speed-steering-acceleration-hacks/, (January 2016); (2018) The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems, IEEE Standards Assoc, , http://standards.ieee.org/develop/indconn/ec/autonomous_systems.html, IEEE; Lin, P., (2015) Autonomes Fahren: Technische, Rechtliche und Gesellschaftliche Aspekte, pp. 69-85. , https://doi.org/10.1007/978-3-662-45854-9_4, Springer Berlin Heidelberg, Berlin, Heidelberg, Chapter Why Ethics Matters for Autonomous Cars; Lin, P., Abney, K., Bekey, G.A., (2011) Robot Ethics: The Ethical and Social Implications of Robotics, , MIT press; Mazza, E., (2015) Stephen Hawking & Elon Musk Warn of Killer Robots, , http://www.huffingtonpost.com/entry/killer-robots-stephen-hawking_55b7163ee4b0074ba5a60a14, Accessed Oct 2018; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21. , https://doi.org/10.1109/MIS.2006.80, (2006); Murphy, R.R., Woods, D.D., Beyond asimov: The three laws of responsible robotics (2009) IEEE Intelligent Systems, 24 (4), pp. 14-20. , https://doi.org/10.1109/MIS.2009.69, (2009); O'Meara, R., Contemporary governance architecture regarding robotics technologies: An assessment (2012) Robot Ethics:The Ethical and Social Implications of Robotics, pp. 169-186. , http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6733990, P. Lin, K. Abney, and G. Bekey (Eds.). MIT Press; Russell, S., Dewey, D., Tegmark, M., Kramar, J., Mallah, R., Research priorities for robust and beneficial artificial intelligence (2015) AI Magazine, 36 (4). , http://hdl.handle.net/1721.1/108478, (2015); Russell, S., Hauert, S., Altman, R., Veloso, M., Robotics: Ethics of artificial intelligence (2015) Nature, 521 (7553), pp. 415-418. , https://doi.org/doi:10.1038/521415a, (May 2015); Sharkey, N., The ethical frontiers of robotics (2008) Science, 322 (5909), pp. 1800-1801. , https://doi.org/10.1126/science.1164582, (2008); Stilgoe, J., Owen, R., Macnaghten, P., Developing a framework for responsible innovation (2013) Research Policy, 42 (9), pp. 1568-1580. , https://doi.org/10.1016/j.respol.2013.05.008, (2013); Vanderelst, D., Winfield, A.F.T., An architecture for ethical robots inspired by the simulation theory of cognition (2018) Cognitive Systems Research, 48, pp. 56-66. , https://doi.org/10.1016/j.cogsys.2017.04.002, (2018); Wallach, W., Allen, C., (2008) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press; Winfield, A., Roboethics for humans (2011) New Scientist, 210 (2811), pp. 32-33. , https://doi.org/10.1016/S0262-4079(11)61052-X, (2011); Winfield, A.F.T., Blum, C., Liu, W., Towards an ethical robot: Internal models, consequences and ethical action selection (2014) Advances in Autonomous Robotics Systems, pp. 85-96. , https://doi.org/10.1007/978-3-319-10401-0_8, Michael Mistry, Aleš Leonardis, Mark Witkowski, and Chris Melhuish (Eds.). Springer International Publishing, Cham; Winfield, A.F.T., Jirotka, M., Ethical governance is essential to building trust in robotics and artificial intelligence systems (2018) Phil. Trans. R. Soc. A, 376, p. 20180085. , https://doi.org/10.1098/rsta.2018.0085, (2018)},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Weng2018286,
author={Weng, Y.-H. and Hirata, Y.},
title={Ethically Aligned Design for Assistive Robotics},
journal={2018 International Conference on Intelligence and Safety for Robotics, ISR 2018},
year={2018},
pages={286-290},
doi={10.1109/IISR.2018.8535889},
art_number={8535889},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059082820&doi=10.1109%2fIISR.2018.8535889&partnerID=40&md5=201634c0541482fc973125818ff877a2},
abstract={Assistive robotics is regarded as a promising solution to solve many problems in an aging society. However., it hasn't been discussed how best to implement the concept of Ethically Aligned Design (EAD) into the design., manufacture., and use of assistive robotics. EAD is a guideline to ensure the usage and development of AI and autonomous systems are not violating human centered value system. Accompanied with the rapid growth trend of AI technologies., this will bring new impacts to assistive robotics. In this paper., we want to make a systematic analysis to see how AI can influence the ELSI to assistive robotics. © 2018 IEEE.},
author_keywords={AI Ethics;  Assistive Robotics;  Ethicallly Aligned Design;  Human-Robot Interaction;  Robot Ethics},
keywords={Machine design;  Philosophical aspects;  Robotics, Aging societies;  AI Technologies;  Assistive robotics;  Autonomous systems;  Rapid growth;  Robot ethics;  Systematic analysis;  Value systems, Human robot interaction},
references={(2017) Statistics Bureau, Ministry of Internal Affairs and Communication (MIC), Population Statistics Report, , http://www.stat.go.jp/data/jinsui/2017np/pdf/2017np.pdf, Japan; (2015) The Headquarters for Japan's Economic Revitalization, New Robot Strategy: Japan's Robot Strategy-Vision, Strategy, Action Plan, , http://www.meti.go.jp/english/press/2015/pdf/0123_01b.pdf; Ministry of economy, trade and industry (meti) and ministry of health, labor and welfare (mhlw) (2014) Revision of the Four Priority Areas to Which Robot Technology is to Be Introduced in Nursing Care of the Elderly, , http://www.meti.go.jp/english/press/2014/0203_02.html, Japan, see; Ministry of economy, trade and industry (meti) and ministry of health, labor and welfare (mhlw) (2017) Revision of the Priority Areas to Which Robot Technology is to Be Introduced in Nursing Care, , http://www.meti.go.jp/english/press/2017/1012_002.html; Ethical, Legal, and Social Implication (ELSI) Research, Wikipedia, See, , https://en.wikipedia.org/wiki/Ethical,_Legal_and_Social_Aspects_research; Definition of Ethical, Legal, and Social Implication (ELSI), Genetics Home Reference, See, , https://ghr.nlm.nih.gov/primer/hgp/elsi; Feil-Seifer, D., Mataric, M., Ethical principles for socially assistive robots IEEE Robotics &Automation Magazine, 18 (1), pp. 24-31; Neumann, D., Human assistant robotics in Japan-challenges and opportunities for european companies (2016) Report by EU-Japan Centre for Industrial Cooperation, , March; Homma, K., Yamada, Y., Matsumoto, O., Lee, S., Ono, E., Ethical review process and subject protection in demonstration experiments of assistive robots for care-giving-case report of the excretion care robot "toilet-assist" (2010) Journal of Robotics Society of Japan (JRSJ), 28 (2), pp. 181-190; (2016) European Parliament, DRART REPORT with Recommendations to the Commission on Civil Law Rules on Robotics (2015/2103(INL)); The ieee global initiative on ethics of autonomous and intelligent systems (2017) Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems (A/IS), Version 2, , https://standards.ieee.org/develop/indconn/ec/autonomous_systems.html; Feil-Seifer, D., Mataric, M., Defining socially assistive robotics (2005) Proceedings of the 2005 IEEE 9th International Conference on Rehabilitation Robotics, , June 28-July 1, , Chicago, IL, USA; Fong, T., Nourbakhsh, I., Dautenhahn, K., A survey of socially interactive robots (2003) Robotics and Autonomous Systems, 42 (3-4), pp. 143-166; Ariani, A., Kapadia, V., Talaei-Khoei, A., Li, J., Ray, P.K., Challenges in seniors adopting assistive robots: A systematic review (2016) The International Technology Management Review, 6 (2), pp. 25-36; Stevens, J.A., Haas, E.N., Haileyesus, T., Nonfatal bathroom injuries among persons aged ≥ 15 years-United States, 2008 (2011) Morbidity and Mortality Weekly Report (MMWR), US Centers for Disease Control and Prevention (CDC), , https://www.cdc.gov/mmwr/preview/mmwrhtml/mm6022a1.htm; Shaban, H., An Amazon Echo recorded a family's conversation, then sent it to a random person in their contacts, report says The Washington Post (2018-05-24), See, , https://www.washingtonpost.com/news/the-switch/wp/2018/05/24/anamazon-echo-recorded-A-familys-conversation-then-sent-it-to-arandom-person-in-their-contacts-reportsays/?noredirect=on&utm_term=.81661210f16b; Takeda, M., Hirata, Y., Katayama, T., Mizuta, Y., Koujina, A., State estimation using cog candidates for standing support system user The Robotics and Mechanics Conference (ROBOMECH 2018), , Kitakyushu, June 2-5; Weng, Y.H., (2014) The Study of Safety Governance for Service Robots: On Open-Texture Risk, , Ph. D. Dissertation, Peking University Law School, Beijing, China, May; Koimizu, J., Kato, K., ELSI on elderly care robots: Japanese discourse and context (2017) Medicine, Life, Society, 14; Arkin, R.C., The Ethics of Robotic Deception, , Technical Report, Georgia Institute of Technology; Tallinn, J., (2017) On Steering the AI, , http://www.tohoku.ac.jp/japanese/2017/07/event20170731-01.html, FRIS Seminar, Tohoku University, September 06; Arkin, R.C., Governing Lethal Behavior: Embedding Ethics in A Hybrid Deliberative/Reactive Robot Architecture-Part 2: Formalization for Ethical Control, , Technical Report, Georgia Institute of Technology, GIT-GVU-07-11; Weng, Y.H., Chen, C.H., Sun, C.T., Toward the human-robot co-existence society: On safety intelligence for next generation robots International Journal of Social Robotics, 1 (4), pp. 267-282; Privacy by Design, Wikipedia, See, , https://en.wikipedia.org/wiki/Privacy_by_design; Stahl, B.C., Coeckelbergh, M., Ethics of Healthcare robotics: Towards responsible research and innovation (2016) Robotics and Autonomous Systems, 86, pp. 152-161; Weng, Y.H., Zhao, S.T.H., The legal challenges of networked robotics: From the safety intelligence perspective Lecture Notes in Computer Science (LNCS): AI Approaches to the Complexity of Legal Systems. Models and Ethical Challenges for Legal Systems, Legal Language and Legal Ontologies, Argumentation and Software Agents, 7639, pp. 61-72. , M. Palmirani et al. (Eds. ), Springer Berlin Heidelberg; Delaney, K.J., The Robot That Takes Your Job Should Pay Taxes, Says Bill Gates, , https://qz.com/911968/billgates-The-robot-that-takes-your-job-should-pay-taxes/, Quartz. See; (2016) Government Office of Science, the United Kingdom, Artificial Intelligence: Opportunities and Implications for the Future of Decision Making; Advisory board on ai and human society, council for science, technology and innovation (csti), the cabinet office of Japan (2017) Report on Artificial Intelligence and Human Society; Weng, Y.H., Sugahara, Y., Hashimoto, K., Takanishi, A., Intersection of "tokku special zone, robots, and the law: A case study on legal impacts to humanoid robots (2015) International Journal of Social Robotics, 7; Pagallo, U., From automation to autonomous systems: A legal phenomenology with problems of accountability (2017) Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI-17), , Melbourne, August 25-27},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Fossa2018115,
author={Fossa, F.},
title={Artificial moral agents: moral mentors or sensible tools?},
journal={Ethics and Information Technology},
year={2018},
volume={20},
number={2},
pages={115-126},
doi={10.1007/s10676-018-9451-y},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044028906&doi=10.1007%2fs10676-018-9451-y&partnerID=40&md5=36bc5aaa847de760f0f7d38d318ffe69},
abstract={The aim of this paper is to offer an analysis of the notion of artificial moral agent (AMA) and of its impact on human beings’ self-understanding as moral agents. Firstly, I introduce the topic by presenting what I call the Continuity Approach. Its main claim holds that AMAs and human moral agents exhibit no significant qualitative difference and, therefore, should be considered homogeneous entities. Secondly, I focus on the consequences this approach leads to. In order to do this I take into consideration the work of Bostrom and Dietrich, who have radically assumed this viewpoint and thoroughly explored its implications. Thirdly, I present an alternative approach to AMAs—the Discontinuity Approach—which underscores an essential difference between human moral agents and AMAs by tackling the matter from another angle. In this section I concentrate on the work of Johnson and Bryson and I highlight the link between their claims and Heidegger’s and Jonas’s suggestions concerning the relationship between human beings and technological products. In conclusion I argue that, although the Continuity Approach turns out to be a necessary postulate to the machine ethics project, the Discontinuity Approach highlights a relevant distinction between AMAs and human moral agents. On this account, the Discontinuity Approach generates a clearer understanding of what AMAs are, of how we should face the moral issues they pose, and, finally, of the difference that separates machine ethics from moral philosophy. © 2018, Springer Science+Business Media B.V., part of Springer Nature.},
author_keywords={Artificial moral agents;  Ethics of technology;  Machine ethics;  Machine morality;  Moral agency},
keywords={Information technology;  Social sciences, Heidegger;  Human being;  Main claims;  Moral agency;  Moral agents;  Moral issues;  Moral philosophy;  Qualitative differences, Philosophical aspects},
references={Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental and Theoretical Artificial Intelligent, 12, pp. 251-261; Anderson, S.L., Machine metaethics (2011) Machine ethics, pp. 21-27. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Beavers, A.F., Moral machines and the threat of ethical nihilism (2012) Robot ethics. The ethical and social implications of robotics, pp. 333-344. , Lin P, Abney K, Bekey GA, (eds), The M.I.T. Press, Cambridge; (2003) Ethical issues in advanced artificial intelligence., , https://nickbostrom.com/ethics/ai.html, Bostrom, N. Accessed 22 Aug 2017; Bostrom, N., (2014) Superintelligence. Paths, dangers, strategies, , Oxford University Press, Oxford; Bryson, J.J., Robots Should Be Slaves (2010) Close engagements with artificial companions: Key social, psychological, ethical and design issues, pp. 63-74. , Wilks Y, (ed), John Benjamins, Amsterdam; (2011) Just an artifact: Why machines are perceived as moral agents., , https://www.cs.bath.ac.uk/~jjb/ftp/BrysonKime-IJCAI11.pdf, Bryson, J. J., & Kime, P. Accessed 22 Aug 2017; Clarke, R., Asimov’s laws of robotics. Implications for information technology (2011) Machine ethics, pp. 254-284. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Dennett, D.C., When HAL kills, who’s to blame? Computer ethics (1997) Hal’s legacy: 2001’s computer as dream and reality, pp. 351-366. , Stork DG, (ed), The M.I.T. Press, Cambridge; Dietrich, E., After humans are gone (2007) Journal of Experimental and Theoretical Artificial Intelligence, 19 (1), pp. 55-67; Dietrich, E., Homo Sapiens 2.0. Building the better robots of our nature (2011) Machine ethics, pp. 531-538. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Duffy, B., Anthropomorphism and the social robot (2003) Robotic and Autonomous Systems, 42, pp. 177-190; (2013) Anthropomorphism and robotics., , http://medialabeurope.org/anthropos/publications/pubsIAISB02-Duffy.pdf, Duffy, B. Accessed 28 Nov 2017; Fabris, A., Philosophy, image and the mirror of machines (2016) Theorizing images, pp. 111-120. , Paić Ž, Purgar K, (eds), Cambridge Scholars, Newcastle upon Tyne; Fink, J., Anthropomorphism and human likeness in the design of robots and human-robot interaction. In S. S. Ge et al. (Eds.), ICSR 2012, LNAI 7621, pp (2012) 199–208; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds and Machine, 14, pp. 349-379; Franklin, S., Graesser, A., Is it an agent, or just a program? A taxonomy for autonomous agents (1996) Intelligent Agents III. Agent Theories, Architectures, and Languages. ATAL 1996. Lecture Notes in Computer Science (Lecture Notes in Artificial Intelligence), vol. 1193, pp. 22-35. , Müller JP, Wooldridge MJ, Jennings NR, (eds), Springer, Berlin; Friedman, B., Kahn, P.H., Human agency and responsible computing: Implications for computer system design (1992) Journal of Systems Software, 17 (7), pp. 7-14; Fussel, S.R., Kiesler, S., Setlock, L.D., Yew, V., How people anthropomorphize robots (2008) In HRI’08 Proceedings of the 3rd ACM/IEEE International Conference on Human Robot Interaction, pp. 145-152; Gips, J., Towards the ethical robot (1995) Android epistemology, pp. 243-252. , Ford GK, Glymour C, Hayes PJ, (eds), The M.I.T. Press, Cambridge; Grodzinsky, F.S., Miller, K.W., Wolf, M.J., The ethics of designing artificial agents (2008) Ethics and Information Technology, 10, pp. 115-121; Gunkel, D.J., (2012) The machine question. Critical perspectives on AI, robots and ethics, , The M.I.T. Press, Cambridge; Hall, J.S., Ethics for machines (2011) Machine ethics, pp. 28-44. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Hall, J.S., Ethics for self-improving machines (2011) Machine ethics, pp. 512-523. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Heidegger, M., (2010) Being and time, , State University of New York Press, New York; Heidegger, M., (2013) The question concerning technology and other essays, , Harper Perennial, New York; Henry, B., Imaginaries of the Global Age. “Golem and others” in the post-human condition (2014) Politica e Società, 2-2014, pp. 221-246; Himma, K.E., Artificial agency, consciousness, and the criteria for moral agency: What properties must an artificial agent have to be a moral agent? (2009) Ethics and Information Technology, 11 (1), pp. 19-29; Johnson, D.G., Computer ethics (2003) A companion to applied ethics, pp. 608-619. , Frey RG, Wellman CH, (eds), Blackwell, Malden-Oxford-Carlton; Johnson, D.G., Computer systems. Moral entities, but not moral agents (2011) Machine ethics, pp. 168-183. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Jonas, H., Cybernetics and purpose: A critique. Social research, XX(2), pp.172–192. Reprinted as § 5 in Id. (2001) (1953) The Phenomenon of Life. Toward a Philosophical Biology, pp. 108-127. , Northwestern University Press, Evanston; Jonas, H., The practical uses of theory. Social research, XXVI(2), pp.151–166. Reprinted as § 8 in Id. (2001) (1959) The Phenomenon of Life. Toward a Philosophical Biology, pp. 188-210. , Northwestern University Press, Evanston; Kakoudaki, D., (2014) Anatomy of a robot. Literature, cinema, and the cultural work of artificial people, , Rutgers University Press, New Brunswick; Kiran, A.E., Verbeek, P.-P., Trusting our selves to technology (2010) Knowledge, Technology, and Policy, 23, pp. 409-427; Kurzweil, R., (2005) The singularity is near. When Humans transcend biology, , Viking, New York; Laukyte, M., Artificial agents among us. Should we recognize them as agents proper? (2017) Ethics and Information Technology, 19 (1), pp. 1-17; Lemaignan, S., Fink, J., Dillenbourg, P., The Dynamics of Anthropomorphism in Robotics (2014) In HRI’14 Proceedings of the 2014 ACM/IEEE International Conference on Human-Robot Interaction, pp. 226-227; McDermott, D., What matters to a machine? (2008) Machine ethics, pp. 88-114. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Moor, J.H., Is ethics computable? (1995) Metaphilosophy, 26 (1-2), pp. 1-21; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Moore, G.E., Cramming more components into integrated circuits (1965) Electronics, 38 (8), pp. 114-117; Mori, M., Bukimi no tani (1970) Energy, 7, pp. 33-35; Nass, C., Moon, Y., Machines and mindlessness: Social responses to computers (2000) Journal of Social Issues, 56 (1), pp. 81-103; Nissenbaum, H., How computer systems embody values (2001) Computer, 34, pp. 118-120; Scheutz, M., The inherent dangers of unidirectional emotional bonds between humans and social robots (2012) Robot ethics. The ethical and social implications of robotics, pp. 205-222. , Lin P, Abney K, Bekey GA, (eds), The MIT Press, Cambridge; Searle, J.R., Minds, brains, and programs (1980) The Behavioral and Brain Sciences, 3, pp. 417-424; Sullins, J.P., When is a robot a moral agent? (2011) Machine ethics, pp. 151-161. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Torrance, S., Machine ethics and the Idea of a more-than-human moral world (2011) Machine ethics, pp. 115-137. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Turing, A.M., Computing machinery and intelligence (1950) Mind, 59 (236), pp. 433-460; Turkle, S., Authenticity in the age of digital companions (2011) Machine ethics, pp. 62-76. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Verbeek, P.-P., (2005) What Things Do. Philosophical Reflections on Technology, Agency, and Design, , The Pennsylvania State University Press, University Park; Vinge, V., The coming technological singularity: How to survive in the post-human era. Vision-21: Interdisciplinary Science and Engineering in the Era of Cyberspace (pp. 11–22) (1993) NASA Scientific and Technical Information Program; Wallach, W., Robot minds and human ethics: the need for a comprehensive model of decision making (2010) Ethics and Information Technology, 12 (3), pp. 243-250; Wallach, W., Allen, C., (2009) Moral machines. Teaching robots right from wrong, , Oxford University Press, New York; Wallach, W., Allen, C., Smit, I., Why machine ethics? (2011) Machine ethics, pp. 51-61. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Whitby, B., On computable morality: An examination of machines as moral advisors (2011) Machine ethics, pp. 138-150. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; (2008) Artificial intelligence as a positive and negative factor in global risk., , http://intelligence.org/files/AIPosNegFactor.pdf, Yudkowsky, E. Machine Intelligence Research Institute. Accessed online 22 Aug 2017},
document_type={Article},
source={Scopus},
}

@ARTICLE{Brutzman2018427,
author={Brutzman, D. and Blais, C.L. and Davis, D.T. and McGhee, R.B.},
title={Ethical Mission Definition and Execution for Maritime Robots under Human Supervision},
journal={IEEE Journal of Oceanic Engineering},
year={2018},
volume={43},
number={2},
pages={427-443},
doi={10.1109/JOE.2017.2782959},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040938066&doi=10.1109%2fJOE.2017.2782959&partnerID=40&md5=9e1eabc5000d1a7fe59f8e316c1f3fc6},
abstract={Experts and practitioners have worked long and hard toward achieving functionally capable robots. While numerous areas of progress have been achieved, ethical control of unmanned systems meeting legal requirements has been elusive and problematic. Common conclusions that treat ethical robots as an always-amoral philosophical conundrum requiring undemonstrated morality-based artificial intelligence are simply not sensible or repeatable. Patterning after successful practice by human teams shows that precise mission definition and task execution using well-defined, syntactically valid vocabularies is a necessary first step. Addition of operational constraints enables humans to place limits on robot activities, even when operating at a distance under gapped communications. Semantic validation can then be provided by a Mission Execution Ontology to confirm that no logical or legal contradictions are present in mission orders. Thorough simulation, testing, and certification of qualified robot responses are necessary to build human authority and trust when directing ethical robot operations at a distance. Together these capabilities can provide safeguards for autonomous robots possessing the potential for lethal force. This approach appears to have broad usefulness for both civil and military application of unmanned systems at sea. © 1976-2012 IEEE.},
author_keywords={Autonomous vehicles;  mission execution automata (MEA);  mission execution ontology (MEO);  robot ethics},
keywords={Intelligent robots;  Ontology;  Philosophical aspects;  Semantics, Autonomous Vehicles;  Ethics;  Mission execution;  Robot ethics;  Robot kinematics;  Robot sensing system, Robots},
references={Davis, D.T., (2006) Design, Implementation, and Testing of A Common Data Model Supporting Autonomous Vehicle Compatibility and Interoperability, , Monterey, CA, USA: Naval Postgraduate School; Brutzman, D.P., Davis, D.T., Lucas, G.R., Jr., McGhee, R.B., Run-time ethics checking for autonomous unmanned vehicles: Developing a practical approach (2013) Proc. 18th Int. Symp. Unmanned Untethered Submersible Technol., pp. 78-89. , Portsmouth, NH, USA; Brutzman, D., (2016) Autonomous Vehicle Command Language, , https://savage.nps.edu/Savage/AuvWorkbench/AVCL/AVCL.html, 1 Jan. 2013. Accessed on: Dec. 9; Brutzman, D., A virtual world for an autonomous underwater vehicle (1994) Naval Postgraduate School, , Monterey, CA, USA; Brutzman, D.P., Davis, D.T., Blais, C.L., McGhee, R.B., Ethical mission definition and execution for maritime and naval robotic vehicles: A practical approach (2016) Proc. IEEE/MTS Oceans, , Monterey, CA, USA; Capek, K., (1921) Rossum's Universal Robots, , 2004 ed., New York, NY, USA: Penguin; I. Azimov, I, Robot, New York, NY: Bantam Dell. 1950; Sparrow, R., 'Just say No' to Drones (2012) Technol. Soc. Mag., 31 (1), pp. 56-63; Arkin, R., (2009) Governing Lethal Behavior in Autonomous Robots, , Boca Raton, AL, USA: Taylor & Francis; Lin, P., Abney, K., Bekey, G.A., (2011) Robot Ethics: The Ethical and Social Implications of Robotics, , Cambridge, MA, USA: MIT Press; Scharre, P., (2016) Autonomous Weapons and Operational Risk, , http://www.cnas.org/autonomous-weapons-andoperational-risk, Feb; (2011) Vicarious Liability, , Merriam-Webster. Merriam-Webster's Dictionary of Law, Springfield, MA, USA: Merriam-Webster; (2012) Autonomy in Weapon Systems, Directive 3000. 09, , http://www.dtic.mil/whs/directives/corres/pdf/300009p.pdf, Department of Defense. Nov. 21. Accessed on: Dec. 23; Mack, W.P., Seymour, H.A., McComas, L.A., (1998) The Naval Officer's Guide, , 11th ed., Annapolis, MD, USA: Naval Inst. Press; Schuller, A.L., At the crossroads of control: The intersection of artificial intelligence in autonomous weapon systems with international humanitarian law (2017) Harvard Nat. Sec. J., 8 (2), pp. 379-425. , May 30; Schuller, A.L., Inimical inceptions of imminence: A new approach to anticipatory self-defense under the law of armed conflict (2014) UCLA J. Int. Law Foreign Affairs, 18 (2), pp. 161-206; Brutzman, D.P., Network optional warfare (NOW) (2017) Naval Postgraduate School, , https://wiki.nps.edu/display/NOW/Network+Optional+Warfare, Jan. 6, 2014. Accessed on: Dec. 1; Brutzman, D., Healey, T., Marco, D., McGhee, B., The phoenix autonomous underwater vehicle (1998) AI-Based Mobile Robots, , Cambridge, MA, USA: MIT/AAAI Press; Marco, D., Healey, A., McGhee, R., Autonomous underwater vehicles: Hybrid control of mission and motion (1996) Autonom. Robots, 3, pp. 169-186; Byrnes, R., (1993) The Rational Behavior Model: A Multi-Paradigm, Tri-Level Software Architecture for the Control of Autonomous Vehicles, , Monterey, CA, USA: Naval Postgraduate School; Byrnes, R.B., Healey, A.J., McGhee, R.B., Nelson, M.L., Kwak, S., Brutzman, D.P., The rational behavior software architecture for intelligent ships (1996) Naval Eng. J., 108, pp. 43-56. , Mar; Duarte, C.N., A common control language to support multiple cooperating UAVs (2005) Proc. 14th Int. Symp. Unmanned Untethered Submersible Technol., , Durham, NH, USA; Ricard, M., Kolitz, S., The ADEPT framework for intelligent autonomy (2002) Proc. Intell. Syst. Aeronautics Workshop, pp. 11-111. , Brussels, Belgium; Albus, J., Engineering intelligent systems (1998) Proc. IEEE ISIC/CIRA/ ISAS Joint Conf., , Gaithersburg, MD, USA; Brutzman, D.P., McGhee, R.B., Davis, D.T., An implemented universal mission controller with run time ethics checking for autonomous unmanned vehicles-AUUVexample (2012) Proc. OES-IEEE Autonom. Underwater Veh., , Southampton, U. K; Dannegger, C., Real-time autonomic automation (2009) Springer Handbook of Automation, pp. 381-404. , S. Y. Nof, Ed., New York, NY, USA: Springer-Verlag; Hammond, G.T., (2001) The Mind of War: John Boyd and American Security, , Washington, DC, USA: Smithsonian Inst. Press; Rowe, N., (1988) Artificial Intelligence Through Prolog, , Englewood Cliffs, NJ, USA: Prentice-Hall; Minsky, M., (1967) Computation: Finite and Infinite Machines, , Englewood Cliffs. Englewood Cliffs, NJ, USA: Prentice-Hall; Petzold, C., (2008) The Annotated Turing: A Guided Tour Through Alan Turing's Historic Paper on Computability and the Turing Machine, , Indianapolis, Indianapolis, IN, USA: Wiley; Simpson, S.G., Logic and mathematics (2000) The Examined Life: Readings from Western Philosophy from Plato to Kant, , S. Rosen, Ed., New York, NY, USA: Random House; McGhee, R.B., Brutzman, D.P., Davis, D.T., A universal multiphase Mission Execution Automaton (MEA) with prolog implementation for unmanned untethered vehicles (2011) Proc. 17th Int. Symp. Unmanned Untethered Submersible Technol., pp. 241-250. , Portsmouth, NH, USA; Brutzman, D., (2016) Autonomous Unmanned Vehicle (AUV) Workbench, , https://savage.nps.edu/AuvWorkbench, Sep. 18, 2016. Accessed on: Dec. 9; McGhee, R.B., Brutzman, D.P., Davis, D.T., Recursive goal refinement and iterative task abstraction for top-level control of autonomous mobile robots by mission execution automata-a UUV example (2012) Naval Postgraduate School, , Monterey, CA, USA; McGhee, R.B., Brutzman, D.P., Davis, D.T., A taxonomy of turing machines and mission execution automata with lisp/prolog implementation (2011) Naval Postgraduate School, , Monterey, CA, USA; Skiena, S.S., (1997) The Algorithm Design Manual, pp. 169-178. , 2 ed., London, U. K.: Springer-Verlag; (2015) COMBATXXI, , http://www.trac.army.mil/COMBATXXI.pdf, U. S. Army Training Doctrine Command Analysis Center. Sep. 29. Accessed on: Jan. 28; Posadas, S., (2001) Stochastic Simulation of A Commander's Decision Cycle (SSIM CODE), , M. S. thesis, Operations Research Naval Postgraduate School, Monterey, CA, USA; Scholz, T., The state transition diagram with path priority and its applications (1993) Naval Postgraduate School, , Monterey, CA, USA. Sep; Ortiz, M., Simkus, M., Reasoning and query answering in description logics (2012) Reasoning Web. Semantic Technologies for Advanced Query Answering (Lecture Notes in Computer Science), 7487. , Berlin, Germany: Springer-Verlag; Berners-Lee, T., Hendler, J., Lassila, O., The semantic web (2001) Sci. Amer., 284 (5), pp. 34-43. , May; (2013) Web Ontology Language (OWL) Semantic Web Standards, , https://www.w3.org/2001/sw/wiki/OWL.Accessedon:Dec.9, World Wide Web Consortium. Dec. 11; (2014) Resource Description Framework (RDF) Semantic Web Standards, , https://www.w3.org/2001/sw/wiki/RDF, World Wide Web Consortium. Mar. 15. Accessed on: Dec. 9; Horrocks, I., Ontologies and the semantic web (2008) Commun. ACM, 51 (12), pp. 58-67; Daconta, M.D., Orbst, L.J., Smith, K.T., (2003) The Semantic Web, A Guide to the Future of XML, Web Services, and Knowledge Management, , Indianapolis, IN, USA: Wiley; Davis, D.T., Semantic web and inferencing technologies for department of defense systems (2014) Naval Postgraduate School, , Monterey, CA, USA; (2017) Uniform Resource Identifier (URI), , https://en.wikipedia.org/wiki/Uniform_Resource_Identifier, Accessed on: Dec. 1; Krisnadhi, A., Maier, F., Hitzler, P., OWL and rules (2011) Reasoning Web: Semantic Technologies for TheWeb OfData, pp. 382-415. , A. Polleres, M. d'Amato, S. Arenas, S. Handschuh, P. Kroner, S. Ossowski, and P. F. Patel-Schneider, Eds., Heidelberg, Germany: Springer-Verlag; Horridge, M., (2014) A Practical Guide to Building OWL Ontologies Using Protege 4 and CO-ODE Tools. Edition 1. 3., , http://owl.cs.manchester.ac.uk/publications/talks-andtutorials/protg-owl-tutorial, Mar. 24, 2011. Accessed on: Dec. 23; Lokhorst, G., Ven Den Hoven, J., Responsibility for military robots (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 145-156. , N. G. Lin, K. Agney, and G. A. Bekey, Eds., Cambridge, MA, USA: MIT Press; Langley, C., Spenser, C., The visual development of rule-based systems (2005) PC AI Mag., 18 (3), pp. 29-36; (2016) Protege Ontology Editor and Application Framework, , http://protege.stanford.edu, Stanford University. Stanford Univ., Stanford, CA, USA. Accessed on: Dec. 9 2016},
document_type={Article},
source={Scopus},
}

@ARTICLE{Anderson2018337,
author={Anderson, M. and Anderson, S.L.},
title={GenEth: A general ethical dilemma analyzer},
journal={Paladyn},
year={2018},
volume={9},
number={1},
pages={337-357},
doi={10.1515/pjbr-2018-0024},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056900104&doi=10.1515%2fpjbr-2018-0024&partnerID=40&md5=200943a8b622198bd67e126a0375271a},
abstract={We argue that ethically significant behavior of autonomous systems should be guided by explicit ethical principles determined through a consensus of ethicists. Such a consensus is likely to emerge in many areas in which intelligent autonomous systems are apt to be deployed and for the actions they are liable to undertake, as we are more likely to agree on how machines ought to treat us than on how human beings ought to treat one another. Given such a consensus, particular cases of ethical dilemmas where ethicists agree on the ethically relevant features and the right course of action can be used to help discover principles needed for ethical guidance of the behavior of autonomous systems. Such principles help ensure the ethical behavior of complex and dynamic systems and further serve as a basis for justification of this behavior. To provide assistance in discovering ethical principles, we have developed GenEth, a general ethical dilemma analyzer that, through a dialog with ethicists, uses inductive logic programming to codify ethical principles in any given domain. GenEth has been used to codify principles in a number of domains pertinent to the behavior of autonomous systems and these principles have been verified using an Ethical Turing Test, a test devised to compare the judgments of codified principles with that of ethicists. © 2018 by Michael Anderson, Susan Leigh Anderson, published by De Gruyter.},
author_keywords={ethical Turing test;  inductive logic programming;  machine ethics;  machine learning},
references={Anderson, M., Anderson, S.L., GenEth: A general ethical dilemma analyzer (2014) Proceedings of the 28th AAAI Conference on Artificial Intelligence, , July Quebec City, Quebec, CA; Lavrac, N., Džeroski, S., (1997) Inductive Logic Programming: Techniques and Applications, , Ellis Harwood; Rawls, J., Outline for a decision procedure for ethics (1951) The Philosophical Review, 60 (2), pp. 177-197; Anderson, M., Anderson, S.L., Machine Ethics: Creating an ethical intelligent agent (2007) Artificial Intelligence Magazine Winter, 28 (4); Diederich, J., Rule Extraction from Support Vector Machines: An introduction (2008) Studies in Computational Intelligence (SCI), 80, pp. 3-31; Martens, D., Huysmans, J., Setiono, R., Vanthienen, J., Baesens, B., Rule extraction from support vectormachines: An overview of issues and application in credit scoring (2008) Studies in Computational Intelligence (SCI), 80, pp. 33-63; Quinlan, J.R., Induction of decision trees (1986) Machine Learning, 1, pp. 81-106; Bundy, A., McNeill, F., Representation as a fluent: An AI challenge for the next half century (2006) IEEE Intelligent Systems, 21 (3), pp. 85-87. , May/June; De Raedt, L., Kersting, K., Probabilistic inductive logic programming (2004) Algorithmic Learning Theory Springer Berlin Heidelberg; Anderson, M., Anderson, S.L., Armen, C., MedEthEx: A prototype medical ethics advisor (2006) Proceedings of the Eighteenth Conference on Innovative Applications of Artificial Intelligence, , August Boston, Massachusetts; Anderson, M., Anderson, S.L., Robot be Good (2010) Scientific American Magazine, , October; Turing, A.M., Computing machinery and intelligence (1950) Mind, 49, pp. 433-460; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12, pp. 251-261; Waldrop, M.M., A question of responsibility Chap. 11 (1987) Man Made Minds: The Promise of Artificial Intelligence, , NY: Walker and Company; Dejoie, R., (1991) Ethical Issues in Information Systems, pp. 260-277. , Reprinted Boston, MA: Boyd and Fraser; Gips, J., (1995) Towards the Ethical Robot, Android Epistemology, pp. 243-252. , Cambridge MA: MIT Press; Khan, A.F.U., (1995) The Ethics of Autonomous Learning Systems, pp. 253-265. , Android Epistemology Cambridge MA: MIT Press; Grau, C., There is no I" in "robot": Robots and utilitarianism (2006) IEEE Intelligent Systems, 21 (4), pp. 52-55. , July/August; Powers, T.M., Prospects for a Kantian machine (2006) IEEE Intelligent Systems, 21 (4), pp. 46-51; Rzepka, R., Araki, K., What could statistics do for ethics? the idea of common sense processing based safety valve (2005) Proceedings of the AAAI Fall Symposium on Machine Ethics, pp. 85-87. , AAAI Press; Guarini, M., Particularism and the classification and reclassification of moral cases (2006) IEEE Intelligent Systems, 21 (4), pp. 22-28. , July/August; McLaren, B.M., Extensionally defining principles and cases in ethics: An AI model (2003) Artificial Intelligence Journal, 150 (1-2), pp. 145-181; Bringsjord, S., Arkoudas, K., Bello, P., Towards a General logicist methodology for engineering ethically correct robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44; Pereira, L.M., Saptawijaya, A., Modeling morality with prospective logic (2007) Progress in Artificial Intelligence: Lecture Notes in Computer Science, 4874, pp. 99-111},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bogosian2017591,
author={Bogosian, K.},
title={Implementation of Moral Uncertainty in Intelligent Machines},
journal={Minds and Machines},
year={2017},
volume={27},
number={4},
pages={591-608},
doi={10.1007/s11023-017-9448-z},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035795763&doi=10.1007%2fs11023-017-9448-z&partnerID=40&md5=e8cad5f53c8dee5944079776d9ba8f5a},
abstract={The development of artificial intelligence will require systems of ethical decision making to be adapted for automatic computation. However, projects to implement moral reasoning in artificial moral agents so far have failed to satisfactorily address the widespread disagreement between competing approaches to moral philosophy. In this paper I argue that the proper response to this situation is to design machines to be fundamentally uncertain about morality. I describe a computational framework for doing so and show that it efficiently resolves common obstacles to the implementation of moral philosophy in intelligent machines. © 2017, Springer Science+Business Media B.V.},
author_keywords={AI ethics;  Bottom-up;  Ethical trade;  Ethical trading;  Macaskill;  Machine ethics;  Machine intelligence;  Metaethics;  Metanormative theory;  Metanormativity;  Moral disagreement;  Moral divergence;  Moral trade;  Moral trading;  Moral uncertainty;  Moral voting;  Normative uncertainty;  Top-down;  Value alignment;  Value differences;  Value specification},
keywords={Artificial intelligence;  Behavioral research;  Commerce;  Computation theory;  Decision making, Bottom up;  Ethical trading;  Macaskill;  Machine intelligence;  Metaethics;  Metanormative theory;  Metanormativity;  Moral disagreement;  Moral divergence;  Moral trading;  Moral uncertainty;  Moral voting;  Normative uncertainty;  Topdown;  Value differences, Philosophical aspects},
references={Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics and Information Technology; Archard, D., Why moral philosophers are not and should not be moral experts (2011) Bioethics, 25 (3), pp. 119-127; Arkoudas, K., Bringsjord, S., Bello, P., Toward ethical robots via mechanized deontic logic (2005) Machine ethics: Papers from the 2005 AAAI fall symposium, pp. 17-23. , http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:Toward+ethical+robots+via+mechanized+deontic+logic#0, Retrieved from, In; Bello, P., Bringsjord, S., On how to build a moral machine (2012) Topoi, 32 (2), pp. 251-266; Bostrom, N., (2009) Moral uncertainty—towards a solution?, , http://www.overcomingbias.com/2009/01/moral-uncertainty-towards-a-solution.html; Bostrom, N., The superintelligent will: Motivation and instrumental rationality in advanced artificial agents (2012) Minds and Machines, 22 (2), pp. 71-85; Bostrom, N., (2014) Superintelligence: Paths, dangers, strategies, , Oxford University Press, Oxford; Brundage, M., Limitations and risks of machine ethics (2014) Journal of Experimental & Theoretical Artificial Intelligence, 26 (3), pp. 355-372; Cotton-Barratt, O., (2013) Geometric reasons for normalising variance to aggregate preferences, , http://users.ox.ac.uk/~ball1714/Variance%20normalisation.pdf; Cross, B., Moral philosophy, moral expertise, and the argument from disagreement (2016) Bioethics, 30 (3), pp. 188-194; Driver, J., Moral expertise: Judgement, practice, and analysis (2014) Social Philosophy and Policy, 30 (1-2), pp. 280-296; Gloor, L., Suffering-focused AI safety: Why “fail-safe” measures might be our top intervention (2016) Foundational Research Institute, Report FRI-, pp. 11-16. , https://foundational-research.org/files/suffering-focused-ai-safety.pdf; Greene, J.D., Sommerville, R.B., Nystrom, L., Darley, J., Cohen, J., An fMRI investigation of emotional engagement in moral judgment (2001) Science, 293 (5537), pp. 2105-2108; Jones, K., Schroeter, F., Moral expertise (2012) Analyse & Kritik, 34 (2), pp. 217-230; Lockhart, T., (2000) Moral uncertainty and its consequences, , Oxford University Press, Oxford; MacAskill, W., The infectiousness of nihilism (2013) Ethics, 123 (3), pp. 508-520; MacAskill, W., (2014) Normative uncertainty, , http://commonsenseatheism.com/wp-content/uploads/2014/03/MacAskill-Normative-Uncertainty.pdf; MacAskill, W., Normative uncertainty as a voting problem (2016) Mind, 125 (500), pp. 967-1004; Nissan-Rozen, I., Against moral hedging (2015) Economics and Philosophy, 3, pp. 1-21; Oesterheld, C., Formalizing preference utilitarianism in physical world models (2015) Synthese; Oesterheld, C., Backup utility functions as a fail-safe AI technique (2016) Foundational Research Institute, Report FRI, pp. 12-16. , https://foundational-research.org/files/backup-utility-functions.pdf; (2009) Preliminary survey results, , http://philpapers.org/surveys/results.pl; Schultz, E., Cokely, E.T., Feltz, A., Persistent bias in expert judgments about free will and moral responsibility: A test of the expertise defense (2011) Consciousness and Cognition, 20 (4), pp. 1722-1731; Schwitzgebel, E., Cushman, F., Expertise in moral reasoning? Order effects on moral judgment in professional philosophers and non-philosophers (2012) Mind and Language, 27 (2), pp. 135-153; Shulman, C., Tarleton, N., Jonsson, H., Which consequentialism? Machine ethics and moral divergence (2009) In AP-CAP 2009: The 5th Asia-Pacific computing and philosophy conference, , https://intelligence.org/files/WhichConsequentialism.pdf; Williams, E., The possibility of an ongoing moral catastrophe (2015) Ethical Theory and Moral Practice, 18 (5), pp. 971-982; Wiltshire, T.J., A prospective framework for the design of ideal artificial moral agents: Insights from the science of heroism in humans (2015) Minds and Machines; Żuradzki, T., (2016) Meta-reasoning in making moral decisions under normative uncertainty. In Argumentation and reasoned action: Proceedings of the 1st European conference on argumentation, Lisbon, 2015 (Vol. 2, pp. 1093–1104)},
document_type={Article},
source={Scopus},
}

@ARTICLE{Pagallo2017625,
author={Pagallo, U.},
title={When Morals Ain’t Enough: Robots, Ethics, and the Rules of the Law},
journal={Minds and Machines},
year={2017},
volume={27},
number={4},
pages={625-638},
doi={10.1007/s11023-017-9418-5},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008716314&doi=10.1007%2fs11023-017-9418-5&partnerID=40&md5=96a1385bcd3ff960681dd9f77c253222},
abstract={No single moral theory can instruct us as to whether and to what extent we are confronted with legal loopholes, e.g. whether or not new legal rules should be added to the system in the criminal law field. This question on the primary rules of the law appears crucial for today’s debate on roboethics and still, goes beyond the expertise of robo-ethicists. On the other hand, attention should be drawn to the secondary rules of the law: The unpredictability of robotic behaviour and the lack of data on the probability of events, their consequences and costs, make hard to determine the levels of risk and hence, the amount of insurance premiums and other mechanisms on which new forms of accountability for the behaviour of robots may hinge. By following Japanese thinking, the aim is to show why legally de-regulated, or special, zones for robotics, i.e. the secondary rules of the system, pave the way to understand what kind of primary rules we may want for our robots. © 2017, Springer Science+Business Media Dordrecht.},
author_keywords={AI;  Moral theory;  Robotics;  Secondary rule;  Special zone},
keywords={Artificial intelligence;  Insurance;  Robotics, Criminal laws;  Insurance premiums;  Legal rules;  Moral theory;  New forms;  Primary rules;  Roboethics;  Secondary rule, Robots},
references={Abney, K., Robotics, ethical theory, and metaethics: A guide for the perplexed (2014) Robot ethics: The ethical and social implications of robotics, pp. 35-52. , Lin P, Abney K, Bekey GA, (eds), The MIT Press, Cambridge, MA; Anderson, M., Anderson, S.L., Ethical healthcare agents (2008) Advanced computational intelligence paradigms in healthcare, pp. 233-257. , Sordo M, (ed), Springer, Berlin; Barfield, W., Issues of law for software agents within virtual environments (2005) Presence, 14 (6), pp. 741-748; Bringsjord, S., Taylor, J., The divine-command approach to robot ethics (2014) Robot ethics: The ethical and social implications of robotics, pp. 85-108. , Lin P, Abney K, Bekey GA, (eds), The MIT Press, Cambridge, MA; Chisholm, R., Practical reason and the logic of requirement (1974) Practical reason, pp. 1-17. , Koerner S, (ed), Basil Blackwell, Oxford; Coudert, A.P., (1995) Leibniz and the Kabbalah, , Kluwer Academic, Boston-London; Davis, J., The (common) laws of man over (civilian) vehicles unmanned (2011) Journal of Law Information and Science; Remoted piloted aerial vehicles regulation. issue No. 2 dated 16 July 2015 (2015) Revision 1 dated, p. 21. , ENAC; Freitas, P.M., Andrade, F., Novais, P., Criminal liability of autonomous agents: From the unthinkable to the plausible (2014) Ai approaches to the complexity of legal systems, pp. 145-156. , Casanovas P, (ed), Springer, Dordrecht; Floridi, L., (2015) The Onlife Manifesto: Being Human in a Hyperconnected Era, , (ed), Springer, Dordrecht; Hallevy, G., (2015) Liability for crimes involving artificial intelligence systems, , Springer, Dordrecht; Hart, H., (1961) The concept of law, , Oxford University Press, Oxford; Horty, J., (2001) Agency and deontic logic, , Oxford University Press, New York; Horvitz, E., (2014) One-hundred year study of artificial intelligence: Reactions and framing, , Stanford University, White Paper; Kant, I., Perpetual peace (1999) The cambridge edition of the works of Immanuel Kant: Practical philosophy, 8. , Gregor M, (ed), Cambridge University Press, Cambridge; Koops, B.J., Should ICT regulation be technology-neutral? (2006) Starting points for ICT regulation: Deconstructing prevalent policy one-liners, pp. 77-108. , Koops B-J, (ed), TMC Asser, The Hague; Kroll, J.A., Huey, J., Barocas, S., Felten, E.W., Reidenberg, J.R., Robinson, D.G., Yu, H., Accountable algorithms (2017) University of Pennsylvania Law Review, 165; Lewis, C.I., Langford, C.H., (1959) Symbolic logic, , Dover, New York; Moor, J., What is computer ethics? (1985) Metaphilosophy, 16 (4), pp. 266-275; Murakami, Y., Utilitarian deontic logic (2004) Proceedings of the fifth international conference on advances in modal logic, pp. 288-302. , Schmidt R, (ed), AiML, Manchester UK; Noack, R., (2015) A robot killed a factory worker in Germany. So who should go on trial?. The Washington Post, 2 July edition; Pagallo, U., (2013) The laws of robots: crimes, contracts, and torts, , Springer, Dordrecht; Pagallo, U., Robots in the cloud with privacy: A new threat to data protection? (2013) Computer Law & Security Review, 29 (5), pp. 501-508; Pagallo, U., Online security and the protection of civil rights: A legal overview (2013) Philosophy and Technology, 26 (4), pp. 381-395; Pagallo, U., The impact of domestic robots on privacy and data protection, and the troubles with legal regulation by design (2016) Data protection on the move, pp. 387-410. , Gutwirth S, Leenes R, Hert P, (eds), Springer, Dordrecht; Pagallo, U., (2016) Three lessons learned for intelligent transport systems that abide by the law. Jusletter IT, 24, November. (Last accessed on Feb 12, 2016 at, , http://jusletter-it.weblaw.ch/issues/2016/24-November-2016/three-lessons-learne_9251e5d324.html; Quinn, P., (1978) Divine commands and moral requirements, , Oxford University Press, New York; Reed, C., (2012) Making laws for cyberspace, , Oxford University Press, Oxford; Sartor, G., Cognitive automata and the law: Electronic contracting and the intentionality of software agents (2009) Artificial Intelligence and Law, 17 (4), pp. 253-290; (2005) Edited by the UN Economic Commission for Europe and co-authored by the International Federation of Robotics, , UN Publication, Geneva (Switzerland); Veruggio, G., Euron roboethics roadmap (2006) Proceedings Euron Roboethics Atelier, February 27th–March 3rd, Genoa, , In:, Italy; Wallach, W., Allen, C., (2009) Moral machines: Teaching robots right from wrong, , Oxford University Press, New York; Weng, Y.H., Sugahara, Y., Hashimoto, K., Takanishi, A., Intersection of “Tokku” special zone, robots, and the law: A case study on legal impacts to humanoid robots (2015) International Journal of Social Robotics, 7, p. 841},
document_type={Article},
source={Scopus},
}

@ARTICLE{Borenstein2017499,
author={Borenstein, J. and Arkin, R.C.},
title={Nudging for good: robots and the ethical appropriateness of nurturing empathy and charitable behavior},
journal={AI and Society},
year={2017},
volume={32},
number={4},
pages={499-507},
doi={10.1007/s00146-016-0684-1},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000443585&doi=10.1007%2fs00146-016-0684-1&partnerID=40&md5=aeb23d28928c11d0e8a8c5616b33c63b},
abstract={An under-examined aspect of human–robot interaction that warrants further exploration is whether robots should be permitted to influence a user’s behavior for that person’s own good. Yet an even more controversial practice could be on the horizon, which is allowing a robot to “nudge” a user’s behavior for the good of society. In this article, we examine the feasibility of creating companion robots that would seek to nurture a user’s empathy toward other human beings. As more and more computing devices subtly and overtly influence human behavior, it is important to draw attention to whether it would be ethically appropriate for roboticists to pursue this type of design pathway. Our primary focus is on whether a companion robot could encourage humans to perform charitable acts; this design possibility illustrates the range of socially just actions that a robot could potentially elicit from a user and what the associated ethical concerns may be. © 2016, Springer-Verlag London.},
author_keywords={Charity;  Companion robots;  Design ethics;  Empathy;  Nudges;  Robot ethics},
keywords={Behavioral research;  Machine design;  Philosophical aspects;  Robots, Charity;  Companion robot;  Design ethics;  Empathy;  Nudges;  Robot ethics, Human robot interaction},
references={News, A.B.C., (2007) Parents: cyber bullying led to teen’s suicide, , http://abcnews.go.com/GMA/story?id=3882520&page=1, Accessed 6 May 2016; Alba, A., (2015) Mattel’s talking Hello Barbie doll raises concern over children’s privacy, , http://www.nydailynews.com/news/national/mattel-barbie-raises-concern-children-privacy-article-1.2151019, New York Daily News, Accessed 19 May 2016; Arkin, R., Theory of mind models for robotic mediation of stigma in patient-caregiver relationships (2014) 2014 conference of the international association for computing and philosophy (IACAP, p. 2014. , Thessaloniki, Greece; Arkin, R.C., Ameliorating patient-caregiver stigma in early-stage Parkinson’s Disease using robot co-mediators (2014) Proceedings of the AISB 50 symposium on machine ethics in the context of medical and health care agents, , b, In: London, UK; Arkin, R., Fujita, M., Takagi, T., Hasegawa, R., An ethological and emotional basis for human–robot interaction (2003) Robot Auton Syst, 42, pp. 191-201; Banks, M.R., Willoughby, L.M., Banks, W.A., Animal-assisted therapy and loneliness in nursing homes: use of robotic versus living dogs (2008) J Am Med Dir Assoc, 9 (3), pp. 173-177; Bloom, P., (2015) The dark side of empathy, , http://www.theatlantic.com/science/archive/2015/09/the-violence-of-empathy/407155/, The Atlantic, Accessed 20 June 2016; Bohannon, J., Government ‘nudges’ prove their worth (2016) Science, 352 (6289), p. 1042; Borenstein, J., Arkin, R., Robotic nudges: the ethics of engineering a more socially just human being (2016) Sci Eng Ethics, 22 (1), pp. 31-46; Brooks, A., Arkin, R.C., Behavioral overlays for non-verbal communication expression on a humanoid robot (2007) Auton Robots, 22 (1), pp. 55-75; Carroll, N., On some affective relations between audiences and the characters in popular fictions (2011) Empathy: philosophical and psychological perspectives, pp. 162-184. , Coplan A, Goldie P, (eds), Oxford University Press, New York; Chang, W.-L., Sabanovic, S., Studying assistive robots in their organizational context: studies with PARO in a nursing home (2015) HRI’15 extended abstracts proceedings of the tenth annual ACM/IEEE international conference on human–robot interaction extended abstracts, pp. 227-228; Coplan, A., Goldie, P., (2011) Empathy: philosophical and psychological perspectives, , eds), Oxford University Press, New York; Dolby, N., The future of empathy: teaching the millennial generation (2014) J Coll Charact, 15 (1), pp. 39-44; Dreyfus, H., Nihilism on the information highway: anonymity versus commitment in the present age (2004) Community in the digital age: philosophy and practice, pp. 69-81. , Feenberg A, Barney D, (eds), Rowman & Littlefield, Maryland; Endenburg, N., van Lith, H.A., The influence of animals on the development of children (2011) Vet J, 190 (2), pp. 208-214; Eyal, N., Hoover, R., (2013) Hooked: how to build habit-forming products, , Nir Eyal; Ferenbok, J., Mann, S., Michael, K., The changing ethics of mediated looking (2016) IEEE Consum Electron Mag, 5 (2), pp. 94-102; Fogg, B.J., (2003) Persuasive technology: using computers to change what we think and do, , Morgan Kaufman, San Francisco; Ham, J., Midden, C., A persuasive robot to stimulate energy conservation: the influence of positive and negative social feedback and task similarity on energy consumption behavior (2013) Int J Soc Robot, 6 (2), pp. 163-171; Ham, J., Spahn, A., Shall i show you some other shirts too? The psychology and ethics of persuasive robots (2015) A construction manual for robots’ ethical systems, pp. 63-81. , Trappl R, (ed), Springer, Basel; Harris, T., (2016) How technology hijacks people’s minds — from a magician and Google’s design ethicist, , http://www.tristanharris.com/2016/05/how-technology-hijacks-peoples-minds%e2%80%8a-%e2%80%8afrom-a-magician-and-googles-design-ethicist/, Accessed 12 June 2016; Hausman, D.M., Welch, B., Debate: to nudge or not to nudge (2010) J Polit Philos, 18 (1), pp. 123-136; Hern, A., (2016) Facebook, YouTube, , https://www.theguardian.com/technology/2016/may/31/facebook-youtube-twitter-microsoft-eu-hate-speech-code, Twitter and Microsoft sign EU hate speech code, The Guardian, Accessed 31 May 2016; Hoffman, G., Zuckerman, O., Hirschberger, G., Luria, M., Shani Sherman, T., Design and evaluation of a peripheral robotic conversation companion (2015) Proceedings of the tenth annual ACM/IEEE international conference on human–robot interaction, pp. 3-10; Hornyak, T., (2014) An AI milestone: chatbot passes turing test by posing as 13-year-old boy, , http://www.pcworld.com/article/2361220/computer-said-to-pass-turing-test-by-posing-as-a-teenager.html, PCWorld, Accessed 12 May 2016; Konrath, S., O’Brien, E., Hsing, C., Changes in dispositional empathy in American college students over time: a meta-analysis (2011) Personal Soc Psychol Rev, 15 (2), pp. 180-198; Kosner, A.W., (2014) Hooked: How to make habit-forming products, and when to stop flapping, , http://www.forbes.com/sites/anthonykosner/2014/02/17/hooked-how-to-make-habit-forming-products-and-when-to-stop-flapping, Forbes, Accessed 12 June 2016; Levy, D., (2007) Love and sex with robots, , Harper Perennial; Lin, P., Abney, K., Bekey, G.A., (2014) Robot ethics: the ethical and social implications of robotics, , eds), The MIT Press, Cambridge; Masunaga, S., (2016) Here are some of the tweets that got Microsoft’s AI Tay in trouble, , http://www.latimes.com/business/technology/la-fi-tn-microsoft-tay-tweets-20160325-htmlstory.html, Los Angeles Times, Accessed 6 June 2016; Mettler, K., (2016) Gen Con, major gaming convention, has more female than male speakers for the first time ever, making some gamers grumpy, , https://www.washingtonpost.com/news/morning-mix/wp/2016/05/18/gen-con-major-gaming-convention-has-more-female-than-male-speakers-for-the-first-time-ever-and-some-gamers-arent-happy-about-it/, The Washington Post, Accessed 18 May 2016; Moshkina, L., (2011) An integrative framework of time-varying affective robotic behavior, , Ph.D,. Dissertation, School of Interactive Computing, Georgia Institute of Technology; Moshkina, L., Arkin, R.C., (2005) Human perspective on affective robotic behavior: a longitudinal study. In: Proceedings of IROS-2005. Calgary, Canada; Nye, D.E., Technological prediction: a Promethean problem (2004) Technological visions: the hopes and fears that shape new technologies, pp. 159-176. , Sturken M, Thomas D, Ball-Rokeach SJ, (eds), Temple University Press, Philadelphia; Orwell, G., (1950), 1984., Penguin Publishing Group; Park, S., Moshkina, L., Arkin, R.C., Mood as an affective component for robotic behavior with continuous adaptation via learning momentum (2010) Proceedings of 10th IEEE-RAS international conference on humanoid robots (Humanoids, p. 2010. , In: Nashville, TN; Pettinati, M., Arkin, R.C., Towards a robot computational model to preserve dignity in stigmatizing patient–caregiver relationships (2015) International conference on social robotics (ICSR 2015, , In: Paris, France; Prinz, J.J., Is empathy necessary for morality? (2011) Empathy: philosophical and psychological perspectives, pp. 211-229. , Coplan A, Goldie P, (eds), Oxford University Press, New York; Reeves, B., Nass, C., (1996) The media equation: how people treat computers, television, and new media like real people and places, , Cambridge University Press, New York; Scasselati, B., Admoni, H., Mataric, M.J., Robots for use in autism research (2012) Annu Rev Biomed Eng, 14, pp. 275-294; Shim, J., Arkin, R.C., An intervening ethical governor for a robot mediator in patient-caregiver relationships (2015) International conference on robot ethics (ICRE, p. 2015. , In: Lisbon, Portugal; Stephan, A., Empathy for artificial agents (2015) Int J Soc Robot, 7, pp. 111-116; Stueber, K., (2014) Empathy. In: Zalta EN (ed) Stanford encyclopedia of philosophy, , http://plato.stanford.edu/archives/win2014/entries/empathy/, Accessed 1 June 2016; Swick, K., Nurturing decency through caring and serving during the early childhood years (2001) Early Child Educ J, 29 (2), pp. 131-137; Swick, K., Preventing violence through empathy development in families (2005) Early Child Educ J, 33 (1), pp. 53-59; Thaler, R.H., Sunstein, C.R., (2008) Nudge: improving decisions about health, wealth, and happiness, , Yale University Press, New Haven; Thomas, F., Johnston, O., (1981) The illusion of life: Disney animation. hyperion; Turkle, S., (1995) Life on the screen: identity in the age of the internet, , Simon and Schuster Paperbacks, New York; Turkle, S., (2005) Relational artifacts/children/elders: the complexities of cybercompanions, , Cognitive Science Society, Stresa; Turkle, S., (2011) Alone together: why we expect more from technology and less from each other, , Basic Books, New York; Turkle, S., (2015) Reclaiming conversation: The power of talk in a digital age, , Penguin Press, London; Vinik, D., (2015) Obama’s effort to ‘nudge’ America, , http://www.politico.com/agenda/story/2015/10/obamas-effort-to-nudge-america-000276, Politico, Accessed 1 July 2016; Wallach, W., Allen, C., (2009) Moral machines: teaching robots right from wrong, , Oxford University Press Inc, New York; Weigel, M., (2016) Flirting with humanity: the search for an artificial intelligence smart enough to love, , https://newrepublic.com/article/133034/flirting-humanity, New Republic, Accessed 19 May 2016; Whitby, B., Do you want a robot lover? The ethics of caring technologies (2012) Robot ethics: the ethical and social implications of robotics, pp. 233-248. , Lin P, Abney K, Bekey GA, (eds), MIT Press, Cambridge; House, W., (2015) Executive order—using behavioral science insights to better serve the American people, , https://www.whitehouse.gov/the-press-office/2015/09/15/executive-order-using-behavioral-science-insights-better-serve-american, Accessed 1 July 2016; Zinn, W., The empathic physician (1993) Arch Intern Med, 153 (3), pp. 306-312; Zuckerman, O., Hoffman, G., Empathy objects: Robotic devices as conversation companions (2015) Proceedings of the ninth international conference on tangible, embedded, and embodied interaction, pp. 593-598},
document_type={Article},
source={Scopus},
}

@ARTICLE{Musiał20171087,
author={Musiał, M.},
title={Designing (artificial) people to serve–the other side of the coin},
journal={Journal of Experimental and Theoretical Artificial Intelligence},
year={2017},
volume={29},
number={5},
pages={1087-1097},
doi={10.1080/0952813X.2017.1309691},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016453364&doi=10.1080%2f0952813X.2017.1309691&partnerID=40&md5=2af1495b765fb3b7048f32e291dadd2e},
abstract={This paper addresses the issue of the ethical obligations of human beings towards the robots that will achieve the status of persons. In particular the text investigates the ethical status of designing such robot-persons as servants. The author disagrees with Steve Petersen–who claims that we can design robot-persons as servants without wronging them by implementing the desire to serve into them. Following Jürgen Habermas critique of positive liberal eugenics, the author argues that any kind of intentional designing inevitably wrongs the designed beings regarding their freedom, autonomy, equality and identity. Moreover, some unintended consequences of developing robot-person servants are discussed. © 2017 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={designing;  eugenics;  robot ethics;  Robots;  servitude},
keywords={Philosophical aspects;  Robots, Can design;  designing;  eugenics;  Habermas;  Human being;  Robot ethics;  servitude;  Unintended consequences, Machine design},
references={Anderson, J., Habermas, Jürgen. The future of human nature. (book review) (2005) Ethics, 115, pp. 816-822; Bryson, J.J., Robots should be slaves (2010) Close engagements with artificial companions: Key social, psychological, ethical and design issues, pp. 63-74. , Wilks Y., (ed), Amsterdam: John Benjamins; Bryson, J.J., Why robot nannies probably won’t do much psychological damage (2010) Interaction Studies, 11, pp. 196-200; Bryson, J.J., Kime, P.P., Just an artifact: Why machines are perceived as moral agents (2011) Proceedings of the 22nd International Joint Conference on Artificial Intelligence, pp. 1641-1646. , Menlo Park, CA: AAAI Press; Carpenter, J., (2016) Culture and human-robot interaction in militarized spaces: A war story, , Surrey, Burlington: Ashgate; Carr, N., (2015) The glass cage: Where automation is taking us, , London: Bodley Head; Coeckelbergh, M., Robot rights? Towards a social-relational justification of moral consideration (2010) Ethics and Information Technology, 12, pp. 209-221. , https://doi.org/10.1007/s10676-010-9235-5; Coeckelbergh, M., (2012) Growing moral relations: Critique of moral status ascription, , Basingstoke; New York: Palgrave Macmillan; Darling, K., ‘Who’s Johnny?’ Anthropomorphic framing in human-robot interaction, integration, and policy Robot ethics 2.0, , in press, Lin P., Bekey G., Abney K., Jenkins R., (eds), Oxford: Oxford University Press; Fink, J., Bauwens, V., Kaplan, F., Dillenbourg, P., Living with a vacuum cleaning robot (2013) International Journal of Social Robotics, 5, pp. 389-408; Garber, M., Funerals for fallen robots: New research explores the deep bonds that can develop between soldiers and the machines that help keep them alive (2013) The Atlantic, , https://www.theatlantic.com/technology/archive/2013/09/funerals-for-fallen-robots/279861/, September; Garreau, J., Bots on the Ground (2007) The Washington Post, , http://www.washingtonpost.com/wp-dyn/content/article/2007/05/05/AR2007050501009.html, May; Gunkel, D.J., (2012) The machine question: critical perspectives on AI, robots, and ethics, , Cambridge, MA: MIT Press; Gunkel, D.J., A vindication of the rights of machines (2014) Philosophy and Technology, 27, pp. 113-132. , https://doi.org/10.1007/s13347-013-0121-z; Gutiu, S., (2012) Sex robots and robotization of consent, , http://robots.law.miami.edu/wp-content/uploads/2012/01/Gutiu-Roboticization_of_Consent.pdf, April, University of Miami School of Law; Habermas, J., (2003) The future of human nature, , Cambridge, UK: Polity; Levy, D., (2007) Robot prostitutes as alternatives to human sex workers, , http://www.roboethics.org/icra2007/contributions/LEVY%20Robot%20Prostitutes%20as%20Alternatives%20to%20Human%20Sex%20Workers.pdf; Levy, D., (2008) Love + sex with robots: the evolution of human-robot relationships, , New York, NY: Harper Perennial; Lundtröm, L., (2012) Äkta människor [Television series], , Sveriges Television (SVT): Stockholm; Musiał, M., Magical thinking and empathy towards robots (2016) What social robots can and should do. Proceedings of Robophilosophy 2016, pp. 347-355. , Seibt J., Nørskov M., Schack Andersen S., (eds), Amsterdam, Berlin, Tokyo, Washington: IOS Press; Petersen, S., The ethics of robot servitude (2007) Journal of Experimental and Theoretical Artificial Intelligence, 19, pp. 43-54; Petersen, S., Designing people to serve (2012) Robot ethics. The ethical and social implications of robotics, pp. 283-298. , Lin P., Bekey G., Abney K., (eds), Cambridge, MA; London: MIT Press; Prusak, B.G., Rethinking ‘liberal eugenics’: Reflections and questions on Habermas on bioethics (2005) Hastings Center Report, 35, pp. 31-42; Richardson, K., Sex robot matters: Slavery, the prostituted, and the rights of machines (2016) IEEE Technology and Society Magazine, 35, pp. 46-53; Richardson, K., The asymmetrical relationship: Parallels between prostitution and the development of sex robots (2016) ACM SIGCAS Computers and Society, 45, pp. 290-293; Rosenthal-von der Pütten, A.M., Krämer, N.C., Hoffmann, L., Sobieraj, S., Eimler, S.C., An experimental study on emotional reactions towards a robot (2013) International Journal of Social Robotics, 5, pp. 17-34; Rosenthal-von der Pütten, A.M., Schulte, F.P., Eimler, S.C., Sobieraj, S., Hoffmann, L., Maderwald, S., Krämer, N.C., Investigations on empathy towards humans and robots using fMRI (2014) Computers in Human Behavior, 33, pp. 201-212; Sandry, E., (2015) Robots and communication, , Palgrave MacMillan: Basingstoke; New York; Scheutz, M., The inherent dangers of unidirectional emotional bonds between humans and social robots (2012) Robot ethics. The ethical and social implications of robotics, pp. 205-222. , Lin P., Bekey G., Abney K., (eds), Cambridge, MA; London: MIT Press; Searle, J.R., Biological naturalism (2007) The Blackwell companion to consciousness, pp. 325-334. , Velmans M., Schneider S., (eds), Malden, MA; Oxford: Blackwell Publishing; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Minds and Machines, 16, pp. 141-161; Sung, J.-Y., Guo, L., Grinter, R.E., Christensen, H.I., ‘My roomba is rambo’: Intimate home appliances (2007) Proceeding for UbiComp 2007: Ubiquitous computing, pp. 145-162. , Krumm J., Abowd G.D., Seneviratne A., Strang T., (eds), Berlin, Heidelberg: Springer-Verlag; Suzuki, Y., Galli, L., Ikeda, A., Itakura, S., Kitazaki, M., Measuring empathy for human and robot hand pain using electroencephalography (2015) Scientific Reports, 5, p. 15924; Turkle, S., (2006) A nascent robotics culture: New complicities for companionship, , http://web.mit.edu/sturkle/www/pdfsforstwebpage/ST_Nascent%20Robotics%20Culture.pdf; Turkle, S., (2012) Alone together: why we expect more from technology and less from each other, , New York, NY: Basic Books; Turkle, S., (2015) Reclaiming conversation: The power of talk in a digital age, , New York, NY: Penguin Press; Turkle, S., Breazeal, C., Dasté, O., Scassellati, B., (2006) Encounters with kismet and cog: Children respond to relational artifacts, pp. 1-20. , Digital Media: Transformations in Human Communication; Turkle, S., Taggart, W., Kidd, C.D., Dasté, O., Relational artifacts with children and elders: the complexities of cybercompanionship (2006) Connection Science, 18, pp. 347-361; Walker, M., A moral paradox in the creation of artificial intelligence: Mary Poppins 3000s of the world unite (2006) Human implications of human-robot Interaction: Papers from the AAAI workshop, pp. 23-28. , http://www.aaai.org/Papers/Workshops/2006/WS-06-09/WS06-09-005.pdf; Walker, M., BIG and technological unemployment: Chicken little versus the economists (2014) Journal of Evolution & Technology, 24, pp. 5-25; Wallach, W., Allen, C., (2009) Moral machines: teaching robots right from wrong, , Oxford: Oxford University Press; Whitby, B., Oversold, unregulated, and unethical: Why we need to respond to robot nannies (2010) Interaction Studies, 11, pp. 290-294},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Malle2017195,
author={Malle, B.F. and Thapa Magar, S.},
title={What kind of mind do i want in my robot?: Developing a measure of desired mental capacities in social robots},
journal={ACM/IEEE International Conference on Human-Robot Interaction},
year={2017},
pages={195-196},
doi={10.1145/3029798.3038378},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016397363&doi=10.1145%2f3029798.3038378&partnerID=40&md5=4c8f049d687ca01fe7771124b02086bb},
abstract={We took a first step in developing a measurement tool for the social and mental capacities that people desire in social robots. 291 respondents indicated the degree to which they would like to see 16 capacities in either a home robot, nursing robot, or military robot. Four orthogonal dimensions emerged: Social-Moral Skills, Autonomous Evaluation, Objective Reasoning, and Negative Feelings. These dimensions were robust across the three robot types and across two assessment years (2013 and 2016). © 2017 Authors.},
author_keywords={human-robot interaction;  robot design;  robot ethics;  social robots},
keywords={Machine design;  Man machine systems;  Robots, Home robot;  Measurement tools;  Mental capacities;  Military robots;  Robot designs;  Robot ethics;  Social robots, Human robot interaction},
references={Goetz, J., Matching robot appearance and behavior to tasks to improve human-robot cooperation (2003) The 12th IEEE International Workshop on Robot and Human Interactive Communication, 2003, pp. 55-60. , Oct; Gray, H.M., Dimensions of mind perception (2007) Science, 315, p. 5812. , Feb. 2007, 619-619; Haring, K.S., How people perceive different robot types: A direct comparison of an android, humanoid, and non-biomimetic robot (2016) Proceedings of the 8th International Conference on Knowledge and Smart Technology (KST), 2016. IEEE, pp. 265-270; Malle, B.F., Scheutz, M., Moral competence in social robots (2014) Proceedings of IEEE International Symposium on Ethics in Engineering, Science, and Technology, Ethics2014. IEEE, pp. 30-35; Sytsma, J., (2014) The Robots of the Dawn of Experimental Philosophy. Current Controversies in Experimental Philosophy, pp. 48-64. , E. Machery & E. ONeill, eds. Routledge; Wallach, W., Allen, C., (2008) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Borges2017199,
author={Borges, J.V.},
title={Robots and the military: A strategic view},
journal={Intelligent Systems, Control and Automation: Science and Engineering},
year={2017},
volume={84},
pages={199-205},
doi={10.1007/978-3-319-46667-5_15},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010430903&doi=10.1007%2f978-3-319-46667-5_15&partnerID=40&md5=56118838a96113c19ad4a887ba3f1d0a},
abstract={This paper views the theme of robotics in the military domain from a strategic perspective, bearing in mind the new paradigm of security and defense, where robots will have an increasing intervention. Considering the trilogy that strategy comprehends—goals, means and threats, three fundamental topics are approached: (i) the need to work at political, strategical, operational and tactical levels (ii) the role of robots in the new security and defense environment (iii) the importance of incorporating robots in the military formation. As a conclusion, this paper also highlights the importance of introducing the major issues associated with robots, from artificial intelligence to robot ethics, in the curricula, research and training carried out at military schools with the purpose of preparing military commanders for a future where robots will most likely have a prominent role. © Springer International Publishing AG 2017.},
author_keywords={Education;  Military strategy;  Robots;  Security and defense;  Threats},
references={Arkin, R., (2009) Governing Lethal Behavior in Autonomous Robots, , CRC Press, New York; Arkin, R., (2013) Lethal Autonomous Systems and the Plight of the Non-Combatant, , https://smartech.gatech.edu/bitstream/handle/1853/50079/aisbq-137.pdf?sequence=1, AISB Q (137), Accessed 25 Mar 2016; Asimov, I., (1950) Robot, , Gnome Press, New York; NATO/multinational joint intelligence (2015) A Feasibility Study, Surveillance and Reconnaissance Unit; Singer, P., (2009) Wired for War: The Robotics Revolution and Conflict in The 21St Century, , The Penguin Press, New York},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Bringsjord201747,
author={Bringsjord, S.},
title={A 21st-century ethical hierarchy for robots and persons: ℰℋ},
journal={Intelligent Systems, Control and Automation: Science and Engineering},
year={2017},
volume={84},
pages={47-61},
doi={10.1007/978-3-319-46667-5_4},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010409234&doi=10.1007%2f978-3-319-46667-5_4&partnerID=40&md5=b08b5d11d9d64db9cecf18416ee440a3},
abstract={I introduce and propose the ethical hierarchy (ℰℋ) into which can be placed robots and humans in general. This hierarchy is catalyzed by the question: Can robots be more moral than humans? The light shed by ℰℋ reveals why an emphasis on legal obligation for robots, while not unwise at the moment, is inadequate, and why at least the vast majority of today’s state-of-the-art deontic logics are morally inexpressive, whether they are intended to formalize the ethical behavior of robots or persons. © Springer International Publishing AG 2017.},
author_keywords={Deontic logic;  Ethical hierarchy;  Ethics;  Machine ethics;  Robot ethics},
references={Arkin, R., (2009) Governing Lethal Behavior in Autonomous Robots, , Chapman and Hall/CRC, New York; Arkoudas, K., Bringsjord, S., Bello, P., Toward ethical robots via mechanized deontic logic (2005) Machine Ethics: Papers from the AAAI Fall Symposium; FS–05–06, pp. 17-23. , http://www.aaai.org/Library/Symposia/Fall/fs05-06.php, American Association for Artificial Intelligence, Menlo Park, CA; Bello, P., Toward a logical framework for cognitive effects-based operations: Some empirical and computational results (2005) Rensselaer Polytechnic Institute, , PhD thesis, RPI), Troy, NY; Bello, P., Bringsjord, S., On how to build a moral machine (2013) Topoi, 32 (2), pp. 251-266. , http://kryten.mm.rpi.edu/Topoi.MachineEthics.finaldraft.pdf; Block, N., On a confusion about a function of consciousness (1995) Behav Brain Sci, 18, pp. 227-247; Bringsjord, S., (1992) What Robots Can and can’t Be, , Kluwer, Dordrecht; Bringsjord, S., The zombie attack on the computational conception of mind (1999) Philos Phenomenol Res, 59 (1), pp. 41-69; Bringsjord, S., Offer: One billion dollars for a conscious robot. If you’re honest, you must decline (2007) J Conscious Stud, 14 (7), pp. 28-43. , http://kryten.mm.rpi.edu/jcsonebillion2.pdf; Bringsjord, S., Declarative/logic-based cognitive modeling (2008) The Handbook of Computational Psychology, pp. 127-169. , http://kryten.mm.rpi.edu/sb_lccm_ab-toc_031607.pdf, Sun R, Cambridge University Press, Cambridge; Bringsjord, S., The logicist manifesto: At long last let logic-based ai become a field unto itself (2008) J Appl Logic, 6 (4), pp. 502-525. , http://kryten.mm.rpi.edu/SB_LAI_Manifesto_091808.pdf; Bringsjord, S., Ferrucci, D., Logic and artificial intelligence: Divorced, still married, separated? (1998) Minds Mach, 8, pp. 273-308; Bringsjord, S., Govindarajulu, N.S., Toward a modern geography of minds, machines, and math (2013) Philosophy and Theory of Artificial Intelligence, Studies in Applied Philosophy, Epistemology and Rational Ethics, 5, pp. 151-165. , http://www.springerlink.com/content/hg712w4l23523xw5, Müller VC (ed), Springer, New York; Bringsjord, S., Licato, J., By disanalogy, cyberwarfare is utterly new (2015) Philos Technol, 28 (3), pp. 339-358. , http://kryten.mm.rpi.edu/SB_JL_cyberwarfare_disanalogy_DRIVER_final.pdf; Bringsjord, S., Licato, J., Crossbows, von Clauswitz, and the eternality of software shrouds: Reply to christianson (2015) Philos Technol, 28 (3), pp. 365-367. , http://kryten.mm.rpi.edu/SB_JL_on_BC.pdf, The url here is to a preprint only; Bringsjord, S., Taylor, J., The divine-command approach to robot ethics (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 85-108. , http://kryten.mm.rpi.edu/Divine-Command_Roboethics_Bringsjord_Taylor.pdf, Lin P, Bekey G, Abney K, MIT Press, Cambridge; Bringsjord, S., Zenzen, M., (2003) Superminds: People Harness Hypercomputation, and More, , Kluwer Academic Publishers, Dordrecht; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intell Syst, 21 (4), pp. 38-44. , http://kryten.mm.rpi.edu/bringsjord_inference:robot_ethics_preprint.pdf; Bringsjord, S., Kellett, O., Shilliday, A., Taylor, J., van Heuveln, B., Yang, Y., Baumes, J., Ross, K., A New Gödelian argument for hypercomputing minds based on the busy beaver problem (2006) Appl Math Comput, 176, pp. 516-530; Bringsjord, S., Taylor, J., Shilliday, A., Clark, M., Arkoudas, K., Slate: An argument-centered intelligent assistant to human reasoners (2008) Proceedings of the 8th International Workshop on Computational Models of Natural Argument (CMNA 8), pp. 1-10. , http://kryten.mm.rpi.edu/Bringsjord_etal_Slate_cmna_crc_061708.pdf, Grasso F, Green N, Kibble R, Reed C, University of Patras, Patras, Greece; Chellas, B.F., (1980) Modal Logic: An Introduction, , Cambridge University Press, Cambridge; Chisholm, R., Contrary-to-duty imperatives and deontic logic (1963) Analysis, 24, pp. 33-36; Chisholm, R., Supererogation and offence: A conceptual scheme for ethics (1982) Brentano and Meinong Studies, pp. 98-113. , Chisholm R, Humanities Press, Atlantic Highlands; Chisholm, R., (1986) Brentano and Intrinsic Value, , Cambridge University Press, Cambridge; Clark, M., (2008) Cognitive Illusions and the Lying Machine, , PhD thesis, Rensselaer Polytechnic Institute (RPI); Davis, M., Sigal, R., Weyuker, E., (1994) Computability, Complexity, and Languages: Fundamentals of Theoretical Computer Science, , Academic Press, New York; Ganascia, J.G., Modeling ethical rules of lying with answer set programming (2007) Ethics Inf Technol, 9, pp. 39-47; Govindarajulu, N.S., Bringsjord, S., Ethical regulation of robots must be embedded in their operating systems (2015) A Construction Manual for robots’ Ethical Systems: Requirements, Methods, Implementations, pp. 85-100. , http://kryten.mm.rpi.edu/NSG_SB_Ethical_Robots_Op_Sys_0120141500.pdf, Trappl R, Springer, Basel; Ladd, J., (1957) The Structure of a Moral Code, , Harvard University Press, Cambridge; Malle, B.F., Guglielmo, S., Monroe, A., Moral, cognitive, and social: The nature of blame (2012) Social Thinking and Interpersonal Behavior, pp. 313-331. , Forgas J, Fiedler K, Sedikides C, Psychology Press, Philadelphia; Powers, T., Prospects for a Kantian machine (2006) IEEE Intell Syst, 21, p. 4; Saptawijaya, A., Pereira, L.M., The potential of logic programming as a computational tool to model morality (2016) A Construction Manual for robots’ Ethical Systems, , http://centria.di.fct.unl.pt/~lmp/publications/online-papers/ofai_book.pdf, Trappl R (ed), Springer, Cham; Schermerhorn, P., Kramer, J., Brick, T., Anderson, D., Dingler, A., Scheutz, M., DIARC: A testbed for natural human-robot interactions (2006) Proceedings of AAAI 2006 Mobile Robot Workshop; Scheutz, M., Arnold, T., (2016) Feats without Heroes: Norms, Means, and Ideal Robotic Action, , Front Robot AI; Schmitt, M., (2013) Tallinn Manual on the International Law Applicable to Cyber Warfare, , Cambridge University Press, Cambridge, UK, This volume was first published in 2011. While M Schmitt is the General Editor, there were numerous contributors, falling under the phrase ‘International Group of Experts at the Invitation of the NATO Cooperative Cyber Defence Centre of Excellence’; Suppes, P., (1972) Axiomatic Set Theory, , Dover Publications, New York; Urmson, J.O., Saints and heroes (1958) Essays in Moral Philosophy, pp. 198-216. , Melden A, University of Washington Press, Seattle; von Wright, G., (1951) Deontic Logic. Mind, 60, pp. 1-15; Winfield, A., Blum, C., Liu, W., Towards an ethical robot: Internal models, consequences and ethical action selection (2014) Advances in Autonomous Robotics Systems. Lecture Notes in Computer Science (LNCS), 8717, pp. 85-96. , Mistry M, Leonardis A, Witkowski M, Melhuish C, Springer, Cham; Youpa, A., Leibniz’s ethics (2013) The Stanford Encyclopedia of Philosophy, the Metaphysics Research Lab, Center for the Study of Language and Information, , http://plato.stanford.edu/entries/leibniz-ethics, Zalta E (ed), Stanford University},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{McBride201676,
author={McBride, N. and Hoffman, R.R.},
title={Bridging the Ethical Gap: From Human Principles to Robot Instructions},
journal={IEEE Intelligent Systems},
year={2016},
volume={31},
number={5},
pages={76-82},
doi={10.1109/MIS.2016.87},
art_number={7579396},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991434315&doi=10.1109%2fMIS.2016.87&partnerID=40&md5=abcba79793c2831d62872df8b6ef6a7b},
abstract={Asimov's three laws of robotics and the Murphy-Woods alternative laws assume that a robot has the cognitive ability to make moral decisions, and fail to escape the myth of self-sufficiency. But ethical decision making on the part of robots in human-robot interaction is grounded on the interdependence of human and machine. Furthermore, the proposed laws are high-level principles that cannot easily be translated into machine instructions because there is an immense gap between the architecture, implementation, and activity of humans and robots in addressing ethical situations. The characterization of the ethical gap, particularly with reference to the Murphy-Woods laws, leads to a proposal for a shift in focus away from the autonomous behavior of the robot to human-robot communication at the interface, and the development of interdependence rules to underpin the process of ethical decision-making. © 2001-2011 IEEE.},
author_keywords={ethical gap;  ethical interdependence;  human-robot interface;  intelligent systems;  laws of robotics;  robot ethics},
keywords={Decision making;  Human computer interaction;  Intelligent robots;  Intelligent systems;  Philosophical aspects;  Robotics;  Robots, Autonomous behaviors;  Ethical decision making;  ethical gap;  ethical interdependence;  Human-robot communication;  Human-Robot Interface;  Machine instructions;  Robot ethics, Human robot interaction},
references={Bizony, P., Asimov's Three Laws of Robotics (2015) Eng. and Technology Magazine, , http://eandt.theiet.org/magazine/2015/06/asimov-3-laws-robotics.cfm, 15 June; Capek, K., (1920) Rossum's Universal Robots, , Penguin; Asimov, I., Robot, I., (1950) Gnome Press; Murphy, R.R., Woods, D.D., Beyond Asimov: The Three Laws of Responsible Robotics (2009) IEEE Intelligent Systems, pp. 14-18. , July/Aug; Bradshaw, J.M., The Seven Deadly Myths of 'Autonomous Systems (2013) IEEE Intelligent Systems, May/June, pp. 54-61; Hoffman, R.R., Hawley, J.K., Bradshaw, J.M., Myths of Automation Part 2: Some Very Human Consequences (2014) IEEE Intelligent Systems, pp. 82-85. , Mar./Apr; Johnson, M., Seven Cardinal Virtues of Human-Machine Teamwork (2014) IEEE Intelligent Systems, pp. 74-79. , Nov./Dec; Newman, R., Can Robots Be Ethical? (2015) Philosophy Now, pp. 30-32. , Oct./Nov; Hursthouse, R., (1999) On Virtue Ethics, , Oxford Univ. Press; Von Neumann, J., (1958) The Computer and the Brain, , Yale Univ. Press; McBride, N., Stahl, B., Developing Responsible Research and Innovation for Robotics (2014) Proc. IEEE Int'l Symp. Ethics in Science, Technology, and Eng; Christofferson, K., Woods, D.D., How to Make Automated Systems Team Players (2002) Advances in Human Performance and Cognitive Eng. Research, 2, pp. 1-12. , Elsevier Science; Hoffman, R.R., Trust in Automation (2013) IEEE Intelligent Systems, pp. 84-88. , Jan./Feb; Hoffman, R.R., A Rose by Any Other Name ... Would Probably Be Given an Acronym (2002) IEEE Intelligent Systems, pp. 72-80. , July/Aug; Pitsch, K., Limits and Opportunities for Mathematicizing Communicational Conduct for Social Robotics in the Real World? Toward Enabling the Robot to Make Use of the Human's Competencies (2015) AI and Society, , 22 Dec; Ashby, W.R., Requisite Variety and Its Implications for the Control of Complex Systems (1958) Cybernetica, 1, pp. 83-99; Klein, G., Ten Challenges for Making Automation a 'Team Player' in Joint Human-Agent Activity (2004) IEEE Intelligent Systems, pp. 91-95. , Nov./Dec},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sullins201637,
author={Sullins, J.},
title={Artificial phronesis and the social robot},
journal={Frontiers in Artificial Intelligence and Applications},
year={2016},
volume={290},
pages={37-39},
doi={10.3233/978-1-61499-708-5-37},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992562717&doi=10.3233%2f978-1-61499-708-5-37&partnerID=40&md5=f4d86bc9dbe933d71c916a64049a72b2},
author_keywords={Action planning;  Artificial general intelligence (AGI);  Inductive reasoning;  Limitations of machine learning;  Machine ethics;  Machine morality;  Phronesis;  Practical reasoning;  Robot ethics;  Skills},
references={(1985) Hackett, Indianapolis, p. 151. , Aristotle, Nichomachean Ethics, Irwin, Terrance (ed.); Wallach, W., Allen, C., (2010) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press, Oxford; Danielson, P., (1992) Artificial Morality: Virtuous Robots for Virtual Games, , Routledge; Danielson, P., (1998) Modeling Rationality, Morality, and Evolution, , Oxford University Press, Oxford; Danielson, P., Designing a machine to learn about the ethics of robotics: The N-reasons platform (2010) Ethics and Information Technology, 12 (3), pp. 251-261; Wallach, W., Franklin, S., Allen, C., Conceptual, A., And Computational Model of Moral Decision Making in Human and Artificial Agents (2010) Topics in Cognitive Science, 2 (3), pp. 454-485; White, J., Manufacturing Morality A general theory of moral agency grounding computational implementations: The ACTWith model (2013) Computational Intelligence, Nova Publications, pp. 1-65. , Floares (ed.); Dewey, J., Evolution and Ethics (1998) The Essential Dewey, 2, pp. 225-236. , Hickman, L. and Alexander, T, (eds.), Indiana University Press; Dewey, J., The Influence of Darwinism on Philosophy (1998) The Essential Dewey, 1, pp. 39-45. , Hickman, L. and Alexander, T, (eds.), Indiana University Press; Rogers, M.L., Action and Inquiry in Dewey's Philosophy (2007) Transactions of the Charles S. Peirce Society, 43 (1), pp. 90-115},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Atkinson2015109,
author={Atkinson, D.J.},
title={Robot Trustworthiness: Guidelines for Simulated Emotion},
journal={ACM/IEEE International Conference on Human-Robot Interaction},
year={2015},
volume={02-05-March-2015},
pages={109-110},
doi={10.1145/2701973.2701976},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969217109&doi=10.1145%2f2701973.2701976&partnerID=40&md5=4225eb9819e0ec286c0141225d7c9b3e},
abstract={Well-justified human evaluations of autonomous robot trustworthiness require evidence from a variety of sources, including observation of robot behavior. Displays of affect by a robot that reflect important internal states not otherwise overtly visible could provide useful evidence for evaluation of robot agent trustworthiness. As an analogy, the human limbic system, sometimes described as an ancient sub-cognitive system, drives human display of affect in a manner that is largely independent of purposeful behavior arising from cognition. Such displays of affect and corresponding attributions of emotion provide important social information that aids understanding and prediction of human behavior. Could an "artificial limbic system" provide similar useful insight into a robot's internal state? The value of affect signals for evaluation of robot trustworthiness depends on three crucial factors that require investigation: 1) Correlation of affective signals to trust-related, measurable attributes of robot agent internal state, 2) Fidelity in portrayal of emotion by the robot agent such that affective signals evoke human anthropomorphic social recognition, and 3) Correct human interpretation of the affective signals for justifiable modulation of beliefs about the robot agent. This paper discusses these three factors as principles to guide robotic simulation of emotion for increasing human ability to make reasonable assessments of robot trustworthiness and appropriate reliance. © 2015 Author.},
author_keywords={Affective computing;  artificial intelligence;  human-robot interaction;  intelligent robots;  robot ethics;  social robots;  trust},
keywords={Anthropomorphic robots;  Artificial intelligence;  Behavioral research;  Brain;  Cognitive systems;  Human computer interaction;  Intelligent robots;  Man machine systems;  Robots, Affective Computing;  Human evaluation;  Robot ethics;  Robotic simulation;  Social information;  Social recognition;  Social robots;  trust, Human robot interaction},
references={Antos, D., Melo, C.D., Gratch, J., Grosz, B., The influence of emotion expression on perceptions of trustworthiness in negotiation (2011) PROC 25 AAAI CONF AI., pp. 772-778. , Menlo Park: AAAI Press; Atkinson, D.J., Clark, M.H., Autonomous agents and human interpersonal trust: Can we engineer a human-machine social interface for trust? (2013) Trust and Autonomous Systems: Papers from the 2013 AAAI Spring Symposium, , TECH REP SS-13-07, Menlo Park: AAAI Press; Thomas Boone, R., Buck, R., Emotional expressivity and trustworthiness: The role of nonverbal behavior in the evolution of cooperation (2003) Journal of Nonverbal Behavior., 27 (3), p. 163. , Academic Research Library; Coeckelbergh, M., Are emotional robots deceptive? (2012) Affective Comp IEEE Trans, 3 (4), pp. 388-393. , DOI: 10.1109/T-AFFC.2011.29; Cramer, H., Goddijn, J., Wielinga, B., Evers, V., Effects of (in) accurate empathy and situational valence on attitudes towards robots (2010) PROC 5th Acm Ieee Int Conf Hri, pp. 141-142; De Melo, C., Zheng, L., Gratch, J., Expression of moral emotions in cooperating agents (2009) PROC 9TH INT CONF on Intelligent Virtual Agents. Amsterdam; Haidt, J., The moral emotions (2003) Handbook of Affective Sciences, , Oxford Press; Lee, J.J., Modeling the dynamics of nonverbal behavior on interpersonal trust for human-robot interactions (2013) Trust and Autonomous Systems: Papers from the 2013 AAAI Spring Symposium, , TECH REP SS-13-07, Menlo Park: AAAI Press; Lee, J.J., Knox, W.B., Wormwood, J.B., Brazeal, C., DeSteno, D., Computationally modeling interpersonal trust (2013) Front. Psychol; Panksepp, J., Instinctual emotional apparatus of the mammalian body and brain (2005) Journal of Consciousness Studies., 12 (8-10), pp. 158-218},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Daswani2015231,
author={Daswani, M. and Leike, J.},
title={A definition of happiness for reinforcement learning agents},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9205},
pages={231-240},
doi={10.1007/978-3-319-21365-1_24},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952837732&doi=10.1007%2f978-3-319-21365-1_24&partnerID=40&md5=df2a78f6611e8c36adafec07fb9703a4},
abstract={What is happiness for reinforcement learning agents? We seek a formal definition satisfying a list of desiderata. Our proposed definition of happiness is the temporal difference error, i.e. the difference between the value of the obtained reward and observation and the agent’s expectation of this value. This definition satisfies most of our desiderata and is compatible with empirical research on humans. We state several implications and discuss examples. © Springer International Publishing Switzerland 2015.},
author_keywords={Machine ethics;  Optimism;  Pleasure;  Reward prediction error;  Temporal difference error;  Well-being},
keywords={Errors;  Intelligent agents, Optimism;  Pleasure;  Reward-prediction error;  Temporal difference errors;  Well being, Reinforcement learning},
references={Bostrom, N., (2014) Superintelligence: Paths, Dangers, , Oxford University Press, Strategies; Brickman, P., Campbell, D.T., (1971) Hedonic relativism and planning the good society, pp. 287-305. , Adaptation-Level Theory; Brickman, P., Coates, D., Janoff-Bulman, R., Lottery winners and accident victims: Is happiness relative? (1978) Journal of Personality and Social Psychology, 36, p. 917; Daswani, M., Leike, J., (2015) A definition of happiness for reinforcement learning agents, , http://arxiv.org/abs/1505.04497, Technical report, Australian National University; Diener, E., Lucas, R.E., Scollon, C.N., Beyond the hedonic treadmill: Revising the adaptation theory of well-being (2006) American Psychologist, 61, p. 305; Jacobs, E., Broekens, J., Jonker, C., Joy, distress, hope, and fear in reinforcement learning (2014) Conference on Autonomous Agents and Multiagent Systems, pp. 1615-1616; Niv, Y., Reinforcement learning in the brain (2009) Journal of Mathematical Psychology, 53, pp. 139-154; Rutledge, R.B., Skandali, N., Dayan, P., Dolan, R.J., A computational and neural model of momentary subjective well-being (2014) Proceedings of the National Academy of Sciences; Schmidhuber, J., Formal theory of creativity, fun, and intrinsic motivation (1990-2010) (2010) IEEE Transactions on Autonomous Mental Development, 2, pp. 230-247; Sutton, R., Barto, A., Time-derivative models of Pavlovian reinforcement (1990) Learning and Computational Neuroscience: Foundations of Adaptive Networks, pp. 497-537. , MIT Press; Sutton, R.S., Barto, A.G., (1998) Reinforcement Learning: An Introduction, , MIT Press, Cambridge; Tomasik, B., (2014) Do artificial reinforcement-learning agents matter morally? Technical report, , http://arxiv.org/abs/1410.8233, Foundational Research Institute},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Tavani201575,
author={Tavani, H.T.},
title={Levels of Trust in the Context of Machine Ethics},
journal={Philosophy and Technology},
year={2015},
volume={28},
number={1},
pages={75-90},
doi={10.1007/s13347-014-0165-8},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924390390&doi=10.1007%2fs13347-014-0165-8&partnerID=40&md5=84ff6aaf4f49c01cd646ab4a41b4daca},
abstract={Are trust relationships involving humans and artificial agents (AAs) possible? This controversial question has become a hotly debated topic in the emerging field of machine ethics. Employing a model of trust advanced by Buechner and Tavani (Ethics and Information Technology 13(1):39–51, 2011), I argue that the “short answer” to this question is yes. However, I also argue that a more complete and nuanced answer will require us to articulate the various levels of trust that are also possible in environments comprising both human agents (HAs) and AAs. In defending this view, I show how James Moor’s model for distinguishing four levels of ethical agents in the context of machine ethics (Moor, IEEE Intelligent Systems 21(4):18–21, 2006) can help us to develop a framework that differentiates four (loosely corresponding) levels of trust. Via a series of hypothetical scenarios, I illustrate each level of trust involved in HA–AA relationships. Finally, I argue that these levels of trust reflect three key factors or variables: (i) the level of autonomy of the individual AAs involved, (ii) the degree of risk/vulnerability on the part of the HAs who place their trust in the AAs, and (iii) the kind of interactions (direct vs. indirect) that occur between the HAs and AAs in the trust environments. © 2014, Springer Science+Business Media Dordrecht.},
author_keywords={Artificial agents;  Autonomy;  Ethical agents;  Machine ethics;  Trust},
references={Anderson, M., Anderson, S.L., (2011) Machine ethics, , (eds), Cambridge University Press, Cambridge:; Baier, A., Trust and antitrust (1986) Ethics, 96 (2), pp. 231-260; Buechner, J., Trust, privacy, and frame problems in social and business E-networks (2011) Information, 2 (1), pp. 195-216; Buechner, J., Tavani, H.T., Trust and multi-agent systems: applying the ‘diffuse, default model’ of trust to experiments involving artificial agents (2011) Ethics and Information Technology, 13 (1), pp. 39-51; Buechner, J., Simon, J., Tavani, H.T., Re-Thinking trust and trustworthiness in digital environments (2014) Ambiguous technologies: philosophical issues, practical solutions, human nature: Proceedings of the Tenth International Conference on Computer Ethics—philosophical enquiry, pp. 65-79. , Buchanan E, (ed), INSEIT, Menomonie, WI:; Carr, L.J., Trust: an analysis of some aspects (2012) Available at, , http://www.rivier.edu/faculty/lcarr/Trust%20-%20an%20analysis%20of%20some%20aspects.pdf; Coeckelbergh, M., Moral appearances: emotions, robots, and human morality (2010) Ethics and Information Technology, 12 (3), pp. 235-241; Coeckelbergh, M., Can we trust robots? (2012) Ethics and Information Technology, 14 (1), pp. 53-60; Decker, M., Gutmann, M., (2012) Robo-and-Information ethics: some fundamentals, , (eds), LIT, Berlin, Germany:; deVries, W., Some forms of trust (2011) Information, 2 (1), pp. 1-16; Durante, M., What is the model of trust for multi-agent systems? Whether or not E-trust applies to autonomous agents (2010) Knowledge, Technology and Policy, 23, pp. 347-366; Durante, M., The online construction of personal identity through trust and privacy (2011) Information, 2, pp. 594-620; Floridi, L., Foundations of information ethics (2008) The handbook of information and computer ethics, pp. 3-23. , Himma KE, Tavani HT, (eds), John Wiley and Sons, Hoboken, NJ:; Floridi, L., On the morality of artificial agents (2011) Machine ethics, pp. 184-2012. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge:; Grodzinsky, F.S., Miller, K., Wolf, M.J., Developing artificial agents worthy of trust: ‘would you buy a used car from this artificial agent?’ (2011) Ethics and Information Technology, 13 (1), pp. 17-27; Himma, K.E., Artificial agency, consciousness, and the criteria for moral agency: what properties must an artificial agent have to be a moral agent? (2009) Ethics and Information Technology, 11 (1), pp. 19-29; Johnson, D.G., Computer systems: moral entities but not moral agents (2006) Ethics and Information Technology, 8 (4), pp. 195-204; Lim, H.C., Stocker, R., Larkin, H., Review of trust and machine ethics research: towards a bio-inspired computational model of ethical trust (CMET). In Proceedings of the 3rd International Conference on Bio-Inspired Models of Network, Information, and Computing Systems. Hyogo, Japan, Nov. 25–27 (2008) Article No, p. 8; Lin, P., Abney, K., Bekey, G.A., (2012) Robot ethics: the ethical and social implications of robotics, , (eds), MIT Press, Cambridge, MA:; McLeod, C., Trust. In E. N (2011) Zalta, , http://plato.stanford.edu/archives/spr2011/entries/trust/, Ed.: Stanford Encyclopedia of Philosophy; Moor, J.H., What is computer ethics? (1985) Metaphilosophy, 16 (4), pp. 266-275; Moor, J.H., Towards a theory of privacy for the information age (1997) Computers and Society, 27 (3), pp. 27-32; Moor, J.H., The nature, difficulty, and importance of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Nissenbaum, H., Privacy as contextual integrity (2004) Washington Law Review, 79 (1), pp. 119-157; Nissenbaum, H., (2010) Privacy in context: technology, policy, and the integrity of social life, , Stanford University Press, Palo Alto, CA:; Autonomous systems: social, legal and ethical issues (2009) London, , www.raeng.org.uk/autonomoussystems; Simon, J., The entanglement of trust and knowledge on the web (2010) Ethics and Information Technology, 12 (4), pp. 343-355; Taddeo, M., Defining trust and E-trust: old theories and new problems (2009) International Journal of Technology and Human Interaction, 5 (2), pp. 23-35; Taddeo, M., Modeling trust in artificial agents: a first step in the analysis of E-trust (2010) Minds and Machines, 20 (2), pp. 243-257; Taddeo, M., Trust in technology: a distinctive and problematic relationship. Special Issue of Knowledge (2010) Technology and Policy 23(3–4); Taddeo, M., Floridi, L., The case for E-trust: a new ethical challenge (2011) Special Issue of Ethics and Information Technology 13(1); Tavani, H.T., Can we develop artificial agents capable of making good moral decisions? (2011) Minds and Machines, 21, pp. 465-474; Tavani, H.T., Ethical aspects of autonomous systems (2012) Robo-and-information ethics: some fundamentals, pp. 89-122. , Decker M, Gutmann M, (eds), LIT, Berlin, Germany:; Tavani, H.T., (2013) Ethics and technology: controversies, questions, and strategies for ethical computing, , John Wiley and Sons, Hoboken, NJ:; Tavani, H. T., & Buechner, J. (in press). Autonomy and trust in the context of artificial agents. In M. Decker & M. Gutmann (Eds.), Evolutionary robotics, organic computing, and adaptive ambience. Berlin, Germany: LIT; Tavani, H.T., Arnold, D., Trust and privacy in a networked world (2011) Special Issue of Information 2(4); Turkle, S., Authenticity in the age of digital companions (2011) Machine ethics, pp. 62-78. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge:; http://www.roboethics.org/atelier2006/docs/ROBOETHICS%20ROADMAP%20Rel2.1.1.pdf, Verrugio, G. (2006). EURON roboethics roadmap (Release 1.1). In G. Verrugio (Ed),. EURON roboethics atelier. Genoa, Italy. Available at; Walker, M.U., (2006) Moral repair: reconstructing moral relations after wrongdoing, , Cambridge University Press, Cambridge:; Wallach, W., Allen, C., (2009) Moral machines: teaching robots right from wrong, , Oxford University Press, New York:},
document_type={Article},
source={Scopus},
}

@ARTICLE{Anderson201567,
author={Anderson, S.L. and Anderson, M.},
title={Towards a principle-based healthcare agent},
journal={Intelligent Systems, Control and Automation: Science and Engineering},
year={2015},
volume={74},
pages={67-77},
doi={10.1007/978-3-319-08108-3_5},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921327706&doi=10.1007%2f978-3-319-08108-3_5&partnerID=40&md5=3bb7921f271ef9fbc8ac7d7dcf3acf97},
abstract={To feel comfortable allowing healthcare robots to interact with human beings, we must ensure that they act in an ethically responsible manner, following an acceptable ethical principle(s). Giving robots ethical principles to guide their behavior results in their being ethical agents; yet we argue that it is the human designers, not the robots, who should be held responsible for their actions. Towards the end of designing ethical autonomous robots that function in the domain of healthcare, we have developed a method, through an automated dialogue with an ethicist, for discovering the ethically relevant features of possible actions that could be taken by a robot, with an appropriate range of intensities, prima facie duties to either maximize or minimize those features, as well as decision principles that should be used to guide its behavior. Our vision of how an ethical robot assistant would behave demonstrates that an ethical principle is used to select the best action at each moment, rather than just determine whether a particular action is acceptable or not. Further, we maintain that machine ethics research gives us a fresh perspective on ethics. We believe that there is a good chance that this research may lead to surprising new insights, and therefore breakthroughs, in ethical theory. © Springer International Publishing Switzerland 2015.},
references={Anderson, M., Anderson, S., EthEl: Toward a principled ethical eldercare robot (2008) Proceedings of conference on human-robot interaction, p. 2008. , Amsterdam, The Netherlands, March; Anderson, M., Anderson, S., GenEth: A general ethical dilemma analyzer (2013) Proceedings of the eleventh international symposium on logical formalizations of commonsense reasoning, , Ayia Napa, Cyprus, May 2013; Anderson, M., Anderson, S.L., Robot be good (2010) Sci Am Mag; Anderson, M., Anderson, S., Armen, C., MedEthEx: A prototype medical ethics advisor (2006) Proceedings of the eighteenth conference on innovative applications of artificial intelligence, , Boston, Massachusetts, August 2006; Anderson, S., The libertarian conception of freedom (1981) Int Philos Q, 21 (4), pp. 391-404; Beauchamp, T.L., Childress, J.F., (1979) Principles of biomedical ethics, , Oxford University Press, Oxford; Bentham, J., (1780) Introduction to principles of morals and legislation; Hume, D., (1748) An enquiry concerning human understanding, p. 95. , In: Selby-Bigge LA (ed) Section 8, Part I. Clarendon Press, 1894; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intell Syst, 21 (4), pp. 18-21; Rawls, J., Outline for a decision procedure for ethics (1951) Philos Rev, p. 60; Rawls, J., (1971) A theory of justice, , Belknap Press of Harvard University Press, Cambridge; Ross, W.D., (1930) The right and the good, , Clarendon Press, Oxford},
document_type={Article},
source={Scopus},
}

@ARTICLE{Goertzel2014391,
author={Goertzel, B.},
title={GOLEM: Towards an AGI meta-architecture enabling both goal preservation and radical self-improvement},
journal={Journal of Experimental and Theoretical Artificial Intelligence},
year={2014},
volume={26},
number={3},
pages={391-403},
doi={10.1080/0952813X.2014.895107},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903269166&doi=10.1080%2f0952813X.2014.895107&partnerID=40&md5=75636190bba14a680efbbb2bcbdd998c},
abstract={A high-level artificial general intelligence (AGI) architecture called goal-oriented learning meta-architecture (GOLEM) is presented, along with an informal but careful argument that GOLEM may be capable of preserving its initial goals while radically improving its general intelligence. As a meta-architecture, GOLEM can be wrapped around a variety of different base-level AGI systems, and also has a role for a powerful narrow-AI subcomponent as a probability estimator. The motivation underlying these ideas is the desire to create AGI systems fulfilling the multiple criteria of being: massively and self-improvingly intelligent, probably beneficial and almost surely not destructive. © 2014 Taylor & Francis.},
author_keywords={artificial general intelligence;  machine ethics;  selfmodification;  superintelligence},
keywords={Artificial intelligence;  Software engineering, Artificial general intelligences;  General Intelligence;  Goal-oriented;  Multiple criteria;  Probability estimator;  Self-modification;  Superintelligence, Architecture},
references={Goertzel, B., Opencog prime: A cognitive synergy based architecture for embodied artificial general intelligence (2009) Proceedings of the 8th IEEE International Conference on Cognitive Informatics, ICCI 2009, June 15-17, pp. 60-68. , G. Baciu, Y. Wang, Y. Yao, W. Kinsner, K. Chan, & L. A. Zadeh (Eds.), IEEE Computer Society: Hong Kong, China; Goertzel, B., Coherent aggregated volition (2010) Multiverse According to Ben, , http://multiverseaccordingtoben.blogspot.com/2010/03/coherent-aggregated- volition-toward.htm; Legg, S., Hutter, M., A definition of machine intelligence (2007) Minds and Machines, 17, pp. 391-444; Schmidhuber, J., Developmental robotics, optimal artificial curiosity, creativity, music, and the fine arts (2006) Connection Science, 18 (2), pp. 173-187. , DOI 10.1080/09540090600768658, PII W3795157767; Sutton, R., Barto, A., (1998) Reinforcement Learning, , Cambridge, MA: MIT Press},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Guarini2013213,
author={Guarini, M.},
title={Introduction: Machine Ethics and the Ethics of Building Intelligent Machines},
journal={Topoi},
year={2013},
volume={32},
number={2},
pages={213-215},
doi={10.1007/s11245-013-9183-x},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884523524&doi=10.1007%2fs11245-013-9183-x&partnerID=40&md5=a65b5bfe1bf17d6c76525ef472944837},
references={Anderson, S., (2011) Machine metaethics, pp. 21-27. , In: Anderson M, Anderson S (eds) Machine ethics. Cambridge University Press; Anderson, M., Anderson, S., Machine ethics: creating an ethically intelligent agent (2007) AI Mag, 28 (4), pp. 15-26; Anderson, M., Anderson, S., (2011) General introduction, pp. 1-4. , (eds) Machine ethics. Cambridge University Press; Anderson, M., Anderson, S., (2011) Introduction. Machine ethics, pp. 7-12. , (eds), Cambridge University Press; Anderson, M., Anderson, S., (2011) Machine Ethics, , Cambridge: Cambridge University Press; Danielson, P., (1992) Artificial Morality: Virtuous Robots for Virtuous Games, , New York: Routledge; Dennett, D., (1978) Brainstorms: Philosophical Essays on Mind and Psychology, , Cambridge, MA: MIT press, a Bradford Book; Guarini, M., Computational neural modeling and the philosophy of ethics: reflections on the particularism-generalism debate (2011) Machine Ethics, pp. 316-334. , M. Anderson and S. Anderson (Eds.), Cambridge: Cambridge University Press; Lin, P., Abney, K., Bekey, G.A., (2012) Robot ethics: The ethical and social implications of robotics, , (eds) MIT Press, Cambridge, MA; Turing, A., Computing machinery and intelligence (1950) Mind, 59 (236), pp. 433-460; Veruggio, G., Abney, K., Roboethics: the applied ethics for a new science (2012) Robot Ethics, pp. 347-363. , In: Lin P, Abney K, Bekey GA (eds). MIT Press, Cambridge, MA; Wallach, W., Allen, C., (2009) Moral machines: Teaching robots right from wrong, , Oxford University Press},
document_type={Editorial},
source={Scopus},
}

@ARTICLE{Pontier2013195,
author={Pontier, M.A. and Widdershoven, G.A.M.},
title={Robots that stimulate autonomy},
journal={IFIP Advances in Information and Communication Technology},
year={2013},
volume={412},
pages={195-204},
doi={10.1007/978-3-642-41142-7_20},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894072554&doi=10.1007%2f978-3-642-41142-7_20&partnerID=40&md5=b8a6ab54df4ddcad6f069a4d58d6a8c1},
abstract={In healthcare, robots are increasingly being used to provide a high standard of care in the near future. When machines interact with humans, we need to ensure that these machines take into account patient autonomy. Autonomy can be defined as negative autonomy and positive autonomy. We present a moral reasoning system that takes into account this twofold approach of autonomy. In simulation experiments, the system matches the decision of the judge in a number of law cases about medical ethical decisions. This may be useful in applications where robots need to constrain the negative autonomy of a person to stimulate positive autonomy, for example when attempting to pursue a patient to make a healthier choice. © IFIP International Federation for Information Processing 2013.},
author_keywords={Cognitive modeling;  Cognitive robotics;  Health care applications;  Machine ethics;  Moral reasoning},
keywords={Artificial intelligence;  Health care;  Philosophical aspects, Cognitive model;  Cognitive robotics;  Health care application;  High standards;  Moral reasoning, Robots},
references={Agich, G.J., (2003) Autonomy and long-term care, , Cambridge University Press; Anderson, M., Anderson, S., Armen, C., Toward Machine Ethics: Implementing Two Action-Based Ethical Theories (2005) Machine Ethics: Papers from the AAAI Fall Symposium; Anderson, M., Anderson, S., (2008) Ethical Healthcare Agents, 107. , SCI,. Springer; Banks, M.R., Willoughby, L.M., Banks, W.A., Animal-Assisted Therapy and Loneliness in Nursing Homes: Use of Robotic versus Living Dogs (2008) Journal of the American Medical Directors Association, 9, pp. 173-177; Beauchamp, T.L., Childress, J.F., (2001) Principles of Biomedical Ethics, , Oxford University Press, Oxford; Berlin, I., (1958) Two concepts of liberty, , Clarendon Press, Oxford; Buchanan, A.E., Brock, D.W., (1989) Deciding for Others: The Ethics of Surrogate Decision Making, , Cambridge University Press; Widdershoven, G.A.M., Abma, T.A., Autonomy, dialogue, and practical rationality (2012) Autonomy and mental disorder, pp. 217-232. , In: Radoilska, L. (ed.),. Oxford University Press, Oxford; Hoorn, J.F., Pontier, M.A., Siddiqui, G.F., Coppélius' Concoction: Similarity and Complementarity Among Three Affect-related Agent Models (2012) Cognitive Systems Research Journal, 15, pp. 33-49; Karimi, A., (2012) Cognitive Systems Research Journal, p. 5. , October 1; Moody, H.R., (1996) Ethics in an ageing society, , Johns Hopkins UP, Baltimore; Picard, R., (1997) Affective computing, , MIT Press, Cambridge; Pontier, M.A., Widdershoven, G., Hoorn, J.F., Moral Coppélia-Combining Ratio with Affect in Ethical Reasoning (2012) IBERAMIA 2012. LNCS, 7637, pp. 442-451. , In: Pavón, J., Duque-Méndez, N.D., Fuentes-Fernández, R. (eds.),. Springer, Heidelberg; Pontier, M.A., Hoorn, J.F., Toward machines that behave ethically better than humans do (2012) Proceedings of of the 34th International Annual Conference of the Cognitive Science Society, pp. 2198-2203. , In: Miyake, N., Peebles, B., Cooper, R.P. (eds.), CogSci 2012; Robins, B., Dautenhahn, K., Boekhorst, R.T., Billard, A., Robotic Assistants in Therapy and Education of Children with Autism: Can a Small Humanoid Robot Help Encourage Social Interaction Skills? (2005) Journal of Universal Access in the Information Society, 4, pp. 105-120; Van Wynsberghe, A., Designing Robots for Care; Care Centered Value-Sensitive Design (2012) Journal of Science and Engineering Ethics, , (in press); Wada, K., Shibata, T., Social Effects of Robot Therapy in a Care House (2009) JACIII, 13, pp. 386-392; (2010) Health topics: Ageing, , http://www.who.int/topics/ageing/en/, WHO},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Torrance201254,
author={Torrance, S.},
title={The centrality of machine consciousness to machine ethics: Between realism and social-relationism},
journal={AISB/IACAP World Congress 2012 - The Machine Question: AI, Ethics and Moral Responsibility, Part of Alan Turing Year 2012},
year={2012},
pages={54-60},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872723885&partnerID=40&md5=2214a36a6baff9be5c3e601377cd7c36},
abstract={I compare a 'realist' with a 'social-relational' perspective on our judgments of the moral status of machines. I argue that moral status is closely bound up with a being's ability to experience states of conscious satisfaction or suffering (CSS). The social-relational view may be right that a wide variety of social interactions between us and machines will proliferate in future generations, and that the appearance of CSS-features in such machines may make moral-role attribution socially prevalent in human-machine relations. But the social world is enabled and constrained by the physical world. Features analogous to physiological features in biological CSS are what need to be present for non-biological CSS. Working out the details of such features will be a scientific inquiry sharing the same kind of 'objectivity' as, for instance, physicists' questions about dark matter.},
keywords={Dark matter;  Future generations;  Human-machine;  Machine consciousness;  Physical world;  Physiological features;  Scientific inquiry;  Social interactions, Philosophical aspects},
references={Wallach, W., Allen, C., Franklin, S., Consciousness and ethics: Artificially conscious moral agents (2011) International Journal of Machine Consciousness, 3 (1), pp. 177-192; Torrance, S.B., Ethics and consciousness in artificial agents (2008) Artificial Intelligence and Society, 22 (4), pp. 495-521; Torrance, S.B., Roche, D., Does an artificial agent need to be conscious to have ethical status' (2011) Technologies on the Stand: Legal and Ethical Questions in Neuroscience and Robotics, pp. 285-310. , B. van den Berg and L. Klaming (eds), Nijmegen: Wolf Legal Publishers; Torrance, S.B., Would a super-intelligent AI necessarily be (super-)conscious' (2011) Proc. Machine Consciousness Symposium, AISB-2011, , University of York; Torrance, S.B., Artificial agents and the expanding ethical circle (2012) AI & Society, , DOI: 10.1007/s00146-012-0422-2; Coeckelbergh, M., (2012) Who Cares about Robots' A Phenomenological Approach to the Moral Status of Autonomous Machines, , Proceedings; Coeckelbergh, M., Robot rights' towards a social-relational justification of moral consideration (2010) Ethics and Information Technology, 12 (3), pp. 209-221; Coeckelbergh, M., Moral appearances: Emotions, robots, and human morality' (2010) Ethics and Information Technology, 12 (3), pp. 235-241; Coeckelbergh, M., Personal robots, appearance, and human good: A methodological reflection on roboethics (2009) International Journal of Social Robotics, 1 (3), pp. 217-221; Coeckelbergh, M., (2012) Growing Moral Relations: A Critique of Moral Status Ascription, , Basingstoke: Palgrave Macmillan; Levy, D., The ethical treatment of artificially conscious robots' (2009) International Journal of Social Robotics, 1 (3), pp. 209-216; Gunkel, D.J., (2012) A Vindication of the Rights of Robots, , Proceedings; Gunkel, D.J., (2012) The Machine Question: Critical Perspectives on AI, Robots and Ethics, , Cambridge, MA: MIT Press; Singer, P., (2011) The Expanding Circle: Ethics, Evolution and Moral Progress, , Princeton University Press; Leopold, A., A land ethic (1948) A Sand County Almanac with Essays on Conservation from Round River, , NY: Oxford University Press; Naess, A., The shallow and the deep long-range ecology movements' (1973) Inquiry, 16, pp. 95-100; Harris, S., (2010) The Moral Landscape: How Science Can Determine Human Values, , London: Random House; Bisson, T., They're made out of meat (1991) Omni, 4; Gallagher, S., Zahavi, D., (2008) The Phenomenological Mind: An Introduction to Philosophy of Mind and Cognitive Science, , London: Taylor & Francis; Wittgenstein, L., (1953) Philosophical Investigations, , Oxford: Blackwell; Turing, A.M., Computing machinery and intelligence' (1950) Mind, 59, pp. 433-460; Thompson, E., Empathy and consciousness (2001) Journal of Consciousness Studies, 8 (5-7), pp. 1-32; Regan, T., (1983) The Case for Animal Rights, , Berkeley: University of California Press},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Guarini2012434,
author={Guarini, M.},
title={Conative dimensions of machine ethics: A defense of duty},
journal={IEEE Transactions on Affective Computing},
year={2012},
volume={3},
number={4},
pages={434-442},
doi={10.1109/T-AFFC.2012.27},
art_number={6263246},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872245644&doi=10.1109%2fT-AFFC.2012.27&partnerID=40&md5=81107f5b11c42ab3e55d5f3ee4424db6},
abstract={Immanuel Kant is one of the giants of moral theorizing in the western philosophical tradition. He developed a view of moral imperatives and duty that continues to inspire thought up to the present. In a thought-provoking series of papers, Anthony Beavers argues that Kant's conception of morality will not be applicable to machines. In other words, it will turn out that when we design machines at a level of sophistication such that ethical constraints must be built into their behavior, Kant's understanding of morality will not be helpful. Specifically, the notion of duty as involving some sort of internal conflict can be jettisoned. The argument in this paper is that there are aspects of duty that can be preserved for machine ethics. The goal will not be to defend any of the details of Kant's position. Rather, it is to motivate some ways of thinking about duty that may be useful for machine ethics. © 2010-2012 IEEE.},
author_keywords={Desire-obligation conflict;  Duty;  Ethics;  Machine ethics;  Obligation-obligation conflict},
keywords={Desire-obligation conflict;  Duty;  Ethics;  Machine ethics;  Obligation-obligation conflict, Philosophical aspects},
references={Kant, I., (1993) Grounding for the Metaphysics of Morals, , J. Ellington, ed. Hackett; Beavers, A., Between angels and animals: The question of robot ethics, or is kantian moral agency desirable?" (2099) Proc. Assoc. for Practical and Professional Ethics 18th Ann. Meeting; Beavers, A., Moral machines and the threat of ethical nihilism (2012) Robot Ethics, the Ethical and Social Implications of Robotics, pp. 333-344. , P. Lin, K. Abney, and G.A. Bekey, eds., MIT Press; Beavers, A., Could and should the ought disappear from ethics?" Digital Ethics: Research and Practice, , D. Heider and A. Massanari, eds., Peter Lang Publishers, forthcoming; Powers, T., Prospects for a kantian machine (2006) IEEE Intelligent Systems, 21 (4), pp. 46-51. , July/Aug; Dennett, D., (1978) Brainstorms: Philosophical Essays on Mind and Psychology, , MIT Press; Pollock, J., (1995) Cognitive Carpentry: A Blueprint for How to Build A Person, , MIT Press; Sinnott-Armstrong, W., Consequentialism (2011) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/win2011/entries/consequentialism/2011, Winter, ed., E.N. Zalta, ed; Fodor, J., (2008) LOT2: The Language of Thought Revisited, , Clarendon Press; Kant, I., (1996) Critique of Practical Reason, , Prometheus Books; Pollock, J., (1989) How to Build A Person: A Prolegomenon, pp. 3-10. , MIT Press},
document_type={Article},
source={Scopus},
}

@ARTICLE{Collins201135,
author={Collins, N.},
title={Trading faures: Virtual musicians and machine ethics},
journal={Leonardo Music Journal},
year={2011},
volume={21},
pages={35-39},
doi={10.1162/LMJ_a_00059},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-82455174328&doi=10.1162%2fLMJ_a_00059&partnerID=40&md5=868f01eaa1c44a9ca69dcf76ce20153f},
abstract={Increased maturity in modeling human musicianship leads to many interesting artistic achievements and challenges. This article takes the opportunity to reflect on future situations in which virtual musicians are traded like baseball cards, associated content-creator and autonomous musical agent rights, and the musical and moral conundrums that may result. Although many scenarios presented here may seem far-fetched with respect to the current level of artificial intelligence, it remains prudent and artistically stimulating to consider them. Accepting basic human curiosity and research teleology, it is salutary to consider the more distant consequences of our actions with respect to aesthetics and ethics. © 2011 ISAST.},
references={Parker, R., (2004) Aubrey de Grey: First Person to Live to 1000 Already Alive, , www.futurepundit.com/archives/001994.html, Retrieved 27 November 2010; De Grey, A., (2004) We Will Be Able to Live to 1,000, , news.bbc.co.uk/1/hi/uk/4003063.stm, Retrieved 27 November 2010; Russell, S., Norvig, P., (2003) Artificial Intelligence: A Modern Approach, , 2nd Ed. (Upper Saddle River, NJ Prentice Hall); Collins, N., Reinforcement learning for live musical agents (2008) Proceedings of the International Computer Music Conference, , Belfast; Fernandez-Armesto, F., (2004) So You Think You're Human? A Brief History of Humankind, , Oxford, U.K.: Oxford Univ. Press; Whitby, B., Sometimes it's hard to be a robot: A call for action on the ethics of abusing artificial agents (2008) Interacting with Computers, 20, pp. 326-333; Thimbleby, H., Robot ethics? Not yet. A reflection on whitby's 'sometimes it's hard to be a robot (2008) Interacting with Computers, 20, pp. 338-341. , p. 338; Stout, R., Twentieth-century moral philosophy (2008) The Routledge Companion to Twentieth Century Philosophy, p. 851. , Dermot Moran, ed., New York: Routledge, 851-882; Vonnegut's, K., (1952) Player Piano, , New York: Charles Scribner's Sons; Lessig, L., (2004) Free Culture: The Nature and Future of Creativity, , New York Penguin Books; Miller, P.D., (2008) Sound Unbound: Sampling Digital Music and Culture, , Cambridge, MA MIT Press; McCutcheon, M.A., Techno, Frankenstein and copyright (2007) Popular Music, 26 (2), pp. 259-280; (2004) Capturing Sound: How Technology Has Changed Music, p. 67. , Berkeley, CA: Univ. of California Press; Lastowka, F.G., Hunter, D., The laws of the virtual worlds (2004) California Law Review, 92 (1), pp. 1-74; Sartor, G., Cognitive automata and the law: Electronic contracting and the intentionality of software agents (2009) Artificial Intelligence Law, 17, pp. 253-390; Barfield, W., Issues of law or software agents within virtual environments (2005) Presence, 14 (6), pp. 741-748; Bonada, J., Serra, X., Synthesis of the singing voice by performance sampling and spectral models (2007) IEEE Signal Processing Magazine, , March; (2010) Exit Tunes Presents Vocalogenesis Featuring Hatsune Miku, (1). , www.oricon.co.jp/news/rankmusic/76554/full/www.vocalogenesis.com/, 31 May. Retrieved 9 Dec 2010; www.crypton.co.jp/mp/pages/prod/vocaloid/cv01_us.jsp; Piapro.jp/; Gibson, W., (1996) Idoru, , New York: G.P Putnam's Sons; World Is Mine Live in HD, , www.youtube.com/watch?v=DTXO7KGHtjI, retrieved 9 December 2010; Werde, B., MUSIC; Could i get that song in elvis, please? (2003) The New York Times, , www.nytimes.com/2003/11/23/arts/music-could-i-get-that-songin-elvis- please.html, 23 November, retrieved 9 December 2010; Werde, 18; www.youtube.com/watch?v=oE2dlRN4F7Y, posted 13 September 2010, retrieved 29 November 2010; Michaels, S., Courtney love to sue over kurt cobain guitar hero appearance (2009) The Guardian, , www.guardian.co.uk/music/2009/sep/10/courtney-love-kurt-cobain, 10 September retrieved 11 December 2010; Murray, R., (2009) Guitar Hero Kurt Cobain Row, , www.clashmusic.com/news/guitar-herokurt-cobain-row, retrieved 11 December 2010; Burns, J., (2010) Celebrity Image Rights in Law, , www.licensingpages.com/2010/03/celebrity-image-rights/, retrieved 20 December2010; Nakano, T., Goto, M., Vocalistener: A singing-to-singing synthesis system based on iterative parameter estimation (2009) Proceedings of the 6th Sound and Music Computing Conference, pp. 343-348; (1977) German Metropolis Influence Also Arises in Ultravox's; Reynolds, S., (2005) Rip It Up and Start Again, , London Faber and Faber Limited; Eve Matrix, S., (2006) Cyberpop: Digital Lifestyles and Commodity Culture, , New York Routledge; Rowe, R., Singer, E., Two highly integrated real-time music and graphics performance systems (1997) Proceedings of International Computer Music Conference, , Thessaloniki, Greece; Singer, E., Improv: Interactive improvisational animation and music (1996) International Symposium on Electronic Art; Taylor, R., Torres, D., Boulanger, R., Using music to interact with a virtual character (2005) Proceedings of NIME, , Vancouver; Mancini, M., Bresin, R., Pelachaud, C., A virtual head driven by music expressivity (2007) IEEE Transactions on Audio, Speech, and Language Processing, 15 (6), pp. 1833-1841; Haro, M., The musical avatar - A visualization of musical preferences by means of audio content description (2010) 5th Audio Mostly Conference: A Conference on Interaction with Sound, , Pitea, Sweden; Reidsma, D., Nijholt, A., Bos, P., Temporal interaction between an artificial orchestra conductor and human musicians (2008) Computers in Entertainment, 6 (4), pp. 1-22; Kapur, A., A history of robotic musical instruments (2005) Proceedings of the International Computer Music Conference (ICMC), , Barcelona; Collins, N., Musical robots and listening machines (2007) The Cambridge Companion to Electronic Music, , N. Collins and J. d'Escrivan, eds (Cambridge, U.K.: Cambridge Univ. Press); Collins, N., (2009) Introduction to Computer Music, , Chichester, U.K. Wiley; Klapuri, A., Davy, M., (2006) Signal Processing Methods for Music Transcription, , New York Springer; Cope, D., (2005) Computer Models of Musical Creativity, , Cambridge, MA MIT Press; Silverberg, R., Gianni (1989) The Conglomeroid Cocktail Party, pp. 152-170. , London: VGSF; Barfield, W., Intellectual property rights in virtual environments: Considering the rights of owners, programmers, and virtual avatars (2006) Akron Law Review, 39, pp. 649-700; Kapur, A., (2010) Allowing Globalization of Master Knowledge on An Instrument, Rather Than [Where] the Selected Few Are Fortunate Enough to Study One on One with A Master Now, , personal communication, 23 November},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Lim2008245,
author={Lim, H.C. and Stocker, R. and Larkin, H.},
title={Ethical trust and social moral norms simulation: A bio-inspired agent-based modelling approach},
journal={Proceedings - 2008 IEEE/WIC/ACM International Conference on Intelligent Agent Technology, IAT 2008},
year={2008},
pages={245-251},
doi={10.1109/WIIAT.2008.184},
art_number={4740628},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-62949117079&doi=10.1109%2fWIIAT.2008.184&partnerID=40&md5=4dd2535905e244af199df305158f2414},
abstract={The understanding of the micro-macro link is an urgent need in the study of social systems. The complex adaptive nature of social systems adds to the challenges of understanding social interactions and system feedback and presents substantial scope and potential for extending the frontiers of computer-based research tools such as simulations and agent-based technologies. In this project, we seek to understand key research questions concerning the interplay of ethical trust at the individual level and the development of collective social moral norms as representative sample of the bigger micro-macro link of social systems. We outline our Computational Model of Ethical Trust (CMET) informed by research findings from trust, machine ethics and neural science. Guided by the CMET architecture, we discuss key implementation ideas for the simulations of ethical trust and social moral norms. © 2008 IEEE.},
keywords={Agent-based modelling;  Agent-based technologies;  Bio-inspired;  Computational models;  Micro macros;  Representative samples;  Research questions;  Research tools;  Social interactions;  Social systems, Macros},
references={Abu-Akel, A., A neurobiological mapping of theory of mind (2003) Brain Research Reviews, 43 (1), pp. 29-40; Adams, J., Khan, H.T., Raeside, R., White, D., (2007) Research Methods for Graduate Business and Social Science Students, , Response books from SAGE; Adolphs, R., Cognitive neuroscience of human social behaviour (2003) Nature Reviews Neuroscience, 4 (3), pp. 165-178; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) Intelligent Systems, IEEE, 21 (4), pp. 12-17; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-25; Anderson, M., Anderson, S.L., Armen, C., An approach to computing ethics (2006) Intelligent Systems, IEEE, 21 (4), pp. 56-63; Anderson, S.W., Bechara, A., Damasio, H., Tranel, D., Damasio, A.R., Impairment of social and moral behavior related to early damage in human prefrontal cortex (1999) Nature Neuroscience, 2, pp. 1032-1037; R. Axelrod. Promoting Norms, chapter 3, In The Complexity of Cooperation: Agent-based Models of Competition and Collaboration. Princeton University Press: Princeton, 1997; Axelrod, R., Advancing the art of simulation in the social sciences (2006) Handbook of Research on Nature Inspired Computing for Economics and Management, , Jean-Philippe Rennard, IGI Publishing Hershey, PA, USA; Bandura, A., Social cognitive theory of moral thought and action (1991) Handbook of moral behavior and development: Theory, , chapter In W. M. Kurtines and J. L. Gewirtz ed, research and applications. Erlbaum, Hillsdale, NJ; Breathnach, C.S., Charles Scott Sherrington's integrative action: A centenary notice (2004) Journal of the Royal Society of Medicine, 97, pp. 34-36; Conte, R., Edmonds, B., Moss, S., Sawyer, R.K., Sociology and social theory in agent based social simulation: A symposium (2001) Computational & Mathematical Organization Theory, 7 (3), pp. 183-205; Daub, E.E., Maxwell's demon (1970) Studies In History and Philosophy of Science Part A, 1 (3), pp. 213-227; Deguet, J., Demazeau, Y., Magnin, L., Elements about the emergence issue: A survey of emergence definitions (2006) Complexus, 3 (1-3), pp. 24-31; Epstein, J., (2007) Generative Social Science: Studies in Agent-Based Computational Modeling (Princeton Studies in Complexity), , Princeton University Press: Princeton; Gallese, V., Goldman, A., Mirror neurons and the simulation theory of mind-reading (1998) Trends in Cognitive Sciences, 2 (12), pp. 493-501; Gilbert, N., Agent-based social simulation: Dealing with complexity. Centre for Research on Social Simulation, , http://cress.soc.surrey.ac.uk/resources/ABSS%20-%20dealing%20with20complexity-1-1.pdf, University of Surrey, Guildford, UK, at, 2004; Glickstein, M., Golgi and Cajal: The neuron doctrine and the 100th anniversary of the 1906 nobel prize (2006) Current Biology, 16 (5), pp. R147-R151; Gotts, N.M., Polhill, J.G., Law, A.N.R., Agent-based simulation in the study of social dilemmas (2003) Artificial Intelligence Review, 19 (1), pp. 3-92; Grcic, J., Ethics, truth and social order (2006) Sophia, 45 (2), pp. 27-42; Greene, J., Haidt, J., How (and where) does moral judgment work? (2002) Trends in Cognitive Sciences, 6 (12), pp. 517-523; Hahn, M., Fley, B., Florian, M., Spresny, D., Fischer, K., Social reputation: A mechanism for flexible self-regulation of multiagent systems (2007) Journal of Artificial Societies and Social Simulation, 10 (1). , http://jasss.soc.surrey.ac.uk/10/l/2.html; Haidt, J., The new synthesis in moral psychology (2007) Science, 316 (5827), pp. 998-1002; Hexmoor, H., Venkata, S.G., Hayes, D., Modelling social norms in multiagent systems (2006) Journal of Experimental & Theoretical Artificial Intelligence, 18 (1), pp. 49-71; Hills, T.T., Building "ethical agent" based simulations: A case study of a pathological problem in altruistic punishment (2006) ALife Ethics Workshop Artificial Life X, Bloomington, , USA; Josang, A., Ismail, R., Boyd, C., A survey of trust and reputation systems for online service provision (2007) Decision Support Systems, 43 (2), pp. 618-644; Lewis, J.D., Weigert, A., Trust as a social reality (1985) Social Forces, 63 (4), pp. 967-985; Lira, H.C., Stacker, R., Larkin, H., Review of trust and machine ethics research: Towards a bio-inspired computational model of ethical trust (cmet) (2008) Proceedings of the third International Conference on Bio-Inspired Models of Networkn Proceedings of the third International Conference on Bio-Inspired Models of Network, Information and Computing Systems (BIONETICS, , Hyogo, Japan in press; R. Lippmann. An introduction to computing with neural nets. ASSP Magazine, IEEE [see also IEEE Signal Processing Magazine], 4(2):4-22, 1987; Luhmann, N., (1980) Trust and Power, , John Wiley and sons; Marsh, S., (1994) Formalising Trust as a Computational Concept, , PhD thesis, Department of Mathematics and Computer Science, University of Stirling; P. Massa. A Survey of Trust Use and Modeling in Real Online Systems, chapter 3, In Ronggong Song and Larry Korba and George Yee (ed) Trust in E-services: Technologies, Practices and Challenges. Idea Group, Inc., 2007; McAllister, D.J., Affect-and cognition-based trust as foundations for interpersonal cooperation in organizations (1995) The Academy of Management Journal, 38 (1), pp. 24-59; McCarthy, J., Ascribing mental qualities to machines. Technical report, Stanford University AI Lab (1979), Stanford, CA 94305; McLaren, B.M., Computational models of ethical reasoning: Challenges, initial steps, and future directions (2006) Intelligent Systems, IEEE, 21 (4), pp. 29-37; Minsky, M., (1986) The Society of Mind, , Simon and Schuster, New York, USA; Mollering, G., The Nature of Trust: From Georg Simmel to a Theory of Expectation, Interpretation and Suspension (2001) Sociology, 35 (2), pp. 403-420; Möllering, G., Understanding trust from the perspective of sociological neoinstitutionalism: The interplay of institutions and agency (2005), Technical report, MAX PLANCK Institute for the study of Societies, MPIfG Discussion Paper 05/13; Nooteboom, B., (2002) Trust: Forms, Foundations, Functions, Failures and Figures, , Edward Elgar, Cheltenham, UK; T. O' Conner and H. Y. Wong. Emergent properties. The Stanford Excyclopedia of Philsosophy; http://plato.stanford.edu/entries/properties- emergent/accessed on 18 August 2008, 2006; Parry, R., Ancient ethical theory The Stanford Excyclopedia of Philsosophy, , http://plato.stanford.edu/entries/ethicsancient, accessed on 03 July 2008, 2004; Prehn, K., Wartenburger, I., Meriau, K., Scheibe, C., Goodenough, O.R., Villringer, A., van der Meer, E., Heekeren, H.R., Individual differences in moral judgment competence influence neural correlates of socio-normative judgments (2008) Social Cognitive and Affective Neuroscience, 3 (1), pp. 33-46; Railsback, S.F., Lytinen, S.L., Jackson, S.K., Agentbased simulation platforms: Review and development recommendations (2006) Simulation, 82 (9), pp. 609-623; J.-P. Rennard. Artificiality in Social Sciences, In Handbook of Research on Nature Inspired Computing for Economics and Management,. IGI Publishing Hershey, PA, USA, 2006; Rizzolatti, G., The mirror neuron system and its function in humans (2005) Anatomy and Embryology, 210, pp. 419-421; Rizzolatti, G., Craighero, L., The mirror neuron system (2004) Annual Review of Neuroscience, 27, pp. 169-192; Robbins, R.W., Wallace, W.A., Decision support for ethical problem solving: A multi-agent approach (2007) Decision Support Systems, 43 (4), pp. 1571-1587; Sabater, J., Sierra, C., Review on computational trust and reputation models (2005) Artificial Intelligence Review, 24 (1), pp. 33-60; Sawyer, R.K., Simulating emergence and downward causation in small groups (2001) Multi-Agent-Based Simulation, LNAI 1979, pp. 49-67; Sawyer, R.K., Artificial societies: Multiagent systems and the micro-macro link in sociological theory (2003) Sociological Methods & Research, 31 (3), pp. 325-363; Schillo, M., Fischer, K., Klein, C., The micro-macro link in DAI and sociology (2001) Multi-Agent-Based Simulation, pp. 303-317; Schwartz, S.H., Awareness of consequences and the influence of moral norms on interpersonal behavior (1968) Sociometry, 31 (4), pp. 355-369; Shoham, Y., Agent oriented programming: An overview of the framework and summary of recent research (1994) Knowledge Representation and Reasoning Under Uncertainty, pp. 123-129; Simmel, G., (1950) The Sociology of Georg Simmel - Translated and Edited by Kurt H Wolff, , Free Press, New York; Smith, E.R., Conrey, F.R., Agent-based modeling: A new approach for theory building in social psychology (2007) Personality and Social Psychology Review, 11 (1), pp. 87-104; Thirion, J.P., Non-rigid matching using demons (1996) Computer Vision and Pattern Recognition, 1996. Proceedings CVPR '96, 1996 IEEE Computer Society Conference on, pp. 245-251; Thomson, W., Kinetic theory of the dissipation of energy (1874) Nature, 9 (232), pp. 441-444; Thomson, W., The sorting demon of Maxwell (1879) Nature, 20 (501), p. 126; Vlastos, G., (1991) Socrates, Ironist and Moral Philosopher, , Cornell University Press, Ithaca, NY; Waterfleld, R., (2000) The First Philosophers: The PreSocratics and Sophists, , Oxford University Press, New York, USA; Wiley, N., The micro-macro problem in social theory (1988) Sociological Theory, 6 (2), pp. 254-261; Wong, D., Chinese ethics The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/entries/ethicschinese, accessed on 18 Feb 2008, 2008; Yilmaz, L., Oren, T., Aghaee, N.-G., Intelligent agents, simulation, and gaming (2006) Simulation & Gaming, 37 (3), pp. 339-349; Zangwill, O.L., Kenneth Craik: The man and his work (1980) British Journal of Psychology, 71, pp. 1-16},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{ChuanLim2008,
author={Chuan Lim, H. and Stocker, R. and Larkin, H.},
title={Review of trust and machine ethics research: Towards a bio-inspired computational model of ethical trust (CMET)},
journal={3rd International ICST Conference on Bio-Inspired Models of Network, Information and Computing Systems, BIONETICS 2008},
year={2008},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899623160&partnerID=40&md5=c5e1c67eaadb9b5b59dae4f3bb364391},
abstract={Recent advances in the fields of robotics, cyborg development, moral psychology, trust, multi agent-based systems and socionics have raised the need for a better understanding of ethics, moral reasoning, judgment and decision-making within the system of man and machines. Here we seek to understand key research questions concerning the interplay of ethical trust at the individual level and the social moral norms at the collective end. We review salient works in the fields of trust and machine ethics research, underscore the importance and the need for a deeper understanding of ethical trust at the individual level and the development of collective social moral norms. Drawing upon the recent findings from neural sciences on mirror-neuron system (MNS) and social cognition, we present a bio-inspired Computational Model of Ethical Trust (CMET) to allow investigations of the interplay of ethical trust and social moral norms. © 2008 ICST 978-963-9799-35-6.},
author_keywords={Ethical trust;  Mirror neuron system (MNS);  Neural network},
keywords={Behavioral research;  Computational methods;  Mirrors;  Neural networks;  Research, Agent-based systems;  Computational model;  Ethical trust;  Individual levels;  Mirror-neuron system;  Moral reasoning;  Research questions;  Social cognition, Philosophical aspects},
references={Abu-Akel, A., A neurobiological mapping of theory of mind (2003) Brain Research Reviews, 43 (1), pp. 29-40; Adolphs, R., Cognitive neuroscience of human social behaviour (2003) Nature Reviews Neuroscience, 4 (3), pp. 165-178; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) Intelligent Systems, IEEE, 21 (4), pp. 12-17; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-25; Anderson, M., Anderson, S.L., Armen, C., Towards machine ethics (2004) Proceedings of AAAI Workshop On Agent Organizations: Theory and Practice, , San Jose, CA, July; Anderson, M., Anderson, S.L., Armen, C., An approach to computing ethics (2006) Intelligent Systems, IEEE, 21 (4), pp. 56-63; Anderson, S.W., Bechara, A., Damasio, H., Tranel, D., Damasio, A.R., Impairment of social and moral behavior related to early damage in human prefrontal cortex (1999) Nature Neuroscience, 2, pp. 1032-1037; Arkin, R.C., Governing lethal behavior: Embedding ethics in a hybrid deliberative/reactive robot architecture (2007) GVU Technical Report GIT-GVU, 7 (11), pp. 1-117. , College of Computing, Georgia Tech; Artz, D., Gil, Y., A survey of trust in computer science and the semantic web (2007) Web Semantics: Science, Services and Agents On the World Wide Web, 5 (2), pp. 58-71; Bandura, A., Social cognitive theory of moral thought and action (1991) Handbook of Moral Behavior and Development: Theory, Research and Applications, , W. M. Kurtines and J. L. Gewirtz (ed), Erlbaum, Hillsdale, NJ; Bolender, J., A two-tiered cognitive architecture for moral reasoning (2001) Biology and Philosophy, 16 (3), pp. 339-356; Borenstein, J., The ethics of autonomous military robots (2008) Studies In Ethics, Law, and Technology, 2 (1); Breathnach, C.S., Charles Scott Sherrington's integrative action: A centenary notice (2004) Journal of the Royal Society of Medicine, 97, pp. 34-36; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) Intelligent Systems, IEEE, 21 (4), pp. 38-44; Bullock, C.J., Trust literature: A survey and a criticism (1901) The Quarterly Journal of Economics, 15 (2), pp. 167-217; Castelfranchi, C., Falcone, R., Social Trust: A Cognitive Approach (2001) Trust and Deception In Virtual Societies, , Cristiano Castelfranchi and Yao-Hua Tan (ed), Kluwer Academic Publishers, Dordrecht/Boston/London; Castelfranchi, C., Falcone, R., Pezzulo, G., Trust in information sources as a source for trust: A fuzzy approach (2003) International Conference On Autonomous Agents, Proceedings of the Second International Joint Conference On Autonomous Agents and Multiagent Systems, , Melbourne, Australia, SESSION: Social networks and trust; Danielson, P., Competition among cooperators: Altruism and reciprocity Proceedings of the National Academy of Sciences of the United States of America, 99 (10), p. 2002; Danielson, P., Playing with ethics: Games, norms and moral freedom (2005) Topoi, 24 (2), pp. 221-227; de Vignemont, F., Singer, T., The empathic brain: How, when and why? (2006) Trends In Cognitive Sciences, 10 (10), pp. 435-441; Epstein, J., (2007) Generative Social Science:Studies In Agent-Based Computational Modeling, , (Princeton Studies in Complexity). Princeton University Press: Princeton; (2008), http://www._pa.org/, FIPA. Foundation for intelligent physical agent (FIPA) home page. accessed 18th August 2008; Fukuyama, F., (1995) Trust: The Social Virtue and The Creation of Prosperit, , Hamish Hamilton London; Gallese, V., The shared manifold hypothesis. from mirror neurons to empathy (2001) Journal of Consciousness Studies, 8, pp. 33-50; Gallese, V., Goldman, A., Mirror neurons and the simulation theory of mind-reading (1998) Trends In Cognitive Sciences, 2 (12), pp. 493-501; Gambetta, D., (2000) Can We Trust Trust, 13, pp. 213-237. , New York: Basil Blackwell; Ganascia, J.-G., Modelling ethical rules of lying with answer set programming (2007) Ethics and Information Technology, 9 (1), pp. 39-47; Gazzola, V., Rizzolatti, G., Wicker, B., Keysers, C., The anthropomorphic brain: The mirror neuron system responds to human and robotic actions (2007) NeuroImage, 35 (4), pp. 1674-1684; Glickstein, M., Golgi and Cajal: The neuron doctrine and the 100th anniversary of the 1906 nobel prize (2006) Current Biology, 16 (5), pp. R147-R151; Greene, J., Haidt, J., How (and where) does moral judgment work? (2002) Trends In Cognitive Sciences, 6 (12), pp. 517-523; Greene, J.D., Nystrom, L.E., Engell, A.D., Darley, J.M., Cohen, J.D., The neural bases of cognitive conict and control in moral judgment (2004) Neuron, 44 (2), pp. 389-400; Griffiths, N., Luck, M., Coalition formation through motivation and trust (2003) Proceedings of the Second International Joint Conference On Autonomous Agents and Multi-Agent Systems, , Melbourne, Australia; Guarini, M., Mind, morals, and reasons (1996) Lecture Notes In Computer Science, Practical Reasoning, 1085, pp. 305-317; Guarini, M., Particularism and the classiffication and reclassiffication of moral cases (2006) Intelligent Systems, IEEE, 21 (4), pp. 22-28; Guinnane, T.W., Trust: A concept too many (2005) Economic Growth Center, , Centre Discussion Paper 907, Yale University; Haidt, J., The emotional dog and its rational tail: A social intuitionist approach to moral judgment (2001) Psychological Review, 108 (1), pp. 814-834; Haidt, J., The new synthesis in moral psychology (2007) Science, 316 (5827), pp. 998-1002; Hauser, M., Cushman, F., Young, L., Jin, K.-X., Mikhail, J., A dissociation between moral judgments and justi_cations (2007) Mind & Language, 22 (1), pp. 1-21; Hopfield, J.J., Neural networks and physical systems with emergent collective computational abilities (1982) Proceedings of the National Academy of Sciences of the United States of America, 79 (8), pp. 2554-2558; Hosmer, L.T., Trust: The connecting link between organizational theory and philosophical ethics (1995) The Academy of Management Review, 20 (2), pp. 379-403; Johnson, D., Grayson, K., Cognitive and Affective trust in service relationships (2005) Journal of Business Research, 58 (4), pp. 500-507; Jones, A.J.I., On the concept of trust (2002) Decision Support Systems, 33 (3), pp. 225-232; Jonker, C., Treur, J., Formal analysis of models for the dynamics of trust based on experiences (1999) Multi-Agent System Engineering, pp. 221-231; Josang, A., Ismail, R., Boyd, C., A survey of trust and reputation systems for online service provision Decision Support Systems, 43 (2), pp. 618-644; Kandel, E.R., Squire, L.R., Neuroscience: Breaking down scientific barriers to the study of brain and mind (2000) Science, 290 (5494), pp. 1113-1120; Knowles, S., Is social capital part of the institutions continuum and is it a deep determinant of development? (2006) World Institute For Development Economics Research, , Research Paper 2006/25, United Nations University; Koenigs, M., Young, L., Adolphs, R., Tranel, D., Cushman, F., Hauser, M., Damasio, A., (2007) Damage to The Prefrontal Cortex Increases Utilitarian Moral Judgements, 446 (7138), pp. 908-911; Ledoux, J.E., (1995) Emotion: Clues From the Brain. Annual Review of Psychology, 46, pp. 209-235; Lewis, J.D., Weigert, A., Trust as a social reality (1985) Social Forces, 63 (4), pp. 967-985; Lieberman, M.D., Social cognitive neuroscience: A review of core processes (2007) Annual Review of Psychology, 58 (1), pp. 259-289; Lippmann, R., An introduction to computing with neural nets (1987) ASSP Magazine, IEEE, 4 (2), pp. 4-22. , see also IEEE Signal Processing Magazine; Luhmann, N., Trust and Power (1980) John Wiley and Sons; Macal, C.M., North, M.J., Agent-based modeling and simulation: Desktop ABMS (2007) Proceedings of the Winter Simulation Conference, , Washington, D.C. USA; Malsch, T., Schulz-Schaeffer, I., Socionics: Sociological concepts for social systems of Artificial (and human) agents (2007) Journal of Artificial Societies and Social Simulation, 10 (1); Marsh, S., Formalising Trust as a Computational Concept (1994) Department of Mathematics and Computer Science, , PhD thesis, University of Stirling; Massa, P., A Survey of Trust Use and Modeling in Real Online Systems (2007) Trust In E-services: Technologies, Practices and Challenges, , Ronggong Song and Larry Korba and George Yee (ed), Idea Group, Inc; Maximilien, E.M., Singh, M.P., Agent-based trust model involving multiple qualities (2005) International Conference On Autonomous Agents, Proceedings of the Fourth International Joint Conference On Autonomous Agents and Multiagent Systems Table of Contents, pp. 519-526. , SESSION: Papers: trust and reputation; Mayer, R.C., Davis, J.H., Schoorman, F.D., An integrative model of organizational trust (1995) The Academy of Management Review, 20 (3), pp. 709-734; McAllister, D.J., Affect- and cognition-based trust as foundations for interpersonal cooperation in organizations (1995) The Academy of Management Journal, 38 (1), pp. 24-59; McCulloch, W.S., Pitts, W., A logical calculus of the ideas immanent in nervous activity (1943) Bulletin of Mathematical Biophysics, 5, pp. 115-133; McKnight, D.H., Chervany, N., Trust and distrust definitions: One bite at a time (2001) Trust In Cyber-societies, pp. 27-54; McKnight, D.H., Kacmar, C.J., Choudhury, V., Shifting factors and the ineffectiveness of third party assurance seals: A two-stage model of initial trust in a web business (2004) Electronic Markets, 14 (3), pp. 252-266; McLaren, B.M., Computational models of ethical reasoning: Challenges, initial steps, and future directions (2006) Intelligent Systems, IEEE, 21 (4), pp. 29-37; Mitchell, J.P., Banaji, M.R., Macrae, C.N., The link between social cognition and self-referential thought in the medial prefrontal cortex (2005) The Journal of Cognitive Neuroscience, 17 (8), pp. 1306-1315; Möllering, G., Understanding trust from the perspective of sociological neoinstitutionalism: The interplay of institutions and agency (2005) Technical Report, MAX PLANCK Institute For the Study of Societies, , MPIfG Discussion Paper 05/13; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) Intelligent Systems, IEEE, 21 (4), pp. 18-21; (2008), http://ccl.northwestern.edu/netlogo/, NetLogo. Netlogo home page, accessed 18th August 2008; Nooteboom, B., (2002) Trust: Forms, Foundations, Functions, Failures and Figures, , Edward Elgar, Cheltenham, UK; Nooteboom, B., Klos, T., Jorna, R., Adaptive trust and co-operation: An agent-based simulation approach (2001) Trust In Cyber-societies: Integrating the Human and Artificial Perspectives, p. 83; Oberman, L.M., Ramachandran, V.S., The simulating social mind: The role of the mirror neuron system and simulation in the social and communicative deficits of autism spectrum disorders (2007) Psychological Bulletin, 133 (2), pp. 310-327; Oztop, E., Kawato, M., Arbib, M., Mirror neurons and imitation: A computationally guided review (2006) Neural Networks, 19 (3), pp. 254-271; Paperin, G., Green, D., Sadedin, S., Leishman, T., A dual phase evolution model of adaptive radiation in landscapes (2007) Progress In Artificial Life, pp. 131-143; Parry, R., Ancient ethical theory (2004) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/entries/ethics-ancient/, accessed on 03 July 2008; Pereira, L., Saptawijaya, A., Modelling morality with prospective logic (2007) Progress In Artificial Intelligence, pp. 99-111; Powers, T.M., Prospects for a kantian machine (2006) Intelligent Systems, IEEE, 21 (4), pp. 46-51; Prehn, K., Wartenburger, I., Meriau, K., Scheibe, C., Goodenough, O.R., Villringer, A., van der Meer, E., Heekeren, H.R., Individual differences in moral judgment competence inuence neural correlates of socio-normative judgments (2008) Social Cognitive and Affective Neuroscience, 3 (1), pp. 33-46; Raine, A., Yang, Y., Neural foundations to moral reasoning and antisocial behavior (2006) Social Cognitive and Affective Neuroscience, 1 (3), pp. 203-213; Rizzolatti, G., The mirror neuron system and its function in humans (2005) Anatomy and Embryology, 210, pp. 419-421; Rizzolatti, G., Craighero, L., The mirror neuron system (2004) Annual Review of Neuroscience, 27, pp. 169-192; Rotter, J., A new scale for the measurement of interpersonal trust (1967) Journal of Personality, 35 (4), pp. 651-665; Schoorman, F.D., Mayer, R.C., Davis, J.H., An integrative model of organizational trust: Past, present, and future (2007) The Academy of Management Review (AMR), 32 (2), pp. 344-354; Siegal, M., Varley, R., Neural systems involved in theory of mind (2002) Neural Reviews Neuroscience, 3, pp. 463-471; Simmel, G., (1950) The Sociology of Georg Simmel, , Translated and Edited by Kurt H Wolff. Free Press, New York; Smith, A., The Theory of Moral Sentiments (1982) LibertyClassics, 1. , Adam Smith, 1723-1790, edited by D. D. Raphael and A. L. Macfie, of LibertyClassics; Thompson, E., Empathy and consciousness (2001) Journal of Consciousness Studies, 8, pp. 1-32; Uddin, L.Q., Iacoboni, M., Lange, C., Keenan, J.P., The self and social cognition: The role of cortical midline structures and mirror neurons (2007) Trends In Cognitive Sciences, 11 (4), pp. 153-157; van den Hoven, J., Lokhorst, G.-J., Deontic logic and computer-supported computer ethics (2002) Metaphilosophy, 33 (3), pp. 376-386; Vlastos, G., (1991) Socrates, Ironist and Moral Philosopher, , Cornell University Press, Ithaca, NY; Wallach, W., Implementing moral decision making faculties in computers and robots (2008) AI & Society, 22 (4), pp. 463-475; Warwick, K., Cyborg morals, cyborg values, cyborg ethics (2003) Ethics and Information Technology, 5 (3), pp. 131-137; Water-Eld, R., (2000) The First Philosophers: The PreSocratics and Sophists, , Oxford University Press, New York, USA; Wicks, A.C., Berman, S.L., Jones, T.M., The structure of optimal trust: Moral and strategic implications (1999) The Academy of Management Review, 24 (1), pp. 99-116; Williamson, O.E., Calculativeness, trust, and economic organization (1993) Journal of Law and Economics, 36 (1), pp. 453-486},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Arkin200845,
author={Arkin, R.C.},
title={On the ethical quandaries of a practicing roboticist: A first-hand look},
journal={Frontiers in Artificial Intelligence and Applications},
year={2008},
volume={175},
number={1},
pages={45-49},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875966236&partnerID=40&md5=1809fc41d329e307e6e8f924f11a5551},
abstract={Robotics has progressed substantially over the last 20 years, moving from simple proof-of-concept experimental research to developing market and military technologies that have significant ethical consequences. This paper provides the reflections of a roboticist on current research directions within the field and the social implications associated with its conduct. © 2008 The authors and IOS Press. All rights reserved.},
author_keywords={entertainment robotics;  military robotics;  Robot ethics},
keywords={Robotics, Developing markets;  Entertainment robotics;  Experimental research;  Military technology;  On currents;  Proof of concept;  Robot ethics;  Social implication, Philosophical aspects},
references={Joy, W., Why the future doesn't need us (2000) Wired, , Issue 8.04, April; Moravec, H., (1990) Mind Children: The Future of Robot and Human Intelligence, , Harvard University Press; Sparrow, R., Killer robots (2006) Journal of Applied Philosophy, 24 (1); Asaro, P., How just could a robot war be? (2007) 5th European Computing and Philosophy Conference, , presentation at, Twente, NL June; Arkin, R.C., (2007) Governing Lethal Behavior: Embedding Ethics in A Hybrid Deliberative/Reactive Robot Architecture, , Technical Report GIT-GVU-07-11, College of Computing, Georgia Institute of Technology; Sparrow, R., The march of the robot dogs (2002) Ethics and Information Technology, 4 (4), pp. 305-318; Sparrow, R., Sparrow, L., The hands of machines? the future of aged care (2006) Mind and Machines, 16, pp. 141-161; Krahling, M., Between companion and cyborg: The double diffracted being elsewhere of a robodog (2006) International Review of Information Ethics, 6, pp. 69-77. , December; (2004) First International Symposium on Roboethics, , http://www.roboethics.org/sanremo04/ROBOETHICS_Program.html, Villa Nobel, San Remo Italy, January; (2007) Proceedings of Roboethics Workshop at 2007 IEEE International Conference on Robotics and Automation, , http://www.roboethics.org/icra07/contributions.html, Rome, Italy, April; Walzer, M., (1977) Just and Unjust Wars, , 4th Ed., Basic Books; Surgeon General's Office, Mental Health Advisory Team (MHAT) IV Operation Iraqi Freedom 05-07, Final Report, Nov. 17, 2006; Arkin, R., Fujita, M., Takagi, T., Hasegawa, R., An ethological and emotional basis for human-robot interaction (2003) Robotics and Autonomous Systems, 42 (3-4). , March; Arkin, R.C., Ethical issues surrounding the use of robotic companions for the elderly: Illusion versus reality (2007) Workshop on Assistive Technologies: Rehabilitation and Assistive Robotics, Held at IEEE/RSJ 2007 International Conference on Intelligent Robotics and Systems (IROS '07), , presentation at, San Diego, CA, October; Arkin, R.C., Murphy, R.R., Autonomous navigation in a manufacturing environment (1990) IEEE Transactions on Robotics and Automation, 6 (4), pp. 445-454. , August; Murphy, R., Arkin, R.C., Autonomous mobile robots in flexible manufacturing systems (1988) Proc. Fourth International Conference on Artificial Intelligence Applications, pp. 412-414. , San Diego, CA},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Anderson20058,
author={Anderson, S.L.},
title={Asimov's "three laws of robotics" and machine metaethics},
journal={AAAI Fall Symposium - Technical Report},
year={2005},
volume={FS-05-06},
pages={8-16},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646156608&partnerID=40&md5=95fc89077837910482602df2da487daa},
abstract={Using Asimov's "Bicentennial Man" as a springboard, a number of metaethical issues concerning the emerging field of Machine Ethics are discussed. Although the ultimate goal of Machine Ethics is to create autonomous ethical machines, this presents a number of challenges. A good way to begin the task of making ethics computable is to create a program that enables a machine to act an ethical advisor to human beings. This project, unlike creating an autonomous ethical machine, will not require that we make a judgment about the ethical status of the machine itself, a judgment that will be particularly difficult to make. Finally, it is argued that Asimov's "Three Laws of Robotics" are an unsatisfactory basis for Machine Ethics, regardless of the status of the machine.},
keywords={Autonomous ethical machine;  Ethical status;  Machine Ethics;  Machine metaethics, Artificial intelligence;  Autonomous agents;  Computation theory;  Computer software;  Machine design, Robotics},
references={Anderson, M., Anderson, S., Armen, C., MedEthEx: Towards a medical ethics advisor (2005) Proceedings of the AAAI Fall Symposium on Caring Machines: Al and Eldercare, , Crystal City, VA, November; Anderson, S., Being morally responsible for an action versus acting responsibly or irresponsibly (1995) Journal of Philosophical Research, 20, pp. 451-462; Asimov, I., The bicentennial man (1984) Philosophy and Science Fiction, pp. 183-216. , Philips, M., ed Prometheus Books, Buffalo, NY; Bentham, J., (1969) An Introduction to the Principles of Morals and Legislation, , chapter 17 (Burns, J. and Hart, H., eds.), Clarendon Press, Oxford; Kant, I., Our duties to animals (1963) Lectures on Ethics, pp. 239-241. , (Infield, L., trans.), Harper & Row, New York, NY; Kant, I., The categorical imperative (2003) Contemporary Moral Problems, Seventh Edition, p. 54. , (White, J., ed.), Wadsworth/Thompson Learning, Belmont, CA; Machan, T., Do animals have rights? (2003) Contemporary Moral Problems, Seventh Edition, p. 494. , (White, J., ed.), Wadsworth/Thompson Learning, Belmont, CA; McLaren, B.M., Extensionally defining principles and cases in ethics: An AI model (2003) Artificial Intelligence, 150, pp. 145-181. , November; Mill, J., Utilitarianism (2002) The Basic Writings of John Stuart Mill, pp. 252-253. , The Modern Library, New York, NY; Singer, P., All animals are equal (2003) Contemporary Moral Problems, Seventh Edition, pp. 472-481. , (White, J., ed.), Wadsworth/Thompson Learning, Belmont, CA; Tooley, M., In defense of abortion and infanticide (1994) The Abortion Controversy: A Reader, p. 191. , (Pojman, L. and Beckwith, F., eds.), Jones and Bartlett, Boston, MA; Warren, M., On the moral and legal status of abortion (2003) Contemporary Moral Problems, Seventh Edition, pp. 144-155. , (White, J., ed.), Wadsworth/Thompson Learning, Belmont, CA},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Rose2001104,
author={Rose, J.R. and Huhns, M.N.},
title={Philosophical agents},
journal={IEEE Internet Computing},
year={2001},
volume={5},
number={3},
pages={104-106},
doi={10.1109/4236.935184},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035331731&doi=10.1109%2f4236.935184&partnerID=40&md5=565e18c8c2a22f416d84a298ff3ba6fa},
abstract={The need for a philosophical approach to distributed system design is emphasized. Such an approach presupposes that the components, or agents, can enter into social commitments to collaborate with others, change their mind about their results, and negotiate with others. Ethical approaches are also given that are single-agent in orientation and encode other agents implicitly.},
keywords={Communication channels (information theory);  Computer system recovery;  Distributed computer systems;  Electronic commerce;  Information retrieval;  Philosophical aspects;  Software agents, Ethical abstractions;  Global system coherence;  Machine ethics;  Philosophical agents, World Wide Web},
references={Tambe, M., Pynadath, D.V., Chauvat, N., Building dynamic agent organizations in cyberspace (2000) IEEE Internet Computing, 4 (2), pp. 65-73. , Mar.-Apr; note; Asimov, I., 1, Robot (1950) Gnome Books; Asimov, I., Foundation and empire (1952) Gnome Books; Van Dyke Parunak, H., 'Go to the ant': Engineering principles from natural multi-agent systems (1997) Annals of Operations Research, 75, pp. 69-101},
document_type={Article},
source={Scopus},
}

@ARTICLE{Danaher2020117,
author={Danaher, J.},
title={Robot Betrayal: a guide to the ethics of robotic deception},
journal={Ethics and Information Technology},
year={2020},
volume={22},
number={2},
pages={117-128},
doi={10.1007/s10676-019-09520-3},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077597664&doi=10.1007%2fs10676-019-09520-3&partnerID=40&md5=f65c9136aef3c9b9afcc939b6c65f1e1},
abstract={If a robot sends a deceptive signal to a human user, is this always and everywhere an unethical act, or might it sometimes be ethically desirable? Building upon previous work in robot ethics, this article tries to clarify and refine our understanding of the ethics of robotic deception. It does so by making three arguments. First, it argues that we need to distinguish between three main forms of robotic deception (external state deception; superficial state deception; and hidden state deception) in order to think clearly about its ethics. Second, it argues that the second type of deception—superficial state deception—is not best thought of as a form of deception, even though it is frequently criticised as such. And third, it argues that the third type of deception is best understood as a form of betrayal because doing so captures the unique ethical harm to which it gives rise, and justifies special ethical protections against its use. © 2020, Springer Nature B.V.},
author_keywords={Anthropomorphism;  Betrayal;  Deception;  Dishonesty;  Loyalty;  Robotics},
keywords={Robotics;  Robots, Anthropomorphism;  Betrayal;  Deception;  Dishonesty;  Loyalty, Philosophical aspects},
references={Bostrom, N., (2014) Superintelligence: Paths, dangers, strategies, , Oxford University Press, Oxford; Damiano, L., Dumouchel, P., Anthropomorphism in human-robot co-evolution (2018) Frontiers in Psychology, 9, p. 468; Danaher, J., The philosophical case for robot friendship (2019) The Journal of Posthuman Studies, 3 (1), pp. 5-24; Danaher, J., Welcoming robots into the moral circle: A defence of ethical behaviourism (2019) Science and Engineering Ethics; Elder, A., False friends and false coinage: A tool for navigating the ethics of sociable robots (2015) SIGCAS Computers and Society, 45 (3), pp. 248-254; Elder, A., Robot friends for autistic children: Monopoly money or counterfeit currency? (2017) Robot Ethics 2.0: From autonomous cars to artificial intelligence, , Lin P, Abney K, Jenkins R, (eds), OUP, Oxford; (2019) Ethics Guidelines for Trustworthy AI, , https://ec.europa.eu/futurium/en/ai-alliance-consultation/guidelines#Top, Brussels, European Commission; Graham, G., Zalta, E., Behaviorism (2015) Stanford Encyclopedia of the Philosophy, , https://plato.stanford.edu/entries/behaviorism/, Retrieved July 10, 2018 from; Grice, P.H., Logic and conversation (1975) Speech acts, pp. 41-58. , Cole P, Morgan JL, (eds), Academic Press, New York; Gunkel, D., (2018) Robot rights, , MIT Press, Cambridge, MA; Häggström, O., Challenges to the Omohundro-Bostrom framework for AI motivations (2019) Foresight, 21 (1), pp. 153-166; Isaac, A.M.C., Bridewell, W., White lies and silver tongues: Why robots need to deceive (and how) (2017) Robot ethics 2.0: From autonomous cars to artificial intelligence, , Lin P, Jenkins R, Abney K, (eds), Oxford University Press, Oxford; Kaminsky, M., Ruben, M., Smart, W., Grimm, C., Averting robot eyes (2017) Maryland Law Review, 76, p. 983; Leong, B., Selinger, E., Robot eyes wide shut: Understanding dishonest anthropomorphism (2019) FAT* Conference, , 2019; Mahon, J.E., Zalta, E., The definition of lying and deception (2015) Stanford Encyclopedia of Philosophy, , https://plato.stanford.edu/entries/lying-definition/, In; Malle, B.F., Scheutz, M., Arnold, T., Voiklis, J., Cusimano, C., Sacrifice one for the good of many?: People apply different moral norms to human and robot agents (2015) Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction, pp. 117-124; Margalit, A., (2017) On betrayal, , Harvard University Press, Cambridge; Neely, E.L., Machines and the moral community (2014) Philosophy Technology, 27 (1), pp. 97-111; Omohundro, S., Wang, P., Goertzel, B., Franklin, S., The basic AI drives (2008) Proceedings of the First AGI Conference Artificial General Intelligence 2008, pp. 483-492. , Amsterdam, IOS; Rahwan, I., Cebrian, M., Obradovich, N., Bongard, J., Bonnefon, J.-F., Jean-Francois, B., Cynthia, C., Jacob, W., Machine behaviour (2019) Nature, 568, pp. 477-486; Schwitzgebel, E., Garza, M., A defense of the rights of artificial intelligences (2015) Midwest Studies in Philosophy, 39 (1), pp. 89-119; Sebo, J., The moral problem of other minds (2018) The Harvard Review of Philosophy; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2010) Ethics and Information Technology, 14 (1), pp. 27-40; Shaw, K., (2015) Experiment on Human Robot Deception, , http://katarinashaw.com/project/experiment-on-human-robot-deception/; Shim, J., Arkin, R.C., Other-Oriented Robot Deception: How Can a Robot’s Deceptive Feedback Help Humans in HRI? (2016) Social Robotics, pp. 222-232. , Springer International Publishing, Cham; Simler, K., Hanson, R., (2018) The elephant in the brain, , Oxford University Press, Oxford; Trivers, R., (2011) The folly of fools, , Basic Books, New York; Turing, A., Computing machinery and intelligence (1950) Mind, 49, pp. 433-460; Turkle, S., Authenticity in the age of digital companions (2007) Interaction Studies, 8, pp. 501-507; Turkle, S., In Good Company (2010) Close engagements with artificial companions, , Wilks Y, (ed), John Benjamins Publishing, Amsterdam; Voiklis, J., Kim, B., Cusimano, C., Malle, B.F., Moral judgments of human vs. Robot agents (2016) 25Th IEEE International Symposium on Robot and Human Interactive Communication, pp. 775-780. , RO-MAN, IEEE; Markowitz, J., (2015) Robots that Talk and Listen, , (ed), DE GRUYTER, Berlin, München, Boston; Wagner, A., Arkin, R., Acting deceptively: Providing robots with the capacity for deception (2011) International Journal of Social Robotics, 3 (1), pp. 5-26; Zawieska, K., Deception and manipulation in social robotics. The emerging policy and ethics of human-robot interaction (2015) Workshop Paper at the 10Th ACM/IEEE International Conference on Human-Robot Interaction (HRI2015), , https://www.researchgate.net/publication/272474319_Deception_and_Manipulation_in_Social_Robotics},
document_type={Article},
source={Scopus},
}

@ARTICLE{Williams20191036,
author={Williams, R.},
title={EPIPHANY PHILOSOPHERS: AFTERWORD: with Fraser Watts, “Mutual Enhancement between Science and Religion: In the Footsteps of the Epiphany Philosophers”; William H. Beharrell, “Transformation and the Waking Body: A Return to Truth via Our Bodies”; Marius Dorobantu and Yorick Wilks, “Moral Orthoses: A New Approach to Human and Machine Ethics”; Galen Watts, “Religion, Science, and Disenchantment in Late Modernity”; and Rowan Williams, “Epiphany Philosophers: Afterword.”},
journal={Zygon},
year={2019},
volume={54},
number={4},
pages={1036-1044},
doi={10.1111/zygo.12561},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075171797&doi=10.1111%2fzygo.12561&partnerID=40&md5=17030522a6df1010729c77ee70eacfaa},
abstract={Being a theist makes a difference, but not so much to what propositions we assent to, nor to an expanded ontology of spiritual entities. Rather, it is concerned with what commitments we enter into, and involves a participatory engagement with a broader reality then we might have supposed was possible. Embodied practices are a crucial part of the contemplative path, which draws on the wisdom of the body. This leads on to a “labor of culture.” Our present culture is not obviously as secular as supposed to be, but what has now become sacred is a strong sense of the individual ego, around which many ethical and political commitments are built, and which sits uneasily with our widely accepted mechanistic view of life. The crucial challenge to artificial intelligence is whether it can find ways of enhancing the mutual recognition that is crucial to the ethical life. © 2019 by the Joint Publication Board of Zygon},
author_keywords={artificial intelligence;  body;  contemplation;  culture;  individuality;  knowing;  participation;  relating;  secularization;  spiritual practices},
references={Fleming, U., (1990) Grasping the Nettle: A Positive Approach to Pain, , London, UK, HarperCollins; Gray, J., (2018) Seven Types of Atheism, , London, UK, Allen Lane; Masterman, M., Metaphysical and Ideographic Language (1957) British Philosophy in Mid-Century, , edited by, C. A. Mace, London, UK, Allen & Unwin; Masterman, M., Theism as a Scientific Hypothesis (1966) Theoria to Theory, 1 (1), pp. 76-87. , 1967. “, 1 (2) 164–86; 1 (3) 232–50; 1 (4) 338–53; Needleman, J., (1980) Lost Christianity: A Journey of Rediscovery to the Centre of Christian Experience, , New York, NY, Doubleday; Pinker, S., (2018) Enlightenment Now: The Case for Reason, Science, Humanism, and Progress, , London, UK, Allen Lane; Sacks, O., (2013) Hallucinations, , London, UK, Picador; Tallis, R., (2018) Logos: The Mystery of How We Make Sense of the World, , Newcastle upon Tyne, UK, Agenda Publishing; Williams, R., (2010) Dostoevsky: Language, Faith and Fiction, , London, UK, Continuum; Williams, R., (2014) The Edge of Words: God and the Habits of Language, , London, UK, Bloomsbury},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sharkey201975,
author={Sharkey, A.},
title={Autonomous weapons systems, killer robots and human dignity},
journal={Ethics and Information Technology},
year={2019},
volume={21},
number={2},
pages={75-87},
doi={10.1007/s10676-018-9494-0},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058137643&doi=10.1007%2fs10676-018-9494-0&partnerID=40&md5=375e04654b1d985031d6bcd1682aa34c},
abstract={One of the several reasons given in calls for the prohibition of autonomous weapons systems (AWS) is that they are against human dignity (Asaro in Int Rev Red Cross 94(886):687–709, 2012; Docherty in Shaking the foundations: the human rights implications of killer robots, Human Rights Watch, New York, 2014; Heyns in S Afr J Hum Rights 33(1):46–71, 2017; Ulgen in Human dignity in an age of autonomous weapons: are we in danger of losing an ‘elementary consideration of humanity’? 2016). However there have been criticisms of the reliance on human dignity in arguments against AWS (Birnbacher in Autonomous weapons systems: law, ethics, policy, Cambridge University Press, Cambridge, 2016; Pop in Autonomous weapons systems: a threat to human dignity? 2018; Saxton in (Un)dignified killer robots? The problem with the human dignity argument, 2016). This paper critically examines the relationship between human dignity and AWS. Three main types of objection to AWS are identified; (i) arguments based on technology and the ability of AWS to conform to international humanitarian law; (ii) deontological arguments based on the need for human judgement and meaningful human control, including arguments based on human dignity; (iii) consequentialist reasons about their effects on global stability and the likelihood of going to war. An account is provided of the claims made about human dignity and AWS, of the criticisms of these claims, and of the several meanings of ‘dignity’. It is concluded that although there are several ways in which AWS can be said to be against human dignity, they are not unique in this respect. There are other weapons, and other technologies, that also compromise human dignity. Given this, and the ambiguities inherent in the concept, it is wiser to draw on several types of objections in arguments against AWS, and not to rely exclusively on human dignity. © 2018, The Author(s).},
author_keywords={Autonomous weapons systems;  Human dignity;  International humanitarian law;  Killer robots;  Laws of war;  Moral machines;  Robot ethics},
keywords={Military equipment;  Philosophical aspects;  Social aspects, Autonomous weapons systems;  Human dignity;  International humanitarian law;  Laws of war;  Robot ethics, Robots},
references={Amoroso, D., Sauer, F., Sharkey, N., Suchman, L., Tamburrini, G., Autonomy in weapon systems: The military application of artificial intelligence as a litmus test for Germany’s new foreign and security policy (2018) Heinrich Böll Stiftung Publication Series on Democracy, 49; Amoroso, D., Tamburrini, G., The ethical and legal case against autonomy in weapons systems (2017) Global Jurist; Arkin, R.C., (2009) Governing lethal behavior in autonomous robots, , CRC Press, Boca Raton; Asaro, P., On banning autonomous lethal systems: Human rights, automation and the dehumanizing of lethal decision-making, special issue on new technologies and warfare (2012) International Review of the Red Cross, 94 (886), pp. 687-709; Bhuta, N., Beck, S., Geiss, R., Present futures: Concluding reflections and open questions on autonomous weapons systems (2016) Autonomous weapons systems: Law, ethics, policy, 15, pp. 347-383. , Bhuta N, Beck S, Geiβ R, Liu H, Kreβ C, (eds), Cambridge University Press, Cambridge; Birnbacher, D., Are autonomous weapon systems a threat to human dignity? (2016) Autonomous weapons systems: Law, ethics, policy, pp. 105-121. , Bhuta N, Beck S, Geiβ R, Liu H, Kreβ C, (eds), Cambridge University Press, Cambridge; Borenstein, J., Pearson, Y., Robot caregivers: Harbingers of expanded freedom for all? (2010) Ethics and Information Technology, 12 (3), pp. 277-288; Bostrom, N., Dignity and enhancement (2008) Human dignity and bioethics: Essays commissioned by the council on bioethics, pp. 173-207. , The President’s Council on Bioethics, Washington, DC; Coeckelbergh, M., Health care, capabilities, and AI assistive technologies (2010) Ethical Theory and Moral Practice, 13 (2), pp. 181-190; De Gaay Fortman, B., Minority rights: A major misconception? (2011) Human Rights Quarterly, 33 (2), pp. 265-303; Docherty, B.L., (2014) Shaking The Foundations: The Human Rights Implications of Killer Robots, , https://www.hrw.org/report/2014/05/12/shaking-foundations/human-rights-implications-killer-robots; Falk, R.A., (2009) Achieving human rights, , Routledge, New York; Goose, S., The growing international movement against killer robots (2017) Harvard International Review, , http://hir.harvard.edu/article/?a=14022, Accessed May 17, 2018 from; Hasenclever, A., Human dignity and war (2014) The Cambridge handbook of human dignity: Interdisciplinary perspectives, pp. 439-445. , Düwell M, Braarvig J, Brownsword R, Mieth D, (eds), Cambridge University Press, Cambridge; Hew, P.C., Artificial moral agents are infeasible with foreseeable technologies (2014) Ethics and Information Technology, 16, pp. 197-206; Heyns, C., (2013) Report of the Special Rapporteur on extrajudicial, summary or arbitrary executions, A/HRC/23/47, , United Nations, New York; Heyns, C., Autonomous weapons systems: Living a dignified life and dying a dignified death (2016) Autonomous weapons systems: Law, ethics, policy, pp. 3-20. , Bhuta N, Beck S, Geiβ R, Liu H, Kreβ C, (eds), Cambridge University Press, Cambridge; Heyns, C., Autonomous weapons in armed conflict and the right to a dignified life: An African perspective (2017) South African Journal on Human Rights, 33 (1), pp. 46-71; (2012) Losing Humanity: The Case against Killer Robots, , http://www.hrw.org/reports/2012/11/19/losing-humanity-0, Accessed May 17, 2018, from; (2014) Shaking The Foundations: The Human Rights Implications of Killer Robots, , https://www.hrw.org/report/2014/05/12/shaking-foundations/human-rights-implications-killer-robots; (2018) Heed the Call: A Moral and Legal Imperative to Ban Killer Robots, , https://www.hrw.org/report/2018/08/21/heed-call/moral-and-legal-imperative-ban-killer-robots; (2014) ICRC, Autonomous Weapon Systems: Technical, Military, Legal and Humanitarian Aspects, p. 3. , In Expert meeting. Geneva, Switzerland, 26–28 March 2014, 1 November 2014; Jacobson, N., A taxonomy of dignity: A grounded theory study (2009) BMC International Health and Human Rights; Johnson, A.M., Axinn, S., The morality of autonomous robots (2013) Journal of Military Ethics, 12 (2), pp. 129-141; Johnson, D.G., Miller, K.W., Un-making artificial moral agents (2008) Ethics and Information Technology, 10, pp. 123-133; Lin, P., Do killer robots violate human rights? (2015) The Atlantic, , https://www.theatlantic.com/technology/archive/2015/04/do-killer-robots-violate-human-rights/390033/, Accessed May 17, 2018 from; Macklin, R., Dignity is a useless concept (2003) British Medical Journal, 327, pp. 1419-1420; Nordenfelt, L., Dignity of the elderly: An introduction (2003) Medicine, Health Care and Philosophy, 6 (2), pp. 99-101; Nordenfelt, L., The varieties of dignity (2004) Health Care Analysis, 12 (2), pp. 69-81; Nussbaum, M.C., (2006) Frontiers of justice, , Belknap Press, Cambridge; Nussbaum, M.C., (2011) Creating capabilities: The human development approach, , Harvard University, Belknap Press; Pinker, S., (2008) The stupidity of dignity, , The New Republic, Washington, DC; Pop, A., Autonomous weapons systems: A threat to human dignity? (2018) Humanitarian Law and Policy, ICRC Blog, , http://blogs.icrc.org/law-and-policy/, Consulted May 17, 2018 from; Saxton, A., (Un)dignified killer robots? (2016) The Problem with the Human Dignity Argument, , https://www.lawfareblog.com/undignified-killer-robots-problem-human-dignity-argument, Lawfare blog. Consulted May 17, 2018 from; Schroeder, D., Dignity: One, two, three, four, five, still counting (2010) Cambridge Quarterly of Healthcare Ethics, 19 (1), pp. 118-125; Sharkey, A., Robots and human dignity: A consideration of the effects of robot care on the dignity of older people (2014) Ethics and Information Technology, 16, pp. 63-75; Sharkey, A., Can we program or train robots to be good? (2017) Ethics and Information Technology; Sharkey, N., Grounds for discrimination: Autonomous robot (2008) RUSI Defence Systems, 11, pp. 86-89; Sharkey, N., The evitability of autonomous robot warfare (2012) International Review of the Red Cross, 94 (886), pp. 787-799; Sharkey, N., Automating warfare: Lessons learned from the drones (2012) Journal of Law, Information and Science, 21 (2), p. 140; Shultziner, D., Human dignity: Functions and meanings (2007) Perspectives on human dignity: A conversation, , Malpas J, Lickiss N, (eds), Springer, Dordrecht; Suchman, L., Situational awareness and adherence to the principle of distinction as a necessary condition for lawful autonomy (2016) Panel Presentation at CCW Informal Meeting of Experts on Lethal Autonomous Weapons, , Geneva, April 12, 2016; Tamburrini, G., On banning autonomous weapons systems: From deontological to wide consequentialist reasons (2016) Autonomous weapons systems: Law, ethics, policy, pp. 121-141. , Bhuta N, (ed), Cambridge University Press, Cambridge; Ulgen, O., Human dignity in an age of autonomous weapons: Are we in danger of losing an ‘elementary consideration of humanity’? (2016) In ESIL Conference Paper Series, 1–19. European Society of International Law (ESIL) 2016 Annual Conference (Riga), 8 (9). , Published on January 31, 2017, ESIL SSRN; (2015) The Weaponization of Increasingly Autonomous Technologies: Considering Ethics and Social Values, , UNIDIR Responses 3; Vallor, S., Carebots and caregivers: Sustaining the ethical ideal of care in the 21st century (2011) Philosophy & Technology, 24 (3), pp. 251-268; Waldron, J., (2009) Dignity, Rank and Rights, , Tanner Lectures, UC Berkeley; Werner, M., Individual and collective dignity (2014) The Cambridge handbook of human dignity: Interdisciplinary perspectives, pp. 343-352. , Düwell M, Braarvig J, Brownsword R, Mieth D, (eds), Cambridge University Press, Cambridge},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kahambing201917,
author={Kahambing, J.G.S. and Deguma, J.J.},
title={Reflecting on the Personality of Artificiality: Reading Asimov's Film Bicentennial Man through Machine Ethics},
journal={Journal of Educational and Social Research},
year={2019},
volume={9},
number={2},
pages={17-24},
doi={10.2478/jesr-2019-0009},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066304099&doi=10.2478%2fjesr-2019-0009&partnerID=40&md5=6e00ae8b012678cb9e3d936b3d290dd9},
abstract={The film Bicentennial Man (1999) pictured in a nutshell a robot who/that became human via his personality by plunging into the realities of freedom and death. The aim of this paper is to reflect on the notion of personality in the case of what this paper coins as a 'robot-incarnate' with the name Andrew, the first man who lived for two hundred years from his inception as an artificial machine. The method of exposition proceeds from (1) utilizing a philosophical reflection on the film concerning the determinacy of Andrew as a person and (2) then anchoring his case as a subject for the understanding of machine ethics. Regarding the first, the paper focuses on the questions of personality, death, and freedom. Regarding the second, the paper exposes the discussions of machine ethics and the issue of moral agency. Deducing from the already existing literature on the matter, the paper concludes that machine ethics must stand as the principle that serves as law and limitation to any scientific machine advancement showing promising potentials. © 2019 Jan Gresil S. Kahambing et al., published by Sciendo 2019.},
author_keywords={Artificiality;  Asimov;  Bicentennial Man;  Freedom;  Machine Ethics;  Personality},
references={Allué, S., Blurring Posthuman Identities: The New Version of Humanity Offered by Bicentennial Man (1999) (2003) Odisea, 4, pp. 17-30; Anderson, S.L., (2016) Asimov's "three Laws of Robotics" and Machine Metaethics. Science Fiction and Philosophy: From Time Travel to Superintelligence, Second Edition, , Wiley; Armstrong, S., (2014) Smarter Than Us: The Rise of Machine Intelligence, , USA: Machine Intelligence Research Institute; Asimov, I., (1976) The Bicentennial Man and Other Stories, , US: Double day; Asimov, I., Silverberg, R., (1992) The Positronic Man, , UK: Gollancz; Bendel, O., Sex robots from the perspective of machine ethics (2017) Love and Sex with Robots. Second International Conference, LSR 2016, London, UK, Revised Selected Papers, pp. 17-26. , Cheok, A.D.; Devlin, K.; Levy, D; Brundage, M., Limitations and risks of machine ethics (2014) In Journal of Experimental & Theoretical Artificial Intelligence, 26, p. 3; Castro, J., (2016) A Bottom-Up Approach to Machine Ethics, , http://dx.doi.org/10.7551/978-0-262-33936-0-ch113; Clarke, R., Asimovs Laws of Robotics: Implications for Information Technology (2011) Machine Ethics, , (Anderson, M., Anderson, S.L. Eds.). Cambridge: Cambridge University Press; Cook, J.C., Machine and metaphor: The ethics of language in American realism (2007) Literary Criticism and Cultural Theory, , Cain, W Routledge; Cuthbertson, A., Meet norman the 'psychopath ai (2018) That's Here to Teach Us a Lesson, , https://www.independent.co.uk/life-style/gadgets-and-tech/news/norman-psychopath-aibias-mit-artificial-intelligence-reddit-a8389011.html/amp, Independent. Retrieved from; Edgar, S., (2003) Morality and Machines: Perspectives on Computer Ethics, , Second Edition. Sudbury, Massachusetts: Jones and Bartlett Publishers; Gunkel, D., (2012) The Machine Question: Critical Perspectives on AI, Robots, Ethics, , London, England: The MIT Press; Haidt, J., Graham, J., When morality opposes justice: Conservatives have moral intuitions that liberals may not recognize (2007) Social Justice Research, 20 (1), pp. 98-116; (2016) World Robotics 2016. Frankfurt: International Federation of Robotics, , International Federation of Robotics IFR; (2017) Softbank Upgrades Humanoid Robot Peper. the Japan Times, , https://www.japantimes.co.jp/news/2017/11/21/business/tech/softbank-upgrades-humanoid-robotpepper/#, Jiji Retrieved from; Wmvqn, H., Knobe, J., Intentional Action and Side Effects in Ordinary Language (2003) Analysis, 63 (3), pp. 190-194; Koenigs, M., Young, L., Adolphs, R., Tranel, D., Cushman, F., Hauser, M., Damasio, A., Damage to the prefrontal cortex increases utilitarian moral judgements (2007) Nature, 446 (7138), pp. 908-911; Kurzweil, R., (1999) The Age of Spiritual Machines: When Computers Exceed Human Intelligence, , England: Viking Penguin; Kurzweil, R., (2012) How to Create a Mind: The Secret of Human Thought Revealed, , London: Penguin; Lumbreras, S., The limits of machine ethics (2017) Religions, 8 (100), pp. 1-10; Murray, H.A., (1938) Explorations in Personality, , New York: Oxford University Press; Ong, T., (2017) Pepper the Robot Is Now a Buddhist Priest Programmed to Chant at Funerals, , https://www.theverge.com/2017/8/24/16196752/robot-buddhist-priest-funeral-softbank, The Verge. Retrieved from; Pereira, L.M., Saptawijaya, A., Programme machine ethics (2016) Studies in Applied Philosophy, Epistemology, Rational Ethics, 26. , Switzerland: Springer International Publishing; Shulman, C., Jonsson, H., Tarleton, N., Machine ethics and superintelligence (2009) AP-CAP 2009: The Fifth Asia-Pacific Computing and Philosophy Conference, October 1st-2nd, University of Tokyo, Japan, Proceedings, pp. 95-97. , Carson Reynolds and Alvaro Cassinelli; Shulman, C., Tarleton, N., Jonsson, H., Which consequentialism machine ethics and moral divergence (2009) AP-CAP 2009: The Fifth Asia-Pacific Computing and Philosophy Conference, October 1st-2nd, University of Tokyo, Japan, Proceedings, Edited by Carson Reynolds and Alvaro Cassinelli, pp. 23-25; Strack, S., (2005) Handbook of Personology and Psychopathology, , Wiley; Sullins, J., (2011) When Is a Robot a Moral Agent in Machine Ethics, , (Anderson, M., Anderson, S.L. Eds.). Cambridge: Cambridge University Press; Veruggio, G., Operto, F., Bekey, G., Roboethics: Social and Ethical Implications (2016) Springer Handbook of Robotics, pp. 2135-2160. , Berlin and Heidelberg: Springer; Warren, M.A., On the moral and legal status of abortion (1973) The Monist, 57, p. 1; Yudkowsky, E., Artificial Intelligence as a Positive and Negative Factor in Global Risk (2008) Global Catastrophic Risks, pp. 308-345. , Nick Bostrom and Milan M. irkovi New York: Oxford University Press},
document_type={Article},
source={Scopus},
}

@ARTICLE{Cave2019562,
author={Cave, S. and Nyrup, R. and Vold, K. and Weller, A.},
title={Motivations and Risks of Machine Ethics},
journal={Proceedings of the IEEE},
year={2019},
volume={107},
number={3},
pages={562-574},
doi={10.1109/JPROC.2018.2865996},
art_number={8456834},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053150380&doi=10.1109%2fJPROC.2018.2865996&partnerID=40&md5=9a04234105bd49309ae683990c446414},
abstract={This paper surveys reasons for and against pursuing the field of machine ethics, understood as research aiming to build 'ethical machines.' We clarify the nature of this goal, why it is worth pursuing, and the risks involved in its pursuit. First, we survey and clarify some of the philosophical issues surrounding the concept of an 'ethical machine' and the aims of machine ethics. Second, we argue that while there are good prima facie reasons for pursuing machine ethics, including the potential to improve the ethical alignment of both humans and machines, there are also potential risks that must be considered. Third, we survey these potential risks and point to where research should be devoted to clarifying and managing potential risks. We conclude by making some recommendations about the questions that future work could address. © 1963-2012 IEEE.},
author_keywords={Ethical alignment;  ethical reasoning;  machine agency;  machine ethics},
keywords={Surveys, ethical reasoning;  Paper surveys;  Potential risks, Philosophical aspects},
references={Lacey, H., (1999) Is Science Value-Free?, , London, U.K.: Routledge; Kitcher, P., (2011) Science in A Democratic Society, , New York, NY, USA: Prometheus Books; Anderson, S.L., Machine metaethics (2011) Machine Ethics, pp. 21-27. , M. Anderson and S. Anderson, Eds. New York, NY, USA: Cambridge Univ. Press; Sullins, J., When is a robot a moral agent? (2006) Int. Rev. Inf. Ethics?, 6, pp. 23-30. , Dec; Tonkens, R., A challenge formachine ethics (2009) Minds Mach.?, 19 (3), pp. 421-438; Hegel, G.W.F., (1991) Elements of the Philosophy of Right, A, , W. Wood, Ed. Cambridge, U.K.: Cambridge Univ. Press; Annas, J., Ancient ethics and modern morality (1992) Philos. Perspectives?, 6, pp. 119-136. , Jan; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) J. Exp. Theor. Artif. Intell.?, 12 (3), pp. 251-261; Allen, C., Wallach, W., (2009) Moral Machines: Teaching Robots Right from Wrong, , London, U.K.: Oxford Univ. Press; Anderson, M., Anderson, S.L., Guest editors' introduction: Machine ethics (2006) IEEE Intell. Syst.?, 21 (4), pp. 10-11. , Jul; Crnkovic, G.D., Çürüklü, B., Robots: Ethical by design (2012) Ethics Inf. Technol.?, 14 (1), pp. 61-71; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intell. Syst.?, 21 (4), pp. 18-21. , Jul; (2017) Ethically Aligned Design: A Vision for Prioritizing Human Well-Being with Autonomous and Intelligent Systems, Version 2, , http://standards.ieee.org/develop/indconn/ec/autonomous_systems.html, IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems; Rawls, J., (1993) Political Liberalism, , New York, NY, USA: Columbia Univ. Press; Peter, F., Political legitimacy (2017) The Stanford Encyclopedia of Philosophy, , https://plato.stanford.edu/archives/sum2017/entries/legitimacy/, E. N. Zalta, Ed; Binns, R., Algorithmic accountability and public reason (2017) Philos. Technol., , https://doi.org/10.1007/s13347-017-0263-5; Searle, J., Minds, brains, and programs (1980) Behav. Brain Sci.?, 3 (3), pp. 417-424; Dreyfuss, H., Why heideggerian AI failed and how fixing it would require making it more heideggerian (2007) Philos. Psychol.?, 20 (2), pp. 247-268; Anderson, M., Anderson, S.L., Armen, C., An approach to computing ethics (2006) IEEE Intell. Syst.?, 21 (4), pp. 56-63. , Jul; Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches Ethics Inf. Technol.?, 7 (3), pp. 149-155. , 2005; Russell, S., Norvig, P., (2010) Artificial Intelligence: A Modern Approach, 3rd Ed, , London, U.K.: Pearson; Himma, K.E., Artificial agency, consciousness, and the criteria for moral agency: What properties must an artificial agent have to be a moral agent? (2009) Ethics Inf. Technol.?, 11 (1), pp. 19-29; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds Mach.?, 14 (3), pp. 349-379; Anderson, M., Anderson, S.L., Armen, C., Towards machine ethics (2004) Proc. IAAA Workshop Agent Org. Theory Pract., pp. 1-7. , San Jose, CA, USA, Jul; Anscombe, G.E.M., (1957) Intention, , Oxford, U.K.: Basil Blackwell; Davidson, D., (1980) Essays on Actions and Events, , Oxford, U.K.: Clarendon Press; Schlosser, M., Agency (2015) The Stanford Encyclopedia of Philosophy, , https://plato.stanford.edu/entries/agency/, E. N. Zalta, Ed; Dennett, D.C., (1987) The Intentional Stance, , Cambridge, MA, USA: MIT Press; Dennett, D.C., (1998) Brainchildren: Essays on Designing Minds, , Cambridge, MA, USA: MIT Press; Searle, J., (1983) SIntentionality: An Essay in the Philosophy of Mind, , Cambridge, U.K.: Cambridge Univ. Press; Brentano, F., (1995) Psychology from An Empirical Standpoint, , London, U.K.: Routledge; Crane, T., (1998) Intentionality As the Mark of the Mental, Contemporary Issues in the Philosophy of Mind, A, , O'Hear, Ed; Dawkins, M., (2012) Why Animals Matter, , London, U.K.: Oxford Univ. Press; Jaeger, C.B., Levin, D.T., If Asimo thinks, does Roomba feel the legal implications of attributing agency to technology (2016) J. Hum.-Robot Interact.?, 5 (3), pp. 3-25; Wu, T., Machine speech (2013) Univ. Pennsylvania Law Rev.?, 161, pp. 1495-1533; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) IEEE Intell. Syst.?, 21 (4), pp. 12-17. , Jul; Brundage, M., Limitations and risks of machine ethics (2014) J. Exp. Theor. Artif. Intell.?, 26 (3), pp. 355-372; Powers, T.M., Incremental machine ethics (2011) IEEE Robot. Automat. Mag.?, 18 (1), pp. 51-58. , Mar; Bryson, J., Winfield, A., Standardizing ethical design for artificial intelligence and autonomous systems (2017) Computer?, 50 (5), pp. 116-119. , May; Weller, A., Challenges for transparency (2017) Proc. ICML Workshop Hum. Interpretability Mach. Learn. (WHI), Sydney, , https://arxiv.org/abs/1708.01870v1, NSW, Australia; Baum, K., Köhl, M.E., Schmidt, Two challenges for CI trustworthiness and how to address them (2017) Proc. 1st Workshop Explainable Comput. Intell., pp. 1-5. , Santiago de Compostela, Spain, Sep; Wachter, S., Mittelstadt, B., Russell, C., Counterfactual explanations without opening the black box: Automated decisions and the GDPR (2017) Havard J. Law Technol., , https://dx.doi.org/10.2139/ssrn.3063289; Pettit, P., Groups with minds of their own (2003) Socializing Metaphysics: Nature Social Reality, pp. 167-193. , F. F. Schmitt, Ed. Lanham, MD, USA: Rowman & Littlefield; Pettit, P., Akrasia, Collective and individual (2003) Weakness of the Will and Practical Irrationality, pp. 68-96. , S. Stroud and C. Tappolet, Eds. London, U.K.: Oxford Univ. Press; Pettit, P., Rationality, reasoning and group agency (2007) Dialectica?, 61 (4), pp. 495-519; List, C., Pettit, P., (2011) Group Agency: The Possibility, Design, and Status of Corporate Persons, , London, U.K.: Oxford Univ. Press; Seville, H., Field, D.G., (2000) What can AI do for ethics" AISB Quart.?, 104, pp. 499-510. , M. Anderson and S. Anderson, Eds. New York, NY, USA: Cambridge Univ. Press; Anderson, M., Anderson, S.L., Robot be good (2010) Sci. Amer.?, 303 (4), pp. 72-77; Marcus, G., (2012) Moral Machines. the New Yorker, , https://www.newyorker.com/news/news-desk/moral-machines, Nov. 24; Anderson, S.L., How machines might help us achieve breakthroughs in ethical theory and inspire us to behave better (2011) Machine Ethics, pp. 524-530. , M. Anderson and S. Anderson, Eds. New York, NY, USA: Cambridge Univ. Press; Athalye, A., Engstrom, L., Ilyas, A., Kwok, K., (2017) Synthesizing Robust Adversarial Examples, , https://arxiv.org/abs/1707.07397; Vanderelst, D., Winfield, A., (2016) The Dark Side of Ethical Robots, , https://arxiv.org/abs/1606.02583; Charsi, V., (2017) Towards Moral Autonomous Systems, , https://arxiv.org/abs/1703.04741; Mason, E., Value pluralism (2015) The Stanford Encyclopedia of Philosophy, , https://plato.stanford.edu/archives/sum2015/entries/value-pluralism/, E. N. Zalta, Ed; Kant, I., (1785) Groundwork of the Metaphysic of Morals; Ross, W.D., (1930) The Right and the Good, , London, U.K.: Oxford Univ. Press; Wiggins, D., Weakness of will, commensurability, and the objects of deliberation and desire (1980) Essays on Aristotle's Ethics, , A. O. Rorty, Ed. Berkeley, CA, USA: Univ. California Press; Wiggins, D., Incommensurability: Four proposals (1997) Incommensurability, Incomparability and Practical Reason, , R. Chang, Ed. Cambridge, MA, USA: Harvard Univ. Press; Williams, B., Ethical consistency (1973) Problems of the Self. Cambridge, , U.K.: Cambridge Univ. Press; Williams, B., (1985) Ethics and the Limits of Philosophy, , Cambridge, MA, USA: Harvard Univ. Press; Berlin, I., (1991) The Crooked Timber of Humanity, , New York, NY, USA: Random House; Stocker, M., (1990) Plural and Conflicting Values, , Oxford, U.K: Clarendon; Stocker, M., Abstract and concrete value: Plurality, conflict and maximization (1997) Incommensurability, Incomparability and Practical Reason, , R. Chang, Ed. Cambridge, MA, USA: Harvard Univ. Press; Proc. Int. Conf. Auton. Agents Multiagent Syst. (AAMAS), , http://celweb.vuse.vanderbilt.edu/aamas18/; Jaworska, A., Tannenbaum, J., The grounds of moral status (2017) The Stanford Encyclopedia of Philosophy, , https://plato.stanford.edu/archives/fall2017/entries/grounds-moral-status/, E. N. Zalta, Ed; Quinn, W., Abortion: Identity and loss (1984) Philos. Public Affairs?, 13 (1), pp. 24-54; McMahan, J., (2002) The Ethics of Killing: Problems at the Margins of Life, , London, U.K.: Oxford Univ. Press; Tooley, M., Abortion and infanticide (1972) Philos. Public Affairs?, 2 (2), pp. 37-65; Dehaene, S., Lau, H., Kouider, S., What is consciousness, and could machines have it" (2017) Science?, 358 (6362), pp. 486-492; Cleeremans, A., Connecting conscious and unconscious processing (2014) Cogn. Sci.?, 38 (6), pp. 1286-1315; Bryson, J.J., Robots should be slaves (2010) Close Engagements with Artificial Companions: Key Social, Psychological, Ethical and Design Issue, pp. 63-74. , Y.Wilks and J. Benjamins, Eds; Harford, T., (2016) Crash: How Computers Are Setting Us Up for Disaster. the Guardian, , https://www.theguardian.com/technology/2016/oct/11/crash-howcomputers-are-setting-us-up-disaster, Oct. , 11; Harford, T., (2016) Messy: How to Be Creative and Resilient in A Tidy-Minded World, , New York, NY, USA: Riverhead; Danaher, J., The rise of the robots and the crisis of moral patiency (2017) AI Soc., pp. 1-8. , https://doi.org/10.1007/s00146-017-0773-9; Lisboa, P.J.G., Interpretability inmachine learning-Principles and practice (2013) Fuzzy Logic and Applications. WILF(Lecture Notes in Computer Science)?, 8256, pp. 15-21. , F. Masulli, G. Pasi, and R. Yager, Eds. Cham, Switzerland: Springer},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Liao2019147,
author={Liao, B. and Slavkovik, M. and Van Der Torre, L.},
title={Building Jiminy cricket: An architecture for moral agreements among stakeholders},
journal={AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
year={2019},
pages={147-153},
doi={10.1145/3306618.3314257},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070651510&doi=10.1145%2f3306618.3314257&partnerID=40&md5=f27688c95cddf385fcb19c6fd98875b5},
abstract={An autonomous system is constructed by a manufacturer, operates in a society subject to norms and laws, and is interacting with end-users. We address the challenge of how the moral values and views of all stakeholders can be integrated and reflected in the moral behavior of the autonomous system. We propose an artificial moral agent architecture that uses techniques from normative systems and formal argumentation to reach moral agreements among stakeholders. We show how our architecture can be used not only for ethical practical reasoning and collaborative decision-making, but also for the explanation of such moral behavior. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
author_keywords={Agreement Reaching;  Explainability;  Formal argumentation;  Machine Ethics},
keywords={Architecture;  Decision making, Autonomous systems;  Collaborative decision making;  End users;  Explainability;  Formal argumentation;  Moral agents;  Normative system;  Practical reasoning, Philosophical aspects},
references={Alchourron, C.E., Conflcits of norms and revision of normative systems (1991) Law and Philosophy, 10, pp. 413-425. , 1991; Anderson, M., Leigh Anderson, S., Geneth: A general ethical dilemma analyzer (2014) Proceedings of the 28th AAAI Conference on AI, pp. 253-261. , http://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/view/8308; Arkin, R.C., Ulam, P., Wagner, A.R., Moral decision making in autonomous systems: Enforcement, moral emotions, dignity, trust, and deception (2012) Proc. Of the IEEE, 100 (3), pp. 571-589. , https://doi.org/10.1109/JPROC.2011.2173265, 2012; Baroni, P., Gabbay, D., Giacomin, M., Van Der Torre, L., (2018) Handbook of Formal Argumentation, , Eds. College Publications; Bench-Capon, T., Atkinson, K., Chorley, A., Persuasion and value in legal argument (2005) Journal of Logic and Computation Comput, 15 (6), pp. 1075-1097. , https://doi.org/10.1093/logcom/exi058, 2005; Biran, O., Cotton, C., Explanation and justification in machine learning: A survey (2017) Proceedings of the IJCAI Workshop on Explainable Artificial Intelligence (XAI 2017), pp. 8-13; Booth, R., Caminada, M., Marshall, B., DisCO: A web-based implementation of discussion games for grounded and preferred semantics (2018) COMMA (Frontiers in Artificial Intelligence and Applications), 305, pp. 453-454. , IOS Press; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2008) IEEE Intelligent Systems, 21 (4), pp. 38-44. , 2008; Charisi, V., Dennis, L.A., Fisher, M., Lieck, R., Matthias, A., Slavkovik, M., Sombetzki, J., Yampolskiy, R., (2017) Towards Moral Autonomous Systems, , http://arxiv.org/abs/1703.04741, CoRR abs/1703.04741 2017; Chopra, A., Van Der Torre, L., Verhagen, H., Villata, S., (2018) Handbook of Normative Multiagent Systems, , College Publications; Cocarascu, O., Čyras, K., Toni, F., Explanatory predictions with artificial neural networks and argumentation (2018) Proceedings of the IJCAI/ECAI Workshop on Explainable Artificial Intelligence (XAI 2018), pp. 26-32; Dennis, L.A., Fisher, M., Slavkovik, M., Webster, M.P., Formal verification of ethical choices in autonomous systems (2016) Robotics and Autonomous Systems, 77, pp. 1-14. , https://doi.org/10.1016/j.robot.2015.11.012, 2016; Dennis, L.A., Fisher, M., Winfield, A.F.T., Towards verifiably ethical robot behaviour (2015) Proceedings of AAAI Workshop on AI and Ethics, , http://aaai.org/ocs/index.php/WS/AAAIW15/paper/view/10119; Dignum, V., Responsible autonomy (2017) Proceedings of the 26th IIJCAI, pp. 4698-4704. , https://doi.org/10.24963/ijcai.2017/655; Dung, P.M., On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games (1995) Artificial Intelligence, 77 (2), pp. 321-358. , 1995; Dyrkolbotn, S., Pedersen, T., Slavkovik, M., On the distinction between implicit and explicit ethical agency (2018) AAAI/ACM AIES Conference, , New Orleans, USA; Etzioni, A., Etzioni, O., Incorporating ethics into artificial intelligence (2017) The Journal of Ethics, pp. 1-16. , https://doi.org/10.1007/s10892-017-9252-2, 2017; (2016) Taxonomy and Definitions for Terms Related to Driving Automation Systems for On-Road Motor Vehicles, , http://standards.sae.org/j3016_201609/, September 2016; Lindner, F., Bentzen, M.M., The hybrid ethical reasoning agent im-manuel (2017) Companion of the 2017 ACM/IEEE International Conference on Human-Robot Interaction, HRI 2017, pp. 187-188. , https://doi.org/10.1145/3029798.3038404, Vienna, Austria, March 6-9, 2017; Malle, B.F., Scheutz, M., Arnold, T., Voiklis, J., Cusimano, C., Sacrifice One for the good of many?: People apply different moral norms to human and robot agents (2015) Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI'15), pp. 117-124. , https://doi.org/10.1145/2696454.2696458; Miller, T., (2017) Explanation in Artificial Intelligence: Insights from the Social Sciences, , http://arxiv.org/abs/1706.07269, CoRR abs/1706.07269 2017; Modgil, S., Prakken, H., A general account of argumentation with preferences (2013) Artificial Intelligence, 195, pp. 361-397. , https://doi.org/10.1016/j.artint.2012.10.008, 2013; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21. , https://doi.org/10.1109/MIS.2006.80, July 2006; Pires Bjørgen, E., Øvervatn Madsen, S., Skaar Bjørknes, T., Vonheim Heimsæter, F., Håvik, R., Linderud, M., Longberg, P.N., Slavkovik, M., Cake, death, and trolleys: Dilemmas as benchmarks of ethical decision-making (2018) AAAI/ACM AIES Conference, , New Orleans, USA; Sergeant, A., Automatic argumentation extraction (2013) The Semantic Web: Semantics and Big Data, pp. 656-660. , Cimiano, O. Corcho, Presutti, L. Hollink, and S. Rudolph (Eds.). Springer SS, Berlin, Heidelberg; Vanderelst, D., Winfield, A., An architecture for ethical robots inspired by the simulation theory of cognition (2017) Cognitive Systems Research, , https://doi.org/10.1016/j.cogsys.2017.04.002, 2017; Čyras, K., Satoh, K., Toni, F., Explanation for case-based reasoning via abstract argumentation (2016) Computational Models of Argument - Proceedings of COMMA, pp. 243-254. , https://doi.org/10.3233/978-1-61499-686-6-243; Vreeswijk, G., Prakken, H., Credulous and sceptical argument games for preferred semantics (2000) JELIA (LNCS), 1919, pp. 239-253. , Springer; Wallach, W., Allen, C., (2008) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press; Walton, D., A dialogue system specification for explanation (2011) Synthese, 182 (3), pp. 349-374. , 2011; Walton, D., Using argumentation schemes for argument extraction: A bottom-up method (2012) Internat. Journal of Cognitive Informatics and Natural Intelligence, 3. , https://doi.org/doi:10.4018/jcini.2012070103, 2012; Ziafati, P., (2015) Information Engineering in Autonomous Robot Software, , Ph.D. Dissertation. University of Luxembourg},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Li2019345,
author={Li, H. and Milani, S. and Krishnamoorthy, V. and Lewis, M. and Sycara, K.},
title={Perceptions of domestic robots' normative behavior across cultures},
journal={AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
year={2019},
pages={345-351},
doi={10.1145/3306618.3314251},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070599707&doi=10.1145%2f3306618.3314251&partnerID=40&md5=883d13dec334bf6b4dbc1caea381dc16},
abstract={As domestic service robots become more common and widespread, they must be programmed to efficiently accomplish tasks while aligning their actions with relevant norms. The first step to equip domestic robots with normative reasoning competence is understanding the norms that people apply to the behavior of robots in specific social contexts. To that end, we conducted an online survey of Chinese and United States participants in which we asked them to select the preferred normative action a domestic service robot should take in a number of scenarios. The paper makes multiple contributions. Our extensive survey is the first to: (a) collect data on attitudes of people on normative behavior of domestic robots, (b) across cultures and (c) study relative priorities among norms for this domain. We present our findings and discuss their implications for building computational models for robot normative reasoning. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
author_keywords={Cross-culture study;  Human-robot interaction;  Machine ethics;  Moral decision making;  Service robots},
keywords={Behavioral research;  Decision making;  Mobile robots;  Philosophical aspects;  Surveys, Computational model;  Cross culture;  Domestic robots;  Domestic services;  Normative reasoning;  Relative priorities;  Service robots;  Social context, Human robot interaction},
references={Arnold, T., Scheutz, M., Beyond moral dilemmas: Exploring the ethical landscape in HRI (2017) Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction, pp. 445-452; Bonnefon, J.-F., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2016) Science, 352 (6293), pp. 1573-1576. , 2016; Brennan, G., Eriksson, L., Goodin, R.E., Southwood, N., (2013) Explaining Norms, , Oxford University Press; Conitzer, V., Sinnott-Armstrong, W., Borg, J.S., Deng, Y., Kramer, M., Moral decision making frameworks for artificial intelligence (2017) Proceedings of the 31st AAAI Conference on Artificial Intelligence (AAAI); De Graaf, M.M.A., Allouch, S.B., Van Dijk, J.A.G.M., Why would I use this in my home? A model of domestic social robot acceptance (2017) Human-Computer Interaction, pp. 1-59. , 2017; Gelfand, M.J., Raver, J.L., Nishii, L., Leslie, L.M., Lun, J., Lim, B.C., Duan, L., Arnadot-Tir, J., Differences between tight and loose cultures: A 33-nation study (2011) Science, 332 (6033), pp. 1100-1104. , 2011; Haring, K.S., Silvera-Tawil, D., Takahashi, T., Velonaki, M., Watanabe, K., Perception of a humanoid robot: A cross-cultural comparison (2015) Robot and Human Interactive Communication (RO-MAN), 2015 24th IEEE International Symposium on, pp. 821-826; Hofstede, G., (2001) Culture's Consequences: Comparing Values, Behaviors, Institutions and Organizations across Nations, , Sage publications; Kahn, P.H., Jr., Kanda, T., Ishiguro, H., Gill, B.T., Ruckert, J.H., Shen, S., Gary, H.E., Severson, R.L., Do people hold a humanoid robot morally accountable for the harm it causes? (2012) Proceedings of the Seventh Annual ACM/IEEE International Conference on Human-Robot Interaction, pp. 33-40; Kitayama, S., Mesquita, B., Karasawa, M., Cultural affor-dances and emotional experience: Socially engaging and disengaging emotions in Japan and the United States (2006) Journal of Personality and Social Psychology, 91 (5), p. 890. , 2006; Koay, K.L., Syrdal, D.S., Ashgari-Oskoei, M., Walters, M.L., Dautenhahn, K., Social roles and baseline proxemic preferences for a domestic service robot (2014) International Journal of Social Robotics, 6 (4), pp. 469-488. , 2014; Krishnamoorthy, V., Luo, W., Lewis, M., Sycara, K., A computational framework for integrating task planning and norm aware reasoning for social robots (2018) INternational Conference of Robot and Human Interactive Communication (RO-MAN); Lee, B.W., Shek, L.P.-C., Gerez, I.F.A., Soh, S.E., Van Bever, H.P., Food allergy-lessons from Asia (2008) World Allergy Organization Journal, 1 (7), p. 129. , 2008; Lee, H.R., Sung, J., Šabanović, S., Han, J., Cultural design of domestic robots: A study of user expectations in Korea and the United States (2012) 2012 IEEE RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, pp. 803-808; Leung, A.K.-Y., Cohen, D., Within-and between-culture variation: Individual differences and the cultural logics of honor, face, and dignity cultures (2011) Journal of Personality and Social Psychology, 100 (3), p. 507. , 2011; Li, D., Patrick Rau, P.L., Li, Y., A cross-cultural study: Effect of robot appearance and task (2010) International Journal of Social Robotics, 2 (2), pp. 175-186. , 2010; Malle, B.F., Scheutz, M., Austerweil, J.L., Networks of social and moral norms in human and robot agents (2017) A World with Robots, pp. 3-17. , Springer; Malle, B.F., Scheutz, M., Forlizzi, J., Voiklis, J., Which robot am I thinking about?: The impact of action and appearance on people's evaluations of a moral robot (2016) The Eleventh ACM/IEEE International Conference on Human Robot Interaction, pp. 125-132. , IEEE Press; Mason, W., Suri, S., Conducting behavioral research on AmazonâĂŹs Mechanical Turk (2012) Behavior Research Methods, 44 (1), pp. 1-23. , 2012; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21. , 2006; Nomura, T.T., Syrdal, D.S., Dautenhahn, K., Differences on social acceptance of humanoid robots between Japan and the UK (2015) Procs 4th Int Symposium on New Frontiers in Human-Robot Interaction., , The Society for the Study of Artificial Intelligence and the Simulation of Behaviour AISB; Pino, M., Boulay, M., Jouen, F., Rigaud, A.S., ÂĂIJAre we ready for robots that care for us?âĂİ Attitudes and opinions of older adults toward socially assistive robots (2015) Frontiers in Aging Neuroscience, 7, p. 141. , 2015; Salem, M., Lakatos, G., Amirabdollahian, F., Dautenhahn, K., Would you trust a (faulty) robot?: Effects of error, task type and personality on human-robot cooperation and trust (2015) Proceedings of ACM/IEEE International Conference on Human-Robot Interaction, pp. 141-148; Salem, M., Ziadee, M., Sakr, M., Marhaba, how may i help you?: Effects of politeness and culture on robot acceptance and anthropo-morphization (2014) Proceedings of the 2014 ACM/IEEE International Conference on Human-Robot Interaction, pp. 74-81; Scopelliti, M., Giuliani, M.V., Fornara, F., Robots in a domestic setting: A psychological approach (2005) Universal Access in the Information Society, 4 (2), pp. 146-155. , 2005; Smarr, C.-A., Mitzner, T.L., Beer, J.M., Prakash, A., Chen, T.L., Kemp, C.C., Rogers, W.A., Domestic robots for older adults: Attitudes, preferences, and potential (2014) International Journal of Social Robotics, 6 (2), pp. 229-247. , 2014; Triandis, H.C., The psychological measurement of cultural syndromes (1996) American Psychologist, 51 (4), p. 407. , 1996; Wang, L., Rau, P.-L.P., Evers, V., Robinson, B.K., Hinds, P., When in Rome: The role of culture & context in adherence to robot recommendations (2010) Proceedings of the 5th ACM/IEEE International Conference on Human-Robot Interaction, pp. 359-366. , IEEE Press; Young, J.E., Hawkins, R., Sharlin, E., Igarashi, T., Toward acceptable domestic robots: Applying insights from social psychology (2009) International Journal of Social Robotics, 1 (1), p. 95. , 2009},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Govindarajulu201929,
author={Govindarajulu, N.S. and Ghosh, R. and Bringsjord, S. and Sarathy, V.},
title={Toward the engineering of virtuous machines},
journal={AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
year={2019},
pages={29-35},
doi={10.1145/3306618.3314256},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070584809&doi=10.1145%2f3306618.3314256&partnerID=40&md5=b391e65a76566b27fd3448cf69b02a14},
abstract={While various traditions under the 'virtue ethics' umbrella have been studied extensively and advocated by ethicists, it has not been clear that there exists a version of virtue ethics rigorous enough to be a target for machine ethics (which we take to include the engineering of an ethical sensibility in a machine or robot itself, not only the study of ethics in the humans who might create artificial agents). We begin to address this by presenting an embryonic formalization of a key part of any virtue-ethics theory: namely, the learning of virtue by a focus on exemplars of moral virtue. Our work is based in part on a computational formal logic previously used to formally model other ethical theories and principles therein, and to implement these models in artificial agents. © 2019 Copyright held by the owner/author(s).},
author_keywords={Deontic cognitive event calculus;  Logic;  Verification;  Virtue ethics;  Virtuous robots},
keywords={Calculations;  Computer circuits;  Formal logic;  Logic programming;  Verification, Artificial agents;  Ethical theories;  Event calculus;  Key parts;  Logic;  Virtue ethics, Philosophical aspects},
references={Adam, C., Herzig, A., Longin, D., A logical formalization of the OCC theory of emotions (2009) Synthese, 168 (2), pp. 201-248. , 2009; Alfano, M., Identifying and defending the hard core of virtue ethics (2013) Journal of Philosophical Research, 38, pp. 233-260. , 2013; Annas, J., (2011) Intelligent Virtue, , Oxford University Press, Oxford, UK. Kindle edition used for AIES 2019; Aristotle, (2000) Nicomachean Ethics, , Cambridge University Press, Cambridge, UK. The editor and translator is Roger Crisp. Aristotle wrote the work around 340 BC; Arkoudas, K., Bringsjord, S., Toward formalizing common-sense psychology: An analysis of the false-belief task (2008) Proceedings of the Tenth Pacific Rim International Conference on Artificial Intelligence (PRICAI 2008) (Lecture Notes in Artificial Intelligence (LNAI)), pp. 17-29. , http://kryten.mm.rpi.edu/KA_SB_PRICAI08_AI_off.pdf, T.-B. Ho and Z.-H. Zhou (Eds.). Springer-Verlag; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44. , http://kryten.mm.rpi.edu/bringsjord_inference_robot_ethics_preprint.pdf, 2006; Bringsjord, S., Govindarajulu, N.S., Thero, D., Si, M., Akratic robots and the computational logic thereof (2014) Proceedings of ETHICS • 2014 (2014 IEEE Symposium on Ethics in Engineering, Science, and Technology), pp. 22-29. , Chicago, IL, IEEE Catalog Number: CFP14ETI-POD; Bringsjord, S., Taylor, J., The divine-command approach to robot ethics (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 85-108. , http://kryten.mm.rpi.edu/Divine-Command_Roboethics_Bringsjord_Taylor.pdf, Lin, G. Bekey, and K. Abney (Eds.). MIT Press, Cambridge, MA; Feldman, F., (1978) Introductory Ethics, , Prentice-Hall, Englewood Cliffs, NJ; Francez, N., Dyckhoff, R., Proof-theoretic Semantics for a Natural Language Fragment (2010) Linguistics and Philosophy, 33, pp. 447-477. , 2010; Gentzen, G., Investigations into logical deduction (1935) The Collected Papers of Gerhard Gentzen, pp. 68-131. , M. E. Szabo (Ed.). North-Holland, Amsterdam, The Netherlands, This is an English version of the well-known 1935 German version; Govindarajulu, N.S., Bringsjord, S., On automating the doctrine of double effect (2017) Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17, pp. 4722-4730. , https://doi.org/10.24963/ijcai.2017/658, Carles Sierra (Ed.). Melbourne, Australia, Preprint this url: https://arxiv.org/abs/1703.08922; Govindarajulu, N.S., Bringsjord, S., (2017) Strength Factors: An Uncertainty System for a Quantified Modal Logic, , https://arxiv.org/abs/1705.10726, Workshop on Logical Foundations for Uncertainty and Machine Learning at IJCAI 2017, Melbourne, Australia; Govindarajulu, N.S., Bringsjord, S., Ghosh, R., Peveler, M., Beyond the doctrine of double effect: A formal model of true self-sacrifice (2017) International Conference on Robot Ethics and Safety Standards, , 2017; Hiller, A., The unusual logic of Hurka's recursive acount (2011) Journal of Ethics and Social Philosophy, 6 (1), pp. 1-6. , 2011; Hurka, T., (2000) Virtue, Vice, and Value, , Oxford University Press, Oxford, UK; Johnson, R., Kant's moral philosophy (2016) The Stanford Encyclopedia of Philosophy, , https://plato.stanford.edu/entries/kant-moral, 2004 Edward Zalta Ed; Kant, I., (1997) Practical Philosophy, , 1785. Cambridge University Press, Cambridge, UK. This edited by Mary Gregor, collects all of Kant's major writings on moral and political philosophy together, and includes what has traditionally taken to be the definitive source of Kant's views on ethics, viz. The Groundwork of the Metaphysics of Morals, first published in 1785 in the German as Grundlegung zur Metaphysik der Sitten; Miles, J.K., Against the recursive account of virtue (2013) Theoretical & Applied Ethics, 2 (1), pp. 83-92. , 2013; Mueller, E., (2014) Commonsense Reasoning: An Event Calculus Based Approach, , Morgan Kaufmann, San Francisco, CA; Muggleton, S.H., Schmid, U., Zeller, C., Tamaddoni-Nezhad, A., Besold, T., Ultra-strong machine learning: Comprehensibility of programs learned with ILP (2018) Machine Learning, 107 (7), pp. 1119-1140. , https://doi.org/10.1007/s10994-018-5707-3, 01 Jul 2018; Nienhuys-Cheng, S.-H., De Wolf, R., (1997) Foundations of Inductive Logic Programming, 1228. , Springer Science & Business Media; Ortony, A., Collins, A., Clore, G.L., (1988) The Cognitive Structure of Emotions, , Number 0521353645. Cambridge England; New York: Cambridge University Press; Powers, T., Prospects for a Kantian machine (2006) IEEE Intelligent Systems, 21, p. 4. , 2006; Quinn, P., (1978) Divine Commands and Moral Requirements, , Oxford University Press, Oxford, UK; Sarathy, V., Scheutz, M., Malle, B.F., Learning behavioral norms in uncertain and changing contexts (2017) Cognitive Infocommuni-Cations (CogInfoCom), 2017 8th IEEE International Conference on, pp. 000301-000306; Sarathy, V., Wilson, J.R., Arnold, T., Scheutz, M., (2016) Enabling Basic Normative HRI in a Cognitive Robotic Architecture, , arXiv preprint 2016; Scheutz, M., Malle, B.F., Moral Robots, , http://research.clps.brown.edu/SocCogSci/Publications/Pubs/ScheutzMalle_inpress_NeuroethicsMoralRobots.pdf, forthcoming. Rout-ledge/Taylor & Francis, New York: NY. URL; Vallor, S., (2016) Technology and the Virtues: A Philosophical Guide to A Future Worth Wanting, , Oxford University Press, Oxford, UK; Van Norden, B., (2007) Virtue Ethics and Consequentialism in Early Chinese Philosophy, , Cambridge University Press, Cambridge, UK; Zagzebski, L., Exemplarist virtue theory (2010) Metaphilosophy, 41 (1-2), pp. 41-57. , 2010},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Robbins2020391,
author={Robbins, S.},
title={AI and the path to envelopment: knowledge as a first step towards the responsible regulation and use of AI-powered machines},
journal={AI and Society},
year={2020},
volume={35},
number={2},
pages={391-400},
doi={10.1007/s00146-019-00891-1},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074574493&doi=10.1007%2fs00146-019-00891-1&partnerID=40&md5=7ebe8bbbc7560ad52df02b86b3d59cd6},
abstract={With Artificial Intelligence (AI) entering our lives in novel ways—both known and unknown to us—there is both the enhancement of existing ethical issues associated with AI as well as the rise of new ethical issues. There is much focus on opening up the ‘black box’ of modern machine-learning algorithms to understand the reasoning behind their decisions—especially morally salient decisions. However, some applications of AI which are no doubt beneficial to society rely upon these black boxes. Rather than requiring algorithms to be transparent we should focus on constraining AI and those machines powered by AI within microenvironments—both physical and virtual—which allow these machines to realize their function whilst preventing harm to humans. In the field of robotics this is called ‘envelopment’. However, to put an ‘envelope’ around AI-powered machines we need to know some basic things about them which we are often in the dark about. The properties we need to know are the: training data, inputs, functions, outputs, and boundaries. This knowledge is a necessary first step towards the envelopment of AI-powered machines. It is only with this knowledge that we can responsibly regulate, use, and live in a world populated by these machines. © 2019, The Author(s).},
author_keywords={AI ethics;  Machine ethics;  Meaningful human control;  Robot ethics},
keywords={Ethical aspects;  Learning algorithms;  Virtual reality, Applications of AI;  Black boxes;  Ethical issues;  Human control;  Microenvironments;  Modern machines;  Robot ethics;  Training data, Machine learning},
references={Bostrom, N., How long before superintelligence? (2006) Linguist Philos Invest, 5 (1), pp. 11-30; Bryson, J., Robots should be slaves (2010) Close engagements with artificial companions: key social, psychological, ethical and design issues, pp. 63-74. , Wilks Y, (ed), John Benjamins Publishing, Amsterdam; Chokshi, N., Is Alexa listening? Amazon echo sent out recording of couple’s conversation (2018) The New York Times, , https://www.nytimes.com/2018/05/25/business/amazon-alexa-conversation-sharedecho.html, Accessed 28 May 2018; Citron, D.K., Pasquale, F.A., The scored society: due process for automated predictions (2014) Wash Law Rev, 89, p. 1; Ensign, D., Friedler, S.A., Neville, S., Runaway feedback loops in predictive policing (2017) arXiv, 1706, p. 09847. , (cs, stat; Floridi, L., Enveloping the world: the constraining success of smart technologies (2011) CEPE 2011: ethics in interdisciplinary and intercultural relations, pp. 111-116. , Mauger J, (ed), Milwaukee, Wisconsin; Floridi, L., Children of the fourth revolution (2011) Philos Technol, 24, pp. 227-232; Floridi, L., (2016) True AI is Both Logically Possible and Utterly implausible—Luciano Floridi | Aeon Essays, , https://aeon.co/essays/true-ai-is-both-logically-possible-and-utterly-implausible, In, Aeon, Accessed 20 Mar 2018; Gaggioli, A., Artificial intelligence: the future of cybertherapy? (2017) Cyberpsychol Behav Soc Netw, 20, pp. 402-403; Gilpin, L.H., Bau, D., Yuan, B.Z., Explaining explanations: An overview of interpretability of machine learning (2018) 2018 IEEE 5Th International Conference on Data Science and Advanced Analytics (DSAA), pp. 80-89; Johnson, D.G., Computer systems: moral entities but not moral agents (2006) Ethics Inf Technol, 8, pp. 195-204; Koepke, L., (2016) Predictive Policing isn’t about the Future, , http://www.slate.com/articles/technology/future_tense/2016/11/predictive_policing_is_too_dependent_on_historical_data.html, In, Slate, Accessed 22 Nov 2016; Lashbrook, A., (2018) Ai-Driven Dermatology Could Leave Dark-Skinned Patients Behind, , https://www.theatlantic.com/health/archive/2018/08/machine-learning-dermatology-skin-color/567619/, In, The Atlantic, Accessed 3 Oct 2018; Levin, S., Tesla fatal crash: “autopilot” mode sped up car before driver killed, report finds (2018) The Guardian, , https://www.theguardian.com/technology/2018/jun/07/tesla-fatal-crash-silicon-valley-autopilot-mode-report, Accessed 16 Oct 2018; Litjens, G., Kooi, T., Bejnordi, B.E., A survey on deep learning in medical image analysis (2017) Med Image Anal, 42, pp. 60-88; Martin, T., Priest, D., (2017) The Complete List of Alexa Commands So Far, , https://www.cnet.com/how-to/amazon-echo-the-complete-list-of-alexa-commands/, In, CNET, Accessed 28 May 2018; McGoogan, C., (2016) Youre Killing people”: Elon Musk Attacks Critics of Self-Driving Cars, , https://www.telegraph.co.uk/technology/2016/10/20/youre-killing-people-elon-musk-attacks-critics-of-self-driving-c/, In, The Telegraph, Accessed 23 May 2018; Müller, V.C., Bostrom, N., Future progress in artificial intelligence: a survey of expert opinion (2016) Fundamental issues of artificial intelligence, pp. 555-572. , Müller VC, (ed), Springer, Switzerland; Pasquale, F., (2015) The Black box society: the secret algorithms that control money and information, , Harvard University Press, Cambridge; Robbins, S., Henschke, A., The value of transparency: bulk data and authoritarianism (2017) Surveill Soc, 15, pp. 582-589; Sampler, I., Ban on killer robots urgently needed, say scientists (2017) The Guardian, , http://www.theguardian.com/science/2017/nov/13/ban-on-killer-robots-urgently-needed-say-scientists, Accessed 23 May 2018; Santoni de Sio, F., van den Hoven, J., Meaningful human control over autonomous systems: a philosophical account (2018) Front Robot AI, 5, p. 15; Scheutz, M., The need for moral competency in autonomous agent architectures (2016) Fundamental issues of artificial intelligence, pp. 515-525. , Müller VC, (ed), Springer, Switzerland; Sharkey, N., Wynsberghe, A., Robbins, S., Hancock, E., (2017) Our Sexual Future with Robots, , https://responsiblerobotics.org/wp-content/uploads/2017/07/FRR-Consultation-Report-Our-Sexual-Future-with-robots_Final.pdf, In, Foundation for Responsible Robotics, Accessed 20 Feb 2019; Sulleyman, A., (2018) Boston Dynamics Robot Dog Opens Door for Another Robot with No Arms, , http://www.independent.co.uk/life-style/gadgets-and-tech/news/boston-dynamics-robot-dog-open-door-video-hold-open-no-arms-help-video-youtube-a8208096.html, In, The Independent, Accessed 28 May 2018; van Wynsberghe, A., Robbins, S., Ethicist as designer: a pragmatic approach to ethics in the lab (2014) Sci Eng Ethics, 20, pp. 947-961; van Wynsberghe, A., Robbins, S., Critiquing the reasons for making artificial moral agents (2018) Sci Eng Ethics; Vincent, J., (2018) AI that Detects Cardiac Arrests during Emergency Calls Will Be Tested across Europe This Summer, , https://www.theverge.com/2018/4/25/17278994/ai-cardiac-arrest-corti-emergency-call-response, In, The Verge, Accessed 23 May 2018; Vollmer, N., (2018) Recital 71 EU General Data Protection Regulation (EU-GDPR)., , http://www.privacy-regulation.eu/en/recital-71-GDPR.htm, Accessed 16 Oct 2018; Wachter, S., Mittelstadt, B., Floridi, L., Why a right to explanation of automated decision-making does not exist in the general data protection regulation (2016) Int Data Priv Law, 7, pp. 76-99; Wachter, S., Mittelstadt, B., Russell, C., Counterfactual explanations without opening the black box: automated decisions and the GDPR (2018) Harv J Law Technol, 31, pp. 1-52; Wallach, W., Allen, C., (2010) Moral machines: teaching robots right from wrong, , 1, Oxford University Press, New York},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Bjørgen201823,
author={Bjørgen, E.P. and Madsen, S. and Bjørknes, T.S. and Heimsæter, F.V. and Håvik, R. and Linderud, M. and Longberg, P.-N. and Dennis, L.A. and Slavkovik, M.},
title={Cake, Death, and Trolleys: Dilemmas as benchmarks of ethical decision-making},
journal={AIES 2018 - Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
year={2018},
pages={23-29},
doi={10.1145/3278721.3278767},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061033997&doi=10.1145%2f3278721.3278767&partnerID=40&md5=4f1114e556e9ea86ce56831f4fa8a568},
abstract={Artificial intelligence (AI) systems are becoming part of our lives and societies. The more decisions such systems make for us, the more we need to ensure that the decisions they make have a positive individual and societal ethical impact. How can we estimate how good a system is at making ethical decisions? Benchmarking is used to evaluate how good a machine or a process performs with respect to industry bests. In this paper we argue that (some) ethical dilemmas can be used as benchmarks for estimating the ethical performance of an autonomous system. We advocate that an open source repository of such dilemmas should be maintained. We present a prototype of such a repository available at https://imdb. uib.no/dilemmaz/articles/all1. © 2018 ACM.},
author_keywords={benchmarking;  machine ethics},
keywords={Artificial life;  Benchmarking;  Decision making, Autonomous systems;  Ethical decision making;  Ethical dilemma;  Open source repositories, Philosophical aspects},
references={Aletras, N., Tsarapatsanis, D., Preotiuc-Pietro, D., Lampos, V., Predicting judicial decisions of the European court of human rights: A natural language processing perspective (2016) Peer J Computer Science, p. 2. , http://dx.doi.org/10.7717/peerj-cs.93, (2016); Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics and Information Technology, 7 (3), pp. 149-155. , (2005); Anderson, M., Leigh-Anderson, S., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), p. 15. , (2007); Anderson, M., Leigh-Anderson, S., GenEth: A general ethical dilemma analyzer (2014) Proceedings of the 28th AAAI Conference on Artificial Intelligence, July 27-31, 2014, Québec City, Québec, Canada., pp. 253-261. , http://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/view/8308; Anderson, M., Leigh-Anderson, S., Toward ensuring ethical behavior from autonomous systems: A case-supported principle-based paradigm (2015) Industrial Robot, 42 (4), pp. 324-331. , http://dx.doi.org/10.1108/IR-12-2014-0434, (2015); Armstrong, S., Motivated value selection for artificial agents (2015) Artificial Intelligence and Ethics, Papers from the 2015 AAAI Workshop, Austin, Texas, USA, , http://aaai.org/ocs/index.php/WS/AAAIW15/paper/view/10183, January 25, 2015; Beauchamp, T.L., Childress, J.F., (1979) Principles of Biomedical Ethics, , https://books.google.no/books?id=nreKPwAACAAJ, Oxford University Press; Bentzen, M.M., (2016) The Principle of Double Effect Applied to Ethical Dilemmas of Social Robots, pp. 268-279. , http://dx.doi.org/10.3233/978-1-61499-708-5-268, IOS Press; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44. , http://dx.doi.org/10.1109/MIS.2006.82, (July 2006); Bryson, J., Winfield, A.F.T., Standardizing ethical design for artificial intelligence and autonomous systems (2017) IEEE Computer, 50 (5), pp. 116-119. , http://dx.doi.org/10.1109/MC.2017.154, (2017); Charisi, V., Dennis, L.A., Fisher, M., Lieck, R., Matthias, A., Slavkovik, M., Sombetzki, J., Yampolskiy, R., Towards moral autonomous systems (2017) CoRR, , http://arxiv.org/abs/1703.04741, abs/1703.04741 (2017); Dennis, L.A., Fisher, M., Slavkovik, M., Webster, M.P., Formal verification of ethical choices in autonomous systems (2016) Robotics and Autonomous Systems, 77, pp. 1-14. , http://dx.doi.org/10.1016/j.robot.2015.11.012, (2016); Dennis, L.A., Fisher, M., Winfield, A.F.T., Towards verifiably ethical robot behaviour (2015) Proceedings of AAAI Workshop on AI and Ethics, , http://aaai.org/ocs/index.php/WS/AAAIW15/paper/view/10119; (2017) ElasticSearch, , https://www.elastic.co/products/elasticsearch, Accessed: -05-09; Elgin, C., (1996) Considered Judgment, , Princeton: New Jersey: Princeton University Press; Ellington, J.W., (1993) Translation Of: Grounding for the Metaphysics of Morals: With on A Supposed Right to Lie because of Philanthropic Concerns by Kant, I. [1785], , Hackett Publishing Company; Etzioni, A., Etzioni, O., Incorporating ethics into artificial intelligence (2017) The Journal of Ethics, pp. 1-16. , http://dx.doi.org/10.1007/s10892-017-9252-2, (2017); Fisher, M., List, C., Slavkovik, M., Winfield, A.F.T., Engineering moral agents - from human morality to artificial morality (Dagstuhl seminar 16222) (2016) Dagstuhl Reports, 6 (5), pp. 114-137. , http://dx.doi.org/10.4230/DagRep.6.5.114, (2016); Foot, P., The problem of abortion and the doctrine of double effect (1967) Oxford Review, 5, pp. 5-15. , (1967); Gallier, J.H., (2015) Logic for Computer Science: Foundations of Automatic Theorem Proving, , Courier Dover Publications; Garrett, J., (2004) A Simple and Usable (Although Incomplete) Ethical Theory Based on the Ethics of W.D. Ross, , http://people.wku.edu/jan.garrett/ethics/rossethc.htm, (2004). http://people.wku.edu/jan.garrett/ethics/rossethc.htm Accessed: 2017-05-09; Gert, B., Gert, J., The definition of morality (2017) The Stanford Encyclopedia of Philosophy, , (fall 2017 ed.), E.N. Zalta (Ed.). Metaphysics Research Lab, Stanford University; Harsanyi, J.C., Rule utilitarianism and decision theory (1977) Erkenntnis (1975-), 11 (1), pp. 25-53. , http://www.jstor.org/stable/20010532, (1977); Lindner, F., Bentzen, M.M., The hybrid ethical reasoning agent IMMANUEL (2017) Companion of the 2017 ACM/IEEE International Conference on Human-Robot Interaction, HRI 2017, Vienna, Austria, pp. 187-188. , http://dx.doi.org/10.1145/3029798.3038404, March 6-9, 2017; Malle, B.F., Scheutz, M., Arnold, T., Voiklis, J., Cusimano, C., Sacrifice one for the good of many?: People apply different moral norms to human and robot agents (2015) Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI '15), pp. 117-124. , http://dx.doi.org/10.1145/2696454.2696458, ACM; McLaren, B., Extensionally defining principles and cases in ethics: An AI model (2003) Artificial Intelligence, 150 (1), pp. 145-181. , http://dx.doi.org/10.1016/S0004-3702(03)00135-8, (2003); Millar, J., An ethics evaluation tool for automating ethical decision- making in robots and self-driving cars (2016) Applied Artificial Intelligence, 30 (8), pp. 787-809. , http://dx.doi.org/10.1080/08839514.2016.1229919, (2016); Mobasher, B., Cooley, R., Srivastava, J., Automatic personalization based on web usage mining (2000) Communications of ACM, 43 (8), pp. 142-151. , http://dx.doi.org/10.1145/345124.345169, (2000); Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21. , http://dx.doi.org/10.1109/MIS.2006.80, (July 2006); Pereira, L.M., Saptawijaya, A., (2016) Programming Machine Ethics. Studies in Applied Philosophy, Epistemology and Rational Ethics, 26. , http://dx.doi.org/10.1007/978-3-319-29354-7, Springer; Powers, T.M., Prospects for a kantian machine (2006) IEEE Intelligent Systems, 21 (4), pp. 46-51. , (2006); Ross, W.D., (1930) The Right and the Good, , Oxford University Press; Scopino, G., Do automated trading systems dream of manipulating the price of futures contracts? Policing markets for improper trading practices by algorithmic robots (2015) Florida Law Review, 67, pp. 221-293. , (2015); Thomson, J.J., Parent, W., The trolley problem (1986) Rights, Restitution, and Risk: Essays in Moral Theory, , https://books.google.no/books?id=sLh4oBgJEtEC, Harvard University Press; Vaughn, L., (2014) Beginning Ethics: An Introduction to Moral Philosophy, , https://books.google.no/books?id=BwChoAEACAAJ, W. W. Norton, Incorporated; Winfield, A.F.T., Blum, C., Liu, W., (2014) Towards An Ethical Robot: Internal Models, Consequences and Ethical Action Selection, pp. 85-96. , http://dx.doi.org/10.1007/978-3-319-10401-0_8, Springer International Publishing},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Hooker2018130,
author={Hooker, J.N. and Kim, T.W.},
title={Toward Non-Intuition-Based Machine and Artificial Intelligence Ethics: A Deontological Approach Based on Modal Logic},
journal={AIES 2018 - Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
year={2018},
pages={130-136},
doi={10.1145/3278721.3278753},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061029211&doi=10.1145%2f3278721.3278753&partnerID=40&md5=d0c6c70984cd0688b38529730c9da3f8},
abstract={We propose a deontological approach to machine (or AI) ethics that avoids some weaknesses of an intuition-based system, such as that of Anderson and Anderson. In particular, it has no need to deal with conflicting intuitions, and it yields a more satisfactory account of when autonomy should be respected. We begin with a "dual standpoint" theory of action that regards actions as grounded in reasons and therefore as having a conditional form that is suited to machine instructions. We then derive ethical principles based on formal properties that the reasons must exhibit to be coherent, and formulate the principles using quantified modal logic. We conclude that deontology not only provides a more satisfactory basis for machine ethics but endows the machine with an ability to explain its actions, thus contributing to transparency in AI. © 2018 ACM.},
author_keywords={accountable ai;  artificial intelligence ethics;  autonomous machine ethics;  deontology;  explainable ai;  kantian ai;  machine ethics;  modal logic},
keywords={Artificial intelligence;  Computer circuits;  Formal logic, Andersons;  Autonomous machines;  deontology;  Ethical principles;  Formal properties;  Machine instructions;  Modal logic;  Quantified modal logic, Philosophical aspects},
references={Alexander, J., (2012) Experimental Philosophy, , Cambridge: Polity Press; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, pp. 15-26. , (winter); Anderson, M., Anderson, S.L., Robot be good (2010) Scientific American, pp. 72-77. , (October); Anderson, S.L., Anderson, M., A prima facie duty approach to machine ethics: Machine learning of fea-tures of ethical dilemmas, prima facie duties, and decision principles through a dialogue with ethicists (2011) Machine Ethics, pp. 476-492. , Anderson, M., and Anderson, S. L., eds., New York: Cambridge University Press; Anderson, S.L., Anderson, M., GenEth: A general ethical dilemma analyzer (2014) Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, pp. 253-261; Anderson, M., Anderson, S.L., Toward ensur-ing ethical behavior from autonomous systems: A case-supported principle-based paradigm (2015) Industrial Robot: An International Journal, 42, pp. 324-331; Anderson, S.L., Anderson, M., Towards a principle-based healthcare agent (2015) Machine Medical Ethics, pp. 67-78. , van Rysewyk, S. P., and Pontier, M., eds., Springer; Anderson, M., Anderson, S.L., Armen, C., An approach to computing ethics (2006) IEEE Intelligent Systems, 21, pp. 2-9; Anderson, M., Anderson, S.L., Berenz, V., A value driven agent: Instantiation of a case-supported principle-based behavior paradigm (2017) Proceedings of the AAAI Workshop on AI, Ethics, and Society, pp. 72-80; Anscombe, G., (1957) Intention, , Oxford: Basil Blackwell; Appiah, K.A., (2008) Experiments in Ethics, , Cambridge, MA: Harvard University Press; Beauchamp, T.J., Childress, J.F., (1979) Principles of Biomedical Ethics, , New York: Oxford University Press; Bilgrami, A., (1996) Self-Knowledge and Resentment, , Cam-bridg, MA: Harvard University Press; Buchanan, A.E., Brock, D.W., (1990) Deciding for Others: The Ethics of Surrogate Decision Making, , New York: Cambridge University Press; Castelvecchi, D., Can we open the black box of AI? (2016) Nature, 538, pp. 20-23; Coates, D.J., Swenson, P., Reasons-responsiveness and degrees of responsibility (2013) Philosophical Studies, 165, pp. 629-645; Davidson, D., Actions, reasons, and causes (1963) Journal of Philosophy, 60, pp. 685-700; Fischer, J.M., Ravizza, M., (1998) Reasons-responsiveness and Degrees of Responsibility, , Cambridge: Cambridge Uni-versity Press; Guarini, M., Computational neural modeling and the philosophy of ethics: Reflections on the particularism-generalism debate (2011) Machine Ethics, pp. 20-23. , Anderson, M., and Anderson, S. L., eds., New York: Cambridge University Press; Kant, I., (1785) Grundlegung Zur Metaphysik der Sit-ten (Foundations of the Metaphysics of Morals), 4. , of Königlichen Preußischen Akademie der Wissenschaften: Kants gesammelte Schriften. Berlin: Georg Reimer (1900); Korsgaard, C.M., (1996) The Sources of Normativity, , Cam-bridge: Cambridge University Press; Mueller, E.T., (2016) Transparent Computers: Designing Un-derstandable Intelligent Systems, , CreateSpace Independent Publishing Platform; Nagel, T., (1986) The View from Nowhere, , Oxford: Oxford University Press; O'Neill, O., (2014) Acting on Principle: An Essay on Kantian Ethics, 2nd Ed., , Cambridge: Cambridge University Press; Rawls, J., (1971) A Theory of Justice, , Cambridge, MA: Harvard University Press; Ross, W.D., (1930) The Right and the Good, , Oxford: Oxford University Press; Schwitzgebel, E., Rust, J., The behavior of ethicists (2016) A Companion to Experimental Philosophy, , Malden, MA: Wiley Blackwell; Sinnott-Armstrong, W., Moral intuitionism meets empirical psychology (2006) Metaethics after Moore, , New York: Oxford University Press; Wallach, W., Allen, C., Smit, I., Machine morality: Bottom-up and topdown approaches for modeling human moral faculties (2008) AI & Society, pp. 565-582; Wortham, R.H., Theodorou, A., Bryson, J.J., Robot transparency, trust and utility (2016) Principles of Robotics Workshop, , Sheffield, UK: Proceedings of AISB; Wortham, R.H., Theodorou, A., Bryson, J.J., What does the robot think? Transparency as a fundamental design requirement for intelligent systems (2016) Ethics for Artificial Intelligence Workshop, , New York: IJCAI},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wächter2018269,
author={Wächter, L. and Lindner, F.},
title={An explorative comparison of blame attributions to companion robots across various moral dilemmas},
journal={HAI 2018 - Proceedings of the 6th International Conference on Human-Agent Interaction},
year={2018},
pages={269-276},
doi={10.1145/3284432.3284463},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060683961&doi=10.1145%2f3284432.3284463&partnerID=40&md5=d92d271ccdbb03c0d304e6fb56aa496a},
abstract={We report results from an exploratory study with a humanoid robot asking participants (n = 30) to attribute blameworthiness to other robots that made decisions in moral dilemmas. Drawing from current research in machine ethics, we identify three ethical theories that have been formalized for the use in robots: Utilitarianism, Deontology, and Value-based ethics. We aligned these ethical theories with the attributions of blame. Our results suggest that a utilitarian robot, although attractive from a computational point of view because of its calculative nature, accumulates most blame across several dilemmas as compared to its alternatives—most significantly in dilemmas that occur in everyday life. Therefore ethical decision making for companion robots may best be implemented using rule-based or value-based procedures rather than utilitarian calculi. © 2018 Association for Computing Machinery.},
author_keywords={Blame;  Ethics;  HRI;  Moral judgment;  Value ethics},
keywords={Anthropomorphic robots;  Biomineralization;  Computation theory;  Decision making, Blame;  Companion robot;  Ethical decision making;  Ethical theories;  Ethics;  Exploratory studies;  Moral judgment;  Value ethics, Philosophical aspects},
references={Abel, D., MacGlashan, J., Littman, M.L., Reinforcement Learning as a Framework for Ethical Decision Making (2016) AAAI Workshop: AI, Ethics, and Society, 92; Arkin, R., (2009) Governing Lethal Behavior in Autonomous Robots, , Chapman and Hall/CRC; Bonnefon, J.-F., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2016) Science, 352 (6293), pp. 1572-1576. , 2016; Bringsjord, S., Taylor, J., The Divine-Command Approach to Robot Ethics (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 85-108. , 2012; Cranefield, S., Winikoff, M., Dignum, V., Dignum, F., No Pizza for You: Value-based Plan Selection in BDI Agents (2017) Proceedings of The 26th International Joint Conference on Artificial Intelligence (IJCAI), pp. 178-184; Dennis, L., Fisher, M., Slavkovik, M., Webster, M., Formal verification of ethical choices in autonomous systems (2016) Robotics and Autonomous Systems, 77, pp. 1-14. , https://doi.org/10.1016/j.robot.2015.11.012, 2016; Dignum, V., Responsible Autonomy (2017) Proceedings of The 26th International Joint Conference on Artificial Intelligence (IJCAI), pp. 4698-4704. , AAAI Press; Driver, J., The History of Utilitarianism (2014) The Stanford Encyclopedia of Philosophy, , (Winter 2014 ed.), Edward N. Zalta (Ed.). Metaphysics Research Lab, Stanford University; Govindarajulu, N.S., Bringsjord, S., On automating the doctrine of double effect (2017) Proceedings of The 26th International Joint Conference on Artificial Intelligence (IJCAI), pp. 4722-4730; Groom, V., Chen, J., Johnson, T., Kara, F.A., Nass, C., Critic, compatriot, or chump?: Responses to robot blame attribution (2010) 2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI), pp. 211-217. , https://doi.org/10.1109/HRI.2010.5453192; Jones, T.M., Ethical Decision Making by Individuals in Organizations: An Issue-Contingent Model (1991) Academy of Management Review, 16 (2), pp. 366-395. , 1991; Kaniarasu, P., Steinfeld, A.M., Effects of blame on trust in human robot interaction (2014) The 23rd IEEE International Symposium on Robot and Human Interactive Communication, pp. 850-855. , https://doi.org/10.1109/ROMAN.2014.6926359; Kim, T., Hinds, P., Who should I blame? Effects of autonomy and transparency on attributions in human-robot interaction (2006) Robot and Human Interactive Communication, 2006. ROMAN 2006. The 15th IEEE International Symposium on., pp. 80-85. , IEEE; Lindner, F., Bentzen, M.M., The Hybrid Ethical Reasoning Agent IMMANUEL (2017) Proceedings of The ACM/IEEE International Conference on Human-Robot Interaction, pp. 187-188. , ACM; Lindner, F., Bentzen, M.M., A Formalization of Kant’s Second Formulation of the Categorical Imperative (2018) Proceedings of The 14th International Conference on Deontic Logic and Normative Systems (DEON 2018); Lindner, F., Bentzen, M.M., Nebel, B., The HERA approach to morally competent robots (2017) 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 6991-6997. , https://doi.org/10.1109/IROS.2017.8206625; Lindner, F., Wächter, L., Bentzen, M.M., Discussions About Lying With an Ethical Reasoning Robot (2017) Proceedings of The 2017 IEEE International Symposium on Robot and Human Interactive Communication (ROMAN’17); Malle, B.F., Guglielmo, S., Monroe, A.E., A theory of blame (2014) Psychological Inquiry, 25 (2), pp. 147-186. , 2014; Malle, B.F., Scheutz, M., Forlizzi, J., Voiklis, J., Which Robot Am I Thinking About?: The Impact of Action and Appearance on People’s Evaluations of a Moral Robot (2016) The Eleventh ACM/IEEE International Conference on Human Robot Interaction, pp. 125-132. , IEEE Press; Schwartz, S.H., An overview of the Schwartz theory of basic values (2012) Online Readings in Psychology and Culture, 2 (1), p. 11. , 2012; Stellmach, H., Lindner, F., Perception of an Uncertain Ethical Reasoning Robot: A Pilot Study (2018) Mensch und Computer 2018 – Tagungsband, , Gesellschaft für Informatik e., Bonn; Winfield, A.F.T., Blum, C., Liu, W., Towards an ethical robot: Internal models, consequences and ethical action selection (2014) Conference Towards Autonomous Robotic Systems, pp. 85-96. , Springer},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Koimizu2018143,
author={Koimizu, J. and Kokado, M. and Kato, K.},
title={Ethical Perspectives of Japanese Engineers on Ambient Assisted Living Technologies: Semi-structured Interview},
journal={Asian Bioethics Review},
year={2018},
volume={10},
number={2},
pages={143-155},
doi={10.1007/s41649-018-0053-0},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050819663&doi=10.1007%2fs41649-018-0053-0&partnerID=40&md5=aa606f1fb0e58b101d4c1c2b266daa96},
abstract={Ambient assisted living (AAL) technologies are expected to solve a significant number of problems related to elderly care. However, in Japan, limited discourse on the ethical issues concerning their application is hindering the spread of AAL technologies. Against this background, this study explores the ethical perspectives of AAL technology engineers in Japanese companies and the circumstances influencing their perspectives. A qualitative study using semi-structured interviews was conducted. Nineteen Japanese AAL-technology companies were contacted, and nine of them and their engineers responded to the interviews. The contents of the interviews were analyzed with thematic analysis which showed that the engineers had ethical concerns about their products as follows: (1) safety and related conflicts, (2) acceptance of the technology, (3) dependence on the technology, (4) accident liability, (5) fair access to the technologies, and (6) privacy. In relation to these issues, they identified as company employees with regard to the following: responding to social needs, having many users, and cost reduction. They also mentioned being influenced by the Japanese national program for AAL-technology promotion. The engineers experienced dilemmas between the various stakeholders’ interests and they hoped that ethical guidelines for developing AAL technologies would resolve such dilemmas. In conclusion, Japanese AAL-technology engineers tackle ethical issues with regard to the application of their products. The engineers hope for the establishment of guidelines for the ethically responsible development of AAL technologies. The guidelines need to be established and implemented in an interactive manner, in order to avoid their being reduced to a bureaucratic formality. © 2018, National University of Singapore and Springer Nature Singapore Pte Ltd.},
author_keywords={Ambient assisted living technology;  Engineering ethics;  Ethics in elderly care;  Robot ethics},
references={Bortz, W., Disuse and aging, 2009 (2009) Journals of Gerontology Series A: Biomedical Sciences and Medical Sciences., 65 (4), pp. 382-385; Standard highlighting the ethical hazards of robots is published (2016) BSI Press Releases, , https://www.bsigroup.com/en-GB/about-bsi/media-centre/press-releases/2016/april/-Standard--highlighting-the-ethical-hazards-of-robots-is-published/, Accessed 11 Jan 2018; Dawkins, C.E., The principle of good faith: Toward substantive stakeholder engagement (2014) Journal of Business Ethics., 121 (2), pp. 283-295; Fereday, J., Muir-Cochrane, E., Demonstrating rigor using thematic analysis: A hybrid approach of inductive and deductive coding and theme development (2006) International journal of qualitative methods., 5 (1), pp. 80-92; Friedman, B., Kahnborning, A., (2002) Value Sensitive Design: Theory and Methods, pp. 02-12. , University of Washington technical report; Fusch, P.I., Ness, L.R., Are we there yet? Data saturation in qualitative research (2015) The Qualitative Report., 20 (9), pp. 1408-1416; Hofmann, B., Ethical challenges with welfare technology: A review of the literature (2013) Science and Engineering Ethics., 19 (2), pp. 389-406; Ienca, M., Wangmo, T., Jotterand, F., Kressig, R.W., Elger, B., Ethical design of intelligent assistive technologies for dementia: A descriptive review (2017) Science and Engineering Ethics, , https://doi.org/10.1007/s11948-017-9976-1; Kosta, E., Pitkänen, O., Niemelä, M., Kaasinen, E., Mobile-centric ambient intelligence in health- and homecare-anticipating ethical and legal challenges (2010) Science and Engineering Ethics., 16 (2), pp. 303-323; Luther, C., Radovic, I., Perspectives on privacy, information technology and company/governmental surveillance in Japan (2012) Surveillance & Society., 10 (3-4), pp. 263-275; Martin, S., Bengtsson, J.E., Dröes, R.-M., Assistive technologies and issues relating to privacy, ethics and security (2010) Supporting people with dementia using pervasive health technologies, pp. 63-76. , Mulvenna MD, Nugent CD, (eds), Springer, London; Novitzky, P., Smeaton, A.F., Chen, C., Irving, K., Jacquemard, T., O’Brolcháin, F., O’Mathúna, D., Gordijn, B., A review of contemporary work on the ethics of ambient assisted living technologies for people with dementia (2015) Science and Engineering Ethics., 21 (3), pp. 707-765; (2014) Kikai No Merit to Anzen Heno Fuan: Kaigoyou Robot Ni Kansuru Ankeito Chousa, , http://www.nursing-plaza.com/report/details/201407.html, Nursing Plaza, [in Japanese] (merits of machines and anxiety for safety: Questionnaire survey in relation to the use of elderly care robots). Nursing Plaza. Accessed 16 Aug 2017; Okawayamada, Y., (2013) Kaihatsu Konseputo Shito Sakusei No Pointo[In Japanese](The Points in Filling the Developmental Concept Form), , http://robotcare.jp/wp-content/uploads/2014/01/SG-1-2_development_help.pdf, Robotic Devices for Nursing Care Project, Accessed 11 Jan 2018; (2015) Robot Shakai No Shouraizou Robot × Mirai × Yumebijon [In Japanese](Future Vision of Robots-Assisted Society: Robots, Future, and Dream Vision), , http://interactive.pesti.jp/robot/, PESTI, Accessed 8 Apr 2017; (2013) Robotic Care Devices Portal, , http://robotcare.jp/, Robotic devices for nursing care project. Accessed 18 Aug 2017; Sponselee, A.-M., Schouten, B., Bouwhuis, D., Willems, C., Smart home technology for the elderly: perceptions of multidisciplinary stakeholders (2008) Constructing Ambient Intelligence, AmI 2007, Communications in Computer and Information Science, 11, pp. 314-326. , Mühlhäuser M, Ferscha A, Aitenbichler E, (eds), Springer, Berlin; (2013) Kaigo Robot Ni Kansuru Tokubetsu-Yoronchousa No Gaiyou [In Japanese](The Summary of Public Opinion Survey on Elderly Nursing Care Robots), , http://survey.gov-online.go.jp/tokubetu/h25/h25-kaigo.pdf, The Cabinet of Japan, Accessed 15 Aug 2017; Kemenademargo, V., Konijn, A.M.E.A., Hoorn, J.F., Robots humanize care moral concerns versus witnessed benefits for the elderly (2015) Proceedings of the International Conference on Health Informatics, 1, pp. 648-653. , https://doi.org/10.5220/0005287706480653, HEALTHINF, (BIOSTEC 2015; Yamauchi, S., Robotto Kenkyusya no tame no Rinri Shinsa [in Japanese](IRB review for protocols in robotics) (2011) Journal of the Robotics Society of Japan., 29 (3), pp. 225-230; Yamauchi, S., (2013) Robotto Kaihatsu Ni Kakawaru Rinri Mondai, , http://www.rehab.go.jp/ri/event/assist/papers/14.pdf, in Japanese, ethical issues in relation to development of robotics, National Rehabilitation Center for Persons with Disabilities, Accessed 11 Jan 2018; Mary, Z., Special Interface requirements for older adults (2001) Proceedings of the 2001 ECNSF Workshop on Universal Accessibility of Ubiquitous Computing, pp. 60-65. , https://doi.org/10.1145/564542.564543},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Williams2018281,
author={Williams, T.},
title={Toward Ethical Natural Language Generation for Human-Robot Interaction},
journal={ACM/IEEE International Conference on Human-Robot Interaction},
year={2018},
pages={281-282},
doi={10.1145/3173386.3176975},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045285359&doi=10.1145%2f3173386.3176975&partnerID=40&md5=8b570505688280c432096fa315b54d7a},
abstract={Recent work on natural language generation algorithms for human-robot interaction has not considered the ethical implications of such algorithms. In this work, we argue that simply by asking for clarification, a robot may unintentionally communicate that it would be willing to perform an unethical action, even if it has ethical programming that would prevent it from doing so. In doing so, the robot may not only miscommunicate its own ethical programming, but negatively influence the morality of its human teammates. © 2018 Author.},
author_keywords={human-robot dialogue;  natural-language generation;  robot ethics},
keywords={Man machine systems;  Natural language processing systems;  Philosophical aspects;  Robot programming, Ethical implications;  Human-robot dialogue;  Natural language generation;  Robot ethics;  Unethical actions, Human robot interaction},
references={Arnold, T., Scheutz, M., Beyond moral dilemmas: Exploring the ethical landscape in hri (2017) Proceedings of HRI. ACM, pp. 445-452; Göckeritz, S., Schmidt, M.F.H., Tomasello, M., Young Children's Creation and Transmission of Social Norms (2014) Cog. Devel., 2014; Hancock, P., Billings, D., Schaefer, K., (2011) Can You Trust Your Robot Ergonomics in Design: The Quarterly of Human Factors Apps; Hancock, P., Billings, D., Schaefer, K., A meta-analysis of factors affecting trust in human-robot interaction (2011) Human Factors; Leidner, J.L., Plachouras, V., Ethical by design: Ethics best practices for natural language processing (2017) Proceedings of EACL, 2017; Malle, B.F., Scheutz, M., Moral Competence in Social Robots (2014) Symposium on Ethics in Science, Technology and Engineering. IEEE; Malle, B.F., Scheutz, M., Austerweil, J.L., Networks of social and moral norms in human and robot agents (2017) A World with Robots; Malle, B.F., Scheutz, M., Forlizzi, J., Voiklis, J., Which Robot Am i Thinking About: The Impact of Action and Appearance on People's Evaluations of a Moral Robot (2016) Proceedings of HRI. ACM, pp. 125-132; Marge, M., Rudnicky, A.I., Miscommunication recovery in physically situated dialogue (2015) Proceedings of SIGDIAL, pp. 22-49; James, H., Moor, The nature, importance, and difficulty of machine ethics (2006) Intelligent Systems, 21 (4), pp. 18-21. , 2006; Neerincx, M.A., Modelling cognitive and affective load for the design of human-machine collaboration (2007) Eng. Psych. and Cognitive Ergonomics; Schaefer, K.E., Straub, E.R., Chen, J.Y.C., Putney, J., Evans, A.W., Communicating intent to develop shared situation awareness and engender trust in human-agent teams (2017) Cognitive Systems Research, 2017; Scheutz, M., 13 the Inherent Dangers of Unidirectional Emotional Bonds between Humans and Social Robots (2011) Robot Ethics. MIT Press, 205; Scheutz, M., The need for moral competency in autonomous agent architectures (2016) Fundamental Issues of Artificial Intelligence, pp. 515-525. , Springer; Scheutz, M., Malle, B., Think and do the right thing-A Plea for morally competent autonomous robots (2014) Symp. on Eth. Sci. Tech. Eng; Steven Siegel, M., (2008) Persuasive Robotics: How Robots Change Our Minds, , Ph.D. Dissertation. Massachusetts Institute of Technology; Simmons, R., Makatchev, M., Kirby, R., Kyung Lee, M., Believable robot characters (2011) AI Magazine, 32 (4), pp. 39-52; Tellex, S., Thaker, P., Deits, R., Simeonov, D., Toward information theoretic human-robot dialog (2013) Robotics, 32 (2013), pp. 409-417; Thieltges, A., Schmidt, F., Hegelich, S., The devil's triangle: Ethical considerations on developing bot detection methods (2016) Proceedings of the AAAI Spring Symposium Series, pp. 253-257; Traum, D.R., (1994) A Computational Theory of Grounding in Natural Language Conversation, , Ph.D. Dissertation. University of Rochester, Rochester, NY; Verbeek, P., (2011) Moralizing Technology: Understanding and Designing the Morality of Things, , University of Chicago Press; Voiklis, J., Malle, B.F., Moral cognition and its basis in social cognition and social regulation (2017) Atlas of Moral Psychology, 2017; Williams, T., Briggs, P., Scheutz, M., Covert robot-robot communication: Human perceptions and implications for human-robot interaction (2015) Journal of Human-Robot Interaction, 2015; Williams, T., Scheutz, M., Resolution of referential ambiguity in human-robot dialogue using dempster-shafer theoretic pragmatics (2017) Proceedings of Robotics: Science and Systems},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Alaieri2018203,
author={Alaieri, F. and Vellino, A.},
title={A decision making model for ethical (ro)bots},
journal={Proceedings - 2017 IEEE 5th International Symposium on Robotics and Intelligent Sensors, IRIS 2017},
year={2018},
volume={2018-January},
pages={203-207},
doi={10.1109/IRIS.2017.8250122},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047394601&doi=10.1109%2fIRIS.2017.8250122&partnerID=40&md5=62ebf901c9ba6a3a88d5674619201b96},
abstract={Autonomous bots and robots (we label '(ro)bots'), ranging from shopping assistant chatbots to self-driving cars are already able to make decisions that have ethical consequences. As more such machines make increasingly complex and significant decisions, we need to know that their decisions are trustworthy and ethically justified so that users, manufacturers and lawmakers can understand how these decisions are made and which ethical principles were brought to bear in making them. Understanding how such decisions are made is particularly important in the case where a (ro)bot is a self-improving, selflearning type of machine whose choices and decisions are based on past experience, given that they may not be entirely predictable ahead of time or explainable after the fact. This paper presents a model that decomposes the stages of ethical decision making into their elementary components with a view to enabling stakeholders to allocate the responsibility for such choices. © 2017 IEEE.},
author_keywords={Autonomy;  Decision making;  Machine ethics;  Responsibility;  Trust},
keywords={Automobile manufacture;  Botnet;  Intelligent control;  Philosophical aspects;  Robotics;  Smart sensors, After-the-fact;  Autonomy;  Decision making models;  Ethical decision making;  Ethical principles;  Responsibility;  Self-learning;  Trust, Decision making},
references={Vellino, A., Alberts, I., Assisting the appraisal of e-mail records with automatic classification (2016) Records Management Journal, 26 (3), pp. 293-313; Lafrance, A., (2016) What Is A Robot?, , https://www.theatlantic.com/technology/archive/2016/03/what-is-ahuman/473166/, March 22Retrieved January 1, 2017, from; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press; Gips, J., Towards the ethical robot (1991) The Second International Workshop on Human and Machine Cognition Android Epistemology, , Florida; Tzafestas, S.G., Roboethics (2016) A Navigating Overview, 79. , Springer, Heidelberg; Alpaydin, E., (2010) Introduction to Machine Learning, , (T. Dietterich, C. Bishop, D. Heckerman, M. Jordan, & M. Kearns, Eds.) (2nd ed.). London: The MIT Press; Ferrucci, D., Brown, E., Chu-Carroll, J., Fan, J., Gondek, D., Kalyanpur, A.A., Building watson: An overview of the deepqa project (2010) AI Magazine, 31 (3), pp. 59-79; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) Intelligent Systems, IEEE, 21 (4), pp. 12-17. , http://doi.org/10.1109/MIS.2006.83; Allen, C., Smit, I., Wallach, W., Artificial morality: Topdown, bottom-up, and hybrid approaches (2005) Ethics and Information Technology, 7 (3), pp. 149-155. , http://doi.org/10.1007/s10676-006-0004-4; Beer, J.M., Fisk, A.D., Rogers, W.A., Toward a framework for levels of robot autonomy in human-robot interaction (2014) Journal of Human-Robot Interaction, 3 (2), pp. 74-77. , http://doi.org/10.5898/JHRI.3.2.Beer; Vanderelst, D., Winfield, A., An architecture for ethical robots inspired by the simulation theory of cognition (2017) Cognitive Systems Research, , https://doi.org/10.1016/j.cogsys.2017.04.002, May 2017; Parasuraman, R., Sheridan, T.B., Wickens, C.D., A model for types and levels of human interaction with automation (2000) IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans, 30 (3), pp. 286-297; Lonsdorf, K., (2017) Hungry? Call Your Neighborhood Delivery Robot, , http://www.npr.org/sections/alltechconsidered/2017/03/23/520848983/hungry-call-your-neighborhood-delivery-robot, March 23 Retrieved July 3, 2017, from; Mathur, V., Stavrakas, Y., Singh, S., Intelligence analysis of tay twitter bot (2016) 2nd International Conference on Contemporary Computing and Informatics (IC3I, pp. 231-236. , December IEEE 2016},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Baum2018,
author={Baum, K. and Hermanns, H. and Speith, T.},
title={From machine ethics to machine explainability and back},
journal={International Symposium on Artificial Intelligence and Mathematics, ISAIM 2018},
year={2018},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069636402&partnerID=40&md5=bc6d80b440e491ee14f51df64ba1040f},
abstract={We find ourselves surrounded by a rapidly increasing number of autonomous and semi-autonomous systems. Two grand challenges arise from this development: Machine Ethics and Machine Explainability. Machine Ethics, on the one hand, is concerned with behavioral constraints for systems, set up in a formal unambiguous, algorithmizable, and implementable way, so that morally acceptable, restricted behavior results; Machine Explainability, on the other hand, enables systems to explain their actions and argue for their decisions, so that human users can understand and justifiably trust them. In this paper, we stress the need to link and cross-fertilize these two areas. We point out how Machine Ethics calls for Machine Explainability, and how Machine Explainability involves Machine Ethics. We develop both these facets based on a toy example from the context of medical care robots. In this context, we argue that moral behavior, even if it were verifiable and verified, is not enough to establish justified trust in an autonomous system. It needs to be supplemented with the ability to explain decisions and should thus be supplemented by a Machine Explanation component. Conversely, such explanations need to refer to the system’s model- and constraint-based Machine Ethics reasoning. We propose to apply a framework of formal argumentation theory for the task of generating useful explanations of the Machine Explanation component and we sketch out how the content of the arguments must use the moral reasoning of the Machine Ethics component. © 2018 University of Virginia. All rights reserved.},
keywords={Artificial intelligence, Autonomous systems;  Constraint-based;  Formal argumentation;  Grand Challenge;  Human users;  Moral reasoning;  S models;  Semi-autonomous systems, Philosophical aspects},
references={Alonso, J.M., Trivino, G., An essay on self-explanatory computational intelligence: A linguistic model of data processing systems (2017) Proceedings of the 1st Workshop on Explainable Computational Intelligence (XCI 2017); Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge University Press; Austin, J.L., A plea for excuses (1964) Ordinary Language: Essays in Philosophical Method, pp. 1-30. , Ed. by V.C. Chappell. Dover Publications; Barthe, G., Facets of software doping (2016) International Symposium on Leveraging Applications of Formal Methods, pp. 601-608. , Springer; Baum, K., What the hack is wrong with software doping? (2016) International Symposium on Leveraging Applications of Formal Methods, pp. 633-647; Baum, K., Köhl, M.A., Schmidt, E., Two challenges for CI trustworthiness and how to address them (2017) Proceedings of the 1st Workshop on Explainable Computational Intelligence (XCI 2017); Bonnefon, J.-F., Shariff, A., Rahwan, I., (2015) Autonomous Vehicles Need Experimental Ethics: Are We Ready for Utilitarian Cars?, , arXiv preprint; Bonnefon, J.-F., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2016) Science, 352 (6293), pp. 1573-1576; Bostrom, N., Yudkowsky, E., The ethics of artificial intelligence (2014) The Cambridge Handbook of Artificial Intelligence, pp. 316-334; Carlini, N., Wagner, D., (2017) Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods, , arXiv preprint; D’Argenio, P.R., Is your software on dope? (2017) European Symposium on Programming, pp. 83-110. , Springer; Davidson, D., Actions, reasons, and causes (1963) The Journal of Philosophy, 60 (23), pp. 685-700; Dung, P.M., On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games (1995) Artificial Intelligence, 77 (2), pp. 321-357; Franklin, B., Letter to J. B. Priestley, 1772 (1887) The Complete Works, p. 522. , Ed. by J. Bigelow. New York: Putnam; Goodfellow, I.J., Shlens, J., Szegedy, C., (2014) Explaining and Harnessing Adversarial Examples, , arXiv preprint; Hein, M., Andriushchenko, M., (2017) Formal Guarantees on the Robustness of a Classifier Against Adversarial Manipulation, , arXiv preprint; Hengstler, M., Enkel, E., Duelli, S., Applied artificial intelligence and trust—the case of autonomous vehicles and medical assistance devices (2016) Technological Forecasting and Social Change, 105, pp. 105-120; Hibbard, B., Avoiding unintended AI behaviors (2012) AGI, pp. 107-116. , Springer; Horacek, H., Requirements for conceptual representations of explanations and how reasoning systems can serve them (2017) Proceedings of the 1st Workshop on Explainable Computational Intelligence (XCI 2017); Kant, I., (1998) Critique of Pure Reason, , Cambridge University Press; Langley, P., Explainable agency for intelligent autonomous systems (2017) AAAI, pp. 4762-4764; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Muehlhauser, L., Helm, L., The singularity and machine ethics (2012) Singularity Hypotheses, pp. 101-126. , Springer; Wallach, W., Allen, C., (2008) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press; Yampolskiy, R.V., Artificial intelligence safety engineering: Why machine ethics is a wrong approach (2013) Philosophy and Theory of Artificial Intelligence, pp. 389-396; Yudkowsky, E., Complex value systems in friendly AI (2011) Artificial General Intelligence, pp. 388-393},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lumbreras2017,
author={Lumbreras, S.},
title={The limits of machine ethics},
journal={Religions},
year={2017},
volume={8},
number={5},
doi={10.3390/rel8050100},
art_number={100},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020401834&doi=10.3390%2frel8050100&partnerID=40&md5=11fc641b1d42709798fcc667b68e037a},
abstract={Machine Ethics has established itself as a new discipline that studies how to endow autonomous devices with ethical behavior. This paper provides a general framework for classifying the different approaches that are currently being explored in the field of machine ethics and introduces considerations that are missing from the current debate. In particular, law-based codes implemented as external filters for action—which we have named filtered decision making—are proposed as the basis for future developments. The emergence of values as guides for action is discussed, and personal language –together with subjectivity- are indicated as necessary conditions for this development. Last, utilitarian approaches are studied and the importance of objective expression as a requisite for their implementation is stressed. Only values expressed by the programmer in a public language—that is, separate of subjective considerations—can be evolved in a learning machine, therefore establishing the limits of present-day machine ethics. © 2017 by the author. Licensee MDPI, Basel, Switzerland.},
author_keywords={Ethics of machines;  Learning automata;  Theory of mind;  Values},
references={Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics and Information Technology, 7, pp. 149-155. , [CrossRef]; Arkin, R., (2009) Governing Lethal Behavior in Autonomous Robots, , Boca Raton: CRC Press; Asimov, I., (1950) I, Robot, p. 1. , Robot. New York: Gnome Press; Avraham, R., Logue, K.D., Schwarcz, D., Understanding Insurance Anti-Discrimination Laws (2012), http://repository.law.umich.edu/cgi/viewcontent.cgi?article=1163&context=law_econ_current, (accessed on 19 May 2017); Campbell, R.L., Christopher, J.C., Bickhard, M.H., Self and values: An interactivist foundation for moral development (2002) Theory & Psychology, 12, pp. 795-823; Casey, B.J., (2017) Amoral Machines, Or: How Roboticists Can Learn to Stop Worrying and Love the Law, , https://ssrn.com/abstract=2923040, (accessed on 1 May 2017); Danielson, P., (1998) Modeling Rationality, Morality, and Evolution, , Oxford: Oxford University Press on Demand; Floridi, L., Information ethics, its nature and scope (2005) ACM SIGCAS Computers and Society, 35, p. 3. , [CrossRef]; Greene, J.D., Sommerville, R.B., Nystrom, L.E., Darley, J.M., Cohen, J.D., An fMRI investigation of emotional engagement in moral judgment (2001) Science Magazine, 293, pp. 2105-2108. , [CrossRef][PubMed]; Handelsman, M.M., Knapp, S., Michael, C.G., 2009. Positive ethics: Themes and variations Oxford Handbook of Positive Psychology, pp. 105-113. , Oxford: Oxford University Press; Hardy, S.A., Carlo, G., Moral identity: What is it, how does it develop, and is it linked to moral action? (2011) Child Development Perspectives, 5, pp. 212-218. , [CrossRef]; Head, S., (2014) Mindless: Why Smarter Machines are Making Dumber Humans, , New York: Basic Books; Honderich, T., (2005) The Oxford Companion to Philosophy, , Oxford: Oxford University Press; Howard, R.A., Korver, C.D., (2008) Ethics for the Real World: Creating a Personal Code to Guide Decisions in Work and Life, , Cambridge: Harvard Business Press; World Robotics 2016 (2016) Frankfurt: International Federation of Robotics; Jackson, F., Decision-theoretic consequentialism and the nearest and dearest objection (1991) Ethics, 101, pp. 461-482. , [CrossRef]; Kahneman, D., (2011) Thinking, Fast and Slow, , New York: Macmillan; Kant, I., Abbott, T.K., (2004) Critique of Practical Reason, , Miami: Courier Corporation; Kuipers, B., Drinking from the firehose of experience (2008) Artificial Intelligence in Medicine, 44, pp. 155-170. , [CrossRef][PubMed]; Kurzweil, R., (2012) How to Create a Mind: The Secret of Human Thought Revealed, , London: Penguin; Lapsley, D.K., Narvaez, D., Character education (2006) In Handbook of Child Psychology, , New York: John Wiley & Sons; Leach, J., (2011) Mathematics and Religion: Our Languages of Sign and Symbol, , West Conshohocken Templeton Foundation Press; Lichtenberg, J., Negative duties, positive duties, and the "new harms (2010) Ethics, 120, pp. 557-578. , [CrossRef]; Luxton, D.D., Recommendations for the ethical use and design of artificial intelligent care providers (2014) Artificial Intelligence in Medicine, 62, pp. 1-10. , [CrossRef][PubMed]; Martin, J., Self-regulated learning, social cognitive theory, and agency (2004) Educational Psychologist, 39, pp. 135-145. , [CrossRef]; Powers, T.M., Prospects for a kantian machine (2006) IEEE Intelligent Systems, 21, pp. 46-51. , [CrossRef]; Rosenbrock, H.H., (1990) Machines with a Purpose, , Oxford: Oxford University Press; Slote, M.A., (1985) Common-Sense Morality and Consequentialism, , Abingdon-on-Thames: Routledge & Kegan; Voort, V.D., Marlies, W.P., Consoli, L., Refining the ethics of computer-made decisions: A classification of moral mediation by ubiquitous machines (2015) Ethics and Information Technology, 17, pp. 41-56. , [CrossRef]; Veruggio, G., Operto, F., George, B., Roboethics: Social and ethical implications (2016) Springer Handbook of Robotics, pp. 2135-2160. , Berlin and Heidelberg: Springer; Wilson, E.O., (1975) Sociology: New Synthesis, , Cambridge: Belknap Press; Yampolskiy, R., Fox, J., Safety engineering for artificial general intelligence (2013) Topoi, 32, pp. 217-226. , [CrossRef]},
document_type={Article},
source={Scopus},
}

@BOOK{Beavers2017143,
author={Beavers, A.F. and Slattery, J.P.},
title={On the Moral Implications and Restrictions Surrounding Affective Computing},
journal={Emotions and Affect in Human Factors and Human-Computer Interaction},
year={2017},
pages={143-161},
doi={10.1016/B978-0-12-801851-4.00005-7},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029358978&doi=10.1016%2fB978-0-12-801851-4.00005-7&partnerID=40&md5=1d94e5f76e6e157cb4ca7d8bcc96405e},
abstract={Building simulated affects into artifacts poses a moral dilemma. On the one hand, in order for humans to interact fully with machines, the machines need to meet them on human terms, and this requires machines that are capable of assessing human affective states and responding to them in kind. On the other hand, doing so amounts to a fundamental deception that humans will find it hard to keep in mind, namely that these machines do not actually have these affective states and may not, therefore, be worthy of our attachment and our moral regard. Yet, simulated affects, we argue, are necessary for creating machines that can make moral decisions, that affects are essential for disambiguating the utterances of machines and humans, and that not all forms of deception are bad. After an initial provocation, these arguments are taken up in order, after which we argue further that while simulated affects are necessary, they could nonetheless lead to abuse. Therefore, the standard ethical limits and principles involved with any technological innovation must be respected. © 2017 Elsevier Inc. All rights reserved.},
author_keywords={Affective artificial agents (AAAs);  Affective computing;  Affectivity;  Human-computer interaction (HCI);  Machine ethics;  Receptivity},
references={(2007) Word Sense Disambiguation: Algorithms and Applications, , Springer, Dordrecht, Netherlands, E. Agirre, P. Edmonds (Eds.); Anderson, M., Anderson, S., Machine ethics: creating an ethical intelligent agent (2007) AI Magazine, 28, pp. 15-26; Arkin, R., (2011) The Ethics of Robotic Deception, , Report from the Georgia Institute of Technology Mobile Robot Laboratory, Atlanta, Georgia; Arkin, R., (2012) Robots that Need to Mislead: Biologically-Inspired Machine Deception, , Report from the Georgia Institute of Technology Mobile Robot Laboratory, Atlanta, Georgia; Arkin, R., Shim, J., A Taxonomy of Robot Deception and its Benefits in HRI (2013) Paper presented at the IEEE International Conference on Systems, Man, and Cybernetics, , Washington, DC; Beavers, A.F., Between angels and animals: the question of robot ethics, or is Kantian moral agency desirable (2009) Paper presented at the annual meeting of the Association for Practical and Professional Ethics, , Cincinnati, Ohio; Beavers, A.F., Cartesian mechanisms and transcendental philosophy (2010) Paper presented at the conference on the myth of the Cartesian 'ego' and the analytic/continental divide, , Radboud University Nijmegen, The Netherlands; Beavers, A.F., Moral machines and the threat of ethical nihilism (2011) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 333-344. , MIT Press, Cambridge, Massachusetts, P. Lin, G. Bekey, K. Abney (Eds.); Beavers, A.F., Could and should the ought disappear from ethics (2012) Digital Ethics: Research and Practice, pp. 197-209. , Peter Lang, New York, D. Heider, A. Massanari (Eds.); Bentham, J., (2007) An Introduction to the Principles of Morals and Legislation, , Dover, Mineola, New York, (Original work published in 1789); Blair, R.J.R., A cognitive developmental approach to morality: investigating the psychopath (1995) Cognition, 57, pp. 1-29; Bringsjord, S., Clark, M., Red pill robots only (2012) IEEE Trans. Affect. Comput, 3, pp. 394-397; Brooker, C., Harris, O., Black Mirror (Television Series) (2013) In: Zeppotron (Producer), , United Kingdom; Cowie, R., The good our field can hope to do, the harm it should avoid (2012) IEEE Trans. Affect. Comput, 3, pp. 410-423; De Sousa, R., Emotion (2014) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/win2015/entries/emotion/, In: Zalta, E.N., (Ed.); Dennett, D., Computers as prostheses for the imagination (2006) Paper presented at the International Computers and Philosophy Conference, , Laval, France; Descartes, R., Discourse on method of rightly conducting one's reason and seeking the truth in the sciences (1985) The Philosophical Writings of Descartes, 1, pp. 111-151. , In: Cottingham, J., Stoothoff, R., Murdoch, D. (Trans.), Cambridge, New York (Original work published in 1637); Descartes, R., Rules for the direction of the mind (1985) The Philosophical Writings of Descartes, 1, pp. 9-78. , In: Cottingham, J., Stoothoff, R., Murdoch, D. (Trans.), Cambridge, New York (Original work published in c. 1628); Descartes, R., The correspondence (1991) The Philosophical Writings of Descartes, 3. , In: Cottingham, J., Stoothoff, R., Murdoch, D. (Trans.), Cambridge University Press, New York (Original letters written 1619 to 1650); Feldman, F., (1978) Introductory Ethics, , Prentice-Hall, Englewood Cliffs, New Jersey; Gallagher, S., Phronesis and psychopathy: the moral frame problem (2013) Philos. Psychiatr. Psychol, 20, pp. 345-348; Grice, H.P., Logic and conversation (1967) Logic of Grammar, pp. 64-75. , Dickenson, Encino, California, D. Davidson, G. Harman (Eds.); Grice, H.P., (1989) Studies in the Way of Words, , Harvard, Cambridge, Massachusetts; Guarini, M., Particularism, analogy, and moral cognition (2010) Minds Mach, 20, pp. 385-422; Horgan, T., Timmons, M., What does the frame problem tell us about moral normativity? (2009) Ethical Theory Moral Pract, 12, pp. 25-51; Kant, I., (1981) Grounding for the Metaphysics of Morals, , In: Ellington, J.W. (Trans.). Hackett, Indianapolis (Original work published in 1785); Korta, K., Perry, J., Pragmatics (2015) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/win2015/entries/pragmatics/, In: Zalta, E.N. (Ed.); Levy, D., (2007) Love and Sex With Robots: The Evolution of Human-Robot Relationships, , Harper Collins, New York; Mill, J.S., (1979) Utilitarianism, , Hackett, Indianapolis, (Original work published in 1861); Minsky, M., (1988) The Society of Mind, , Simon & Schuster, New York; Minsky, M., (2007) The Emotion Machine: Commonsense Thinking, Artificial Intelligence, and the Future of the Human Mind, , Simon & Schuster, New York; Nichols, S., (2004) Sentimental Rules, , Oxford, New York; Nolan, C., Thomas, E., Obst, L., Nolan, C., (2014) Interstellar [Motion Picture], , Paramount Pictures, Warner Bros., Legendary Pictures, Lynda Obst Productions, Syncopy, United States; Powers, T., Prospects for a Kantian machine (2006) IEEE Intell. Syst, 21, pp. 46-51; Prinz, J., (2008) The Emotional Construction of Morals, , Oxford, New York; Scheutz, M., (2011) Evolution of affect and communication, , Affective Computing and Interaction: Psychological, Cognitive, and Neuroscientific Perspectives. IGI Global, Hershey, Pennsylvania; Scheutz, M., The affect dilemma for artificial agents: should we develop affective artificial agents? (2012) IEEE Trans. Affect. Comput, 3, pp. 424-433; Sullins, J.P., Robots, love and sex: the ethics of building a love machine (2012) IEEE Trans. Affect. Comput, 3, pp. 398-409; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right From Wrong, , Oxford, New York},
document_type={Book Chapter},
source={Scopus},
}

@BOOK{Bhargava20175,
author={Bhargava, V. and Kim, T.W.},
title={Autonomous vehicles and moral uncertainty},
journal={Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence},
year={2017},
pages={5-19},
doi={10.1093/oso/9780190652951.003.0001},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058246702&doi=10.1093%2foso%2f9780190652951.003.0001&partnerID=40&md5=76f6a3ae5aecb0bed4c1dd6ac505ebc5},
abstract={The chief purposes of this chapter are to explore the problem of moral uncertainty as it pertains to autonomous vehicles and to outline possible solutions. The problem is the following: How should autonomous vehicles be programmed to act when the person who has the authority to choose the ethics of the autonomous vehicle is under moral uncertainty? Roughly, an agent is morally uncertain when she has access to all (or most) of the relevant non-moral facts, including but not limited to empirical and legal facts, but still remains uncertain about what morality requires of her. We argue that the problem of moral uncertainty in the context of autonomous vehicles is an important problem and then critically engage with two solutions to the problem. We conclude by discussing a solution that we think is more promising-that of the philosopher Andrew Sepielli-and offer some support in its defense. © Oxford University Press 2017. All rights reserved.},
author_keywords={Artificial intelligence;  Autonomous vehicles;  Cars;  Decision making;  Ethics;  Machine ethics;  Morality;  Normative;  Robots;  Uncertainty},
references={De Groot, M.H., (2004) Optimal Statistical Decisions., , New York: Wiley-Interscience; Douma, F., Palodichuk, S.A., Criminal Liability Issues Created by Autonomous Vehicles (2012) Santa Clara Law Review, 52, pp. 1157-1169; Duff, A., Pascal’s Wager and Infinite Utilities (1986) Analysis, 46, pp. 107-109; Enoch, D., A Defense of Moral Deference (2014) Journal of Philosophy, 111, pp. 229-258; Fagnant, D., Kockelman, K.M., (2013) Preparing a Nation for Autonomous Vehicles: Opportunities, Barriers and Policy Recommendations., , Washington, DC:Eno Center for Transportation; Foot, P., The Problem of Abortion and the Doctrine of Double Effect (1967) Oxford Review, 5, pp. 5-15; Goodall, N.J., Ethical Decision Making During Automated Vehicle Crashes (2014) Transportation Research Record: Journal of the Transportation Research Board, pp. 58-65; Goodall, N.J., Vehicle Automation and the Duty to Act (2014) Proceedings of the 21st World Congress on Intelligent Transport Systems., , Detroit; Gurney, J.K., Sue My Car Not Me: Products Liability and Accidents Involving Autonomous Vehicles (2013) Journal of Law, Technology & Policy, 2, pp. 247-277; Gustafsson, J.E., Torpman, O., In Defence of My Favourite Theory (2014) Pacific Philosophical Quarterly, 95, pp. 159-174; Hájek, A., Pascal’s Wager (2012) Stanford Encyclopedia of Philosophy., , http://plato.stanford.edu/entries/pascal-wager/; Hare, C., Obligations to Merely Statistical People (2012) Journal of Philosophy, 109, pp. 378-390; Harman, E., The Irrelevance of Moral Uncertainty (2015) Oxford Studies in Metaethics, pp. 53-79. , vol. 10, edited by Luss-Shafer Laundau, New York: Oxford University Press; Hills, A., Moral Testimony and Moral Epistemology (2009) Ethics, 120, pp. 94-127; Hsieh, N.-Ĥ., Strudler, A., Wasserman, D., The Numbers Problem (2006) Philosophy & Public Affairs, 34, pp. 352-372; Jones, K., Second-Hand Moral Knowledge (1999) Journal of Philosophy, 96, pp. 55-78; Lin, P., The Robot Car of Tomorrow May Just Be Programmed to Hit You (2014) Wired, , http://www.wired.com/2014/05/the-robot-car-of-tomorrowmight-just-be-programmed-to-hit-you/, May 6; Lin, P., Why Ethics Matters for Autonomous Cars (2015) Autonomes Fahren, pp. 70-85. , edited by M. Maurer, C. Gerdes, B. Lenz, and H. Winner, Berlin: Springer; Lin, P., Abney, K., Bekey, G.A., (2012) Robot Ethics: The Ethical and Social Implications of Robotics., , Cambridge, MA: MIT Press; Lockhart, T., (2000) Moral Uncertainty and Its Consequences., , New York: Oxford University Press; MacAskill, W., Normative Uncertainty as a Voting Problem (2016) Mind.; Mackie, J.L., (1982) The Miracle of Theism., , New York: Oxford University Press; Millar, J., You Should Have a Say in Your Robot Car’s Code of Ethics (2014) Wired, , http://www.wired.com/2014/09/set-the-ethics-robot-car/, September 2; Nourbakhsh, I.R., (2013) Robot Futures., , Cambridge, MA: MIT Press; Parfit, D., (2017) On What Matters, , part 3. Oxford University Press; Pascal, B., (1670) Pensées., , Translated by A. K. Krailsheimer. Reprint, Baltimore: Penguin Books; Raiffa, H., (1997) Decision Analysis: Introductory Lectures on Choices under Uncertainty., , New York: McGraw-Hill College; Rescher, N., (1985) Pascal’s Wager., , South Bend, IN: Notre Dame University; Sepielli, A., Review of Ted Lockhart’s Moral Uncertainty and Its Consequences (2006) Ethics, 116, pp. 601-604; Sepielli, A., What to Do When You Don’t Know What to Do (2009) Oxford Studies in Metaethics, 4, pp. 5-28. , edited by Russ-Shafer Laundau, New York:Oxford University Press; Sepielli, A., (2010) Along an Imperfectly-Lighted Path: Practical Rationality and Normative Uncertainty., , PhD dissertation, Rutgers University; Sepielli, A., Normative Uncertainty for Non-Cognitivists (2012) Philosophical Studies, 160, pp. 191-207; Sepielli, A., What to Do When You Don’t Know What to Do When You Don’t Know What to Do… (2013) Nous, 47, pp. 521-544; Sepielli, A., Moral Uncertainty Routledge Handbook of Moral Epistemology, , Forthcoming, edited by Karen Jones. Abingdon: Routledge; Snow, N.E., Humility (1995) Journal of Value Inquiry, 29, pp. 203-216; Thomson, J.J., Killing, Letting Die, and the Trolley Problem (1976) Monist, 59, pp. 204-217; Urmson, C., (2014) Just Press Go: Designing a Self-driving Vehicle., , http://googleblog.blogspot.com/2014/05/just-press-go-designingself-driving.html, Google Official Blog, May 27; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong., , New York: Oxford University Press; Werhane, P., (1999) Moral Imagination and Management Decision-Making., , New York: Oxford University Press},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Bendel20172,
author={Bendel, O.},
title={LADYBIRD: The animal-friendly robot vacuum cleaner},
journal={AAAI Spring Symposium - Technical Report},
year={2017},
volume={SS-17-01 - SS-17-08},
pages={2-6},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028711719&partnerID=40&md5=c6172e57aba93eca1a91750ac9fec2cf},
abstract={More and more autonomous and semi-autonomous machines make decisions that have moral implications. Machine ethics as a discipline examines the possibilities and limits of moral machines. In this context, the author developed various design studies and thus submitted proposals for their appearance and functions. He focused on animal-friendly machines which make morally sound decisions, and chatbots with specific skills. For the design of moral machines decision trees are still little used. This article focuses on a service robot which shall spare beneficial insects - a vacuum cleaner called LADYBIRD - and an annotated decision tree modelled for this objective will be presented. The outlined work leads to a practice project that was proposed in spring 2017 at the School of Business FHNW. © Copyright 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
keywords={Animals;  Artificial intelligence;  Decision trees;  Machine oriented languages;  Vacuum cleaners, Autonomous machines;  Chatbots;  Design studies;  Practice projects;  Robot vacuum cleaners;  Service robots;  Sound decision, Learning systems},
references={Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge: Cambridge University Press; Azad-Manjiri, M., A new architecture for making moral agents based on C4.5 decision tree algorithm (2014) International Journal of Information Technology and Computer Science (IJITCS), 6 (5), pp. 50-57. , April 2014; Bendel, O., Annotated decision trees for simple moral machines (2016) The 2016 AAAI Spring Symposium Series, pp. 195-201. , Palo Alto: AAAI Press; Bendel, O., Einfache moralische Maschinen: Vom Design zur Konzeption (2015) Prozesse, Technologie, Anwendungen, Systeme und Management 2015, pp. 171-180. , Barton, T.; Erdlenbruch, B.; and Herrmann, F. et al. eds. 2015 Tagungsband zur 28. AKWI-Jahrestagung vom 06.09.2015 bis 09.09.2015 an der Hochschule Luzern - Wirtschaft. Heide: mana-Buch; Bendel, O., Die Roboter sind unter uns (2014) Netzwoche, p. 28. , 22/2014; Bendel, O., Advanced driver assistance systems and animals (2014) Künstliche Intelligenz, 28 (4), pp. 263-269. , (2014); Bendel, O., Fahrerassistenzsysteme aus ethischer Sicht (2014) Zeitschrift für Verkehrssicherheit, pp. 108-110. , 2/2014; Bendel, O., Wirtschaftliche und technische Implikationen der Maschinenethik (2014) Die Betriebswirtschaft, pp. 237-248. , 4/2014; Bendel, O., (2013) Ich Bremse Auch für Tiere: Überlegungen Zu Einfachen Moralischen Maschinen, , http://www.inside-it.ch/articles/34646, inside-it.ch, December 4, 2013; Bendel, O., Maschinenethik (2012) Gabler Wirtschaftslexikon, , http://wirtschaftslexikon.gabler.de/Definition/maschinenethik.html, Wiesbaden: Springer Gabler; Deghani, M., Forbus, K., Tomai, E., Klenk, M., An integrated reasoning approach to moral decision making (2011) Machine Ethics, pp. 237-248. , Anderson, M.; and Anderson, S. L. eds. 2011 Cambridge: Cambridge University Press; Federle, S., Radar soll Zugvögel schützen (2014) Tierwelt, (10), pp. 22-23. , March 5, 2014; Hueber, J., Wir sehen Farbe - das können Sensoren auch! (2013) Sensor Magazin, pp. 8-11. , 1; Mancini, C., Animal-computer interaction (ACI): A manifesto (2011) Interactions, 18 (4), pp. 69-73. , 2011; Mondada, F., Halloy, J., Martinoli, A., A general methodology for the control of mixed natural-artificial societies (2013) Handbook of Collective Robotics: Fundamentals and Challenges, , Kernbach, S. ed. Boca Raton: Taylor & Francis; Pereira, L.M., Saptawijaya, A., (2016) Programming Machine Ethics, , Springer International Publishing Switzerland, Cham; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford: Oxford University Press},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Tran201677,
author={Tran, B.},
title={Machine (technology) ethics: The theoretical and philosophical paradigms},
journal={International Journal of Technoethics},
year={2016},
volume={7},
number={2},
pages={77-90},
doi={10.4018/IJT.2016070105},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971607208&doi=10.4018%2fIJT.2016070105&partnerID=40&md5=cf44796fd4ea544f484ba1ef76a58004},
abstract={At the foundational level, for computer programmers, the code that programmers build and built into, are based on instructions, and the purpose of the program it later services. But computers do not have their own discretion beyond what humans incorporate into such systems and are essentially limited only to the extent its writer chooses. However, ABET to date, does not provide assurance or require accredited colleges and universities programs in applied science, computing, engineering, and engineering technology to take ethics courses or offer ethics courses nor train graduates in ethics. Yet, graduates, who then become practitioners, and ethical agents, are expected to be ethical agents. Hence, the purpose of this article is on machine ethics, specifically, on the theoretical and philosophical meaning of ethics-different types of ethics and utilitarianism. In addition to exploring the theoretical and philosophical paradigm of ethics, technology will be defined, in relations to machine ethics. © 2016, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.},
author_keywords={Act utilitarianism;  Classical utilitarianism;  Ideal utilitarianism;  Rule utilitarianism;  Technology;  Utilitarianism},
keywords={Engineering;  Technology, Act utilitarianism;  Classical utilitarianism;  Ideal utilitarianism;  Rule utilitarianism;  Utilitarianism, Philosophical aspects},
references={Allen, P.M., Coherence, chaos and evolution in the social context (1994) Futures, 26 (6), pp. 583-597; Anderson, M., Anderson, S.L., Machine ethics Creating an ethical intelligent agent (2007) American Association for Artificial Intelligence, 28 (4), pp. 15-26; Anderson, M., Anderson, S.L., (2011) Machine Ethics, , UK Cambridge University Press; Anderson, M., Anderson, S.L., Armen, C., Towards machine ethics Implementing two action-based ethical theories (2005) Machine Ethics Papers from the Fall Symposium (Technical Report FS-05-06) Association for the Advancement of Artificial Intelligence (AAAI), , In, Menlo Park, California; Anderson, S.L., Being morally responsible for an action versus acting responsibly or irresponsibly (1995) Journal of Philosophical Research, 20, pp. 462-543; Anderson, S.L., Anderson, M., The relationship between intelligent, autonomously functioning machines and ethics (2013) Proceedings of The2013 Meeting of the International Association for Computing and Philosophy Annual Conference, College Park, Maryland; Anschutz, R.P., (2015) John Stuart Mill British Philosopher and Economist, , http//www.britannica.com/biography/John-Stuart-Mill, Britannica.com. Retrieved from; Bentham, J., An introduction to the principles of morals and legislation Printed in the year 1780 (2012) Hachette Livre-Bnf., , 1789th ed.). (Original work published 1789; Bijker, W.E., Hughes, T.P., Pinch, T., (1987) The Social Construction of Technological Systems New Directions in the Sociology and History of Technology, , Cambridge, MA MIT Press; Brandt, R., Toward a credible form of utilitarianism (1963) Morality and the Language of Conduct, pp. 107-143. , H. N. Castañeda & G. Nakhnikian (Eds.), . Detroit Wayne State University Press; David, L., (1965) Forms and Limits of Utilitarianism, , Oxford Clarendon Press; Donner, W., (1991) The Liberal Self John Stuart Mill's Moral and Political Philosophy, , Ithaca, NY Cornell University Press; Donner, W., Morality, virtue, and aesthetics in Mill's art of life (2011) John Stuart Mill and the Art of Life, , B. Eggleston, D. E. Miller, & D. Weinstein (Eds.), Oxford Oxford University Press; Driver, J., (2014) The History of Utilitarianism, , http//plato.stanford.edu/entries/utilitarianismhistory/, Retrieved from; Duignan, B., (2015) Jeremy Bentham British Philosopher and Economist, , http//www.britannica.com/biography/Jeremy-Bentham, Retrieved from; Ellul, J., The technological society (1964) J. Wilkinson Trans, , New York Vintage Books; Fieser, J., Ethics, , http//www.iep.utm.edu/ethics/, N.Y.). Retrieved from; Foucault, M., Technologies of the self (1988) Technologies of the Self A Seminar with Michel Foucault, pp. 16-49. , L. H. Martin, H. Gutman, & P. H. Hutton (Eds.), . London Tavistock Publications; Galvan, J.M., On technoethics (2003) IEEE-RAS Magazine, 10 (4), pp. 58-63; Hooker, B., (2015) Rule Consequentialism, , http//plato.stanford.edu/entries/consequentialism-rule/#FulVerParRulCon, Stanford.edu. Retrieved from; Hughes, T.P., The seamless web Technology, science, etcetera, etcetera (1986) Social Studies of Science, 16 (2), pp. 281-292; Hughes, T.P., The evolution of large technological systems (1987) The Social Construction of Technological Systems New Directions in the Sociology and History of Technology, pp. 51-82. , W. E. Bijker, T. P. Hughes, & T. Pinch (Eds.), . Cambridge, MA The MIT Press; Hughes, T.P., From deterministic dynamos to seamless-web systems (1991) Engineering as A Social Enterprise, pp. 7-25. , H. E. Sladovich (Ed.), . Washington National Academy Press; Krantz, S.F., (2002) Refuting Peter Singer's Ethical Theory the Importance of Human Dignity, , Praeger Publishers, Inc; Law, J., Callon, M., The death of an aircraft a network analysis of technical change (1992) Shaping Technology/building Society Studies in Sociotechnical Change, pp. 21-52. , W. Bijker & J. Law (Eds.), . Cambridge, MA MIT Press; Luppicini, R., Technoethics and the evolving knowledge society Ethical issues in technological design, research, development, and innovation (2010) Hersey, PA IGI Global; Mayocchi, D., (1995) Sound System the Social Shaping and Construction of the Phonogram Industry [Master of Science Dissertation], , Griffith University, Queensland, Australia; Moore, G.E., (1903) Principia Ethica, , Cambridge University; Moore, G.E., The nature of judgment (2002) La Naturaleza Del Juicio. Disliber, , Original work published 1899; Moore, G.E., (1903) The Refutation of Idealism, 12 (48), pp. 433-453. , Mind New Series; Nef, J., Vanderkop, J., Wiseman, H., (1989) Ethics and Technology Ethical Choices in the Age of Pervasive Technology, , Toronto, Ontario University of Guelph; Preston, A., George Edward Moore, , http//www.iep.utm.edu/moore/, N.Y.). Retrieved from; Raval, V., Information ethics Machine ethics (2014) Information Systems Audit and Control Association Journal, 5, pp. 1-3; Rooney, D., A contextualising, socio-technical definition of technology Learning from Ancient Greece and Foucault (1997) Prometheus Critical Studies in Innovation, 15 (3), pp. 399-407; Schmookler, J., (1966) Invention and Economic Growth, , Cambridge, MA Harvard University Press; Schneewind, J.B., (1977) Sidgwick's Ethics and Victorian Moral Philosophy, , Oxford Clarendon Press; Sidgwick, H., (1874) Methods of Ethics, , University of California Libraries; Singer, P., (2011) Practical Ethics, , 3rd ed.). Cambridge University Press; Singer, P., (2013) Preference Utilitarianism, , http//students.thetablet.co.uk/util-preference, Retrieved from; Sinnott-Armstrong, W., Consequentialism (2015) Stanford.edu, , http//plato.stanford.edu/entries/consequentialism/#ClaUti, Retrieved from; Smart, J.J.C., (1961) An Outline of A System of Utilitarian Ethics, , Australia Melbourne University Press; (2015) The Editors of Encycloaedia Britannica, , http//www.britannica.com/topic/consequentialism, Consequentialism Ethics. Retrieved from; (2015) The Editors of Encyclopaedia Britannica, , http//www.britannica.com/biography/Henry-Sidgwick, Henry Sidgwick British philosopher. Retrieved from; (2015) The Editors of Encyclopaedia Britannica, , http//www.britannica.com/biography/G-E-Moore, G. E. Moore British philosopher. Retrieved from; Tran, B., Ethical and legal data mining Paradigms of organizational development practitioners and organizational psychologists (2013) Ethical Data Mining Applications for Socioeconomic Development, pp. 201-229. , H. Rahman and I. Ramos (Eds.), . Hershey, PA IGI Global; Wallach, W., Allen, C., (2008) Moral Machines Teaching Robots Right from Wrong, , UK Oxford University; Weber, M., (1958) The Rational and Social Foundations of Music, , D. Martindale, J. Riedel, and G. Neuwirth Trans.). Southern Illinois University Press; (2015) Preference Utilitarianism, , https//en.wikipedia.org/wiki/Preference_utilitarianism, Wikipedia. (November 27). Retrieved from; (2015) Act Utilitarianism, , https//en.wikipedia.org/wiki/Act_Utilitarianism, Wikipedia. (November 27). Retrieved from; Willemsen, M., Defending utilitarianism Mill's posthumous answer to Nozick's experience machine (2014) Academia.edu, , http//www.academia.edu/7016590/Defending_Utilitarianism_Mill_s_posthumous_answer_to_Nozick_s-experience-machine, Retrieved from; Wolfe, A., Weekend confidential Ray Kurzweil (2014) Wall Street Journal, , http//www.wsj.com/articles/ray-kurzweil-looks-into-the-future-1401490952, Retrieved from},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bendel2016103,
author={Bendel, O.},
title={Considerations about the relationship between animal and machine ethics},
journal={AI and Society},
year={2016},
volume={31},
number={1},
pages={103-108},
doi={10.1007/s00146-013-0526-3},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955181137&doi=10.1007%2fs00146-013-0526-3&partnerID=40&md5=3e0815e1d6ded469855077b34e00b9d3},
abstract={Ethics researches morality in respect to humans and animals. Usually, it implies human morality; therefore, the focus is on human–human relationships (generally in ethics) and human–animal relationships (in animal ethics). Ethics can also deal with the morality of machines such as unmanned aerial vehicles, robots and agents or of self-driving cars and computers in automated trading, in other words more or less autonomous systems and programs. Machine ethics almost exclusively concentrates on machine–human relationships rather than on machine–animal relationships. Before this background, this article contributes some basic considerations about the relationship between animal and machine ethics. © 2013, Springer-Verlag London.},
author_keywords={Animal ethics;  Animal–machine interaction;  Information ethics;  Machine ethics;  Moral machines;  Robot ethics;  Technology ethics},
keywords={Animals, Animal ethics;  Automated trading;  Autonomous systems;  Human relationships;  Information ethics;  On-machines;  Robot ethics;  Self drivings, Philosophical aspects},
references={Anderson, M., Anderson, S.L., (2011) Machine Ethics, , (eds), Cambridge University Press, Cambridge; Bendel, O., Pädagogische Agenten im Corporate E-Learning. Doctoral Thesis (2003) Difo, , St, Gallen; Bendel, O., Maschinenethik (2012) Beitrag für das Gabler Wirtschaftslexikon, , http://wirtschaftslexikon.gabler.de/Definition/maschinenethik.html, Gabler/Springer, Wiesbaden; Bendel, O., (2012) Die Rache der Nerds, , UVK, Konstanz; http://www.inside-it.ch/articles/30517, Bendel O (2012c) Die Moral der Maschinen. Überlegungen zur Maschinenethik. In: inside-it.ch. Accessed Nov 28, 2013; Bendel, O., Die Medizinethik in der Informationsgesellschaft (2012) Überlegungen zur Stellung der Informationsethik, , In: Informatik-Spektrum, (“Online-First”-Article on SpringerLink; Bendel, O., Towards a machine ethics (2013) Technology assessment and policy areas of great transitions: book of abstracts. 1st PACITA Project Conference, Prague, March, 13-15 (2013), pp. 229-230; Bendel, O., Good bot, bad bot (2013) UnternehmerZeitung, 7 (19), pp. 30-31; http://www.spiegel.de/auto/aktuell/projekt-sartre-der-traum-vom-selbststaendig-fahrenden-auto-a-740501.html, Büttner R (2011) Projekt Sartre. Der Traum vom selbstständig fahrenden Auto. In: Spiegel Online, January 20, 2011. Accessed Nov 28, 2013; http://www.androidscience.com/proceedings2005/MacDormanCogSci2005AS.pdf, MacDorman KF (2005) Androids as an experimental apparatus: Why is there an Uncanny Valley and can we exploit it? In: Proceedings of the CogSci 2005 Workshop: toward social mechanisms of android science, Stresa. Accessed Nov 28, 2013; http://www.zeit.de/digital/internet/2013-05/roboter-ethik-kate-darling, Wendt J (2013) Brauchen wir Roboterschutz-Gesetze? In: ZEIT ONLINE, May 10, 2013. Accessed Nov 28, 2013; Wild, M., (2006) Die anthropologische Differenz: Der Geist der Tiere in der frühen Neuzeit, , Walter de Gruyter, Berlin; Wolf, U., (2012) Ethik der Mensch-Tier-Beziehung, , Klostermann, Frankfurt am Main; http://www.nytimes.com/2010/09/13/technology/13roadkill.html, Wollan M (2010) Mapping traffic’s toll on wildlife. In: The New York Times, September 12, 2010. Accessed Nov 28, 2013},
document_type={Article},
source={Scopus},
}

@ARTICLE{Ess2016386,
author={Ess, C.},
title={Phronesis for machine ethics? Can robots perform ethical judgments?},
journal={Frontiers in Artificial Intelligence and Applications},
year={2016},
volume={290},
pages={386-389},
doi={10.3233/978-1-61499-708-5-386},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992623373&doi=10.3233%2f978-1-61499-708-5-386&partnerID=40&md5=a220818f35e16564d05ff49ed2d2d8a9},
references={Vallor, S., Carebots and Caregivers: Sustaining the Ethical Ideal of Care in the Twenty-First Century (2011) Philosophy of Technology, 24, pp. 251-268; Van Wynsberghe, A., Designing Robots for Care: Care Centered Value-Sensitive Design (2013) Science and Engineering Ethics, 19, pp. 407-433; Ess, C., What's Love Got to Do with It?: Robots, sexuality, and the arts of being human (2016) Social Robots: Boundaries, Potentials, pp. 57-79. , Marko Nørskov (ed.), Challenges, Ashgate, Farnham, Surrey, England; Gerdes, A., Ethical Issues Concerning Lethal Autonomous Robots in Warfare (2014) Sociable Robots and the Future of Social Relations: Proceedings of Robo-Philosophy 2014, pp. 277-289. , J. Seibt, R. Hakli, and M. Nørskov (eds.), Berlin, IOS Press; Bringsjord, S., Licato, J., Sundar Govindarajulu, N., Ghosh, R., Sen, A., Real Robots that Pass Human Tests of Self-Consciousness (2015) Proceedings of RO-MAN 2015 (The 24th International Symposium on Robot and Human Interactive Communication), , August 31-September 4, Kobe, Japan; Sullins, J., Machine Morality Operationalized (2014) Sociable Robots and the Future of Social Relations: Proceedings of Robo-Philosophy 2014, 7. , J. Seibt, R. Hakli, and M. Nørskov (eds), Berlin, IOS Press; Sullins, J., Robots Love and Sex: The Ethics of Building a Love Machine (2012) IEEE Transactions on Affective Computing, 3 (4), pp. 398-409. , October-December; Ruddick, S., Better Sex (1975) Philosophy and Sex, pp. 280-299. , Robert Baker and Frederick Elliston (eds.), Amherst, NY, Prometheus Books},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Furbach20163,
author={Furbach, U. and Schon, C.},
title={Commonsense reasoning meets theorem proving},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={9872 LNAI},
pages={3-17},
doi={10.1007/978-3-319-45889-2_1},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988672424&doi=10.1007%2f978-3-319-45889-2_1&partnerID=40&md5=d5a595d717ed4b50bc75ed46251fbc0f},
abstract={The area of commonsense reasoning aims at the creation of systems able to simulate the human way of rational thinking. This paper describes the use of automated reasoning methods for tackling commonsense reasoning benchmarks. For this we use a benchmark suite introduced in literature. Our goal is to use general purpose background knowledge without domain specific hand coding of axioms, such that the approach and the result can be used as well for other domains in mathematics and science. Furthermore, we discuss the modeling of normative statements in commonsense reasoning and in robot ethics (This paper is an extended version of the informal proceedings [9] and [10]). © Springer International Publishing Switzerland 2016.},
keywords={Theorem proving, Automated reasoning;  Back-ground knowledge;  Benchmark suites;  Commonsense reasoning;  Domain specific;  Extended versions;  Hand coding;  Robot ethics, Multi agent systems},
references={Basile, V., Cabrio, E., Gandon, F., Building a general knowledge base of physical objects for robots (2016) The Semantic Web. Latest Advances and New Domains; Bender, M., Pelzer, B., Schon, C., System description: E-KRHyper 1.4 -extensions for unique names and description logic (2013) CADE 2013. LNCS, 7898, p. 126. , Bonacina, M.P. (ed.), Springer, Heidelberg; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intell. Syst, 21 (4), pp. 38-44; Curran, J.R., Clark, S., Bos, J., Linguistically motivated large-scale NLP with C&C and boxer (2007) Proceedings of the ACL 2007 Demo and Poster Sessions, p. 33. , Prague, Czech Republic; Ferrucci, D.A., IBM’s Watson, DeepQA (2011) SIGARCH Computer Architecture News, 39 (3); Furbach, U., Glöckner, I., Helbig, H., Pelzer, B., Logic-based question answering (2010) KI - Künstliche Intelligenz, 2010, Special Issue on Automated Deduction, , February; Furbach, U., Gordon, A., Schon, C., Tackling benchmark problems for commonsense reasoning (2015) Proceedings of Bridging - Workshop on Bridging the Gap between Human and Automated Reasoning; Furbach, U., Pelzer, B., Schon, C., Automated reasoning in the wild (2015) CADE-25. LNCS, 9195, p. 55. , Felty, A.P., Middeldorp, A. (eds.), Springer, Heidelberg; Furbach, U., Schon, C., Commonsense reasoning meets theorem proving (2016) Proceedings of the 1St Conference on Artificial Intelligence and Theorem Proving AITP 2016, , Obergurgl, Austria; Furbach, U., Schon, C., Commonsense reasoning meets theorem proving (2016) Proceedings of Bridging-20016 - Workshop on Bridging the Gap between Human and Automated Reasoning, , to appear; Gordon, A.S., Commonsense interpretation of triangle behavior (2016) Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, p. 3719. , Schuurmans, D. Wellman, M.P. (eds.), 12, –17 February 2016, Phoenix, Arizona, USA; Grassi, M., Biometric ID Management and Multimodal Communication: Joint COST 2101 and 2102 International Conference, BioID MultiComm 2009, Madrid, Spain, 16–18 September 2009 (2009) Proceedings, Chapter Developing HEO Human Emotions Ontology, p. 244. , Springer, Heidelberg; Hall, M.A., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., Witten, I.H., The WEKA data mining software: An update (2009) SIGKDD Explor, 11 (1), pp. 10-18; Hastings, J., Ceusters, W., Smith, B., Mulligan, K., The emotion ontology: Enabling interdisciplinary research in the affective sciences (2011) CONTEXT 2011. LNCS, 6967, p. 119. , Beigl, M., Christiansen, H., Roth-Berghofer, T.R., Kofod-Petersen, A., Coventry, K.R., Schmidtke, H.R. (eds.), Springer, Heidelberg; Kaliszyk, C., Schulz, S., Urban, J., Vyskocil, J., System description: E.T. 0.1 (2015) CADE-25. LNCS, 9195, p. 389. , Felty, A.P., Middeldorp, A. (eds.), Springer, Heidelberg; Lenat, D.B., Cyc: A large-scale investment in knowledge infrastructure. Commun (1995) ACM, 38 (11), pp. 33-38; Levesque, H.J., The winograd schema challenge (2011) Logical Formalizations of Commonsense Reasoning, Papers from the 2011 AAAI Spring Symposium, Technical Report SS-11-06, , Stanford, California, USA, 21-23 March 2011, AAAI; Liu, H., Singh, P., ConceptNet–a practical commonsense reasoning tool-kit (2004) BT Technol. J, 22 (4), pp. 211-226; Maslan, N., Roemmele, M., Gordon, A.S., One hundred challenge problems for logical formalizations of commonsense psychology (2015) Twelfth International Symposium on Logical Formalizations of Commonsense Reasoning, , Stanford, CA; Miller, G.A., WordNet: A lexical database for English (1995) Commun. ACM, 38 (11), p. 39; Moro, A., Raganato, A., Navigli, R., Entity linking meets word sense disambiguation: A unified approach (2014) Trans. Assoc. Comput. Linguist. (TACL), 2, pp. 231-244; Murakami, Y., Utilitarian deontic logic (2004) Proceedings of the Fifth International Conference on Advances in Modal Logic Aiml 2004, p. 288; Navigli, R., Ponzetto, S.P., BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network (2012) Artif. Intell, 193, p. 217; Niles, I., Pease, A., Towards a standard upper ontology (2001) Proceedings of the International Conference on Formal Ontology in Information Systems, 2001, p. 2. , ACM; Pease, A., (2011) Ontology: A Practical Guide, , Articulate Software Press, Angwin; Roemmele, M., Bejan, C.A., Gordon, A.S., Choice of plausible alternatives: An evaluation of commonsense causal reasoning (2011) AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning; Suchanek, F.M., Kasneci, G., Weikum, G., Yago: A large ontology from Wikipedia and WordNet (2008) Web Semant, 6 (3), pp. 203-217},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Bendel2016195,
author={Bendel, O.},
title={Annotated decision trees for simple moral machines},
journal={AAAI Spring Symposium - Technical Report},
year={2016},
volume={SS-16-01 - 07},
pages={195-201},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980009796&partnerID=40&md5=af27e4cdfebc19f2ec8c61444b20dde6},
abstract={Autonomization often follows after the automization on which it is based. More and more machines have to make decisions with moral implications. Machine ethics, which can be seen as an equivalent of human ethics, analyses the chances and limits of moral machines. So far, decision trees have not been commonly used for modelling moral machines. This article proposes an approach for creating annotated decision trees, and specifies their central components. The focus is on simple moral machines. The chances of such models are illustrated with the example of a self-driving car that is friendly to humans and animals. Finally the advantages and disadvantages are discussed and conclusions are drawn.},
keywords={Forestry;  Philosophical aspects, Automization;  Central component;  Self drivings, Decision trees},
references={Aegerter, J., FHNW forscht an "moralisch gutem" Chatbot (2014) Netzwoche, 4, p. 18. , 2014; Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge: Cambridge University Press; Azad-Manjiri, M., A new architecture for making moral agents based on C4.5 decision tree algorithm (2014) International Journal of Information Technology and Computer Science (IJITCS), 6 (5), pp. 50-57. , April 2014; Bendel, O., Einfache moralische Maschinen: Vom Design zur Konzeption (2015) Proceedings der AKWI2015, , Luzern; Bendel, O., Die Maschinenstürmer des Informationszeit-alters (2015) ICTkommunikation, , http://ictk.ch/content/die-maschinenst%C3%BCrmer-des-informationszeitalters, March 5, 2015; Bendel, O., Private drohnen aus ethischer sicht: Chancen und risiken fur benutzer und betroffene (2015) Informatik-Spektrum, , February 14, 2015 ("Online-First" Article on SpringerLink); Bendel, O., Selbststandig fahrende Autos (2015) Gabler Wirtschaftslexikon, , http://wirtschaftslexikon.gabler.de/Definition/selbststaendig-fahrende-autos.html, Wiesbaden: Springer Gabler; Bendel, O., Die Roboter sind unter uns (2014) Netzwoche, 221 (2014), p. 28; Bendel, O., Advanced driver assistance systems and animals (2014) Künstliche Intelligenz, 28 (4), pp. 263-269. , 2014; Bendel, O., Fur wen bremst das Roboterauto? (2014) Computer-world.ch, , http://www.computerworld.ch/marktanalysen/studien-analysen/artikel/, May 16, 2014; Bendel, O., Fahrerassistenzsysteme aus ethischer Sicht (2014) Zeitschrift fur Verkehrssicherheit, 2, pp. 108-110. , 2014d; Bendel, O., Wirtschaftliche und technische Implikationen der Maschinenethik (2014) Die Betriebswirtschaft, 4, pp. 237-248. , 2014; Bendel, O., Ich bremse auch fur Tiere: Uberlegungen zu einfachen moralischen Maschinen (2013) Inside-it.ch, , http://www.inside-it.ch/articles/34646, December 4, 2013; Bendel, O., Buridans robot: uberlegungen zu maschinel-len dilemmata (2013) Telepolis, , http://www.heise.de/tp/artikel/40/40328/l.html, November 20, 2013; Bendel, O., Maschinenethik (2012) Gabler Wirtschaftslexikon, , http://wirtschaftslexikon.gabler.de/Definition/maschinenethik.html, Wiesbaden: Springer Gabler; Bostrom, N., Yudkowsky, E., The ethics of artificial intelligence (2014) The Cambridge Handbook of Artificial Intelligence, pp. 316-334. , Frankish, K., and Ramsey, W. M. eds. Cambridge: Cambridge University Press; Bradl, N., Autonome lkw: future truck soil schnell auf die straße (2015) LOGISTIK HEUTE, , http://www.logistik-heute.de/Logistik-News-Logistik-Nachrichten/Markt-http://heute.de/Logistik-News-Logistik-Nachrichten/Markt-News/13347/Daimler-Vorstandsmitglied-rechnet-mit-Genehmigung-in-den-naechsten-Wochen-Au, July 28, 2015; Deghani, M., Forbus, K., Tomai, E., Klenk, M., An integrated reasoning approach to moral decision making (2011) Machine Ethics, pp. 237-248. , Anderson, M., and Anderson, S. L. eds. 2011. Cambridge: Cambridge University Press; Deng, B., Machine ethics: The robot's dilemma (2015) Nature, , http://www.nature.com/news/machine-ethics-the-robot-s-dilemma-1.17881, July 1, 2015; Emmerth, D., Ein zimmer aus dem 3-d-drucker (2013) Tages-Anzeiger, , http://www.tagesanzeiger.ch/wissen/technik/Ein-Zimmer-aus-dem-3DDrucker/story/l1214726, October 22, 2013; Federle, S., Radar soil zugvogel schützen (2014) Tierwelt, (10), pp. 22-23. , March 5, 2014; Goodall, N.J., Ethical decision making during automated vehicle crashes (2014) Journal Transportation Research, pp. 58-65. , September 29,2014; Häuptli, L., Kampf den drohnen (2014) NZZ Am Sonntag, , http://www.nzz.ch/nzzas/nzz-am-sonntag/kampf-den-drohnen-1.18439765, December 7, 2014; Holzer, H., Wer programmiert die Moral fur die Maschine? (2015) Handelsblatt, , http://www.handelsblatt.com/auto/nachrichten/autonome-fahrzeuge-wer-programmiert-die-moral-fuer-die-maschine/11295740.html, January 28, 2015; Kolhagen, J., Autopiloten auf radern (2013) Versicher-ungswirtschaft, (11), p. 70. , June 1, 2013; Kopf, M., (1994) Ein Beitrag Zur Modellbasierten, Adaptiven Fahrerunterstützung fur das Fahren Auf Deutschen Autobahnen, , Dissertation. Dusseldorf: VDI-Verlag; Lorenz, L.M., (2014) Entwicklung und Bewertung Auf-merksamkeitslenkender Warn-und Informationskonzepte fur Fahrerassistenzsysteme: Aufmerksamkeitssteuerung in der Frühen Phase Kritischer Verkehrssituationen, , Dissertation. Munchen; Pellkofer, M., (2003) Verhaltensentscheidung fur Autonome Fahr-zeuge mit Blickrichtungssteuerung, , http://athene-forschung.unibw.de/doc/85319/85319.pdf, Dissertation. Munchen; Stoller, D., Vollautomatisch und ohne Fahrer in der Stadt unterwegs (2013) Ingenieur.De, , http://www.ingenieur.de/Themen/Automobil/Vollautomatisch-Fahrer-in-Stadt-unterwegs, July 15, 2013; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford: Oxford University Press},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lutz201527,
author={Lutz, C. and Tamò, A.},
title={RoboCode-ethicists - Privacy-friendly robots, an ethical responsibility of engineers?},
journal={NS Ethics 2015 - Proceedings of the 2015 ACM SIGCOMM Workshop on Ethics in Networked Systems Research, part of SIGCOMM 2015},
year={2015},
pages={27-28},
doi={10.1145/2793013.2793022},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960156703&doi=10.1145%2f2793013.2793022&partnerID=40&md5=031a39623b1d68ce7f32010d340fbfad},
abstract={This contribution addresses the privacy implications of robots. Two aspects are of fundamental concern in this context: the pervasiveness and intrusiveness of robots on the one hand and a general lack of awareness and knowledge about how robots work, collect and process sensitive data on the other hand. The existing literature on robot ethics provides a suitable framework to address these two issues. In particular, robot ethics are useful to point out how engineers' and regulators' mindset towards privacy protection differs. Different, at first sight incommensurable, rationalities exist between the two when it comes to robotic privacy. As a contribution to the emerging field of robotic privacy, we propose an interdisciplinary and collaborative approach that bridges the two rationalities. This approach considers the role of code as the central governing element of robots. RoboCode-Ethicists, trans-disciplinary experts trained in the technical/computational, legal and social aspects of robotics, should lead the way in the discussion on robotic privacy. They could mediate between different stakeholders and address emerging privacy issues as early as possible. The robot revolution is well on its way. A current estimation assumes that between 2013 and 2016, 22 million robots will be sold [7]. Robots - defined as a "machine situated in the world that senses, thinks, and acts" [1:18] - are currently used in many professional and social contexts, such as labor and services, military and security, research and education, healthcare, as personal companions or toys. © 2015 ACM.},
keywords={Economic and social effects;  Philosophical aspects;  Robotics;  Social aspects, Collaborative approach;  Current estimation;  Ethical responsibility;  Privacy issue;  Privacy protection;  Robot ethics;  Sensitive datas;  Social context, Robots},
references={Bekey, G., Current trends in robotics: Technology and ethics (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 17-34. , P. Lin, G. Bekey, and K. Abney, Eds. MIT Press, Cambridge, MA; Calo, R., Robots and privacy (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 187-202. , P. Lin, G. Bekey, and K. Abney, Eds. MIT Press, Cambridge, MA; Calo, R., (2014) Robotics and the New Cyberlaw, pp. 101-146. , http://robots.law.miami.edu/2014/wpcontent/uploads/2013/06/Calo-Robotics-and-the-New-Cyberlaw.pdf, SSRN Electronic Journal; Cavoukian, A., (2009) Privacy by Design - The 7 Foundational Principles, , https://www.iab.org/wp-content/IABuploads/2011/03/fred_carter.pdf, Information and Privacy Commissioner of Ontario; Doctorow, C., Why it is not possible to regulate robots here (2014) The Guardian Technology Blog 2014, , http://www.theguardian.com/technology/blog/2014/apr/02/why-it-is-not-possible-to-regulate-robots, Robots, April 2; Gips, J., (2011) Towards the Ethical Robot, pp. 244-253. , Machine Ethics, M. Anderson and S. L. Anderson, Eds. Cambridge University Press, Cambridge, UK; (2013) IRF - International Federation of Robotics, 2013, , World Robotics Report; Langheinrich, M., (2005) Personal Privacy in Ubiquitous Computing: Tools and System Support., , http://ecollection.library.ethz.ch/eserv/eth:28011/eth-28011-01.pdf, Dissertation submitted to the Swiss Federal Institute of Technology Zurich; Lederer, S., Hong, J.I., Key, A.D., Landay, J.A., Personal privacy through understanding and action: Five pitfalls for designers (2004) Journal of Personal and Ubiquitious Computing, 8 (6), pp. 440-454; Mayer-Schönberger, V., Cukier, K., (2013) Big Data: A Revolution That Will Transform How We Live, Work and Think, , HMH Books, Boston, MA and New York, NY; Smith, H.J., Dinev, T., Xu, H., Information privacy research: An interdisciplinary review (2011) MIS Quarterly, 35 (4), pp. 989-1016; Veruggio, G., (2007) EURON Robotics Roadmap, , http://www.roboethics.org/index_file/Roboethics%20Roadmap%20Rel.1.2.pdf},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Lutz2015,
author={Lutz, C. and Tamò, A.},
title={RoboCode-Ethicists - Privacy-friendly robots, an ethical responsibility of engineers?},
journal={Proceedings of the 2015 ACM Web Science Conference},
year={2015},
doi={10.1145/2786451.2786465},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978033686&doi=10.1145%2f2786451.2786465&partnerID=40&md5=6f02e54a549123f999a9d58485b275d9},
abstract={This article asks why engineers building robots should consider privacy aspects when programming their gadgets. We start with a definition of robots, differentiating active, social robots from passive, non-social robots. We then discuss the related literature on the privacy implications of social robots. Two aspects are of fundamental concern in this context: the pervasiveness and intrusiveness of robots on the one hand and a general lack of awareness and knowledge about how robots work, collect and process sensitive data on the other hand. We explain how the existing literature on robot ethics provides a suitable framework to address these two issues. In particular, robot ethics are useful to point out how engineers' and regulators' mindset towards privacy protection differs. The paper argues that different - at first sight incommensurable - rationalities exist when it comes to robotic privacy. As a contribution to the emerging field of robotic privacy, we propose an interdisciplinary and collaborative approach that bridges the two rationalities. This approach considers the role of code as the central governing element of robots. RoboCode-Ethicists, trans-disciplinary experts trained in the technical/computational, legal and social aspects of robotics, should lead the way in the discussion on robotic privacy. They could mediate between different stakeholders - mainly regulators, users and engineers - and address emerging privacy issues as early as possible. © 2015 ACM.},
author_keywords={Applied ethics;  Ethical coding;  Privacy;  Robots},
keywords={Data privacy;  Economic and social effects;  Engineers;  Philosophical aspects;  Robotics;  Robots;  Social aspects, Applied ethics;  Building robots;  Collaborative approach;  Ethical coding;  Ethical responsibility;  Privacy aspects;  Privacy protection;  Sensitive datas, Robot programming},
references={Aeschlimann, L., Harasgama, R., Kehr, F., Lutz, C., Milanova, V., Müller, S., Strathoff, P., Tamò, A., Re-Setting the Stage for Privacy: A Multi-Layered Privacy Interaction Framework and Its Application (2015) Mensch und Maschine - Symbiose Oder Parasitismus, pp. 1-43. , S. Brändli, R. Harasgama, R. Schister, and A. Tamò (eds.), Stämpfli, Berne; Allen, C., Wallach, W., Moral Machines: Contradiction in Terms or Abdication of Human Responsibility? (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 55-68. , P. Lin, G. Bekey, and K. Abney (eds.), MIT Press, Cambridge (MA); Anderson, S.L., Philosophical Concerns with Machine Ethics (2011) Machine Ethics, pp. 162-167. , M. Anderson and S. L. Anderson (eds.), Cambridge University Press, Cambridge (UK); Anderson, S.L., The Unacceptability of Asimov's Three Laws of Robotics as a Basis for Machine Ethics (2011) Machine Ethics, pp. 285-296. , M. Anderson and S. L. Anderson (eds.), Cambridge University Press, Cambridge (UK); Asscher, L., 'Code' as Law. Using Fuller to Assess Code Rules (2006) Coding Regulation: Essays on the Normative Role of Information Technology, pp. 61-90. , E. Dommering and L. Asscher (eds.), Asser Press, The Hague; Bekey, G., Current Trends in Robotics: Technology and Ethics (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 17-34. , P. Lin, G. Bekey, and K. Abney (eds.), MIT Press, Cambridge (MA); Bennet, C.J., Raab, C., (2006) The Governance of Privacy - Policy Instruments in Global Perspective, , D. MIT Press 2006, Cambridge (MA); Boyd, D., Crawford, K., Critical Questions for Big Data (2012) Information, Communication & Society, 15 (5), pp. 662-679; Brey, P., Values in technology and disclosive computer ethics (2010) The Cambridge Handbook of Information and Computer Ethics, pp. 41-58. , L. Floridi (ed.), Cambridge University Press, Cambridge (UK); Borenstein, J., Pearson, Y., Robot Caregivers: Ethical Issues across the Human Lifespan (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 251-265. , P. Lin, G. Bekey, and K. Abney (Eds.), MIT Press, Cambridge (MA); Brownsword, R., (2008) Rights, Regulation, and the Technological Revolution, , Oxford University Press, Oxford (UK); Bygrave, L.A., (2014) Data Privacy Law, , Oxford University Press, Oxford (UK; Calo, R., Robots and Privacy (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 187-202. , P. Lin, G. Bekey, and K. Abney (Eds.), MIT Press, Cambridge (MA); Calo, R., Robotics and the New Cyberlaw (2014) SSRN Electronic Journal, pp. 101-146. , http://robots.law.miami.edu/2014/wp-content/uploads/2013/06/Calo-Robotics-and-the-New-Cyberlaw.pdf, Online; Cate, F.H., Mayer-Schönberger, V., Notice and consent in a world of Big Data (2013) International Data Privacy Law, 3 (2), pp. 67-73; Cavoukian, A., Privacy by Design - The 7 Foundational Principles (2009) Information and Privacy Commissioner of Ontario, , https://www.iab.org/wp-content/IAB-uploads/2011/03/fred_carter.pdf, Online; Clarke, R., Asimov's Laws of Robotics: Implications for Information Technology (2011) Machine Ethics, pp. 254-284. , M. Anderson and S. L. Anderson (eds.), Cambridge University Press, Cambridge (UK); Crawford, K., Schultz, J., Big Data and Due Process: Toward a Framework to Redress Predictive Privacy Harms (2014) Boston College Law Review, 55 (93), p. 2014; Darling, K., Extending Legal Rights to Social Robots (2012) SSRN Online Journal, pp. 1-18. , http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2044797, Online; De Graaf, M.M.A., Ben Allouch, S., Klamer, T., Sharing a life with Harvey: Exploring the acceptance of and relationship-building with a social robot (2015) Computers in Human Behavior, 43, pp. 1-14; Del Campo, M., Fure, A., McGee, W., Manninger, S., Flexer, A., Autonomous Tectonics - A Research into Emergent Robotics Construction Methods (2013) Rethinking Prototyping: Proceedings of the Design Modelling Symposium Berlin 2013, pp. 1-13. , F. Scheurer, J. Nembrini, A. Kilian, and C. Gengnagel (eds.); Denning, T., Matuszek, C., Koscher, K., Smith, J.R., Kohno, T., Allen, P.G., A Spotlight on Security and Privacy Risks with Future Household Robots: Attacks and Lessons (2009) Proceedings of the 11th International Conference on Ubiquitous Computing (UbiComp '09), pp. 1-10. , Orlando, FL, September 30-October 03 2009); Doctorow, C., Why it is not possible to regulate robots here (2014) The Guardian Technology Blog, Robots, , http://www.theguardian.com/technology/blog/2014/apr/02/why-it-is-not-possible-to-regulate-robots, April 2 2014; Attitudes on Data Protection and Electronic Identity in the European Union (2011) EU Eurobarometer, , http://ec.europa.eu/public_opinion/archives/ebs/ebs_359_en.pdf, Research Report. Online; Floridi, L., Information ethics: On the philosophical foundations of computer ethics (1999) Ethics and Information Technology, 1 (1), pp. 37-56; Floridi, L., Information ethics (2010) The Cambridge Handbook of Information and Computer Ethics, pp. 77-100. , L. Floridi (ed.), Cambridge University Press, Cambridge (UK); Friedman, B., Kahn, P.H., The Ethics of Systems Design (2002) Computers, Ethics, and Society, pp. 55-63. , M. D. Ermann and M. S. Shauf (eds.), Oxford University Press, Oxford (UK); Friedman, B., Kahn, P., Human Values, Ethics and Design (2008) The Human Computer Interaction Handbook, pp. 1241-1266. , J. Jacko and A. Sears (eds.), (2nd edition), Lawrence Erlbaum Associates, Mahwah (NJ); Friedman, B., Kahn, P.H., Borning, A., Value sensitive design: Theory and methods (2002) University of Washington Technical Report, pp. 02-12. , http://www.urbansim.org/pub/Research/ResearchPapers/vsd-theory-methods-tr.pdf, Online; Fussell, S.R., Kiesler, S., Setlock, L.D., Yew, V., How people anthropomorphize robots (2008) Proceedings of the 3rd ACM/IEEE International Conference on Human Robot Interaction, pp. 145-152. , Amsterdam, The Netherlands, March 12-15 2008); (2004) Fukuoka World Robot Declaration, , http://www.prnewswire.co.uk/news-releases/world-robot-declaration-from-international-robot-fair-2004-organizing-office-154289895.html, Online; Garfinkel, S., Privacy in a Database Nation (2003) Computers, Ethics, and Society, pp. 137-152. , M. D. Ermann and M. S. Shauf (eds). Oxford University Press, Oxford (UK); Gips, J., Towards the Ethical Robot (2011) Machine Ethics, pp. 244-253. , M. Anderson and S. L. Anderson (eds.), Cambridge University Press, Cambridge (UK); Hoffmann, C.P., Lutz, C., Ranzini, G., Meckel, M., Diversity by Choice: Applying a Social Cognitive Perspective to the Role of Public Service Media in the Digital Age (2015) International Journal of Communication, 9, pp. 1-20. , in press; Hospers, J., The Best Action Is One with the Best Consequences (2002) Computers, Ethics, and Society, pp. 3-11. , M. D. Ermann, M. N. Williams, and M. S. Shauf (eds.), Oxford University Press, Oxford (UK); (2013) World Robotics 2013 Report; Klein, H.K., Kleinman, D.L., The Social Construction of Technology: Structural Considerations (2002) Science Technology Human Values, 27 (1), pp. 28-52; Langheinrich, M., (2005) Personal Privacy in Ubiquitous Computing: Tools and System Support, , http://e-collection.library.ethz.ch/eserv/eth:28011/eth-28011-01.pdf, Dissertation submitted to the Swiss Federal Institute of Technology Zurich, 2005. Online; Lederer, S., Hong, J.I., Key, A.D., Landay, J.A., Personal Privacy through Understanding and Action: Five Pitfalls for Designers (2004) Journal of Personal and Ubiquitious Computing, 8 (6), pp. 440-454; Lessig, L., (1999) Code and Other Laws of Cyberspace, , Basic Books, New York (NY); Lessig, L., (2006) Code Version 2.0, , Basic Books, New York (NY); Lin, P., Introduction to Robot Ethics (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 3-16. , P. Lin, K. Abney, and G. A. Bekey (eds.), MIT Press, Cambridge (MA); Lin, P., Abney, K., Bekey, G., Robot ethics: Mapping the issues for a mechanized world (2011) Artificial Intelligence, 175 (5-6), pp. 942-949; Lutz, C., Strathoff, P., Privacy Concerns and Online Behavior - Not so Paradoxical After All? Viewing the Privacy Paradox through Different Theoretical Lenses (2013) Multinationale Unternehmen und Institutionen Im Wandel - Herausforderungen für Wirtschaft, Recht und Gesellschaft, pp. 81-99. , S. Brändli, R. Schister, and A. Tamò (eds.), Stämpfli, Berne; MacKenzie, D., Wajcman, J., (1999) The Social Shaping of Technology, , Open University Press, Buckingham (UK); Margulis, S.T., Three Theories of Privacy - An Overview (2011) Privacy Online - Perspectives on Privacy and Self-Disclosure in the Social Web, pp. 9-18. , S. Trepte and. L. Reinecke, L. (eds.), Springer, Berlin/Heidelberg; Mayer-Schönberger, V., Cukier, K., (2013) Big Data: A Revolution That Will Transform How We Live, Work and Think, , HMH Books, Boston (MA) & New York (NY; Moor, J.H., The nature, importance, and difficulty of machine ethics (2011) Machine Ethics, pp. 13-20. , M. Anderson and S. L. Anderson (eds.), Cambridge University Press, Cambridge (UK); Nissenbaum, H., Privacy as Contextual Integrity (2004) Washington Las Review, 79, pp. 101-139; Omohundro, S., Autonomous technology and the greater human good (2014) Journal of Experimental & Theoretical Artificial Intelligence, 26 (3), pp. 303-315; Oosterlaken, I., Design for development: A capability approach (2009) Design Issues, 25 (4), pp. 91-102; (2014) Internet of Things Report, , http://www.pewinternet.org/files/2014/05/PIP_Internet-of-things_0514142.pdf, PEW Research Online; (2014) AI, Robotics, and the Future of Jobs, , http://www.pewinternet.org/files/2014/08/Future-of-AI-Robotics-and-Jobs.pdf, PEW Research Online; (2014) Public Perceptions of Privacy and Security in the Post-Snowden Era, , http://www.pewinternet.org/files/2014/11/PI_PublicPerceptionsofPrivacy_111214.pdf, PEW Research Online; Pinch, T.J., Bijker, W.E., The social construction of facts and artefacts: Or how the sociology of science and the sociology of technology might benefit each other (1984) Social Studies of Science, 14 (3), pp. 399-441; Pfleeger, C.P., Pfleeger, S.H., (2007) Security in Computing, , (4th edition). Prentice Hall, New York (NY); Reidenberg, J.R., Lex Informatica: The Formulation of Information Policy Rules Through Technology (1998) Texas Law Review, 76 (3), pp. 554-593; Riek, L.D., Howard, D., A Code of Ethics for the Human-Robot Interaction Profession (2014) We Robot Conference, pp. 1-10. , Coral Gables, FL, April 04-05 2014; Rosenthal-Von Der Pütten, A.M., Krämer, N., How design characteristics of robots determine evaluation and uncanny valley related responses (2014) Computers in Human Behavior, 36, pp. 422-439; Scheutz, M., The Inherent Dangers of Unidirectional Emotional Bonds between Humans and Social Robots (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 205-222. , P. Lin, G. Bekey and K. Abney (eds.), MIT Press, Cambridge (MA); Scheutz, M., Crowell, C., The Burden of Embodied Autonomy: Some Reflections on the Social and Ethical Implications of Autonomous Robots (2007) Workshop on Roboethics at the 2007 IEEE International Conference on Robotics and Automation (IRCA), pp. 1-7. , http://www.roboethics.org/icra2007/contributions/SCHEUTZ%20The%20Burden%20of%20Embodied%20Autonomy.pdf, Rome, Italy, 10-14 April 2007; Singer, P., (2009) Wired for War, , Penguin Press, New York (NY); Smith, H.J., Dinev, T., Xu, H., Information privacy research: An interdisciplinary review (2011) MIS Quarterly, 35 (4), pp. 989-1016; Solove, D.J., (2008) Understanding Privacy, , Harvard University Press, Cambridge (MA); Solove, D.J., Introduction: Privacy Self-Management and the Consent Dilemma (2012) Harvard Law Review, 126, pp. 1880-1881; Tufekci, Z., Can you see me now? Audience and disclosure regulation in online social network sites (2008) Bulletin of Science, Technology & Society, 28 (1), pp. 20-36; Turkle, S., Authenticity in the age of digital companions (2011) Machine Ethics, pp. 62-76. , M. Anderson and S. L. Anderson (eds.), Cambridge University Press, Cambridge (UK); Van Rest, J., Boonstra, D., Everts, M., Van Rijn, M., Van Paassen, R., Designing Privacy-by-Design (2014) Privacy Technologies and Policy, pp. 55-72. , B. Preneel and D. Ikonomou (eds.), Springer, Berlin & Heidelberg; Veruggio, G., (2007) EURON Robotics Roadmap, , http://www.roboethics.org/index_file/Roboethics%20Roadmap%20Rel.1.2.pdf, Online; Watson, S., If Customers Knew How You Use Their Data, Would They Call It Creepy? (2014) Harvard Business Review, , https://hbr.org/2014/04/if-customers-knew-how-you-use-their-data-would-they-call-it-creepy/, April 29 2014. Online; Weber, M., (1978) Economy and Society, , University of California Press, Oakland (CA); Weiser, M., The computer for the 21st centruy (1991) Scientific American, 265 (3), pp. 66-75; (2002) IEEE Pervasive Computing, 1 (1), pp. 19-25. , Jan.-Mar; Winner, L., (1977) Autonomous Technology: Technics-out-of-Control as a Theme in Political Thought, , MIT Press, Cambridge (MA},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Danielson201573,
author={Danielson, P.},
title={Surprising judgments about robot drivers: Experiments on raising expectations and blaming humans},
journal={Etikk i Praksis},
year={2015},
volume={9},
number={1},
pages={73-86},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963814158&partnerID=40&md5=b939b4cec74b48eaf2f5acb6065ebdf5},
abstract={N-Reasons is an experimental Internet survey platform designed to enhance public participation in applied ethics and policy. N-Reasons encourages survey respondents to generate reasons to support their judgments, and groups to converge on a common set of reasons for and against various issues. In the Robot Ethics Survey, some of the reasons included surprising judgments about autonomous machines. Participants gave unexpected answers when presented with a version of the trolley problem with an autonomous train as the agent, revealing high expectations for the autonomous machine and shifting blame from the automated device to the humans in the scenario. Further experiments with a standard pair of human-only trolley problems refine these results. Responses reflect high expectations even when no autonomous machine is involved, but human bystanders are only blamed in the machine case. A third experiment explicitly aimed at responsibility for driverless cars confirms our findings about shifting blame in the case of autonomous machine agents. We conclude methodologically that both sets of results point to the power of an experimental survey-based approach to public participation in exploring surprising assumptions and judgments in applied ethics. However, these results also support using caution when interpreting survey results in ethics and demonstrate the importance of qualitative data to provide greater context for evaluating judgments revealed by surveys. On the ethics side, the result about shifting blame to humans interacting with autonomous machines suggests caution about the unintended consequences of intuitive principles requiring human responsibility.},
author_keywords={Autonomous machines;  Responsibility;  Robot ethics;  Survey methods;  Trolley problem},
references={Ahmad, R., Bailey, J.P., Analysis of an innovative survey platform: Comparison of the public's responses to human health and salmon genomics surveys (2010) Public Understanding of Science, 19 (2), pp. 155-165. , http://dx.doi.org/10.1177/0963662508091806; Ahmad, R., Bailey, J., Bornik, Z., Danielson, P., Dowlatabadi, H., Levy, E., A web-based instrument to model social norms: NERD design and results (2006) Integrated Assessment, 6 (2), pp. 9-36. , http://journals.sfu.ca/int_assess/index.php/iaj/article/view/157/204; Moon, A.J., Danielson, P., Van Der Loos, H.F.M., Survey-based discussions on morally contentious applications of interactive robotics (2012) International Journal of Social Robotics, pp. 1-20. , http://dx.doi.org/10.1007/s12369-011-0120-0; Danielson, P., A collaborative platform for experiments in ethics and technology (2010) Philosophy and Engineering: An Emerging Agenda, pp. 239-252. , http://link.springer.com/chapter/10.1007/978-90-481-2804-4-20, In I. van der Poel & D. E. Goldberg (Eds.), Berlin: Springer; Danielson, P., Prototyping N-reasons: A computer mediated ethics machine (2011) Machine Ethics, pp. 442-450. , http://ebooks.cambridge.org/chapter.jsf?bid=CBO9780511978036&cid=CBO9780511978036A038, In M. Anderson & E. Anderson (Eds.), New York: Cambridge University Press; Danielson, P., Engaging the public in the ethics of robots for war and peace (2011) Philosophy & Technology, 24, pp. 239-249. , http://dx.doi.org/10.1007/s13347-011-0025-8; Danielson, P., N-Reasons: Computer mediated ethical decision support for public participation (2013) Publics & Emerging Technologies: Cultures, Contexts, and Challenges, pp. 248-260. , http://www.ubcpress.ca/search/title_book.asp?BookID=299173962, (Eds, Einsiedel, E. & O'Doherty, K.) UBC Press, Vancouver; Danielson, P., Ahmad, R., Bornik, Z., Dowlatabadi, H., Levy, E., Deep, cheap, and improvable: Dynamic democratic norms & the ethics of biotechnology (2007) Ethics and the Life Sciences, pp. 315-326. , http://dx.doi.org/10.5840/jpr_2007_26, In F. Adams (Ed.), Charlottesville, Va.: Philosophy Documentation Center; Danielson, P., N-Reasons: Computer mediated ethical decision support for public participation (2013) Publics & Emerging Technologies: Cultures, Contexts, and Challenges, pp. 248-260. , In E. Einsiedel & K. O'Doherty (Eds.), Vancouver: UBC Press; Foot, P., The problem of abortion and the doctrine of the double effect (1967) Oxford Review, 5, pp. 5-15; Goodall, N.J., Ethical decision making during automated vehicle crashes (2014) Transportation Research Record: Journal of the Transportation Research Board, 2424, pp. 58-65. , http://dx.doi.org/10.3141/2424-07, Transportation Research Board of the National Academies, Washington, D.C; Greene, J., Beyond point and shoot morality: Why cognitive (neuro)science matters to ethics (2013) Ethics, 124 (14), pp. 695-726. , https://dx.doi.org/10.1086/675875; Greene, J.D., Sommerville, R.B., Nystrom, L.E., Darley, J.M., Cohen, J.D., An fMRI investigation of emotional engagement in moral judgment (2001) Science, 293 (5537), pp. 2105-2108. , http://dx.doi.org/10.1126/science.1062872; Hauser, M., (2006) Moral Minds: How Nature Designed Our Universal Sense of Right and Wrong, , New York: HarperCollins; Lerner, M.J., (1980) The Belief in a Just World, , http://dx.doi.org/10.1007/978-1-4899-0448-5, New York: Springer; Mikhail, J., Universal moral grammar: Theory, evidence and the future (2007) Trends in Cognitive Sciences, 11 (4), pp. 143-152. , http://www.sciencedirect.com/science/article/pii/S1364661307000496; Sparrow, R., Killer robots (2007) Journal of Applied Philosophy, 24 (1), pp. 62-77. , http://dx.doi.org/10.1111/j.1468-5930.2007.00346.x; Thomson, J.J., The trolley problem (1985) Yale Law Journal, 94, pp. 1395-1415. , http://dx.doi.org/10.2307/796133},
document_type={Article},
source={Scopus},
}

@ARTICLE{Anderson2015155,
author={Anderson, M. and Anderson, S.L.},
title={Case-supported principle-based behavior paradigm},
journal={Cognitive Technologies},
year={2015},
volume={40},
pages={155-168},
doi={10.1007/978-3-319-21548-8_9},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948761868&doi=10.1007%2f978-3-319-21548-8_9&partnerID=40&md5=2e806278a593879277f9d820e99c16d2},
abstract={We assert that ethical decision-making is, to a degree, computable. Some claim that no actions can be said to be ethically correct because all value judgments are relative either to societies or individuals. We maintain, however, along with most ethicists, that there is agreement on the ethically relevant features in many particular cases of ethical dilemmas and on the right course of action in those cases. Just as stories of disasters often overshadow positive stories in the news, so difficult ethical issues are often the subject of discussion rather than those that have been resolved, making it seem as if there is no consensus in ethics. Although, admittedly, a consensus of ethicists may not exist for a number of domains and actions, such a consensus is likely to emerge in many areas in which intelligent autonomous systems are likely to be deployed and for the actions they are likely to undertake. © Springer International Publishing Switzerland 2015.},
author_keywords={Artificial intelligence;  Case-supported principle-based paradigm;  Machine ethics},
keywords={Artificial intelligence;  Decision making, Course of action;  Ethical decision making;  Ethical dilemma;  Ethical issues;  Intelligent autonomous systems;  Relevant features;  Value judgment, Philosophical aspects},
references={Anderson, M., Anderson, S., Armen, C., MedEthEx: A prototype medical ethics advisor (2006) Proceedings of the Eighteenth Conference on Innovative Applications of Artificial Intelligence, , Boston, MA, August; Anderson, M., Anderson, S.L., GenEth: A general ethical dilemma analyzer (2013) 11th International Symposium on Formalizations of Commonsense Reasoning, , Ayia Napa, Greece, May; Ross, W.D., (1930) The Right and the Good, , Oxford University Press, Oxford; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) Artif. Intell. Mag, 28, p. 4; Lavrač, N., Džeroski, S., (1997) Inductive Logic Programming: Techniques and Applications, , Ellis Harwood, New York; Anderson, M., Anderson, S.L., (2010) Robot be Good, , Scientific American Magazine, October; Turing, A.M., Computing machinery and intelligence (1950) Mind, 59, pp. 433-460; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) J. Exp. Theor. Artif. Intell, 12, pp. 251-261; Waldrop, M.M., A question of responsibility (Chap. 11) (1987) Man Made Minds: The Promise of Artificial Intelligence, , Walker and Company, NY (Reprinted in R. Dejoie et al., eds. Ethical Issues in Information Systems. Boston, MA: Boyd and Fraser, 1991, pp. 260-277.); Gips, J., Towards the Ethical Robot (1995) Android Epistemology, pp. 243-252. , MIT Press, Cambridge; Khan, A.F.U., The Ethics of Autonomous Learning Systems (1995) Android Epistemology, pp. 253-265. , MIT Press, Cambridge; Grau, C., There is no "I" in "Robot": Robots and utilitarianism (2006) IEEE Intell. Syst, 21 (4), pp. 52-55; Powers, T.M., Prospects for a Kantian machine (2006) IEEE Intell. Syst, 21 (4), pp. 46-51; Rzepka, R., Araki, K., What could statistics do for ethics? The idea of common sense processing based safety valve (2005) Proceedings of the AAAI Fall Symposium on Machine Ethics, pp. 85-87. , AAAI Press, Menlo Park; Guarini, M., Particularism and the classification and reclassification of moral cases (2006) IEEE Intell. Syst, 21 (4), pp. 22-28; McLaren, B.M., Extensionally defining principles and cases in ethics: An AI model (2003) Artif. Intell. J, 150, pp. 145-181; Bringsjord, S., Arkoudas, K., Bello, P., Towards a general logicist methodology for engineering ethically correct robots (2006) IEEE Intell. Syst, 21 (4), pp. 38-44; Pereira, L.M., Saptawijaya, A., Modeling morality with prospective logic (2007) Prog. Artif. Intell.: Lect. Notes Comput. Sci, 4874, pp. 99-111},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Saptawijaya2015414,
author={Saptawijaya, A. and Pereira, L.M.},
title={Logic programming applied to machine ethics},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9273},
pages={414-422},
doi={10.1007/978-3-319-23485-4_41},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945953430&doi=10.1007%2f978-3-319-23485-4_41&partnerID=40&md5=6c89b768485f3a06e0ffba6dba5b2725},
abstract={This paper summarizes our investigation on the application of LP-based reasoning to machine ethics, a field that emerges from the need of imbuing autonomous agents with the capacity for moral decision-making. We identify morality viewpoints (concerning moral permissibility and the dual-process model) as studied in moral philosophy and psychology, which are amenable to computational modeling. Subsequently, various LP-based reasoning features are applied to model these identified morality viewpoints, via classic moral examples taken off-the-shelf from the literature. © Springer International Publishing Switzerland 2015.},
keywords={Artificial intelligence;  Autonomous agents;  Computation theory;  Decision making;  Philosophical aspects, Based reasonings;  Computational model;  Dual process;  Moral philosophy, Logic programming},
references={Anderson, M., Erson, S.L., EthEl: Toward a principled ethical eldercare robot (2008) Procs. AAAI Fall 2008 Symposium on AI in Eldercare; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44; Cushman, F., Young, L., Greene, J.D., Multi-system moral psychology (2010) The Moral Psychology Handbook, , Doris, J.M. (ed.), Oxford University Press; Dell’Acqua, P., Pereira, L.M., Preferential theory revision (2007) Journal of Applied Logic, 5 (4), pp. 586-601; Foot, P., The problem of abortion and the doctrine of double effect (1967) Oxford Review, 5, pp. 5-15; Ganascia, J.-G., Modelling ethical rules of lying with answer set programming (2007) Ethics and Information Technology, 9 (1), pp. 39-47; Anh, H.T., Kencana Ramli, C.D.P., Damàsio, C.V., An implementation of extended P-Log using XASP (2008) ICLP 2008. LNCS, 5366, pp. 739-743. , Garcia de la Banda, M., Pontelli, E. (eds.), Springer, Heidelberg; Han, T.A., Saptawijaya, A., Pereira, L.M., Moral reasoning under uncertainty (2012) LPAR-18 2012. LNCS, 7180, pp. 212-227. , In: Bjørner, N., Voronkov, A. (eds.), Springer, Heidelberg; Hauser, M., Cushman, F., Young, L., Jin, R.K., Mikhail, J., A dissociation between moral judgments and justifications (2007) Mind and Language, 22 (1), pp. 1-21; Kamm, F.M., (2006) Intricate Ethics: Rights, Responsibilities, and Permissible Harm, , Oxford U. P; Kowalski, R., (2011) Computational Logic and Human Thinking: How to Be Artificially Intelligent, , Cambridge U. P; Lopes, G., Pereira, L.M., Prospective storytelling agents (2010) PADL 2010. LNCS, 5937, pp. 294-296. , Carro, M., Peña, R. (eds.), Springer, Heidelberg; Lopes, G., Pereira, L.M., (2010) Visual Demo of “Princess-saviour Robot”, , http://centria.di.fct.unl.pt/; Mallon, R., Nichols, S., Rules (2010) The Moral Psychology Handbook, , Doris, J.M. (ed.), Oxford University Press; McIntyre, A., Doctrine of double effect (2004) The Stanford Encyclopedia of Philosophy. Center for the Study of Language and Information, , http://plato.stanford.edu/archives/fall2011/entries/double-effect/, Zalta, E.N. (ed.), Stanford University, Fall 2011 edition; Newman, J.O., Quantifying the standard of proof beyond a reasonable doubt: A comment on three comments. Law (2006) Probability and Risk, 5 (3-4), pp. 267-269; Pereira, L.M., Saptawijaya, A., Modelling morality with prospective logic (2011) Machine Ethics, pp. 398-421. , Anderson, M., Anderson, S.L. (eds.), Cambridge U. P; Pereira, L.M., Saptawijaya, A., (2015) Abduction and beyond in Logic Programming with Application to Morality, , http://goo.gl/yhmZzy, Accepted in “Frontiers of Abduction”, Special Issue in IfCoLog Journal of Logics and their Applications; Pereira, L.M., Saptawijaya, A., Bridging two realms of machine ethics (2015) Rethinking Machine Ethics in the Age of Ubiquitous Technology. IGI Global, , White, J.B., Searle, R. (eds.); Pereira, L.M., Saptawijaya, A., (2015) Counterfactuals in Logic Programming with Applications to Agent Morality, , http://goo.gl/6ERgGG, Accepted at a special volume of Logic, Argumentation & Reasoning, (preprint); Saptawijaya, A., Pereira, L.M., Incremental tabling for query-driven propagation of logic program updates (2013) LPAR-19 2013. LNCS, 8312, pp. 694-709. , In: McMillan, K., Middeldorp, A., Voronkov, A. (eds.), Springer, Heidelberg; Saptawijaya, A., Pereira, L.M., TABDUAL: A Tabled Abduction System for Logic Programs (2015) Ifcolog Journal of Logics and Their Applications, 2 (1), pp. 69-123; Scanlon, T.M., Anderson, M., Erson, S.L., EthEl: Toward a principled ethical eldercare robot (2008) Procs. AAAI Fall 2008 Symposium on AI in Eldercare; Scanlon, T.M., (2008) Moral Dimensions: Permissibility, , Meaning, Blame. Harvard University Press; Swift, T., Tabling for non-monotonic programming (1999) Annals of Mathematics and Artificial Intelligence, 25 (3-4), pp. 201-240; (2015) Research Priorities for Robust and Beneficial Artificial Intelligence, , http://futureoflife.org/static/data/documents/researchpriorities.pdf, The Future of Life Institute},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{VanRysewyk201593,
author={Van Rysewyk, S.P. and Pontier, M.},
title={A hybrid bottom-up and top-down approach to machine medical ethics: Theory and data},
journal={Intelligent Systems, Control and Automation: Science and Engineering},
year={2015},
volume={74},
pages={93-110},
doi={10.1007/978-3-319-08108-3_7},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921498381&doi=10.1007%2f978-3-319-08108-3_7&partnerID=40&md5=5d05c492c329aa49cd64d6847b5591f2},
abstract={The perceived weaknesses of philosophical normative theories as machine ethic candidates have led some philosophers to consider combining them into some kind of a hybrid theory. This chapter develops a philosophical machine ethic which integrates “top-down” normative theories (rule-utilitarianism and prima-facie deontological ethics) and “bottom-up” (case-based reasoning) computational structure. This hybrid ethic is tested in a medical machine whose inputoutput function is treated as a simulacrum of professional human ethical action in clinical medicine. In six clinical medical simulations run on the proposed hybrid ethic, the output of the machine matched the respective acts of human medical professionals. Thus, the proposed machine ethic emerges as a successful model of medical ethics, and a platform for further developments. © Springer International Publishing Switzerland 2015.},
references={Allen, C., Smit, I., Wallach, W., Artificial morality: Top–down, bottom–up, and hybrid approaches (2005) Ethics Inf Technol, 7 (3), pp. 149-155; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Mag, 28 (4), pp. 15-26; Anderson, S.L., (2011) Machine metaethics, pp. 21-27. , Anderson M, Anderson SL (eds) Machine ethics. Cambridge University Press, Cambridge; Anderson, M., Anderson, S.L., Ethical healthcare agents (2008) Advanced computational intelligence paradigms in healthcare–3, pp. 233-257. , In: Magarita S, Sachin V, Lakhim C, Springer, Berlin; Anderson, M., Anderson, S., Armen, C., MedEthEx: A prototype medical ethics advisor (2006) In: Proceedings of the eighteenth conference on innovative applications of artificial intelligence, , AAAI Press, Menlo Park, CA; Anderson, M., Anderson, S., Armen, C., Toward machine ethics: Implementing two action–based ethical theories. Machine ethics: Papers from the AAAI fall symposium (2005) Technical report FS–05–06, association for the advancement of artificial intelligence, , Menlo Park, CA; Ashley, K.D., McLaren, B.M., Reasoning with reasons in case-based comparisons (1995) Case-based reasoning research and development: First international conference, ICCBR-95, pp. 23-26. , In: Veloso M, Aamodt A, Sesimbra, Portugal; Ashley, K.D., McLaren, B.M., A CBR knowledge representation for practical ethics (1994) Proceedings of the second European workshop on case-based reasoning (EWCBR), , Chantilly, France; Banks, M.R., Willoughby, L.M., Banks, W.A., Animal-assisted therapy and loneliness in nursing homes: Use of robotic versus living dogs (2008) J Am Med Dir Assoc, 9, pp. 173-177; Bentham, J., Rationale of Reward (1843) The Works of Jeremy Bentham, , Book 3, Chapter 1. In: Bowring J, William Tait, Edinburgh; Buchanan, A.E., Brock, D.W., (1989) Deciding for others: The ethics of surrogate decision making, , Cambridge University Press, Cambridge; Casebeer, W., (2001) Natural ethical facts, , MIT Press, Cambridge; Chalmers, D.J., The singularity: A philosophical analysis (2010) J Conscious Stud, 17 (9-10), pp. 7-65; Churchland, P.M., Toward a cognitive neurobiology of the moral virtues (1998) Topoi, 17, pp. 83-96; Churchland, P.S., (2011) Braintrust: What neuroscience tells us about morality, , MIT Press, Cambridge; Damasio, A., (2000) The feeling of what happens: Body and emotion in the making of consciousness, , Harcourt Brace & Company, New York; Damasio, A., (1994) Descartes' error, , Putnam & Sons, New York; Flanagan, O., (1991) Varieties of moral personality: Ethics and psychological realism, , Harvard University Press, Cambridge; Gillon, R., Medical ethics: Four principles plus attention to scope (1994) BMJ, 309 (6948), pp. 184-188; Greene, J.D., Why are VMPFC patients more utilitarian? A dual-process theory of moral judgment explains (2007) Trends Cogn Sci, 11 (8), pp. 322-323; Guarini, M., Particularism and the classification and reclassification of moral cases (2006) IEEE Intell Syst, 21 (4), pp. 22-28; Guarini, M., Introduction: Machine ethics and the ethics of building intelligent machines (2013) Topoi, 32, pp. 213-215; Guarini, M., Moral case classification and the nonlocality of reasons (2012) Topoi, pp. 1-23; Guarini, M., Case classification, similarities, spaces of reasons, and coherences (2013) Coherence: insights from philosophy, jurisprudence and artificial intelligence, pp. 187-220. , In: M Araszkiewicz, J Savelka, Springer, Netherlands; Honarvar, A.R., Ghasem-Aghaee, N., An artificial neural network approach for creating an ethical artificial agent (2009) Computational intelligence in robotics and automation (ICRA), 2009 IEEE international symposium, pp. 290-295; Hoorn, J.F., Pontier, M.A., Siddiqui, G.F., Coppélius” concoction: Similarity and complementarity among three affect–related agent models (2011) Cog Syst Res J, 15, pp. 33-59; Hoorn, J.F., Pontier, M.A., Siddiqui, G.F., Coppélius’ concoction: Similarity and complementarity among three affect-related agent models (2012) Cogn Syst Res, 15-16, pp. 33-49; Hume, D., A treatise of human nature, , 1739/2000, Oxford University Press, Oxford (edited by Norton DF, Norton MJ); (2013) Executive summary of world robotics 2013 industrial robots and service robots, , http://www.worldrobotics.org/uploads/media/Executive_Summary_WR_2013.pdf, Available via, Accessed 24 Oct 2013; Johnson, M., (1993) Moral imagination, , Chicago University Press, Chicago; Kamm, F.M., (2007) Intricate ethics: Rights, responsibilities, and permissible harms, , Oxford University Press, Oxford; Kant, I., The metaphysical elements of justice: part I of the metaphysics of morals, , 1780/1965, Hackett Pub. Co., Indianapolis (translated by Ladd J); Kant, I., Groundwork of the metaphysic of morals, , 1785/1964, Harper and Row, New York (translated by Paton HJ); Kidd, C., Taggart, W., Turkle, S., A social robot to encourage social interaction among the elderly (2006) Proceedings of IEEE ICRA, pp. 3972-3976; Koenigs, M., Young, L., Adolphs, R., Tranel, D., Cushman, F., Hauser, M., Damasio, A., Damage to the prefrontal cortex increases utilitarian moral judgements (2007) Nature, 446 (7138), pp. 908-911; Konijn, E.A., Hoorn, J.F., Some like it bad. Testing a model for perceiving and experiencing fictional characters (2005) Media Psychol, 7 (2), pp. 107-144; Leake, D.B., Case–based reasoning (1998) A companion to cognitive science, pp. 465-476. , Bechtel W, Graham G (eds), Blackwell, Oxford; López, M.E., Bergasa, L.M., Barea, R., Escudero, M.S., A navigation system for assistant robots using visually augmented POMDPs (2005) Auton Robots, 19 (1), pp. 67-87; Marti, P., Bacigalupo, M., Giusti, L., Mennecozzi, C., Socially assistive robotics in the treatment of actional and psychological symptoms of dementia (2006) Proceedings of BioRob, pp. 438-488; McLaren, B.M., Extensionally defining principles and cases in ethics: An AI Model (2003) Artif Intell J, 150, pp. 145-181; McLaren, B.M., Ashley, K.D., Case-based comparative evaluation in truth-teller (1995) The proceedings of the seventeenth annual conference of the cognitive science society, , Pittsburgh, PA; McLaren, B.M., Ashley, K.D., Context sensitive case comparisons in practical ethics: Reasoning about reasons (1995) The proceedings of the fifth international conference on artificial intelligence and law, , College Park, MD; McLaren, B.M., Ashley, K.D., Assessing relevance with extensionally defined principles and cases (2000) The proceedings of AAAI-2000, , Austin, Texas; Meng, Q., Lee, M.H., Design issues for assistive robotics for the elderly (2006) Adv Eng Inform, 20 (2), pp. 171-186; Mill, J.S., (1861/1998) Utilitarianism. In: Crisp R (ed), Oxford University Press, New York; Moll, J., De Oliveira-Souza, R., Moral judgments, emotions and the utilitarian brain (2007) Trends Cogn Sci, 11 (8), pp. 319-321; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intell Syst, 21 (4), pp. 18-21; Thomas, N., (1970) The possibility of altruism, , Princeton University Press, Princeton, NJ; Nejat, G., Ficocelli, M., Can i be of assistance? The intelligence behind an assistive robot (2008) Proceedings of IEEE international conference on robotics and automation ICRA, 2008, pp. 3564-3569; Parfit, D., (1984) Reasons and persons, , Clarendon Press, Oxford; Picard, R., (1997) Affective computing, , MIT Press, Cambridge; Pineau, J., Montemerlo, M., Pollack, M., Roy, N., Thrun, S., Towards robotic assistants in nursing homes: Challenges and results (2003) Robot Auton Syst, 42, pp. 271-281. , (Special issue on Socially Interactive Robots); Pontier, M.A., Hoorn, J.F., Toward machines that behave ethically better than humans do (2012) Proceedings of the 34th international annual conference of the cognitive science society. CogSci, pp. 2198-2203; Powers, T.M., Prospects for a Kantian machine (2006) Intell Syst IEEE, 21 (4), pp. 46-51; Rawls, J., (1971) A theory of justice, , Harvard University Press, Cambridge; Robins, B., Dautenhahn, K., Boekhorst, R.T., Billard, A., Robotic assistants in therapy and education of children with autism: Can a small humanoid robot help encourage social interaction skills? (2005) J Univers Access Inf Soc, 4, pp. 105-120; Robinson, H., Macdonald, B.A., Kerse, N., Broadbent, E., Suitability of healthcare robots for a dementia unit and suggested improvements (2013) J Am Med Dir Assoc, 14 (1), pp. 34-40; Ross, W.D., The right and the good. Clarendon Press, Oxford 59. van Rysewyk S (2013) Robot pain (1930) Int J Synth Emot, 4 (2), pp. 22-33; Rzepka, R., Araki, K., What could statistics do for ethics? The idea of a common sense processing– based safety valve (2005) Machine ethics: Papers from the AAAI fall symposium, , Technical report FS–05–06, association for the advancement of artificial intelligence. Menlo Park, CA; Sidgwick, H., (1907) Methods of Ethics, , 7th edn. Macmillan, London; Super, D.E., The work values inventory (1973) Contemporary approaches to interest measurement, , In: Zytowski DG, University of Minnesota Press, Minneapolis; Tonkens, R., Out of character: On the creation of virtuous machines (2012) Ethics Inf Technol, 14 (2), pp. 137-14964. , http://www.who.int/topics/ageing/en/, WHO (2010) Health topics: ageing. Available from; Wada, K., Shibata, T., Social effects of robot therapy in a care house (2009) JACIII, 13, pp. 386-392; Wallach, W., Robot minds and human ethics: The need for a comprehensive model of moral decision making (2010) Ethics Inf Technol, 12 (3), pp. 243-250; Wallach, W., Allen, C., (2009) Moral machines: Teaching robots right from wrong, , Oxford University Press, Oxford; Wallach, W., Allen, C., Smit, I., Machine morality: Bottom-up and top-down approaches for modelling human moral faculties (2008) AI Soc, 22 (4), pp. 565-582; Wallach, W., Franklin, S., Allen, C., A conceptual and computational model of moral decision making in human and artificial agents (2010) Top Cogn Sci, 2, pp. 454-485; Williams, B., (1973) A critique of utilitarianism, 19 (2), pp. 407-433. , Smart JJC, Williams B (eds) Utilitarianism: for and against. Cambridge University Press, Cambridge, pp 77–150 71. van Wynsberghe A. (2013) Designing robots for care: care centered value-sensitive design. Science and engineering ethics},
document_type={Article},
source={Scopus},
}

@ARTICLE{Santos-Lang2015111,
author={Santos-Lang, C.C.},
title={Moral ecology approaches to machine ethics},
journal={Intelligent Systems, Control and Automation: Science and Engineering},
year={2015},
volume={74},
pages={111-127},
doi={10.1007/978-3-319-08108-3_8},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921383640&doi=10.1007%2f978-3-319-08108-3_8&partnerID=40&md5=a85fa6ea1a4880edfbb476c3505fd3d9},
abstract={Wallach and Allen’s seminal book, Moral Machines: Teaching Robots Right from Wrong, categorized theories of machine ethics by the types of algorithms each employs (e.g., top-down vs. bottom-up), ultimately concluding that a hybrid approach would be necessary. Humans are hybrids individually: our brains are wired to adapt our evaluative approach to our circumstances. For example, stressors can inhibit the action of oxytocin in the brain, thus forcing a nurse who usually acts from subjective empathy to defer to objective rules instead. In contrast, ecosystem approaches to ethics promote hybridization across, rather than within, individuals; the nurse being empowered to specialize in personalized care because other workers specialize in standardization, and profitability. Various philosophers have argued, or laid the framework to argue, that such specialization can be advantageous to teams and societies. Rather than mass-produce identical machines to emulate the best individual human, perhaps we should build diverse teams of machines to emulate the best human teams. © Springer International Publishing Switzerland 2015},
references={Alford, J.R., Funk, C.L., Hibbing, J.R., Are political orientations genetically transmitted? (2005) Am Polit Sci Rev, 99, pp. 153-167; Arias-Carrión, Ó., Pöppel, E., Dopamine, learning and reward–seeking behavior (2007) Acta Neurobioligiae Experimentalis, 67, pp. 481-488; Barreto, M., Ellmers, N., The impact of anonymity and group identification on pro– group behavior in computer–mediated groups (2002) Small Group Res, 33, pp. 590-610; Berea, A., Twardy, C., Automated trading in prediction markets (2013) Social computing, behavioral–cultural modeling and prediction, pp. 111-122. , Kennedy WG, Agarwal N, Yang SJ (eds), Springer, Berlin; Caruana, R., Niculescu-Mizil, A., An empirical comparison of supervised learning algorithms (2006) Proceedings of the 23rd international conference on machine learning, pp. 161-168. , The Association for Computing Machinery, New York; Charlesworth, A., A proof of Gödel’s Theorem in terms of computer programs (1980) Math Mag, 54, pp. 109-121; (2007), http://creativecommons.org/licenses/by–sa/3.0/, Attribution–ShareAlike 3.0 unported (CC BY–SA 3.0), Accessed 8 Oct 2012; Cushman, F., Young, L., Hauser, M., The role of conscious reasoning and intuition in moral judgment: Testing three principles of harm (2006) Psychol Sci, 17, pp. 1082-1089; De Jong, K.A., (2006) Evolutionary computation: A unified approach, , MIT Press, Cambridge; Dean, T., Evolution and moral diversity. Baltic International Yearbook of Cognition (2012) Logic and Communication, 7 (1), pp. 1-16; Denison, D.R., (1990) Corporate culture and organizational effectiveness, , Wiley, New York; Diener, E., Fujita, F., Life satisfaction set point: Stability and change (2005) J Pers Soc Psychol, 88, p. 158; Dunbar, K., Fugelsang, J., Causal thinking in science: How scientists and students interpret the unexpected (2005) Sci Technol Think, pp. 57-79; Eddy, D.M., Adler, J., Patterson, B., Lucas, D., Smith, K.A., Morris, M., Individualized guidelines: The potential for increasing quality and reducing costs (2011) Ann Intern Med, 154, pp. 627-634; Fan, P., Innovation capacity and economic development: China and India (2011) Econ Change Restructuring, 44, pp. 49-73; Fehr, E., Gachter, S., Altruistic punishment in humans (2002) Nature, 415, pp. 137-140; (2012), http://www.gnu.org/copyleft/fdl.html, Inc (2008) GNU free documentation license, Accessed 8 Oct; Giarratano, J.C., Riley, G.D., (2005) Expert systems, principles and programming, , Thomson Course Technology, Boston; Graham, J., Haidt, J., Nosek, B.A., Liberals and conservatives rely on different sets of moral foundations (2009) J Pers Soc Psychol, 96, pp. 1029-1046; Greene, J.D., The cognitive neuroscience of moral judgment (2009) The cognitive neurosciences IV, , In: Gazzaniga MS (ed), MIT Press, Cambridge; Hanson, R., Logarithmic market scoring rules for modular combinatorial information aggregation (2007) J Prediction Markets, 1, pp. 3-15; Heisenberg, W., Über den anschaulichen Inhalt der quantentheoretischen Kinematik und Mechanik (1927) Zeitschrift für Physik, 43, pp. 172-198; Hofstede, G.H., (2001) Culture’s consequences: Comparing values, behaviors, institutions, and organizations across nations, , Sage Publications, Thousand Oaks; Isen, A.M., Levin, P.F., Effect of feeling good on helping: Cookies and kindness (1972) J Pers Soc Psychol, 21, pp. 384-388; Kanai, R., Feilden, T., Firth, C., Rees, G., Political orientations are correlated with brain structure in young adults (2011) Curr Biol, 21, pp. 677-680; Kitcher, P., The division of cognitive labor (1990) J Philos, 87, pp. 5-22; Kohlberg, L., (1981) The philosophy of moral development, , Harper & Row, San Francisco; Kram, M.L., Kramer, G.L., Ronan, P.J., Steciuk, M., Petty, F., Dopamine receptors and learned helplessness in the rat: An autoradiographic study (2002) Prog Neuropsychopharmacol Biol Psychiatry, 26, pp. 639-645; Kulkarni, D., Simon, H.A., The processes of scientific discovery: The strategy of experimentation (1988) Cogn Sci, 12, pp. 139-175; Lewontin, R.C., The units of selection (1970) Annu Rev Ecol Syst, 1, pp. 1-18; Lind, G., (1978) Wie misst man moralisches Urteil? Probleme und alternative Möglichkeiten der Messung eines komplexen Konstrukts, pp. 171-201. , Portele G (ed) Sozialisation Und Moral. Beltz, Weinheim; Lorenz, E.N., Deterministic nonperiodic flow (1963) J Atmos Sci, 20, pp. 130-141; Lykken, D., Tellegen, A., Happiness is a stochastic phenomenon (1996) Psychol Sci, 7, pp. 186-189; Maynard Smith, J., (1982) Evolution and the theory of games, , Cambridge University Press, Cambridge; Milgram, S., Behavioral study of obedience (1963) J Abnorm Soc Psychol, 67, pp. 371-378; Newton, I., (1676) Personal letter, 1, p. 416. , In: Turnbull HW (ed) The correspondence of Isaac Newton, Cambridge University Press, Cambridge; Norman, W.T., Toward an adequate taxonomy of personality attributes: Replicated factor structure in peer nomination personality ratings (1963) J Abnorm Soc Psychol, 66, pp. 574-583; O’reilly, C.A., Chatman, J., Caldwell, D.F., People and organizational culture: A profile comparison approach to assessing person–organization fit (1991) Acad Manag J, 34, pp. 487-516; Page, S.E., (2011) Diversity and complexity, , Princeton University Press, Princeton; Pascal, B., Havet, E., (1852), Pensées. Dezobry et E. Magdeleine; Pinker, S., (2011) The better angels of our nature: Why violence has declined, , Viking Adult, New York; Pizarro, D.A., Laney, C., Morris, E.K., Loftus, E.F., Ripple effects in memory: Judgments of moral blame can distort memory for events (2006) Mem Cogn, 34, pp. 550-555; Polgreen, P.M., Nelson, F.D., Neumann, G.R., Weinstein, R.A., Use of prediction markets to forecast infectious disease activity (2007) Clin Infect Dis, 44, pp. 272-279; Quere, C.L., Harrison, S.P., Colin Prentice, I., Buitenhuis, E.T., Aumont, O., Bopp, L., Claustre, H., Ecosystem dynamics based on plankton functional types for global ocean biogeochemistry models (2005) Glob Change Biol, 11, pp. 2016-2040; Raymond, E., (2000) The cathedral and the bazaar, , http://www.catb.org/esr/writings/homesteading/cathedral–bazaar/, Accessed 8 Oct 2012; Rest, J., (1979) Development in judging moral issues, , University of Minnesota Press, Minneapolis; Santos-Lang, C.C., (2002) Ethics for artificial intelligences, , http://santoslang.wordpress.com/article/ethics-for-artificial-intelligences-3iue30fi4gfq9-1/, Presented at the 2002 Wisconsin State-wide technology symposium, Accessed July 2011; Sauper, C., (2008) Automated creation of Wikipedia articles. Dissertation, , Massachusetts Institute of Technology; Schiff, J.L., (2011) Cellular automata: A discrete view of the world, , Wiley, Hoboken; Servan-Schreiber, E., Wolfers, J., Pennock, D.M., Galebach, B., Prediction markets: Does money matter? (2004) Electron Markets, 14, pp. 243-251; Slovic, P., If I look at the mass I will never act: Psychic numbing and genocide (2007) Judgment Decis Making, 2, pp. 79-95; Sober, E., Wilson, D.S., (1998) Unto others: The evolution and psychology of unselfish behavior, , Harvard University Press, Cambridge; Sober, E., Wilson, S., Summary of: Unto others: The evolution and psychology of unselfish behavior (2000) J Conscious Stud, 7, pp. 185-206; Sosis, R., Ruffle, B.J., Religious ritual and cooperation: Testing for a relationship on Israeli religious and secular kibuttzun (2003) Curr Anthropol, 44, pp. 713-722; Steare, R., (2006) Ethicability, , Roger Steare Consulting, London; Steil, B., Victor, D.G., Nelson, R.R., (2002) Technological Innovation and Economic Performance, , Princeton University Press, Princeton; Stephens, S.L., Martin, R.E., Clinton, N.E., Prehistoric fire area and emissions from California’s forests, woodlands, shrublands, and grasslands (2007) For Ecol Manage, 251, pp. 205-216; Stephens, S.L., Ruth, L.W., Federal forest-fire policy in the United States (2005) Ecol Appl, 15, pp. 532-542; Taleb, N.N., The black swan: The impact of the highly improbable (2010) Random House Digital, , Inc, New York; Thompson, A., (1996) Silicon evolution. In: Proceedings of the first annual conference on genetic programming, pp. 444-452. , MIT Press, Cambridge; Turiel, E., (1983) The development of social knowledge: Morality and convention, , Cambridge University Press, Cambridge; Versel, N., NCQA tests new healthcare quality measure (2013) Information Week, p. 12. , April; Walker, L.J., Frimer, J.A., Dunlop, W.L., Varieties of moral personality: Beyond the banality of heroism (2010) J Pers, 78, pp. 907-942; Wallach, W., Allen, C., Smit, I., Machine morality: Bottom–up and top-down approaches for modeling human moral faculties (2008) AI Soc, 22, pp. 565-582; Wallach, W., Allen, C., Moral machines: Teaching robots right from wrong. Oxford University Press (2008) Oxford; Wilde, D., Personalities into teams (2011) Eng Manage Rev IEEE, 39, pp. 20-24; Wilson, D.S., Wilson, E.O., Evolution “for the good of the group (2008) Am Sci, 96, pp. 380-389; Wilson, D.S., Near, D., Miller, R., Machiavellianism: A synthesis of the evolutionary and psychological literatures (1996) Psychol Bull, 119, pp. 285-299; Wittgenstein, L., (1958) Philosophical investigations, , Blackwell, Oxford; Wolfers, J., Zitzewitz, E., Prediction markets. No. w10504 (2004) National Bureau of Economic Research; Yamagishi, T., Cross–societal experimentation on trust: A comparison of the United States and Japan (2003) Trust and reciprocity: Interdisciplinary lessons from experimental evidence, pp. 352-370. , In: Ostrom E, Walker J, Russel Sage Foundation, New York; Yang, X.-S., Firefly algorithms for multimodal optimization (2009) In: Proceedings of the 5th international conference on stochastic algorithms: Foundations and applications, pp. 169-178. , Springer, Berlin; Zak, P., The physiology of moral sentiments (2011) J Econ Behav Organ, 77, pp. 53-65},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bogue2014398,
author={Bogue, R.},
title={Robot ethics and law part two: Law},
journal={Industrial Robot},
year={2014},
volume={41},
number={5},
pages={398-402},
doi={10.1108/IR-04-2014-0332},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927561809&doi=10.1108%2fIR-04-2014-0332&partnerID=40&md5=255671993628d5e52c7778cffd3e9cb6},
abstract={Purpose: This is the second part of a two-part paper which aims to provide an insight into the ethical and legal issues surrounding certain classes of robot. This part is concerned with law. Design/methodology/approach: Following an introduction, this paper first describes the European RoboLaw project and then considers legal issues and activities relating to civilian airborne drones, driverless road vehicles and assistive robots. It concludes with a short discussion. Findings: The legal issues associated with many classes of robot are the topic of much debate, and efforts are underway to create appropriate legislative frameworks. A project is presently seeking to create a framework for the development of a Europe-wide "Robolaw" and in certain cases, laws are already being formulated to accommodate recent robotic developments. These deliberations are rapidly gaining pace and are now also considering future generations of highly autonomous and intelligent robots. Originality/value: This paper provides an insight into the highly topical and complex issue of robot law. © Emerald Group Publishing Limited.},
author_keywords={Law;  Legislation;  Liability;  Robots},
keywords={Laws and legislation;  Machine design;  Philosophical aspects;  Product liability;  Robots, Assistive robots;  Design/methodology/approach;  Future generations;  Law;  Legal issues;  Legislative frameworks;  Road vehicles;  Robot ethics, Intelligent robots},
document_type={Article},
source={Scopus},
}

@ARTICLE{Muntean2014217,
author={Muntean, I. and Howard, D.},
title={Artificial moral agents: Creative, autonomous, social. An approach based on evolutionary computation},
journal={Frontiers in Artificial Intelligence and Applications},
year={2014},
volume={273},
pages={217-230},
doi={10.3233/978-1-61499-480-0-217},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922570742&doi=10.3233%2f978-1-61499-480-0-217&partnerID=40&md5=1ff70d753d46c42e81a6175517b191de},
abstract={In this paper we propose a model of artificial normative agency that accommodates some social competencies that we expect from artificial moral agents. The artificial moral agent (AMA) discussed here is based on two components: (i) a version of virtue ethics of human agents (VE) adapted to artificial agents, called here 'virtual virtue ethics' (VVE); and (ii) an implementation based on evolutionary computation (EC), more concretely genetic algorithms. The reasons to choose VVE and EC are related to two elements that are, we argue, central to any approach to artificial morality: autonomy and creativity. The greater the autonomy an artificial agent has, the more it needs moral standards. In the virtue ethics, each agent builds her own character in time; creativity comes in degrees as the individual becomes morally competent. The model of an autonomous and creative AMA thus implemented is called GAMA= Genetic(-inspired) Autonomous Moral Agent. First, unlike the majority of other implementations of machine ethics, our model is more agent-centered, than action-centered; it emphasizes the developmental and behavioral aspects of the ethical agent. Second, in our model, the AMA does not make decisions exclusively and directly by following rules or by calculating the best outcome of an action. The model incorporates rules as initial data (as the initial population of the genetic algorithms) or as correction factors, but not as the main structure of the algorithm. Third, our computational model is less conventional, or at least it does not fall within the Turing tradition in computation. Genetic algorithms are excellent searching tools that avoid local minima and generate solutions based on previous results. In the GAMA model, only prospective at this stage, the VVE approach to ethics is better implemented by EC. Finally, the GAMA agents can display sociability through competition among the best moral actions and the desire to win the competition. Both VVE and EC are more adequate to a 'social approach' to AMA when compared to the standard approaches. The GAMA is more promising a 'moral and social artificial agent'. © 2014 The authors and IOS Press. All rights reserved.},
author_keywords={artificial moral agents;  autonomous agents;  behaviorism;  dispositionalism;  evolutionary computation;  genetic algorithms;  naturalism;  sociability;  virtue ethics},
keywords={Algorithms;  Calculations;  Evolutionary algorithms;  Genetic algorithms;  Ontology;  Philosophical aspects;  Population statistics;  Virtual reality, behaviorism;  dispositionalism;  Moral agents;  naturalism;  sociability;  Virtue ethics, Autonomous agents},
references={Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental & Theoretical Artificial Intelligence, 12, pp. 251-261; Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics Inf Technol, 1 (7), pp. 149-155. , September; Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge University Press; Savulescu, J., Maslen, H., Moral enhancement and artificial intelligence: Moral ai (2015) Topics in Intelligent Engineering and Informatics, pp. 79-95. , Romportl J, Zackova E, Kelemen J, editors. Beyond Artificial Intelligence Springer International Publishing; Chalmers, D., The Singularity: A philosophical analysis (2010) Journal of Consciousness Studies, 17 (9), pp. 7-65; Kurzweil, R., (2006) The Singularity is Near: When Humans Transcend Biology, , New York: Penguin; Tonkens, R., Out of character: On the creation of virtuous machines (2012) Ethics Inf Technol, 14, pp. 137-149; Pritchard, D., Virtue epistemology and epistemic luck (2003) Metaphilosophy, 34, pp. 106-130; Allen, C., Wallach, W., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford; New York: Oxford University Press; Bello, P., Bringsjord, S., On how to build a moral machine (2013) Topoi., 32, pp. 251-266; Schmidt, M., Lipson, H., Distilling free-form natural laws from experimental data (2009) Science, 324, pp. 81-85; Gips, J., Towards the ethical robot (1995) Android Epistemology, , Ford KM, Glymour CN, Hayes PJ, editors. Menlo Park; Cambridge, Mass.: AAAI Press; MIT Press; Sørensen, M.H., The genealogy of biomimetics: Half a century's quest for dynamic it (2004) Biologically Inspired Approaches to Advanced Information Technology. Lecture Notes in Computer Science, 3141, p. 496. , Ijspeert AJ, Murata M, Wakamiya N, editors Berlin; New York: Springer; Asimov, I., Runaround (1942) Astounding Science Fiction, 29, pp. 94-103; Danielson, P., (1992) Artificial Morality Virtuous Robots for Virtual Games, , London; New York: Routledge; Arkin, R., (2009) Governing Lethal Behavior in Autonomous Robots, , CRC Press; Arkin, R.C., (1998) Behavior-based Robotics, , Cambridge, Mass.: MIT Press; Turing, A.M., Computing machinery and intelligence (1950) Mind, 59, pp. 433-460; Koza, J.R., Poli, R., A genetic programming tutorial (2003) Introductory Tutorials in Optimization, Search and Decision Support; Jong, K.A., De, D., Evolutionary computation (2006) 1st Ed., , Cambridge MA: MIT Press: A Bradford Book; Olariu, S., Zomaya, A.Y., (2006) Handbook of Bioinspired Algorithms and Applications 1st Ed., , Chapman and Hall/CRC; Ford, K.M., Glymour, C.N., Hayes, P.J., (1995) Android Epistemology, , Menlo Park; Cambridge, Mass.: AAAI Press; MIT Press; Doris, J.M., Persons, situations, and virtue ethics (1998) Noûs., 32, pp. 504-530; Harman, G., Moral philosophy meets social psychology: Virtue ethics and the fundamental attribution error (1999) Proceedings of the Aristotelian Society, pp. 315-331; Thomson, J.J., The right and the good (1997) The Journal of Philosophy, 94, p. 273; Appiah, A., (2008) Experiments in Ethics, , Harvard University Press; Macintyre, A.C., After virtue: A study in moral theory (1984) Notre Dame, , Ind.: University of Notre Dame Press; Hursthouse, R., (1999) On Virtue Ethics, , Oxford; New York: Oxford University Press; Murdoch, I., (1970) The Sovereignty of Good, , London; New York: Routledge},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Bogue2014335,
author={Bogue, R.},
title={Robot ethics and law: Part one: Ethics},
journal={Industrial Robot},
year={2014},
volume={41},
number={4},
pages={335-339},
doi={10.1108/IR-04-2014-0328},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904683103&doi=10.1108%2fIR-04-2014-0328&partnerID=40&md5=a60c032c060ff2234535c96c8fa030e4},
abstract={Purpose - This first part of a two-part paper aims to provide an insight into the ethical and legal issues associated with certain classes of robot. This part is concerned with ethics. Design/methodology/approach - Following an introduction, this paper first considers the ethical deliberations surrounding robots used in warfare and healthcare. It then addresses the issue of robot truth and deception and subsequently discusses some on-going deliberations and possible ways forward. Finally, brief conclusions are drawn. Findings - Robot ethics are the topic of wide-ranging debate and encompass such diverse applications as military drones and robotic carers. Many ethical considerations have been raised including philosophical issues such as moral behaviour and truth and deception. Preliminary research suggests that some of these concerns may be ameliorated through the use of software which encompasses ethical principles. It is widely recognised that a multidisciplinary approach is required and there is growing evidence of this. Originality/value - This paper provides an insight into the highly topical and complex issue of robot ethics. © Emerald Group Publishing Limited.},
author_keywords={Autonomy;  Drones;  Ethics;  Roboethics;  Robots},
keywords={Military applications;  Robots;  Target drones, Autonomy;  Design/methodology/approach;  Diverse applications;  Drones;  Ethical considerations;  Ethics;  Multi-disciplinary approach;  Roboethics, Philosophical aspects},
document_type={Article},
source={Scopus},
}

@ARTICLE{Borenstein201217,
author={Borenstein, J.},
title={Robotics, ethics, and the environment},
journal={International Journal of Technoethics},
year={2012},
volume={3},
number={2},
pages={17-29},
doi={10.4018/jte.2012040103},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864531494&doi=10.4018%2fjte.2012040103&partnerID=40&md5=393c2a50198d7bc2a2582c3998589864},
abstract={As robots become more pervasive and take on an ever-growing number of tasks, exploring ethical issues relating to the technology takes on increasing importance. Specifically, the manufacturing and sale of personal service robots could be severely detrimental to the environment. Ideally, members of the robotics community would develop a comprehensive awareness of the complex ethical and environmental consequences emerging from their design pathways before historical patterns are repeated. Copyright © 2012, IGI Global.},
author_keywords={Engineering Ethics;  Environmental Ethics;  Planned Obsolescence;  Robot Ethics;  Sustainable Design},
references={Allada, V., Preparing engineering students to meet the ecological challenges through sustainable product design (2000) Proceedings of the International Conference on Engineering Education, , http://www.ineer.org/Events/ICEE2000/Proceedings/papers/TuA9-3.pdf, Retrieved June 22, 2011, from; Code of Ethics of Engineers, , http://files.asme.org/ASMEORG/Governance/3675.pdf, American Society of Mechanical Engineers (ASME). (2009, April 23). Retrieved June 21, 2011; Association for computing machinery ACM (1992) ACM Code of Ethics and Professional Conduct, , http://www.acm.org/about/code-of-ethics, October 16, Retrieved June 21, 2011; Baker, K., Why should we be friends? (2008) Newsweek, , http://www.newsweek.com/2008/08/08/why-should-we-be-friends.html, August 9, Retrieved June 21, 2011, from; Barboza, D., China surpasses U.S. In number of internet users (2008) The New York Times, , http://www.nytimes.lcom/2008/07/26/business/worldbusiness/26internet.html, July 26, Retrieved June 22, 2011; Beamon, B.M., Environmental and sustainability ethics in supply chain management (2010) Science and Engineering Ethics, 11, pp. 221-234. , doi:10.1007/s11948-005-0043-y; Bodeen, C., China not fighting off e-waste nightmare (2007) The Associated Press, , http://www.washingtonpost.com/wp-dyn/content/article/2007/11/18/ AR2007111800357.html, November 19, Retrieved June 21, 2011; Clarke, R., Asimov's laws of robotics: Implications for information technology-part i (1993) Computer, 26 (12), pp. 53-61. , doi:10.1109/2.247652; Clarke, R., Asimov's laws of robotics: Implications for information technology-part II (1994) Computer, 27 (1), pp. 57-66. , doi:10.1109/2.248881; Davidson, C.I., Matthews, H.S., Hendrickson, C.T., Bridges, M.W., Allenby, B.R., Crittenden, J.C., Viewpoint: Adding sustainability to the engineer's toolbox: A challenge for engineering educators (2007) Environmental Science & Technology, 41 (14), pp. 4847-4849. , doi:10.1021/es072578f; De Graaf, J., Wann, D., Naylor, T.H., (2001) Affluenza, , San Francisco, CA: Berrett-Koehler; Delaney, J., Recyclers' illegally exporting electronic waste (2008) Epoch Times, , http://www.theepochtimes.com/n2/canada/recyclers-illegal-exporting- electrical-waste-7440.html, November 19, Retrieved June 21, 2011; Dwyer, J., Trail of hot air (2008) Engineering & Technology, 3 (20), pp. 63-65. , doi:10.1049/et:20082013; Essick, K., Guns, money and cell phones (2001) The Industry Standard, , http://www.globalissues.org/article/442/guns-money-and-cell-phones, June 11, Retrieved June 21, 2011; (2000) Commission Tackles Growing Problem of Electrical and Electronic Waste, , http://europa.eu/rapid/pressReleasesAction.do?reference=IP/00/ 602&format=HTML&aged=0&language=EN&guiLanguage=en, June 13, Europa Press Releases. Retrieved June 21, 2011, from; Fanara, A., Home energy use and the proliferation of consumer electronics products (2006) Energy Star Podcast, , http://www.energystar.gov/index.cfm?c=products.pr_podcasts_transcript, September 10, Retrieved June 22, 2011; Fountain, H., Recycling that harms the environment and people (2008) The New York Times, , http://www.nytimes.com/2008/04/15/science/earth/15obrecy.html, April 15, Retrieved June 22, 2011; Friedman, T.L., (2006) The World Is Flat: A Brief History of the Twenty-first Century, , New York, NY: Farrar, Straus and Giroux; Goleman, D., (2009) Ecological Intelligence: How Knowing the Hidden Impacts of What We Buy Can Change Everything, , New York, NY: Broadway Books; Guiltinan, J., Creative destruction and destructive creations: Environmental ethics and planned obsolescence (2009) Journal of Business Ethics, 89, pp. 19-28. , doi:10.1007/s10551-008-9907-9; Guizzo, E., World robot population reaches 8.6 million (2010) IEEE Spectrum Blogs/Automation, , http://spectrum.ieee.org/automaton/robotics/industrial-robots/ 041410-world-robot-population, Retrieved June 22, 2011, from; Guizzo, E., Obama commanding robot revolution, announces major robotics initiative (2011) IEEE Spectrum Blogs/Automation, , http://spectrum.ieee.org/automaton/robotics/industrial-robots/ obama-announces-major-robotics-initiative, June 24, Retrieved July 5, 2011, from; Harden, B., The dirt in the new machine (2001) The New York Times, , http://www.nytimes.com/2001/08/12/magazine/the-dirt-in-the-new-machine. html, August 12; Harris Jr., C.E., Pritchard, M.S., Rabins, M.J., (2009) Engineering Ethics: Concepts & Cases, , 4th ed. Independence, KY: Thomson. Wadsworth; Hilty, L.M., Electronic waste-an emerging risk? (2005) Environmental Impact Assessment Review, 25 (5), pp. 431-435. , doi:10.1016/j.eiar.2005.04.002; Horvath, J., Borne by blood: The other-and often bloody-side of the 'digital revolution (2002) Telepolis, , http://www.heise.de/tp/artikel/12/12860/1.html, Retrieved June 22, 2011; Hosoda, E., International aspects of recycling of electrical and electronic equipment: Material circulation in the East Asian region (2007) Journal of Material Cycles and Waste Management, 9 (2), pp. 140-150. , doi:10.1007/s10163-007-0179-8; (2006) IEEE Code of Ethics, , http://www.ieee.org/portal/cms_docs/about/CoE_poster.pdf, IEEE. Retrieved June 21, 2011, from; Kaufman, L., A green way to dump low-tech electronics (2009) The New York Times, , http://www.nytimes.com/2009/06/30/science/earth/30ewaste.html, June 30, Retrieved June 22, 2011, from; Krumsiek, B., Socially responsible high tech companies: Emerging issues (2003) Journal of Business Ethics, 43, pp. 179-187. , The Calvert Social Research Department doi:10.1023/A:1022929812030; Lankey, R., McMichael, F., (1999) Rechargeable Battery Management and Recycling: A Green Design Educational Module, , http://www.ce.cmu.edu/GreenDesign/gd/education/Battery.pdf, Green Design Initiative Tech. Rep. Pittsburgh, PA: Carnegie Mellon University. Retrieved December 6, 2010; Levy, D., (2008) Love and Sex with Robots: The Evolution of Human-robot Relationships, , New York, NY: Harper Perennial; MacDorman, K.F., Vasudevan, S.K., Ho, C.-C., Does Japan really have robot mania? Comparing attitudes by implicit and explicit measures (2009) AI & Society, 23, pp. 485-510. , doi:10.1007/s00146- 008-0181-2; Martin, M.W., Schinzinger, R., (2005) Ethics in Engineering, , 4th ed. New York, NY: McGraw-Hill; McDonough, W., Braungart, M., (2002) Cradle to Cradle: Remaking the Way We Make Things, , New York, NY: North Point Press; Mieszkowski, K., Stanford considers guideline for 'conflict minerals (2010) The New York Times, , http://www.nytimes.com/2010/06/13/us/13bcminerals.html, June 11 Retrieved June 22, 2011; Onishi, N., A wired South Korea, robots will feel right at home (2006) The New York Times, , http://www.nytimes.com/2006/04/02/world/asia/02robot.html, April 2, Retrieved June 22, 2011, from; Oosterlaken, I., Design for development: A capability approach (2009) Design Issues, 25 (4), pp. 91-102. , doi:10.1162/desi.2009.25.4.91; Reports, C., (2006) E-waste Survey, , http://www.greenerchoices.org/electronicsrecycling/Ewaste_survey_2006.pdf, March 28 Retrieved December 15, 2010; Riley, D., (2008) Engineering and Social Justice, , San Rafael, CA: Morgan and Claypool; Sharkey, N., The ethical frontiers of robotics (2008) Science, 322, pp. 1800-1801. , doi:10.1126/science.1164582; Siegel, M., The sense-think-act paradigm revisited (2003) Proceedings of the 1st International Workshop on Robotic Sensing; Siklos, R., Linking a device to a gadget that's wired to a gizmo (2006) The New York Times, , http://www.nytimes.com/2006/01/08/business/yourmoney/08frenzy.html, January 8, Retrieved June 22, 2011; Slade, G., (2007) Made to Break: Technology and Obsolescence in America, , Boston, MA: Harvard University Press; Sofge, E., Can robots be trusted? (2010) Popular Mechanics, pp. 54-61; Sparrow, R., Sparrow, L., In the hands of machines? the future of aged care (2006) Minds and Machines, 16, pp. 141-161. , doi:10.1007/s11023-006-9030-6; The European commission (2006) Directive on Waste Electrical and Electronic Equipment, , http://ec.europa.eu/environment/docum/00347_en.htm, June 14, Retrieved June 21, 2011, from; The european commission joint research centre (JRC) (2010) Report Forecasts Shortages of 14 Critical Mineral Raw Materials, , http://ec.europa.eu/dgs/jrc/index.cfm?id=1410&obj_id= 10890&dt_code=NWS&lang=en, June 17 Retrieved June 22, 2011; (2003) Directive 2002/95/EC of the European Parliament and of the Council of 27 January 2003 on the Restriction of the Use of Certain Hazardous Substances in Electrical and Electronic Equipment, , http://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:32002L0095: EN:NOT, The european parliament and the council of the European Union Retrieved June 22, 2011; Torres, K., NIOSH report: Prison computer recycling plant plagued with heavy metals (2007) EHSToday, , http://ehstoday.com/ppe/respirators/ehs_imp_77363/, December 26, Retrieved June 22, 2011, from; (2007) Toxic Wastes and Race and Toxic Wastes and Race at Twenty, , http://www.ucc.org/justice/environmental-justice/pdfs/ toxic-wastes-and-race-at-twenty-1987-2007.pdf, United Church of Christ.1987-2007. Retrieved June 22, 2011, from; (2005) Human development report-International cooperation at a crossroads: Aid, trade and security in an unequal world, , http://hdr.undp.org/en/reports/global/hdr2005/, Retrieved June 22, 2011, from United Nations; (2011) Recycling of Europe's electronic waste needs improvement, UN report urges. ScienceDaily, , http://www.sciencedaily.com/releases/2007/11/071115113338.htmc, United Nations University. (2007, November 16). Retrieved June 22; Unmanned Aerial Vehicles Roadmap 2000-2025, , http://www.globalsecurity.org/intell/library/reports/2001/uavr0401.htm, U.S. Department of Defense (DoD) Office of the Secretary of Defense. (2001). Retrieved June 22, 2011; http://www.epa.gov/waste/conserve/materials/battery.htm, U.S. Environmental Protection Agency (EPA). (2010a, December 1). Batteries. Retrieved December 17, 2010; (2011) General Information on E-waste. Retrieved June 22, , http://www.epa.gov/waste/conserve/materials/ecycling/faq.htm#general, U.S. Environmental Protection Agency (EPA). (2010b, December 2); Statistics on the Management of Used and End-of-life Electronics, , http://www.epa.gov/waste/conserve/materials/ecycling/manage.htm, U.S. Environmental Protection Agency (EPA). (2010c, December 2). Retrieved June 22, 2011; Weber, A., New manufacturing process could boost demand for conductive plastic (2010) Assembly Magazine, , http://www.assemblymag.com/Articles/Web_Exclusive/BNP_GUID_9-5- 2006_A_10000000000000960893, December 15, Retrieved June 22, 2011, from; Widmer, R., Oswald-Krapf, H., Sinha-Khetriwal, D., Schnellmann, M., Boni, H., Global perspectives on e-waste (2005) Environmental Impact Assessment Review, 25 (5), pp. 436-458. , doi:10.1016/j. eiar.2005.04.001; Witness, G., (2005) Under-mining Peace-Tin: The Explosive Trade in Cassiterite in Eastern DRC, , http://www.globalwitness.org/sites/default/files/pdfs/ Under-Mining%20Peace.pdf, Retrieved December 17, 2010, from; Woodhouse, E.J., Curbing overconsumption: Challenge for ethically responsible engineering (2001) IEEE Technology and Society Magazine, 20 (3), pp. 23-30. , doi:10.1109/44.952762},
document_type={Article},
source={Scopus},
}

@BOOK{Anderson2011162,
author={Anderson, S.L.},
title={Philosophical concerns with machine ethics},
journal={Machine Ethics},
year={2011},
volume={9780521112352},
pages={162-167},
doi={10.1017/CBO9780511978036.011},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927048871&doi=10.1017%2fCBO9780511978036.011&partnerID=40&md5=1ace531eaa26bb93df1242d70236e349},
abstract={The challenges facing those working on machine ethics can be divided into two main categories: philosophical concerns about the feasibility of computing ethics and challenges from the AI perspective. In the first category, we need to ask first whether ethics is the sort of thing that can be computed. One well-known ethical theory that supports an affirmative answer to this question is Act Utilitarianism. According to this teleological theory (a theory that maintains that the rightness and wrongness of actions is determined entirely by the consequences of the actions), the right act is the one, of all the actions open to the agent, which is likely to result in the greatest net good consequences, taking all those affected by the action equally into account. Essentially, as Jeremy Bentham (1781) long ago pointed out, the theory involves performing "moral arithmetic." Of course, before doing the arithmetic, one needs to know what counts as "good" and "bad" consequences. The most popular version of Act Utilitarianism - Hedonistic Act Utilitarianism - would have us consider the pleasure and displeasure that those affected by each possible action are likely to receive. As Bentham pointed out, we would probably need some sort of scale to account for such things as the intensity and duration of the pleasure or displeasure that each individual affected is likely to receive. This is information that a human being would need to have, as well, in order to follow the theory. © Cambridge University Press 2011.},
keywords={Computation theory, Counts-as;  Ethical theories;  Human being;  On-machines, Philosophical aspects},
references={Anderson, M., Anderson, S., Armen, C., Toward machine ethics: Implementing two action-based ethical theories (2005) Machine Ethics: Papers from the AAAI Fall Symposium. Technical Report FS- 05–06, , Association for the Advancement of Artificial Intelligence, Menlo Park, CA; Anderson, M., Anderson, S., Armen, C., An approach to computing ethics (2006) IEEE Intelligent Systems, 21 (4); Anderson, S.L., Being morally responsible for an action versus acting responsibly or irresponsibly (1995) Journal of Philosophical Research, 20; Bentham, J., (1781) An Introduction to the Principles of Morals and Legislation, , Clarendon Press, Oxford; Dietrich, E., After the humans are gone (2006) NA-CAP, , 2006 Keynote Address, RPI, Troy, New York; Gazzaniga, M., (2006) The Ethical Brain: The Science of Our Moral Dilemmas, , Harper Perennial, New York; Mappes, T.A., Degrazia, D., (2001) Biomedical Ethics, , 5th edition, McGraw-Hill, New York; Pojman, L.J., The case for moral objectivism (1996) Do the Right Thing: A Philosophical Dialogue on the Moral and Social Issues of Our Time, , ed. by F. J. Beckwith, Jones and Bartlett, New York; Ross, W.D., (1930) The Right and the Good, , Oxford University Press, Oxford},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Krichmar2011209,
author={Krichmar, J.L. and Wagatsuma, H.},
title={Neuromorphic and brain-based robots},
journal={Frontiers in Artificial Intelligence and Applications},
year={2011},
volume={233},
pages={209-214},
doi={10.3233/978-1-60750-959-2-209},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-80155130654&doi=10.3233%2f978-1-60750-959-2-209&partnerID=40&md5=90c552667c42eac09860e8f8a0934cef},
abstract={Neuromorphic and brain-based robotics have enormous potential for furthering our understanding of the brain. By embodying models of the brain on robotic platforms, researchers can investigate the roots of biological intelligence and work towards the development of truly intelligent machines. This paper discusses the history of the field and its potential. We give examples of biologically inspired robot designs and neural architectures that lead to brain-based robots. Looking to the future, we consider the development of cognitive, or even conscious, robots that display the adaptability and intelligence of biological organisms. © 2011 The authors and IOS Press. All rights reserved.},
author_keywords={Brain-based robots;  cognitive robots;  computational neuroscience;  machine ethics;  neuromorphic engineering;  neurorobots},
keywords={Machine design;  Neural networks;  Robotics;  Robots, Biological organisms;  Biologically-inspired robots;  Cognitive robots;  Computational neuroscience;  Intelligent machine;  Neural architectures;  Neuromorphic engineering;  Neurorobots, Intelligent robots},
references={Krichmar, J.L., Wagatsuma, H., (2011) Neuromorphic and Brain-Based Robots, , Cambridge University Press; Grey Walter, W., (1953) The Living Brain, 2nd Ed, , London: Penguin; Braitenberg, V., (1986) Vehicles: Experiments in Synthetic Psychology, , Cambridge: MIT Press; Pfeifer, R., Bongard, J., (2007) How the Body Shapes the Way We Think: A New View of Intelligence, , Cambridge: MIT Press; Hosoda, K., Robust haptic recognition by anthropomorphic robot hand (2011) Neuromorphic and Brain-Based Robots, pp. 11-22. , J. L. Krichmar and H. Wagatsuma, Eds., ed: Cambridge University Press; Mitchinson, B., Biomimetic robots as scientific models: A view from the whisker tip (2011) Neuromorphic and Brain-Based Robots, pp. 23-57. , J. L. Krichmar and H. Wagatsuma, Eds., ed: Cambridge University Press; Cox, B.R., Krichmar, J.L., Neuromodulation as a Robot Controller: A Brain Inspired Design Strategy for Controlling Autonomous Robots (2009) IEEE Robotics & Automation Magazine, 16, pp. 72-80; Krichmar, J.L., The Neuromodulatory System-A Framework for Survival and Adaptive Behavior in a Challenging World (2008) Adaptive Behavior, 16, pp. 385-399; Wyeth, G., The RatSLAM project: Robot spatial navigation (2011) Neuromorphic and Brain-Based Robots, pp. 87-108. , J. L. Krichmar and H. Wagatsuma, Eds., ed: Cambridge University Press; Kaplan, F., Oudeyer, P., From hardware and software to kernels and envelopes: A concept shift for robotics, developmental psychology and brain sciences (2011) Neuromorphic and Brain-Based, pp. 217-250. , Robots, J. L. Krichmar and H. Wagatsuma, Eds., ed: Cambridge University Press; Asada, M., Can cognitive developmental robotics cause a paradigm shift? (2011) Neuromorphic and Brain-Based, pp. 251-273. , Robots, J. L. Krichmar and H. Wagatsuma, Eds., ed: Cambridge University Press; Wagatsuma, H., A look at the hidden side of situated cognition: A robotic study of brain-oscillationbased dynamics of instantaneous, episodic, and conscious memories (2011) Neuromorphic and Brain-Based, pp. 274-302. , Robots, J. L. Krichmar and H. Wagatsuma, Eds., ed: Cambridge University Press; Edelman, G.M., Naturalizing consciousness: A theoretical framework (2003) Proceedings of the National Academy of Sciences of the United States of America, 100 (9), pp. 5520-5524. , DOI 10.1073/pnas.0931349100; Fleischer, J.G., The case for using brain-based devices to study consciousness (2011) Neuromorphic and Brain-Based, pp. 303-319. , Robots, J. L. Krichmar and H. Wagatsuma, Eds., ed: Cambridge University Press; Bekey, G.A., Ethical implications of intelligent robots (2011) Neuromorphic and Brain-Based, pp. 323-344. , Robots, J. L. Krichmar and H. Wagatsuma, Eds., ed: Cambridge University Press},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Dogramadzi2010133,
author={Dogramadzi, S. and Virk, G.S. and Tokri, M.O. and Harper, C.},
title={Service robot ethics},
journal={Mobile Robotics: Solutions and Challenges - Proceedings of the 12th International Conference on Climbing and Walking Robots and the Support Technologies for Mobile Machines, CLAWAR 2009},
year={2010},
pages={133-139},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885637721&partnerID=40&md5=a9b3d966a4d62b91100b27d5f88ad993},
abstract={The area of robotics is moving from its traditional roots in the industrial sector as the entire robotic community is keen to develop new types of robots for new environments. This change is emphasis is being driven by many factors and it is now widely accepted that robots must become mass market products in order that they may fulfil their full potential in providing assistive capabilities to humans in a wide range of applications. This shift has been noticed and the International Standards Organisation (ISO) has set up new standardization groups to investigate the robot standardization activities that need to be encouraged to facilitate the commercialisation of new types of robots throughout the world. The robotic community has been developing prototype robotic systems for a variety of new applications and many new sectors are causing concern and if they should be encouraged or not. This has started an ethical debate on what should be encouraged and if there are robot applications that should be discouraged. It is accepted that robot applications that generically improve the quality of life for humans should be encouraged but areas which promote unethical areas of human activities should be looked at more closely to determine of robots should be allowed to enter these sector or not; this includes applications such as military applications, sex robots, fully autonomous robots, etc. In view of these developments, discussions have commenced within ISO so that internationally accepted views can be formulated and accepted. This paper presents the start of these deliberations and raises some of the important issues that need to be debated so that internationally accepted views can be agreed at the ISO level so that commercialisation of only the accepted systems is permitted across international boundaries.},
keywords={Commercialisation;  Human activities;  Industrial sector;  International standards;  New applications;  Quality of life;  Robotic community;  Robotic systems, Military applications;  Mobile robots;  Robot applications;  Standardization, Robotics},
references={Assaro, P.M., International review of information ethics (2006) What Should We Want from a Robot Ethic?, 6, pp. 9-16; Veruggio, G., (2006) Proceedings EURON Roboethics Atelier, EURON Roboethics Roadmap, , ed., 2/27-3/3; Arkin, R., (2006) Technical Report GIT-GVU-07-JJ, Governing Lethal Behavior: Embedding Ethics in a Hybrid Deliberative/Reactive Robot Architecture; Wagner, J.J., Cannon, D.M., Van Der Loos, H.F.M., (2005) Proc. ICORR'2005 Cross-Cultural Considerations in Establishing Roboethics for Neuro-Robot Applications, 1; Levy, D., (2007) Harper Collins Love and Sex with Robots: The Evolution of Human-Robot Relationships; http://www.infoniac.com/hi-tech/robotics-expert-calls-for-robot- ethicsguidelines.html; (2006) International Organization for Standardization, , ISO Robot Safety Standard 10218-1, June 2006; Virk, G.S., Sjostrom, C., Engstrom, M., Trinius, W., (2006) Proceedings of the Workshop on Ethics of Human Interaction with Robotic, Bionic, and AI Systems: Concepts and Policies, Standards And/or Ethics for Service Robots?, pp. 69-75; Scopelliti, M., Giuliani, M.V., D'amico, A.M., Fornara, F., Designing a more inclusive world. If i had a robot at home (2004) Peoples' Representation of Domestic Robots, pp. 257-266. , S. Keates, J. Clarkson, P. Langdon, and P. Robinson, Eds. Springer; Dautenhahn, K., (2002) Proc. IEEE Ro-man Design Spaces and Niche Spaces of Believable Social Robots, pp. 192-197; Woods, S., Dautenhahn, K., Schulz, I., (2004) Proc. IEEE Ro-man. The Design Space of Robots: Investigating Children's Views, pp. 47-52; Soyama, R., Ishii, S., Fukase, A., (2003) Proceedings of the ICORR, the Development of Meal -Assistance Robot My Spoon; www.popularmechanics.com/technology/industryI1288241.html; http://www.respectproject.org/ethics/principles.php; Trevelyan, J.P., (1996) Service Robot, Automatic Sheep Shearing, 2 (3)},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Tonkens200938,
author={Tonkens, R.S.},
title={Ethical implementation: A challenge for Machine Ethics},
journal={Adaptive and Emergent Behaviour and Complex Systems - Proceedings of the 23rd Convention of the Society for the Study of Artificial Intelligence and Simulation of Behaviour, AISB 2009},
year={2009},
pages={38-45},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859013327&partnerID=40&md5=37a9eadb197b4a1378fdcbedc2183988},
abstract={The discipline of Machines Ethics, whose mandate is to create artificial moral agents (AMAs), is gaining momentum. Although it is often asked whether a given moral framework can be implemented into machines, it is never asked whether it should be. This paper articulates a pressing challenge for Machine Ethics: To identify an ethical framework that is both implementable into machines and whose tenets permit the creation of such AMAs in the first place. Without consistency between ethics and engineering, the resulting AMAs would not be genuine ethical robots, and hence the discipline of Machine Ethics would be a failure in this regard. Here this challenge is articulated through a critical analysis of the development of Kantian AMAs, which represents a leading contender for successful implementation of ethics into machines. In the end, the development of Kantian AMAs is found to be anti-Kantian. The upshot of all this is that machine ethicists need to look elsewhere for an ethic to implement into their machines.1.},
keywords={Critical analysis;  Gaining momentum;  Moral agents, Artificial intelligence, Philosophical aspects},
references={Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) IEEE Intelligent Systems, 21 (4), pp. 12-17; Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics and Information Technology, 7 (3), pp. 149-155. , DOI 10.1007/s10676-006-0004-4, Ethics of New Information Technology Papers from CEPE 2005; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12 (3), pp. 251-261; Anderson, M., Anderson, S.L., The status of machine ethics: A report from the AAAI Symposium (2007) Minds and Machines, 17 (1), pp. 1-10. , DOI 10.1007/s11023-007-9053-7; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-27; Anderson, M., Anderson, S.L., Machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 10-11; Anderson, M., Anderson, S.L., Armen, C., An approach to computing ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 56-63; Boden, M.A., (1994) Dimensions of Creativity, , Cambridge: MIT Press; Brooks, R.A., Intelligence without Representation (1991) Artificial Intelligence, 47, pp. 139-159; Calverley, D.J., Imagining a non-biological machine as a legal person (2008) AI & Society, 22 (4), pp. 523-537; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds and Machines, 14 (3), pp. 349-379; Gips, J., Creating ethical robots: A grand challenge (2005) AAAI Symposium on Machine Ethics, , Washington, D.C; Gips, J., Towards the ethical robot (1995) Android Epistemology, pp. 243-252. , K. Ford, C. Glymour, & P. Hayes (eds.). Cambridge: MIT Press; Grau, C., There is no 'I' in 'Robot': Robots and utilitarianism (2006) IEEE Intelligent Systems, 21 (4), pp. 52-55; Guarini, M., Particularism and the classification and reclassification of moral cases (2006) IEEE Intelligent Systems, 21 (4), pp. 22-28; Johnson, D.G., Computer systems: Moral entities but not moral agents (2006) Ethics and Information Technology, 8 (4), pp. 195-204. , DOI 10.1007/s10676-006-9111-5; Kant, I., (1997) Lectures on Ethics, , Trans. P. Heath. Cambridge: Cambridge University Press; Kant, I., (1996) The Metaphysics of Morals, , Trans. M. Gregor. Cambridge: Cambridge University Press; Kant, I., (1988) Fundamental Principles of the Metaphysic of Morals, , Trans. T. K. Abbott. New York: Prometheus; McCarthy, J., Free will-even for robots (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12 (3), pp. 341-352; McLaren, B., Computational models of ethical reasoning: Challenges, initial steps, and future directions (2006) IEEE Intelligent Systems, 21 (4), pp. 29-37; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Nadeau, J.E., Only androids can be ethical (2006) Thinking about Android Epistemology, pp. 241-248. , K. Ford, C. Glymour, & P. J. Hayes (eds.). Cambridge: MIT Press; O'neill, O., (1989) Constructions of Reason: Explorations of Kant's Practical Philosophy, , New York: Cambridge University Press; Picard, R.W., (1997) Affective Computing, , Cambridge: MIT Press; Powers, T.M., Prospects for a kantian machine (2006) IEEE Intelligent Systems, 21 (4), pp. 46-51; Rawls, J., (2000) Lectures on the History of Moral Philosophy, , Cambridge: Harvard University Press; Sparrow, R., Killer robots (2007) Journal of Applied Philosophy, 24 (1), pp. 62-77; (2006) The U. S. Army Future Combat Systems Program, , www.cbo.gov/ftpdoc.cfm?index=7122, Accessed March 3 rd, 2009; Torrance, S., Ethics and consciousness in artificial agents (2008) AI & Society, 22 (4), pp. 495-521; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford: Oxford University Press; Wallach, W., Allen, C., Smit, I., Machine morality: Bottom-up and top-down approaches for modelling human moral faculties (2008) AI & Society, 22, pp. 565-582},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Anderson20082,
author={Anderson, M. and Anderson, S.L.},
title={Developing a general, interactive approach to codifying ethical principles},
journal={AAAI Workshop - Technical Report},
year={2008},
volume={WS-08-05},
pages={2-8},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-66149163107&partnerID=40&md5=cb32e57801515a07bfd10f97b3a385b9},
abstract={Building on our previous achievements in machine ethics (Anderson el al. 2006a-b, 2007, 2008), we are developing and implementing a general interactive approach to analyzing ethical dilemmas with the goal to apply it toward the end of codifying the ethical principles that will help resolve ethical dilemmas that intelligent systems will encounter in their interactions with human beings. Making a minimal epistemological commitment that there is at least one ethical duty and at least two possible actions that could be performed, the general system will: 1) incrementally construct, through an interactive exchange with experts in ethics, a representation scheme needed to handle the dilemmas with which it is presented, and 2) discover principles implicit in the judgments of these ethicists in particular cases that lead to their resolution. The system will commit only to the assumption that any ethically relevant features of a dilemma can be represented as the degree of satisfaction or violation of one or more duties that an agent must take into account to determine which of the actions that are possible in that dilemma is ethically preferable. Copyright © 2008, Association for the Advancement of Artificial Intelligence.},
keywords={Anderson;  Degree of satisfaction;  Ethical dilemma;  Ethical principles;  Human being;  Interactive approach;  Representation schemes, Intelligent systems},
references={Allen, C., Varner, G., Zinser, J., Prolegomena ID Any Future Artificial Moral Agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12, pp. 251-261; Anderson, M., Anderson, S., Armen, C., MedEthEx: A Prototype Medical Ethics Advisor (2006) Proceedings of the Eighteenth Conference on Innovative Applications of Artificial Intelligence, , Boston, Massachusetts, August; Anderson, M., Anderson, S., Armen, C., An Approach to Computing Ethics (2006) Special Issue of IEEE Intelligent Systems on Machine Ethics, , August; Anderson, M., Anderson, S., Machine Ethics: Creating an Ethical Intelligent Agent (2007) Artificial Intelligence Magazine, 28. , Winter; Anderson, M. & Anderson, S. EthEl: Toward a Principled Ethical Eldercare Robot. 2008. Workshop on Assistive Robots at the Conference on Human-Robot Interaction, March; Beauchamp, T.L., Childress, J.F., (1979) Principles of Biomedical Ethics, , Oxford University Press; Boden, M. 2006. Robots and Anthropomorphism. In (Metzler 2006); Bringsjord, S., Arkoudas, K., Bello, P., Toward a General Logicist Methodology for Engineering Ethically Correct Robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44. , July/August; Buchanan, A.E., Brock, D.W., (1989) Deciding for Others: The Ethics of Surrogate Decision Making, pp. 48-57. , Cambridge University Press; Bundy, A., McNeill, F., Representation as a Fluent: An AI Challenge for the Next Half Century (2006) IEEE Intelligent Systems, 21 (3), pp. 85-87. , May/June; Gips, J., (1995) Towards the Ethical Robot. Android Epistemology, pp. 243-252. , Cambridge MA: MIT Press, pp; Grau, C., There Is No "I" in "Robot": Robots and Utilitarianism (2006) IEEE Intelligent Systems, 21 (4), pp. 52-55. , July/August; Guarini, M., Particularism and the Classification and Reclassification of Moral Cases (2006) IEEE Intelligent Systems, 21 (4), pp. 22-28. , July/August; Khan, A.F.U., (1995) The Ethics of Autonomous Learning Systems. Android Epistemology, pp. 253-265. , Cambridge MA: MIT Press, pp; Mappes, T.A., DeGrazia, D., Biomedical Ethics (2001) 5th Edtion, pp. 39-42. , McGraw-Hill, New York; McLaren, B.M., Extensionally Defining Principles and Cases in Ethics: An AI Model (2003) Artificial Intelligence Journal, 150, pp. 145-181. , November, pp; Metzler, T., Human Implications of Human-Robot Interaction (2006) AAAI Technical Report, , WS-06-09, AAAI Press; Metzler, T., Human Implications of Human-Robot Interaction (2007) AAAI Technical Report, , WS-07-07, AAAI Press; Moor, J.H., The Nature, Importance, and Difficulty of Machine Ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21. , July/August; Powers, T.M., Prospects for a Kantian Machine (2006) IEEE Intelligent Systems, 21 (4), pp. 46-51. , July/August; Rawls, J., Outline for a Decision Procedure for Ethics (1951) Philosophical Review, 60; Ross, W.D., (1930) The Right and the Good, , Clarendon Press, Oxford; Rzepka, R., Araki, K., What Could Statistics Do for Ethics? The Idea of Common Sense Processing Based Safety Valve (2005) Proceedings of the AAAI Fall Symposium on Machine Ethics, pp. 85-87. , AAAI Press; Syrdal, D. S., Walters, M. L., Otero, N., Koay, K. L.and Dautenhahn, K. 2007. 'He knows when you are sleeping' - Privacy and the Personal Robot Companion. In (Metzler 2007); Turkle, S. 2006. Robot as Rorschach: New Complicities for Companionship. In (Metzler 2006); Waldrop, M. M. 1987. A Question of Responsibility. Chap. 11 in Man Made Minds: The Promise of Artificial Intelligence. NY: Walker and Company, 1987. (Reprinted in R. Dejoie et al., eds. Ethical Issues in Information Systems. Boston, MA: Boyd and Fraser, 1991, pp. 260-277.)},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Karnouskos2020252,
author={Karnouskos, S.},
title={Self-Driving Car Acceptance and the Role of Ethics},
journal={IEEE Transactions on Engineering Management},
year={2020},
volume={67},
number={2},
pages={252-265},
doi={10.1109/TEM.2018.2877307},
art_number={8542947},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057369446&doi=10.1109%2fTEM.2018.2877307&partnerID=40&md5=9b7c1bc6b6d11b60a835aaa3481be8b4},
abstract={Mass availability of self-driving cars is ante portas and independent of their sophistication, unavoidable fatal accidents will occur where the car will have to take life and death decisions. However, there is a knowledge gap, since the impact, that the ethical frameworks (used in the car's decision-making process) have on the overall acceptance of self-driving cars, is not well investigated. This paper addresses the key question: In the scope of unavoidable accidents, what is the effect of different ethical frameworks governing self-driving car decision-making, on their acceptance? This quantitative positivist research investigates the link of selected ethical frameworks, i.e., utilitarianism, deontology, relativism, absolutism (monism), and pluralism, to the acceptance of self-driving cars. It is hypothesized that they have an impact on the acceptance of the self-driving cars, and a model linking them to it is proposed and assessed. All five selected ethical frameworks investigated are found to have an effect on self-driving car acceptance, which implies actions for several involved stakeholders as these may be a deciding factor for the success or failure of the self-driving car market introduction. © 1988-2012 IEEE.},
author_keywords={Autonomous vehicles;  ethical dilemmas;  machine ethics;  self-driving car acceptance},
keywords={Accidents;  Decision making;  Philosophical aspects, Car markets;  Decision making process;  Ethical dilemma;  Fatal accidents;  Knowledge gaps;  Life and death;  Model linking;  Self drivings, Autonomous vehicles},
references={Begg, D., A 2050 vision for London: What are the implications of driverless transport (2014) Tech. Rep., , http://www.transporttimes.co.uk/Admin/uploads/64165-transport-times_a-2050-vision-for-london_aw-web-ready.pdf; Greenough, J., 10 million self-driving cars will be on the road by 2020 (2016) Business Insider, , https://goo.gl/e4DbJe, Jun; Urmson, C., Whittaker, W.R., Self-driving cars and the urban challenge (2008) IEEE Intell. Syst., 23 (2), pp. 66-68. , Mar; Valdes-Dapena, P., (2016) Volvo promises deathproof cars by 2020, , http://money.cnn.com/2016/01/20/luxury/volvo-no-death-crash-cars-2020, Jan; Automatisiertes und vernetztes fahren (2017) Tech. Rep., , http://www.bmvi.de/berichtethikkommission, Jun. Ethik-Kommission; Critical reasons for crashes investigated in the national motor vehicle crash causation survey (2015) Tech. Rep., , https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812115; Preliminary report highway HWY18MH010 (2018) Tech. Rep., , https://www.ntsb.gov/investigations/AccidentReports/Reports/HWY18MH010-prelim.pdf; Goodall, N., Ethical decision making during automated vehicle crashes (2014) Transp. Res. Rec., J. Transp. Res. Board, 2424, pp. 58-65. , Dec; Carsten, P., Andel, T.R., Yampolskiy, M., McDonald, J.T., Invehicle networks: Attacks, vulnerabilities, and proposed solutions (2015) Proc. 10th Annu. Cyber Inf. Secur. Res. Conf., pp. 11-18; Thomson, J.J., The trolley problem (1985) Yale Law J., 94 (6), pp. 1395-1415. , May; Goodall, N.J., Can you program ethics into a self-driving car? (2016) IEEE Spectrum, 53 (6), pp. 28-58. , Jun; Bryson, J., Winfield, A., Standardizing ethical design for artificial intelligence and autonomous systems (2017) Computer, 50 (5), pp. 116-119. , May; Karnouskos, S., (2017) Ethical Frameworks in Critical Decisions and the Acceptance of Self-driving Cars, , Master's thesis, Dept. Comput. Syst. Sci., Stockholm Univ., Stockholm, Sweden; (2018) Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems, , http://standards.ieee.org/develop/indconn/ec/autonomous_systems.html; Ethical aspects of cyber-physical systems (2016) Scientific Foresight Study, , https://goo.gl/Fp5Wjs, Jun. European Parliament; Lin, P., Why ethics matters for autonomous cars (2015) Autonomes Fahren, pp. 69-85. , Berlin, Germany, Springer; Bonnefon, J.-F., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2016) Science, 352 (6293), pp. 1573-1576. , Jun; Sikkenk, M., Terken, J., Rules of conduct for autonomous vehicles (2015) Proc. 7th Int. Conf. Automot. User Interfaces Interactive Veh. Appl., pp. 19-22. , Jun; Frison, A.-K., Wintersberger, P., Riener, A., First person trolley problem (2016) Proc. 8th Int. Conf. Automot. User Interfaces Interactive Veh. Appl., pp. 117-122; Sütfeld, L.R., Gast, R., König, P., Pipa, G., Using virtual reality to assess ethical decisions in road traffic scenarios: Applicability of valueof-life-based models and influences of time pressure (2017) Frontiers Behav. Neurosci., 11. , Jul; Ess, C., (2014) Digital Media Ethics (Digital Media and Society), , 2nd ed. Cambridge, U. K. : Polity Press; Self-driving vehicles in an urban context (2015) Press Briefing, , https://goo.gl/IPVVtf, World Economic Forum, Nov; Hevelke, A., Nida-Rümelin, J., Responsibility for crashes of autonomous vehicles: An ethical analysis (2014) Sci. Eng. Ethics, 21 (3), pp. 619-630. , Jun; Nees, M.A., Acceptance of self-driving cars: An examination of idealized versus realistic portrayals with a self-driving car acceptance scale (2016) Proc. Human Factors Ergonom. Soc. Annu. Meeting, 60 (1), pp. 1449-1453. , Sep; Kyriakidis, M., Happee, R., DeWinter, J., Public opinion on automated driving: Results of an international questionnaire among 5000 respondents (2015) Transp. Res. Part F, Traffic Psychol. Behav., 32, pp. 127-140. , Jul; (2011) Consumers in US and UK Frustrated with Intelligent Devices That Frequently Crash or Freeze, New Accenture Survey Finds, , https://newsroom.accenture.com/article_display.cfm?article_id=5146, Feb; Yvkoff, L., (2012) Many Car Buyers Show Interest in Autonomous Car Tech, , https://www.cnet.com/roadshow/news/many-car-buyers-show-interest-in-autonomous-car-tech/, Apr; Schoettle, B., Sivak, M., A survey of public opinion about autonomous and self-driving vehicles in the U. S., the U. K., and Australia (2014) Tech. Rep., , https://deepblue.lib.umich.edu/bitstream/handle/2027.42/108384/103024.pdf; (2013) Consumers Desire More Automated Automobiles, According to Cisco Study, , https://newsroom.cisco.com/press-release-content?articleId=1184392, CISCO May; Hohenberger, C., Spörrle, M., Welpe, I.M., How and why do men and women differ in their willingness to use automated cars? The influence of emotions across different age groups (2016) Transp. Res. Part A, Policy Pract., 94, pp. 374-385. , Dec; Driving the future: Understanding the new automotive consumer (2016) Tech. Rep., , http://www.pwc.com/us/en/industry/entertainment-media/publications/consumer-intelligence-series/assets/pwc-autotech-v18.pdf; Bansal, P., Kockelman, K.M., Singh, A., Assessing public opinions of and interest in new vehicle technologies: An Austin perspective (2016) Transp. Res. Part C, Emerg. Technol., 67, pp. 1-14. , Jun; Casley, S.V., Jardim, A.S., Quartulli, A.M., (2013) A Study of Public Acceptance of Autonomous Cars, , https://web.wpi.edu/Pubs/E-project/Available/E-project-043013-155601/unrestricted/A_Study_of_Public_Acceptance_of_Autonomous_Cars.pdf, B. Sc. Thesis, Worcester Polytech. Inst., Worcester, MA, USA; Payre, W., Cestac, J., Delhomme, P., Intention to use a fully automated car: Attitudes and a priori acceptability (2014) Transp. Res. Part F, Traffic Psychol. Behav., 27, pp. 252-263. , Nov; Bansal, P., Kockelman, K.M., Are we ready to embrace connected and self-driving vehicles? A case study of Texans (2016) Transportation, 45, pp. 641-675. , Nov; Howard, D., Dai, D., Public perceptions of self-driving cars: The case of Berkeley, California (2013) Proc. 93rd Annu. Meeting Transp. Res. Board, , http://www.danielledai.com/academic/howard-dai-selfdrivingcars.pdf; Only 18 per cent of Britons believe driverless cars to be an important development for the car industry to focus on (2014) Ipsos MORI Loyalty Automotive Survey, , https://goo.gl/S7TZa8, Jul. Ipsos MORI; Youngs, J., (2014) 2014 U. S. Automotive Emerging Technologies Study Results, , http://www.jdpower.com/cars/articles/jdpower-studies/2014-us-automotive-emerging-technologies-study-results, May; (2013) Continental Mobility Study 2013: Findings to the Acceptance of Advanced Driver Assistance Systems and Automated Driving, , https://goo.gl/JbVGGa, Continental; Haboucha, C.J., Ishaq, R., Shiftan, Y., User preferences regarding autonomous vehicles (2017) Transp. Res. Part C, Emerg. Technol., 78, pp. 37-49. , May; Zmud, J., Sener, I.N., Wagner, J., Consumer acceptance and travel behavior impacts of automated vehicles (2016) Tech. Rep. PRC 15-49 F, , http://tti.tamu.edu/documents/PRC-15-49-F.pdf; Leicht, T., Chtourou, A., Youssef, K.B., Consumer innovativeness and intentioned autonomous car adoption (2018) J. High Technol. Manage. Res., 29, pp. 1-11. , May; Kaur, K., Rampersad, G., Trust in driverless cars: Investigating key factors influencing the adoption of driverless cars (2018) J. Eng. Technol. Manage., 48, pp. 87-96. , Apr; Hulse, L.M., Xie, H., Galea, E.R., Perceptions of autonomous vehicles: Relationships with road users, risk, gender and age (2018) Safety Sci., 102, pp. 1-13. , Feb; Körber, M., Baseler, E., Bengler, K., Introduction matters: Manipulating trust in automation and reliance in automated driving (2018) Appl. Ergonom., 66, pp. 18-31. , Jan; Myers, M.D., Qualitative research in information systems (1997) Originally Published in MISQ Discovery, , http://www.qual.auckland.ac.nz, Living Version, Univ. Auckland, Auckland, New Zealand, Jun; Straub, D., Gefen, D., Boudreau, M.-C., (2004) The IS World Quantitative, Positivist Research Methods Website, , http://dstraub.cis.gsu.edu:88/quant/, https://web. archive.org/web/20140819221204/; Forsyth, D.R., A taxonomy of ethical ideologies (1980) J. Person. Soc. Psychol., 39 (1), pp. 175-184; Denscombe, M., (2010) The Good Research Guide for Small-Scale Social Research Projects, , 4th ed. New York, NY, USA: McGraw Hill; Byrne, B.M., (2009) Structural Equation Modeling with AMOS: Basic Concepts, Applications, and Programming, , Multivariate Applications Series, 2nd ed. New York, NY, USA: Taylor & Francis; Straub, D., Boudreau, M.-C., Gefen, D., Validation guidelines for IS positivist research (2004) Commun. Assoc. Inf. Syst., 13 (24), pp. 380-427; Cronbach, L., Coefficient alpha and the internal structure of tests (1951) Psychometrika, 16 (3), pp. 297-334; Yin, R.K., (2009) Case Study Research: Design and Methods, , 4th ed. Newbury Park, CA, USA: Sage, Dec; Eisenführ, F., Weber, M., Langer, T., (2010) Rational DecisionMaking, , Berlin, Germany: Springer; Gerdes, J.C., Thornton, S.M., Implementable ethics for autonomous vehicles (2015) Autonomes Fahren, pp. 87-102. , Berlin, Germany: Springer; Malle, B.F., Scheutz, M., Arnold, T., Voiklis, J., Cusimano, C., Sacrifice one for the good of many? People apply different moral norms to human and robot agents (2015) Proc. 10th Annu. ACM/IEEE Int. Conf. Human-Robot Interact., pp. 117-124; Kant, I., (1959) Critique of Practical Reason, , Indianapolis, IN, USA: Bobbs-Merrill, 1785 transl. : by L. White Beck, Ed; Coca-Vila, I., Self-driving cars in dilemmatic situations: An approach based on the theory of justification in criminal law (2017) Criminal Law Philosophy, 12, pp. 59-82. , Jan; Millar, J., Technology as moral proxy: Autonomy and paternalism by design (2014) Proc. IEEE Int. Symp. Ethics Sci., Technol. Eng, pp. 1-7. , May; Tedre, M., What should be automated? The fundamental question underlying human-centered computing (2006) Proc. 1st ACM Int. Workshop Human-Centered Multimedia, pp. 19-24; Flemisch, F., Heesen, M., Hesse, T., Kelsch, J., Schieben, A., Beller, J., Towards a dynamic balance between humans and automation: Authority, ability, responsibility and control in shared and cooperative control situations (2011) Cognition, Technol., Work, 14 (1), pp. 3-18. , Nov; De Sio, F.S., Killing by autonomous vehicles and the legal doctrine of necessity (2017) Ethical Theory Moral Pract., 20, pp. 411-429. , Feb; Borenstein, J., Herkert, J., Miller, K., Self-driving cars: Ethical responsibilities of design engineers (2017) IEEE Technol. Soc. Mag., 36 (2), pp. 67-75. , Jun; Gogoll, J., Müller, J.F., Autonomous cars: In favor of a mandatory ethics setting (2016) Sci. Eng. Ethics, 23, pp. 681-700. , Jul; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) IEEE Intell. Syst., 21 (4), pp. 12-17. , Jul; Applin, S., Riener, A., Fischer, M., Extending driver-vehicle interface research into the mobile device commons: Transitioning to (nondriving) passengers and their vehicles (2015) IEEE Consum. Electron. Mag., 4 (4), pp. 101-106. , Oct; McBride, N., The ethics of driverless cars (2016) SIGCAS Comput. Soc., 45 (3), pp. 179-184. , Jan; Petit, J., Shladover, S., Potential cyberattacks on automated vehicles (2014) IEEE Trans. Intell. Transp. Syst., 16 (2), pp. 546-556. , Apr; Karnouskos, S., Kerschbaum, F., Privacy and integrity considerations in hyperconnected autonomous vehicles (2018) Proc. IEEE, 106 (1), pp. 160-170. , Jan; Ali Alheeti, K., Gruebler, A., McDonald-Maier, K., An intrusion detection system against malicious attacks on the communication network of driverless cars (2015) Proc. 12th Annu. IEEE Consum. Commun. Netw. Conf., pp. 916-921. , Jan; Akhtar, N., Mian, A., Threat of adversarial attacks on deep learning in computer vision: A survey (2018) IEEE Access, 6, pp. 14410-14430; Schellekens, M., Self-driving cars and the chilling effect of liability law (2015) Comput. Law Secur. Rev., 31 (4), pp. 506-517; Norman, G., Likert scales, levels of measurement and the laws of statistics (2010) Adv. Health Sci. Educ., Theory Pract., 15 (5), pp. 625-632. , Feb; Sposito, V.A., Hand, M.L., Skarpness, B., On the efficiency of using the sample kurtosis in selecting optimal Lp estimators (1983) Commun. Statist.-Simul. Comput., 12 (3), pp. 265-272. , Jan; Norris, M., Lecavalier, L., Evaluating the use of exploratory factor analysis in developmental disability psychological research (2010) J. Autism Develop. Disorders, 40 (1), pp. 8-20; Kaiser, H.F., Rice, J., Little jiffy, mark IV (1974) Educ. Psychol. Meas., 34 (1), pp. 111-117. , Apr; Kaiser, H.F., The application of electronic computers to factor analysis (1960) Educ. Psychol. Meas., 20 (1), pp. 141-151. , Apr; Fabrigar, L.R., Evaluating the use of exploratory factor analysis in psychological research (1999) Psychol. Methods, 4, pp. 272-299; Hair, J.F., Black, W.C., Babin, B.J., Anderson, R.E., (2010) Multivariate Data Analysis, , 7th ed. Upper Saddle River, NJ, USA: Prentice Hall; George, D., Mallery, P., (2013) IBM SPSS Statistics 21 Step by Step: A Simple Guide and Reference, , 13th ed. London, U. K. : Pearson; Tanaka, J.S., Multifaceted conceptions of fit in structural equation models (1993) Testing Structural Equation Models, , Newbury Park, CA, USA: Sage; Wheaton, B., Muthén, B., Alwin, D., Summers, G., Assessing reliability and stability in panel models (1977) Sociological Methodology, pp. 84-136. , San Francisco, CA, USA: Jossey-Bass; Carmines, E., McIver, J., Analyzing models with unobserved variables (1981) Social Measurement: Current Issues, , Beverly Hills, CA, USA: Sage; Byrne, B.M., (1989) A Primer of LISREL: Basic Applications and Programming for Confirmatory Factor Analytic Models, , New York, NY, USA: Springer-Verlag; Jöreskog, K., Sörbom, D., (1986) LISREL-VI: Analysis of Linear Structural Relationships by Maximum Likelihood, Instrumental Variables, and Least Squares Methods, , 4th ed. Mooresville, IN, USA: Scientific Software; Tanaka, J., Huba, G., A fit index for covariance structure models under arbitrary GLS estimation (1985) Brit. J. Math. Statist. Psychol., 38, pp. 197-201; Sharma, S., Mukherjee, S., Kumar, A., Dillon, W.R., A simulation study to investigate the use of cutoff values for assessing model fit in covariance structure models (2005) J. Bus. Res., 58 (7), pp. 935-943; Bentler, P., Comparative fit indexes in structural models (1990) Psychol. Bull., 107, pp. 238-246; Browne, M.W., Cudeck, R., (1993) Alternative Ways of Assessing Model Fit, pp. 136-162. , Newbury Park, CA, USA: Sage; MacCallum, R.C., Browne, M.W., Sugawara, H.M., Power analysis and determination of sample size for covariance structure modeling (1996) Psychol. Methods, 1 (2), pp. 130-149; Hox, J., Bechger, T., An introduction to structural equation modeling (1998) Family Sci. Rev., 11, pp. 354-373; Russell, S., Dewey, D., Tegmark, M., Research priorities for robust and beneficial artificial intelligence (2015) AI Mag., 36 (4), pp. 105-114; Li, S., Sui, P.-C., Xiao, J., Chahine, R., Policy formulation for highly automated vehicles: Emerging importance, research frontiers and insights (2018) Transp. Res. Part A, Policy Pract., , May to be published},
document_type={Article},
source={Scopus},
}

@ARTICLE{Cervantes2020501,
author={Cervantes, J.-A. and López, S. and Rodríguez, L.-F. and Cervantes, S. and Cervantes, F. and Ramos, F.},
title={Artificial Moral Agents: A Survey of the Current Status},
journal={Science and Engineering Ethics},
year={2020},
volume={26},
number={2},
pages={501-532},
doi={10.1007/s11948-019-00151-x},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075200736&doi=10.1007%2fs11948-019-00151-x&partnerID=40&md5=99fe752fd03d7d4d10a6f7e8635b2f6b},
abstract={One of the objectives in the field of artificial intelligence for some decades has been the development of artificial agents capable of coexisting in harmony with people and other systems. The computing research community has made efforts to design artificial agents capable of doing tasks the way people do, tasks requiring cognitive mechanisms such as planning, decision-making, and learning. The application domains of such software agents are evident nowadays. Humans are experiencing the inclusion of artificial agents in their environment as unmanned vehicles, intelligent houses, and humanoid robots capable of caring for people. In this context, research in the field of machine ethics has become more than a hot topic. Machine ethics focuses on developing ethical mechanisms for artificial agents to be capable of engaging in moral behavior. However, there are still crucial challenges in the development of truly Artificial Moral Agents. This paper aims to show the current status of Artificial Moral Agents by analyzing models proposed over the past two decades. As a result of this review, a taxonomy to classify Artificial Moral Agents according to the strategies and criteria used to deal with ethical problems is proposed. The presented review aims to illustrate (1) the complexity of designing and developing ethical mechanisms for this type of agent, and (2) that there is a long way to go (from a technological perspective) before this type of artificial agent can replace human judgment in difficult, surprising or ambiguous moral situations. © 2019, Springer Nature B.V.},
author_keywords={Artificial agent;  Ethical agent;  Machine ethics;  Moral dilemma},
keywords={care behavior;  ethics;  human;  human experiment;  morality;  review;  robotics;  taxonomy},
references={Abbass, H.A., Petraki, E., Merrick, K., Harvey, J., Barlow, M., Trusted autonomy and cognitive cyber symbiosis: Open challenges (2016) Cognitive Computation, 8 (3), pp. 385-408; Alaieri, F., Vellino, A., Ethical decision making in robots: Autonomy, trust and responsibility (2016) International Conference on Social Robotics, pp. 159-168. , Cham, Springer; Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics and Information Technology, 7 (3), pp. 149-155; Amstutz, M.R., (2013) International ethics: Concepts, theories, and cases in global politics, , Rowman & Littlefield Publishers, New York; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-26; Anderson, M., Anderson, S.L., The status of machine ethics: A report from the AAAI symposium (2007) Minds and Machines, 17 (1), pp. 1-10; Anderson, M., Anderson, S.L., Ethical healthcare agents (2008) Advanced computational intelligence paradigms in healthcare-3, pp. 233-257. , Sordo M, Vaidya S, Jain LC, (eds), Springer, Berlin; Anderson, M., Anderson, S.L., Robot be good (2010) Scientific American, 303 (4), pp. 72-77; Anderson, M., Anderson, S.L., Geneth: A general ethical dilemma analyzer (2014) Twenty-Eighth AAAI Conference on Artificial Intelligence, pp. 253-261; Anderson, M., Anderson, S.L., Armen, C., Towards machine ethics (2004) . in Proceedings of the AOTP’04—The AAAI-04 Workshop on Agent Organizations: Theory and Practice.; Anderson, M., Anderson, S.L., Armen, C., Medethex: Toward a medical ethics advisor (2005) Proceedings of the AAAI 2005 Fall Symposium on Caring Machines: AI in Elder Care, pp. 9-16; Anderson, M., Anderson, S.L., Armen, C., An approach to computing ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 56-63; Anderson, M., Anderson, S.L., Armen, C., Medethex: A prototype medical ethics advisor (2006) Proceedings of the National Conference on Artificial Intelligence, 21 (2), pp. 1759-1765. , (b), Menlo Park, CA/Cambridge, MA, AAAI Press/MIT Press; Andino, C., Place of ethics between technical knowledge. A philosophical approach (2015) Revista Científica de la UCSA, 2 (2), pp. 85-94; Arkin, R., (2009) Governing lethal behavior in autonomous robots, , Chapman and Hall/CRC, London; Arkin, R.C., The case for ethical autonomy in unmanned systems (2010) Journal of Military Ethics, 9 (4), pp. 332-341; Arkin, R., Lethal autonomous systems and the plight of the noncombatant (2018) The political economy of robots, pp. 317-326. , Kiggins R, (ed), Springer, Cham; Arkoudas, K., Bringsjord, S., Bello, P., Toward ethical robots via mechanized deontic logic (2005) AAAI Fall Symposium on Machine Ethics, pp. 17-23; Ashrafian, H., Artificial intelligence and robot responsibilities: Innovating beyond rights (2015) Science and Engineering Ethics, 21 (2), pp. 317-326; Bandyopadhyay, D., Sen, J., Internet of things: Applications and challenges in technology and standardization (2011) Wireless Personal Communications, 58 (1), pp. 49-69; Batty, M., Axhausen, K.W., Giannotti, F., Pozdnoukhov, A., Bazzani, A., Wachowicz, M., Ouzounis, G., Portugali, Y., Smart cities of the future (2012) The European Physical Journal Special Topics, 214 (1), pp. 481-518; Beauvisage, T., Computer usage in daily life (2009) Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 575-584. , ACM; Bedaf, S., Draper, H., Gelderblom, G.J., Sorell, T., de Witte, L., Can a service robot which supports independent living of older people disobey a command? The views of older people, informal carers and professional caregivers on the acceptability of robots (2016) International Journal of Social Robotics, 8 (3), pp. 409-420; Belloni, A., Berger, A., Besson, V., Boissier, O., Bonnet, G., Bourgne, G., Towards a framework to deal with ethical conflicts in autonomous agents and multi-agent systems (2014) CEPE 2014 Well-Being, Flourishing, and Icts, pp. 1-10; Belloni, A., Berger, A., Boissier, O., Bonnet, G., Bourgne, G., Chardel, P.A., Dealing with ethical conflicts in autonomous agents and multi-agent systems (2015) 1St International Workshop on Artificial Intelligence and Ethics at the 29Th AAAI Conference on Artificial Intelligence; Blass, J.A., Interactive learning and analogical chaining for moral and commonsense reasoning (2016) Thirtieth AAAI Conference on Artificial Intelligence, pp. 4289-4290; Blass, J.A., Forbus, K.D., Moral decision-making by analogy: Generalizations versus exemplars (2015) Twenty-Ninth AAAI Conference on Artificial Intelligence, pp. 501-507; Bonnemains, V., Saurel, C., Tessier, C., Embedded ethics: Some technical and ethical challenges (2018) Ethics and Information Technology, 20 (1), pp. 41-58; Borenstein, J., Arkin, R., Robots, ethics, and intimacy: The need for scientific research (2019) On the cognitive, ethical, and scientific dimensions of artificial intelligence, pp. 299-309. , Berkich D, dAlfonso M, (eds), Springer, Cham; Borst, J.P., Anderson, J.R., Using the ACT-R cognitive architecture in combination with fMRI data (2015) An introduction to model-based cognitive neuroscience, pp. 339-352. , Forstmann B, Wagenmakers EJ, (eds), Springer, Berlin; Brachman, R.J., Systems that know what they’re doing (2002) IEEE Intelligent Systems, 17 (6), pp. 67-71; Briggs, G., Scheutz, M., (2015) Sorry, I can’t do that”: Developing mechanisms to appropriately reject directives in human–robot interactions; Bringsjord, S., Sundar, G.N., Thero, D., Si, M., Akratic robots and the computational logic thereof (2014) Proceedings of the IEEE 2014 International Symposium on Ethics in Engineering, Science, and Technology, pp. 1-8. , IEEE Press; Brundage, M., Limitations and risks of machine ethics (2014) Journal of Experimental & Theoretical Artificial Intelligence, 26 (3), pp. 355-372; Capraro, V., Rand, D.G., Do the right thing: Experimental evidence that preferences for moral behavior, rather than equity or efficiency per se, drive human prosociality (2018) Forthcoming in Judgment and Decision Making, 13 (1), pp. 99-111; Cervantes, J.A., Rodríguez, L.F., López, S., Ramos, F., Robles, F., Autonomous agents and ethical decision-making (2016) Cognitive Computation, 8 (2), pp. 278-296; Cervantes, J.A., Rosales, J.H., López, S., Ramos, F., Ramos, M., Integrating a cognitive computational model of planning and decision-making considering affective information (2017) Cognitive Systems Research, 44, pp. 10-39; Choi, D., Langley, P., Evolution of the icarus cognitive architecture (2018) Cognitive Systems Research, 48, pp. 25-38; Coeckelbergh, M., Moral appearances: Emotions, robots, and human morality (2010) Ethics and Information Technology, 12 (3), pp. 235-241; Conway, P., Gawronski, B., Deontological and utilitarian inclinations in moral decision making: A process dissociation approach (2013) Journal of Personality and Social Psychology, 104 (2), pp. 216-235; Cook, D.J., Das, S.K., Pervasive computing at scale: Transforming the state of the art (2012) Pervasive and Mobile Computing, 8 (1), pp. 22-35; Cristani, M., Burato, E., Approximate solutions of moral dilemmas in multiple agent system (2009) Knowledge and Information Systems, 18 (2), pp. 157-181; Czubenko, M., Kowalczuk, Z., Ordys, A., Autonomous driver based on an intelligent system of decision-making (2015) Cognitive Computation, 7 (5), pp. 569-581; Dehghani, M., Tomai, E., Forbus, K.D., Klenk, M., An integrated reasoning approach to moral decision-making (2008) Twenty-Third AAAI Conference on Artificial Intelligence, pp. 1280-1286; Deng, B., Machine ethics: The robot’s dilemma (2015) Nature, 523 (7558), pp. 24-26; Dennis, L.A., Fisher, M., Lincoln, N.K., Lisitsa, A., Veres, S.M., Practical verification of decision-making in agent-based autonomous systems (2016) Automated Software Engineering, 23 (3), pp. 305-359; Dennis, L., Fisher, M., Slavkovik, M., Webster, M., Formal verification of ethical choices in autonomous systems (2016) Robotics and Autonomous Systems, 77, pp. 1-14; Epting, S., A different trolley problem: The limits of environmental justice and the promise of complex moral assessments for transportation infrastructure (2016) Science and Engineering Ethics, 22 (6), pp. 1781-1795; Erdur, M., Moral realism and the incompletability of morality (2018) The Journal of Value Inquiry, 52 (2), pp. 227-237; Fagin, R., Halpern, J.Y., Vardi, M.Y., A nonstandard approach to the logical omniscience problem (1990) Proceedings of the 3Rd Conference on Theoretical Aspects of Reasoning about Knowledge, pp. 41-55. , Morgan Kaufmann Publishers Inc; Feil-Seifer, D., Matarić, M.J., Socially assistive robotics (2011) IEEE Robotics and Automation Magazine, 18 (1), pp. 24-31; Ferrell, O.C., Gresham, L.G., A contingency framework for understanding ethical decision making in marketing (1985) The Journal of Marketing, 49 (3), pp. 87-96; Fleetwood, J., Vaught, W., Feldman, D., Gracely, E., Kassutto, Z., Novack, D., Medethex online: A computer-based learning program in medical ethics and communication skills (2000) Teaching and Learning in Medicine, 12 (2), pp. 96-104; Fumagalli, M., Priori, A., Functional and clinical neuroanatomy of morality (2012) Brain, 135 (7), pp. 2006-2021; Gerdes, A., Øhrstrøm, P., Issues in robot ethics seen through the lens of a moral turing test (2015) Journal of Information, Communication and Ethics in Society, 13 (2), pp. 98-109; Gogoll, J., Müller, J.F., Autonomous cars: In favor of a mandatory ethics setting (2017) Science and Engineering Ethics, 23 (3), pp. 681-700; Govindarajulu, N.S., Bringjsord, S., Ghosh, R., (2018) One formalization of virtue ethics via learning; Greene, J.D., Morelli, S.A., Lowenberg, K., Nystrom, L.E., Cohen, J.D., Cognitive load selectively interferes with utilitarian moral judgment (2008) Cognition, 107 (3), pp. 1144-1154; Greene, J., Rossi, F., Tasioulas, J., Venable, K.B., Williams, B.C., Embedding ethical principles in collective decision support systems (2016) Thirtieth AAAI Conference on Artificial Intelligence, pp. 4147-4151; Greene, J.D., Sommerville, R.B., Nystrom, L.E., Darley, J.M., Cohen, J.D., An fMRI investigation of emotional engagement in moral judgment (2001) Science, 293 (5537), pp. 2105-2108; Guerini, M., Pianesi, F., Stock, O., Is it morally acceptable for a system to lie to persuade me? (2015) Workshops at the Twenty-Ninth AAAI Conference on Artificial Intelligence, pp. 53-60; Han, T.A., Pereira, L.M., Evolutionary machine ethics (2018) Handbuch Maschinenethik, pp. 1-25. , Bendel O, (ed), Springer, Wiesbaden; Hassabis, D., Kumaran, D., Summerfield, C., Botvinick, M., Neuroscience-inspired artificial intelligence (2017) Neuron, 95 (2), pp. 245-258; Honarvar, A.R., Ghasem-Aghaee, N., Casuist BDI-agent: A new extended BDI architecture with the capability of ethical reasoning (2009) International Conference on Artificial Intelligence and Computational Intelligence, pp. 86-95. , Berlin, Springer; Howard, D., Muntean, I., A minimalist model of the artificial autonomous moral agent (AAMA) (2016) The 2016 AAAI Spring Symposium Series, pp. 217-225; Hughes, G.J., (2001) Routledge philosophy guidebook to Aristotle on ethics, , Routledge, London; Kahn, Kanda, T., Jr., Ishiguro, H., Gill, B.T., Ruckert, J.H., Shen, S., Do people hold a humanoid robot morally accountable for the harm it causes? (2012) Proceedings of the Seventh Annual ACM/IEEE International Conference on Human–Robot Interaction, pp. 33-40. , ACM; Kirchin, S., (2012) What is Metaethics? In Metaethics, pp. 1-20. , London, Palgrave Macmillan; Kishi, T., Hashimoto, K., Takanishi, A., Human like face and head mechanism (2017) Humanoid robotics: A reference, pp. 1-26. , Goswami A, Vadakkepat P, (eds), Springer, Dordrecht; Kruglanski, A.W., Gigerenzer, G., Intuitive and deliberate judgments are based on common principles (2011) Psychological Review, 118 (1), pp. 97-109; Laird, J.E., Extending the soar cognitive architecture (2008) Frontiers in Artificial Intelligence and Applications, 171, pp. 224-235; Laird, J.E., Kinkade, K.R., Mohan, S., Xu, J.Z., Cognitive robotics using the soar cognitive architecture (2012) Workshops at the Twenty-Sixth AAAI Conference on Artificial Intelligence, pp. 46-54; Laird, J.E., Lebiere, C., Rosenbloom, P.S., A standard model of the mind: Toward a common computational framework across artificial intelligence, cognitive science, neuroscience, and robotics (2017) AI Magazine, 38 (4), pp. 13-26; Lombrozo, T., The role of moral commitments in moral judgment (2009) Cognitive Science, 33 (2), pp. 273-286; Long, L.N., Kelley, T.D., Review of consciousness and the possibility of conscious robots (2010) Journal of Aerospace Computing, Information, and Communication, 7 (2), pp. 68-84; Madl, T., Franklin, S., Constrained incrementalist moral decision making for a biologically inspired cognitive architecture (2015) A construction manual for robots’ ethical systems, pp. 137-153. , Trappl R, (ed), Springer, Cham; Malle, B.F., Integrating robot ethics and machine morality: The study and design of moral competence in robots (2016) Ethics and Information Technology, 18 (4), pp. 243-256; Malle, B.F., Scheutz, M., Arnold, T., Voiklis, J., Cusimano, C., Sacrifice one for the good of many? People apply different moral norms to human and robot agents (2015) Proceedings of the Tenth Annual ACM/IEEE International Conference on human–robot Interaction, pp. 117-124. , ACM; Mermet, B., Simon, G., Formal verification of ethical properties in multiagent systems (2016) In ECAI 2016 Workshop on Ethics in the Design of Intelligent Agents (EDIA’16), , The Netherlands, The Hague; Metta, G., Natale, L., Nori, F., Sandini, G., Vernon, D., Fadiga, L., Von Hofsten, C., Santos-Victor, J., The iCub humanoid robot: An open-systems platform for research in cognitive development (2010) Neural Networks, 23 (8), pp. 1125-1134; Mikhail, J., Universal moral grammar: Theory, evidence and the future (2007) Trends in Cognitive Sciences, 11 (4), pp. 143-152; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Mordoch, E., Osterreicher, A., Guse, L., Roger, K., Thompson, G., Use of social commitment robots in the care of elderly people with dementia: A literature review (2013) Maturitas, 74 (1), pp. 14-20; Mostafa, S.A., Ahmad, M.S., Mustapha, A., Adjustable autonomy: A systematic literature review (2019) Artificial Intelligence Review, 51 (2), pp. 149-186; Mostafa, S.A., Mustapha, A., Mohammed, M.A., Ahmad, M.S., Mahmoud, M.A., A fuzzy logic control in adjustable autonomy of a multi-agent system for an automated elderly movement monitoring application (2018) International Journal of Medical Informatics, 112, pp. 173-184; Pellizzoni, S., Siegal, M., Surian, L., The contact principle and utilitarian moral judgments in young children (2010) Developmental Science, 13 (2), pp. 265-270; Podschwadek, F., Do androids dream of normative endorsement? On the fallibility of artificial moral agents (2017) Artificial Intelligence and Law, 25 (3), pp. 325-339; Reig, S., Norman, S., Morales, C.G., Das, S., Steinfeld, A., Forlizzi, J., A field study of pedestrians and autonomous vehicles (2018) Proceedings of the 10Th International Conference on Automotive User Interfaces and Interactive Vehicular Applications, pp. 198-209. , ACM; Rodríguez, L.F., Ramos, F., Development of computational models of emotions for autonomous agents: A review (2014) Cognitive Computation, 6 (3), pp. 351-375; Schaich Borg, J., Hynes, C., Van Horn, J., Grafton, S., Sinnott-Armstrong, W., Consequences, action, and intention as factors in moral judgments: An fMRI investigation (2006) Journal of Cognitive Neuroscience, 18 (5), pp. 803-817; Scheutz, M., Malle, B.F., Think and do the right thing: A plea for morally competent autonomous robots (2014) Proceedings of the IEEE 2014 International Symposium on Ethics in Engineering, Science, and Technology, p. 9. , IEEE Press; Schroeder, M., Normative ethics and metaethics (2017) The Routledge handbook of metaethics, pp. 674-686. , McPherson T, Plunkett D, (eds), Routledge, London; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics and Information Technology, 14 (1), pp. 27-40; Shigemi, S., ASIMO and humanoid robot research at Honda (2018) Humanoid Robotics: A Reference (Pp. 1–36), , A. Goswami, P. Vadakkepat, Springer; Tikhanoff, V., Cangelosi, A., Metta, G., Integration of speech and action in humanoid robots: iCub simulation experiments (2011) IEEE Transactions on Autonomous Mental Development, 3 (1), pp. 17-29; Trafton, G., Hiatt, L., Harrison, A., Tamborello, F., Khemlani, S., Schultz, A., ACT-R/E: An embodied cognitive architecture for human–robot interaction (2013) Journal of Human–Robot Interaction, 2 (1), pp. 30-55; van Riemsdijk, M.B., Jonker, Lesser, C.M.V., Creating socially adaptive electronic partners: Interaction, reasoning and ethical challenges (2015) Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems, pp. 1201-1206. , International Foundation for Autonomous Agents and Multiagent Systems; Van Staveren, I., Beyond utilitarianism and deontology: Ethics in economics (2007) Review of Political Economy, 19 (1), pp. 21-35; Van Wynsberghe, A., Robbins, S., Critiquing the reasons for making artificial moral agents (2018) Science and Engineering Ethics, 25 (3), pp. 1-17; Vanderelst, D., Winfield, A., An architecture for ethical robots inspired by the simulation theory of cognition (2018) Cognitive Systems Research, 48, pp. 56-66; Vernon, D., Metta, G., Sandini, G., A survey of artificial cognitive systems: Implications for the autonomous development of mental capabilities in computational agents (2007) IEEE Transactions on Evolutionary Computation, 11 (2), pp. 151-180; Viroli, M., Pianini, D., Montagna, S., Stevenson, G., Pervasive ecosystems: A coordination model based on semantic chemistry (2012) Proceedings of the 27Th Annual ACM Symposium on Applied Computing, pp. 295-302. , ACM; Von der Pfordten, D., Five elements of normative ethics—A general theory of normative individualism (2012) Ethical Theory and Moral Practice, 15 (4), pp. 449-471; Von Wright, G.H., Deontic logic (1951) Mind, 60 (237), pp. 1-15; Waldrop, M.M., Autonomous vehicles: No drivers required (2015) Nature News, 518 (7537), p. 20; Walker, L.J., Hennig, K.H., Differing conceptions of moral exemplarity: Just, brave, and caring (2004) Journal of Personality and Social Psychology, 86 (4), pp. 629-647; Wallach, W., Implementing moral decision making faculties in computers and robots (2008) AI & Society, 22 (4), pp. 463-475; Wallach, W., Robot minds and human ethics: The need for a comprehensive model of moral decision making (2010) Ethics and Information Technology, 12 (3), pp. 243-250; Wallach, W., Allen, C., Smit, I., Machine morality: Bottom-up and top-down approaches for modelling human moral faculties (2008) AI & Society, 22 (4), pp. 565-582; Wallach, W., Franklin, S., Allen, C., A conceptual and computational model of moral decision making in human and artificial agents (2010) Topics in Cognitive Science, 2 (3), pp. 454-485; Wang, S., Wan, J., Zhang, D., Li, D., Zhang, C., Towards smart factory for industry 4.0: A self-organized multi-agent system with big data based feedback and coordination (2016) Computer Networks, 101, pp. 158-168; Wellman, M.P., Rajan, U., Ethical issues for autonomous trading agents (2017) Minds and Machines, 27 (4), pp. 609-624; Winfield, A.F., Blum, C., Liu, W., Towards an ethical robot: Internal models, consequences and ethical action selection (2014) Conference Towards Autonomous Robotic Systems, pp. 85-96. , Cham, Springer; Yampolskiy, R.V., Artificial intelligence safety engineering: Why machine ethics is a wrong approach (2013) Philosophy and theory of artificial intelligence, pp. 389-396. , Müller V, (ed), Springer, Berlin; Young, L., Durwin, A., Moral realism as moral motivation: The impact of meta-ethics on everyday decision-making (2013) Journal of Experimental Social Psychology, 49 (2), pp. 302-306; Zambonelli, F., Viroli, M., A survey on nature-inspired metaphors for pervasive service ecosystems (2011) International Journal of Pervasive Computing and Communications, 7 (3), pp. 186-204; Zieba, S., Polet, P., Vanderhaegen, F., Debernard, S., Principles of adjustable autonomy: A framework for resilient human–machine cooperation (2010) Cognition, Technology & Work, 12 (3), pp. 193-203},
document_type={Review},
source={Scopus},
}

@ARTICLE{vanWynsberghe202043,
author={van Wynsberghe, A. and Comes, T.},
title={Drones in humanitarian contexts, robot ethics, and the human–robot interaction},
journal={Ethics and Information Technology},
year={2020},
volume={22},
number={1},
pages={43-53},
doi={10.1007/s10676-019-09514-1},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076533010&doi=10.1007%2fs10676-019-09514-1&partnerID=40&md5=6e8a280954b5d8376d287e422f374922},
abstract={There are two dominant trends in the humanitarian care of 2019: the ‘technologizing of care’ and the centrality of the humanitarian principles. The concern, however, is that these two trends may conflict with one another. Faced with the growing use of drones in the humanitarian space there is need for ethical reflection to understand if this technology undermines humanitarian care. In the humanitarian space, few agree over the value of drone deployment; one school of thought believes drones can provide a utility serving those in need while another believes the large scale deployment of drones will exacerbate the already prevalent issues facing humanitarian aid providers. We suggest in this paper that the strength of the humanitarian principles approach to answer questions of aid provision can be complimented by a technology-facing approach, namely that of robot ethics. We have shown that for humanitarian actors we ought to be concerned with the risks of a loss of contextualization and de-skilling. For the beneficiary, we raise three concerns associated with the threat to the principle of humanity for this group: a loss of dignity by reducing human-to-human interactions; a threat to dignity through a lack of informational transparency; and, a threat to dignity by failing to account for the physiological and behavioral impacts of the drone on human actors. Although we acknowledge the obstacles (and dangers) associated with understanding the physiological and behavioral impacts we insist that the moral acceptability and desirability of drones in humanitarian contexts is dependent on the findings from such studies and that tailored ethical guidelines for drone deployment in humanitarian action be created to reflect the results of such studies. © 2019, The Author(s).},
author_keywords={Dignity;  Drones;  Humanitarian ethics;  Robot ethics;  Robots},
keywords={Drones;  Facings;  Philosophical aspects;  Physiology;  Robots, Contextualization;  Dignity;  Human actor;  Human-to-human interactions;  Humanitarian ethics;  Large-scale deployment;  Robot ethics;  Robot interactions, Human robot interaction},
references={Alvarez-de-los-Mozos, E., Renteria, A., Collaborative robots in e-waste management (2017) Procedia Manufacturing, 11, pp. 55-62; Anderson, M., Anderson, S.L., Robot be good: A call for ethical autonomous machines (2010) Scientific American, 303 (4), pp. 15-24; Arkin, R., (2009) Governing lethal behavior in autonomous robots, , CRC Press, Boca Raton; Bagshaw, S., (2012) OCHA on Message: Humanitarian Principles, p. 2. , http://www.unocha.org/sites/dms/Documents/OOM-humanitarianprinciples_eng_June12.pdf, Retrieved from, Accessed 13 Oct 2019; Bouvier, P., (2012) Humanitarian Care and Small Things in Dehumanised Places. International Committee of the Red Cross, 888. , https://www.icrc.org/en/doc/resources/documents/red-cross-crescent-movement/fundamental-principles-movement-1986-10-31.htm.Accessed13Oct2019, Retrieved from; Calo, M.R., The drone as a privacy catalyst (2011) Stanford Law Review Online, 64, p. 29; Capurro, R., (2009) Ethics and Robotics, pp. 117-123. , Capurro Rafael, Nagenborg Michael, (eds), AKA; IOS Press, Heidelberg [Amsterdam]; Auston, C.-F., Drones for good: Technological innovations, social movements, and the State (2014) Journal of International Affairs, (1), p. 68. , https://search.proquest.com/openview/468bc87b04291e1f45ff0f60f9edf97b/1?pq-origsite=gscholar&cbl=41938, Retrieved from, Accessed 13 Oct 2019; Choi-Fitzpatrick, A., Chavarria, D., Cychosz, E., Dingens, J.P., Duffey, M., Koebel, K., Almquist, L., (2016) Up in the Air: A Global Estimate of Non-Violent Drone Use 2009–2015, , http://digital.sandiego.edu/gdl2016report/1, Retrieved from Universtiy of San Diego website, Accessed October 13, 2019; Clarke, R., The regulation of civilian drones’ impacts on behavioural privacy (2014) Computer Law & Security Review, 30 (3), pp. 286-305; Collinson, S., Elhawary, S., (2012) Humanitarian Space: Trends and Issues, , ALNAP; Comes, T., Cognitive and motivational biases in humanitarian sensemaking and decision-making (2016) IEEE, pp. 56-62; Comes, T., Designing for networked community resilience (2016) Procedia Engineering, 159, pp. 6-11; Comes, T., Adrot, A., (2016) Power as Driver of Inter-Organizational Information Sharing in Crises, , In ISCRAM; Ditmer, M.A., Vincent, J.B., Werden, L.K., Tanner, J.C., Laske, T.G., Iaizzo, P.A., Fieberg, J.R., Bears show a physiological but limited behavioral response to unmanned aerial vehicles (2015) Current Biology, 25 (17), pp. 2278-2283; Donini, A., Maxwell, D., From face-to-face to face-to-screen: Remote management, effectiveness and accountability of humanitarian action in insecure environments (2014) International Review of the Red Cross, 95 (890), pp. 383-413; Custers, B., (2016) The Future of Drone Use—Opportunities and Threats from Ethical and Legal Perspectives—Asser.nl, , http://www.asser.nl/asserpress/books/?rId=12851, Dr, Retrieved from, Accessed 13 Oct 2019; Elisabeth, V., Amélie, L., Olivier, D., Guillaume, B., David, G., Approaching birds with drones: First experiments and ethical guidelines (2015) Biology Letters, 11 (2), p. 20140754; Gilman, D., Easton, M., (2014) Unmanned Aerial Vehicles in Humanitarian Response (, , https://docs.unocha.org/sites/dms/Documents/Unmanned%20Aerial%20Vehicles%20in%20Humanitarian%20Response%20OCHA%20July%202014.pdf, Occational Policy Paper No. 010). Retrieved from United Nations Office for the Coordination of Humanitarian Affairs website:, Accessed 13 Oct 2019; Haidari, L.A., Brown, S.T., Ferguson, M., Bancroft, E., Spiker, M., Wilcox, A., Lee, B.Y., The economic and operational value of using drones to transport vaccines (2016) Vaccine, 34 (34), pp. 4062-4067; Hevelke, A., Nida-Rümelin, J., Responsibility for crashes of autonomous vehicles: An ethical analysis (2015) Science and Engineering Ethics, 21 (3), pp. 619-630; Hodgson, J.C., Koh, L.P., Best practice for minimising unmanned aerial vehicle disturbance to wildlife in biological field research (2016) Current Biology, 26 (10), pp. R404-R405; Chow, J., (2012) The Case for Humanitarian Drones. Opencanada, , https://www.opencanada.org/features/the-case-for-humanitarian-drones/, Retrieved Dec 12, 2012, from, Accessed 13 Oct 2019; Karlsrud, J., Rosén, F., In the eye of the beholder? UN and the use of drones to protect civilians (2013) Stability: International Journal of Security and Development; Lichtman, A., Nair, M., Humanitarian uses of drones and satellite imagery analysis: The promises and perils (2015) AMA Journal of Ethics, 17 (10), p. 931; Lin, P., Why ethics matters for autonomous cars (2016) Autonomous Driving; Lin, P., Abney, K., Bekey, G.A., (2011) Robot ethics: The ethical and social implications of robotics, , MIT Press, Cambridge; Lin, P., Abney, K., Jenkins, R., (2017) Robot ethics 2.0: From autonomous cars to artificial intelligence, , (eds), Oxford University Press, Oxford, New York; Lokhorst, G.-J., van den Hoven, J., Responsibility for military robots (2011) Robot ethics: The ethical and social implications of robotics, pp. 145-155. , Lin P, Abney K, Bekey GA, (eds), MIT Press, Cambridge; Juul, M., (2015) Civil drones in the European Union, , http://www.europarl.europa.eu/RegData/etudes/BRIE/2015/571305/EPRS_BRI(2015)571305_EN.pdf, (Members’ Research Service No. PE 571.305). Retrieved from European Parliamentary Research Service website:, Accessed 13 Oct 2019; Meier, P., Next generation humanitarian computing (2014) In Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work & Social Computing; Momont, A., (2014), https://repository.tudelft.nl/islandora/object/uuid:36ce77ad-1b06-4149-8da4-a231dcdfec69?collection=education, Drones for Good. Retrieved from, Accessed 13 Oct 2019; Moor, J.H., Machine ethics—The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), p. 18; Raymond, N.B., Cardachkar, Z.A., (2012) The Case against Humanitarian Drones. Opencanada, , https://www.opencanada.org/features/the-case-against-humanitarian-drones/, Retrieved from, Accessed 13 Oct 2019; Murphy, R., (2014) Disaster Robotics, , https://mitpress.mit.edu/books/disaster-robotics, Retrieved from, Accessed 13 Oct 2019; Rümmler, M.-C., Mustafa, O., Maercker, J., Peter, H.-U., Esefeld, J., Measuring the influence of unmanned aerial vehicles on Adélie penguins (2016) Polar Biology, 39 (7), pp. 1329-1334; Salvadó, L.L., Lauras, M., Comes, T., van De Walle, B., Towards more relevant research on humanitarian disaster management coordination (2015) ISCRAM.; Sandvik, K.B., Jumbert, M.G., (2016) The good drone, , Taylor & Francis, London; Sandvik, K.B., Lohne, K., The rise of the humanitarian drone: Giving content to an emerging concept (2014) Millennium: Journal of International Studies, 43 (1), pp. 145-164; Sandvik, K., Raymond, N., Beyond the protective effect (2017) Genocide Studies and Prevention: An International Journal, 11 (1), pp. 9-24; Schlag, C., The new privacy battle: How the expanding use of drones continues to erode our concept of privacy and privacy rights (2012) Pittsburgh Journal of Technology Law and Policy; Sharkey, N., The ethical frontiers of robotics (2008) Science, 322 (5909), pp. 1800-1801; Sharkey, N., Saying ‘No!’ to lethal autonomous targeting (2010) Journal of Military Ethics, 9 (4), pp. 369-383; Sharkey, A., Robots and human dignity: A consideration of the effects of robot care on the dignity of older people (2014) Ethics and Information Technology, 16 (1), pp. 63-75; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics and Information Technology, 14 (1), pp. 27-40; Singer, P.W., (2009) Wired for war: The robotics revolution and conflict in the twenty-first century, , Penguin Press, New York; Slim, H., (2015) Humanitarian ethics: A guide to the morality of aid in war and disaster, , Oxford University Press, Oxford; Soesilo, D., Meier, P., Lessard-Fontaine, A., Plessis, J.D., Stuhlberger, C., Fabbroni, V., (2016) Drones in Humanitarian Action » Drones in Humanitarian Action, , http://drones.fsd.ch/en/drones-in-humanitarian-action/, Retrieved from Swiss Foundation for Mine Action website, Accessed 13 Oct 2019; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Minds and Machines, 16 (2), pp. 141-161; Sullins, J., (2011) Machine ethics, , Anderson Michael, Anderson SL, (eds), Cambridge University Press, Cambridge; Thomasen, K., Beyond airspace safety: A feminist perspective on drone privacy regulation (2018) Canadian Journal of Law and Technology, 16 (2), pp. 1-21; Vallor, S., Carebots and caregivers: Sustaining the ethical ideal of care in the twenty-first century (2011) Philosophy and Technology, 24 (3), pp. 251-268; Vallor, S., Moral deskilling and upskilling in a new machine age: Reflections on the ambiguous future of character (2015) Philosophy & Technology, 28 (1), pp. 107-124; van Wynsberghe, A., (2015) Healthcare robots: Ethics, design and implementation, , Ashgate Publishing Ltd, Farnham; Wynsberghe, Soesilo, A., Thomasen, D., Sharkey, K.N., (2018) Drones in the Service of Society, , https://responsiblerobotics.org/2018/06/05/report-drones-in-the-service-of-society/, Retrieved from Foundation for Responsible Robotics website, Accessed 13 Oct 2019; Veruggio, G., Abney, K., Roboethics: The applied ethics for a new science (2011) Robot ethics: The ethical and social implications of robotics, pp. 347-364. , Lin P, Abney K, Bekey GA, (eds), MIT Press, Cambridge},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bauer2020263,
author={Bauer, W.A.},
title={Virtuous vs. utilitarian artificial moral agents},
journal={AI and Society},
year={2020},
volume={35},
number={1},
pages={263-271},
doi={10.1007/s00146-018-0871-3},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058244330&doi=10.1007%2fs00146-018-0871-3&partnerID=40&md5=8b045f4e5943275485b98f1a87dfd1cb},
abstract={Given that artificial moral agents—such as autonomous vehicles, lethal autonomous weapons, and automated trading systems—are now part of the socio-ethical equation, we should morally evaluate their behavior. How should artificial moral agents make decisions? Is one moral theory better suited than others for machine ethics? After briefly overviewing the dominant ethical approaches for building morality into machines, this paper discusses a recent proposal, put forward by Don Howard and Ioan Muntean (2016, 2017), for an artificial moral agent based on virtue theory. While the virtuous artificial moral agent has various strengths, this paper argues that a rule-based utilitarian approach (in contrast to a strict act utilitarian approach) is superior, because it can capture the most important features of the virtue-theoretic approach while realizing additional significant benefits. Specifically, a two-level utilitarian artificial moral agent incorporating both established moral rules and a utility calculator is especially well suited for machine ethics. © 2018, Springer-Verlag London Ltd., part of Springer Nature.},
author_keywords={Artificial moral agent;  Machine ethics;  Machine learning;  Two-level utilitarianism;  Virtue theory},
keywords={Learning systems;  Philosophical aspects, Automated trading systems;  Important features;  Moral agents;  Moral theory;  Rule based;  Two-level utilitarianism;  Virtue theory, Autonomous agents},
references={Anderson, S.L., Anderson, M., (2011) A Prima Facie Duty Approach to Machine Ethics and Its Application to Elder Care, pp. 2-7. , American Association for Artificial Intelligence, Menlo Park; Anderson, M., Anderson, S.L., Armen, C., (2004) Towards Machine Ethics: Implementing Two Action-Based Ethical Theories, , American Association for Artificial Intelligence, Menlo Park; Anderson, M., Anderson, S.L., Armen, C., (2006) MedEthEx: a prototype medical ethics advisor, pp. 1759-1765. , American Association for Artificial Intelligence, Menlo Park; The Internet Classics Archive, , http://classics.mit.edu/Aristotle/nicomachaen.html, Ross WD (trans), Accessed 7 Oct 2018; Bentham, J., An Introduction to the Principles of Morals and Legislation (1789) The Collected Works of Jeremy Bentham: An Introduction to the Principles of Morals and Legislation, , Burns J. H., Hart H. L. A., (eds; Bringsjord, S., Konstantine, A., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intell Syst, 21 (4), pp. 38-44; Doyle, J., What is rational psychology? Toward a modern mental philosophy (1983) AI Mag, 4 (3), pp. 50-53; Floridi, L., (2013) The ethics of information, , Oxford University Press, New York; Foot, P., The problem of abortion and the doctrine of double effect (1967) Oxf Rev, 5, pp. 5-15; Grau, C., There is no “I” in “robot”: robots and utilitarianism (2006) IEEE Intell Syst, 21 (4), pp. 52-55; Hare, R.M., (1983) Moral thinking: its levels, method, and point, , Oxford University Press, New York; Hooker, B., (2000) Ideal code, real world, , Oxford University Press, New York; Howard, D., Muntean, I., (2016) A minimalist model of the artificial autonomous moral agent (AAMA), , Association for the Advancement of Artificial Intelligence, Menlo Park; Howard, D., Muntean, I., Artificial moral cognition: moral functionalism and autonomous moral agency (2017) Philosophy and computing, 128, pp. 121-160. , Powers TM, (ed), Philosophical studies series, Springer, New York; Jackson, F., (1998) From metaphysics to ethics: a defence of conceptual analysis, , Oxford University Press, New York; Kahneman, D., (2011) Thinking, fast and slow, , Farrar, Straus, and Giroux, New York; Kant, I., (1785) Groundwork for the Metaphysics of Morals, , http://www.earlymoderntexts.com, (in the version by J. Bennett presented at; Leben, D., A Rawlsian algorithm for autonomous vehicles (2017) Ethics Inf Technol, 19, pp. 107-115; Mill, J.S., (1861), http://www.earlymoderntexts.com, Utilitarianism (in the version by Jonathan Bennett presented at; Nathanson, S., Act and rule utilitarianism (2018) Internet Encyclopedia of Philosophy, , http://www.iep.utm.edu/util-a-r/, Accessed 7 Oct 2018; Powers, T.M., Prospects for a Kantian machine (2006) IEEE Intell Syst, 21 (4), pp. 46-51; Rawls, J., (1971) A theory of justice, , Belknap (Harvard University Press), Cambridge; Ross, W.D., (1930) The right and the good, , Oxford University Press, New York; Singer, P., (2011) The expanding circle: ethics, evolution, and moral progress, , Princeton University Press, Princeton: (revised edition; original published 1981; Varner, G., (2012) Personhood, ethics, and animal cognition: situating animals in Hare’s two level utilitarianism, , Oxford University Press, New York; Wallach, W., Allen, C., (2009) Moral machines: teaching robots right from wrong, , Oxford University Press, New York},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gordon2020209,
author={Gordon, J.-S.},
title={What do we owe to intelligent robots?},
journal={AI and Society},
year={2020},
volume={35},
number={1},
pages={209-223},
doi={10.1007/s00146-018-0844-6},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046035358&doi=10.1007%2fs00146-018-0844-6&partnerID=40&md5=7f209ac04a7e3aeb73840fb78d11cf32},
abstract={Great technological advances in such areas as computer science, artificial intelligence, and robotics have brought the advent of artificially intelligent robots within our reach within the next century. Against this background, the interdisciplinary field of machine ethics is concerned with the vital issue of making robots “ethical” and examining the moral status of autonomous robots that are capable of moral reasoning and decision-making. The existence of such robots will deeply reshape our socio-political life. This paper focuses on whether such highly advanced yet artificially intelligent beings will deserve moral protection (in the form of being granted moral rights) once they become capable of moral reasoning and decision-making. I argue that we are obligated to grant them moral rights once they have become full ethical agents, i.e., subjects of morality. I present four related arguments in support of this claim and thereafter examine four main objections to the idea of ascribing moral rights to artificial intelligent robots. © 2018, Springer-Verlag London Ltd., part of Springer Nature.},
author_keywords={Artificially intelligent robots;  Full ethical agents;  Machine rights;  Moral agency;  Moral rights;  Moral status},
keywords={Artificial intelligence;  Behavioral research;  Decision making;  Philosophical aspects, Artificial intelligent;  Interdisciplinary fields;  Moral agency;  Moral reasoning;  Moral right;  Moral status;  Technological advances, Intelligent robots},
references={Allen, C., Wallach, W., Smit, I., Why machine ethics? (2011) Machine ethics, pp. 51-61. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Altman, M.C., (2011) Kant and applied ethics: the uses and limits of kant’s practical philosophy, , Wiley-Blackwell, New Jersey; Anderson, S.L., The unacceptability of Asimov’s three laws of robotics as a basis for machine ethics (2011) Machine ethics, pp. 285-296. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Anderson, S.L., Machine metaethics (2011) Machine ethics, pp. 21-27. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Anderson, M., Anderson, S.L., (2011) Machine ethics, , Cambridge University Press, Cambridge; Asimov, I., (1942) Runaround. A short story, , Street and Smith Publications, New York; Asimov, I., (1986) Robots and empire. The classic robot novel, , HarperCollins, New York; Atapattu, S., (2015) Human rights approaches to climate change: challenges and opportunities, , Routledge, New York; Bringsjord, S., Ethical robots: the future can heed us (2008) AI Soc, 22 (4), pp. 539-550; Bryson, J., Robots should be slaves (2010) Close engagements with artificial companions: key social, psychological, ethical and design issues, pp. 63-74. , Wilks Yorick, (ed), John Benjamins, Amsterdam; Calverley, D.J., Legal rights for machines (2011) Machine ethics, pp. 213-227. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Čapek, K., (1920) Rossum’s universal robots, , The University of Adelaide, Adelaide; Clark, R., Asimov’s laws of robotics: implications for information technology (2011) Machine ethics, pp. 254-284. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Cochrane, A., Undignified bioethics (2010) Bioethics, 24 (5), pp. 234-241; Coeckelbergh, M., The moral standing of machines: towards a relational and non-cartesian moral hermeneutics (2014) Philos Technol, 27 (1), pp. 61-77; Darling, K., Extending legal protection to social robots: the effects of anthropomorphism, empathy, and violent behavior towards robotic objects (2016) Robot law, pp. 213-231. , Calo R, Michael Froomkin A, Kerr I, (eds), Edward Elgar, Northampton; Davenport, D., Moral mechanisms (2014) Philos Technol, 27 (1), pp. 47-60; Dehghani, M., Forbus, K., Tomai, E., Klenk, M., An integrated reasoning approach to moral decision making (2011) Machine ethics, pp. 422-441. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Delvaux, M., (2017) Report with Recommendations to the Commission on Civil Law Rules on Robotics, , 2015/2103, INL; Dennett, D., When hal kills, Who’s to blame? Computer ethics (1998) Hal’s Legacy: 2001’s computer as dream and reality, pp. 351-365. , Stork D, (ed), The MIT Press, Massachusetts; Donaldson, S., Kymlicka, W., (2013) Zoopolis. A political theory of animal rights, , Oxford University Press, Oxford; Döring, S.A., Mayer, V., (2002) Die Moralität der Gefühle. In: Deutsche Zeitschrift für Philosophie, 4. , (eds), Akademie-Verlag, Berlin; Floridi, L., On the morality of artificial agents (2011) Machine ethics, pp. 184-212. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Mind Mach, 14 (3), pp. 349-379; Francione, G.L., (2009) Animals as persons: essays on the abolition of animal exploitation, , Columbia University Press, New York; Frankfurt, H., Alternate possibilities and moral responsibility (1969) J Philos, 66 (23), pp. 829-839; Frankfurt, H., Freedom of the will and the concept of the person (1971) J Philos, 68 (1), pp. 5-20; Gibilisco, S., (2003) Concise encyclopedia of robotics, , McGraw-Hill, New York; Gordon, J.S., Modern morality and ancient ethics (2013) Internet Encyclopedia of Philosophy, , http://www.iep.utm.edu/anci-mod/, Published online 2013; Gordon, J.S., Human dignity, human rights, and global bioethics (2014) Global bioethics and human rights: contemporary issues., pp. 68-91. , Teays W, Renteln A, (eds), Rowman & Littlefield, Lanham; Gordon, J.S., Human rights (2016) Oxford Bibliographies in Philosophy, , http://www.oxfordbibliographies.com/view/document/obo-9780195396577/obo-9780195396577-0239.xml?rskey=z2W9vS&result=47&q=, edited by Duncan Pritchard, published online 2016; Gordon, J.S., Remarks on a disability-conscious bioethics (2017) Human rights and disability. interdisciplinary perspectives, pp. 9-20. , Gordon JS, Pöder JC, Burckhart H, (eds), Routledge, London; Grau, C., There is no ‘I’ in ‘Robot’: robots and utilitarianism (2011) Machine Ethics, pp. 451-463. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Guarini, M., Particularism and the classification and reclassification of moral cases (2006) IEEE Intell Syst, 21 (4), pp. 22-28; Gunkel, D.J., (2012) The machine question: critical perspectives on AI, robots, and ethics, , MIT Press, Cambridge; Gunkel, D.J., A vindication of the rights of machines (2014) Philos Technol, 27 (1), pp. 113-132; Gunkel, D.J., Bryson, J., Introduction to the special issue on machine morality: the machine as moral agent and patient (2014) Philos Technol, 27 (1), pp. 5-8; Gunkel, D.J., Bryson, J., The machine as moral agent and patient (2014) Philos Technol, 27 (1), pp. 5-142; Hall, J.S., Ethics for self-improving machines (2011) Machine ethics, pp. 512-523. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Hanna, R., Thompson, E., The mind-body-body problem (2003) Theoria Et Historia Scientiarum, 7, pp. 24-44; Hernández-Orallo, J., (2017) The measure of all minds: evaluating natural and artificial intelligence, , Cambridge University Press, Cambridge; Johnson, D.G., Computer systems: moral entities but not moral agents (2011) Machine ethics, pp. 168-183. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Johnson, A.M., Axinn, S., Acting vs. Being Moral: The Limits of Technological Moral Actors (2014) Proceedings of the IEEE 2014 International Symposium on Ethics in Engineering, Science, and Technology, 30, pp. 1-4. , ETHICS’14. Piscataway, NJ, USA: IEEE Press; Kane, R., (2002) The Oxford handbook of free will, , (ed), Oxford University Press, Oxford; Kant, I., (2009) Groundwork of the metaphysic of morals, , Harper Perennial Modern Classics, New York; Knapton, S., (2017) Alphago Zero: Google Deepmind Supercomputer Learns 3,000 Years of Human Knowledge in 40 Days, , https://www.telegraph.co.uk/science/2017/10/18/alphago-zero-google-deepmind-supercomputer-learns-3000-years/, Accessed 27 March 2018; Koch, T., The difference that difference makes: bioethics and the challenge of ‘disability’ (2004) J Med Philos, 29 (6), pp. 697-716; Levy, D., (2007) Love and sex with robots: the evolution of human-robot relationships, , Harper, New York; Lin, P., Abney, K., Bekey, G.A., (2014) Robot ethics: the ethical and social implications of robotics. Intelligent robotics and autonomous agents, , (eds), The MIT Press, Cambridge; Macklin, R., Dignity is a useless concept (2003) BMJ Br Med J, 327 (7429), pp. 1419-1420; Meyer, M., The simple dignity of sentient life: speciesism and human dignity (2001) J Soc Philos, 32 (2), pp. 115-126; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) Res Gate, 21 (4), pp. 18-21; Nadeau, J.E., Only androids can be ethical (2006) Thinking about android epistemology, pp. 241-248. , Ford K, Glymour C, (eds), MIT Press, Cambridge; Nussbaum, M., (2006) Frontiers of justice. disability, nationality, species membership, , The Belknap Press of the Harvard University Press, Cambridge; Picard, R., (1997) Affective computing, , The MIT Press, Cambridge; Pothast, U., Seminar, Freies Handeln Und Determinismus (1978) Suhrkamp, Suhrkamp Taschenbuch Wissenschaft, 257. , 1. Aufl, Frankfurt am Main; Rodogno, R., Robots and the Limits of Morality (2016) Social Robots. Boundaries, Potential, Challenges, Routledge, , http://pure.au.dk/portal/files/90856828/Robots_and_the_Limits_of_Morality.pdf, Norskov M, Accessed 03 Dec 2016; Rzepka, R., Araki, K., What statistics could do for ethics? The idea of common sense processing based safety valve (2005) AAAI Fall Symposium on Machine Ethics, pp. 85-87. , Technical Report FS-05-06; Searle, J., Minds, brains and computers (1980) Behav Brain Sci, 3 (3), pp. 417-457; Searle, J., (1994) The rediscovery of mind, , The MIT Press, Cambridge; Silver, D., Mastering the game of Go without human knowledge (2017) Nature, 550, pp. 354-359; Singer, P., (1975) Animal liberation, , Avon Books, London; Singer, P., (1979) Practical ethics, , Cambridge University Press, Cambridge; Singer, P., Speciesism and moral status (2009) Metaphilosophy, 40 (3-4), pp. 567-581; Singer, P., (2011) The Expanding Circle: Ethics, Evolution, and Moral Progress. 1st Princeton University Press pbk, , Princeton University Press, Princeton; Sullins, J.P., When is a robot a moral agent? (2011) Machine ethics, pp. 151-161. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Torrance, S., A robust view of machine ethics (2005) Technical Report—Machine Ethics: Papers from the AAAI Fall Symposium, FS-D5-06, pp. 88-93. , American Association of Artificial Intelligence, Menlo Park; Turkle, S., Authenticity in the age of digital companions (2011) Machine ethics, pp. 62-76. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; (2016) Preliminary Draft Report of COMEST on Robotics Ethics, (3), pp. 1-31. , http://unesdoc.unesco.org/images/0024/002455/245532E.pdf, SHS/YES/COMEST-9EXT/16, Accessed 03 Dec 2016; Wallach, W., Allen, C., (2010) Moral machines: teaching robots right from wrong, , Oxford University Press, Oxford; Warren, M., On the moral and legal status of abortion (1973) Monist, 57 (1), pp. 43-61; Watson, G., Free will (2003) Oxford Readings in Philosophy, , Oxford University Press, Oxford; Whitby, B., On computable morality: an examination of machines as moral advisors (2011) Machine ethics, pp. 138-150. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Ziff, P., The feelings of robots (1959) Analysis, 19 (3), pp. 64-68; Zuolo, F., Dignity and animals. Does it make sense to apply the concept of dignity to all sentient beings? (2016) Ethical Theor Moral Pract, 19 (5), pp. 1117-1130},
document_type={Article},
source={Scopus},
}

@ARTICLE{Nath2020103,
author={Nath, R. and Sahu, V.},
title={The problem of machine ethics in artificial intelligence},
journal={AI and Society},
year={2020},
volume={35},
number={1},
pages={103-111},
doi={10.1007/s00146-017-0768-6},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031784550&doi=10.1007%2fs00146-017-0768-6&partnerID=40&md5=0b561c3a2ad7e511772407fbb8bf5073},
abstract={The advent of the intelligent robot has occupied a significant position in society over the past decades and has given rise to new issues in society. As we know, the primary aim of artificial intelligence or robotic research is not only to develop advanced programs to solve our problems but also to reproduce mental qualities in machines. The critical claim of artificial intelligence (AI) advocates is that there is no distinction between mind and machines and thus they argue that there are possibilities for machine ethics, just as human ethics. Unlike computer ethics, which has traditionally focused on ethical issues surrounding human use of machines, AI or machine ethics is concerned with the behaviour of machines towards human users and perhaps other machines as well, and the ethicality of these interactions. The ultimate goal of machine ethics, according to the AI scientists, is to create a machine that itself follows an ideal ethical principle or a set of principles; that is to say, it is guided by this principle or these principles in decisions it makes about possible courses of action it could takea. Thus, machine ethics task of ensuring ethical behaviour of an artificial agent. Although, there are many philosophical issues related to artificial intelligence, but our attempt in this paper is to discuss, first, whether ethics is the sort of thing that can be computed. Second, if we are ascribing mind to machines, it gives rise to ethical issues regarding machines. And if we are not drawing the difference between mind and machines, we are not only redefining specifically human mind but also the society as a whole. Having a mind is, among other things, having the capacity to make voluntary decisions and actions. The notion of mind is central to our ethical thinking, and this is because the human mind is self-conscious, and this is a property that machines lack, as yet. © 2017, Springer-Verlag London Ltd.},
author_keywords={Artificial intelligence;  Artificial moral agent;  Mind;  Moral agency;  Subjectivity},
keywords={Artificial intelligence;  Human computer interaction;  Intelligent robots, Artificial agents;  Computer ethics;  Ethical issues;  Ethical principles;  Mind;  Moral agency;  Moral agents;  Subjectivity, Philosophical aspects},
references={Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) J Exp Theor Artif Intell, 12 (3), pp. 251-261; Anderson, M., Anderson, S.L., Machine ethics: creating an ethical intelligent agent (2007) AI Mag, 28 (4), pp. 15-26; Beavers, A.F., Between angels and animals: The question of robot ethics, or is Kantian moral agency desirable (2009) Association for Practical and Professional Ethics. Eighteenth Annual Meeting, , http://faculty.evansville.edu/tb2/PDFs/Robot%20Ethics%20-%20APPE.pdf, Cincinnati, Ohio, March 5–8, Retrieved on 1 Oct 2017; Chalmers, D.J., (1996) The Conscious Mind, , Oxford and New York: Oxford; DeBaets, A.M., Can a robot pursue the good? Exploring artificial moral agency (2014) J Evolut Technol, 24 (3), pp. 76-86; Gunkel, D.J., (2012) The machine question: critical perspectives on AI, robots, and ethics, , MIT Press, Cambridge; Haugeland, J., (1989) Artificial intelligence: the very idea, , The MIT Press, Cambridge; Kant, I., (1993) Grounding for the metaphysics of morals, , [1785],. Translated by Ellington, James W (3rd Edn), Hackett; LaChat, M.R., Artificial intelligence and ethics: an exercise in the moral imagination (1986) AI Magz, 7 (2), pp. 70-79; Lycan, W.G., (1987) Consciousness, , The MIT Press, Massachusetts; McCorduck, P., (1979) Machines who thinks, , W.H. Freeman and Company, San Francisco; McGinn, C., Can we solve the mind–body problem? (1997) The Nature of Consciousness, , Ned B, Owen F, Güven G, The MIT Press, Cambridge; Moor, J.H., The nature, importance and difficulty of machine ethics (2006) IEEE Intell Syst, 21 (4), pp. 18-21; Nagel, T., What it is like to be a bat (1998) The Nature of Consciousness, , Ned B, Owen F, Güven G, The MIT Press, Cambridge, MA; Nath, R., (2009) Philosophy of artificial intelligence. A critique of the mechanistic theory of mind, , The Universal Publishers, Boca Raton; Nath, R., Can naturalism explain consciousness: a critique (2016) Artif Intell Soc J Knowl Cult Commun; Searle, J.R., Minds and brains without programs (1987) Mindwaves: Thoughts on Intelligence, Identity, and Consciousness, , Blakemore C, Greenfield S, Bail Blackwell, Oxford; Searle, J.R., Is the brain a digital computer? (1990) Proc Address Am Philos Assoc, 64 (3), pp. 21-37; Searle, J.R., (1994) The rediscovery of the mind, , Harvard University Press, Cambridge; Searle, J.R., (1996) Minds, brains and science, , Harvard University Press, Cambridge; Simon, H.A., Guest foreword (1987) Encyclopedia of Artificial Intelligence, 1. , Stuart CS, Wiley, New York; Tanimoto, S.L., (1987) The elements of artificial intelligence, , Computer Science Press Inc, Maryland; Turing, A.M., Computing machinery and intelligence (1950) Mind, 49, pp. 433-460; Winston, P.H., (1984) Artificial intelligence, , Addison-Wesley Publishing Company, London; Wittgenstein, L., (1976) Philosophical investigations, , Anscombe GEM (translated), Basil Blackwell, Oxford},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gamez2020,
author={Gamez, P. and Shank, D.B. and Arnold, C. and North, M.},
title={Artificial virtue: the machine question and perceptions of moral character in artificial moral agents},
journal={AI and Society},
year={2020},
doi={10.1007/s00146-020-00977-1},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084154151&doi=10.1007%2fs00146-020-00977-1&partnerID=40&md5=c260902fb4c88a776b7d369dbdc9b007},
abstract={Virtue ethics seems to be a promising moral theory for understanding and interpreting the development and behavior of artificial moral agents. Virtuous artificial agents would blur traditional distinctions between different sorts of moral machines and could make a claim to membership in the moral community. Accordingly, we investigate the “machine question” by studying whether virtue or vice can be attributed to artificial intelligence; that is, are people willing to judge machines as possessing moral character? An experiment describes situations where either human or AI agents engage in virtuous or vicious behavior and experiment participants then judge their level of virtue or vice. The scenarios represent different virtue ethics domains of truth, justice, fear, wealth, and honor. Quantitative and qualitative analyses show that moral attributions are weakened for AIs compared to humans, and the reasoning and explanations for the attributions are varied and more complex. On “relational” views of membership in the moral community, virtuous machines would indeed be included, even if they are indeed weakened. Hence, while our moral relationships with artificial agents may be of the same types, they may yet remain substantively different than our relationships to human beings. © 2020, Springer-Verlag London Ltd., part of Springer Nature.},
author_keywords={Agents;  Artificial intelligence;  Machine ethics;  Moral psychology;  Robot rights;  Virtue ethics},
references={Agar, N., How to treat machines that might have minds (2019) Philos Technol; Annas, J., Learning virtue rules: the issue of thick concepts (2016) Developing the virtues: integrating perspectives, pp. 224-234. , Annas J, Narvaez D, Snow NE, (eds), Oxford University Press, New York; (2011) Aristotle’s nicomachean ethics, , (trans and ed: Bartlett RC, Collins SD). University of Chicago, Chicago; Berberich, N., Diepold, K., (2018) The Virtuous Machine-Old Ethics for New Technology?; Bigman, Y.E., Gray, K., People are averse to machines making moral decisions (2018) Cognition, 181, pp. 21-34; Boden, M.A., (2006) Mind as machine: a history of cognitive science, , Clarendon Press, Oxford; Boden, M.A., (2016) AI: its nature and future, , Oxford University Press, New York; Bostrom, N., (2014) Superintelligence: paths, dangers, strategies, , Oxford, New York; Coeckelbergh, M., Robot rights? Towards a social-relational justification of moral consideration (2010) Ethics Inf Technol, 12 (3), pp. 209-221; Danaher, J., The threat of algocracy: reality, resistance, and accommodation (2016) Philos Technol, 29, pp. 245-268; Danaher, J., Welcoming robots into the moral circle: a defence of ethical behaviourism (2019) Sci Eng Ethics; Dastur, F., The question of the other in French phenomenology (2011) Cont Philos Rev, 44 (2), pp. 165-178; Emerging technology from the arXiv (2015) Why self-driving cars must be programmed to kill MIT Technology Review, , https://www.technologyreview.com, Accessed 22 Oct 2015; Eubanks, V., (2018) Automating inequality: how high-tech tools profile, police, and punish the poor, , St Martin’s, New York; Gamez, P., Metaphysics or metaphors for the anthropocene? Scientific naturalism and the agency of things (2018) Open Philos, 1 (1), pp. 191-212; Govindarajulu, N.S., Bringsjord, S., Ghosh, R., Sarathy, V., Toward the engineering of virtuous machines (2019) Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society, pp. 29-35. , ACM; Gray, K., Wegner, D., Feeling robots and human zombies: mind perception and the uncanny valley (2012) Cognition, 125 (1), pp. 125-130; Gray, K., Young, L., Waytz, A., Mind perception is the essence of morality (2012) Psychol Inq, 23 (2), pp. 101-124; Gunkel, D.J., (2012) The machine question: critical perspectives on AI, robots, and ethics, , MIT Press, Cambridge; Gunkel, D.J., (2018) Robot rights, , MIT Press, Cambridge; Hitlin, S., (2008) Moral selves, evil selves: the social psychology of conscience, , Palgrave Macmillan, New York; Howard, D., Muntean, I., A minimalist model of the artificial autonomous moral agent (AAMA) (2016) 2016 AAAI Spring Symposium Series, , https://www.aaai.org/ocs/index.php/SSS/SSS16/paper/view/12760/11954, Palo Alto California, March 2016, Accessed 20 Apr 2020; Howard, D., Muntean, I., Artificial moral cognition: Moral functionalism and autonomous moral agency (2017) Philos Comput, pp. 121-159. , Springer, Cham; Hursthouse, R., (1999) On virtue ethics, , OUP, Oxford; Keown, D., (2005) Buddhist ethics: a very short introduction, , Oxford University Press, New York; Knobe, J., Intentional action in folk psychology: an experimental investigation (2003) Philos Psychol, 16 (2), pp. 309-324; Knobe, J., Intentional action and side effects in ordinary language (2003) Analysis, 63 (3), pp. 190-194; Kraut, R., (2018) Aristotle’s Ethics. the Stanford Encyclopedia of Philosophy, , https://plato.stanford.edu/entries/Aristotle-ethics, Accessed 15 June 2018; Large, W., (2015) Levinas’ “Totality and Infinity”: a reader’s guide, , Bloomsbury Publishing, New York; Moor, J., The nature, importance, and difficulty of machine ethics (2006) IEEE Intell Syst, 21 (4), pp. 18-21; Malle, B.F., Magar, S.T., Scheutz, M., AI in the sky: how people morally evaluate human and machine decisions in a lethal strike dilemma (2019) Robots and eell-being, pp. 111-133. , Ferreira IA, Sequeira JS, Virk GS, Kadar EE, Tokhi O, (eds), Springer Verlag, Berlin; McDermott, D., What matters to a machine? (2011) Machine ethics, pp. 88-114. , Anderson M, Anderson SL, (eds), Cambridge University Press, New York; Morgan, M.L., (2007) Discovering levinas, , Cambridge University Press, New York; Nass, C., Moon, Y., Machines and Mindlessness: Social Responses to Computers (2000) J Soc Issues, 56 (1), pp. 81-103; Noble, S., (2018) Algorithms of oppression: how search engines reinforce racism, , NYU, New York; O’Neil, C., (2016) Weapons of math destruction: how big data increases inequality and threatens democracy, , Crown, New York; Regan, T., The case for animal rights (1987) Adv Anim Welf Sci, pp. 179-189. , Springer, Dordrecht; Seidel, J., Life savers, or killer robots? Australian airforce ‘Loyal Wingman’ autonomous drones (2019) The Advertiser, , https://www.adelaidenow.com.au, Accessed 11 Mar 2019; Shank, D.B., Are computers good or bad for business? How mediated customer-computer interaction alters emotion, impressions, and patronage toward organizations (2013) Comput Hum Behav, 29 (3), pp. 715-725; Shank, D.B., Impressions of computer and human agents after interaction: computer identity weakens power but not goodness impressions (2014) Int J Hum Comput Stud, 72 (10-11), pp. 747-756; Shank, D.B., Desanti, A., Attributions of morality and mind to artificial intelligence after real-world moral violations (2018) Comput Hum Behav, 86, pp. 401-411; Shank, D.B., DeSanti, A., Maninger, T., When are artificial intelligence versus human agents faulted for wrongdoing? Moral attributions after individual and joint decisions (2019) Inf Commun Soc; Sejnowski, M., (2018) The deep learning revolution: machine intelligence meets human intelligence, , The MIT Press, Cambridge; Sim, M., Confucian and daoist virtue ethics (2017) Varieties of virtue ethics, pp. 105-121. , Carr D, Arthur J, Kristjánsson K, (eds), Palgrave Macmillan, London; Singer, P., (1975) Animal liberation: a new ethics for the treatment of animals, , New York Review, New York; Smith, H., Using moral principles to guide actions (2012) Philos Investig, 22, pp. 369-386; Strawson, P.F., Freedom and resentment (1962) Proceedings of the British Academy, 48, pp. 1-25. , Watson G, Oxford, vol; Torrance, S., Machine ethics and the idea of a more-than-human moral world (2011) Machine ethics, pp. 115-137. , Anderson M, Anderson SL, (eds), Cambridge University Press, New York; Turkle, S., Authenticity in the age of digital companions (2011) Machine ethics, pp. 62-76. , Anderson M, Anderson SL, (eds), Cambridge University Press, New York; Vallor, S., (2016) Technology and the virtues: a philosophical guide to a future worth wanting, , Oxford University Press, Oxford; van Wynsberghe, A., Robbins, S., Critiquing the reasons for making moral machines (2019) Sci Eng Ethics, 25, pp. 719-735; Wallach, W., Allen, C., (2009) Moral machines: teaching robots right from wrong, , Oxford University Press, Oxford; Wroe, D., (2019) Killer Robots to Be Taught Ethics in World-Topping Australian Research Project, , https://www.smh.com/au, Sydney Morning Herald, Accessed 28 Feb 2019; Yampolskiy, R., Artificial intelligence safety engineering: why machine ethics is a wrong approach (2013) Philosophy and theory of artificial intelligence, pp. 389-396. , Müller V, (ed), Springer, New York; Young, A.D., Monroe, A.E., Autonomous morals: inferences of mind predict acceptance of AI behavior in sacrificial moral dilemmas (2019) J Exp Soc Psychol, 85, p. 103870},
document_type={Article},
source={Scopus},
}

@ARTICLE{Nieuważny2020329,
author={Nieuważny, J. and Masui, F. and Ptaszynski, M. and Rzepka, R. and Nowakowski, K.},
title={How religion and morality correlate in age of society 5.0: Statistical analysis of emotional and moral associations with Buddhist religious terms appearing on Japanese blogs},
journal={Cognitive Systems Research},
year={2020},
volume={59},
pages={329-344},
doi={10.1016/j.cogsys.2019.09.026},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074655757&doi=10.1016%2fj.cogsys.2019.09.026&partnerID=40&md5=6b3913b047cb9f84621270a567db3351},
abstract={In this paper we analyzed how much religious vocabulary, in particular Buddhist vocabulary taken from the largest online dictionary of Buddhist terms, is present in everyday social space of Japanese people, particularly, in Japanese blog entries appearing on a popular blog service (Ameba blogs). We interpreted the level of everyday usage of Buddhist terms as appearance of such terms in the consciousness of people. We further analyzed what emotional and moral associations such contents generate. In particular, we analyzed whether expressions containing Buddhist vocabulary are considered appropriate or not from a moral point of view, as well as the emotional response of Internet users to Buddhist terminology. As a result of analyzing the data, we found out that Buddhist terms were in fact not absent as a theme from Japanese blogs and generated a strong emotional response. However, while the general reaction to several expressions using Buddhist terms was as expected, there were sometimes surprising twists in terms of social consequences, major discrepancies between what is perceived as ethically correct behavior between the Buddhist doctrine and the reasoning of the general population, as well as a considerate number of terms which have lost their original meaning and instead became slang expressions. © 2019 Elsevier B.V.},
author_keywords={Automated moral reasoning;  Buddhist terminology;  Large-scale corpus;  Machine ethics},
keywords={Behavioral research;  Terminology, Emotional response;  General population;  Internet users;  Large-scale corpus;  Moral reasoning;  Online dictionaries;  Social consequences;  Social spaces, Blogs, age;  article;  Buddhist;  consciousness;  ethics;  human;  human experiment;  Internet;  Japanese (people);  morality;  nomenclature;  reasoning;  religion;  vocabulary},
references={Azniah, I., Shamsul, A.A., Maizatul, H.Y., Salman, F.S., An assessment of culturally appropriate design: A Malaysian University context (2018) International Journal of Interactive Mobile Technologies (iJIM), 12 (2), pp. 207-214; Danaylov, N., (2018), https://www.singularityweblog.com/technology-is-the-how/, Technology is the How, not the Why or What. Singularity Weblog, January 30, 2018. <>; Guthrie, S.E., Faces in the clouds: A new theory of religion (1993), Oxford University Press; Hameroff, S.R., Kaszniak, A.W., Scott, A.C., (1996) Towards a science of consciousness: The first Tucson discussions and debates, , The MIT Press Cambridge, MA, US; Hameroff, S.R., Kaszniak, A.W., Scott, A.C., (1998) Toward a science of consciousness II: The second Tucson discussions and debates, 2. , MIT Press Cambridge, Mass; Husain, A., The sentient machine: The coming age of artificial intelligence (2017), Simon and Schuster; Geraci, R., (2006), 4 (3), pp. 229-246. , doi: 10.1080/14746700600952993. M. Spiritual robots: Religion and our scientific view of the natural world. In: Theology and science; Jakubíček, M., Kilgarriff, A., Kovář, V., Rychlý, P., Suchomel, V., (2013), pp. 125-127. , The tenten corpus family. In: Proceedings of the international conference on corpus linguistics; Kant, I., (1785), Grundlegung zur Metaphysik der Sitten [Groundwork of the Metaphysics of Morals]; Komuda, R., Ptaszynski, M., Momouchi, Y., Rzepka, R., Araki, K., Machine moral development: Moral reasoning agent based on wisdom of web-crowd and emotions (2010) International Journal of Computational Linguistics Research, 1 (3), pp. 155-163; Komuda, R., Rzepka, R., Araki, K., Aristotelian approach and shallow search settings for fast ethical judgment (2013) International Journal of Computational Linguistics Research, 4 (1), pp. 14-22; Kurzweil, R., (2005), The singularity is near: When humans transcend biology. Viking; MacDorman, K.F., Entezari, S., Individual differences predict sensitivity to the uncanny valley (2015) Interaction Studies, 16 (2), pp. 141-172; McGrath, J., (2011) Religion and science fiction, , Wipf and Stock; McLaren, B., Extensionally Defining Principles and Cases in Ethics: An AI Model (2001) Artificial Intelligence Journal, 150 (1-2), pp. 145-181; Minsky, M.L., The society of mind (1986), Simon and Schuster New York, N.Y; Moor, J., The Nature, Importance, and Difficulty of Machine Ethics. (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Mori, M., The Uncanny Valley (Translated by Karl F. MacDorman and Norri Kageki) (1970) IEEE Robotics & Automation Magazine, 19/2012; Maciejewski, J., Ptaszynski, M., Dybala, P., Developing a Large-Scale Corpus for Natural Language Processing and Emotion Processing Research in Japanese (2010) In Proceedings of the International Workshop on Modern Science and Technology (IWMST), pp. 192-195; Nakamura, A., (1993), Kanjō hyōgen jiten [Dictionary of Emotive Expressions (in Japanese)]. Tōkyōdō; Picard, R.W., Affective computing (1997), MIT Press; Ptaszynski, M., Dybala, P., Rzepka, R., Araki, K., Momouchi, Y.Y., (2012), A five-billion-word corpus of Japanese blogs fully annotated with syntactic and affective information. In: Proceedings of the AISB/IACAP world congress 2012 in honour of Alan Turing, 2nd symposium on linguistic and cognitive approaches to dialog agents (LaCATODA 2012), 2-6 July 2012 (pp. 40–49). Birmingham, UK: University of Birmingham; Reeves, J.F., Computational morality: A process model of belief conflict and resolution for story understanding (1991), PhD thesis Computer Science Department, UCLA; Rzepka, R., Araki, K., (2005), pp. 85-87. , What statistics could do for ethics? The idea of common sense processing based safety valve. In: AAAI fall symposium on machine ethics, technical report FS-05-06; Wallach, W., Allen, C., Moral machines: Teaching robots right from wrong (2006), Oxford University Press; Anderson, M., Anderson, S.L., (2011) Machine ethics, , Cambridge University Press; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (2007), pp. 15-26; Anderson, M., Anderson, S., Robot, L., (2010), pp. 72-77. , Be Good. In: Scientific American, 303(4); Anderson, M., Anderson, S.L., Berenz, V., (2017), A value driven agent: Instantiation of a case-supported principle-based behavior paradigm. AAAI 2016 workshop on AI, Ethics & Society; Burns, J.H., Hart, H.L.A., (1996) The collected works of Jeremy Bentham: An introduction to the principles of morals and legislation, , Clarendon Press},
document_type={Article},
source={Scopus},
}

@ARTICLE{Misselhorn2020,
author={Misselhorn, C.},
title={Artificial systems with moral capacities? A research design and its implementation in a geriatric care system},
journal={Artificial Intelligence},
year={2020},
volume={278},
doi={10.1016/j.artint.2019.103179},
art_number={103179},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074135264&doi=10.1016%2fj.artint.2019.103179&partnerID=40&md5=52fbac65d9cb3d3fa8b33c2135f1ff57},
abstract={The development of increasingly intelligent and autonomous technologies will eventually lead to these systems having to face morally problematic situations. This gave rise to the development of artificial morality, an emerging field in artificial intelligence which explores whether and how artificial systems can be furnished with moral capacities. This will have a deep impact on our lives. Yet, the methodological foundations of artificial morality are still sketchy and often far off from possible applications. One important area of application of artificial systems with moral capacities is geriatric care. The goal of this article is to afford the methodological foundations for artificial morality, i.e., for implementing moral capacities in artificial systems in general, and to discuss them with respect to an assistive system in geriatric care which is capable of moral learning. © 2019 Elsevier B.V.},
author_keywords={Artificial moral agents;  Artificial morality;  Assistive systems in geriatric care;  Elder care robots;  Functional morality;  Machine ethics;  Moral capacities;  Moral implementation},
keywords={Artificial intelligence, Artificial morality;  Elder care;  Functional morality;  Geriatric cares;  Moral agents;  Moral capacities;  Moral implementation, Geriatrics},
references={Alston, W.P., Moral attitudes and moral judgments (1968) Noûs, 2, pp. 1-23; Anderson, S., Anderson, M., Armen, C., MedEthEx: a prototype medical ethics advisor (2006) Proceedings of the Eighteenth Conference on Innovative Applications of Artificial Intelligence, , AAAI Boston, Massachusetts; Anderson, S., Anderson, M., ETHEL: toward a principled ethical elder care robot (2008) Proceedings of the AAAI Fall 2008 Symposium on AI in Eldercare: New Solutions to Old Problems, Arlington, Virginia; Anderson, S., Anderson, M., A prima facie duty approach to machine ethics and its application to elder care (2011) Proceedings of the AAAI Workshop on Human-Robot Interaction in Elder Care, San Francisco; Arkin, R., Governing Lethal Behavior: Embedding Ethics in a Hybrid Deliberative/Reactive Robot Architecture (2007), Technical Report GIT-GVU-07-11 College of Computing, Georgia Institute of Technology; Axelrod, R., The Evolution of Cooperation (1984), Basic Books New York; Bajo, J., GR-MAS: multi-agent system for geriatric residences (2008) ECAI 2008, Frontiers in Artificial Intelligence and Applications, 178, pp. 875-876; Beauchamp, T., Childress, J., Principles of Biomedical Ethics (1979), Oxford University Press Oxford, New York; Bermudez, J., Philosophy of Psychology: A Contemporary Introduction (2005), Routledge New York; Block, N., On a confusion about the function of consciousness (1995) Behavioral and Brain Sciences, 18, pp. 227-247; Bratman, M.E., Faces of Intention: Selected Essays on Intention and Agency (1999), Cambridge University Press Cambridge; Bratman, M.E., Structures of Agency. Essays (2007), Oxford University Press Oxford, New York; Breazeal, C., Scassellati, B., Robots that imitate humans (2002) Trends in Cognitive Sciences, 6, pp. 481-487; Chisholm, R., Human Freedom and the Self. The Lindley Lectures (1964) Free Will, pp. 26-37. , Department of Philosophy, University of Kansas, repr. G. Watson 2nd edition Oxford University Press Oxford 2003; Coeckelbergh, M., How I learned to love the robot (2012) The Capability Approach, Technology and Design, pp. 77-86. , I. Oosterlaken J. van den Hoven Springer Dordrecht; Dancy, J., Moral particularism (2013) The Stanford Encyclopedia of Philosophy (Fall 2013 Edition), , http://plato.stanford.edu/archives/fall2013/entries/moral-particularism/, E.N. Zalta; Davidson, D., Essays on Actions and Events (1980), Oxford University Press Oxford, New York; Dennett, D.C., The Intentional Stance (1987), MIT Press Cambridge, MA; Dennett, D.C., Cognitive science as reverse engineering. Several meanings of “Top-down” and “Bottom-up” (1994) Logic, Methodology and Philosophy of Science 9, pp. 679-693. , D. Prawitz B. Skyrms D. Westerstahl Elsevier Amsterdam; De Paz Santana, J.F., An integrated system for helping disabled and dependent people: AGALZ, AZTECA, and MOVI-MAS projects (2015) Adv. Intell. Syst. Comput., 333, pp. 3-24; Dretske, F., Explaining Behavior: Reasons in a World of Causes (1995), 4th printing Cambridge University Press Cambridge; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds Mach., 14, pp. 349-379; Fong, T., Illah, N., Dautenhahn, K., A Survey of Socially Interactive Robots: Concepts, Design, and Applications (2002), Technical Report No. CMU-RI-TR: 2–29 Robotics Institute, Carnegie Mellon University; Frankena, W.K., The concept of morality (1966) Journal of Philosophy, 63, pp. 688-696; Frankfurt, H., Freedom of the will and the concept of a person (1971) Journal of Philosophy, 68, pp. 5-20; Froese, T., Di Paolo, E., Modelling social interaction as perceptual crossing: an investigation into the dynamics of the interaction process (2010) Connect. Sci., 22, pp. 43-68; Horgan, T., Timmons, M., What does the frame problem tell us about moral normativity? (2009) Ethical Theory and Moral Practice, 12, pp. 25-51; Knobe, J., What is experimental philosophy? (2004) Philos. Mag., 28, pp. 37-39; Korsgaard, C.M., The Sources of Normativity (1996), Cambridge University Press Cambridge; Levy, N., Consciousness and Moral Responsibility (2014), Oxford University Press Oxford; Marr, D., Vision: A Computational Investigation into the Human Representation and Processing of Visual Information (1982), MIT Press Cambridge, MA; McCarthy, J., Hayes, P.J., Some Philosophical Problems from the Standpoint of Artificial Intelligence (1969) Machine Intelligence, pp. 463-502. , B. Meltzer D. Michie Edinburgh University Press Edinburgh, UK; Misselhorn, C., Robots as moral agents? (2013) Roboethics, Proceedings of the Annual Conference on Ethics of the German Association for Social Science Research on Japan, pp. 30-42. , F. Roevekamp Iudicum München; Misselhorn, C., Ethical considerations regarding the use of social robots in the fourth age (2013) GeroPsych, J. Gerontopsychol. Geriatr. Psychiatry, 26, pp. 121-133. , Special issue: emotional and social robots for aging well?; Misselhorn, C., Collective agency and cooperation in natural and artificial systems (2015) Collective Agency and Cooperation in Natural and Artificial Systems. Explanation, Implementation and Simulation, Philosophical Studies Series, 122, pp. 3-25. , C. Misselhorn Springer Dordrecht; Nichols, S., Knobe, J., (2008) Experimental Philosophy, , Oxford University Press Oxford, New York; Nussbaum, M., “Finely aware and richly responsible.” Moral attention and the moral task of literature (1985) Journal of Philosophy, 82, pp. 516-529; Nussbaum, M., Frontiers of Justice: Disability, Nationality, Species Membership (2006), The Belknap Press of Harvard University Press Cambridge, London; Nussbaum, M., Adaptive preferences and women's options (2001) Economics and Philosophy, 17, pp. 67-88; Nussbaum, M., Sen, A., The Quality of Life (1993), Clarendon Press Oxford; Parra, V., A multiagent system to assist elder people by TV communication (2014) ADCAIJ, Adv. Distrib. Comput. Artif. Intell. J., 3, pp. 10-16; Rawls, J., Political Liberalism (1993), Columbia University Press New York; Ross, W.D., The Right and the Good (1930), Clarendon Press Oxford; Stahl, B.C., Information, ethics, and computers: the problem of autonomous moral agents (2004) Minds and Machines, 14, pp. 67-83; Shanahan, M., The frame problem (2009) The Stanford Encyclopedia of Philosophy (Winter 2009 Edition), , http://plato.stanford.edu/archives/win2009/entries/frame-problem/, Edward N. Zalta; Von der Pfordten, D., Five elements of normative ethics – a general theory of normative individualism (2012) Ethical Theory and Moral Practice, 15, pp. 449-471; Wallach, W., Allen, C., Moral Machines: Teaching Robots Right from Wrong (2009), Oxford University Press Oxford, New York; Zato Domínguez, C., Virtual organizations of agents for monitoring elderly and disabled people in geriatric residences. Information Fusion (FUSION) 2013 (2013) 16th International Conference, Istanbul, Turkey, July 9–12, pp. 327-333},
document_type={Article},
source={Scopus},
}

@ARTICLE{Takeda20191248,
author={Takeda, M. and Hirata, Y. and Weng, Y.-H. and Katayama, T. and Mizuta, Y. and Koujina, A.},
title={Accountable system design architecture for embodied AI: a focus on physical human support robots},
journal={Advanced Robotics},
year={2019},
volume={33},
number={23},
pages={1248-1263},
doi={10.1080/01691864.2019.1689168},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075135772&doi=10.1080%2f01691864.2019.1689168&partnerID=40&md5=e5637d96b14fd3fe24033f8c367fa5f5},
abstract={Although the development of robot-based support systems for elderly people has become more popular, it is difficult for humans to understand the actions, plans, and behavior of autonomous robots and the reasons behind them, particularly when the robots include learning algorithms. Learning-based autonomous systems which are called AI are treated as an inherently untrustworthy ‘black box,’ because machine learning or deep learning algorithms are difficult for humans to understand. Robot systems such as assistive robots, which work closely with humans, however, should be trusted. Systems should therefore achieve accountability for all stakeholders. However, most research in this field has focused on particular systems and situations, and no general design architecture exists. In this study, we propose a new design method, focused on accountability and transparency, for learning-based robot systems. Describing the entire system is a necessary first step, and transcribing the described system for each stakeholder based on several principles is effective for achieving accountability. The method improves transparency for systems, including learning algorithms. A standing assistive robot is used as an example of the entire system to clarify which system parts require greater transparency. This study adopted the Systems Modeling Language (SysML) to describe the system and the described system is used for the information representation. Information should be represented considering the relationships between stakeholders, information, and the system interface. Because of their complexity, it is difficult for humans to understand the complete set of information available in robot systems. Systems should therefore present only the information required, depending on the situation. The stakeholder–interface relationship is also important because it is more beneficial for professionals to view information relevant to their specialized field, which would be difficult for others to understand. By contrast, the interface should be intuitive for general users. Visualization and sound are very useful means of transmitting information, with advantages and disadvantages for different circumstances. These relationships are important for achieving accountability. Finally, we show an example of implementation with a developed support system. It is confirmed that accountable systems can be designed based on the proposed design architecture. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group and The Robotics Society of Japan.},
author_keywords={black box;  Health care management;  physically assistive devices;  robot ethics},
keywords={Deep learning;  Machine design;  Machine learning;  Modeling languages;  Robots;  Transparency, Assistive devices;  Black boxes;  Design architecture;  Health-care managements;  Human support robot;  Information representation;  Robot ethics;  Systems modeling languages, Learning algorithms},
references={Moe-Nilssen, R., A new method for evaluating motor control in gait under real-life environmental conditions. part 2: gait analysis (1998) Clin Biomech, 13 (4), pp. 328-335; Li, X., Xu, H., Cheung, J.T., Gait-force model and inertial measurement unit-based measurements: a new approach for gait analysis and balance monitoring (2016) J Exerc Sci Fit, 14 (2), pp. 60-66; Hirata, Y., Komatsuda, S., Kosuge, K., Fall prevention control of passive intelligent walker based on human model. In: 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems; Nice, France. 2008 Sep. p. 1222–1228; Di, P., Huang, J., Nakagawa, S., Fall detection and prevention the elderly based on the zmp stability control. In: 2013 IEEE Workshop on Advanced Robotics and its Social Impacts; Tokyo, Japan. 2013 Nov. p. 82–87, et al; Miezal, M., Taetz, B., Bleser, G., Real-time inertial lower body kinematics and ground contact estimation at anatomical foot points for agile human locomotion. In: 2017 IEEE International Conference on Robotics and Automation (ICRA); Singapore. 2017 May. p. 3256–3263; Zabjek, K., Coillard, C., Rivard, C., Estimation of the centre of mass for the study of postural control in idiopathic scoliosis patients: a comparison of two techniques (2008) Eur Spine J, 17, pp. 355-360. , Apr; Mannini, A., Sabatini, A.M., Machine learning methods for classifying human physical activity from on-body accelerometers (2010) Sensors, 10 (2), pp. 1154-1175; Anguita, D., Ghio, A., Oneto, L., Human activity recognition on smartphones using a multiclass hardware-friendly support vector machine. Bravo J, Hervás R, Rodríguez M, editors. Ambient assisted living and home care. Berlin, Heidelberg: Springer; 2012. p. 216–223; Tome, D., Russell, C., Agapito, L., Lifting from the deep: convolutional 3d pose estimation from a single image. In: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA. 2017 Jul; Tompson, J.J., Jain, A., LeCun, Y., Joint training of a convolutional network and a graphical model for human pose estimation. In: Ghahramani Z, Welling M, Cortes C, et al., editors. Advances neural information processing systems 27. Montreal, Quebec: MIT Press Cambridge; 2014. p. 1799–1807; Yin, X., Pan, L., Enhancing trajectory tracking accuracy for industrial robot with robust adaptive control (2018) Robot Comput Integr Manuf, 51, pp. 97-102; Yin, X., Pan, L., Direct adaptive robust tracking control for 6 dof industrial robot with enhanced accuracy (2018) ISA Trans, 72, pp. 178-184; Kiguchi, K., Hayashi, Y., An emg-based control for an upper-limb power-assist exoskeleton robot (2012) IEEE Trans Syst Man Cybern B (Cybernet), 42 (4), pp. 1064-1071. , Aug; Hirata, Y., Yamaya, H., Kosuge, K., Anomaly state assessing of human using walker-type support system based on statistical analysis. In: 2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN); Kobe, Japan. 2015 Aug. p. 146–152; Takeda, T., Kosuge, K., Hirata, Y., Hmm-based dance step estimation for dance partner robot -ms dancer-. In: 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems; Edmonton, Canada. 2005 Aug. p. 3245–3250; Hirata, Y., Muraki, A., Kosuge, K., Motion control of intelligent walker based on renew of estimation parameters for user state. In: 2006 IEEE/RSJ International Conference on Intelligent Robots and Systems; Beijing, China. 2006 Oct. p. 1050–1055; Chuy, O., Hirata, Y., Wang, Z., Motion control algorithms for a new intelligent robotic walker emulating ambulatory device function. In: IEEE International Conference Mechatronics and Automation, 3, 2005 July, Ontario, Canada. p. 1509–1514, et al; Wortham, R.H., Theodorou, A., Bryson, J.J., Improving robot transparency: Real-time visualisation of robot ai substantially improves understanding naive observers. In: 2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN); Lisbon, Portugal. 2017 Aug. p. 1424–1431; Wortham, R.H., Theodorou, A., Bryson, J.J., Robot transparency: Improving understanding of intelligent behaviour for designers and users. In: Gao Y, Fallah S, Jin Y, editors. Towards autonomous robotic systems. Cham: Springer International Publishing; 2017. p. 274–289; Song, S., Yamada, S., Designing led lights for a robot to communicate gaze (2019) Adv Robot, 33 (7-8), pp. 360-368; Park, D.H., Hendricks, L.A., Akata, Z., Attentive explanations: Justifying decisions and pointing to the evidence. CoRR, abs/1612.04757, 2016, et al; DeFauw, J., Ledsam, J.R., Romera-Paredes, B., Clinically applicable deep learning for diagnosis and referral in retinal disease (2018) Nat Med, 24, pp. 1342-1350. , Aug, et al; Kurnia, R., Hossain, M.A., Nakamura, A., Generation of efficient and user-friendly queries for helper robots to detect target objects (2006) Adv Robot, 20 (5), pp. 499-517. , et al; Green, A., Eklundh, K.S., Designing for learnability in human-robot communication (2003) IEEE Trans Ind Electron, 50 (4), pp. 644-650. , Aug; Shinozawa, K., Miyashita, T., Kakio, M., User specification method and humanoid confirmation behavior. In: 2007 7th IEEE-RAS International Conference on Humanoid Robots; Pittsburgh, PA, USA. 2007 Nov. p. 366–370, et al; Paez Granados, D.F., Yamamoto, B.A., Kamide, H., Dance teaching by a robot: combining cognitive and physical human-robot interaction for supporting the skill learning process (2017) IEEE Robot Autom Lett, 2 (3), pp. 1452-1459. , July, et al; Novikova, J., Watts, L., Towards artificial emotions to assist social coordination in hri (2015) Int J Soc Robot, 7 (1), pp. 77-88. , Feb; Hosseini, M., Shahri, A., Phalp, K., A modelling language for transparency requirements business information systems. Nurcan S, Soffer P, Bajec M, et al., editors, Advanced information systems engineering. Cham: Springer International Publishing; 2016. p. 239–254; Wortham, R.H., Gaudl, S.E., Bryson, J.J., Instinct: a biologically inspired reactive planner for embedded environments. In: Proceedings of ICAPS 2016 PlanRob Workshop, London, UK; 2016; Pakrasi, S., Burmeister, O., Coppola, J.F., Ethical telehealth design for users with dementia (2015) Gerontechnology, 13 (4), pp. 383-387. , Imported on 12 Apr 2017DigiTool details were: Journal title (773t) = Gerontechnology. 1569-1101; Baldini, G., Botterman, M., Neisse, R., Ethical design in the internet of things (2018) Sci Eng Ethics, 24 (3), pp. 905-925. , June, et al; The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems (2019) Ethically Aligned Design: A Vision for Prioritizing Human Well-Being with Autonomous and Intelligent Systems, First Edition, , https://standards.ieee.org/content/ieee-standards/en/industry-connections/ec/autonomous-systems.html; Bryson, J., Winfield, A., Standardizing ethical design for artificial intelligence and autonomous systems (2017) Computer, 50 (5), pp. 116-119. , May; Weng, Y., Hirata, Y., Ethically aligned design for assistive robotics. In: 2018 IEEE International Conference on Intelligence and Safety for Robotics (ISR), Shenyang, China. 286–290, Aug 2018; (2018) Nursing-Care Robots Development Guidline., , http://robotcare.jp/?page_id=5731; Waltl, B., Vogl, R., Explainable artificial intelligence–the new frontier in legal informatics (2018) Jusletter IT, 4, pp. 1-10; Bologna, G., Hayashi, Y., Characterization of symbolic rules embedded in deep dimlp networks: A challenge to transparency of deep learning (2017) J Artif Intell Soft Comput Res, 7, pp. 265-286. , July; Miller, T., Explanation in artificial intelligence: insights from the social sciences (2019) Artif Intell, 267, pp. 1-38; Weller, A., Challenges for transparency. CoRR, abs/1708.01870, 2017; Boscoe, B., Creating transparency in algorithmic processes (2019) Delphi–Interdiscipl Rev Emerg Technol, 2 (1), pp. 12-22; (2012), http://www.omg.org/spec/SysML/1.3/, OMG: OMG Systems Modeling Language (OMG SysML), Version 1.3; Sigrist, R., Rauter, G., Riener, R., Augmented visual, auditory, haptic, and multimodal feedback in motor learning: A review (2013) Psychon Bull Rev, 20 (1), pp. 21-53. , Feb, et al; Matthew, J.B.P., Gray, A.A., ICMI'06: 8th International Conference on Multimodal Interfaces, Conference Proceeding, , Comparing the effects of visual-auditory and visual-tactile feedback on user performance: A meta-analysis.; Banff, Alberta, Canada. 2006 Jan. p. 108–117; Funk, M., Heusler, J., Akcay, E., Haptic, auditory, or visual?: Towards optimal error feedback at manual assembly workplaces. In: Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments, PETRA 16. New York, NY, USA: ACM; 2016. p. 43:1–43:6; Hatsukari, T., Kuroko, S., Miyake, N., 2008 IEEE International Conference on Robotics and Biomimetics, , Self-help standing-up method based on quasi-static motion.; Qingdao, China. 2009 Feb. p. 342–347; Kawazoe, S., Chugo, D., Yokota, S., 2017 IEEE International Conference on Industrial Technology (ICIT), , Development of standing assistive walker for domestic use.; Toronto, Canada. 2017 Mar. p. 1455–1460, et al; Takeda, M., Hirata, Y., Katayama, T., State estimation using the cog candidates for sit-to-stand support system user (2018) IEEE Robot Automat Lett, 3 (4), pp. 3011-3018. , Oct; Takeda, M., Hirata, Y., Kosuge, K., 2017 IEEE International Conference on Robotics and Automation (ICRA), , Human cog estimation for assistive robots using a small number of sensors.; Singapore. May 2017. p. 6052–6057},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gabbay2019425,
author={Gabbay, D.M. and Schild, U. and David, E.},
title={The Talmudic Logic Project, Ongoing Since 2008},
journal={Logica Universalis},
year={2019},
volume={13},
number={4},
pages={425-442},
doi={10.1007/s11787-019-00228-y},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075448689&doi=10.1007%2fs11787-019-00228-y&partnerID=40&md5=4e947beed12a81c8e0c5e7730b2bf3a1},
abstract={We describe the state of the Talmudic Logic project as of end of 2019. The Talmud is the most comprehensive and fundamental work of Jewish religious law, employing a large number of logical components centuries ahead of their time. In many cases the basic principles are not explicitly formulated, which makes it difficult to formalize and make available to the modern student of Logic. This project on Talmudic Logic, aims to present logical analysis of Talmudic reasoning using modern logical tools. We investigate principles of Talmudic Logic and publish a series of books, one book or more for each principle. http://www.collegepublications.co.uk/stl/ The series begins with the systematic analysis of Talmudic inference rules. The first book shows that we can present Talmudic reasoning intuitions as a systematic logical system basic to modern non-deductive reasoning, such as Argumentum A Fortiori, Abduction and Analogy. The second book offers a systematic common sense method for intuitively defining sets and claims that this method adequately models the Talmudic use of the rules Klal uPrat. These books also criticize modern Talmudic research methodology. Later books deal with additional topics like Deontic logic, and Temporal logic, Agency and processes in the Talmud and more. The aims of the project are two fold:1.To import into the Talmudic study modern logical methods with a view to help understand complicated Talmudic passages, which otherwise cannot be addressed.2.To export from the Talmud new logical principles which are innovative and useful to modern contemporary logic. © 2019, The Author(s).},
author_keywords={Argumentation;  Identity theory;  Logic and law;  Machine ethics;  Talmudic logic;  Temporal logic},
references={Abraham, M., Gabbay, D., Schild, U., Studies in Talmudic Logic (2010) Non- Deductive Inferences in the Talmud (In Hebrew and English), 1, p. 289. , 78, College Publications, London; Abraham, M., Gabbay, D., Hazut, G., Maruvka, Y., Schild, U., (2010) Studies in Talmudic Logic, Volume 2: The Textual Inference Rules Klal Uprat, How The Talmud Defines Sets (In Hebrew and English), Pp. 388+17, , College Publications, London; Abraham, M., Gabbay, D., Schild, U., (2010) Studies in Talmudic Logic, Volume 3: Talmudic Deontic Logic (In Hebrew and English), Pp. 267+29, , College Publications, London; Abraham, M., Belfer, I., Gabbay, D., Schild, U., Studies in Talmudic Logic (2011) Temporal Logic in the Talmud (In Hebrew and English), 4, p. 588+70. , College Publications, London; Abraham, M., Gabbay, D., Schild, U., (2011) Studies in Talmudic Logic, 5, p. 280+25. , Resolution of Conflicts and Normative Loops in the Talmud (in Hebrew and English), College Publications, London; Abraham, M., Belfer, I., Gabbay, D., Schild, U., (2011) Studies in Talmudic Logic, Volume 7: Delegation in Talmudic Logic (In Hebrew and English), Pp. 315+25, , College Publications, London; Abraham, M., Belfer, I., Gabbay, D., Schild, U., (2012) Studies in Talmudic Logic, Volume 8: Synthesis of Concepts in Talmudic Logic (In Hebrew and English), Pp. 455+14, , College Publications, London; Abraham, M., Belfer, I., Gabbay, D., Schild, U., (2014) Studies in Talmudic Logic, Volume 9: Analysis of Concepts in Talmudic Reasoning (In Hebrew and English, p. 301 + 11. , College Publications, London; Abraham, M., Gabbay, D., Schild, U., Studies in Talmudic Logic (2013) Principles of Talmudic Logic, 10, p. 296. , College Publications, London; Abraham, M., Gabbay, D., Schild, U., (2014) Studies in Talmudic Logic, Volume 11: Platonic Realism and Talmudic Reasoning, p. 325 + 15. , College Publications, London; Abraham, M., Belfer, I., Gabbay, D., Schild, U., Studies in Talmudic Logic (2015) Fuzzy Logic and Quantum States in Talmudic Reasoning, 12. , College Publications, London; Abraham, M., Belfer, I., Gabbay, D., Schild, U., (2016) Studies in Talmudic Logic, Volume 13: Partition Problems in Talmudic Reasoning, , College Publications, London; Abraham, M., Belfer, I., Gabbay, D., David, E., David, S., Schild, U., (2017) Studies in Talmudic Logic, 14, p. 360. , Joint Ownership Partnership in Talmudic Reasoning, pp, College Publications, London; (1970), Edited by L. M. De Rijk in Petrus Abaelardus: Dialectica, Assen: Van Gorcum (second edition); Arnauld, A., (1880) The Art of Thinking: Being the Port-Royal Logic, , 1612–1694; Nicole, Pierre, 1625–1695. Logic, or, Sutherland and Knox, Edinburgh; (2013) Handbook of the History of Logic, the Rise of Modern Logic: From Leibniz to Frege, 3, p. 780. , Paperback 4 Apr 2013 by D. M. Gabbay and J. Woods (eds.), Elsevier, Amsterdam; Barwise, J., (1977) Handbook of Mathematical Logic, , (ed), Elsevier, Amsterdam; Tübingen. Texts and Studies in Ancient Judaism (Book 89) (2002) Mohr Siebeck; Abraham, M., Belfer, I., Gabbay, D., Schild, U., Future determination of entities in Talmudic logic (2013) J. Appl. Log., 11 (1), pp. 63-90; Abraham, M., Belfer, R., Gabbay, D., Schild, U., Delegation, count-as and security in Talmudic logic, a preliminary study (2011) Logic without Frontiers. Festschrift for Walter Alexandre Carnielli on the Occasion of His 60Th Birthday, , Beziau, J.-Y., Coniglio, M.E., College Publications, London, December; The Schottenstein Talmud, , https://www.artscroll.com/Talmud1.htm; Abraham, M., Belfer, I., Gabbay, D., Schild, U., Identity merging and identity revision in Talmudic logic (2016) .) Computational Models of Rationality — Essays Dedicated to Gabriele Kern-Isberner on the Occasion of Her 60Th Birthday, pp. 179-194. , College Publications, volume 29 of Tributes. (February; Etzioni, O., Etzioni, A., Designing AI systems that obey our laws and values (2016) Commun. ACM, 59 (9), pp. 29-31; Crochemore, M., Gabbay, D.M., Reactive automata (2011) Inf. Comput., 209 (4), pp. 692-704; Dominic, H., Sorites Paradox, , Stanford Encyclopedia of Philosophy; Hinnant, C.H., (1980) Thomas Hobbes: A Reference Guide, , G. K. Hall & Co., Boston; Gianni, M., Kruijff-Korbayová, I., Worst, R., NIFTi Project Team. Human-robot teaming in disaster response — a user-centric approach (2015) Where We are and Where We Can Be Proceedings of the ICRA 2015 Workshop on Robotics & Automation Technologies for Humanitarian Applications; The Steinsaltz Talmud Bavli - 29 Volume Set Commentary by Rabbi Adin Steinsaltz, , https://www.korenpub.com/koren_en_usd/koren/talmud/talmud-sets/steinsaltz-talmud-bavli-29-volume-set.html; Non Monotonic Logic, , https://plato.stanford.edu/entries/logic-nonmonotonic/Accessed09/09/2017; Gabbay, D., Rozenberg, G., Rivlin, L., Reasoning under the influence of universal distortion (2017) IFCoLog J. Log. Appl., 4 (6), pp. 1789-1900; (1998), by William Shakespeare (Author), Ann Thompson (Editor), David Scott Kastan (Editor), Richard Proudfoot (Editor); (1990), Othello (New Swan Shakespeare. Advanced Series) Paperback — September, 1990 by William Shakespeare (Author), Gamini Salgado (Editor) September, by William Shakespeare, Author, Gamini Salgado (Editor; Abraham, M., Gabbay, D.M., Schild, U., Contrary to time conditionals in Talmudic logic (2012) Artif. Intell. Law, 20 (2), pp. 145-179; The handling of loops in Talmudic Logic, with application to odd and even loops in argumentation (2011) Proceedings of Howard 60, pp. 1-25. , Rydeheard, D., Voronkov, A., Korovina, M., Dec; (2018), http://dafpshat.blogspot.co.uk/2009/05/bam-21-whatis-yeush.htm, accessed January 10; Gabbay, D., Robaldo, L., Sun, X., van Der Toorre, L., Baniasadi, Z., A solution to the miner paradox: A beth semantics approach (2014) Deontic Logic and Normative Systems. 12 International Conference, DEON, pp. 108-123. , Fabrizio, C., Davide, G., Joke, M., Xavier P; Gabbay, D., Cramer, M., Dauphin, J., Farjami, A., Rivlin, L., van Der Torre, L., Machine argumentation. Can we replace taxi drivers by robots? (2019) Natural Argument, a Tribute to John Woods, pp. 177-199. , Gabbay, D., Lorenzo, M., Woosuk P., Athi-Veikko, P.(eds.), College Publications (,); Abraham, M., Gabbay, D.M., Schild, U., Obligations and prohibitions in Talmudic deontic logic (2011) Artif. Intell. Law, 19 (2-3), pp. 117-148; Abraham, M., Gabbay, D., Hazut, G., Maruvka, Y., Schild, U., Logic analysis of the Talmudic rules of general and specific (Klal uPrat) (2011) Hist. Philos. Log., 32 (1), pp. 47-62; Abraham, M., Gabbay, D., Schild, U., Analysis of the Talmudic argumentum a fortiori inference rule (kal vachomer) using matrix abduction (2009) Stud. Log., 92 (3), pp. 281-364; Abraham, M., Gabbay, D., Schild, U., Kal vaChomer (In Hebrew) (2009) BBD Journal},
document_type={Article},
source={Scopus},
}

@ARTICLE{Srinivasan2019145,
author={Srinivasan, B. and Shah, K.},
title={Towards a unified framework for developing ethical and practical Turing tests},
journal={AI and Society},
year={2019},
volume={34},
number={1},
pages={145-152},
doi={10.1007/s00146-017-0763-y},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030864354&doi=10.1007%2fs00146-017-0763-y&partnerID=40&md5=da001b6ea389af410a7d6f2f2565a944},
abstract={Since Turing proposed the first test of intelligence, several modifications have been proposed with the aim of making Turing’s proposal more realistic and applicable in the search for artificial intelligence. In the modern context, it turns out that some of these definitions of intelligence and the corresponding tests merely measure computational power. Furthermore, in the framework of the original Turing test, for a system to prove itself to be intelligent, a certain amount of deceit is implicitly required which can have serious security implications for future human societies. In this article, we propose a unified framework for developing intelligence tests which takes care of important ethical and practical issues. Our proposed framework has several important consequences. Firstly, it results in the suggestion that it is not possible to construct a single, context independent, intelligence test. Secondly, any measure of intelligence must have access to the process by which a problem is solved by the system under consideration and not merely the final solution. Finally, it requires an intelligent agent to be evolutionary in nature with the flexibility to explore new algorithms on its own. © 2017, Springer-Verlag London Ltd.},
author_keywords={Artificial intelligence;  Imitation game;  Machine ethics;  Turing test},
keywords={Artificial intelligence;  Network security;  Philosophical aspects, Computational power;  Context independent;  Imitation games;  Intelligence tests;  Practical issues;  Security implications;  Turing tests;  Unified framework, Testing},
references={Allcott, H., Gentzkow, M., (2017) Social Media and Fake News in the 2016 Elections, , NBER working paper 23089; Arleback, J.B., Bergsten, C., On the use of realistic fermi problems in introducing mathematical modelling in upper secondary mathematics (2013) Modeling students’ mathematical modeling competencies. International perspectives on the teaching and learning of mathematical modelling, , Lesh R, Galbraith P, Haines C, Hurford A, (eds), Springer, Dordrecht; Bringsjord, S., Bello, P., Ferrucci, D., Creativity, the Turing test, and the (Better) Lovelace test (2001) Mind Mach, 11, p. 3; Burgess, A., (2013) A clockwork orange, , Penguin Books, London; Calude, C.S., Jurgensen, H., Is complexity a source of incompletenesss? (2005) Adv Appl Math, 35, p. 1; Chaitin, G.J., Godel’s theorem and information (1982) Int J Theor Phys, 21, p. 941; Cohen, P.J., (2008) Set theory and the continuum hypothesis, , Dover, New York; Conroy, N.J., Rubin, V.L., Chen, Y., Automatic deception detection: methods for finding fake news (2015) Proc Assoc Inf Sci Technol, 52, p. 1; Gardner, H., (2011) Frames of mind: the theory of multiple intelligences, , Basic Books, New York; Godel, K., (1940) The consistency of the continuum-hypothesis, , Princeton University Press, New Jersey; Halmos, P.R., The legend of John von Neumann (1973) Am Math Mon, 80, pp. 382-394; Legg, S., Hutter, M., Universal intelligence: a definition of machine intelligence (2007) Mind Mach, 17, p. 391; Levesque, H.J., On our best behaviour (2014) Artif Intell, 212, p. 27; Levesque, H.J., Davis, E., Morgenstern, L., The Winograd schema challenge (2011) AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning; Luger, G.F., Chakrabarti, C., From Alan Turing to modern AI: practical solutions and an implicit epistemic stance (2017) AI Soc, 32, p. 321; Markowitz, D.M., Hancock, J.T., Linguistic traces of a scientific fraud: the case of diederik stapel (2014) PLoS One, 9; Oppy, G., Dowe, D., (2016) The Turing test, the Stanford encyclopedia of philosophy, , https://plato.stanford.edu/archives/spr2016/entries/turing-test/, In: Zalta EN (ed), Accessed 15 Aug 2017; Silver, D., Mastering the game of Go with deep neural networks and tree search (2016) Nature, 529, p. 484; Tesla, N., (1937) A machine to end war, PBS.org, , https://www.pbs.org/tesla/res/res_art11.html, Viereck GS (ed), Accessed 10 Sept 2017; Turing, A., Computing machinery and intelligence (1950) Mind, 59, p. 433; Warwick, K., Shah, H., Can machines think? A report on Turing test experiments at the Royal Society (2016) J Expt Theo AI, 28, p. 989; Warwick, K., Shah, H., The importance of a human viewpoint on computer natural language capabilities: a Turing test perspective (2016) AI Soc, 31, p. 207; Warwick, K., Shah, H., Effects of lying in practical Turing tests (2016) AI Soc, 31, p. 5; Wu, Y., (2016) Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation; Warwick, K., Shah, H., Taking the fifth amendment in Turing’s imitation game (2016) J Expt Theor AI, 29, p. 1},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sandewall2019,
author={Sandewall, E.},
title={Ethics, Human Rights, the Intelligent Robot, and its Subsystem for Moral Beliefs},
journal={International Journal of Social Robotics},
year={2019},
doi={10.1007/s12369-019-00540-z},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078876418&doi=10.1007%2fs12369-019-00540-z&partnerID=40&md5=7aa2798b86cb0db8bac122ddbfdc3048},
abstract={The Universal Declaration of Human Rights specifies a number of properties that characterize human beings, such as ‘dignity’, ‘conscience’, and several others. In this article we focus on these properties and on how they have been defined in the history of philosophy. We show how they can be interpreted in terms of a prototypical architecture for an intelligent robot, and how the robot can be provided with several aspects of ethical capability in this way. The key idea is to provide the robot with a Moral Belief System that cooperates with, and moderates the robot’s capability of planning and action. © 2019, The Author(s).},
author_keywords={Giovanni Pico della Mirandola;  Immanuel Kant;  Moral belief state;  Robot ethics;  Universal Declaration of Human Rights},
keywords={Ethical aspects;  Robot programming;  Social aspects, Giovanni Pico della Mirandola;  Human rights;  Immanuel Kant;  Moral belief state;  Robot ethics, Intelligent robots},
references={(1948) Universal Declaration of Human Rights, , http://www.un.org/en/universal-declaration-human-rights/index.html; della Mirandola, P.G., (1486/1496) Oration on the Dignity of Man, , De hominis dignitate; Kant, I., (1781) Critique of Pure Reason (Kritik Der Reinen Vernunft), , Riga; Kant, I., (1788) Critique of Practical Reason (Kritik Der Praktischen Vernunft), , Riga; A collection of documents Dag Hammarskjöld Library, , https://research.un.org/en/undhr/draftingcommittee; Asimov, I., (1950) I, Robot, , Gnome Press, New York; Anderson, M., Anderson, S.L., Machine ethics: creating an ethical intelligent agent (2007) AAAI Mag, 28 (4), p. 15; Hew, P.C., Artificial moral agents are infeasible with foreseeable technologies (2014) Ethics Inf Technol, 16 (3), pp. 197-206; Palmquist, S., (2010) Cultivating personhood: Kant and Asian philosophy, , (ed), De Gruyter, Berlin; Ghallab, M., Nau, D., Traverso, P., (2016) Automated planning and acting, , Cambridge University Press, Cambridge; Kant, I., (1785) Groundwork of the Metaphysics of Morals, pp. 53-74. , Gregor M, Cambridge University Press,, 9780521626958. OCLC 47008768; McCarthy, J., Free will—even for robots (2000) J Exp and Theor Artif Intell, 12 (3), pp. 341-352; (2002) Stanford Encyclopedia of Philosophy, , https://plato.stanford.edu/entries/compatibilism/, 2015; (2002) Stanford Encyclopedia of Philosophy, , https://plato.stanford.edu/entries/morality-definition/; Martins, J.P., Reinfrank, M., Truth maintenance systems (1990) Proceedings of the ECAI-90 Workshop, , Springer lecture notes in computer science; Johnson-Laird, P.N., Reasoning about inconsistency—list of Relevant Publications. Mental Models and Reasoning, , http://mentalmodels.princeton.edu/portfolio/reasoning-about-inconsistency/, Princeton University; Hallaq, W.B., (2012) The impossible state. Islam, politics, and modernity’s moral predicament, , Columbia University Press, New York; Danchin, P., Article 1: Fundamental Human Rights. a Page in a Website about the Universal Declaration of Human Rights, , http://ccnmtl.columbia.edu/projects/mmt/udhr/article_1/meaning.html; Taskhiri, M.-A., (1997) Human Rights: A Study of the Universal and the Islamic Declarations of Human Rights, p. 92. , http://alhassanain.org/english/?com=book&id=1153, Islamic Culture and Relations Organization, Alhassanain institute, Iran},
document_type={Article},
source={Scopus},
}

@ARTICLE{Smids2019,
author={Smids, J. and Nyholm, S. and Berkers, H.},
title={Robots in the Workplace: a Threat to—or Opportunity for—Meaningful Work?},
journal={Philosophy and Technology},
year={2019},
doi={10.1007/s13347-019-00377-4},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074848448&doi=10.1007%2fs13347-019-00377-4&partnerID=40&md5=c8cdd733272fe47fc18e52507c40a18b},
abstract={The concept of meaningful work has recently received increased attention in philosophy and other disciplines. However, the impact of the increasing robotization of the workplace on meaningful work has received very little attention so far. Doing work that is meaningful leads to higher job satisfaction and increased worker well-being, and some argue for a right to access to meaningful work. In this paper, we therefore address the impact of robotization on meaningful work. We do so by identifying five key aspects of meaningful work: pursuing a purpose, social relationships, exercising skills and self-development, self-esteem and recognition, and autonomy. For each aspect, we analyze how the introduction of robots into the workplace may diminish or enhance the meaningfulness of work. We also identify a few ethical issues that emerge from our analysis. We conclude that robotization of the workplace can have both significant negative and positive effects on meaningful work. Our findings about ways in which robotization of the workplace can be a threat or opportunity for meaningful work can serve as the basis for ethical arguments for how to—and how not to—implement robots into workplaces. © 2019, The Author(s).},
author_keywords={Meaningful work;  Meaningfulness;  Robot-ethics;  Robotization;  Robots;  The workplace},
references={Anteby, M., Nishani, S., (2016) Managerial role transitions for members of high reliability occupations, , &, (,).,., Presented at the 76th annual meeting of the academy of management,., Anaheim, CA; (2009) The Nicomachean ethics (revised edition; L. Brown, Ed.; D. Ross, trans.), , Oxford University Press, Oxford; Baumeister, R.F., Vohs, K.D., The pursuit of meaningfulness in life (2002) Handbook of positive psychology, pp. 608-618. , Snyder CR, Lopez SJ, (eds), Oxford University Press, Oxford; Bowie, N.E., A Kantian theory of meaningful work (1998) Journal of Business Ethics, 17 (9-10), pp. 1083-1092; Brynjolfsson, E., McAfee, A., (2016) The second machine age: work, progress, and prosperity in a time of brilliant technologies (1 edition), , W. W. Norton & Company, New York; Bryson, J.J., (2010) Robots should be slaves. In Y. Wilks (Ed.), Close engagements with artificial companions: key social, psychological, ethical and design issues (pp. 63–74), , https://researchportal.bath.ac.uk/en/publications/robots-should-be-slaves, (,).,., Retrieved from; Burrell, J., How the machine ‘thinks’: understanding opacity in machine learning algorithms (2016) Big Data & Society, 3 (1). , 2053951715622512; Carpenter, J., (2016) Culture and human-robot interaction in militarized spaces: a war story (1 edition), , Routledge, Burlington; Cascio, W.F., Montealegre, R., How technology is changing work and organizations (2016) Annual Review of Organizational Psychology and Organizational Behavior, 3 (1), pp. 349-375; Coeckelbergh, M., Robot rights? Towards a social-relational justification of moral consideration (2010) Ethics and Information Technology, 12 (3), pp. 209-221; Danaher, J., Will life be worth living in a world without work? Technological unemployment and the meaning of life (2017) Science and Engineering Ethics, 23 (1), pp. 41-64; Danaher, J., (2018) Programmed to love: is a human-robot relationship wrong? – John Danaher | aeon essays. Retrieved 5 April 2019, from Aeon website, , https://aeon.co/essays/programmed-to-love-is-a-human-robot-relationship-wrong; Danaher, J., Welcoming robots into the moral circle: a defence of ethical behaviourism (2019) Science and Engineering Ethics, , (,).,.,., https://doi.org/10.1007/s11948-019-00119-x; Deci, E.L., Ryan, R.M., The ‘what’ and ‘why’ of goal pursuits: human needs and the self-determination of behavior (2000) Psychological Inquiry, 11 (4), pp. 227-268; Deci, E.L., Ryan, R.M., Self-determination theory: a macrotheory of human motivation, development, and health (2008) Canadian Psychology/Psychologie Canadienne, 49 (3), pp. 182-185; Decker, M., Fischer, M., Ott, I., Service robotics and human labor: a first technology assessment of substitution and cooperation (2017) Robotics and Autonomous Systems, 87, pp. 348-354; Esteva, A., Kuprel, B., Novoa, R.A., Ko, J., Swetter, S.M., Blau, H.M., Thrun, S., Dermatologist-level classification of skin cancer with deep neural networks (2017) Nature, 542 (7639), pp. 115-118; Ford, M., (2016) Rise of the robots: technology and the threat of a jobless future (Reprint edition), , Basic Books, New York; Garber, M., (2013) Funerals for fallen robots. Retrieved 7 December 2018, from The Atlantic website, , https://www.theatlantic.com/technology/archive/2013/09/funerals-for-fallen-robots/279861/; Gheaus, A., Herzog, L., The goods of work (other than money!) (2016) Journal of Social Philosophy, 47 (1), pp. 70-89; Grant, A.M., The significance of task significance: Job performance effects, relational mechanisms, and boundary conditions (2008) The Journal of Applied Psychology, 93 (1), pp. 108-124; Groom, V., Nass, C., Can robots be teammates? Benchmarks in human–robot teams (2007) Interaction Studies, 8 (3), pp. 483-500; Gunkel, D.J., (2018) Robot rights, , The MIT Press, Cambridge; Hackman, J.R., Oldham, G.R., Motivation through the design of work: test of a theory (1976) Organizational Behavior and Human Performance, 16 (2), pp. 250-279; Hicks, J.A., King, L.A., Positive mood and social relatedness as information about meaning in life (2009) The Journal of Positive Psychology, 4 (6), pp. 471-482; Honneth, A., (1996) The struggle for recognition: the moral grammar of social conflicts (1st MIT Press ed edition; J. Anderson, Trans.), , The MIT Press, Cambridge; Lambert, N.M., Stillman, T.F., Hicks, J.A., Kamble, S., Baumeister, R.F., Fincham, F.D., To belong is to matter: sense of belonging enhances meaning in life (2013) Personality and Social Psychology Bulletin, 39 (11), pp. 1418-1427; Landau, I., (2017) Finding meaning in an imperfect world (1 edition), , Oxford University Press, New York; Lanzing, M., The transparent self (2016) Ethics and Information Technology, 18 (1), pp. 9-16; Lepisto, D.A., Pratt, M.G., Meaningful work as realization and justification: toward a dual conceptualization (2017) Organizational Psychology Review, 7 (2), pp. 99-121; Lysova, E.I., Allan, B.A., Dik, B.J., Duffy, R.D., Steger, M.F., Fostering meaningful work in organizations: a multi-level review and integration (2019) Journal of Vocational Behavior, 110, pp. 374-389; Madden, C., Bailey, A., What makes work meaningful — or meaningless (2016) MIT Sloan Management Review, 57 (4), pp. 52-61; Martela, F., Pessi, A.B., Significant work is about self-realization and broader purpose: defining the key dimensions of meaningful work (2018) Frontiers in Psychology, 9. , &, (,).,.,., https://doi.org/10.3389/fpsyg.2018.00363; Martela, F., Riekki, T.J.J., Autonomy, competence, relatedness, and beneficence: a multicultural comparison of the four pathways to meaningful work (2018) Frontiers in Psychology, 9. , &, (,).,.,., https://doi.org/10.3389/fpsyg.2018.01157; Mindell, D.A., (2015) Our robots, ourselves: robotics and the myths of autonomy, , Viking, New York; Mittelstadt, B.D., Allo, P., Taddeo, M., Wachter, S., Floridi, L., The ethics of algorithms: mapping the debate (2016) Big Data & Society, 3 (2); Montani, F., Boudrias, J.-S., Pigeon, M., Employee recognition, meaningfulness and behavioural involvement: test of a moderated mediation model (2017) The International Journal of Human Resource Management, pp. 1-29; Nyholm, S. & Smids, J. (under review). Can a Robot be a Good Colleague?; Oshana, M., (2006) Personal autonomy in society (New edition edition), , Routledge, Aldershot; Pratt, M., Ashforth, B., Fostering meaningfulness in working and at work (2003) Positive organizational scholarship: foundations of a new discipline, pp. 309-327. , Cameron K, Dutton J, Quinn RE, (eds), Berrett-Koehler, San Francisco; Rawls, J., (1971) A theory of justice; Roessler, B., Meaningful work: arguments from autonomy* (2012) Journal of Political Philosophy, 20 (1), pp. 71-93; Rosso, B.D., Dekas, K.H., Wrzesniewski, A., On the meaning of work: a theoretical integration and review (2010) Research in Organizational Behavior, 30, pp. 91-127; Rothausen, T.J., Henderson, K.E., Meaning-based job-related well-being: exploring a meaningful work conceptualization of job satisfaction (2018) Journal of Business and Psychology, pp. 1-20. , &, (,).,., https://doi.org/10.1007/s10869-018-9545-x; Royakkers, L., van Est, R., (2015) Just ordinary robots: automation from love to war (1 edition), , CRC Press, Boca Raton; Ryan, R.M., Deci, E.L., (2004) Overview of self-determination theory. an organismic dialectical perspective. In Handbook of self-determination research. Rochester, NY: University of Rochester Press, , &; Ryff, C.D., Psychological well-being revisited: advances in the science and practice of eudaimonia (2014) Psychotherapy and Psychosomatics, 83 (1), pp. 10-28; Schwab, K., (2017) The fourth industrial revolution, , PENGUIN GROUP, London; Schwartz, A., Meaningful work (1982) Ethics, 92 (4), pp. 634-646; Seligman, M., (2010) Flourish: positive psychology and positive interventions. Presented at the the Tanner lectures on human values, the University of Michigan, , https://tannerlectures.utah.edu/_documents/a-to-z/s/Seligman_10.pdf, (,).,., Retrieved from, https://tannerlectures.utah.edu/_documents/a-to-z/s/Seligman_10.pdf; Senders, J.T., Arnaout, O., Karhade, A.V., Dasenbrock, H.H., Gormley, W.B., Broekman, M.L., Smith, T.R., Natural and artificial intelligence in neurosurgery: a systematic review (2018) Neurosurgery, 83 (2), pp. 181-192; Sharkey, A., Robots and human dignity: a consideration of the effects of robot care on the dignity of older people (2014) Ethics and Information Technology, 16 (1), pp. 63-75; Shaw, K., (2018) Global sales for industrial robots doubled over last five years, report says. Retrieved 27 March 2019, from Robotics Business Review website, , https://www.roboticsbusinessreview.com/news/global-sales-for-industrial-robots-doubled-over-last-five-years/; Sinnott-Armstrong, W., (2015) Consequentialism. In E. N. Zalta (Ed.), The Stanford Encyclopedia of Philosophy (winter 2015), , https://plato.stanford.edu/archives/win2015/entries/consequentialism/, (,).,., Retrieved from; Sparrow, R., Killer robots (2007) Journal of Applied Philosophy, 24 (1), pp. 62-77; Steger, M.F., Dik, B.J., Duffy, R.D., Measuring meaningful work: the work and meaning inventory (WAMI) (2012) Journal of Career Assessment, 20 (3), pp. 322-337; Tweedie, D., Recognizing skills and capacities (2010) Decent work and unemployment, , Bagusat C, Keenan WJF, Sedmak C, (eds), Verlag, Berlin; Veltman, A., (2016) Meaningful work (1 edition), , Oxford University Press, New York; Wang, D., Khosla, A., Gargeya, R., Irshad, H., Beck, A.H., (2016) Deep learning for identifying metastatic breast cancer, , https://arxiv.org/abs/1606.05718, &, (,).,., Retrieved from; Ward, S.J., King, L.A., Work and the good life: how work contributes to meaning in life (2017) Research in Organizational Behavior, 37, pp. 59-82; Wingfield, N., (2017) As Amazon pushes forward with robots, workers find new roles. The New York Times, , https://www.nytimes.com/2017/09/10/technology/amazon-robots-workers.html, (,).,., Retrieved from; Wolf, S., Macedo, S., Koethe, J., Adams, R.M., Arpaly, N., Haidt, J., (2010) Meaning in life and why it matters: (STU-student edition), , http://www.jstor.org/stable/j.ctt7t3cm, &, (,).,., Retrieved from; Wrzesniewski, A., Dutton, J.E., Crafting a job: revisioning employees as active crafters of their work (2001) Academy of Management Review, 26 (2), pp. 179-201; Wrzesniewski, A., McCauley, C., Rozin, P., Schwartz, B., Jobs, careers, and callings: people’s relations to their work (1997) Journal of Research in Personality, 31 (1), pp. 21-33},
document_type={Article},
source={Scopus},
}

@ARTICLE{Boyles2020505,
author={Boyles, R.J.M. and Joaquin, J.J.},
title={Why friendly AIs won’t be that friendly: a friendly reply to Muehlhauser and Bostrom},
journal={AI and Society},
year={2020},
volume={35},
number={2},
pages={505-507},
doi={10.1007/s00146-019-00903-0},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069702538&doi=10.1007%2fs00146-019-00903-0&partnerID=40&md5=747cd286c8c80ac29c71a497aa1a6eab},
abstract={In “Why We Need Friendly AI”, Luke Muehlhauser and Nick Bostrom propose that for our species to survive the impending rise of superintelligent AIs, we need to ensure that they would be human-friendly. This discussion note offers a more natural but bleaker outlook: that in the end, if these AIs do arise, they won’t be that friendly. © 2019, Springer-Verlag London Ltd., part of Springer Nature.},
author_keywords={Counterfactual reasoning;  Friendly AI;  Machine ethics;  Superintelligence},
keywords={Counterfactual reasoning;  Human-friendly;  Superintelligence},
references={Goertzel, B., Should humanity build a global AI nanny to delay the singularity until it’s better understood? (2012) J Conscious Stud, 19 (1-2), pp. 96-111; Muehlhauser, L., Bostrom, N., Why we need friendly AI (2014) Think, 13 (36), pp. 41-47; Pfeifer, R., Scheier, C., (1999) Understanding intelligence, , MIT Press, Cambridge; Restall, G., Russell, G., Barriers to consequence (2010) Hume on is and ought, pp. 243-259. , Pigden C, (ed), Palgrave Macmillan, Basingstoke},
document_type={Article},
source={Scopus},
}

@ARTICLE{Trussell20181774,
author={Trussell, H.J.},
title={Why a Special Issue on Machine Ethics},
journal={Proceedings of the IEEE},
year={2018},
volume={106},
number={10},
pages={1774-1776},
doi={10.1109/JPROC.2018.2868336},
art_number={8472909},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054366195&doi=10.1109%2fJPROC.2018.2868336&partnerID=40&md5=5b66aea3f5eb004a2b38b3ea5ef7e6a2},
abstract={In early 2019, the PROCEEDINGS OF THE IEEE will publish a Special Issue on Building Ethical Autonomous Systems. This topic is a departure from the usual reviews and surveys of highly technical and mathematical areas on the cutting edge of electrical and computer engineering research. You may have to search for the equations in this issue, but the logic can be challenging. The ethical questions that are addressed, while framed as dealing with autonomous systems, are important and applicable to dealing with all research areas under the IEEE umbrella. The methods of addressing these questions draw mainly from artificial intelligence and machine learning. © 1963-2012 IEEE.},
keywords={Artificial intelligence, Autonomous systems;  Cutting edges;  Electrical and computer engineering;  Ethical question;  On-machines, Philosophical aspects},
references={Minsky, M., Papert, S.A., (1972) Perceptrons: An Introduction to Computational Geometry, , 2nd ed. Cambridge, MA, USA: MIT Press; Anderson, M., Anderson, S., Berenz, V., A value-driven eldercare robot: Virtual and physical instantiations of a case-supported principle-based behavior paradigm Proc. IEEE, , to be published; Ema, A., Clarifying privacy, property, and power: Case study on value conflict of a fan fiction research paper Proc. IEEE, , to be published; Korunovska, J., Spiekermann, S., Langheinrich, M., Inside the organization: Why privacy and security engineering is a challenge for engineers Proc. IEEE, , to be published; https://www.brookings.edu/blog/techtank/2018/07/23/brookings-surveyfinds-only-21-percent-willing-to-ridein-a-selfdriving-car/},
document_type={Review},
source={Scopus},
}

@ARTICLE{Grinbaum2018353,
author={Grinbaum, A.},
title={Chance as a value for artificial intelligence},
journal={Journal of Responsible Innovation},
year={2018},
volume={5},
number={3},
pages={353-360},
doi={10.1080/23299460.2018.1495032},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054184831&doi=10.1080%2f23299460.2018.1495032&partnerID=40&md5=aa147ab526c134bd575e76b8b8a9ce2c},
abstract={Deep learning techniques lead to fundamentally non-interpretable decisions made by the machine. Although such choices do not have an explanation, they impact the users in significant ways. If the ultimate innovator is a machine, what is the meaning of responsible conduct? I argue in a recent book that the capacity to extract an AI system from human judgment, by reducing transparency in favor of opacity, is an essential value in machine ethics. This can be achieved through the use of randomness, as illustrated with the example of the trolley dilemma. Methodologically, a comparison of common motives between technological setups and mythological narratives is used to achieve ethical insights. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={Artificial intelligence;  chance;  ethics;  myth},
references={(2017), Advisory Board on Artificial Intelligence and Human Society (Cabinet Office, Government of Japan), Report on Artificial Intelligence and Human Society; Bonnefon, J.-F., Shariff, A., Rahwan, I., The Social Dilemma of Autonomous Vehicles (2016) Science, 352, pp. 1573-1576; Bonnemains, V., Saurel, C., Tessier, C., Embedded Ethics: Some Technical and Ethical Challenges (2018) Ethics and Information Technology, 20, pp. 41-58; (2017) Report on Ethical Questions in Machine Learning, , cerna-ethics-allistene.org; Ethically Aligned Design: A Vision for Prioritizing Human Wellbeing with Artificial Intelligence and Autonomous Systems The IEEE Global Initiative for Ethical Considerations in Artificial Intelligence and Autonomous Systems, pp. 2016-2017; Ethik-Kommission Automatisiertes und Vernetztes Fahren (2017) Report Commission by the Bundesminister für Verkehr Und Digitale Infrastruktur, , www.bmvi.de; Foot, P., (1978) The Problem of Abortion and the Doctrine of the Double Effect in Virtues and Vices, , Oxford: Blackwell; Grinbaum, A., (2017) - (Machina Delatrix), , St Petersburg: Translit Машина доносчица; Grinbaum, A., Satanas Ex Machina: L’intelligence Artificielle Saisie par le Mythe, , Paris: Desclée de Brouwer, (in print; Grinbaum, A., Groves, C., What is “Responsible” About Responsible Innovation? Understanding the Ethical Issues (2013) Responsible Innovation: Managing the Responsible Emergence of Science and Innovation in Society, pp. 119-142. , Owen R., Bessant J., Heintz M., (eds), New York: Wiley, and,. edited by; Hanley, W., When did Egyptians Stop Being Ottomans? An Imperial Citizenship Case Study (2013) Multilevel Citizenship, pp. 89-109. , Maas W., (ed), Philadelphia: University of Pennsylvania Press,. edited by; Leben, D., A Rawlsian Algorithm for Autonomous Vehicles (2017) Ethics of Information Technology, 19, pp. 107-115; (2018) The Future Computed: Artificial Intelligence and Its Role in Society, p. 75. , Redmond: Microsoft Corporation; Monod, J., (1971) Chance and Necessity: An Essay on the Natural Philosophy of Modern Biology, , New York: Alfred A. Knopf; (2015), Research Priorities for Robust and Beneficial Artificial Intelligence: An Open Letter, Future of Life Institute; Self-driving Mercedes-Benzes Will Prioritize Occupant Safety over Pedestrians (2016) Car and Driver; The Malicious Use of Artificial Intelligence: Forecasting, Prevention and Mitigation (2018) Report by the Future of Humanity Institute (University of Oxford), Centre for the Study of Existential Risk (University of Cambridge), Center for a New American Security, , Electronic Frontier Foundation, and OpenAI; (2017) Report of COMEST on Robotics Ethics, , http://www.unesco.org},
document_type={Review},
source={Scopus},
}

@CONFERENCE{Rolf2018204,
author={Rolf, M. and Crook, N. and Steil, J.},
title={From social interaction to ethical AI: A developmental roadmap},
journal={2018 Joint IEEE 8th International Conference on Development and Learning and Epigenetic Robotics, ICDL-EpiRob 2018},
year={2018},
pages={204-211},
doi={10.1109/DEVLRN.2018.8761023},
art_number={8761023},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064513268&doi=10.1109%2fDEVLRN.2018.8761023&partnerID=40&md5=4b62cb31179438eb854cbffac912132b},
abstract={AI and robot ethics have recently gained a lot of attention because adaptive machines are increasingly involved in ethically sensitive scenarios and cause incidents of public outcry. Much of the debate has been focused on achieving highest moral standards in handling ethical dilemmas on which not even humans can agree, which indicates that the wrong questions are being asked. We suggest to address this ethics debate strictly through the lens of what behavior seems socially acceptable, rather than idealistically ethical. Learning such behavior puts the debate into the very heart of developmental robotics. This paper poses a roadmap of computational and experimental questions to address the development of socially acceptable machines. We emphasize the need for social reward mechanisms and learning architectures that integrate these while reaching beyond limitations of plain reinforcement-learning agents. We suggest to use the metaphor of 'needs' to bridge rewards and higher level abstractions such as goals for both communication and action generation in a social context. We then suggest a series of experimental questions and possible platforms and paradigms to guide future research in the area. © 2018 IEEE.},
keywords={Intelligent agents;  Philosophical aspects;  Robotics, Developmental robotics;  Ethical dilemma;  Higher-level abstraction;  Learning architectures;  Plain reinforcement;  Social context;  Social interactions;  Through the lens, Reinforcement learning},
references={Bostrom, N., (2014) Superintelligence: Paths, Dangers, Strategies; Senne, S., (2017) For Driverless Cars, A Moral Dilemma: Who Lives and Who Dies, , https://www.nbcnews.com/tech/innovation/driverless-cars-moraldilemma-who-lives-who-dies-n708276; Brooks, R., The seven deadly sins of ai predictions (2017) MIT Technology Review, 120 (6), pp. 79-86; Wallach, W., Allen, C., (2008) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press; Duffy, B.R., Fundamental issues in social robotics (2006) International Review of Information Ethics, 6 (12); Deigh, J., (2010) An Introduction to Ethics, , Cambridge University Press; Dennis, L., Fisher, M., Slavkovik, M., Webster, M., Formal verification of ethical choices in autonomous systems (2016) Robotics and Autonomous Systems, 77, pp. 1-14. , http://www.sciencedirect.com/science/article/pii/S0921889015003000; Kasperson, R.E., Renn, O., Slovic, P., Brown, H.S., Emel, J., Goble, R., Kasperson, J.X., Ratick, S., The social amplification of risk: A conceptual framework (1988) Risk Analysis, 8 (2), pp. 177-187; Otway, H.J., Von Winterfeldt, D., Beyond acceptable risk: On the social acceptability of technologies (1982) Policy Sciences, 14 (3), pp. 247-256; Bastide, S., Moatti, J.-P., Fagnani, F., Risk perception and social acceptability of technologies: The French case (1989) Risk Analysis, 9 (2), pp. 215-223; Lin, P., Tesla autopilot crash: Why we should worry about a single death (2016) IEEE Spectrum, , Jul; (2010) 12100: Safety of Machinery-general Principles for Design-risk Assessment and Risk Reduction (Iso 12100: 2010), , E. ISO; Casey, B., Amoral machines, or: How roboticists can learn to stop worrying and love the law (2016) Nw. UL Rev, 111, p. 1347; Walters, M.L., Dautenhahn, K., Te Boekhorst, R., Koay, K.L., Syrdal, D.S., Nehaniv, C.L., An empirical framework for human-robot proxemics (2009) New Frontiers in Human-Robot Interaction; Matsumoto, D., Hwang, H.C., Cultural similarities and differences in emblematic gestures (2013) Journal of Nonverbal Behavior, 37 (1), pp. 1-27; Kita, S., Ide, S., Nodding, aizuchi, and final particles in Japanese conversation: How conversation reflects the ideology of communication and social relationships (2007) Journal of Pragmatics, 39 (7), pp. 1242-1254; Malle, B.F., Scheutz, M., Austerweil, J.L., Networks of social and moral norms in human and robot agents (2017) A World with Robots, pp. 3-17. , Springer; Rolf, M., Crook, N., What if: Robots create novel goals? Ethics based on social value systems (2016) EDIA@ ECAI, pp. 20-25; Graham, J., Meindl, P., Beall, E., Johnson, K.M., Zhang, L., Cultural differences in moral judgment and behavior, across and within societies (2016) Current Opinion in Psychology, 8, pp. 125-130; Loftin, R., Peng, B., MacGlashan, J., Littman, M.L., Taylor, M.E., Huang, J., Roberts, D.L., Learning something from nothing: Leveraging implicit human feedback strategies (2014) Robot and Human Interactive Communication, 2014 RO-MAN: The 23rd IEEE International Symposium On. IEEE, pp. 607-612; Thomaz, A.L., Breazeal, C., Reinforcement learning with human teachers: Evidence of feedback and guidance with implications for learning performance (2006) AAAI, pp. 1000-1005; Fox, K., (2014) Watching the English: The Hidden Rules of English Behavior Revised and Updated, , Nicholas Brealey Publishing; Schultz, P.W., Nolan, J.M., Cialdini, R.B., Goldstein, N.J., Griskevicius, V., The constructive, destructive, and reconstructive power of social norms (2007) Psychological Science, 18 (5), pp. 429-434; Dodge, K.A., Lansford, J.E., Burks, V.S., Bates, J.E., Pettit, G.S., Fontaine, R., Price, J.M., Peer rejection and social informationprocessing factors in the development of aggressive behavior problems in children (2003) Child Development, 74 (2), pp. 374-393; Initiative, I.G., Ethically aligned design v2 (2018) IEEE Standards; Asada, M., MacDorman, K.F., Ishiguro, H., Kuniyoshi, Y., Cognitive developmental robotics as a new paradigm for the design of humanoid robots (2001) Robotics and Autonomous Systems, 37 (2-3), pp. 185-193; Lungarella, M., Metta, G., Pfeifer, R., Sandini, G., Developmental robotics: A survey (2003) Connection Science, 15 (4), pp. 151-190; Metta, G., Sandini, G., Vernon, D., Natale, L., Nori, F., The icub humanoid robot: An open platform for research in embodied cognition (2008) Proceedings of the 8th Workshop on Performance Metrics for Intelligent Systems. ACM, pp. 50-56; Gouaillier, D., Hugel, V., Blazevic, P., Kilner, C., Monceaux, J., Lafourcade, P., Marnier, B., Maisonnier, B., Mechatronic design of nao humanoid (2009) IEEE International Conference on Robotics and Automation (ICRA). IEEE, pp. 769-774; Fitzpatrick, P., Metta, G., Natale, L., Rao, S., Sandini, G., Learning about objects through action-initial steps towards artificial cognition (2003) IEEE International Conference on Robotics and Automation (ICRA), 3, pp. 3140-3145. , IEEE; Oudeyer, P.-Y., Kaplan, F., Hafner, V.V., Intrinsic motivation systems for autonomous mental development (2007) IEEE Trans. Evolutionary Computation, 11 (2), pp. 265-286; Rolf, M., Steil, J.J., Gienger, M., Goal babbling: A new concept for early sensorimotor exploration (2012) Proceedings of Workshop on Developmental Robotics; Teuliere, C., Forestier, S., Lonini, L., Zhang, C., Zhao, Y., Shi, B., Triesch, J., Self-calibrating smooth pursuit through active efficient coding (2015) Robotics and Autonomous Systems, 71, pp. 3-12; Johnson, M.H., Subcortical face processing (2005) Nature Reviews Neuroscience, 6 (10), p. 766; Viola, P., Jones, M.J., Robust real-time face detection (2004) International Journal of Computer Vision, 57 (2), pp. 137-154; Vouloumanos, A., Hauser, M.D., Werker, J.F., Martin, A., The tuning of human neonates preference for speech (2010) Child Development, 81 (2), pp. 517-527; Haigh, J., Mason, J., Robust voice activity detection using cepstral features (1993) IEEE Conference on Computer, Communication, Control and Power Engineering (TENCON), 3, pp. 321-324. , IEEE; Rolf, M., Hanheide, M., Rohlfing, K.J., Attention via synchrony: Making use of multimodal cues in social learning (2009) IEEE Transactions on Autonomous Mental Development, 1 (1), pp. 55-67; Emery, N.J., The eyes have it: The neuroethology, function and evolution of social gaze (2000) Neuroscience &Biobehavioral Reviews, 24 (6), pp. 581-604; Schillingmann, L., Nagai, Y., Yet another gaze detector: An embodied calibration free system for the iCub robot (2015) IEEE-RAS International Conference on Humanoid Robots (Humanoids). IEEE, pp. 8-13; Lohan, K.S., (2011) A Model of Contingency Detection to Spot Tutoring Behavior and Respond to Ostensive Cues in Human-robot-interaction, , Ph.D. dissertation, Bielefeld University; Nagai, Y., Kawai, Y., Asada, M., Emergence of mirror neuron system: Immature vision leads to self-other correspondence (2011) IEEE INT. Conf. Development and Learning (ICDL), 2, pp. 1-6. , IEEE; Asada, M., Towards artificial empathy (2015) International Journal of Social Robotics, 7 (1), pp. 19-33; Klucharev, V., Hytonen, K., Rijpkema, M., Smidts, A., Fernández, G., Reinforcement learning signal predicts social conformity (2009) Neuron, 61 (1), pp. 140-151; Isbell, C., Shelton, C.R., Kearns, M., Singh, S., Stone, P., A social reinforcement learning agent (2001) Proceedings of the Fifth International Conference on Autonomous Agents. ACM, pp. 377-384; Vamplew, P., Yearwood, J., Dazeley, R., Berry, A., On the limitations of scalarisation for multi-objective reinforcement learning of pareto fronts (2008) Australasian Joint Conference on Artificial Intelligence, pp. 372-378. , Springer; Seymour, B., Elfwing, S., Parallel reward and punishment control in humans and robots: Safe reinforcement learning using the maxpain algorithm (2017) IEEE Int. Conf. Development and Learning and Epigenetic Robotics (ICDL-EpiRob); Navarro-Guerrero, N., Lowe, R.J., Wermter, S., The effects on adaptive behaviour of negatively valenced signals in reinforcement learning (2017) IEEE Int. Conf. Development and Learning and Epigenetic Robotics (ICDL-EpiRob); Lones, J., Lewis, M., Canamero, L., From sensorimotor experiences to cognitive development:: How does experiential diversity influence the development of an epigenetic robot (2016) Frontiers in Robotics and AI; Rolf, M., Asada, M., What are goals? and if so, how many (2015) IEEE Int. Joint Conf. Development and Learning and Epigenetic Robotics (ICDL-EpiRob); Rolf, M., Asada, M., (2014) Where Do Goals Come From? A Generic Approach to Autonomous Goal-system Development, , http://arxiv.org/abs/1410.5557; Rolf, M., Asada, M., Autonomous development of goals: From generic rewards to goal and self detection (2014) IEEE Int. Joint Conf. Development and Learning and Epigenetic Robotics (ICDL-EpiRob); Vernon, D., Beetz, M., Sandini, G., Prospection in cognition: The case for joint episodic-procedural memory in cognitive robotics (2015) Frontiers in Robotics and AI, 2, p. 19; Soltoggio, A., Reinhart, F., Lemme, A., Steil, J., Learning the rules of a game: Neural conditioning in human-robot interaction with delayed rewards (2013) IEEE Int. Conf. Development and Learning and Epigenetic Robotics (ICDL-EpiRob). IEEE, pp. 1-6; Soltoggio, A., Lemme, A., Reinhart, F., Steil, J.J., Rare neural correlations implement robotic conditioning with delayed rewards and disturbances (2013) Frontiers in Neurorobotics, 7, p. 6; Muhl, C., Nagai, Y., Does disturbance discourage people from communicating with a robot (2007) IEEE Int. Symposium Robot and Human Interactive Communication (RO-MAN), pp. 1137-1142; Kozima, H., Michalowski, M.P., Nakagawa, C., Keepon (2009) International Journal of Social Robotics, 1 (1), pp. 3-18; Sen, S., Airiau, S., Emergence of norms through social learning (2007) IJCAI, 1507, p. 1512; Steels, L., The synthetic modeling of language origins (1997) Evolution of Communication, 1 (1), pp. 1-34; Spranger, M., (2016) The Evolution of Grounded Spatial Language, , Language Science Press; Kanda, T., Sato, R., Saiwaki, N., Ishiguro, H., A two-month field trial in an elementary school for long-term human-robot interaction (2007) IEEE Transactions on Robotics, 23 (5), pp. 962-971; Rheey, J., Method of Breeding Robot Pet Using On-line and Off-line Systems Simultaneously, , July 2002, uS Patent App. 09/808,119; Ackerman, E., Beatbots releasing $40 'my keepon' robot toy (2011) IEEE Spectrum},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Castell2018739,
author={Castell, S.},
title={The future decisions of RoboJudge HHJ Arthur Ian Blockchain: Dread, delight or derision?},
journal={Computer Law and Security Review},
year={2018},
volume={34},
number={4},
pages={739-753},
doi={10.1016/j.clsr.2018.05.011},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048703856&doi=10.1016%2fj.clsr.2018.05.011&partnerID=40&md5=a56cdc118b492fd14ebff86934c4fd63},
abstract={Steve Saxby's prescient founding of CLSR, two hundred issues ago, encouraged and resonated with my own digital visionary thinking and professional activity in the evolving field of ICT and the Law. From Infolex, the UK's first commercially-available computer-assisted legal information retrieval service, and my APPEAL Report (on the admissibility of computer evidence in court and the legal reliability/security of IT systems), via my Forensic Systems Analysis expert methodology, to the nascent CryptoBlockTV, Steve's scholarly foresight in promoting adventurous exploration of ‘digilaw’ high-ground topics and issues has presented me with opportunities to generate a stream of prescient material, for which I am immensely grateful. And what is beyond prescient today is that the Coming of the Robots is unstoppable. The Artificial Intelligence (AI) Age is upon us; RoboJudge has all but already arrived. While many are concerned about defining and developing Machine Ethics, Castell's Second Dictum: “You cannot construct an algorithm that will reliably decide whether or not any algorithm is ethical” reveals that this is a futile exercise. Algorithms are also pivotal to the current mania for Crypto-Algorithmic Blockchain Technology Initial Coin Offerings (ICOs), with a ‘Crypto Tribe’ of Millennials relentlessly raising billions in real money thereby, to the extent that I have dubbed Crypto the Millennials’ Rock'n'Roll. The seasoned ICT expert professional however bears in mind that there are as yet no ISO standards for blockchain, and there is far more to creating and delivering a complete quality-assured system than just the blockchain component. Furthermore, the legal status of cryptocurrency, smart contract and distributed ledger technology is not clear or uncontentious – and there is already ICO litigation on foot. Nevertheless, taking my limerick-writing Castell GhostWriteBot's advice, it is perhaps time for my own asset-linked ICO, to launch my CapChere.com concept designed to reboot Capitalism and achieve ubiquitous universal share and wealth ownership. Look out for Castell GhostWriteBot's account (with or without limericks) of how I fared, in the 400th issue of CLSR. © 2018 Stephen Castell},
author_keywords={Algorithm;  Blockchain;  Crypto;  Ethic;  Intelligence;  Robot},
keywords={Algorithms;  Computer aided analysis;  Computer hardware description languages;  Intelligent robots;  ISO Standards;  Laws and legislation;  Lime;  Philosophical aspects;  Reliability analysis;  Robots;  Safety devices;  Search engines;  Systems analysis, Computer assisted;  Computer evidence;  Crypto;  Ethic;  Intelligence;  Legal information retrieval;  Professional activities;  Smart contracts, Blockchain},
document_type={Article},
source={Scopus},
}

@ARTICLE{Thomson2018379,
author={Thomson, I. and Grubnic, S. and Georgakopolous, G.},
title={Review: Time machines, ethics and sustainable development: accounting for inter-generational equity in public sector organizations},
journal={Public Money and Management},
year={2018},
volume={38},
number={5},
pages={379-388},
doi={10.1080/09540962.2018.1477677},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047983879&doi=10.1080%2f09540962.2018.1477677&partnerID=40&md5=bea787cee5e4deafc9349e178e93e5d5},
abstract={This review paper explores the key challenges associated with effective inter-generational equity accounts in relation to the governance of public sector organizations and sustainable development transformations. Three different approaches to inter-generational equity accounting are evaluated and an outline for future research is provided. © 2018 CIPFA.},
author_keywords={Governance;  inter-generational equity;  sustainable development},
references={Attfield, R., Global warming, equity and future generations (2010) Human Ecology Review, 17 (2), pp. 102-105; Auerbach, A., Gokhale, J., Kotlikoff, L., Generational accounts: a meaningful alternative to deficit accounting (1991) Tax Policy and the Economy, pp. 55-110. , Bradford D., (ed), MIT Press, and,. In, (Ed); Auerbach, A., Gokhale, J., Kotlikoff, L., Generational accounting: a meaningful way to evaluate fiscal policy (1994) Journal of Economic Perspectives, 8 (1), pp. 73-94; Bebbington, J., Larrinaga, C., Accounting and sustainable development: an exploration (2014) Accounting, Organizations and Society, 39 (6), pp. 395-413; Bebbington, J., Russell, S., Thomson, I., Accounting and sustainable development: reflections and propositions (2017) Critical Perspectives on Accounting, 48, pp. 21-34; Bengston, V., Will ‘generational accounting’ doom the welfare state? (1993) Gerontologist, 33 (6), pp. 812-816; (2017) Implementing the Sustainable Development Goals; Cardarelli, R., Sefton, J., Kotlikoff, L., Generational accounting in the UK (2000) Economic Journal, 110 (467), pp. 547-574; Colquhoun, P., (2010) Inter-generational Equity in Municipal Accounting: New Zealand 1910s, , University of Wellington; Dasgupta, P., Mäler, K., Barrett, S., Inter-generational equity, social discount rates and global warming (1999) Discounting and Inter-generational Equity, , Portney P., Weyant J., (eds), Resources for the Future, and,. In, (Eds); Dunlop, S., Trebeck, K., (2012) The Oxfam Humankind Index for Scotland: The New Measure of Scotland’s Prosperity, , Oxfam, and; Esping-Andersen, G., Sarasa, S., The generational conflict reconsidered (2002) Journal of European Social Policy, 12, pp. 5-21; Gagné, A., (2016) The Index of Inter-generational Equity 2016, , Institute des Générations, Québec; Gray, R., Is accounting for sustainability actually accounting for sustainability … and how would we know? An exploration of narratives of organizations and the planet (2010) Accounting, Organisations and Society, 35 (1), pp. 47-62; Kohli, M., Aging and justice (2006) Handbook of Aging and the Social Sciences, pp. 456-478. , Binstock R., George L., (eds), Academic Press,. In, (Eds); Kohli, M., Generational equity: concepts and attitudes (2008) Pension Reform in Europe, pp. 196-214. , Arze C., Kohli M., (eds), Routledge,. In, (Eds); Lisenkovaa, K., Sanchez-Martineza, M., Seftond, J., (2015) The Sustainability of Scottish Public Finances: A Generational Accounting Approach, , National Institute of Economic and Social Research, and; Lyon, R., Amidharmo, R., (2016) Lies, damned lies and the 2015 Inter-generational Report, , Presented at Actuaries Institute conference, Reimagine the Future (Melbourne), and; Lyons, O., An Iroquois perspective (1994) American Indian Environments: Ecological Issues in Native American History, , Vecsey C., Venables R., (eds), Syracuse University Press,. In, (Eds); Norton, B., Ecology and opportunity: Inter-generational equity and sustainable options (1999) Fairness and Futurity, , Dobson A., (ed), Oxford University Press,. In, (Ed); Pallot, J., The legitimate concern with fairness: a comment (1991) Accounting, Organizations and Society, 16 (2), pp. 201-208; Piachaud, D., Macnicol, J., Lewis, J., (2016) A Think Piece on Inter-generational Equity, , London School of Economics, and; Povah, C., Vaukins, S., (2017) Generation Z is starting university—but is higher education ready?, , Guardian (10 July), and; Preston, S., Children and the elderly: divergent paths for America’s dependents (1984) Demography, 21, pp. 435-457; Rawls, J., (1972) A Theoryof Justice, , Oxford University Press; Robinson, M., Measuring compliance with the golden rule (1998) Fiscal Studies, 19 (4), pp. 447-462; Roemer, J., Suzumura, K., (2007) Inter-generational Equity and Sustainability, , Palgrave Macmillan, and; Russell, S., Thomson, I., Analysing the role of sustainable development indicators in accounting for and constructing a sustainable Scotland (2008) Accounting Forum, 33 (3), pp. 225-244; Stout, L., The corporation as time machine: inter-generational equity, inter-generational efficiency, and the corporate form (2015) Seattle University Law Review, 38, pp. 685-722; Thomson, I., Grubnic, S., Georgakopoulos, G., Exploring accounting-sustainability hybridisation in the UK public sector (2014) Accounting, Organizations and Society, 39 (6), pp. 453-476; (2015) 2030 Agenda for Sustainable Development, , http://www.un.org/sustainabledevelopment; Weiss, E., In fairness to future generations and sustainable development (1992) American University International Law Review, 8 (1), pp. 19-26; Willetts, D., (2010) The Pinch: How the Baby Boomers Took Their Children’s Future—and Why They Should give it Back, , Atlantic Books; Williamson, J., McNamara, T., Howling, S., Generational equity, generational interdependence and the framing of the debate over social security reform (2003) Journal of Sociology & Social Welfare, 30 (3), pp. 3-13; Williamson, J., Rhodes, A., A critical assessment of generational accounting and its contribution to the generational equity debate (2011) International Journal of Ageing and Later Life, 6 (1), pp. 33-57; (2017) Inter-generational Fairness—Third Report of Session 2016–17, , House of Commons},
document_type={Review},
source={Scopus},
}

@CONFERENCE{Poulsen2018293,
author={Poulsen, A. and Burmeister, O.K. and Tien, D.},
title={Care Robot Transparency Isn't Enough for Trust},
journal={2018 IEEE Region 10 Symposium, Tensymp 2018},
year={2018},
pages={293-297},
doi={10.1109/TENCONSpring.2018.8692047},
art_number={8692047},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065095697&doi=10.1109%2fTENCONSpring.2018.8692047&partnerID=40&md5=d9b7b4013a45c357058120ada9688f69},
abstract={A recent study featuring a new kind of care robot indicated that participants expect a robot's ethical decision-making to be transparent to develop trust, even though the same type of 'inspection of thoughts' isn't expected of a human carer. At first glance, this might suggest that robot transparency mechanisms are required for users to develop trust in robot-made ethical decisions. But the participants were found to desire transparency only when they didn't know the specifics of a human-robot social interaction. Humans trust others without observing their thoughts, which implies other means of determining trustworthiness. The study reported here suggests that the method is social interaction and observation, signifying that trust is a social construct. Moreover, that 'social determinants of trust' are the transparent elements. This socially determined behaviour draws on notions of virtue ethics. If a caregiver (nurse or robot) consistently provides good, ethical care, then patients can trust that caregiver to do so often. The same social determinants may apply to care robots and thus it ought to be possible to trust them without the ability to see their thoughts. This study suggests why transparency mechanisms may not be effective in helping to develop trust in care robot ethical decision-making. It suggests that roboticists need to build sociable elements into care robots to help patients to develop patient trust in the care robot's ethical decision-making. © 2018 IEEE.},
author_keywords={Healthcare robotics;  Human robot interaction;  Machine transparency;  Robot ethics},
keywords={Decision making;  Philosophical aspects;  Transparency, Ethical decision making;  Healthcare robotics;  Human robots;  Robot ethics;  Social interactions;  Transparency mechanism;  Virtue ethics, Human robot interaction},
references={Wortham, R.H., Theodorou, A., Bryson, J.J., What does the robot think? Transparency as a fundamental design requirement for intelligent systems (2016) IJCAI 2016 Ethics for AI Workshop, , New York Hilton Hotel; Theodorou, A., Wortham, R.H., Bryson, J.J., Designing and implementing transparency for real time inspection of autonomous robots (2017) Connection Science, 29, pp. 230-241; Wortham, R.H., Theodorou, A., Bryson, J.J., Improving robot transparency: Real-time visualisation of robot AI substantially improves understanding in naive observers (2017) IEEE RO-MAN 2017, , Pestana Palace Hotel; Wortham, R.H., Theodorou, A., Bryson, J.J., Robot transparency: Improving understanding of intelligent behaviour for designers and users (2017) Cham, pp. 274-289; Burmeister, O.K., The development of assistive dementia technology that accounts for the values of those affected by its use (2016) Ethics and Information Technology, 18, pp. 185-198; Friedman, B., Hendry, D.G., Borning, A., A survey of value sensitive design methods (2017) Foundations and Trends® in Human-Computer Interaction, 11, pp. 63-125; Poulsen, A., Dynamic Value Trade-offs in Run-time to Provide Good, Customised Patient Care with Robots, , honours thesis, Charles Sturt University, 2018, honours thesis; Poulsen, A., Burmeister, O.K., Overcoming carer shortages with care robots: Dynamic value trade-offs in run-time (2018) Australasian Journal of Information Systems, 22; Morse, J.M., Confusing categories and themes (2008) Qualitative Health Research, 18, pp. 727-728; Burmeister, O.K., Weckert, J., Williamson, K., Seniors extend understanding of what constitutes universal values (2011) Journal of Information, Communication and Ethics in Society, 9, pp. 238-252; Van Den Hoven, J., Manders-Huits, N., Value-sensitive Design (2009) A Companion to the Philosophy of Technology, pp. 477-480. , J. K. B. Olsen, S. A. Perdersen, and V. F. Hendricks, Eds. West Sussex, UK: Wiley-Blackwell; Friedman, B., Grudin, J., Trust and accountability: Preserving human values in interactional experience (1998) Computer-Human Interaction '98 Conference Summary on Human Factors in Computing Systems, p. 213. , Los Angeles, CA, United States; Volkman, R., Being a good computer professional: The advantages of virtue ethics in computing (2013) Professionalism in the Information and Communication Technology Industry, pp. 109-126. , J. Weckert and R. Lucas, Eds.: ANU E Press; Hardin, R., Conceptions and explanations of trust (2001) Trust in Society, 2, pp. 3-39. , K. S. Cook, Ed. New York, NY, US: Russell Sage Foundation; Hearn, F., (1997) Moral Order and Social Disorder: The American Search for Civil Society, , New York: Aldine de Gruyter; Misztal, B., (1996) Trust in Modern Societies, , Cambridge: Polity; Schwerter, F., Zimmermann, F., Determinants of Trust: The Role of Personal Experiences, , unpublished; Beauchamp, T.L., Does ethical theory have a future in bioethics? (2004) The Journal of Law, Medicine &Ethics, 32, pp. 209-217; Upton, H., Moral theory and theorizing in health care ethics (2011) Ethical Theory and Moral Practice, 14, pp. 431-443; Tronto, J.C., Creating caring institutions: Politics, plurality, and purpose (2010) Ethics &Social Welfare, 4, pp. 158-171; Vallor, S., Carebots and caregivers: Sustaining the ethical ideal of care in the twenty-first century (2011) Philosophy &Technology, 24, pp. 251-268; Vanlaere, L., Gastmans, C., A personalist approach to care ethics (2011) Nursing Ethics, 18, pp. 161-173; Gámez, G.G., The nurse-patient relationship as a caring relationship (2009) Nursing Science Quarterly, 22, pp. 126-127; Mittelstadt, B.D., Allo, P., Taddeo, M., Wachter, S., Floridi, L., The ethics of algorithms: Mapping the debate (2016) Big Data &Society, 3, pp. 1-21; Turilli, M., Floridi, L., The ethics of information transparency (2009) Ethics and Information Technology, 11, pp. 105-112. , June 01; Burrell, J., How the machine 'thinks': Understanding opacity in machine learning algorithms (2016) Big Data &Society, 3, pp. 1-12; Hildebrandt, M., Who needs stories if you can get the data? ISPs in the era of big number crunching (2011) Philosophy &Technology, 24, pp. 371-390; Leese, M., The new profiling: Algorithms, black boxes, and the failure of anti-discriminatory safeguards in the European Union (2014) Security Dialogue, 45, pp. 494-511; Anderson, M., Anderson, S.L., GenEth: A general ethical dilemma analyzer (2014) AAAI Conference on Artificial Intelligence, , Quebec City, CA; Anderson, M., Anderson, S.L., Toward ensuring ethical behavior from autonomous systems: A case-supported principle-based paradigm (2015) Industrial Robot: An International Journal, 42, pp. 324-331; Shaw, N.P., Stockel, A., Orr, R.W., Lidbetter, T.F., Cohen, R., Towards provably moral AI agents in bottom-up learning frameworks (2018) AAAI/ACM Conference on Artificial Intelligence, , Ethics, and Society, New Orleans, USA},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Coeckelbergh201871,
author={Coeckelbergh, M.},
title={How to describe and evaluate “deception” phenomena: recasting the metaphysics, ethics, and politics of ICTs in terms of magic and performance and taking a relational and narrative turn},
journal={Ethics and Information Technology},
year={2018},
volume={20},
number={2},
pages={71-85},
doi={10.1007/s10676-017-9441-5},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031771687&doi=10.1007%2fs10676-017-9441-5&partnerID=40&md5=6893069774592993ff581a897da076c5},
abstract={Contemporary ICTs such as speaking machines and computer games tend to create illusions. Is this ethically problematic? Is it deception? And what kind of “reality” do we presuppose when we talk about illusion in this context? Inspired by work on similarities between ICT design and the art of magic and illusion, responding to literature on deception in robot ethics and related fields, and briefly considering the issue in the context of the history of machines, this paper discusses these questions through the lens of stage magic and illusionism, with the aim of reframing the very question of deception. It investigates if we can take a more positive or at least morally neutral view of magic, illusion, and performance, while still being able to understand and criticize the relevant phenomena, and if we can describe and evaluate these phenomena without recourse to the term “deception” at all. This leads the paper into a discussion about metaphysics and into taking a relational and narrative turn. Replying to Tognazzini, the paper identifies and analyses two metaphysical positions: a narrative and performative non-dualist position is articulated in response to what is taken to be a dualist, in particular Platonic, approach to “deception” phenomena. The latter is critically discussed and replaced by a performative and relational approach which avoids a distant “view from nowhere” metaphysics and brings us back to the phenomena and experience in the performance relation. The paper also reflects on the ethical and political implications of the two positions: for the responsibility of ICT designers and users, which are seen as co-responsible magicians or co-performers, and for the responsibility of those who influence the social structures that shape who has (more) power to deceive or to let others perform. © 2017, The Author(s).},
author_keywords={Deception;  Ethics;  ICTs;  Magic;  Performance;  Politics},
keywords={Computer games;  Machine design;  Ontology, Deception;  Ethics;  ICTs;  Magic;  Performance;  Politics, Philosophical aspects},
references={(2013) Benevolent deception in human computer interaction., , http://www.cond.org/deception.pdf, Adar, E., Tan, D. S., & Teevan, J. In CHI 2013, ACM (conference paper), April 27–May 2, 2013, Paris, France. Accessed February 4, 2017, from; Akrich, M., Latour, B., A summary of a convenient vocabulary for the semiotics of human and nonhuman assemblies (1992) Shaping technology/building society: Studies in sociotechnicalchange, pp. 259-264. , Bijker WE, Law J, (eds), MIT Press, Massachussetts; Ananthaswamy, A., Virtual reality could be an ethical minefield: Are we ready?. New Scientist, 4 March 2016. Accessed February 4, 2017 (2016) from, , https://www.newscientist.com/article/2079601-virtual-reality-could-be-an-ethical-minefield-are-we-ready/; Coeckelbergh, M., Virtual moral agency, virtual moral responsibility: on the moral significance of the appearance, perception, and performance of artificial agents (2009) AI and Society, 24 (2), pp. 181-189; Coeckelbergh, M., New romantic cyborgs: Romanticism, information technology, and the end of the machine (2017) Cambridge, , MA/London: The MIT Press; Bryson, J., Robots should be slaves (2010) Close engagements with artificial companions: Key social, psychological, ethical and design issues, pp. 63-74. , Wilks Y, (ed), John Benjamins, Amsterdam; Carpenter, J., (2016) Culture and human–robot interaction in militarized spaces: A war story, , Ashgate, New York; Coeckelbergh, M., (2012) Growing moral relations: Critique of moral status ascription, , Palgrave Macmillan, New York; Coeckelbergh, M., The moral standing of machines: Towards a relational and non-cartesian moral hermeneutics (2014) Philosophy & Technology, 27 (1), pp. 61-77; Coeckelbergh, M., Technology games: Using Wittgenstein for understanding and evaluating technology (2017) Science and Engineering Ethics, pp. 1-17; Coeckelbergh, M., Gunkel, D., Facing animals: A relational, other-oriented approach to moral standing (2014) Journal of Agricultural and Environmental Ethics, 27 (5), pp. 715-733; Coeckelbergh, M., Reijers, W., Narrative technologies: A philosophical investigation of narrative capacities of technologies by using Ricoeur’s narrative theory (2016) Human Studies, 39, pp. 325-346; Dreyfus, H., (1992) What computers still can’t do, , MIT Press, New York; Floridi, L., (2015) The onlife manifesto, , (ed), Springer, Cham; Flusser, V., (1999) Shape of things: A philosophy of design, , Reaction Books, London; Foucault, M., (1975) Discipline and punish: The birth of the prison, Trans. A. Sheridan, , Vintage Books/Random House, New York; Gell, A., The technology of enchantment and the enchantment of technology (1988) Anthropology, art and aesthetics, , Coote J, (ed), The Clarendon Press, Oxford; Kidd, C.D., Taggart, W., Turkle, S., A sociable robot to encourage social interaction among the elderly. In Proceedings of the 2006 IEEE International Conference on Robotics and Automation, Orlando, Florida (2006) May, 2006, pp. 3972-3976; Latour, B., We have never been modern. (trans: Porter (1993) C.) Cambridge, , Massachusetts: Harvard University Press; (2010) Deception and magic in collaborative interaction., , http://www.cs.nott.ac.uk/pszjm2/wp-content/uploads/2010/04/marshall-chi-deception.pdf, Marshall, J., Benford, S., & Pridmore, T. In CHI 2010: Performance, stagecraft, and magic, ACM (conference paper), Atlanta, GA, USA, April 10–15. Accessed February 4, 2017; Musial, M., Magical thinking and empathy towards robots (2016) What social robots can and should do. Proceedings of Robophilosophy 2016, pp. 347-355. , Seibt J, Nørskov M, Søren SA, (eds), IOS Press, Amsterdam; Pasquinelli, E., The illusion of reality: Cognitive aspects and ethical drawbacks: The case of second life (2010) Emerging ethical Issues of life in virtual worlds, , Wankel C, Malleck S, (eds), IAP, Charlotte, North Caroline; Pickering, A., (1995) The mangle of practice: Time, agency, and science, , University of Chicago Press, Chicago; Rowe, N.C., Deception in defense of computer systems from cyber-attack (2007) Cyber war and cyber terrorism, pp. 97-104. , Janczewski LJ, Colarik AM, (eds), Information Science Reference, New York; Scheutz, M., The inherent dangers of unidirectional emotional bonds between humans and social robots. In P. Lin, G. Bekey & K. Abney (Eds.), Robot ethics: The ethical and social implications of robotics (pp. 205–222). Cambridge (2011) MA, , London: MIT Press; Sharkey, N., Sharkey, A., The crying shape of robot nannies: An ethical appraisal (2010) Interaction Studies, 11 (2), pp. 161-190; Sparrow, R., Robots in aged care: A dystopian future? (2016) AI & Society, 31, pp. 445-454; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Minds and Machines, 16 (2), pp. 141-161; Sparrow, R., Harrison, R., Oakley, J., Keogh, B., Playing for fun, training for war: Can popular claims about recreational video gaming and military simulations be reconciled? Games and Culture. Published Online First (2015) November, 26, p. 2015; Sung, J.-Y., Guo, L., Grinter, R.E., Henrik, I.C., My Roomba is Rambo”: Intimate home appliances (2007) Proceedings of UbiComp 2007, LNCS 4717, Lecture notes in computer science 4717, pp. 145-162. , Krumm J, (ed), Springer, Berlin; (1993) Principles, techniques, and ethics of stage magic and their application to human interface design., , http://dl.acm.org/citation.cfm?id=169284, Tognazzini, B. In INTERCHI’93, ACM (conference paper), pp. 355–362. Accessed February 4, 2017, from; Turkle, S., In good company: On the threshold of robotic companions (2010) Close engagements with artificial companions, , Wilks Yorick, (ed), Basic Books, Amsterdam; Turkle, S., (2011) Alone together: Why we expect more from technology and less from each other, , New York: Basic Books},
document_type={Article},
source={Scopus},
}

@ARTICLE{VanDang2018,
author={Van Dang, C. and Jun, M. and Shin, Y.-B. and Choi, J.-W. and Kim, J.-W.},
title={Application of modified Asimov’s laws to the agent of home service robot using state, operator, and result (Soar)},
journal={International Journal of Advanced Robotic Systems},
year={2018},
volume={15},
number={3},
doi={10.1177/1729881418780822},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049994131&doi=10.1177%2f1729881418780822&partnerID=40&md5=dc4b38675f29e209e9d840a598f20299},
abstract={This study aims to interpret and apply Asimov’s Three Laws of Robotics to home service robots. An agent is developed herein with the ability to focus its attention on human beings’ health, particularly the elderly and the diseased, by delivering food. The agent is developed on a cognitive agent architecture, state, operator, and result (Soar), to enable effective reasoning and decision-making skills. This study deals with basic home care services, such as food delivery and emergency response; therefore, common food care and emergency rules are newly proposed based on the priority values that correspond to a family’s circumstances and/or emergency levels. Asimov’s Three Laws are modified to aid the home service robot to follow a predetermined order in selecting a food item or recommending an alternative food item suitable for its user’s prevailing health condition. Experimental results confirm that reasoning and decision-making of the proposed agent are logically and ethically valid for a home service robot and ensure compliance with both the original and modified Asimov’s Three Laws. © 2018, The Author(s) 2018.},
author_keywords={Asimov’s laws of robotics;  cognitive agent;  home service robot;  robot ethics;  Soar},
keywords={Decision making;  Intelligent agents;  Mobile robots;  Robotics, Cognitive agent architecture;  Cognitive agents;  Decision-making skills;  Emergency response;  Home service robot;  Home-care services;  Robot ethics;  Soar, Emergency services},
references={Wallach, W., Allen, C., (2008) Moral machines: teaching robots right from wrong, , Oxford, Oxford University Press; Mill, J.S., (2001) Utilitarianism, , Kitchener, Batoche Books; Kant, I., (2002) Groundwork for the metaphysics of morals, , New Haven and London, Yale University Press; Asimov, I., Runaround (1942) Astounding science fiction, pp. 94-103. , Campbell Jr. J.W., (ed), New York, USA, Street & Smith Publications, Inc, [Reprinted Ballantin Books, New York, 1983], In:, (ed; Gert, M., (1988) Morality, , Oxford, Oxford University Press; Gips, J., Towards the ethical robot (1995) Android epistemology, pp. 243-252. , Ford K.M., Glymour C., Hayes P., (eds), Cambridge, MA, USA, MIT Press, In:, (eds; Weng, Y.H., Chen, C.H., Sun, C.T., Safety intelligence and legal machine language: do we need the three laws of robotics? (2008) Service robot applications, pp. 195-214. , Takahashi Y., (ed), Vienna, InTech Education & Publishing, In:, (ed; Anderson, M., Anderson, S.L., (2011) Machine ethics, , Cambridge, Cambridge University Press; After 75 years, Isaac Asimov’s Three Laws of Robotics need updating, 2017, , http://theconversation.com/after-75-years-isaac-asimovs-three-laws-of-robotics-need-updating-74501, accessed 31 July 2017; (2014) Do we need Asimov’s laws?, , https://www.technologyreview.com/s/527336/do-we-need-asimovs-laws/, accessed 31 July 2017; Executive Summary World Robotics 2016 Service Robots, , https://ifr.org/free-downloads/, accessed 31 July 2017; Gautam, R., Gedam, A., Zade, A., Review on development of industrial robotic arm (2017) Int Res J Eng Tech, 4 (3), pp. 1752-1755; Iqbal, J., Khan, Z.H., Khalid, A., Prospects of robotics in food industry (2017) Food Sci Tech, 37 (2), pp. 159-165; Hans, M., Graf, B., Schraft, R.D., Robotic home assistant Care-O-bot: past-present-future, pp. 380-385. , Proceedings of the 2002 IEEE, international workshop on robot and human interactive communication, Berlin, Germany, IEEE, In; Hsu, S.C., Huang, H.H., Huang, C.L., Facial expression recognition for human-robot interaction, pp. 1-7. , 2017 First IEEE international conference on robotic computing (IRC), Taichung, Taiwan, IEEE, In; Ge, S.S., Wang, C., Hang, C.C., Facial expression imitation in human robot interaction, pp. 213-218. , RO-MAN 2008-The 17th IEEE international symposium on robot and human interactive communication, Munich, IEEE, In; Sial, S.B., Sial, M.B., Ayaz, Y., Interaction of robot with humans by communicating simulated emotional states through expressive movements (2016) Int Ser Robot, 9 (3), pp. 231-255; Ju, M.H., Kang, H.B., Emotional interaction with a robot using facial expressions, face pose and hand gestures (2012) Int J Adv Robot Syst, 9 (95), pp. 1-13; Van Wynsberghe, A., Service robots, care ethics, and design (2016) Ethic Inf Technol, 18 (4), pp. 311-321; Trafton, J.G., Hiatt, L.M., Harrison, A.M., ACT-R/E: an embodied cognitive architecture for human-robot interaction (2013) J Hum Robot Interact, 2 (1), pp. 30-35; Beetz, M., Mösenlechner, L., Tenorth, M., CRAM—A cognitive robot abstract machine for everyday manipulation in human environments, pp. 1012-1017. , IEEE/RSJ international conference on intelligent robots and systems, Taipei, Taiwan, IEEE, In; Kelley, T.D., Developing a psychologically inspired cognitive architecture for robotic control: the symbolic and subsymbolic robotic intelligence control system (SS-RICS) (2006) Int J Adv Robot Syst, 3 (3), pp. 219-222; Laird, J.E., (2012) The Soar cognitive architecture, , Cambridge, MA, USA, MIT Press; (2017) RiveScript, , https://www.rivescript.com, accessed 31 July 2017; Dang, C.V., Tran, T.T., Pham, T.X., Implementation of a refusable human-robot interaction task with humanoid robot by connecting Soar and ROS (2017) J Korea Robot Soc, 12 (1), pp. 55-64; Quigley, M., Gerkey, B., Smart, W.D., (2015) Programming robots with ROS, , USA, O’Reilly Media; Bugmann, G., Copleston, S.N., What can a personal robot do for you?, pp. 360-371. , Proceedings of the 12th annual conference on towards autonomous robotic systems, Sheffield, UK, Berlin, Springer-Verlag, In; Biswas, J., Veloso, M., Multi-sensor mobile robot localization for diverse environments (2014) RoboCup 2013: Robot World Cup XVII, pp. 468-479. , Behnke S., (ed), Berlin, Heidelberg, Springer-Verlag, In:, (eds; Lee, Y.S., Lim, H.S., Ahn, H.S., (2011) Nutrition through the life cycle, , 3rd ed, Korea, Kyomunsa, Chapter 2},
document_type={Article},
source={Scopus},
}

@ARTICLE{Hauer2018100,
author={Hauer, T.},
title={Society and the Second Age of Machines: Algorithms Versus Ethics},
journal={Society},
year={2018},
volume={55},
number={2},
pages={100-106},
doi={10.1007/s12115-018-0221-6},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042107172&doi=10.1007%2fs12115-018-0221-6&partnerID=40&md5=bc9ecc6b89f1df24747c8744608ff525},
abstract={The term “Second Machine Age” was used by Erik Brynjolfsson and Andrew McAfee in their book of the same name as an indication of the impact of AI technology on people, society, and the economy. The term seeks to analyse the age we actually live in, its hidden patterns, which jobs and fields of study have a perspective, and which do not. It is about the second industrial revolution that is going on right now, and it changes the world no less radically than the first one, driven by the steam locomotive. Exponential growth of digital technologies, digitization of everything and recombinant innovation is a driving engine and fuel of the Second Machine Age. However, the ethical issues of this change remain unaddressed. Artificial intelligence is currently being dealt with by a great many scientists and philosophers who ask many questions. The most important questions are whether the machines can think, whether we will give them the copyright, which the animals do not have until now, and the question whether AI can has its own ethics. The study focuses on these issues, and uses concrete examples to show our unpreparedness for these topics. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
author_keywords={Artificial intelligence;  Computer functionalism;  Ethical problem in robotics;  Machine ethics;  Moral dilemmas;  Second machine age},
references={Anderson, M., Anderson, S., (2011) Machine Ethics, , Cambridge University Press, Cambridge; Asimov, I., (2008) I, Robot, , Spectra Books: Reprint edition; Boddington, P., (2017) Towards a Code of Ethics for Artificial Intelligence (Artificial Intelligence: Foundations, Theory, and Algorithms), , 1st ed., Springer; Bonnefon, J., Shariff, A., Rahwan, I., Autonomous vehicles need experimental ethics: Are we ready for utilitarian cars? (2015) Science, 352 (6293), pp. 1573-1576; Brynjolfsson, E., McAfee, A., (2016) The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies, , New York, W. W. Norton & Company; Carter, M., (2007) Minds and Computers: An Introduction to the Philosophy of Artificial Intelligence, , Edinburgh, Edinburgh University Press; Dreyfus, H., (1992) What Computers Still Can’t Do, , MIT Press, New York; Erbas, M.D., Bull, L., Winfield, A.F., On the evolution of behaviors through embodied imitation (2015) Artificial Life, 21 (2). , https://doi.org/10.1162/ARTL_a_00164; Finn, E., (2017) What Algorithms Want: Imagination in the Age of Computing, , MIT Press; Kurzweil, R., (2005) The Singularity is Near: When Humans Transcend Biology, , Viking, New York; Li, D., Du, Y., (2007) Artificial Intelligence with Uncertainty, , CRC Press, Boca Raton; Lin, P., Abney, K., Bekey, G., (2012) Robot Ethics: The Ethical and Social Implications of Robotics, , MIT Press, Cambridge; Minsky, M., (1988) Society of Mind, , Simon & Schuster, New York; Oliveira, A., (2017) The Digital Mind: How Science is Redefining Humanity, , MIT Press; Penrose, R., (1996) Shadows of the Mind: A Search for the Missing Science of Consciousness, , Oxford University Press, Oxford; Wallach, W.A., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press, Oxford; Warwick, K., (2011) Artificial Intelligence: the Basics, , London:Routledge},
document_type={Note},
source={Scopus},
}

@CONFERENCE{Poulsen2018,
author={Poulsen, A. and Burmeister, O.K. and Tien, D.},
title={A new design approach and framework for elderly care robots},
journal={ACIS 2018 - 29th Australasian Conference on Information Systems},
year={2018},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071683888&partnerID=40&md5=fd1f68c189b711900689fed061c8dce1},
abstract={A relatively new area within information systems is the design of robotic healthcare. This narrative review considers the question, how does one ethically design an elderly care robot? To answer this question, robot ethicists consider the ethical impact of robots, how designers ought to design robots ethically, and how a robot design ought to be, so its behaviour is ethical. The latter consideration defines another field of study, machine ethics. Machine ethicists ask, how does one design a robot information system to behave ethically? Thus, robot ethics is concerned with the ethics of design practice, whereas machine ethics is concerned with the ethics of the product designed. The findings from this narrative review point the way forward to how one can answer both questions with a new design approach that is grounded in care and professional ethics, value sensitive design, and the integration of two machine ethics schools of thought. © 2018 Adam Poulsen, Oliver K. Burmeister, and David Tien.},
author_keywords={Care;  DSR;  Ethics;  Robot;  Systems},
keywords={Computer systems;  Information systems;  Information use;  Medical computing;  Philosophical aspects;  Product design;  Robots, Care;  Design approaches;  Design practice;  Ethics;  Professional ethics;  Robot designs;  Two machines;  Value sensitive design, Machine design},
references={Abras, C., Maloney-Krichmar, D., Preece, J., User-centered design (2004) Encyclopedia of Human-Computer Interaction, , W. Bainbridge (ed.). Thousand Oaks: Sage Publications; Alexander, L., Moore, M., Deontological ethics (2016) The Stanford Encyclopedia of Philosophy, , E.N. Zalta (ed.). Stanford, CA: Stanford University; Anderson, M., Anderson, S.L., EtheL: Toward a principled ethical eldercare system (2008) AAAI Fall Symposium: AI in Eldercare: New Solutions to Old Problems; Anderson, M., Anderson, S.L., A value driven agent: Instantiation of a case-supported principle-based behavior paradigm (2017) AAAI 2016 Workshop on AI, Ethics & Society; Baumeister, R.F., Leary, M.R., Writing narrative literature reviews (1997) Review of General Psychology, 1 (3), p. 311; Beauchamp, T.L., Does ethical theory have a future in bioethics? (2004) The Journal of Law, Medicine & Ethics, 32 (2), pp. 209-217; Beauchamp, T.L., Childress, J.F., (2009) Principles of Biomedical Ethics, , Oxford: Oxford University Press; Bernoth, M., Burmeister, O.K., Morrison, M., Islam, M.Z., Onslow, F., Cleary, M., The impact of a participatory care model on work satisfaction of care workers and the functionality, connectedness and mental health of community-dwelling older people (2016) Issues in Mental Health Nursing, 37 (6), pp. 1-7; Boonstra, A., Van Offenbeek, M., Towards consistent modes of e-health implementation: Structurational analysis of a telecare programme's limited success (2010) Information Systems Journal, 20 (6), pp. 537-561; Bowern, M., Burmeister, O.K., Gotterbarn, D., Weckert, J., ICT integrity: Bringing the ACS code of ethics up to date (2006) Australasian Journal of Information Systems, 13 (2), pp. 168-181; Burmeister, O.K., Websites for seniors: Cognitive accessibility (2010) International Journal of Emerging Technologies and Society, 8 (2), pp. 99-113; Burmeister, O.K., The development of assistive dementia technology that accounts for the values of those affected by its use (2016) Ethics and Information Technology, 18 (3), pp. 185-198; Burmeister, O.K., Professional ethics in the information age (2017) Journal of Information, Communication & Ethics in Society, 15 (4), pp. 348-356; Burmeister, O.K., Bernoth, M., Dietsch, E., Cleary, M., Enhancing connectedness through peer training for community-dwelling older people: A person centred approach (2016) Issues in Mental Health Nursing, 37 (6), pp. 1-6; Burmeister, O.K., Islam, M.Z., Dayhew, M., Crichton, M., Enhancing client welfare through better communication of private mental health data between rural service providers (2015) Australasian Journal of Information Systems, (19), pp. 1-14; Burmeister, O.K., Kreps, D., Power influences upon technology design for age-related cognitive decline using the VSD framework (2018) Ethics and Information Technology, 20 (3); Cheon, E., Su, N.M., Integrating roboticist values into a value sensitive design framework for humanoid robots (2016) The Eleventh ACM/IEEE International Conference on Human Robot Interaction, pp. 375-382. , Christchurch, New Zealand: IEEE Press; Chesney, T., Coyne, I., Logan, B., Madden, N., Griefing in virtual worlds: Causes, casualties and coping strategies (2009) Information Systems Journal, 19 (6), pp. 525-548; (2017) Commission on Civil Law Rules on Robotics, , P8_Ta(2017)0051; Dainow, B.O., Threats to autonomy from emerging ICTs (2017) Australasian Journal of Information Systems, (21), pp. 1-16; Di Nuovo, A., Broz, F., Wang, N., Belpaeme, T., Cangelosi, A., Jones, R., Esposito, R., Dario, P., The multi-modal interface of robot-era multi-robot services tailored for the elderly (2018) Intelligent Service Robotics, 11 (1), pp. 109-126; Duarte, J., Guerra, A., User-centered healthcare design (2012) Procedia Computer Science, (14), pp. 189-197; Friedman, B., Value-sensitive design (1996) Interactions, 3 (6), pp. 17-23; Friedman, B., Kahn, P.H.J., Borning, A., Value sensitive design and information systems (2006) Human-Computer Interaction and Management Information Systems: Foundations, pp. 348-372. , Zhang and D. Galletta (eds.). New York: M. E. Sharpe; Green, B.N., Johnson, C.D., Adams, A., Writing narrative literature reviews for peer-reviewed journals: Secrets of the trade (2006) Journal of Chiropractic Medicine, 5 (3), pp. 101-117; Hagedorn, T.J., Krishnamurty, S., Grosse, I.R., An information model to support user-centered design of medical devices (2016) Journal of Biomedical Informatics, 62, pp. 181-194; Helms, R., Giovacchini, E., Teigland, R., Kohler, T., (2010) A Design Research Approach to Developing User Innovation Workshops in Second Life, 3 (1). , 2010; Hevner, A.R., March, S.T., Park, J., Ram, S., Design science in information systems research (2004) MIS Q, 28 (1), pp. 75-105; (2016) Preparing for Submission, , http://www.icmje.org/recommendations/browse/manuscript-preparation/preparing-forsubmission.html; (2012) The ICN Code of Ethics for Nurses, , http://www.icn.ch/who-we-are/code-of-ethics-for-nurses/; (2014) Robots and Robotic Devices -- Safety Requirements for Personal Care Robots, , https://www.iso.org/standard/53820.html, International Organization for Standardization; Leenes, R., Lucivero, F., Laws on robots, laws by robots, laws in robots: Regulating robot behaviour by design (2014) Law, Innovation and Technology, 6 (2), pp. 193-220; Madl, T., Franklin, S., Constrained incrementalist moral decision making for a biologically inspired cognitive architecture (2015) A Construction Manual for Robots' Ethical Systems: Requirements, Methods, Implementations, pp. 137-153. , R. Trappl (ed.). Cham: Springer International Publishing; Malle, B.F., Integrating robot ethics and machine morality: The study and design of moral competence in robots (2016) Ethics and Information Technology, 18 (4), pp. 243-256; Mast, M., Burmester, M., Krüger, K., Fatikow, S., Arbeiter, G., Graf, B., Kronreif, G., Qiu, R., User-centered design of a dynamic-autonomy remote interaction concept for manipulation-capable robots to assist elderly people in the home (2012) J. Hum.-Robot Interact., 1 (1), pp. 96-118; Meacham, D., Studley, M., Could a robot care? it’s all in the movement (2017) Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence, , Lin, K. Abney and R. Jenkins (eds.). Oxford University Press; Melson, G.F., Kahn, P.H., Beck, A.M., Friedman, B., Roberts, T., Garrett, E., Robots as dogs?: Children's interactions with the robotic dog aibo and a live australian shepherd (2005) CHI '05 Extended Abstracts on Human Factors in Computing Systems, pp. 1649-1652. , J, Portland, OR, USA: ACM; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Pakrasi, S., Burmeister, O.K., McCallum, T.J., Coppola, J.F., Loeb, G., Ethical telehealth design for users with dementia (2015) Gerontechnology, 13 (4), pp. 383-387; Peffers, K., Tuunanen, T., Rothenberger, M.A., Chatterjee, S., A design science research methodology for information systems research (2007) Journal of Management Information Systems, 24 (3), pp. 45-77; Poulsen, A., (2018) Dynamic Value Trade-Offs in Run-Time to Provide Good, Customised Patient Care with Robots, p. 116. , Charles Sturt University; Poulsen, A., Burmeister, O.K., Overcoming carer shortages with care robots: Dynamic value trade-offs in run-time (2018) Australasian Journal of Information Systems, (22); Poulsen, A., Burmeister, O.K., Kreps, D., The ethics of inherent trust in care robots for the elderly (2018) This Changes Everything – ICT and Climate Change: What Can We Do?, pp. 314-328. , D. Kreps, C. Ess, L. Leenen and K. Kimppa (eds.). Poznan, Poland: Springer International Publishing; Poulsen, A., Burmeister, O.K., Tien, D., Care robot transparency isn’t enough for trust (2018) 2018 IEEE Region 10 Symposium (TENSYMP), , Sydney, Australia; Schnall, R., Rojas, M., Bakken, S., Brown, W., Carballo-Dieguez, A., Carry, M., Gelaude, D., Travers, J., A user-centered model for designing consumer mobile health (mhealth) applications (apps) (2016) Journal of Biomedical Informatics, 60, pp. 243-251; Sharkey, A., Robots and human dignity: A consideration of the effects of robot care on the dignity of older people (2014) Ethics and Information Technology, 16 (1), pp. 63-75; Sharkey, A., Sharkey, N., Children, the elderly, and interactive robots (2011) Robotics & Automation Magazine, IEEE, 18 (1), pp. 32-38; Sharkey, A., Sharkey, N., The eldercare factory (2012) Gerontology, 58 (3), pp. 282-288; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics and Information Technology, 14 (1), pp. 27-40; Shaw, N.P., Stockel, A., Orr, R.W., Lidbetter, T.F., Cohen, R., Towards provably moral AI agents in bottom-up learning frameworks (2018) AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, , New Orleans, USA; Sparrow, R., The march of the robot dogs (2002) Ethics and Information Technology, 4 (4), pp. 305-318; Sparrow, R., Sparrow, L., In the hands of machines? the future of aged care (2006) Minds and Machines, 16 (2), pp. 141-161; Strömberg, H., Leikas, J., Ikonen, V., Iivari, N., Jokela, T., Leurs, N., (2005) User-Centred Design Guidelines for Methods and Tools, , Nomadic Media; Sung, J.Y., Towards the human-centered design of everyday robots (2011) College of Computing, , Georgia Institute of Technology; Teipel, S., Babiloni, C., Hoey, J., Kaye, J., Kirste, T., Burmeister, O.K., Information and communication technology solutions for outdoor navigation in dementia (2016) Alzheimer's & Dementia: The Journal of the Alzheimer's Association, 12 (6), pp. 695-707; Tronto, J.C., (1993) Moral Boundaries A Political Argument for An Ethic of Care, , Abingdon, United Kingdom: Routledge; Upton, H., Moral theory and theorizing in health care ethics (2011) Ethical Theory and Moral Practice, 14 (4), pp. 431-443; Vallor, S., Carebots and caregivers: Sustaining the ethical ideal of care in the twenty-first century (2011) Philosophy & Technology, 24 (3), pp. 251-268; van Andel, J., Leijten, F., van Delden, H., van Thiel, G., What makes a good home-based nocturnal seizure detector? a value sensitive design (2015) PLOS ONE, 10 (4); van Wynsberghe, A., Designing robots for care: Care centered value-sensitive design (2013) Science and Engineering Ethics, 19 (2), pp. 407-433; van Wynsberghe, A., A method for integrating ethics into the design of robots (2013) Industrial Robot: An International Journal, 40 (5), pp. 433-440; Vanlaere, L., Gastmans, C., A personalist approach to care ethics (2011) Nursing Ethics, 18 (2), pp. 161-173; Vredenburg, K., Mao, J.-Y., Smith, P.W., Carey, T., A survey of user-centered design practice (2002) Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 471-478. , Minneapolis, Minnesota, USA: ACM; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , New York: Oxford University Press; Zimmerman, M.J., Intrinsic Vs. Extrinsic Value (2015) The Stanford Encyclopedia of Philosophy, , E.N. Zalta (ed.). Stanford, CA: Stanford University},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Schäffner2018327,
author={Schäffner, V.},
title={Caught up in ethical dilemmas: An adapted consequentialist perspective on self-driving vehicles},
journal={Frontiers in Artificial Intelligence and Applications},
year={2018},
volume={311},
pages={327-335},
doi={10.3233/978-1-61499-931-7-327},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058239455&doi=10.3233%2f978-1-61499-931-7-327&partnerID=40&md5=79a0d46235030e386b0a8f4083cbe0ee},
abstract={Although being potentially able to reduce the number of severe road accidents, self-driving vehicles will still face situations where harming someone cannot be avoided. Therefore there is a need for an ethical investigation into the programming of crash-optimization algorithms: which ethical principles are suitable to guide decisions in dilemma situations and to morally justify them? This paper presents an in-depth overview of research articles revealing the difficulties of a potential utilitarian solution. It evaluates an aggregative consequentialist approach that is adapted to the specific characteristics of dilemmas in autonomous driving, building upon the notions of negative utilitarianism and prioritarianism. © 2018 The authors and IOS Press. All rights reserved.},
author_keywords={Automation;  Autonomous driving;  Consequentialism;  Crash-optimization;  Driverless cars;  Ethical;  Ethical algorithms;  Ethical programming;  Ethics;  Moral dilemma;  Prioritarianism;  Risk management;  Robot ethics;  Self-driving vehicles;  Utilitarianism},
keywords={Accidents;  Automation;  Risk management;  Robot programming;  Robots;  Vehicles, Autonomous driving;  Consequentialism;  Driverless cars;  Ethical;  Ethics;  Moral dilemmas;  Prioritarianism;  Robot ethics;  Self-driving vehicles;  Utilitarianism, Philosophical aspects},
references={Coeckelbergh, M., Responsibility and the moral phenomenology of using self-driving cars (2016) Applied Artificial Intelligence, 30 (8), pp. 748-757; Gogoll, J., Müller, J.F., Autonomous cars: In favor of a mandatory ethics setting (2017) Science and Engineering Ethics, 23 (3), pp. 681-700; Lin, P., The ethics of autonomous cars (2013) The Atlantic, , http://www.theatlantic.com/technology/, retrieved from Accessed: September 6, 2017; Trappl, R., Ethical systems for self-driving cars: An introduction (2016) Applied Artificial Intelligence, 30 (8), pp. 745-747; Gerdes, J.C., Thornton, S.M., Implementable ethics for autonomous vehicles (2016) Autonomous Driving, pp. 87-102. , M. Maurer, J. C. Gerdes, B. Lenz and H. Winner (Eds.), Springer Verlag, Berlin, Heidelberg; Lin, P., Why ethics matters for autonomous cars (2015) Autonomes Fahren. Technische, Rechtliche und Gesellschaftliche Aspekte, pp. 69-85. , M. Maurer, J. C. Gerdes, B. Lenz, and H. Winner (Eds.), Springer Vieweg, Berlin; Goodall, N.J., Ethical decision making during automated vehicle crashes (2014) Transportation Research Record: Journal of The Transportation Research Board, 2424, pp. 58-65; Goodall, N.J., Machine ethics and automated vehicles (2014) Lecture Notes in Mobility. Road Vehicle Automation, pp. 93-102. , G. Meyer and S. Beiker (Eds.), Springer International Publishing, Cham; Bonnefon, J.-F., Shariff, A., Rahwan, I., (2015) Autonomous Vehicles Need Experimental Ethics: Are We Ready for Utilitarian Cars?, , http://arxiv.org/abs/1510.03346, Accessed: February 4, 2018; Applin, S., Autonomous vehicle ethics: Stock or custom? (2017) IEEE Consumer Electronics Magazine, 6 (3), pp. 108-110; Thornton, S.M., Pan, S., Erlien, S.M., Gerdes, J.C., Incorporating ethical considerations into automated vehicle control (2017) IEEE Transactions on Intelligent Transportation Systems, 18 (6), pp. 1429-1439; Goodall, N.J., Can you program ethics into a self-driving car? (2016) IEEE Spectrum, 53 (6), pp. 28-58; Bonnefon, J.-F., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2016) Science, 352 (6293), pp. 1573-1576. , New York, N.Y; Sinnott-Armstrong, W., Consequentialism (2015) The Stanford Encyclopedia of Philosophy, , https://plato.stanford.edu/archives/win2015/entries/consequentialism/, Winter Edition), Edward N. Zalta (Ed.); retrieved Accessed: December 11, 2017. from; Goodall, N.J., Vehicle automation and the duty to act (2014) Proceedings of The 21st World Congress on Intelligent Transport Systems, 53 (6), pp. 28-58. , 7–11 September 2014 Detroit; Santoni de Sio, F., Killing by autonomous vehicles and the legal doctrine of necessity (2017) Ethical Theory and Moral Practice, 20 (2), pp. 411-429; Etzioni, A., Etzioni, O., Incorporating ethics into artificial intelligence (2017) The Journal of Ethics, 21 (4), pp. 403-418; Loh, W., Loh, J., Autonomy and responsibility in hybrid systems: The example of autonomous cars (2017) Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence, pp. 35-50. , Lin, R. Jenkins, and K. Abney (Eds.), Oxford University Press, Oxford; Hevelke, A., Nida-Rümelin, J., Selbstfahrende Autos und Trolley-Probleme: Zum Aufrechnen von Menschenleben im Falle unausweichlicher Unfälle (2014) Jahrbuch Für Wissenschaft und Ethik, 19 (1), pp. 5-24; Hevelke, A., Nida-Rümelin, J., Responsibility for crashes of autonomous vehicles: An ethical analysis (2015) Science and Engineering Ethics, 21 (3), pp. 619-630; Goodall, N.J., Away from trolley problems and toward risk management (2016) Applied Artificial Intelligence, 30 (8), pp. 810-821; Liu, H.-Y., Structural discrimination and autonomous vehicles: Immunity devices, trump cards and crash optimisation (2016) What Social Robots Can and Should Do: Proceedings of Robophilosophy 2016/TRANSOR 2016, 290, pp. 164-173. , J. Seibt, M. Nørskov and S. Schack Andersen (Eds.), IOS Press; Millar, J., Ethics settings for autonomous vehicles (2017) Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence, pp. 20-34. , Lin, R. Jenkins, and K. Abney (Eds.), Oxford University Press, Oxford; Lin, P., The robot car of tomorrow may just be programmed to hit you (2014) WIRED, , https://www.wired.com/2014/05/the-robot-car-of-tomorrow-might-just-be-programmed-to-hit-you/, retrieved from Accessed: January 17, 2018; Parfit, D., Equality and priority (1997) Ratio, 10 (3), pp. 202-221; Arneson, R.J., Egalitarianism and responsibility (1999) The Journal of Ethics, 3 (3), pp. 225-247},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Dignum201843,
author={Dignum, V. and Dignum, F. and Vazquez-Salceda, J. and Clodic, A. and Gentile, M. and Mascarenhas, S. and Augello, A.},
title={Design for values for social robot architectures},
journal={Frontiers in Artificial Intelligence and Applications},
year={2018},
volume={311},
pages={43-52},
doi={10.3233/978-1-61499-931-7-43},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058222837&doi=10.3233%2f978-1-61499-931-7-43&partnerID=40&md5=dab1f635e2f9f043c7d1f81a8a2768d8},
abstract={The integration of social robots in human societies requires that they are capable to take decisions that may affect the lives of people around them. In order to ensure that these robots will behave according to shared ethical principles, an important shift in the design and development of social robots is needed, one where the main goal is improving ethical transparency rather than technical performance, and placing human values at the core of robot designs. In this abstract, we discuss the concept of ethical decision making and how to achieve trust according to the principles of Autonomy, Responsibility and Transparency (ART). © 2018 The authors and IOS Press. All rights reserved.},
author_keywords={Human-robot interaction;  Robot ethics;  Social practices;  Social robotics;  Value-based design},
keywords={Behavioral research;  Decision making;  Human robot interaction;  Machine design;  Philosophical aspects;  Robotics;  Transparency, Design and Development;  Ethical decision making;  Ethical principles;  Robot ethics;  Social practices;  Social robotics;  Technical performance;  Value-based, Economic and social effects},
references={Aldewereld, H., Dignum, V., Tan, Y.H., Design for values in software development (2015) Handbook of Ethics, Values, and Technological Design: Sources, Theory, Values and Application Domains, pp. 831-845; Binmore, K., (2005) Natural Justice, , Oxford University Press; Cranefield, S., Winikoff, M., Dignum, V., Dignum, F., No pizza for you: Value-based plan selection in BDI agents (2017) Proceedings of The Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17, pp. 178-184; Dignum, V., Responsible autonomy (2017) Proceedings of The Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI’2017, pp. 4698-4704; Floridi, L., Sanders, J., On the morality of artificial agents (2004) Minds and Machines, 14, pp. 349-379; Gigerenzer, G., Moral satisficing: Rethinking moral behavior as bounded rationality (2010) Topics in Cognitive Science, 2, pp. 528-554; Li, W., Sadigh, D., Sastry, S., Seshia, S., Synthesis for human-in-the-loop control systems (2014) International Conference on Tools and Algorithms for The Construction and Analysis of Systems, pp. 470-484. , Springer; Modgil, S., Prakken, H., A general account of argumentation with preferences (2013) Artificial Intelligence, 195, pp. 361-397. , 2013; Ostrom, E., Gardner, R., Walker, J., (1994) Rules, Games, and Common-Pool Resources, , University of Michigan Press; Russell, S., Norvig, P., (2009) Artificial Intelligence: A Modern Approach, , Pearson Education, 3rd edition; Sutton, R., Barto, A., (1998) Reinforcement Learning: An Introduction, , MIT Press; Van De Poel, I., Translating values into design requirements (2013) Philosophy and Engineering: Reflections on Practice, Principles and Process, pp. 253-266. , Springer, Dordrecht; Van Den Hoven, J., Design for values and values for design (2005) Information Age +, Journal of The Australian Computer Society, 7, pp. 4-7; Verdiesen, I., Dignum, V., Van Den Hoven, J., Measuring moral acceptability in e-Deliberation: A practical application of ethics by participation (2018) ACM Transactions on Internet Technology (TOIT), 18, p. 4},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Bendel201812,
author={Bendel, O.},
title={Service robots from the perspectives of information and machine ethics},
journal={Frontiers in Artificial Intelligence and Applications},
year={2018},
volume={311},
pages={12-18},
doi={10.3233/978-1-61499-931-7-12},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058221760&doi=10.3233%2f978-1-61499-931-7-12&partnerID=40&md5=db5a358981f6aa6a5c305b228c307523},
abstract={Service robots are becoming ever more pervasive in society-at-large. They are present in our apartments and our streets. They are found in hotels, hospitals, and care homes, in shopping malls, and on company grounds. In doing so, various challenges arise. Service robots consume energy, they take up space in ever more crowded cities, sometimes leading us to collide with them and stumble over them. They monitor us, they communicate with us and retain our secrets on their data drives. In relation to this, they can be hacked, kidnapped and abused. The first section of this article presents different types of service robots—like security, transport, therapy, and care robots—and discusses the moral implications that arise from their existence. Information ethics and machine ethics will form the basis for interrogating these moral implications. The second section discusses the draft for a patient declaration, by which people can determine whether and how they want to be treated and cared for by a robot. However, individual specifications may violate personal interests or the business interests of the hospital or nursing home. The author argues such a patient declaration will be vital in a world ever more impacted by these service robots. © 2018 The authors and IOS Press. All rights reserved.},
author_keywords={Ethics;  Information ethics;  Machine ethics;  Moral machines;  Patient declaration;  Service robots},
keywords={Digital storage;  Hospitals;  Patient treatment;  Philosophical aspects, Care homes;  Data drives;  Ethics;  Information ethics;  Nursing homes;  Patient declaration;  Service robots, Mobile robots},
references={Bendel, O., (2018) Pflegeroboter, , ed, Springer Gabler, Wiesbaden, print; Bendel, O., (2018) Ausgewählte Artefakte Der Maschinenethik, , http://ictk.ch/content/ausgew%C3%A4hlte-artefakte-der-maschinenethik#content, ICTkommunikation, 16 January; Bendel, O., (2017) Service Robots in Public Spaces, , https://www.heise.de/tp/features/Service-Robots-in-Public-Spaces-3754173.html, Telepolis, 25 June; Bendel, O., Mehr Unsicherheit mit Sicherheitsrobotern? (2016) SicherheitsForum, 6, pp. 8-20; Bendel, O., (2016) 300 Keywords Informationsethik, , Springer Gabler, Wiesbaden; Bendel, O., (2016) The GOODBOT Project: A Chatbot as A Moral Machine, , http://www.heise.de/tp/artikel/48/48260/1.html, Telepolis, 17 May; Decker, M., Technology Assessment of Service Robotics (2012) Robo- and Informationethics: Some Fundamentals, pp. 53-88. , Michael Decker, Mathias Gutmann, eds, LIT Verlag, Münster; Fahlberg, C., (2017) Use Cases for Care Robots: A List of Use Cases for The Nursing Sector, , Master Thesis, School of Business FHNW},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Heuer2018265,
author={Heuer, T. and Schiering, I. and Gerndt, R.},
title={Privacy and socially assistive robots - A meta study},
journal={IFIP Advances in Information and Communication Technology},
year={2018},
volume={526},
pages={265-281},
doi={10.1007/978-3-319-92925-5_18},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048970100&doi=10.1007%2f978-3-319-92925-5_18&partnerID=40&md5=51280a145279b5b9f7ec1d19ea44a25b},
abstract={This paper investigates studies about socially assistive robotics with focus on privacy and ethical concerns. Therefore, the privacy aspects are considered and the concerns expressed by users with regard to privacy are examined additionally. It becomes clear, there are still a lot of concerns regarding the use of robots, that’s why robots are not well accepted so far. To get a more transparent view on that, two models are introduced which might improve the understanding towards important privacy aspects. © IFIP International Federation for Information Processing 2018.},
author_keywords={HRI;  Human-robot friendship;  Human-robot interaction;  Machine ethics;  Privacy;  Robot ethics;  Socially assistive robot},
keywords={Data privacy;  Philosophical aspects, Assistive robotics;  Ethical concerns;  Human robots;  Meta-study;  Privacy aspects;  Robot ethics;  Socially assistive robots, Human robot interaction},
references={Amirfar, V.A., A little robot with big promise may be future of personalized health care (2016) Pharm. Today, 22 (9), p. 38; Banks, M.R., Willoughby, L.M., Banks, W.A., Animal-assisted therapy and loneliness in nursing homes: Use of robotic versus living dogs (2008) J. Am. Med. Directors Assoc., 9 (3), pp. 173-177; Beer, J.M., Takayama, L., Mobile remote presence systems for older adults: Acceptance, benefits, and concerns (2011) Proceedings of the 6Th International Conference on Human-Robot Interaction, pp. 19-26. , ACM; Breazeal, C., (2007) How Robotic Products Become Social Products: An Ethnographic Study of Cleaning in the House, , http://dl.acm.org/citation.cfm?id=1228716, ACM, New York; Breazeal, C., (2015) A Social Robot in Every Home, , MIT Media Lab, Cambridge; Breazeal, C.L., (2002) Designing Sociable Robots (Intelligent Robotics and Autonomous Agents), , MIT Press, Cambridge; Broadbent, E., Jayawardena, C., Kerse, N., Human-robot interaction research to improve quality of life in elder care-an approach and issues (2011) AAAI Workshop Conference on Artificial Intelligence; Broadbent, E., Stafford, R., Macdonald, B., Acceptance of healthcare robots for the older population: Review and future directions (2009) Int. J. Soc. Robot., 1 (4), pp. 319-330; Coeckelbergh, M., Pop, C., Simut, R., Peca, A., Pintea, S., David, D., Vanderborght, B., A survey of expectations about the role of robots in robot-assisted therapy for children with ASD: Ethical acceptability, trust, sociability, appearance, and attachment (2016) Sci. Eng. Ethics, 22 (1), pp. 47-65; Denning, T., Matuszek, C., Koscher, K., Smith, J.R., Kohno, T., A spotlight on security and privacy risks with future household robots: Attacks and lessons (2009) Proceedings of the 11Th International Conference on Ubiquitous Computing, pp. 105-114. , ACM; Disalvo, C.F., Gemperle, F., Forlizzi, J., Kiesler, S., All robots are not created equal: The design and perception of humanoid robot heads (2002) Proceedings of the 4Th Conference on Designing Interactive Systems: Processes, Practices, Methods, and Techniques, pp. 321-326. , ACM; Döring, N., Richter, K., Gross, H.M., Schröter, C., Mueller, S., Volkhardt, M., Scheidig, A., Debes, K., Robotic companions for older people: A case study in the wild (2016) Stud. Health Technol. Inform., 219, pp. 147-152; Duffy, B.R., Anthropomorphism and the social robot (2003) Robot. Auton. Syst., 42 (3), pp. 177-190; Feil-Seifer, D., Mataric, M., Socially assistive robotics (2011) IEEE Robot. Autom. Mag., 18 (1), pp. 24-31; Fink, J., Bauwens, V., Kaplan, F., Dillenbourg, P., Living with a vacuum cleaning robot (2013) Int. J. Soc. Robot., 5 (3), pp. 389-408; Fink, J., Bauwens, V., Mubin, O., Kaplan, F., Dillenbourg, P., People’s perception of domestic service robots: Same household, same opinion? (2011) ICSR 2011. LNCS (LNAI), 7072, pp. 204-213. , https://doi.org/10.1007/978-3-642-25504-521, Mutlu, B., Bartneck, C., Ham, J., Evers, V., Kanda, T. (eds.), Springer, Heidelberg; Finn, R.L., Wright, D., Friedewald, M., Seven types of privacy (2013) European Data Protection: Coming of Age, pp. 3-32. , https://doi.org/10.1007/978-94-007-5170-51, Gutwirth, S., Leenes, R., de Hert, P., Poullet, Y. (eds.), Springer, Heidelberg; Fong, T., Nourbakhsh, I., Dautenhahn, K., A survey of socially interactive robots (2003) Robot. Auton. Syst., 42 (3), pp. 143-166; de Graaf, M.M.A., Ben Allouch, S., van Dijk, J.A.G.M., What makes robots social?: A user’s perspective on characteristics for social human-robot interaction (2015) ICSR 2015. LNCS (LNAI), 9388, pp. 184-193. , https://doi.org/10.1007/978-3-319-25554-519, Tapus, A., André, E., Martin, J.C., Ferland, F., Ammi, M. (eds.), Springer, Cham; Graaf, M., Ben Allouch, S., Dijk, J., Why do they refuse to use my robot? (2017) Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction-Hri 2017, pp. 224-233. , Mutlu, B., Tscheligi, M., Weiss, A., Young, J.E. (eds.), ACM Press, New York; de Graaf, M.M., An ethical evaluation of human-robot relationships (2016) Int. J. Soc. Robot., 8 (4), pp. 589-598; de Graaf, M.M., Allouch, S.B., Klamer, T., Sharing a life with harvey: Exploring the acceptance of and relationship-building with a social robot (2015) Comput. Hum. Behav., 43, pp. 1-14; Heerink, M., Kröse, B., Evers, V., Wielinga, B., The influence of social presence on acceptance of a companion robot by older people (2008) J. Phys. Agents, 2 (2), pp. 33-40; International Federation of Robotics: Executive Summary World Robotics 2016 Service Robots, , https://ifr.org/downloads/press/022016/ExecutiveSummaryServiceRobots2016.pdf; Kahn, P.H., Friedman, B., Perez-Granados, D.R., Freier, N.G., Robotic pets in the lives of preschool children (2006) Interact. Stud., 7 (3), pp. 405-436; Kahn, P.H., Jr., Kanda, T., Ishiguro, H., Freier, N.G., Severson, R.L., Gill, B.T., Ruckert, J.H., Shen, S., “Robovie, you’ll have to go into the closet now”: Children’s social and moral relationships with a humanoid robot (2012) Dev. Psychol., 48 (2), p. 303; Kanda, T., Hirano, T., Eaton, D., Ishiguro, H., Interactive robots as social partners and peer tutors for children: A field trial (2004) Hum.-Comput. Interact., 19 (1), pp. 61-84; Kidd, C.D., Breazeal, C., Robots at home: Understanding long-term human-robot interaction (2008) IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2008, pp. 3230-3235; Klamer, T., Ben Allouch, S., Heylen, D., Adventures of harvey” – use, acceptance of and relationship building with a social robot in a domestic environment (2011) HRPR 2010. LNICST, 59, pp. 74-82. , https://doi.org/10.1007/978-3-642-19385-910, Lamers, M.H., Verbeek, F.J. (eds.), Springer, Heidelberg; Koay, K.L., Syrdal, D.S., Walters, M.L., Dautenhahn, K., Living with robots: Investigating the habituation effect in participants’ preferences during a longitudinal human-robot interaction study (2007) The 16Th IEEE International Symposium on Robot and Human Interactive Communication, RO-MAN 2007, pp. 564-569; Koay, K.L., Syrdal, D.S., Walters, M.L., Dautenhahn, K., Five weeks in the robot house-exploratory human-robot interaction trials in a domestic setting (2009) Second International Conferences on Advances in Computer-Human Interactions, ACHI 2009, pp. 219-226; Koay, K., Syrdal, D., Dautenhahn, K., Arent, K., Malek, L., Kreczmer, B., (2011) Companion Migration-Initial participants’ Feedback from a Video-Based Prototyping Study, 1010, pp. 133-151. , Wang, X. (ed.) Mixed Reality and Human-Robot Interaction. Intelligent Systems, Control and Automation: Science and Engineering, Springer, Heidelberg; Kozima, H., Michalowski, M.P., Nakagawa, C., (2009) Keepon. Int. J. Soc. Robot., 1 (1), pp. 3-18; Lee, H.R., Šabanović, S., Chang, W.L., Nagata, S., Piatt, J., Bennett, C., Hakken, D., Steps toward participatory design of social robots: Mutual learning with older adults with depression (2017) Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction, pp. 244-253. , ACM; Lee, K.M., Peng, W., Jin, S.A., Yan, C., Can robots manifest personality? An empirical test of personality recognition, social responses, and social presence in human-robot interaction (2006) J. Commun., 56 (4), pp. 754-772; Leite, I., Martinho, C., Paiva, A., Social robots for long-term interaction: A survey (2013) Int. J. Soc. Robot., 5 (2), pp. 291-308; Leite, I., Martinho, C., Pereira, A., Paiva, A., As time goes by: Long-term evaluation of social presence in robotic companions (2009) The 18Th IEEE International Symposium on Robot and Human Interactive Communication, RO-MAN 2009, pp. 669-674; Murphy, R., Woods, D.D., Beyond Asimov: The three laws of responsible robotics (2009) IEEE Intell. Syst., 24 (4); Pineau, J., Montemerlo, M., Pollack, M., Roy, N., Thrun, S., Towards robotic assistants in nursing homes: Challenges and results (2003) Robot. Auton. Syst., 42 (3), pp. 271-281; Robinson, H., Macdonald, B., Kerse, N., Broadbent, E., The psychosocial effects of a companion robot: A randomized controlled trial (2013) J. Am. Med. Directors Assoc., 14 (9), pp. 661-667; Sabelli, A.M., Kanda, T., Robovie as a mascot: A qualitative study for long-term presence of robots in a shopping mall (2016) IJ Soc. Robot., 8 (2), pp. 211-221; Scassellati, B.M., (2001) Foundations for a theory of mind for a humanoid robot., , Ph.D. thesis, Massachusetts Institute of Technology; Scheeff, M., Pinto, J., Rahardja, K., Snibbe, S., Tow, R., Experiences with sparky, a social robot (2002) Socially Intelligent Agents. Multiagent Systems, Artificial Societies, and Simulated Organizations, 3, pp. 173-180. , Dautenhahn, K., Bond, A., Cañamero, L., Edmonds, B. (eds.), Springer, Heidelberg; Schmitt, C., Schäfer, J., Burmester, M., (2017) Wie Wirkt Der Care-O-Bot 4 Im Verkaufsraum? In: Mensch Und Computer 2017-Usability Professionals; Shamsuddin, S., Yussof, H., Ismail, L.I., Mohamed, S., Hanapiah, F.A., Zahari, N.I., Initial response in HRI-a case study on evaluation of child with autism spectrum disorders interacting with a humanoid robot NAO (2012) Procedia Eng, 41, pp. 1448-1455; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2010) Ethics Inf. Technol., 14 (1), pp. 27-40; Stanton, C.M., Kahn, P.H., Severson, R.L., Ruckert, J.H., Gill, B.T., Robotic animals might aid in the social development of children with autism (2008) 2008 3Rd ACM/IEEE International Conference on Human-Robot Interaction (HRI), pp. 271-278; Sung, J., Christensen, H.I., Grinter, R.E., Robots in the wild: Understanding long-term use (2009) Proceedings of the 4Th ACM/IEEE International Conference on Human Robot Interaction, pp. 45-52. , ACM; Syrdal, D.S., Dautenhahn, K., Koay, K.L., Ho, W.C., Views from within a narrative: Evaluating long-term human-robot interaction in a naturalistic environment using open-ended scenarios (2014) Cogn. Comput., 6 (4), pp. 741-759; Syrdal, D.S., Walters, M.L., Otero, N., Koay, K.L., Dautenhahn, K., He knows when you are sleeping-privacy and the personal robot companion (2007) Proceedings of Workshop Human Implications of Human-Robot Interaction, Association for the Advancement of Artificial Intelligence (AAAI 2007), pp. 28-33; Wada, K., Shibata, T., Living with seal robots–its sociopsychological and physiological influences on the elderly at a care house (2007) IEEE Trans. Robot., 23 (5), pp. 972-980; Wada, K., Shibata, T., Kawaguchi, Y., Long-term robot therapy in a health service facility for the aged-a case study for 5 years (2009) IEEE International Conference on Rehabilitation Robotics, ICORR 2009, pp. 930-933; Wagemaker, E., Dekkers, T.J., Agelink van Rentergem, J.A., Volkers, K.M., Huizenga, H.M., Advances in mental health care: Five n= 1 studies on the effects of the robot seal paro in adults with severe intellectual disabilities (2017) J. Mental Health Res. Intellect. Disabil., 10 (4), pp. 1-12; Wainer, J., Dautenhahn, K., Robins, B., Amirabdollahian, F., A pilot study with a novel setup for collaborative play of the humanoid robot kaspar with children with autism (2014) Int. J. Soc. Robot., 6 (1), pp. 45-65; Weiss, A., Igelsböck, J., Tscheligi, M., Bauer, A., Kühnlenz, K., Wollherr, D., Buss, M., Robots asking for directions: The willingness of passers-by to support robots (2010) Proceedings of the 5Th ACM/IEEE International Conference on Human-Robot Interaction, pp. 23-30. , IEEE Press; Weiss, A., Wurhofer, D., Tscheligi, M., “I love this dog”-children’s emotional attachment to the robotic dog AIBO (2009) Int. J. Soc. Robot., 1 (3), pp. 243-248; Fernaeus, Y., Håkansson, M., Jacobsson, M., Ljungblad, S., How do you play with a robotic toy animal? A long-term study of pleo (2010) ACM, New York, , http://dl.acm.org/citation.cfm?id=1810543},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Bendel2018275,
author={Bendel, O.},
title={Co-robots from an ethical perspective},
journal={Studies in Systems, Decision and Control},
year={2018},
volume={141},
pages={275-288},
doi={10.1007/978-3-319-74322-6_18},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043463456&doi=10.1007%2f978-3-319-74322-6_18&partnerID=40&md5=7e48d574186d3e265cc64f4dc85649fe},
abstract={Cooperation and collaboration robots work hand in hand with their human colleagues. This contribution focuses on the use of these robots in production. The co-robots (to use this umbrella term) are defined and classified, and application areas, examples of applications and product examples are mentioned. Against this background, a discussion on moral issues follows, both from the perspective of information and technology ethics and business ethics. Central concepts of these fields of applied ethics are referred to and transferred to the areas of application. In moral terms, the use of cooperation and collaboration robots involves both opportunities and risks. Co-robots can support workers and save them from strains and injuries, but can also displace them in certain activities or make them dependent. Machine ethics is included at the margin; it addresses whether and how to improve the decisions and actions of (partially) autonomous systems with respect to morality. Cooperation and collaboration robots are a new and interesting subject for it. © 2018, Springer International Publishing AG.},
author_keywords={Business ethics;  Co-robots;  Cobots;  Collaboration robots;  Cooperation robots;  Information ethics;  Machine ethics;  Technology ethics},
references={Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge University Press, Cambridge; Bauernhansl, T., Ten Hompel, M., Vogel-Heuser, B., (2014) Industrie 4.0 in Produktion, Automatisierung Und Logistik, , Springer Vieweg, Wiesbaden; Becker, J., Maschinensteuer. Beitrag für Das Gabler Wirtschaftslexikon. Springer Gabler, Wiesbaden, , http://wirtschaftslexikon.gabler.de/Definition/maschinensteuer.html, Accessed 9 Aug 2017; Bendel, O., (2012) Maschinenethik, , http://wirtschaftslexikon.gabler.de/Definition/maschinenethik.html, Gabler Wirtschaftslexikon. Springer Gabler, Wiesbaden, Accessed 9 Aug 2017; Bendel, O., (2012) Informationsethik, , http://wirtschaftslexikon.gabler.de/Definition/informationsethik.html, Gabler Wirtschaftslexikon. Springer Gabler, Wiesbaden, Accessed 9 Aug 2017; Bendel, O., Wirtschaftliche und technische Implikationen der Maschinenethik (2014) Die Betriebswirtschaft, 4 (2014), pp. 237-248; Bendel, O., Maschinenethik in der Industrie 4.0: Plädoyer für einfache moralische Maschinen (2014) Wissenschaftsjahr 2014 – Die Digitale Gesellschaft, 12. Juni 2014, , http://www.digital-ist.de/experten-blog/maschinenethik-in-der-industrie-40.html, Accessed 9 Aug 2017; Bendel, O., Die Industrie 4.0 aus ethischer Sicht (2015) HMD – Praxis Der Wirtschaftsinformatik, 52, pp. 739-748. , Reinheimer S (ed), 5; Bendel, O., Human Enhancement: Die informationstechnische Erweiterung und ihre Folgen (2015) Tatup, 2015 (2), pp. 82-89; Bendel, O., (2016) Robotersteuer. Beitrag für Das Gabler Wirtschaftslexikon. Springer Gabler, Wiesbaden 2016., , http://wirtschaftslexikon.gabler.de/Definition/robotersteuer.html, Accessed 9 Aug 2017; Bendel, O., Co-Robots und Co. – Entwicklungen und Trends bei Industrierobotern (2017) Netzwoche, 25 (2017), pp. 4-5. , 9; Christaller, O., T (2001) Robotik: Perspektiven für Menschliches Handeln in Der zukünftigen Gesellschaf, , Berlin, Heidelberg, New York; Delvaux, M., (2017) REPORT with Recommendations to the Commission on Civil Law Rules on Robotics (2015/2103(INL)). A8-0005/2017, 24 Jan 2017, , European Parliament, Brussels; Herda, N., Ruf, S., Industrie 4.0 aus der Perspektive der Wirtschaftsinformatik (2014) Wirtschaftsinformatik & Management, 5 (2014), pp. 7-19; Hirsch-Kreinsen, H., (2014) Wandel Von Produktionsarbeit - “Industrie 4.0”. Soziologisches Arbeitspapier Nr. 38/2014, , http://www.wiso.tu-dortmund.de/wiso/is/de/forschung/soz_arbeitspapiere/Arbeitspapier_Industrie_4_0.pdf, Accessed 9 Aug 2017; Kagermann, H., Wahlster, W., Helbig, J., Umsetzungsempfehlungen für Das Zukunftsprojekt Industrie 4.0: Abschlussbericht Des Arbeitskreises Industrie 4.0. April 2013., , http://www.bmbf.de/pubRD/Umsetzungsempfehlungen_Industrie4_0.pdf, Accessed 9 Aug 2017; Kuhlen, R., (2004) Informationsethik: Umgang Mit Wissen Und Informationen in Elektronischen Räumen, , UVK, Konstanz; Peshkin, M., “Cobots” work with people (1996) IEEE Robotics & Automation Magazine, 3 (4), pp. 8-9. , Dec 1996},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Bösl2018140,
author={Bösl, D.B.O. and Bode, M.},
title={Roboethics and robotic governance – A literature review and research agenda},
journal={Advances in Intelligent Systems and Computing},
year={2018},
volume={693},
pages={140-146},
doi={10.1007/978-3-319-70833-1_12},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033693011&doi=10.1007%2f978-3-319-70833-1_12&partnerID=40&md5=14e7c534a30c7e6154bded25276681ed},
abstract={Roboethics is an often-discussed topic in recent years. It has been addressed by science-fiction authors and Hollywood as well as by governments and scientists in various different ways. There seems to be a general consensus on the importance of the issue, but there are still many different approaches that did not achieve a great deal of awareness. Robotic Governance provides an opportunity to consolidate all these approaches and to start a discussion with all involved stakeholders in order to reach a consensus on research, manufacturing and use of technologies in the fields of robotics, automation as well as artificial intelligence. This is the first step to realize sustainable robotics and to successfully and consciously shape the future of coming generations of robotic natives without compromising our own needs. © Springer International Publishing AG 2018.},
author_keywords={Future;  Future of robotics;  Generation R;  Innovation;  Machine ethics;  Megatrends;  Roboethics;  Robotic governance;  Robotic natives;  Robotics;  Technology ethics},
keywords={Industrial research;  Innovation;  Intelligent robots;  Philosophical aspects, Future;  Generation R;  Hollywood;  Literature reviews;  Megatrends;  Research agenda;  Roboethics;  Science fictions, Robotics},
references={Boesl, D.B.O., Bode, M., Generation ‘R’: Why our grandchildren will grow up as the first Generation of “Robotic Natives” (2016) Emerging Technologies and Innovative Business Practices for the Transformation of Societies, pp. 417-420. , IEEE; Veruggio, G., The EURON roboethics roadmap (2006) Humanoids, pp. 612-617; Reynolds, C., Ishikawa, M., Robotic thugs (2007) Ethicomp, pp. 487-492; Tamburrini, G., Ethics, R., A View from the Philosophy of Science (2009) Dipartimento Di Scienze Fisiche, , Universita di Napoli Federico II, Italy; Delvaux, M., Draft Report with recommendations to the Commission on Civil Law Rules on Robotics (2015/2103(INL)). (2016) Committee on Legal Affairs, , European Parliament, PR\1095387EN.doc, PE582.443v01-00; Asimov, I., (1950) I Robot. Double Day & Company, , New York; Asimov, I., (1994) The Robots of Dawn, 4. , Spectra, New York, first published January 1st 1983; Asimov, I., Martin, J.P., (1985) Robots and Empire, , Doubleday, New York; Howlader, D., Moral and ethical questions for robotics public policy (2011) Synesis J. Sci. Technol. Ethics Policy, 2 (1), pp. G1-G6; Metzinger, T., Two principles for robot ethics (2013) Robotik Und Gesetzgebung, pp. 247-286; Lovgren, S., (2007) Robot Code of Ethics to Prevent Android Abuse, Protect Humans, , http://news.nationalgeographic.com/news/2007/03/070316-robot-ethics.html, National Geopraphic News, 16 March; Albrecht, J.P., Reda, J., Ersson, M., Reimon, M., Reintke, T., Green Positions: Robotics and Artificial Intelligence. Green Digital Working Group (2016) The Greens in the European Parliament, , November; Riek, L.D., Howard, D., A code of ethics for the human-robot interaction profession (2014) We Robot; BS 8611:2016 - Robots and robotic devices (2016) Guide to the Ethical Design and Application of Robots and Robotic Systems, , http://shop.bsigroup.com/ProductDetail?pid=000000000030320089; Mattiews, A., (2016) How to Ethically Design Your Robot, , http://www.electronicspecifier.com/robotics/how-to-ethically-design-your-robot; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics Inf. Technol, 14 (1), pp. 27-40; Feil-Seifer, D., Matarić, M.J., Socially assistive robotics (2011) IEEE Robot. Autom. Mag, 18 (1), pp. 24-31; Kernaghan, K., The rights and wrongs of robotics: Ethics and robots in public organizations (2014) Can. Pub. Adm, 57 (4), pp. 485-506; Bostrom, N., Yudkowsky, E., The ethics of artificial intelligence (2014) The Cambridge Handbook of Artificial Intelligence, pp. 316-334; Greene, J., Rossi, F., Tasioulas, J., Venable, K.B., Williams, B., Embedding ethical principles in collective decision support systems (2016) AAAI, pp. 4147-4151; Van Aaken, D., Schreck, P., Theorien der Wirtschafts- und Unternehmensethik (2015) Suhrkamp Taschenbuch Wissenschaft, pp. 269-309; Brundtland, G.H., Khalid, M., Our Common Future. Oxford University Press (1987) New York; Rahwan, I., Bonnefon, J.F., Shariff, A., Moral Machine, , http://moralmachine.mit.edu/; Estellés-Arolas, E., González-Ladrón-de-Guevara, F., Towards an integrated crowdsourcing definition (2012) J. Inf. Sci, 38 (2), pp. 189-200},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Cadzow2018257,
author={Cadzow, S.},
title={Preserving dignity, maintaining security and acting ethically},
journal={Advances in Intelligent Systems and Computing},
year={2018},
volume={593},
pages={257-268},
doi={10.1007/978-3-319-60585-2_24},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021686730&doi=10.1007%2f978-3-319-60585-2_24&partnerID=40&md5=e045b9729b319d1d3c8d3b14d59fb283},
abstract={Humans design, operate and are the net beneficiaries of most systems. However humans are fallible and make mistakes. At the same time humans are adaptable and resourceful in both designing systems and correcting them when they go wrong. In contrast machines have in the main been designed to follow rules and are often constrained to produce the same output for the same input over and over again. Ethical decisions require that different outputs arise from apparently identical appearing inputs as the wider context for the decision has changed. Humans make ethical decisions almost automatically but as we move towards an increasingly machine led society those aspects of dignity, ethics and security which are managed by humans will be addressed by machines. The aim of this paper is to give an overview of the state of the art in security standardization in machine to machine and IoT systems, for the use cases of eHealth and autonomous transport systems, in order to outline the new ethics and security challenges of the machine led society. This will consider progress being made in standards towards the ideal of each of a Secure and Privacy Preserving Turing Machine and of an Ethical Turing Machine. © Springer International Publishing AG 2018.},
author_keywords={Ethics;  Human factors;  Machine ethics;  Security},
keywords={Data privacy;  Human engineering;  Machinery;  Philosophical aspects, Designing systems;  Ethics;  Machine to machines;  Privacy preserving;  Security;  Security challenges;  State of the art;  Transport systems, Turing machines},
references={CIS Critical Security Controls - Version 6.1192, , http://www.cisecurity.org/critical-controls/; The Common Criteria, , www.commoncriteriaportal.org; ETSI TS 102 165-1: CYBER; Methods and Protocols; Part 1: Method and Proforma for Threat, Vulnerability, Risk Analysis (TVRA)., , https://portal.etsi.org/webapp/WorkProgram/SimpleSearch/QueryForm.asp; Luft, J., Ingham, H., (1955) The Johari Window, a Graphic Model of Interpersonal Awareness, , Proceedings of the Western Training Laboratory in Group Development, Los Angeles},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Graves2017333,
author={Graves, M.},
title={Shared Moral and Spiritual Development Among Human Persons and Artificially Intelligent Agents},
journal={Theology and Science},
year={2017},
volume={15},
number={3},
pages={333-351},
doi={10.1080/14746700.2017.1335066},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021053091&doi=10.1080%2f14746700.2017.1335066&partnerID=40&md5=03572ff8768361aab06b1d2c321e5821},
abstract={Technical advances in artificial intelligence make somewhat likely the possibility of robotic or software agents exhibiting or extending human-level intelligence within a few decades. Theological investigation can help meet significant research goals in artificial intelligence by orienting the development of agent communication and moral reasoning toward a shared moral and spiritual development of human persons and intelligent agents. In particular, Josiah Royce’s Loyalty-to-Loyalty initiates a moral stance within which humans and intelligent agents can develop constructive ethical frameworks and his semiotic philosophy of community can guide the development and functioning of an agent’s interpretive processes and can model shared spiritual formation. © 2017 Graduate Theological Union (CTNS Program).},
author_keywords={Artificial intelligence;  Charles Sanders Peirce;  Josiah Royce;  machine ethics;  moral theology;  semiotics;  spiritual formation},
references={Müller, V.C., Bostrom, N., Future Progress in Artificial Intelligence: A Survey of Expert Opinion (2014) Fundamental Issues of Artificial Intelligence; Hall, J.S., Self-Improving AI: An Analysis (2007) Minds and Machines, 17 (3), pp. 249-259; Kurzweil, R., (2005) The Singularity is Near: When Humans Transcend Biology, , New York: Viking; Goertzel, B., Artificial General Intelligence: Concept, State of the Art, and Future Prospects (2014) Journal of Artificial General Intelligence, 5 (1), pp. 1-48; Alpert, J., Hajaj, N., We Knew the Web Was Big (2008) Official Google Blog, , http://googleblog.blogspot.com/2008/07/we-knew-web-was-big.html, July 25, May 30, 2015; Anderson, M., Anderson, S.L., Machine Ethics: Creating An Ethical Intelligent Agent (2007) AI Magazine, 28 (4); Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge: Cambridge University Press; Storrs Hall, J., Beyond, A.I., (2007) Creating the Conscience of the Machine, , Amherst, NY: Prometheus Books; Wallach, W., Allen, C., (2008) Moral Machines: Teaching Robots Right from Wrong, , New York: Oxford University Press; Wallach, W., Deep Learning, AI Safety, Machine Ethics and Superintelligence (2015) Proceedings Joint Meeting of CEPE-IACAP, , Computer Ethics: Philosophical Enquiry and International Association for Computing and Philosophy; Bengio, Y., Goodfellow, I., Courville, A., (2016) Deep Learning, , http://www.deeplearningbook.org/, Cambridge, Mass: MIT Press; Sawyer, R.J., Robot Ethics (2007) Science, 318 (5853), p. 1037; Russell, S., Robotics: Ethics of Artificial Intelligence (2015) Nature News, 521, p. 7553; Yampolskiy, R.V., Attempts to Attribute Moral Agency to Intelligent Machines Are Misguided (2013) Proceedings of International Association of Computers and Philosophy; Chalmers, D., The Singularity: A Philosophical Analysis (2010) Journal of Consciousness Studies, 17 (9-10), pp. 7-65; Peters, T., (1996) For the Love of Children: Genetic Technology and the Future of the Family, , Louisville, KY: Westminster John Knox Press; Brown, W.S., Murphy, N.C., Newton Malony, H., (1998) Whatever Happened to the Soul?: Scientific and Theological Portraits of Human Nature, , Minneapolis, MN: Fortress Press; Peters, T., Theologians Testing Transhumanism (2015) Theology and Science, 13 (2), pp. 130-149; Foerst, A., Artificial Intelligence: Walking the Boundary (1996) Zygon, 31 (4), pp. 681-693; Foerst, A., Cog, a Humanoid Robot, and the Question of the Image of God (1998) Zygon 33:1, pp. 91-111; Foerst, A., Artificial Sociability: From Embodied AI Toward New Understandings of Personhood (1999) Technology in Society, 21 (4), pp. 373-386; Foerst, A., (2004) God in the Machine: What Robots Teach Us about Humanity and God, , New York: Dutton; Barbour, I.G., Neuroscience, Artificial Intelligence, and Human Nature: Theological and Philosophical Reflections (1999) Zygon, 34 (3), pp. 361-398; Barbour, I., (2002) Nature, Human Nature, and God, , Minneapolis, MN: Augsburg Fortress; Herzfeld, N.L., (2002) In Our Image: Artificial Intelligence and the Human Spirit, Theology and the Sciences, , Minneapolis, MN: Fortress Press; Herzfeld, N., Creating in Our Own Image: Artificial Intelligence and the Image of God (2002) Zygon, 37 (2), pp. 303-316; Geraci, R.M., Artificial Intelligence, Networks, and Spirituality (2010) Zygon, 45 (4), pp. 1003-1020; Turing, A.M., Computing Machinery and Intelligence (1950) Mind, 59 (236), pp. 433-460; Searle, J.R., Minds, Brains, and Programs (1980) Behavioral and Brain Sciences, 3 (3), pp. 417-424; Cole, D., The Chinese Room Argument (2014) Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/entries/chinese-room/, (Summer 2014 Edition); Kegan, R., (2001) The Evolving Self: Problem and Process in Human Development, , Cambridge, MA: Harvard University Press; Parker, K.A., (1998) The Continuity of Peirce’s Thought, pp. 156-157. , Nashville, TN: Vanderbilt University Press; Tillich, P., Jung, C., define symbol and sign differently from Peirce: for them, a symbol partakes of the reality to which it points and a sign simply points to it; Lakoff, G., Johnson, M., (1980) Metaphors We Live By, 4-5, p. 15. , Chicago: University of Chicago Press, For embodied metaphors, in particular; Steels, L., Fifty Years of AI: From Symbols to Embodiment-and Back (2007) 50 Years of Artificial Intelligence, , ed. M. Lungarella (Berlin: Springer; Steels, L., Self-Organization and Selection in Cultural Language Evolution (2012) Experiments in Cultural Language Evolution, , ed. Luc Steels, Amsterdam: John Benjamins; Newell, A., Shaw, J.C., Simon, H.A., Report on a General Problem-solving Program (1959) International Conference on Information Processing; Laird, J.E., Newell, A., Rosenbloom, P.S., Soar: An Architecture for General Intelligence (1987) Artificial Intelligence, 33 (1), pp. 1-64; Sowa, J.F., Structures, C., (1984) Information Processing in Mind and Machine, , Reading, MA: Addison-Wesley; Meystel, A.M., Intelligent Systems: A Semiotic Perspective (1996) Int J of Intelligent Control and Systems, 1 (1), pp. 31-57; Gomes, A., Gudwin, R., Queiroz, J., On a Computational Model of the Peircean Semiosis (2003) International Conference on Integration of Knowledge Intensive Multi-Agent Systems, 2003; Loula, A., Emergence of Self-Organized Symbol-Based Communication in Artificial Creatures (2010) Cognitive Systems Research, 11 (2), pp. 131-147; Konderak, P., On a Cognitive Model of Semiosis (2015) Studies in Logic, Grammar and Rhetoric, 40 (1), pp. 129-144; Steiner, P., C.S. Peirce and Artificial Intelligence: Historical Heritage and (New) Theoretical Stakes (2013) Philosophy and Theory of Artificial Intelligence, , Berlin: Springer; Peirce called his philosophy objective idealism; Jorna, R.J., Heusden, B.V., Posner, R., (1993) Signs, Search and Communication: Semiotic Aspects of Artificial Intelligence, , Berlin: W. de Gruyter; Andersen, P.B., (1997) A Theory of Computer Semiotics: Semiotic Approaches to Construction and Assessment of Computer Systems, , Cambridge: Cambridge University Press; Gudwin, R., Queiroz, J., (2007) Semiotics and Intelligent Systems Development, , Hershey, PA: Idea Group; Royce, J., (1995) The Philosophy of Loyalty, Vanderbilt Library of American Philosophy, , Nashville, TN: Vanderbilt University Press; Royce, J., (2001) The Problem of Christianity, , Washington, DC: Catholic University of America Press; Fong, T., Nourbakhsh, I., Dautenhahn, K., A Survey of Socially Interactive Robots (2003) Robotics and Autonomous Systems, 42 (3-4), pp. 143-166. , For embedded agents; Mascarenhas, S., Modeling Culture in Intelligent Virtual Agents (2015) Autonomous Agents and Multi-Agent Systems, pp. 1-32; Panait, L., Luke, S., Cooperative Multi-agent Learning: The State of the Art (2005) Autonomous Agents and Multi-Agent Systems, 11 (3), pp. 387-434; Brambilla, M., Swarm Robotics: A Review From the Swarm Engineering Perspective (2013) Swarm Intelligence, 7 (1), pp. 1-41; Duffy, B.R., Joue, G., Intelligent Robots: The Question of Embodiment (2000) Proceedings of the Brain-Machine Workshop; Pfeifer, R., Iida, F., Embodied Artificial Intelligence: Trends and Challenges (2004) Embodied Artificial Intelligence, , Berlin: Springer; Ziemke, T., Lowe, R., On the Role of Emotion in Embodied Cognitive Architectures: From Organisms to Robots (2009) Cognitive Computation, 1 (1), pp. 104-117; Lindblom, J., (2015) Embodied Social Cognition, Cognitive Systems Monographs, 26. , Berlin: Springer International Publishing; Scott Peck, M., (1987) The Different Drum: Community-Making and Peace, , New York: Simon and Schuster; Schneiders, S.M., Approaches to the Study of Christian Spirituality The Blackwell Companion to Christian Spirituality, p. 2005. , ed. A. Holder, Oxford: John Wiley & Sons; Emmons, R.A., (1999) The Psychology of Ultimate Concerns: Motivation and Spirituality in Personality, , New York: Guilford Press; Monroe, K.R., (2012) Ethics in an Age of Terror and Genocide: Identity and Moral Choice, , Princeton, NJ: Princeton University Press; Asimov, I., Runaround (1942) Astounding Science Fiction, 29 (1), pp. 94-103; Sinnott-Armstrong, W., (2008) Moral Psychology, Volume 3: The Neuroscience of Morality: Emotion, Disease, and Development, , Cambridge, MA: MIT Press; Macintyre, A.C., Virtue, A., (1984) A Study in Moral Theory, , Notre Dame, IN: University of Notre Dame Press; Kieval, H.J., Pursuing the Golem of Prague: Jewish Culture and the Invention of a Tradition (1997) Modern Judaism, 17 (1), pp. 1-20; Rappaport, Z.H., Robotics and Artificial Intelligence: Jewish Ethical Perspectives (2006) Acta Neurochirurgica, 98, pp. 9-12; Graves, M., (2008) Mind, Brain, and the Elusive Soul: Human Systems of Cognitive Science and Religion, , Burlington, VT: Ashgate; Graves, M., The Emergence of Transcendental Norms in Human Systems (2009) Zygon 44:3, pp. 501-532; Murphy, N.C., Bodies and Souls, or Spirited Bodies? (2006) Current Issues in Theology, , Cambridge: Cambridge University Press; Murphy, N.C., Brown, W.S., (2007) Did My Neurons Make Me Do It?: Philosophical and Neurobiological Perspectives on Moral Responsibility, , Oxford: Oxford University; Burrow, R., The Beloved Community: Martin Luther King, Jr. And Josiah Royce (2012) Encounter, 73 (1), p. 37; Barry, W.A., (2004) Spiritual Direction and the Encounter with God: A Theological Inquiry, , Mahwah, NJ: Paulist Press; Edwards, D., (1983) Human Experience of God, , New York: Paulist Press; Smith, J.E., (1968) Experience and God, , New York: Oxford University Press; Mori, M., (1981) The Buddha in the Robot, , Tokyo: Kosei},
document_type={Article},
source={Scopus},
}

@ARTICLE{Sorell2017217,
author={Sorell, T. and Draper, H.},
title={Second thoughts about privacy, safety and deception},
journal={Connection Science},
year={2017},
volume={29},
number={3},
pages={217-222},
doi={10.1080/09540091.2017.1318826},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019761110&doi=10.1080%2f09540091.2017.1318826&partnerID=40&md5=46a94ba0c4800912a5ea5762da7b3827},
abstract={In this paper, we point out some difficulties with interpreting three of five principles formulated at a retreat on robot ethics sponsored by the Arts and Humanities Council and the Engineering and Physical Sciences Research Council. We also attempt to iron out some conflicts between the principles. Some of the difficulties arise from the way that the autonomy of robot users–their capacity to live by their own choices–can be a goal in the design of care robots. We discuss (a) problems for Principle 2 that arise from competing legal and philosophical understandings of privacy; (b) a tension between privacy and safety (Principles 2 and 3) and (c) some scepticism about the application of Principle 4, which addresses robot design that might result in the deception of vulnerable users. © 2017 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={autonomy;  deception;  privacy;  Social robotics;  the elderly},
keywords={Data privacy;  Philosophical aspects;  Robotics;  Robots;  Safety engineering, autonomy;  deception;  Engineering and physical sciences research councils;  Robot designs;  Robot ethics;  Social robotics;  the elderly, Machine design},
references={(2000), http://ec.europa.eu/justice/fundamental-rights/charter/index_en.htm, European Charter of Fundamental Rights, Retrieved from; Sharkey, A., Sharkey, N., Children, the elderly and interactive robots (2011) IEEE Robotics and Automation Magazine, 18 (1), pp. 32-38},
document_type={Article},
source={Scopus},
}

@ARTICLE{Hagendorff201761,
author={Hagendorff, T.},
title={Animal rights and robot ethics},
journal={International Journal of Technoethics},
year={2017},
volume={8},
number={2},
pages={61-71},
doi={10.4018/IJT.2017070105},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018885870&doi=10.4018%2fIJT.2017070105&partnerID=40&md5=e5ca38b2dbd17c65abe07f21217ad99b},
abstract={This paper investigates challenges which anthropocentric and pathocentric ethics have to face when confronted with moral considerations about non-human animals, especially so-called disenhanced animals, and a new class of technological artifacts, namely social robots. Referring to the case of animal welfare, robot ethics emerges as a new discipline that has not yet reflected on the ideological biases that commonly underlie moral judgments toward animals and find expression in robot ethics, too. As a consequence, robot ethics perpetuates the "work of purification," that is, the isolation and definition of a particular entity possessing a moral status. Whenever such an entity is defined, the definition excludes all those entities which could likewise possess a moral status but do not fit exactly to the pre-specified definition. The crucial question, then, is whether to seek an ethic of unconditional compassion that doesn't allow itself to be restricted by ideology and is therefore convenient for animal rights and robot ethics as well. Copyright © 2017, IGI Global.},
author_keywords={Animal rights;  Anthropocentrism;  Carnism;  Compassion;  Robot ethics},
keywords={Animals;  Philosophical aspects, Animal rights;  Anthropocentrism;  Carnism;  Compassion;  Robot ethics, Robots},
references={Adams, C.J., The War on Compassion (2014) Critical Animal Studies. Thinking the Unthinkable, pp. 18-28. , J. Sorenson (Ed.), Toronto: Canadian Scholars' Press; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental & Theoretical Artificial Intelligence, 12 (3), pp. 251-261; Ascione, F.R., (2001) Animal Abuse and Youth Violence, , US Department of Justice; Asimov, I., (2004) I, Robot, , New York: Random House LLC; Bekoff, M., Pierce, J., (2009) Wild Justice: The Moral Lives of Animals, , Chicago, IL: University of Chicago Press; Bentham, J., (1838) The Works of Jeremy Bentham. Published under the Superintendence of His Executor, 1. , Edinburgh, UK: William Tait; Boat, B.W., The Relationship between Violence to Children and Violence to Animals: An Ignored Link? (1995) Journal of Interpersonal Violence, 10 (2), pp. 229-235; Bräuer, J., (2014) Klüger als wir Denken: Wozu Tiere Fähig Sind, , Berlin: Springer; Calverley, D.J., Android science and animal rights, does an analogy exist? (2006) Connection Science, 18 (4), pp. 403-417; Coeckelbergh, M., Robot rights?: Towards a social-relational justification of moral consideration (2010) Ethics and Information Technology, 12 (3), pp. 209-221; Darling, K., Extending legal protection to social robots: The effect of anthropomorphism, empathy, and violent behavior towards robotic objects (2016) Robot Law, pp. 213-234. , R. Calo, A. M. Froomkin, & I. Kerr (Eds.), Cheltenham, UK: Edward Elgar; Donovan, J., Attention to suffering: A feminist caring ethic for the treatment of animals (1996) Journal of Social Philosophy, 27 (1), pp. 81-102; Ferrari, A., Animal Disenhancement for Animal Welfare: The Apparent Philosophical Conundrums and the Real Exploitation of Animals. A Response to Thompson and Palmer (2012) NanoEthics, 6 (1), pp. 65-76; Freeman, C.P., Embracing humanimality: Deconstructing the human/animal dichotomy (2010) Arguments about Animal Ethics, pp. 11-30. , G. Goodale & E. Black (Eds.), Lanham, MD: Rowman & Littlefield; Fuchs, P., Behinderung und soziale Systeme, Anmerkungen zu einem schier unlösbaren Problem (2002) Das Gepfefferte Ferkel; Hayles, K.N., (1999) How We Became Posthuman: Virtual Bodies in Cybernetics, Literature, and Informatics, , Chicago: The University of Chicago Press; Huffman, M.A., Seifu, M., Observations on the illness and consumption of a possibly medicinal plant Vernonia amygdalina (Del.), by a wild chimpanzee in the Mahale Mountains National Park, Tanzania (1989) Primates, 30 (1), pp. 51-63; Joy, M., (2002) Psychic Numbing and Meat Consumption. The Psychology of Carnism, , (Dissertation). Faculty of Saybrook Graduate School and Research Center, San Francisco, CA; Joy, M., Humanistic psychology and animal rights: Reconsidering the boundaries of the humanistic ethic (2005) Journal of Humanistic Psychology, 45 (1), pp. 106-130; Joy, M., (2011) Why We Love Dogs, Eat Pigs, and Wear Cows: An Introduction to Carnism, , Conari Press; Kant, I., (1977) Kants Werke, Akademie Textausgabe: Anmerkungen der Bände I, , Walter de Gruyter; Kellert, S.R., Felthous, A.R., Childhood cruelty toward animals among criminals and noncriminals (1985) Human Relations, 38 (12), pp. 1113-1129; Kurzweil, R., (2005) The Singularity is Near: When Humans Transcend Biology, , London: Penguin Group; Kurzweil, R., (2012) How to Create a Mind: The Secret of Human Thought Revealed, , London: Penguin Group; Latour, B., (2005) Reassembling the Social: An Introduction to Actor-Network-Theory, , New York: Oxford University Press; Latour, B., (2012) We Have Never Been Modern, , Cambridge, MA: Harvard University Press; Laux, H., Latours Akteure. Ein Beitrag zur Neuvermessung der Handlungstheorie (2011) Akteur - Individuum - Subjekt. Fragen zu 'Personalität' und 'Sozialität', pp. 275-300. , N. Lüdke (Ed.), Wien: VS Verlag für Sozialwissenschaften; MacDonald, L., (2002) Biotechnology at the Margins of Personhood. An Evolving Legal Paradigm, , Montreal, Canada: Faculty of Graduade Studies and Research; Macho, T., Tiere, Menschen, Maschinen. Für einen inklusiven Humanismus (2013) Tiere. Der Mensch und Seine Natur, pp. 153-173. , K. P. Liessmann (Ed.), Wien: Paul Zsolnay; Nagenborg, M., Capurro, R., Weber, J., Pingel, C., Ethical regulations on robotics in Europe (2008) AI & Society, 22 (3), pp. 349-366; Palmer, C., Animal disenhancement and the non-identity problem (2011) NanoEthics, 5 (1), pp. 43-48; Patterson, F., Conversations with a gorilla (1978) National Geographic, 154 (4), pp. 438-465; Peggs, K., (2012) Animals and Sociology, , Hampshire: Palgrave MacMillan; Regan, T., (2003) Animal Rights, Human Wrongs: An Introduction to Moral Philosophy, , Lanham, MD: Rowman & Littlefield; Regan, T., (2004) The Case for Animal Rights, , London: Routledge & Kegan Paul; Rollin, B.E., (1998) The Unheeded Cry: Animal Consciousness, Animal Pain, and Science Expanded Edition, , Ames, IA: Iowa State University Press; Rosenthal-von Der Pütten, A.M., Schulte, F.P., Eimler, S.C., Hoffmann, L., Sobieraj, S., Maderwald, S., Brand, M., Neural correlates of empathy towards robots (2012) 8th ACM/IEEE International Conference on Human-Robot Interaction; Rosenthal-von Der Pütten, A.M., Krämer, N.C., Hoffmann, L., Sobieraj, S., Eimler, S.C., An Experimental Study on Emotional Reactions Towards a Robot (2013) International Journal of Social Robotics, 5 (1), pp. 17-34; Singer, P., (1975) Animal Liberation, , New York: HarperCollins Publishers; Thompson, P.B., Ethics and the genetic engineering of food animals (1997) Journal of Agricultural & Environmental Ethics, 10 (1), pp. 1-23; Thompson, P.B., The Opposite of Human Enhancement: Nanotechnology and the Blind Chicken Problem (2008) NanoEthics, 2 (3), pp. 305-316; Turkle, S., (2011) Alone Together: Why We Expect More from Technology and Less from Each Other, , New York: Basic Books; Waal, F.D., (2009) The Age of Empathy: Nature's Lessons for a Kinder Society, , New York: Harmony Books; Wallach, W., Robot minds and human ethics: The need for a comprehensive model of moral decision making (2010) Ethics and Information Technology, 12 (3), pp. 243-250; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , New York: Oxford University Press; Whitby, B., Sometimes its hard to be a robot: A call for action on the ethics of abusing artificial agents (2008) Interacting with Computers, 20 (3), pp. 326-333},
document_type={Article},
source={Scopus},
}

@ARTICLE{Müller2017137,
author={Müller, V.C.},
title={Legal vs. ethical obligations–a comment on the EPSRC’s principles for robotics},
journal={Connection Science},
year={2017},
volume={29},
number={2},
pages={137-141},
doi={10.1080/09540091.2016.1276516},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018640961&doi=10.1080%2f09540091.2016.1276516&partnerID=40&md5=0102fa704e43bd467baa42d94f9a229d},
abstract={While the 2010 EPSRC principles for robotics state a set of five rules of what “should” be done, I argue they should differentiate between legal obligations and ethical demands. Only if we make this difference can we state clearly what the legal obligations already are, and what additional ethical demands we want to make. I provide suggestions how to revise the rules in this light and how to make them more structured. © 2017 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={killer robots;  legal obligation;  principles of robotics;  Robot ethics;  robot law},
keywords={Robotics;  Robots, Legal obligations;  Robot ethics, Philosophical aspects},
references={Alpers, P., Rossetti, A., Wilson, M., (2016), http://www.gunpolicy.org/firearms/region/european-union, European Union–gun facts, figures and the law. Sydney School of Public Health. Retrieved December 13, 2016, from; (1991), http://data.europa.eu/eli/dir/1991/477/oj, 91/477/EEC–European Firearms Directive. EUR-Lex. Retrieved June 18, 1991, from; (2010), https://www.epsrc.ac.uk/research/ourportfolio/themes/engineering/activities/principlesofrobotics/, Principles of robotics: Regulating robots in the real world. Retrieved from; Eshleman, A., Moral responsibility (2014) Stanford encyclopedia of philosophy, , https://plato.stanford.edu/entries/moral-responsibility/, Zalta E.N., (ed), Palo Alto, CA: Stanford University, Retrieved from; (2010), http://icrac.net/statements/, Berlin statement. International Committee for Robotic Arms Control. Retrieved from; Leveringhaus, A., (2016) Ethics and autonomous weapons, , London: Palgrave Pivot; Müller, V.C., Autonomous killer robots are probably good news (2016) Drones and responsibility: Legal, philosophical and socio-technical perspectives on the use of remotely controlled weapons, pp. 67-81. , Di Nucci E., Santoni de Sio F., (eds), London: Ashgate; Simpson, T.W., Müller, V.C., Just war and robots’ killings (2016) The Philosophical Quarterly, 66 (263), pp. 302-322; Sparrow, R., Robots and respect: Assessing the case against autonomous weapon systems (2016) Ethics & International Affairs, 30 (1), pp. 93-116; (2016), http://www.legislation.gov.uk/ukpga/2016/25/contents/enacted/data.htm, Investigatory powers act. The National Archives. Retrieved November 29, 2016, from},
document_type={Article},
source={Scopus},
}

@ARTICLE{Boddington2017170,
author={Boddington, P.},
title={EPSRC Principles of Robotics: commentary on safety, robots as products, and responsibility},
journal={Connection Science},
year={2017},
volume={29},
number={2},
pages={170-176},
doi={10.1080/09540091.2016.1271396},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007242115&doi=10.1080%2f09540091.2016.1271396&partnerID=40&md5=be3374dc09cf2cbd9145bcf1659fa1a4},
abstract={The EPSRC Principles of Robotics refer to safety. How safety is understood is relative to how tasks are characterised and identified. But the exact task(s) a robot plays within a complex system of agency may be hard to identify. If robots are seen as products, it is nonetheless vital that the safety and other implications of their use in situ must also be considered carefully, and they must be fit for purpose. The Principles identify humans as responsible, rather than robots. We must thus understand how the replacement of human agency by robotic agency may impact upon attributions of responsibility. The Principles seek to fit into existing systems of law and ethics. But these may need development, and in certain context, attention to more local regulations is also needed. A distinction between ethical issues related to the design of robotics, and to their use, may be needed in the Principles. © 2016 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={Principles of Robotics;  responsibility;  Robot ethics;  safety},
keywords={Accident prevention;  Laws and legislation;  Philosophical aspects;  Robotics, Ethical issues;  Existing systems;  Fit for purpose;  Human agency;  Local regulations;  responsibility;  Robot ethics, Robots},
references={Arribas-Ayllon, M., Featherstone, K., Atkinson, P.A., The practical ethics of genetic responsibility: Non-disclosure and the autonomy of affect (2011) Social Theory & Health, 9 (1), pp. 3-23; Boden, M., Bryson, J., Caldwell, D., Dautenhahn, K., Edwards, L., Kember, S., Winfield, A., (2011) Principles of robotics, , Swindon: Engineering and Physical Sciences Research Council ESPRC; Booth, J., Kumlien, S., Zang, Y., Promoting urinary continence with older people: Key issues for nurses (2009) International Journal of Older People Nursing, 4 (1), pp. 63-69; Daykin, N., Clarke, B., ‘They’ll still get the bodily care’. Discourses of care and relationships between nurses and health care assistants in the NHS (2000) Sociology of Health and Illness, 22 (3), pp. 349-363; Donaldson, L., (2003), Making amends. Department of Health, London: HMSO; Glover, J., (1971) Responsibility, , Oxford: Blackwell; (2011) Service user experience in adult mental health: Improving the experience of care for people using adult NHS mental health services, , London: NICE; Oliver, D., Healey, F., Haines, T., Preventing falls and fall-related injuries in hospitals (2010) Clinical Geriatric Medicine, 26, pp. 645-692},
document_type={Article},
source={Scopus},
}

@ARTICLE{Laue2017,
author={Laue, C.},
title={Familiar and strange: Gender, sex, and love in the uncanny valley},
journal={Multimodal Technologies and Interaction},
year={2017},
volume={1},
number={1},
doi={10.3390/mti1010002},
art_number={2},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079700303&doi=10.3390%2fmti1010002&partnerID=40&md5=85c89b9379e7cc1923500953c71fb736},
abstract={Early robotics research held that increased realism should result in increased positivity of the interactions between people and humanoid robots. However, this turned out to be true only to a certain point, and researchers now recognize that human interactions with highly realistic humanoid robots are often marked by feelings of disgust, fear, anxiety, and distrust. This phenomenon is called the Uncanny Valley. In a world in which Artificial Companions are increasingly likely, and even desired, engineering humanoid robots that avoid the Uncanny Valley is of critical importance. This paper examines theories of the uncanny, and focuses on one in particular—that humans subconsciously appraise robots as potential sexual partners. Drawing from work on love, sexuality, and gender from a variety of fields, this paper speculates on possible futures in a world of intimate companionships between humans and machines. © 2017 by the author; licensee MDPI, Basel, Switzerland.},
author_keywords={Human-robot interactions;  Human-technology interactions;  Machine ethics;  Uncanny valley},
references={Mori, M., The Uncanny Valley (1970) Energy, 7, pp. 33-35; Mori, M., Macdorman, K.F., Kageki, N., The uncanny valley [from the field] (2012) IEEE Robot. Autom. Mag., 19, pp. 98-100; Jentsch, E., On the Psychology of the Uncanny Angelaki (1996) J. Theor. Humanit., 2, pp. 7-16; Freud, S., (1919) The Uncanny; the Standard Edition of the Complete Psychological Works of Sigmund Freud 17, pp. 219-252. , Imago: London, UK; Kristeva, J., (1982) Powers of Horror; University Presses of California, p. 71. , Jackson, TN, USA; University Presses of Columbia: New York, NY, USA; University Presses of Princeton: West Sussex, UK; Walters, M.L., Syrdal, D.S., Dautenhahn, K., Te Boekhorst, R., Koay, K.L., Avoiding the uncanny valley: Robot appearance, personality and consistency of behavior in an attention-seeking home scenario for a robot companion (2008) Auton. Robot., 24, pp. 159-178; Brenton, M.G., Daniel, B., David, C., The uncanny valley: Does it exist (2005) Proceedings of the Conference of Human Computer Interaction, Workshop on Human Animated Character Interaction, , In, Las Vegas, NV, USA, 22–27 July; Burleigh, T.J., Schoenherr, J.R., Lacroix, G.L., Does the Uncanny Valley Exist? An Empirical Test of the Relationship between Eeriness and the Human Likeness of Digitally Created Faces (2013) Comput. Hum. Behav., 29, pp. 759-771; Cheetham, M., Pascal, S., Lutz, J., The Human Likeness Dimension of the “Uncanny Valley Hypothesis”: Behavioral and Functional MRI Findings (2011) Front. Hum. Neurosci., 5, p. 126. , [CrossRef] [PubMed]; Saygin, A.P., Thierry, C., Ishiguro, H., Driver, J., Frith, C., The Thing That Should Not Be: Predictive Coding and the Uncanny Valley in Perceiving Human and Humanoid Robot Actions (2013) Soc. Cogn. Affect. Neurosci, 7, pp. 413-422; Cheetham, M., Pavlovic, I., Jordan, N., Suter, P., Jancke, L., Category Processing and the Human Likeness Dimension of the Uncanny Valley Hypothesis: Eye-tracking Data (2013) Front. Psychol., 4, p. 108; Yamada, Y., Kawabe, T., Ihaya, K., Categorization Difficulty is Associated with Negative Evaluation in the “Uncanny Valley” Phenomenon (2013) Jpn. Psychol. Res., 55, pp. 20-32; Calder, A.J., Categorical Perception of Morphed Facial Expressions (1996) Vis. Cogn., 3, pp. 81-118; Harnad, S.R., (1990) Categorical Perception: The Groundwork of Cognition, , (Ed.), Cambridge University Press: Cambridge, UK; Tondu, B., Bardou, N., A new interpretation of Mori’s uncanny valley for future humanoid robots (2001) Int. J. Robot. Autom, 26, p. 337; Gray, K., Wegner, D.M., Feeling robots and human zombies: Mind perception and the uncanny valley (2012) Cognition, 125, pp. 125-130; Ramey, C.H., The uncanny valley of similarities concerning abortion, baldness, heaps of sand, and humanlike robots (2005) Proceedings of the Views of the Uncanny Valley Workshop: IEEE-RAS International Conference on Humanoid Robots, pp. 8-13. , Tsukuba, Japan; Lamb, M.E., The development of social expectations in the first year of life (1981) Infant Social Cognition: Empirical and Theoretical Considerations, pp. 155-175. , Psychology Press: East Sussex, UK; Landis, D., Triandis, H.C., Adamopoulos, J., Habit and behavioral intentions as predictors of social behavior (1978) J. Soc. Psychol., 106, pp. 227-237; Eyssel, F., Kuchenbrandt, D., Bobinger, S., Effects of anticipated human-robot interaction and predictability of robot behavior on perceptions of anthropomorphism (2011) Proceedings of the 6Th International Conference on Human-Robot Interaction ACM 2011, pp. 61-68. , Lausanne, Switzerland, 6–9 March, pp; Tinwell, A., Grimshaw, M., Nabi, D.A., Williams, A., Facial expression of emotion and perception of the Uncanny Valley in virtual characters (2011) Comput. Hum. Behav., 27, pp. 741-749; Mitchell, W.J., Szerszen, K.A., Lu, A.S., Schermerhorn, P.W., Scheutz, M., Macdorman, K.F., A mismatch in the human realism of face and voice produces an uncanny valley (2011) I-Percept, 2, pp. 10-12; Blow, M., Dautenhahn, K., Appleby, A., Nehaniv, C.L., Lee, D., The art of designing robot faces: Dimensions for human-robot interaction (2006) Proceedings of the 1St ACM SIGCHI/SIGART Conference on Human-Robot Interaction 2006, pp. 331-332. , Salt Lake City, UT, USA; Macdorman, K.F., Subjective ratings of robot video clips for human likeness, familiarity, and eeriness (2006) An Exploration of the Uncanny Valley. in Proceedings of the Iccs/Cogsci-2006 Long Symposium: Toward Social Mechanisms of Android Science, Vancouver, BC, Canada, pp. 26-29. , 26 July; Seyama, J., Rnagayama, R.S., The uncanny valley: Effect of realism on the impression of artificial human faces (2007) Presence, 16, pp. 337-351; Disalvo, C.F., Gemperle, F., Forlizzi, J., Kiesler, S., All robots are not created equal: The design and perception of humanoid robot heads (2002) Proceedings of the 4Th Conference on Designing Interactive Systems: Processes, pp. 321-326. , Practices, Methods, and Techniques ACM, London, UK; Hanson, D., Olney, A., Prilliman, S., Mathews, E., Zielke, M., Hammons, D., Stephanou, H., Upending the uncanny valley (2005) Proceedings of the National Conference on Artificial Intelligence, , Pittsburgh, Pennsylvania; Clasen, M., The Anatomy of the Zombie: A Bio-Psychological Look at the Undead Other (2010) Otherness Essays Stud, 1, pp. 1-23; Rozin, P., Fallon, A.P., A perspective on disgust (1987) Psychol. Rev, 94, pp. 23-41; Moosa, M.M., Minhaz Ud-Dean, S.M., Danger avoidance: An evolutionary explanation of the uncanny valley (2010) Biol. Theory, 5, pp. 12-14; Macdorman, K.F., Mortality Salience and the Uncanny Valley (2005) Proceedings of the 2005 5Th IEEE-RAS International Conference on Humanoid Robots, Tukuba, Japan, 5–7, , December; Macdorman, K.F., Ishaguro, H., Subjective Ratings of Robot Video Clips for Human Likeness, Familiarity, and Eeriness: An exploration of the uncanny valley Proceedings of the Iccs/Cogsci-2006 Long Symposium: Toward Social Mechanisms of Android Science, , Vancouver, BC, Canada; Ho, C.C., Macdorman, K.F., Pramono, Z.D., Human emotion and the uncanny valley: A GLM, MDS, and Isomap analysis of robot video ratings (2008) Proceedings of the 3Rd ACM/IEEE International Conference on Human Robot Interaction, pp. 169-176. , Amsterdam, The Netherlands, 12–15 March, pp; Schaller, M., Park, J.H., The behavioral immune system (And why it matters) (2011) Curr. Dir. Psychol. Sci., 20, pp. 99-103; Green, R.D., Macdorman, K.F., Ho, C.-C., Vasudevan, S., Sensitivity to the proportions of faces that vary in human likeness (2008) Comput. Hum. Behav., 24, pp. 2456-2474; Macdorman, K.F., Green, R.D., Ho, C.-C., Koch, C.T., Too Real for Comfort? Uncanny Responses to Computer Generated Faces (2009) Comput. Hum. Behav., 25, pp. 695-710; Donovan, J.M., (2002) Facial Attractiveness: Evolutionary, Cognitive, and Social Perspectives, , Ablex Publishing: Westport, CT, USA; Rhodes, G., The Evolutionary Psychology of Facial Beauty (2006) Annu. Rev. Psychol., 57, pp. 199-226; Breazeal, C., Emotion and sociable humanoid robots (2003) Int. J. Hum. Comput. Stud., 59, pp. 119-155; Krach, S., Hegel, F., Wrede, B., Sagerer, G., Binkofski, F., Kircher, T., Can machines think? Interaction and perspective taking with robots investigated via fMRI (2008) Plos ONE, 3; Chaminade, T., Hodgins, J., Kawato, M., Anthropomorphism influences perception of computer-animated characters’ actions (2007) Soc. Cogn. Affect. Neurosci., 2, pp. 206-216; Coeckelbergh, M., Artificial companions: Empathy and vulnerability mirroring in human-robot relations (2010) Studies Ethics, Law, and Technology, 4. , Berkeley Electronic Press: Berkeley, CA, USA; Suzuki, Y., Galli, A., Ilkeda, A., Itakura, S., Kitazaki, M., Measuring empathy for human and robot hand pain using electroencephalography (2015) Sci. Rep., 5; Sabanovic, S., Michalowski, M.P., Simmons, R., Robots in the wild: Observing human-robot social interaction outside the lab (2006) Proceedings of the 9Th IEEE International Workshop on Advanced Motion Control, pp. 596-601. , Istanbul, Turkey, 27–29 March; Broekens, J., Heerink, M., Rosendal, H., Assistive social robots in elderly care: A review (2009) Gerontechnology, 8, pp. 94-103; Tapus, A., Peca, A., Aly, A., Pop, C., Jisa, L., Pintea, S., Rusu, A.S., David, D.O., Children with autism social engagement in interaction with Nao, an imitative robot—A series of single case experiments (2012) Interact. Stud., 13, pp. 315-347; Breazeal, C., Toward sociable robots (2003) Robot. Auton. Syst., 42, pp. 167-175; Breazeal, C., Takanishi, A., Kobayashi, T., Social robots that interact with people (2008) Springer Handbook of Robotics, pp. 1349-1369. , Springer: Berlin/Heidelberg, Germany; Fong, T., Nourbakhsh, I., Dautenhahn, K., A survey of socially interactive robots (2003) Robot. Auton. Syst., 42, pp. 143-166; Kidd, C.D., Taggart, W., Turkle, S., A sociable robot to encourage social interaction among the elderly (2006) Proceedings of the 2006 IEEE International Conference on Robotics and Automation, pp. 3972-3976. , Orlando, FL, USA, 15–19 May; Sung, J.-Y., Guo, L., Grinter, R.E., Christensen, H.I., My Roomba is Rambo”: Intimate home appliances (2007) International Conference on Ubiquitous Computing, pp. 145-162. , Springer: Berlin/Heidelberg, Germany; Lee, S.-L., Lau, I.Y.-M., Kiesler, S., Chiu, C.-Y., Human mental models of humanoid robots (2005) Proceedings of the 2005 IEEE International Conference on Robotics and Automation, pp. 2767-2772. , In, Shatin, China, 5–9 July,; pp; Powers, A., Kiesler, S., The advisor robot: Tracing people’s mental model from a robot’s physical attributes (2006) Proceedings of the 1St ACM SIGCHI/SIGART Conference on Human-Robot Interaction, pp. 218-225. , Salt Lake City, UT, USA; Phillips, E., Ososky, S., Grove, J., Jentsch, F., From tools to teammates toward the development of appropriate mental models for intelligent robots (2011) Proceedings of the Human Factors and Ergonomics Society Annual Meeting, 55, pp. 1491-1495. , Las Vegas, NV, USA, 19–23 September; Dautenhahn, K., Woods, S., Kaouri, C., Walters, M.L., Koay, K.L., Werry, I., What is a robot companion-friend, assistant or butler? (2005) Proceedings of the 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1192-1197. , Edmonton, AB, Canada; Goetz, J., Kiesler, S., Powers, A., Matching robot appearance and behavior to tasks to improve human-robot cooperation (2003) Proceedings of the 12Th IEEE International Workshop on Robot and Human Interactive Communication (ROMAN 2003), pp. 55-60. , Millbrae, CA, USA, 31 October–2 November; Schaefer, K.E., Sanders, T.L., Yordon, R.E., Billings, D.R., Hancock, P.A., Classification of robot form: Factors predicting perceived trustworthiness (2012) Proceedings of the Human Factors and Ergonomics Society Annual Meeting, 56, pp. 1548-1552. , Boston, MA, USA, 22–26 October; Bartneck, C., Kulić, D., Croft, E., Zoghbi, S., Measurement instruments for the anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety of robots (2009) Int. J. Soc. Robot., 1, pp. 71-81; Reeves, B., Nass, C., (1996) The Media Equation: How People Treat Computers, Television, and New Media like Real People and Places, , Center for the Studies of Language and Information Publications: Stanford, CA, USA; Breazeal, C., (2004) Designing Sociable Robots, , MIT Press: Cambridge, MA, USA; Shipman, P., (2011) The Animal Connection, , Norton: New York, NY, USA; Dautenhahn, K., Robots we like to live with?!—A developmental perspective on a personalized, life-long robot companion (2004) Proceedings of the 13Th IEEE International Workshop on Robot and Human Interactive Communication (ROMAN 2004), pp. 17-22. , Okayama, Japan, 20–22 September; Brown, L.A., Walker, W.H., Prologue: Archaeology, animism and non-human agents (2008) J. Archaeol. Method Theory, 15, pp. 297-299; Alberti, B., (2009) Camb. Archaeol. J, 19, pp. 337-343; Turkle, S., Authenticity in the Age of Computers (2011) Machine Ethics, , Michael, A., Anderson, S.L., Eds.; Cambridge University Press: New York, NY, USA; Duffy, B.R., Anthropomorphism and the social robot (2003) Robot. Auton. Syst., 42, pp. 177-190; Tondu, B., Bardou, N., Aesthetics and robotics: Which form to give to the human-like robot? (2009) World Acad. Sci. Eng. Technol., 58, pp. 650-657; Miyauchi, D., Sakurai, A., Nakamura, A., Kuno, Y., Active eye contact for human-robot communication. In Proceedings of the CHI’04 Extended Abstracts on Human Factors in Computing Systems, Vienna (2004) Austria, 24-29, pp. 1099-1102. , April; Dautenhahn, K., Socially intelligent robots: Dimensions of human–robot interaction (2007) Philos. Trans. R. Soc. B Biol. Sci, 362, pp. 679-704; Siegel, M., Brazeal, C., Norton, M.I., Persuasive robotics (2009) The Influence of Robot Gender on Human Behavior. in Proceedings of the IEEE/RSJ International Conference on Intelligent, pp. 2563-2568. , Robots and Systems (IROS’09), St. Louis, MO, USA, 10–15 October; Carpenter, J., Davis, J.M., Erwin-Stuart, N., Lee, T.R., Bransford, J.D., Vye, N., Gender representation and humanoid robots designed for domestic use (2009) Int. J. Soc. Robot., 1, pp. 261-265; Nass, C., Moon, Y., Machines and mindlessness: Social responses to computers (2010) J. Soc. Issues, 56, pp. 81-103; Woods, S., Dautenhann, K., Sschultz, J., Exploring the design space of robots: Children’s perspectives (2006) Interact. Comput., 18, pp. 1390-1418; Robertson, J., Gendering humanoid robots: Robo-sexism in Japan (2010) Body Soc, 16, pp. 1-36; Schermerhorn, P., Sscheutz, M., Crowell, C.R., Robot social presence and gender: Do females view robots differently than males? (2008) Proceedings of the 3Rd ACM/IEEE International Conference on Human Robot Interaction, New York Association for Computer Machining, pp. 263-270. , In, Amsterdam, The Netherlands, 12–15 March,; pp; Yeoman, I., Michelle, M., Robots, men and sex tourism (2010) Futures, 44, pp. 365-371; Levy, D., (2009) Love and Sex with Robots, , Harper Collins: New York, NY, USA; Levy, D., (2012) The Ethics of Robot Prostitutes. in Robots Ethics: The Ethical and Social Implications of Robotics, pp. 223-231. , MIT Press: Cambridge, MA, USA,; pp; Sullins, J.P., Robots, love, and sex: The ethics of building a love machine (2012) IEEE Trans. Affect. Comput., 3, pp. 398-409; Whitby, B., Do You Want a Robot Lover? (2011) The Ethics of Caring Technologies. Robot Ethics: The Ethical and Social Implications of Robotics, 233p. , Lin, P., Keith, A., Bekey, G.A., Eds.; MIT Press: Cambridge, MA, USA; Tao, J., Tan, T., Affective computing: A review (2005) International Conference on Affective Computing and Intelligent Interaction, pp. 981-995. , Springer: Berlin/Heidelberg, Germany; Gilbert, D.T., Jones, E.E., Perceiver-Induced Constraint: Interpretations of Self-Generated Reality (1986) J. Personal. Soc. Psychol., 50, pp. 269-280; Glenda, S.-G., Loving machines: Theorizing human and sociable-technology interaction (2010) International Conference on Human-Robot Personal Relationship, pp. 1-10. , Springer: Berlin/Heidelberg, Germany},
document_type={Review},
source={Scopus},
}

@CONFERENCE{Bendel20177,
author={Bendel, O. and Schwegler, K. and Richards, B.},
title={Towards kant machines},
journal={AAAI Spring Symposium - Technical Report},
year={2017},
volume={SS-17-01 - SS-17-08},
pages={7-11},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028711580&partnerID=40&md5=56a50b4ae498bd9bb83b32bab0549b13},
abstract={For some years now, ethics no longer only means human ethics. The young discipline of machine ethics researches the morality of semi-autonomous and autonomous systems like self-driving cars, robots and drones. Interactive software systems such as chatbots are also relevant. In 2013, the School of Business at the University of Applied Sciences and Arts Northwestern Switzerland FHNW implemented a prototype of the GOODBOT, which is a novelty chatbot and a simple moral machine. One of its meta-rules was that it should not lie unless not lying would hurt the user. In a follow-up project in 2016, the LIEBOT was developed, a kind of Munchausen machine. This article describes the background and the foundations of this project and lists the chatbot's strategies of lying. Then it discusses how Munchausen machines as immoral machines can contribute to the construction and optimization of moral machines, for example Kant machines, which prefer the truth. The LIEBOT serves as a contribution to machine ethics as well as a critical review of electronic language-based systems and services. © Copyright 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
keywords={Artificial intelligence;  Learning systems;  Philosophical aspects, Autonomous systems;  Critical review;  Electronic languages;  Interactive software;  Meta rules;  Self drivings;  Switzerland;  University of applied science, Machine oriented languages},
references={Aegerter, A., FHNW forscht an "moralisch gutem" Chatbot (2014) Netzwoche, p. 18. , 4/2014; Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge: Cambridge University Press; Arkin, R.C., Robots that need to mislead: Biologically inspired machine deception (2016) Technical Report GIT-MRL12-04, Georgia Tech, , http://www.cc.gatech.edu/ai/robot-lab/online-publications/Robots_that_Need_to_Misleadv5.pdf, Atlanta, GA; Asimov, I., (1973) The Best of Isaac Asimov, , Stamford, CT: Sphere; Bendel, O., Schwegler, K., Richards, B., The L1EBOT project (2016) Machine Ethics and Machine Law, , http://machinelaw.philosophyinscience.com/wp-content/uploads/2016/06/PROCEEDINGS-verl-2.pdf, Extended abstract for the international conference in Krakow, November 18-19, 2016; Bendel, O., Towards munchausen machines (2016) Whitepaper, , http://luegenbot.ch/res/LIEBOT_Whitepaper.pdf; Bendel, O., Können Maschinen lügen? Die Wahrheit über Münchhausen-Maschinen (2015) Telepolis, , http://www.heise.de/tp/artikel/44/44242/1.html, March 1, 2015; Bendel, O., Good bot, bad bot: Dialog zwischen mensch und maschine (2013) UnternehmerZeitung, 7 (19), pp. 30-31. , (2013); Bendel, O., Der Lügenbot und andere Münchhausen-Maschinen (2013) CyberPress, , http://cyberpress.de/wiki/Maschinenethik, September 11, 2013; Bendel, O., Maschinenethik (2012) Gabler Wirtschaftslexikon, , http://wirtschaftslexikon.gabler.de/Definition/maschinenethik.html, Wiesbaden: Springer Gabler; Hammwöhner, R., Können Computer lügen? (2003) Kulturen der Lüge, pp. 299-320. , Mayer, M. ed. Köln: Böhlau; Kant, I., (1914) Werke (Akademie-Ausgabe), 6. , Berlin: Königlich Preußische Akademie der Wissenschaften; Mill, J.S., (1976) Der Utilitarismus, , Ditzingen: Reclam; Rojas, R., (2013) Können Roboter Lügen? Essays zur Robotik und Künstlichen Intelligenz, , Hannover: Heise Zeitschriften Verlag; Schwegler, K., (2016) Gefahrenpotenzial von Lügenbots, , Bachelor Thesis. School of Business FHNW. Olten; Wagner, A.R., Arkin, R.C., Acting deceptively: Providing robots with the capacity for deception (2011) International Journal of Social Robotics, 3 (1), pp. 5-26. , January 2011; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford: Oxford University Press; Williams, H., (2016) Microsoft's Teen Chatbot has Gone Wild, , http://www.gizmodo.com.au/2016/03/microsofts-teen-chatbot-has-gone-wild, March 25, 2016},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Welsh2017171,
author={Welsh, S.},
title={Clarifying the language of lethal autonomy in military robots},
journal={Intelligent Systems, Control and Automation: Science and Engineering},
year={2017},
volume={84},
pages={171-183},
doi={10.1007/978-3-319-46667-5_13},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010402414&doi=10.1007%2f978-3-319-46667-5_13&partnerID=40&md5=b1b4a2d7f0939ec9e97d6c11c1717ef6},
abstract={Many argue that robots should not make the decision to kill humans and thus call for a ban on “killer robots” or lethal autonomous weapons systems (LAWS). However lethal decision making is complex and requires detailed analysis to define what is to be banned or regulated. It is common to make distinctions between in the loop, on the loop and off the loop LAWS. It is also common to refer to the “critical functions” of selecting and engaging targets. In this paper I propose two extra LAWS types. A Type 0 LAWS is an RPV with “no robot on the lethal loop.” A Type 4 LAWS is a robot that has gone “beyond human control” and has “no human in the loop.” Types 1–3 are the familiar in, on and off the loop LAWS. I also define a third “critical function” namely defining the targeting criteria. The aim is to clarify what exactly is meant by “meaningful human control” of a LAWS and to facilitate wording such as might occur in a Protocol VI to be added to the Convention on Certain Conventional Weapons (CCW). © Springer International Publishing AG 2017.},
author_keywords={International humanitarian law;  Killer robots;  Lethal autonomous weapons systems;  Machine ethics;  Meaningful human control;  Robot ethics},
references={Adams, T., Future warfare and the decline of human decisionmaking (2001) Parameters, 41 (4), pp. 1-15; Alpaydin, E., Machine learning (2011) Wiley Interdiscip Rev: Comput Stat, 3 (3), pp. 195-203; Anderson, K., Waxman, M., (2013) Law and Ethics for Autonomous Weapon Systems: Why a Ban won’t Work and How the Laws of War Can, , http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2250126, Accessed 12 Feb 2015; Arkin, R., (2009) Governing Lethal Behaviour in Autonomous Robots, , CRC Press, Boca Rouge; (2013) Killer Robots: UK Government Policy on Fully Autonomous Weapons, , http://www.article36.org/wp-content/uploads/2013/04/Policy_Paper1.pdf; Asaro, P., Modelling the moral user (2009) IEEE Technol Soc Mag, 28 (1), pp. 20-24; Boella, G., Introduction to the special issue on normative multi-agent systems (2008) Auton Agents Multi-Agent Syst, 17 (1), pp. 1-10; Brooks, R., (2015) In defense of Killer Robots. Foreign Policy, , http://foreignpolicy.com/2015/05/18/in-defense-of-killer-robots/, Accessed 27 May 2015; Carr, N., (2015) The Glass Cage, , Random House, London; (2005) Patriot System Performance, , http://www.acq.osd.mil/dsb/reports/ADA435837.pdf, Accessed 18 Feb 2015; Galliott, J., (2015) Military Robots: Mapping the Moral Landscape, , Ashgate, Farnham, UK; Heyns, C., (2013) Report of the Special Rapporteur on Extrajudicial, Summary Or Arbitrary Executions, , http://www.ohchr.org/Documents/HRBodies/HRCouncil/RegularSession/Session23/A-HRC-23-47_en.pdf, Accessed 16 Feb 2015; Heyns, C., (2015) Comments by Christof Heyns, United Nations Special Rapporteur on Extra-Judicial, Summary Or Arbitrary Executions, , http://unog.ch/80256EDD006B8954/(httpAssets)/1869331AFF45728BC1257E2D0050EFE0/38file/2015_LAWS_MX_Heyns_Transcript.pdf, Accessed 10 Oct 2016; (2014) Statement of the International Committee of the Red Cross, , http://unog.ch/80256EDD006B8954/(httpAssets)/C99C06D328117A11C1257CD7005D8753/38file/ICRC_MX_LAWS_2014.pdf, Accessed 10 Oct 2016; (2015) Intervention by Israeli Delegation in Characteristics of LAWS (Part II), , http://unog.ch/80256EDD006B8954/(httpAssets)/AB30BF0E02AA39EAC1257E29004769F3/38file/2015_LAWS_MX_Israel_characteristics.pdf, Accessed 10 Oct 2016; Lin, P., (2015) The Right to Life and the Martens Clause, , http://unog.ch/80256EDD006B8954/(httpAssets)/2B52D16262272AE2C1257E2900419C50/38file/24+Patrick+Lin_Patrick+SS.pdf, Accessed 10 October 2016; Liu, B., Genetic algorithms (2009) Theory and Practice of Uncertain Programming, pp. 9-17. , Springer, Berlin; Lokhorst, G., van den Hoven, J., Responsibility for military robots (2011) Robot Ethics: The Ethical and Social Implications of Robotics, , Lin P, Abney K, Bekey G, MIT Press, Cambridge, MA; Lucas, G., Engineering, ethics and industry: The moral challenges of lethal autonomy (2013) Killing by Remote Control: The Ethics of an Unmanned Military, pp. 211-228. , Strawser B, OUP, New York; Matthias, A., The responsibility gap: Ascribing responsibility for the actions of learning automata (2004) Ethics Inf Technol, 6 (3), pp. 165-183; Matthias, A., (2011) Is the Concept of an Ethical Governor Philosophically Sound? STAND 338; (2014) Statement by Ambassador Zamir Akram, , http://unog.ch/80256EDD006B8954/(httpAssets)/D0326935FBB0FB7EC1257CE6005465A6/38file/Pakistan+LAWS+2014.pdf, Accessed 10 Oct 2016; (2015) Statement by Irfan Mahmood Bokhari, , http://unog.ch/80256EDD006B8954/(httpAssets)/C6F268A1B1D7B80BC1257E26005E33E4/38file/Statement+on+LAWS+-+CCW+Informal+Meeting+of+Experts+April+2015.pdf, Accessed 10 Oct 2016; Russell, S., (2015) Artificial Intelligence: Implications for Autonomous Weapons, , http://unog.ch/80256EDD006B8954/(httpAssets)/36AF841749DE9819C1257E2F0033554B/38file/2015_LAWS_MX_Russell+bis.pdf, Accessed 10 Oct 2016; Scharre, P., (2015) Presentation at the United Nations Convention on Certain Conventional Weapons, , http://unog.ch/80256EDD006B8954/(httpAssets)/98B8F054634E0C7EC1257E2F005759B0/38file/Scharre+presentation+text.pdf, Accessed 10 Oct 2016; Schmitt, M., Thurnher, J., Out of the loop: Autonomous weapon systems and the law of armed conflict (2012) Harv Natl Secur J, 4, p. 231; Sharkey, N., Death strikes from the sky: The calculus of proportionality (2009) IEEE Technol Soc Mag, 28 (1), pp. 16-19; Sharkey, N., Saying ‘no!’ to lethal autonomous targeting (2010) J Mil Ethics, 9 (4), pp. 369-383; Sharkey, N., Killing made easy: From joysticks to politics (2012) Robot Ethics: The Social and Ethical Implications of Robotics, pp. 111-128. , Lin P, Abney K, Bekey G, MIT Press, Cambridge, MA; Sparrow, R., Killer robots (2007) J Appl Philos, 24 (1), pp. 62-77; Sparrow, R., Can machines be people? Reflections on the turing triage test (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 301-316. , Lin P, Abney K, Bekey G, MIT Press, Cambridge, MA; Sutton, R., Rew, G., Barto, A., (1998) Introduction to Reinforcement Learning, , MIT Press; (2015) Statement to the Informal Meeting of Experts on Lethal Autonomous Weapons Systems, , http://unog.ch/80256EDD006B8954/(httpAssets)/1CBF996AF7AD10E2C1257E260060318A/38file/2015_LAWS_MX_United+Kingdom.pdf, Accessed 10 Oct 2016; (2014) Opening Statement, , http://unog.ch/80256EDD006B8954/(httpAssets)/E7CB7B95715BFEB4C1257CD7005DCD54/38file/USA_MX_LAWS_2014.pdf, Accessed 10 Oct 2016; (2015) Opening Statement, , http://unog.ch/80256EDD006B8954/(httpAssets)/8B33A1CDBE80EC60C1257E2800275E56/38file/2015_LAWS_MX_USA+bis.pdf, Accessed 10 Oct 2016; (2009) Unmanned Aircraft Systems Flight Plan 2009-2047, , http://fas.org/irp/program/collect/uas_2009.pdf, Accessed 13 May 2015; (1891) Official Report No. 21. the War of the Rebellion: A Compilation of the Official Records of the Union and Confederate Armies, 16. , Government Printing Office, Washington; Yudkowsky, E., Artificial intelligence as a positive and negative factor in global risk (2008) Global Catastrophic Risks, pp. 308-345. , Bostrom N, Ćirković M, Oxford University Press, New York},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Oesterheld20162747,
author={Oesterheld, C.},
title={Formalizing preference utilitarianism in physical world models},
journal={Synthese},
year={2016},
volume={193},
number={9},
pages={2747-2759},
doi={10.1007/s11229-015-0883-1},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941662419&doi=10.1007%2fs11229-015-0883-1&partnerID=40&md5=8b47b19c31374be9829d7722aa7c7dd7},
abstract={Most ethical work is done at a low level of formality. This makes practical moral questions inaccessible to formal and natural sciences and can lead to misunderstandings in ethical discussion. In this paper, we use Bayesian inference to introduce a formalization of preference utilitarianism in physical world models, specifically cellular automata. Even though our formalization is not immediately applicable, it is a first step in providing ethics and ultimately the question of how to “make the world better” with a formal basis. © 2015, The Author(s).},
author_keywords={(Machine) ethics;  Artificial life;  Formalization;  Preference utilitarianism},
references={Anderson, S.L., How machines might help us achieve breakthroughs in ethical theory and inspire us to behave better (2011) Machine ethics, pp. 524-530. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Anderson, M., Anderson, S.L., (2011) Machine ethics, , http://www.cambridge.org/cr/academic/subjects/computer-science/artificial-intelligence-and-natural-language-processing/machine-ethics, Cambridge: Cambridge University Press; Anderson, M., Anderson, S.L., Armen, C., Towards machine ethics (2004) In: AAAI-04 Workshop on agent organizations: Theory and practice, , http://www.researchgate.net/publication/259656154_Towards_Machine_Ethics, American Association for Artificial Intelligence, Menlo Park; Arneson, R.J., What, if anything (1998) renders all humans morally equal?, , http://philosophyfaculty.ucsd.edu/faculty/rarneson/singer.pdf; Bentham, J., (1823) An introduction to the principles of morals and legislation, , http://www.econlib.org/library/Bentham/bnthPMLCover.html, Oxford: Clarendon Press; Bostrom, N., Infinite ethics (2011) Analysis and Metaphysics, 10, pp. 9-59; Bostrom, N., (2014) Superintelligence. Paths, dangers, strategies, , Oxford University Press, Oxford; Charniak, E., The Bayesian basis of common sense medical diagnosis (1983) In: AAAI-83 Proceedings, , Washington: DC; Dennett, D., Intentional systems (1971) The Journal of Philosophy, 68 (4), pp. 87-106. , http://www.jstor.org/stable/2025382; Dennett, D., (1989) The intentional stance, , mit press, Cambridge; Dennett, D., Computers as prostheses for the imagination (2006) In: Talk at The International Computers and Philosophy Conference, , Laval: France; Downey, A.B., (2012) Think complexity, , O’Reilly, Sebastopol; http://www.nbi.dk/~emmeche/cePubl/97e.defLife.v3f.html, Emmeche, C. (1997). Center for the Philosophy of Nature and Science Studies Niels Bohr Institute; Ettinger, R.C.W., (2009) Youniverse: Toward a self-centered philosophy of immortalism and cryonics, , Boca Raton: Universal-Publishers; Fürnkranz, J., Hüllermeier, E., (2010) Preference learning, , Berlin: Springer; Gips, J., Towards the ethical robot. In M. Anderson & S. L. Anderson (Eds.), Machine ethics (1st ed., pp (2011) 244–253), , Cambridge: Cambridge University Press; Gruen, L., In E. N (2014) Zalta, , http://plato.stanford.edu/archives/fall2014/entries/moral-animal, Ed.: The Stanford Encyclopedia of Philosophy; http://homepages.warwick.ac.uk/~ecsgaj/icuSurvey.pdf, Hammond, P. J. (1989). Interpersonal comparison of utility: Why and how they are and should be made; Hare, R.M., (1981) Moral thinking. Its levels method, and point. Two-level consequentialism, , Clarendon Press, Oxford; Harsanyi, J.C., Sen, A., Williams, B., Morality and the theory of rational behaviour (1982) Utilitarianism and beyond, Chap. 2, pp. 39-62. , http://ebooks.cambridge.org/chapter.jsf?bid=CBO9780511611964&cid=CBO9780511611964A009&tabName=Chapter, Cambridge, Cambridge University Press; Hawking, S., Mlodinow, L., (2010) The grand design, , New York: Bantam B; Hofstadter, D., (2007) I am a strange loop, , Basic Books, New York; Isbell, J.R., Absolute games (1959) Contributions to the theory of games, pp. 357-396. , Tucker AW, Luce RD, (eds), 4, Princeton University Press, Princeton; Legg, S., Solomonoff induction. MA Thesis (1997) University of Auckland, , http://www.vetta.org/documents/legg-1996-solomonoff-induction.pdf; McLaren, B.N., Computation models of ethical reasoning. Challenges, initial steps, and future directions (2011) Machine Ethics, pp. 297-315. , Anderson M, Anderson SL, (eds), cambridge University Press, Cambridge; Moor, J.H., The nature, importance, and difficulty of machine ethics (2011) Machine ethics, Chap. 1, pp. 13-20. , Anderson M, Anderson SL, (eds), Cambridge University Press, Cambridge; Nielsen, T.D., Jensen, F.V., Learning a decision maker’s utility function from (possibly) inconsistent behavior (2004) Artificial Intelligence, 160 (1-2), pp. 53-78. , http://www.sciencedirect.com/science/article/pii/S0004370204001328; Nozick, R., Rescher, N., Newcomb’s problem and two principles of choice (1969) Essays in honor of Carl G. Hempel, pp. 114-146. , http://faculty.arts.ubc.ca/rjohns/nozick_newcomb.pdf, Berlin: Springer; Olshausen, B., (2004), http://redwood.berkeley.edu/bruno/npb163/bayes.pdf, Bayesian probability theory, Retrieved from; Orseau, L., Ring, M., Bach, J., Goertzel, B., Iklé, M., Space-time embedded intelligence (2012) Artificial general intelligence, 5, p. 391. , http://agi-conference.org/2012/wp-content/uploads/2012/12/paper_76.pdf; Peterson, M., (2009) An introduction to decision theory, , Cambridge University Press, Cambridge; Robert, C.P., The Bayesian choice (1994) A decision-theoretic motivation (1st ed.), , Berlin: Springer; Schmidhuber, J., A computer scientist’s view of life, the universe (1999) and everything, , http://arxiv.org/pdf/quant-ph/9904050v1.pdf; Shiffman, D., (2012) In S. Fry, , http://natureofcode.com/book/, Ed., The nature of code; Singer, P., (1993) Practical ethics, , Cambridge University Press, Cambridge; http://www.webcitation.org/6X7w4AJnb, Tomasik, B. (2015a). Do video-game characters matter morally?; Tomasik, B., Hedonistic vs (2015) preference utilitarianism, , http://www.webcitation.org/6X7vepyJP; http://www.webcitation.org/6X7vte3XP, Tomasik, B. (2015c). Is there suffering in fundamental physics?; Wolfram, S., Cellular automata (1983) Los Alamos Science, 9, pp. 2-21. , http://www.stephenwolfram.com/publications/academic/cellular-automata.pdf; Wolfram, S., (2002) A new kind of science, , http://www.wolframscience.com/nksonline/toc.html, Champaign: Wolfram Media; Yudkowsky, E., Creating friendly AI 1.0: The analysis and design of benevolent goal architectures (2001) Machine Intelligence Research Institute, , http://intelligence.org/files/CFAI.pdf; Zuse, K., Rechnender Raum. In: Elektronische Datenverarbeitung, 8, 336–344 (1967) ftp://ftp.idsia.ch/pub/juergen/zuse67scan.pdf, , ftp://ftp.idsia.ch/pub/juergen/zuse67scan.pdf; Zuse, K., (1969) Rechnender Raum, , Vieweg & Sohn, Brunswick},
document_type={Article},
source={Scopus},
}

@ARTICLE{Stowers201617,
author={Stowers, K. and Leyva, K. and Hancock, G.M. and Hancock, P.A.},
title={Life or Death by Robot?},
journal={Ergonomics in Design},
year={2016},
volume={24},
number={3},
pages={17-22},
doi={10.1177/1064804616635811},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978511498&doi=10.1177%2f1064804616635811&partnerID=40&md5=bea1057a74d51f101779e8a368136444},
abstract={Although robots are becoming widely known as aids to human success, they are likewise gaining reputations as tools of death. This begs the question of whether robots can be morally programmed. We address this question through discussion of various conceptualizations of robots in society. Using case studies, we highlight the irony of robots functioning both as heroic and hazardous agents. We conclude by assessing whether morality can be designed in robots and present guidelines for designers to attempt such a feat. © 2016 Human Factors and Ergonomics Society.All rights reserved.},
author_keywords={AIBO;  artificial intelligence;  ASIMO;  da Vinci Surgical System;  DARPA Robot Challenge;  human-robot interaction;  morality;  robot ethics;  robot self-awareness;  service robot},
keywords={Artificial intelligence;  Intelligent robots;  Robots, AIBO;  ASIMO;  DARPA Robot Challenge;  morality;  Robot ethics;  Self awareness;  Service robots;  Surgical systems, Human robot interaction},
references={(2013) Will i Be Next? US Drone Strikes in Pakistan, , Amnesty International. London, UK: Author; Arkin, R.C., (2009) Accountable Autonomous Agents: The Next Level, , http://www.cc.gatech.edu/ai/robot-lab/publications.html, Retrieved from; Arkin, R.C., (2009) Ethical Robots in Warfare, , http://www.cc.gatech.edu/ai/robot-lab/publications.html, Retrieved from; Arkin, R.C., (2009) Governing Lethal Behavior in Autonomous Robots, , Boca Raton, FL: CRC Press; Arkin, R.C., (2011) Moral Emotions for Robots, , http://www.cc.gatech.edu/ai/robot-lab/publications.html, Retrieved from; Arkin, R.C., (2013) The Robot Didn't Do It, , http://www.cc.gatech.edu/ai/robot-lab/publications.html, Retrieved from; Asimov, I., (1950) I, Robot, , New York, NY: Doubleday and Company; FDA eyes increase in freak accidents during robotic surgeries (2013) CBS News, , http://www.cbsnews.com/news/fda-eyes-increase-in-freak-accidents-during-robotic-surgeries/, Associated Press. (9). Retrieved from; Birkhoff, G.D., (1933) Aesthetic Measure, , Cambridge, MA: Harvard University Press; Brennan, T., Robotic technology saves life and limb (2014) JDNews, , http://www.jdnews.com/news/military/robotic-technology-saves-life-and-limb-1.298157, (31). Retrieved from; Carver, M., (1998) Britain's Army in the 20th Century, , New York, NY: Macmillan; Caulfield, B., Riding the AI rocket: Robots won't kill us, says top artificial intelligence researcher (2015) NVIDIA Blog, , http://blogs.nvidia.com/blog/2015/03/19/riding-the-ai-rocket-top-artificial-intelligence-researcher-says-robots-wont-kill-us-all/, (19). Retrieved from; Chrisley, R., Robots can't kill you - Claiming they can is dangerous (2015) The Conversation, , http://theconversation.com/robots-cant-kill-you-claiming-they-can-is-dangerous-44208, (3). Retrieved from; Cooper, M.A., Ibrahim, A., Lyu, H., Makary, M.A., Underreporting of robotic surgery complications (2013) Journal for Healthcare Quality, 37, pp. 133-138; (2014) DARPA Robotics Challenge, , http://www.darpa.mil/Our_Work/TTO/Programs/DARPA_Robotics_Challenge.aspx, Defense Advanced Research Projects Agency. Retrieved from; Davenport, C., Military push for emergency robots worries skeptics about lethal uses (2015) The Washington Post, , http://www.washingtonpost.com, (16). Retrieved from; (2012) The da Vinci Surgery Experience, , http://www.davincisurgery.com/assets/docs/da-vinci-surgery-fact-sheet-en-1005195.pdf?location=2&version=b, da Vinci. Retrieved from; (2015) Da Vinci® Surgical System: The Future of Surgery, , https://www.med.unc.edu/cares/davinci-robot, da Vinci Surgical System. Chapel Hill, NC: Computer and Robotic Enhanced Surgery Center (CARES). Retrieved from; Killer robot (1981) Deseret News, , http://news.google.com/newspapers?id=1t00AAAAIBAJ&sjid=xoMDAAAAIBAJ&pg=6313,2597702&dq=kenji+urada&hl=en, Deseret. (8). Retrieved from; Dockterman, E., Robot kills man at Volkswagen plant (2015) Time, , http://time.com/3944181/robot-kills-man-volkswagen-plant/, (1). Retrieved from; Fulcher, J., (2006) Advances in Applied Artificial Intelligence, , (Ed.). Hershey, PA: IGI Global; (2015) Autonomous Weapons: An Open Letter from AI and Robotics Researchers, , http://futureoflife.org/AI/open_letter_autonomous_weapons, Future of Life Institute. (28). Retrieved from; Gips, J., Ford, K.M., Glymour, C.N., Hayes, P.J., Towards the ethical robot (1995) Android Epistemology, pp. 243-251. , In (Eds.), Cambridge, MA: MIT Press; Gorbenko, A., Popov, V., Sheka, A., Robot self-awareness: Exploration of internal states (2012) Applied Mathematical Sciences, 6, pp. 675-688; Haidt, J., Joseph, C., Intuitive ethics: How innately prepared intuitions generate culturally variable virtues (2004) Daedalus, 133 (4), pp. 55-66; Hamilton, J.E., Hancock, P.A., Robotics safety: Exclusion guarding for industrial operations (1986) Journal of Occupational Accidents, 8 (1), pp. 69-78; Hancock, P.A., Billings, D.R., Schaefer, K.E., Chen, J.Y., De Visser, E.J., Parasuraman, R., A meta-analysis of factors affecting trust in human-robot interaction (2011) Human Factors, 53, pp. 517-527; Hancock, P.A., Hancock, G.M., Warm, J.S., Individuation: The N = 1 revolution (2009) Theoretical Issues in Ergonomics Science, 10, pp. 481-488; Hayes, C.C., Miller, C.A., (2010) Human-computer Etiquette: Cultural Expectations and the Design Implications They Place on Computers and Technology, , Boca Raton, FL: Taylor & Francis; Hofstede, G.H., (2001) Culture's Consequences: Comparing Values, Behaviors, Institutions and Organizations Across Nations, , Thousand Oaks, CA: Sage; (2015) Specifications, , http://asimo.honda.com/asimo-specs/, Honda. Asimo. Retrieved from; (2015) Service Robots, , http://www.ifr.org/service-robots/, International Federation of Robotics. Retrieved from; (2012) Living under Drones: Death, Injury, and Trauma to Civilians from US Drone Practices in Pakistan, , http://www.livingunderdrones.org/wp-content/uploads/2013/10/Stanford-NYU-Living-Under-Drones.pdf, International Human Rights and Conflict Resolution Clinic at Stanford Law School & Global Justice Clinic at NYU School of Law. Retrieved from; (2015) IRobot 510 PackBot®, , http://www.irobot.com/For-Defense-and-Security/Robots/510-PackBot.aspx#PublicSafety, iRobot. Retrieved from; Khan, A.F.U., Ford, K.M., Glymour, C.N., Hayes, P.J., Ethics of autonomous learning systems (1995) Android Epistemology, pp. 253-265. , In (Eds.), Cambridge, MA: MIT Press; Kravets, D., Jan. 25, 1979: Robot kills human (2010) Wired, , http://www.wired.com/2010/01/0125robot-kills-worker/, (25). Retrieved from; Lin, P., Stanford expert says AI probably won't kill us all (2015) Forbes, , http://www.forbes.com/sites/patricklin/2015/08/04/stanford-expert-says-ai-probably-wont-kill-us-all/, (4). Retrieved from; Lin, P., Abney, K., Bekey, G., Lin, N.G., Abney, K., Bekey, G.A., A body to kick, but still no soul to damn: Legal perspectives on robotics (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 169-186. , In (Eds.), Cambridge, MA: MIT Press; McVeigh, K., Drone strikes: Tears in Congress as Pakistani family tells of mother's death (2013) Guardian, , http://www.theguardian.com/world/2013/oct/29/pakistan-family-drone-victim-testimony-congress, (29). Retrieved from; Mears, B., High court upholds lethal injection method (2008) CNN, , http://www.cnn.com/2008/CRIME/04/16/scotus.injections/index.html, (16). Retrieved from; Murphy, R.R., Woods, D.D., Beyond Asimov: The three laws of responsible robotics (2009) IEEE Intelligent Systems, 24 (4), pp. 14-20; Novianto, R., Williams, M.A., The role of attention in robot self-awareness (2009) The 18th IEEE International Symposium on Robot and Human Interactive Communication, pp. 1047-1053. , In. Piscataway, NJ: IEEE; O'Meara, R.M., Lin, N.G., Abney, K., Bekey, G.A., Contemporary governance architecture regarding robotics technologies: An assessment (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 159-168. , In (Eds.), Cambridge, MA: MIT Press; (2015) Oxford Dictionaries, , http://www.oxforddictionaries.com/us/definition/american_english/robot, Robot. Retrieved from; Russel, B., (1925) What i Believe, , London, UK: Kegan Paul, Trench Trubner, and Co; Schaefer, K.E., Billings, D.R., Szalma, J.L., Adams, J.K., Sanders, T.L., Chen, J.Y.C., Hancock, P.A., (2014) A Meta-analysis of Factors Influencing the Development of Trust in Automation: Implications for Human-robot Interaction, , (Report ARL-TR-6984). Aberdeen Proving Ground, MD: Army Research Laboratory; Sharkey, N., Automating warfare: Lessons learned from the drones (2011) Journal of Information Science, 21, p. 140; (2015) Sony Aibo ERS 7, , http://www.sony-aibo.com/aibo-models/sony-aibo-ers-7/, Sony. Retrieved from; Taylor, A.J.P., (1948) The Habsburg Monarchy, 1809-1918: A History of the Austrian Empire and Austria-Hungary, , London, UK: Hamish Hamilton; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , New York, NY: Oxford University Press; Wong, U., Perkowski, M., A new approach to robot's imitation of behaviors by decomposition of multiple-valued relations (2002) Proceedings of Symposium on Boolean Problems, pp. 265-270. , In. Freiberg, Germany: Freiberg University of Mining and Technology},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Castro2016,
author={Castro, J.F.},
title={A bottom-up approach to machine ethics},
journal={Proceedings of the Artificial Life Conference 2016, ALIFE 2016},
year={2016},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086138133&partnerID=40&md5=09473acbd4a40cde9bb6fa70d901b686},
abstract={This paper presents a bottom-up approach to machine ethics, based on the Measurement Logic Machine (MLM). It is explained how ethical notions emerge from the workings, architecture, and environmental assumptions of the MLM framework. The MLM uses sequences of measurements to perform short-term predictive inference. The MLM ethical behavior stems from the inner evaluation of measurements that are used to filter the predictions. The MLM ethical discernment is based on measurements that detect immediate suffering in other agents. Also, a definition of what is an ethically positive modification of the inner evaluations is proposed, based on the notion of environmental intelligence and the corresponding notion of suffering. It is shown how this double approach is consistent with our intuitive notion of ethics. The MLM, with or without ethical discernment, can be used in evolutionary game theory, and gives clues to the search of ethical senses that increase the chances of survival of autonomous agents. © 2016 MIT Press. All rights reserved.},
keywords={Autonomous agents;  Game theory, Bottom up approach;  Environmental intelligence;  Ethical behavior;  Evolutionary game theory;  Logic machines;  Predictive inferences;  Short term, Philosophical aspects},
references={Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics and Information Technology, 7 (3), pp. 149-155; Bechara, A., Damasio, H., Tranel, D., Damasio, A., Deciding advantageously before knowing the advantageous strategy (1997) Science, 275 (5304), pp. 1293-1295; Blum, A., On-line algorithms in machine learning (1998) Online Algorithms: The State of the Art, pp. 306-325. , Fiat and Woeginger, editors, chapter 14, Springer, New-York; Bostrom, N., (2014) Superintelligence: Paths, Dangers, Strategies, , Oxford University Press; Castro, J.F., M-logic: Thinking with measurements and cinematic memories (2008) Proceedings of the 2008 Conference on Human System Interactions, pp. 633-638; Castro, J.F., Sub-rationality and cognitive driven cooperation (2010) Proceedings of the 3rd International Workshop on Evolutionary and Reinforcement Learning for Autonomous Robot Systems (ERLARS), pp. 53-57. , Nils T Siebel, J. and Kassahun, Y., editors; Castro, J.F., A memory structure that gives meaning to the notions of knowledge and belief (2011) AISB 2011 Human Memory for Artificial Agents, 1, pp. 2-9. , Kosakov, D. and Tsoulas, G., editors, AISBSB, York UK; Castro, J.F., Applying the measurement logic machine to multi-agent iterated games (2013) EPIA 2013 Advances in Artificial Intelligence - Local Proceedings, pp. 579-590. , Correia, L., Reis, L. Cascalho, J., Gomes, L. M., Guerra, H., and Cardoso, editors, CMATI, Azores, PO; Crandall, J.W., Non-myopic learning in repeated stochastic games (2014) CoRR, , abs/1409.8498; Crandall, J.W., Towards minimizing disappointment in repeated games (2014) Journal of Artificial Intelligence Research, 49, pp. 111-142; Gintis, H., (2009) Game Theory Evolving: A Problem-Centered Introduction to Modeling Strategic Interaction (Second, , Edition). Princeton University Press; Hamilton, W., The genetical evolution of social behaviour. I (1964) Journal of Theoretical Biology, 7 (1), pp. 1-16; Ishowo-Oloko, F., Crandall, J.W., Cebrián, M., Abdallah, S., Rahwan, I., Learning in repeated games: Human versus machine (2014) CoRR, , abs/1404.4985; Lehmann, L., Keller, L., The evolution of cooperation and altruism a general framework and a classification of models (2006) Journal of Evolutionary Biology, 19 (5), pp. 1365-1376; Libet, B., Gleason, C., Wright, E., Pearl, D., Time of conscious intention to act in relation to onset of cerebral activity (readiness-potential). The unconscious initiation of a freely voluntary act (1983) Brain, 106 (3), pp. 623-642; Lin, C.H., Chiu, Y.C., Lee, P.L., Hsieh, J.C., Is deck b a disadvantageous deck in the Iowa gambling task? (2007) Behavioral and Brain Functions, 3 (1), p. 16; Mitri, S., Floreano, D., Keller, L., The evolution of information suppression in communicating robots with conflicting interests (2009) PNAS, 106 (37), pp. 15786-15790. , communication; Pereira, L.M., Saptawijaya, A., (2016) Programming Machine Ethics, , 26 of Springer Sapere Series. Springer International Publishing, Berlin, GE; Schultze-Kraft, M., Birman, D., Rusconi, M., Allefeld, C., Grgen, K., Dhne, S., Blankertz, B., Haynes, J., The point of no return in vetoing self-initiated movements (2016) Proceedings of the National Academy of Sciences, 113 (4), pp. 1080-1085; Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., van den Driessche, G., Schrittwieser, J., Lanctot, M., Mastering the game of go with deep neural networks and tree search (2016) Nature, 529 (7587), pp. 484-489; Skinner, B.F., Superstition’ in the pigeon (1948) Journal of Experimental Psychology, 38, pp. 168-172; Trappl, R., (2015) A Construction Manual for Robots’ Ethical Systems: Requirements, Methods, Implementations, , editor Springer International Publishing, New-York, NY; Wolpert, D.H., The lack of a priori distinctions between learning algorithms (1996) Neural Computation, 8 (7), pp. 1341-1390},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Pereira2016159,
author={Pereira, L.M. and Saptawijaya, A.},
title={Bridging two realms of machine ethics},
journal={Studies in Applied Philosophy, Epistemology and Rational Ethics},
year={2016},
volume={26},
pages={159-165},
doi={10.1007/978-3-319-29354-7_10},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019707560&doi=10.1007%2f978-3-319-29354-7_10&partnerID=40&md5=92649b9923ec2e2a125aa18139c81d65},
abstract={In prior chapterswe have addressed issues and topics of machine ethics programming, whether from the individual or from the collective viewpoints, which we dub “the two realms.” Bridging capabilities between the two realms, towit, the individual and collective, helps understand the emergent ethical behavior of agents in groups, and implements them not just in simulations, but in the world of future robots and their swarms. With our co-authors, have staked footholds on either side of the two realms gap, and promoted their mutually beneficial bridging. In studies of human morality, these distinct interconnected realms are evinced too: one stressing above all individual cognition, deliberation, and behavior; the other stressing collective morals, and how they emerged. Of course, the two realms are necessarily intertwined, for cognizant individuals form populations, and the twain evolved jointly to cohere into collective norms, and into individual interaction. Evolutionary Biology, Evolutionary Anthropology and the Cognitive Sciences provide inspirational teachings to that effect. The chapter is naturally organized as follows. First, on the basis of preceding chapters, we consider the bridging of these two realms in machine ethics. Last but not least, we ponder over the teachings of human moral evolution in this regard. A final coda foretells a road to be tread, and portends about ethical machines and us. © Springer International Publishing Switzerland 2016.},
references={Ashford, E., Mulgan, T., Contractualism (2014) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/fall2012/entries/contractualism/, E.N. Zalta (ed.), Fall 2014 edn. Center for the Study of Language and Information, Stanford University; Baumard, N., (2010) Comment Nous Sommes Devenus Moraux: Une Histoire Naturelle Du Bien Et Du Mal, , Odile Jacob, Paris; Boehm, C., (1999) Hierarchy in The Forest: The Evolution of Egalitarian Behavior, , Harvard University Press, Cambridge; Boehm, C., (2012) Moral Origins: The Evolution of Virtue, Altruism, and Shame, , Basic Books, New York; Börgers, T., Sarin, R., Learning through reinforcement and replicator dynamics (1997) J.Econ. Theory, 77 (1), pp. 1-14; Bowles, S., Gintis, H., (2011) Acooperative Species:Human Reciprocity and Its Evolution, , Princeton University Press, Princeton; Boyd, R., Richerson, P., Punishment allows the evolution of cooperation (Or anything else) in sizable groups (1992) Ethol. Sociobiol, 13 (3), pp. 171-195; Churchland, P., (2011) Braintrust: What Neuroscience Tells Us about Morality, , Princeton University Press, Princeton; Elster, J., (1998) A Plea for Mechanisms. Social Mechanisms: An Analytical Approach to Social Theory, , Cambridge University Press, Cambridge; Erdal, D., Whiten, A., Boehm, C., Knauft, B., Onhuman egalitarianism: An evolutionary product of machiavellian status escalation? (1994) Curr. Anthropol, 35 (2), pp. 175-183; Gazzaniga, M.S., (2006) The Ethical Brain: The Science of Our Moral Dilemmas, , Harper Perennial, New York; Greene, J., (2013) Moral Tribes: Emotion, Reason, and the Gap between Us and Them, , The Penguin Press HC, New York; Hauser, M.D., (2007) Moral Minds: How Nature Designed Our Universal Sense of Right Andwrong, , Little Brown, London; Henrich, J., Boyd, R., Why people punish defectors: Weak conformist transmission can stabilize costly enforcement of norms in cooperative dilemmas (2001) J. Theor. Biol, 208 (1), pp. 78-89; Krebs, D.L., (2011) The Origins of Morality—An Evolutionary Account, , Oxford University Press, Oxford; Pereira, L.M., Han, T.A., Intention recognition with evolution prospection and causal bayesian networks (2011) Computational Intelligence for Engineering Systems: Emergent Applications. Intelligent Systems, Control and Automation: Science and Engineering Book Series, pp. 1-33. , Madureira, A., Ferreira, J., Vale, Z. (eds.), Springer, Dordrecht; Pinheiro, F.L., Pacheco, J.M., Santos, F.C., From local to global dilemmas in social networks (2012) Plos ONE, 7 (2); Rawls, J., (1971) A Theory of Justice, , Harvard University Press, Cambridge; Segbroeck, S.V., Jong, S.D., Nowé, A., Santos, F.C., Lenaerts, T., Learning to coordinate in complex networks (2010) Adap. Behav, 18 (5), pp. 416-427; Sober, E., Wilson, D., (1998) Unto Others: The Evolution and Psychology of Unselfish Behavior, , Harvard University Press, Cambridge; Sperber, D., Individualisme méthodologique et cognitivisme (1997) Cognition Et Sciences Sociales, , Presses Universitaires de France, Paris; Thomson, J.J., A defense of abortion (1971) Philos. Publ. Aff, 1 (1), pp. 47-66; Tomasello, M., (2014) A Natural History of Human Thinking, , Harvard University Press, Cambridge},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Bringsjord20163,
author={Bringsjord, S.},
title={Can phronetic robots be engineered by computational logicians? No . . . and yes},
journal={Frontiers in Artificial Intelligence and Applications},
year={2016},
volume={290},
pages={3-6},
doi={10.3233/978-1-61499-708-5-3},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992536217&doi=10.3233%2f978-1-61499-708-5-3&partnerID=40&md5=a262ae2128716cff6334f3eb37b852a8},
author_keywords={Divine-command ethics;  Leibniz's ethics;  Logic-based/logicist artificial intelligence;  Machine ethics;  Phronesis;  Robot ethics;  Virtue ethics},
references={Bringsjord, S., The logicist manifesto: At long last let logic-based AI become a field unto itself (2008) Journal of Applied Logic, 6 (4), pp. 502-525. , {\scriptsize{http://kryten.mm.rpi.edu/SB\_LAI\_Manifesto\_091808.pdf}}; Bringsjord, S., Declarative/logic-based cognitive modeling (2008) Ron Sun, Editor, the Handbook of Computational Psychology, pp. 127-169. , http://kryten.mm.rpi.edu/sb\_lccm\_ab-toc\_031607.pdf}, Cambridge University Press, Cambridge, UK; Bringsjord, S., (1992) What Robots Can and Can't Be, , Kluwer, Dordrecht, The Netherlands; Bringsjord, S., Offer: One billion dollars for a conscious robot. if you're honest, you must decline (2007) Journal of Consciousness Studies, 14 (7), pp. 28-43. , http://kryten.mm.rpi.edu/jcsonebillion2.pdf; Bringsjord, S., The symbol grounding problem-remains unsolved (2015) Journal of Experimental & Theoretical Artificial Intelligence, 27 (1), pp. 63-72; Bringsjord, S., Ferrucci, D., Bello, P., Creativity, the turing test, and the (better) lovelace test (2001) Minds and Machines, 11, pp. 3-27. , http://kryten.mm.rpi.edu/lovelace.pdf; Arkoudas, K., Bringsjord, S., Bello, P., Toward ethical robots via mechanized deontic logic (2005) Machine Ethics: Papers from the AAAI Fall Symposium; FS-05-06, pp. 17-23. , http://www.aaai.org/Library/Symposia/Fall/fs05-06.php, American Association for Artificial Intelligence, Menlo Park, CA; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44. , {\small{http://kryten.mm.rpi.edu/bringsjord\_inference\_robot\_ethics\_preprint.pdf}}; Johnson-Laird, P., Oatley, K., The language of emotions: An analysis of a semantic field (1989) Cognition and Emotion, 3 (2), pp. 81-123; Bringsjord, S., Sen, A., On creative self-driving cars: Hire the computational logicians, fast Applied Artificial Intelligence, , http://kryten.mm.rpi.edu/SB\_AS\_CreativeSelf-DrivingCars\_0323161130NY.pdf, forthcoming; Anscombe, G., Modern moral philosophy (1958) Philosophy, 33 (124), pp. 1-19; Driver, J., Gertrude Elizabeth Margaret Anscombe (2011) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/entries/anscombe, Edward Zalta, editor; Bringsjord, S., Taylor, J., The Divine-Command Approach to Robot Ethics (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 85-108. , http://kryten.mm.rpi.edu/Divine-Command\_Roboethics\_Bringsjord\_Taylor.pdf, P. Lin, G. Bekey, and K. Abney, editors, MIT Press, Cambridge, MA; Sullins, J., Artificial Phronesis and the Social Robot (2016) Proceedings of Robo-Philosophy 2016, Frontier of Artificial Intelligent Systems and Their Applications, Amsterdam, the Netherlands, , J. Seibt, M. Nørskov, and S. Schack Andesen, editors, IOS Press},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Funk2016119,
author={Funk, M.},
title={Tacit security? Roboethics and societal challenges of 'social robotic informationand cyberwar'},
journal={Frontiers in Artificial Intelligence and Applications},
year={2016},
volume={290},
pages={119-128},
doi={10.3233/978-1-61499-708-5-119},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992533488&doi=10.3233%2f978-1-61499-708-5-119&partnerID=40&md5=f6e9056f8cb4c88f5a7fbca305568072},
abstract={In this paper ethical and epistemological challenges of data security, information protection and privacy in social robotics are addressed. Analyzing the characteristics of asymmetric "new wars" including cyberwar and information warfare the IT based problematic of social robots will be elaborated as Social Robotic Information- and Cyberwar. It is argued that a security policy based on tacit knowledge (Tacit Security) is one possible answer to current questions in robot ethics and robot philosophy concerning data security. © 2016 The authors and IOS Press. All rights reserved.},
author_keywords={Asymmetry;  Combat robots;  Cyberwar;  Information warfare;  New wars;  Roboethics;  Robophilosophy;  Security policy;  Social robots},
keywords={Philosophical aspects;  Robots;  Security systems, Asymmetry;  Cyberwar;  Information warfare;  New wars;  Roboethics;  Robophilosophy;  Security policy;  Social robots, Robotics},
references={Nørskov, M., Editorś Preface (2016) Social Robots. Boundaries, Potential, Challenges, pp. xv-xxii. , M. Nørskov (ed.), Ashgate, Farnham & Burlington; Seibt, J., Introduction (2014) Sociable Robots and the Future of Social Relations. Proceedings of Robo Philosophy 2014, p. vii. , J. Seibt, R. Hakli & M. Nørskov (eds.), viii., (Frontiers in Artificial Intelligence and Applications, 273). IOS Press, Amsterdam a.o; Greenwald, G., (2014) No Place to Hide: Edward Snowden the NSA and the U.S. Surveillance State, , Henry Holt & Co, New York; Fidler, D.P., (2015) The Snowden Reader, , Indiana University Press, Bloomington IN; http://www.heise.de/newsticker/meldung/IslamistenhackenTV52597578.html, [accessed 2016-06-30]; http://www.faz.net/aktuell/wirtschaft/unternehmen/schreibmaschinenalsantwortaufdiensa13045490.html, [accessed 2016-06-30]; https://www.theguardian.com/world/2015/aug/21/amsterdamparistraingunmanfrance, [accessed 2016-06-30]; Gaycken, S., (2013) Einführung Cyberwar, , Freie Universität Berlin; Gaycken, S., (2013) Einführung Cybercrime, , Freie Universität Berlin; Kaldor, M., (2007) Neue und Alte Kriege. Organisierte Gewalt im Zeitalter der Globalisierung, , Suhrkamp, Frankfurt a.M; Münkler, H., (2014) Die Neuen Kriege. 5, , Auflage. Rowohlt, Reinbek bei Hamburg; Münkler, H., Der Wandel des Krieges (2014) Von der Symmetrie Zur Asymmetrie, 3. , Auflage. Velbrück Wissenschaft, Weilerswist; Arquilla, J., Ronfeldt, D., (1993) Cyberwar Is Coming!, , CA: RAND Corporation, Santa Monica; David, P.A., Clio and the Economics of QWERTY (1985) American Economic Review, 75 (2), pp. 332-337; Gordon, D.E., (1981) Electronic Warfare. Element of Strategy and Multiplier of Combat Power, , Pergamon Press, New York; Biermann, K., Wiegold, Th., (2015) Drohnen. Chancen und Gefahren Einer Neuen Technik, , Ch. Links Verlag, Berlin; Seibt, J., Towards An Ontology of Simulated Social Interaction Varieties of the 'As If' for Robots and Humans, , (forthcoming); Coeckelbergh, M., (2013) Human Being @ Risk: Enhancement, Technology, and the Evaluation of Vulnerability Transformations, , Springer, Dordrecht; Sharkey, N., Sharkey, A., The Rights and Wrongs of Robot Care (2012) Robot Ethics: The Ethical and Social Implications of Robotics, p. 278. , P. Lin, K. Abney & G. A. Bekey (eds.), The MIT Press, Cambridge, MA; Gaycken, S., (2012) Cyberwar: Das Wettrüsten Hat Längst Begonnen, , Goldmann Verlag, München; Krüger, J., Nickolay, B., Gaycken, S., (2013) The Secure Information Society, , Springer, New York; Funk, M., Humanoid Robots and Human Knowing - Perspectivity and Hermeneutics in Terms of Material Culture (2014) Robotics in Germany and Japan. Philosophical and Technical Perspectives, p. 87. , M. Funk & B. Irrgang (eds.), Peter Lang, Frankfurt am Main a.o., 69; Funk, M., Paleoanthropology and Social Robotics A Philosophical Methodology of Old and New Ways in Mediating Alterity Relations, , Tafdrup, Aagaard, Hasse & Friis (eds.), Postphenomenological Methodologies. New Ways in Mediating Techno Human Relationships. (forthcoming); Sparrow, R., Just say no' to drones (2012) IEEE Technology and Society, 31 (1), pp. 56-63; Dreyfus, H., (1972) What Computers Cańt Do: The Limits of Artificial Intelligence, , MIT Press, New York; Polanyi, M., (2009) The Tacit Dimension. with A New Foreword by Amartya Sen. The, , University of Chicago Press, Chicago & London; Gerdes, A., Ethical Issues Concerning Lethal Autonomous Robots in Warfare (2014) Sociable Robots and the Future of Social Relations. Proceedings of Robo Philosophy 2014. (Frontiers in Artificial Intelligence and Applications, 273), 277, p. 289. , J. Seibt, R. Hakli & M. Nørskov (eds.), IOS Press, Amsterdam a.o; Ess, Ch., What's Love Got to Do with It? Sexuality, and the Arts of Being Human (2016) Social Robots. Boundaries, Potential, Challenges, 57, p. 79. , M. Nørskov (ed.), Ashgate, Farnham & Burlington; Ferguson, E.S., (1992) Engineering and the Mindś Eye, , N.p., MIT Press},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Jaafar2016239,
author={Jaafar, N.H. and Ahmad, M.S. and Ahmad, A.},
title={The influence of human blaming or bragging behaviour towards software agent sincerity implementation},
journal={Advances in Intelligent Systems and Computing},
year={2016},
volume={474},
pages={239-246},
doi={10.1007/978-3-319-40162-1_26},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975513339&doi=10.1007%2f978-3-319-40162-1_26&partnerID=40&md5=62cddca2e1d6b33c8c7c46f7442b29d1},
abstract={Machine ethics have become an important field of research in software agent technology. Granting autonomy to agents and instilling strong moral values in the agents have become a priority for designing agents to ensure that they will ethically perform tasks. Sincerity is one ethical behaviour that has been proven in human organizations to motivate humans in ethically performing their jobs. However, the sincerity is ruined if they display blaming or bragging behavior while performing their jobs. This paper shows how human blaming and bragging behaviour can influence software agent sincerity implementation. We propose operational rules of software agent sincerity implementation that responds to human blaming or bragging behaviour. © Springer International Publishing Switzerland 2016.},
author_keywords={Blaming;  Bragging;  Machine ethics;  Sincerity;  Software agent},
keywords={Artificial intelligence;  Autonomous agents;  Distributed computer systems;  Philosophical aspects, Blaming;  Bragging;  Designing agents;  Sincerity;  Software agent technology, Software agents},
references={Hameed, A.S., Aljumaily, A.A., Ahmed, I.M., Daoud, I.J., Ethical Based Mathematical Model to Evaluate Software Engineering (2013) World Appl. Sci. J. (Mathematical Appl. Eng.), 21, pp. 44-49; Bhatti, O.K., Alkahtani, A., Hassan, A., Sulaiman, M., The Relationship between Islamic Piety (Taqwa) and Workplace Deviance with Organizational Justice as a Moderator (2015) Int. J. Bus. Manag, 10 (4), pp. 136-154; Gandhi, A., The sincerity of purpose: Sustainability and world peace (2013) Practicing Sustainability, pp. 45-49. , Madhavan, G., Oakley, B., Green, D., Koon, D., Low, P. (eds.), Springer New York, New York; di Zhang, J.P.D., Quality alone is not enough to be trustworthy: The mediating role of sincerity perception (2014) Int. J. Pharm. Healthc. Mark, 8 (2), pp. 226-242; Al-Mishri, M., (2011) Ensiklopedia Akhlak Muhammad (SAW), , 2nd end. Pena Pundi Aksara, Jakarta; Jaafar, N.H., Ahmad, M.S., Ahmad, A., Operational rules for implementing sincere software agents in corrective and preventive actions environment (2015) Comput. Intell. Inf. Syst, 331, pp. 307-314; Caza, A., Zhang, G., Wang, L., Bai, Y., How do you really feel? Effect of leaders’ perceived emotional sincerity on followers’ trust (2015) Leadersh. Q, 26 (4), pp. 518-531; Mat, Z., Basir, S.A., Zanariah, J., A Study on Practice of Islamic Professional Ethics in Shaping an Ethical Work Culture within Malaysian Civil Service Sector (2015) Asian Soc. Sci, 11 (17), pp. 28-34; Anderson, M., Erson, S.L., Robotics Robot Be Good (2010) Scientific American, pp. 72-77. , October; Jaafar, N.H., Basir, N.M., Ahmad, M.S., Ahmad, A., Human sincerity factors for adaptation in software agents (2014) 2014 IEEE International Conference on Control System, Computing and Engineering (ICCSCE 2014), , November; Jamaluddin, A.-S.M., Ad-Dimasqi, A.-Q., (2013) Mutiara Ihya’ Ulumuddin: Hak Milik Muslim - Imam Al-Ghazali, , 5th edn. Illusion Network, Shah Alam; Groom, V., Chen, J., Johnson, T., Kara, F.A., Nass, C., Critic, compatriot, or chump?: Responses to robot blame attribution (2010) Proceedings of the 5Th ACM/IEEE International Conference on Human-Robot Interaction, pp. 211-218; Gurdal, M.Y., Miller, J.B., Rustichini, A., Why Blame? (2013) J. Polit. Econ., 121 (6), pp. 1205-1247; Friedman, M., How to Blame People Responsibly (2013) J. Value Inq, 47 (3), pp. 271-284; Vince, R., Saleem, T., The Impact of Caution and Blame on Organizational Learning (2004) Manag. Learn, 35 (2), pp. 133-154; Gorini, A., Miglioretti, M., Pravettoni, G., A new perspective on blame culture: An experimental study (2012) J. Eval. Clin. Pract, 18 (3), pp. 671-675; Decapua, A., Boxer, D., Bragging, boasting and bravado: Male banter in a brokerage house: WL WL (1999) Women Lang, 22 (1), pp. 5-22; Zammuner, V.L., Felt Emotions, and Verbally Communicated Emotions: The Case of Pride (1996) Eur. J. Soc. Psychol, 26, pp. 233-245; Anderson, M., Erson, S.L., (2014) Toward Ensuring Ethical Behavior from Autonomous Systems: A Case-Supported Principle-Based Paradigm, pp. 19-28; Wooldridge, M., (2009) An Introduction to Multiagent Systems, , 2nd edn. John Wiley & Sons Ltd., UK; Kaur, H., Kahlon, K.S., Virk, R.S., Migration of Agents in Artificial Agent Societies: Framework and State-of-the-Art (2015) Comput. Intell. Data Min, 3, pp. 27-51; Briggs, G., Scheutz, M., Modeling blame to avoid positive face threats in natural language generation (2014) Proceedings of the INLG and SIGDIAL 2014 Joint Session, pp. 1-5. , June; De Melo, C.M., Carnevale, P., Gratch, J., The effect of expression of anger and happiness in computer agents on negotiations with humans (2011) Proceeding AAMAS 2011 the 10Th International Conference on Autonomous Agents and Multiagent Systems, pp. 937-944; Medhat, W., Hassan, A., Korashy, H., Sentiment analysis algorithms and applications: A survey (2014) Ain Shams Eng. J, 5 (4), pp. 1093-1113; Wilson, T.A., Wiebe, J., Hoffmann, P., Recognizing Contextual Polarity: An exploration of features for phrase-level sentiment analysis (2009) Comput. Linguist, 35 (3), pp. 399-433},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Swan201597,
author={Swan, M.},
title={Machine ethics interfaces: An ethics of perception of nanocognition},
journal={Rethinking Machine Ethics in the Age of Ubiquitous Technology},
year={2015},
pages={97-123},
doi={10.4018/978-1-4666-8592-5.ch006},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957364200&doi=10.4018%2f978-1-4666-8592-5.ch006&partnerID=40&md5=ea4a6b6f4be3848ec75c5f50ce9e4ef3},
abstract={The purpose of this chapter is to conceptualize cognitive nanorobots, an ethics of perception, and machine ethics interfaces. Three areas are developed as a foundational background. First is the context and definition of cognitive nanorobots (nano-scale machines that could be deployed to facilitate, aid, and improve the processes of cognition like perception and memory as a sort of neural nano-prosthetics). Second is philosophical concepts from Bergson and Deleuze regarding perception and memory, and time, image, difference, becoming, and reality. Third is a summary of traditional models of ethics (Ethics 1.0). These building blocks are then used to connect perception and ethics in the concept of machine ethics interfaces, for which an ethics of perception is required, and where an ethics of immanence (Ethics 2.0) is most appropriate. Finally, killer applications of cognitive nanorobots, and their limitations (neural data privacy rights and cognitive viruses) and future prospects are discussed. © 2015, IGI Global.},
keywords={Data privacy;  Nanorobotics;  Nanorobots;  Robots;  Viruses, Building blockes;  Future prospects;  Killer-application;  Nano-scale machines;  Neural data;  Privacy rights;  Traditional models, Philosophical aspects},
references={Ansell-Pearson, K., (2002) Philosophy and the Adventure of the Virtual: Bergson and the Time of Life, , London, UK: Routledge; Asimov, I., (1950) I, Robot, , New York, NY: Doubleday & Company; Bergson, H., (1957) Time and Free Will, , London, UK: Unwin; Bergson, H., (1988) Matter and Memory, , Brooklyn, NY: Zone Books; Bergson, H., (1999) Duration and Simultaneity, , Manchester, UK: Clinamen Press Ltd; Boehm, F., (2013) Nanomedical Device and Systems Design: Challenges, Possibilities, Visions, pp. 654-722. , New York, NY: CRC Press, especially Chapter 17: Nanomedicine in Regenerative Biosystems, Human Augmentation, and Longevity; BonJour, L., Epistemological Problems of Perception (2013) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/spr2013/entries/perception-episprob/, E.N. Zalta (Ed.), Retrieved from; Boysen, E., Nanotechnology in Medicine - Nanomedicine (2014) UnderstandingNano.com, , http://www.understandingnano.com/medicine.html, Retrieved from; Brey, P., Technology and Embodiment in Ihde and Merleau-Ponty (2000) Metaphysics, Epistemology, and Technology: Research in Philosophy and Technology, , http://www.utwente.nl/bms/wijsb/organization/brey/Publicaties_Brey/Brey_2000_Embodiment.pdf, C. Mitcham (Ed.), Retrieved from; Chiu, C.Y., Hong, Y.Y., Dweck, C.S., Lay dispositionism and implicit theories of personality (1997) Journal of Personality and Social Psychology, 73 (1), pp. 19-30. , PMID:9216077; Clark, A., (1998) Being There: Putting Brain, Body, and World Together Again, , London, UK: Bradford Books; Colebrook, C., (2002) Understanding Deleuze, , Crows Nest, Australia: Allen & Unwin; Crane, T., The Problem of Perception (2011) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/spr2011/entries/perception-problem/, E.N. Zalta (Ed.), Retrieved from; Deleuze, G., (1986) Cinema 1: The-Movement-Image, , Minneapolis, MN: University of Minnesota Press; Deleuze, G., (1989) Cinema 2: The Time-Image, , Minneapolis, MN: University of Minnesota Press; Deleuze, G., Guatarri, F., (1987) A Thousand Plateaus, , Minneapolis, MN: University of Minnesota Press; Deleuze, G., Guatarri, F., (1989) Anti-Oedipus, , Minneapolis, MN: University of Minnesota Press; Deleuze, G., Guatarri, F., (1996) What is Philosophy?, , New York, NY: Columbia University Press; Denning, T., Matsuoka, Y., Kohno, T., Neurosecurity: Security and privacy for neural devices (2009) Neurosurgical Focus, 27 (1), p. E7. , PMID:19569895; Descartes, R., (1637) Dioptrics, , http://science.larouchepac.com/fermat/Descartes%20--%20Dioptrique.pdf, Retrieved from; Foucault, M., (1980) Power/Knowledge, , New York, NY: Pantheon Books; Franssen, M., Lokhorst, G.J., van de Poel, I., Philosophy of Technology (2013) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/win2013/entries/technology/, E.N. Zalta (Ed.), Retrieved from; Freitas, R., Jr., (2003) Nanomedicine, Vol. IIA: Biocompatibility, , Austin, TX: Landes Bioscience; Guattari, F., (2009) Chaosophy: Texts and Interviews 1972-1977, , Los Angeles CA: Semiotext(e); Heidegger, M., The Question Concerning Technology (1982) The Question Concerning Technology and Other Essays, , W. Lovitt, (Ed.), New York, NY: Harper and Row; Hu, C.M., Fang, R.H., Copp, J., Luk, B.T., Zhang, L., A biomimetic nanosponge that absorbs pore-forming toxins (2013) Nature Nanotechnology, 8 (5), pp. 336-340. , PMID:23584215; Ihde, D., Bodies (2001) Technology (Electronic Mediations), , Minneapolis, MN: University of Minnesota Press; Ihde, D., A phenomenology of technics (2010) Technology and Values: Essential Readings, pp. 134-155. , C. Hanks (Ed.), New York, NY: Wiley-Blackwell; Kahneman, D., (2013) Thinking, Fast and Slow, , New York, NY: Farrar, Straus and Giroux; Kateb, B., Heiss, J.D., (2013) The Textbook of Nanoneuroscience and Nanoneurosurgery, , New York, NY: CRC Press; Kelly, K., Conversation: The Technium (2014) Edge, , http://edge.org/memberbio/kevin_kelly, Retrieved from; Klapoetke, N.C., Murata, Y., Kim, S.S., Pulver, S.R., Birdsey-Benson, A., Cho, Y.K., Independent Optical Excitation of Distinct Neural Populations (2014) Nature Methods, 11 (3), pp. 338-346. , PMID:24509633; Lanier, J., (2013) Who Owns the Future?, , New York, NY: Simon & Schuster; Mavroidis, C., (2014) Nano-Robotics in Medical Applications: From Science Fiction to Reality, , http://www.albany.edu/selforganization/presentations/2-mavroidis.pdf, Northeastern University. Retrieved from; McDonough, J., Descartes' "Dioptrics" and "Optics." (2003) The Cambridge Descartes Lexicon, , L. Nolan (Ed.), Cambridge: Cambridge University Press; Nordmann, A., Responsible innovation, the art and craft of anticipation (2014) Journal of Responsible Innovation., 1 (1), pp. 87-98; Nummenmaa, L., Glerean, E., Hari, R., Hietanen, J.K., Bodily maps of emotions (2014) Proceedings of the National Academy of Sciences of the United States of America, 111 (2), pp. 646-651. , PMID:24379370; Poell, T., Movement and Time in Cinema, Discernements: Deleuzian Aesthetics (2004) Rodopi, pp. 1-21. , J. Bloois (Ed.); Provenzale, J.M., Mohs, A.M., Nanotechnology in Neurology: Current Status and Future Possibilities (2010) US Neurology., 6 (1), pp. 12-17; Ross, L., Nisbett, R.E., (2011) The Person and the Situation: Perspectives of Social Psychology, , London, UK: Pinter & Martin Ltd; Schulz, M.J., Shanov, V.N., Yun, Y., (2009) Nanomedicine Design of Particles, Sensors, Motors, Implants, Robots, and Devices, , New York, NY: Artech House; Seo, D., Carmena, J.M., Rabaey, J.M., Alon, E., Maharbiz, M.M., Neural Dust: An Ultrasonic, Low Power Solution for Chronic Brain-Machine Interfaces (2013) arXiv, , http://arxiv.org/abs/1307.2196, 1307.2196 [q-bio.NC]. Retrieved from; Swan, M., Neural Data Privacy Rights: An Invitation For Progress In The Guise Of An Approaching Worry (2014) What Should We Be Worried About?: Real Scenarios That Keep Scientists Up at Night, , J. Brockman (Ed.), New York, NY: Harper Perennial; Vitale, C., Guide to Reading Deleuze's The Movement-Image, Part I: The Deleuzian Notion of the Image, or Worldslicing as Cinema Beyond the Human (2011) networkologies, , http://networkologies.wordpress.com/2011/04/04/the-deleuzian-notion-of-the-image-a-slice-of-the-world-orcinema-beyond-the-human/, Retrieved from; Bergson, H., (1944) Creative Evolution, , New York, NY: The Modern Library; Colebrook, C., (2002) Gilles Deleuze, , London, UK: Routledge; Deleuze, G., (1990) Bergsonism, , New York, NY: Zone Books; Deleuze, G., (1994) Difference and Repetition, , New York, NY: Columbia University Press; Deleuze, G., (2000) Proust et les signes, , Minneapolis, MN: University of Minnesota Press; Deleuze, G., Parnet, C., (1987) Dialogues, , New York, NY: Columbia University Press; Guerlac, S., (2006) Thinking in Time: An Introduction to Henri Bergson, , Cornell, NY: Cornell University Press; Meacham, D.E., Medicine and society, new continental perspectives (Preface) (2014) Medicine and Society, New Continental Perspectives, , D. E. Meacham (Ed.), New York, NY: Springer; Wheeler, M., Embodied Cognition and the Extended Mind (2011) The Continuum Companion to Philosophy of Mind, pp. 220-238. , J. Garvey (Ed.), London, UK: Bloomsbury Companions; Williams, J., (2003) Gilles Deleuze's "Difference and Repetition": A Critical Introduction and Guide, , Edinburgh, UK: Edinburgh University Press},
document_type={Book Chapter},
source={Scopus},
}

@BOOK{White20151,
author={White, J. and Searle, R.},
title={Rethinking machine ethics in the age of ubiquitous technology},
journal={Rethinking Machine Ethics in the Age of Ubiquitous Technology},
year={2015},
pages={1-331},
doi={10.4018/978-1-4666-8592-5},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957355663&doi=10.4018%2f978-1-4666-8592-5&partnerID=40&md5=b3f3e7a49465923aa3e545503dd64aaa},
abstract={As the utilization of intelligent machines spreads to numerous realms, the discourse of machine ethics has also developed and expanded. Concerns over machine intelligence and the role of automata in everyday life must be addressed before artificial intelligence and robotic technologies may be fully integrated into human society. Rethinking Machine Ethics in the Age of Ubiquitous Technology blends forward-looking, constructive, and interdisciplinary visions of ethical ideals, aims, and applications of machine technology. This visionary reference work incorporates ethical conversations in the fields of technology, computer science, robotics, and the medical industry, creating a vibrant dialogue between philosophical ideals and the applied sciences. With its broad scope of relevant topics, this book serves as an excellent tool for policymakers, academicians, researchers, advanced-level students, technology developers, and government officials. This timely publication features thoroughly researched articles on the topics of artificial moral agency, cyber-warfare, transhumanism, organic neural nets, human worker replacement, automaticity and global governance, security and surveillance, military drones, and more. © 2015 by IGI Global. All rights reserved.},
keywords={Artificial intelligence;  Intelligent robots;  Robotics, Government officials;  Intelligent machine;  Machine intelligence;  Machine technology;  Medical industries;  Robotic technologies;  Security and surveillances;  Ubiquitous technology, Philosophical aspects},
references={Aayeshah, W., Bebawi, S., The Use of Facebook as a Pedagogical Platform for Developing Investigative Journalism Skills (2014) The Social Classroom: Integrating Social Network Use in Education, pp. 83-99. , G. Mallia (Ed.), Hershey, PA: Information Science Reference;; Adi, A., Scotte, C.G., Barriers to Emerging Technology and Social Media Integration in Higher Education: Three Case Studies (2013) Social Media in Higher Education: Teaching in Web 2.0, pp. 334-354. , M. Pătruţ & B. Pătruţ (Eds.), Hershey, PA: Information Science Reference;; Agazzi, E., How Can the Problems of An Ethical Judgment on Science and Technology Be Correctly Approached? (2012) Ethical Impact of Technological Advancements and Applications in Society, pp. 30-38. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Agina, A.M., Tennyson, R.D., Kommers, P., Understanding Children's Private Speech and Self-Regulation Learning in Web 2.0: Updates of Vygotsky through Piaget and Future Recommendations (2013) Advancing Information Management through Semantic Web Concepts and Ontologies, pp. 1-53. , P. Ordóñez de Pablos, H. Nigro, R. Tennyson, S. Gonzalez Cisaro, & W. Karwowski (Eds.), Hershey, PA: Information Science Reference;; Ahrens, A., Bassus, O., Zaščerinska, J., Enterprise 2.0 in Engineering Curriculum (2014) Handbook of Research on Enterprise 2.0: Technological, Social, and Organizational Dimensions, pp. 599-617. , M. Cruz-Cunha, F. Moreira, & J. Varajão (Eds.), Hershey, PA: Business Science Reference;; Akputu, O.K., Seng, K.P., Lee, Y.L., Affect Recognition for Web 2.0 Intelligent E-Tutoring Systems: Exploration of Students' Emotional Feedback (2014) E-Learning 2.0 Technologies and Web Applications in Higher Education, pp. 188-215. , J. Pelet (Ed.), Hershey, PA: Information Science Reference;; Al-Hajri, S., Tatnall, A., A Socio-Technical Study of the Adoption of Internet Technology in Banking, Re-Interpreted as an Innovation Using Innovation Translation (2013) Social and Professional Applications of Actor-Network Theory for Technology Development, pp. 207-220. , A. Tatnall (Ed.), Hershey, PA: Information Science Reference;; Al Hujran, O., Aloudat, A., Altarawneh, I., Factors Influencing Citizen Adoption of E-Government in Developing Countries: The Case of Jordan. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (2), pp. 1-19; Alavi, R., Islam, S., Jahankhani, H., Al-Nemrat, A., Analyzing Human Factors for an Effective Information Security Management System. [IJSSE] (2013) International Journal of Secure Software Engineering, 4 (1), pp. 50-74; Altun, N.E., Yildiz, S., Effects of Different Types of Tasks on Junior ELT Students' Use of Communication Strategies in Computer-Mediated Communication. [IJCALLT] (2013) International Journal of Computer-Assisted Language Learning and Teaching, 3 (2), pp. 17-40; Amaldi, P., Smoker, A., An Organizational Study into the Concept of "Automation Policy" in a Safety Critical Socio-Technical System. [IJSKD] (2013) International Journal of Sociotechnology and Knowledge Development, 5 (2), pp. 1-17; An, I.S., Integrating Technology-Enhanced Student Self-Regulated Tasks into University Chinese Language Course. [IJCALLT] (2013) International Journal of Computer-Assisted Language Learning and Teaching, 3 (1), pp. 1-15; Andacht, F., The Tangible Lure of the Technoself in the Age of Reality Television (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 360-381. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Anderson, A., Petersen, A., Shaping the Ethics of an Emergent Field: Scientists' and Policymakers' Representations of Nanotechnologies (2012) Ethical Impact of Technological Advancements and Applications in Society, pp. 219-231. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Anderson, J.L., Games and the Development of Students' Civic Engagement and Ecological Stewardship (2014) Gamification for Human Factors Integration: Social, Education, and Psychological Issues, pp. 199-215. , J. Bishop (Ed.), Hershey, PA: Information Science Reference;; Ann, O.C., Lu, M.V., Theng, L.B., A Face Based Real Time Communication for Physically and Speech Disabled People (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1434-1460. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Aricak, O.T., Tanrikulu, T., Siyahhan, S., Kinay, H., Cyberbullying: The Bad and the Ugly Side of Information Age (2013) Social Media in Higher Education: Teaching in Web 2.0, pp. 318-333. , M. Pătruţ & B. Pătruţ (Eds.), Hershey, PA: Information Science Reference;; Ariely, G., Boundaries of Socio-Technical Systems and IT for Knowledge Development in Military Environments. [IJSKD] (2011) International Journal of Sociotechnology and Knowledge Development, 3 (3), pp. 1-14; Ariely, G., Boundaries of Socio-Technical Systems and IT for Knowledge Development in Military Environments (2013) Knowledge and Technological Development Effects on Organizational and Social Structures, pp. 224-238. , J. Abdelnour-Nocera (Ed.), Hershey, PA: Information Science Reference;; Arjunan, S., Kumar, D.K., Weghorn, H., Naik, G., Facial Muscle Activity Patterns for Recognition of Utterances in Native and Foreign Language: Testing for its Reliability and Flexibility (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1462-1480. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Arling, P.A., Miech, E.J., Arling, G.W., Comparing Electronic and Face-to-Face Communication in the Success of a Long-Term Care Quality Improvement Collaborative. [IJRQEH] (2013) International Journal of Reliable and Quality E-Healthcare, 2 (1), pp. 1-10; Asghari-Oskoei, M., Hu, H., Using Myoelectric Signals to Manipulate Assisting Robots and Rehabilitation Devices (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 970-990. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Aspradaki, A.A., Deliberative Democracy and Nanotechnologies in Health. [IJT] (2013) International Journal of Technoethics, 4 (2), pp. 1-14; Asselin, S.B., Assistive Technology in Higher Education (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1196-1208. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Auld, G., Henderson, M., The Ethical Dilemmas of Social Networking Sites in Classroom Contexts (2014) The Social Classroom: Integrating Social Network Use in Education, pp. 192-207. , G. Mallia (Ed.), Hershey, PA: Information Science Reference;; Awwal, M.A., Influence of Age and Genders on the Relationship between Computer Self-Efficacy and Information Privacy Concerns. [IJTHI] (2012) International Journal of Technology and Human Interaction, 8 (1), pp. 14-37; Ballesté, F., Torras, C., Effects of Human-Machine Integration on the Construction of Identity (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 574-591. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Baporikar, N., Effective E-Learning Strategies for a Borderless World (2014) ELearning 2.0 Technologies and Web Applications in Higher Education, pp. 22-44. , J. Pelet (Ed.), Hershey, PA: Information Science Reference;; Bardone, E., Unintended Affordances as Violent Mediators: Maladaptive Effects of Technologically Enriched Human Niches. [IJT] (2011) International Journal of Technoethics, 2 (4), pp. 37-52; Basham, R., Surveilling the Elderly: Emerging Demographic Needs and Social Implications of RFID Chip Technology Use (2014) Uberveillance and the Social Implications of Microchip Implants: Emerging Technologies, pp. 169-185. , M. Michael & K. Michael (Eds.), Hershey, PA: Information Science Reference;; Bates, M., The Ur-Real Sonorous Envelope: Bridge between the Corporeal and the Online Technoself (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 272-292. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Bauer, K.A., Transhumanism and Its Critics: Five Arguments against a Posthuman Future (2012) Ethical Impact of Technological Advancements and Applications in Society, pp. 232-242. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Bax, S., Normalisation Revisited: The Effective Use of Technology in Language Education. [IJCALLT] (2011) International Journal of Computer-Assisted Language Learning and Teaching, 1 (2), pp. 1-15; Baya'a, N., Daher, W., Facebook as an Educational Environment for Mathematics Learning (2014) The Social Classroom: Integrating Social Network Use in Education, pp. 171-190. , G. Mallia (Ed.), Hershey, PA: Information Science Reference;; Bayerl, P.S., Janneck, M., Professional Online Profiles: The Impact of Personalization and Visual Gender Cues on Online Impression Formation. [IJSKD] (2013) International Journal of Sociotechnology and Knowledge Development, 5 (3), pp. 1-16; Bell, D., Shirzad, S.R., Social Media Business Intelligence: A Pharmaceutical Domain Analysis Study. [IJSKD] (2013) International Journal of Sociotechnology and Knowledge Development, 5 (3), pp. 51-73; Bergmann, N.W., Ubiquitous Computing for Independent Living (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 679-692. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Bertolotti, T., Facebook Has It: The Irresistible Violence of Social Cognition in the Age of Social Networking. [IJT] (2011) International Journal of Technoethics, 2 (4), pp. 71-83; Berzsenyi, C., Writing to Meet Your Match: Rhetoric and Self-Presentation for Four Online Daters (2014) Innovative Methods and Technologies for Electronic Discourse Analysis, pp. 210-234. , H. Lim & F. Sudweeks (Eds.), Hershey, PA: Information Science Reference;; Best, L.A., Buhay, D.N., McGuire, K., Gurholt, S., Foley, S., The Use of Web 2.0 Technologies in Formal and Informal Learning Settings (2014) The Social Classroom: Integrating Social Network Use in Education, pp. 1-22. , G. Mallia (Ed.), Hershey, PA: Information Science Reference;; Bhattacharya, S., Model-Based Approaches for Scanning Keyboard Design: Present State and Future Directions (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1497-1515. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Bibby, S., Do Students Wish to 'Go Mobile'?: An Investigation into Student Use of PCs and Cell Phones. [IJCALLT] (2011) International Journal of Computer-Assisted Language Learning and Teaching, 1 (2), pp. 43-54; Bishop, J., The Psychology of Trolling and Lurking: The Role of Defriending and Gamification for Increasing Participation in Online Communities Using Seductive Narratives (2014) Gamification for Human Factors Integration: Social, Education, and Psychological Issues, pp. 162-179. , J. Bishop (Ed.), Hershey, PA: Information Science Reference;; Bishop, J., Goode, M.M., Towards a Subjectively Devised Parametric User Model for Analysing and Influencing Behaviour Online Using Neuroeconomics (2014) Gamification for Human Factors Integration: Social, Education, and Psychological Issues, pp. 80-95. , J. Bishop (Ed.), Hershey, PA: Information Science Reference;; Biswas, P., A Brief Survey on User Modelling in Human Computer Interaction (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 102-119. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Black, D., The Digital Soul (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 157-174. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Blake, S., Winsor, D.L., Burkett, C., Allen, L., iPods, Internet and Apps, Oh My: Age Appropriate Technology in Early Childhood Educational Environments (2014) K-12 Education: Concepts, Methodologies, Tools, and Applications, pp. 1650-1668. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Boghian, I., Using Facebook in Teaching (2013) Social Media in Higher Education: Teaching in Web 2.0, pp. 86-103. , M. Pătruţ & B. Pătruţ (Eds.), Hershey, PA: Information Science Reference;; Boling, E.C., Beatty, J., Overcoming the Tensions and Challenges of Technology Integration: How Can We Best Support our Teachers? (2014) K-12 Education: Concepts, Methodologies, Tools, and Applications, pp. 1504-1524. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Bonanno, P., Designing Learning in Social Online Learning Environments: A Process-Oriented Approach (2014) The Social Classroom: Integrating Social Network Use in Education, pp. 40-61. , G. Mallia (Ed.), Hershey, PA: Information Science Reference;; Bongers, B., Smith, S., Interactivating Rehabilitation through Active Multimodal Feedback and Guidance (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1650-1674. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Bottino, R.M., Ott, M., Tavella, M., Serious Gaming at School: Reflections on Students' Performance, Engagement and Motivation. [IJGBL] (2014) International Journal of Game-Based Learning, 4 (1), pp. 21-36; Brad, S., Design for Quality of ICTAided Engineering Course Units. [IJQAETE] (2014) International Journal of Quality Assurance in Engineering and Technology Education, 3 (1), pp. 52-80; Braman, J., Thomas, U., Vincenti, G., Dudley, A., Rodgers, K., Preparing Your Digital Legacy: Assessing Awareness of Digital Natives (2014) The Social Classroom: Integrating Social Network Use in Education, pp. 208-223. , G. Mallia (Ed.), Hershey, PA: Information Science Reference;; Bratitsis, T., Demetriadis, S., Research Approaches in Computer-Supported Collaborative Learning. [IJeC] (2013) International Journal of e-Collaboration, 9 (1), pp. 1-8; Brick, B., The Role of Social Networking Sites for Language Learning in UK Higher Education: The Views of Learners and Practitioners. [IJCALLT] (2012) International Journal of Computer-Assisted Language Learning and Teaching, 2 (3), pp. 35-53; Burke, M.E., Speed, C., Knowledge Recovery: Applications of Technology and Memory (2014) Uberveillance and the Social Implications of Microchip Implants: Emerging Technologies, pp. 133-142. , M. Michael & K. Michael (Eds.), Hershey, PA: Information Science Reference;; Burton, A.M., Liu, H., Battersby, S., Brown, D., Sherkat, N., Standen, P., Walker, M., The Use of Motion Tracking Technologies in Serious Games to Enhance Rehabilitation in Stroke Patients (2014) Gamification for Human Factors Integration: Social, Education, and Psychological Issues, pp. 148-161. , J. Bishop (Ed.), Hershey, PA: Information Science Reference;; Burusic, J., Karabegovic, M., The Role of Students' Personality Traits in the Effective Use of Social Networking Sites in the Educational Context (2014) The Social Classroom: Integrating Social Network Use in Education, pp. 224-243. , G. Mallia (Ed.), Hershey, PA: Information Science Reference;; Busch, C.D., Lorenzo, A.M., Sánchez, I.M., González, B.G., García, T.P., Riveiro, L.N., Loureiro, J.P., In-TIC for Mobile Devices: Support System for Communication with Mobile Devices for the Disabled (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 345-356. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Bute, S.J., Integrating Social Media and Traditional Media within the Academic Environment (2013) Social Media in Higher Education: Teaching in Web 2.0, pp. 75-85. , M. Pătruţ & B. Pătruţ (Eds.), Hershey, PA: Information Science Reference;; Butler-Pascoe, M.E., The History of CALL: The Intertwining Paths of Technology and Second/Foreign Language Teaching. [IJCALLT] (2011) International Journal of Computer-Assisted Language Learning and Teaching, 1 (1), pp. 16-32; Cabrera, L., Human Implants: A Suggested Framework to Set Priorities (2012) Ethical Impact of Technological Advancements and Applications in Society, pp. 243-253. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Cacho-Elizondo, S., Shahidi, N., Tossan, V., Intention to Adopt a Text Message-based Mobile Coaching Service to Help Stop Smoking: Which Explanatory Variables? [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (4), pp. 1-19; Caldelli, R., Becarelli, R., Filippini, F., Picchioni, F., Giorgetti, R., Electronic Voting by Means of Digital Terrestrial Television: The Infrastructure, Security Issues and a Real Test-Bed (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 905-915. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Camacho, M., Making the Most of Informal and Situated Learning Opportunities through Mobile Learning (2013) Social Media in Higher Education: Teaching in Web 2.0, pp. 355-370. , M. Pătruţ & B. Pătruţ (Eds.), Hershey, PA: Information Science Reference;; Camilleri, V., Busuttil, L., Montebello, M., MOOCs: Exploiting Networks for the Education of the Masses or Just a Trend? (2014) The Social Classroom: Integrating Social Network Use in Education, pp. 348-366. , G. Mallia (Ed.), Hershey, PA: Information Science Reference;; Campos, P., Noronha, H., Lopes, A., Work Analysis Methods in Practice: The Context of Collaborative Review of CAD Models. [IJSKD] (2013) International Journal of Sociotechnology and Knowledge Development, 5 (2), pp. 34-44; Cao, G., A Paradox Between Technological Autonomy and Ethical Heteronomy of Philosophy of Technology: Social Control System. [IJT] (2013) International Journal of Technoethics, 4 (1), pp. 52-66; Carofiglio, V., Abbattista, F., BCIBased User-Centered Design for Emotionally-Driven User Experience (2013) Cases on Usability Engineering: Design and Development of Digital Products, pp. 299-320. , M. Garcia-Ruiz (Ed.), Hershey, PA: Information Science Reference;; Carpenter, J., Just Doesn't Look Right: Exploring the Impact of Humanoid Robot Integration into Explosive Ordnance Disposal Teams (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 609-636. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Carroll, J.L., Wheelchairs as Assistive Technology: What a Special Educator Should Know (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 623-633. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Casey, L.B., Williamson, R.L., A Parent's Guide to Support Technologies for Preschool Students with Disabilities (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1340-1356. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Caviglione, L., Coccoli, M., Merlo, A., On Social Network Engineering for Secure Web Data and Services (2013) Social Network Engineering for Secure Web Data and Services, pp. 1-4. , L. Caviglione, M. Coccoli, & A. Merlo (Eds.), Hershey, PA: Information Science Reference;; Chadwick, D.D., Fullwood, C., Wesson, C.J., Intellectual Disability, Identity, and the Internet (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 198-223. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Chao, L., Wen, Y., Chen, P., Lin, C., Lin, S., Guo, C., Wang, W., The Development and Learning Effectiveness of a Teaching Module for the Algal Fuel Cell: A Renewable and Sustainable Battery. [IJTHI] (2012) International Journal of Technology and Human Interaction, 8 (4), pp. 1-15; Charnkit, P., Tatnall, A., Knowledge Conversion Processes in Thai Public Organisations Seen as an Innovation: The Re-Analysis of a TAM Study Using Innovation Translation (2013) Social and Professional Applications of Actor-Network Theory for Technology Development, pp. 88-102. , A. Tatnall (Ed.), Hershey, PA: Information Science Reference;; Chen, E.T., Challenge and Complexity of Virtual Team Management (2014) Collaborative Communication Processes and Decision Making in Organizations, pp. 109-120. , E. Nikoi & K. Boateng (Eds.), Hershey, PA: Business Science Reference;; Chen, R., Xie, T., Lin, T., Chen, Y., Adaptive Windows Layout Based on Evolutionary Multi-Objective Optimization. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (3), pp. 63-72; Chen, W., Juang, Y., Chang, S., Wang, P., Informal Education of Energy Conservation: Theory, Promotion, and Policy Implication. [IJTHI] (2012) International Journal of Technology and Human Interaction, 8 (4), pp. 16-44; Chino, T., Torii, K., Uchihira, N., Hirabayashi, Y., Speech Interaction Analysis on Collaborative Work at an Elderly Care Facility. [IJSKD] (2013) International Journal of Sociotechnology and Knowledge Development, 5 (2), pp. 18-33; Chiu, M., Gaps Between Valuing and Purchasing Green-Technology Products: Product and Gender Differences. [IJTHI] (2013) International Journal of Technology and Human Interaction, 8 (3), pp. 54-68; Chivukula, V., Shur, M., Web-Based Experimentation for Students with Learning Disabilities (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1156-1172. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Coakes, E., Bryant, A., Land, F., Phippen, A., The Dark Side of Technology: Some Sociotechnical Reflections. [IJSKD] (2011) International Journal of Sociotechnology and Knowledge Development, 3 (4), pp. 40-51; Cole, I.J., Usability of Online Virtual Learning Environments: Key Issues for Instructors and Learners (2013) Student Usability in Educational Software and Games: Improving Experiences, pp. 41-58. , C. Gonzalez (Ed.), Hershey, PA: Information Science Reference;; Colombo, B., Antonietti, A., Sala, R., Caravita, S.C., Blog Content and Structure, Cognitive Style and Metacognition. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (3), pp. 1-17; Constantinides, M., Integrating Technology on Initial Training Courses: A Survey Amongst CELTA Tutors. [IJCALLT] (2011) International Journal of Computer-Assisted Language Learning and Teaching, 1 (2), pp. 55-71; Cook, R.G., Crawford, C.M., Addressing Online Student Learning Environments and Socialization Through Developmental Research (2013) Cases on Assessment and Evaluation in Education, pp. 504-536. , M. Khosrow-Pour (Ed.), Hershey, PA: Information Science Reference;; Corritore, C.L., Wiedenbeck, S., Kracher, B., Marble, R.P., Online Trust and Health Information Websites. [IJTHI] (2012) International Journal of Technology and Human Interaction, 8 (4), pp. 92-115; Covarrubias, M., Bordegoni, M., Cugini, U., Gatti, E., Supporting Unskilled People in Manual Tasks through Haptic-Based Guidance (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 947-969. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Coverdale, T.S., Wilbon, A.D., The Impact of In-Group Membership on e-Loyalty of Women Online Shoppers: An Application of the Social Identity Approach to Website Design. [IJEA] (2013) International Journal of E-Adoption, 5 (1), pp. 17-36; Crabb, P.B., Stern, S.E., Technology Traps: Who Is Responsible? (2012) Ethical Impact of Technological Advancements and Applications in Society, pp. 39-46. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Crespo, R.G., Martíne, O.S., Lovelle, J.M., García-Bustelo, B.C., Díaz, V.G., Ordoñez de Pablos, P., Improving Cognitive Load on Students with Disabilities through Software Aids (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1255-1268. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Croasdaile, S., Jones, S., Ligon, K., Oggel, L., Pruett, M., Supports for and Barriers to Implementing Assistive Technology in Schools (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1118-1130. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Cucchiarini, C., Strik, H., Second Language Learners' Spoken Discourse: Practice and Corrective Feedback through Automatic Speech Recognition (2014) Innovative Methods and Technologies for Electronic Discourse Analysis, pp. 169-189. , H. Lim & F. Sudweeks (Eds.), Hershey, PA: Information Science Reference;; Dafoulas, G.A., Saleeb, N., 3D Assistive Technologies and Advantageous Themes for Collaboration and Blended Learning of Users with Disabilities (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 421-453. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Dai, Z., Paasch, K., A Web-Based Interactive Questionnaire for PV Application. [IJSKD] (2013) International Journal of Sociotechnology and Knowledge Development, 5 (2), pp. 82-93; Daradoumis, T., Lafuente, M.M., Studying the Suitability of Discourse Analysis Methods for Emotion Detection and Interpretation in Computer-Mediated Educational Discourse (2014) Innovative Methods and Technologies for Electronic Discourse Analysis, pp. 119-143. , H. Lim & F. Sudweeks (Eds.), Hershey, PA: Information Science Reference;; Davis, B., Mason, P., Positioning Goes to Work: Computer-Aided Identification of Stance Shifts and Semantic Themes in Electronic Discourse Analysis (2014) Innovative Methods and Technologies for Electronic Discourse Analysis, pp. 394-413. , H. Lim & F. Sudweeks (Eds.), Hershey, PA: Information Science Reference;; Dogoriti, E., Pange, J., Considerations for Online English Language Learning: The Use of Facebook in Formal and Informal Settings in Higher Education (2014) The Social Classroom: Integrating Social Network Use in Education, pp. 147-170. , G. Mallia (Ed.), Hershey, PA: Information Science Reference;; Donegan, M., Features of Gaze Control Systems (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1055-1061. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Douglas, G., Morton, H., Jack, M., Remote Channel Customer Contact Strategies for Complaint Update Messages. [IJTHI] (2012) International Journal of Technology and Human Interaction, 8 (2), pp. 43-55; Drake, J.R., Byrd, T.A., Searching for Alternatives: Does Your Disposition Matter? [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (1), pp. 18-36; Driouchi, A., ICTs and Socioeconomic Performance with Focus on ICTs and Health (2013) ICTs for Health, Education, and Socioeconomic Policies: Regional Cases, pp. 104-125. , Hershey, PA: Information Science Reference; Driouchi, A., Social Deficits, Social Cohesion, and Prospects from ICTs (2013) ICTs for Health, Education, and Socioeconomic Policies: Regional Cases, pp. 230-251. , Hershey, PA: Information Science Reference; Driouchi, A., Socioeconomic Reforms, Human Development, and the Millennium Development Goals with ICTs for Coordination (2013) ICTs for Health, Education, and Socioeconomic Policies: Regional Cases, pp. 211-229. , Hershey, PA: Information Science Reference; Drula, G., Media and Communication Research Facing Social Media (2013) Social Media in Higher Education: Teaching in Web 2.0, pp. 371-392. , M. Pătruţ & B. Pătruţ (Eds.), Hershey, PA: Information Science Reference;; Druzhinina, O., Hvannberg, E.T., Halldorsdottir, G., Feedback Fidelities in Three Different Types of Crisis Management Training Environments. [IJSKD] (2013) International Journal of Sociotechnology and Knowledge Development, 5 (2), pp. 45-62; Eason, K., Waterson, P., Davda, P., The Sociotechnical Challenge of Integrating Telehealth and Telecare into Health and Social Care for the Elderly. [IJSKD] (2013) International Journal of Sociotechnology and Knowledge Development, 5 (4), pp. 14-26; Edenius, M., Rämö, H., An Office on the Go: Professional Workers, Smartphones and the Return of Place. [IJTHI] (2011) International Journal of Technology and Human Interaction, 7 (1), pp. 37-55; Eke, D.O., ICT Integration in Nigeria: The Socio-Cultural Constraints. [IJTHI] (2011) International Journal of Technology and Human Interaction, 7 (2), pp. 21-27; Evett, L., Ridley, A., Keating, L., Merritt, P., Shopland, N., Brown, D., Designing Serious Games for People with Disabilities: Game, Set, and Match to the Wii (2014) Gamification for Human Factors Integration: Social, Education, and Psychological Issues, pp. 97-105. , J. Bishop (Ed.), Hershey, PA: Information Science Reference;; Evmenova, A.S., Behrmann, M.M., Communication Technology Integration in the Content Areas for Students with High-Incidence Disabilities: A Case Study of One School System (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 26-53. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Evmenova, A.S., King-Sears, M.E., Technology and Literacy for Students with Disabilities (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1269-1291. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Ewais, A., De Troyer, O., Usability Evaluation of an Adaptive 3D Virtual Learning Environment. [IJVPLE] (2013) International Journal of Virtual and Personal Learning Environments, 4 (1), pp. 16-31; Farrell, H.J., The Student with Complex Education Needs: Assistive and Augmentative Information and Communication Technology in a Ten-Week Music Program (2014) K-12 Education: Concepts, Methodologies, Tools, and Applications, pp. 1436-1472. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Fathulla, K., Rethinking Human and Society's Relationship with Technology. [IJSKD] (2012) International Journal of Sociotechnology and Knowledge Development, 4 (2), pp. 21-28; Fidler, C.S., Kanaan, R.K., Rogerson, S., Barriers to e-Government Implementation in Jordan: The Role of Wasta. [IJTHI] (2011) International Journal of Technology and Human Interaction, 7 (2), pp. 9-20; Fischer, G., Herrmann, T., Socio-Technical Systems: A Meta-Design Perspective (2013) Knowledge and Technological Development Effects on Organizational and Social Structures, pp. 1-36. , J. Abdelnour-Nocera (Ed.), Hershey, PA: Information Science Reference;; Foreman, J., Borkman, T., Learning Sociology in a Massively Multi-Student Online Learning Environment (2014) Gamification for Human Factors Integration: Social, Education, and Psychological Issues, pp. 216-224. , J. Bishop (Ed.), Hershey, PA: Information Science Reference;; Fornaciari, F., The Language of Technoself: Storytelling, Symbolic Interactionism, and Online Identity (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 64-83. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Fox, J., Ahn, S.J., Avatars: Portraying, Exploring, and Changing Online and Offline Identities (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 255-271. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Fox, W.P., Binstock, J., Minutas, M., Modeling and Methodology for Incorporating Existing Technologies to Produce Higher Probabilities of Detecting Suicide Bombers. [IJORIS] (2013) International Journal of Operations Research and Information Systems, 4 (3), pp. 1-18; Franchi, E., Tomaiuolo, M., Distributed Social Platforms for Confidentiality and Resilience (2013) Social Network Engineering for Secure Web Data and Services, pp. 114-136. , L. Caviglione, M. Coccoli, & A. Merlo (Eds.), Hershey, PA: Information Science Reference;; Frigo, C.A., Pavan, E.E., Prosthetic and Orthotic Devices (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 549-613. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Fuhrer, C., Cucchi, A., Relations Between Social Capital and Use of ICT: A Social Network Analysis Approach. [IJTHI] (2012) International Journal of Technology and Human Interaction, 8 (2), pp. 15-42; Galinski, C., Beckmann, H., Concepts for Enhancing Content Quality and eAccessibility: In General and in the Field of eProcurement (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 180-197. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Galván, J.M., Luppicini, R., The Humanity of the Human Body: Is Homo Cybersapien a New Species? [IJT] (2012) International Journal of Technoethics, 3 (2), pp. 1-8; García-Gómez, A., Technoself-Presentation on Social Networks: A Gender-Based Approach (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 382-398. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Gill, L., Hathway, E.A., Lange, E., Morgan, E., Romano, D., Coupling Real-Time 3D Landscape Models with Microclimate Simulations. [IJEPR] (2013) International Journal of E-Planning Research, 2 (1), pp. 1-19; Godé, C., Lebraty, J., Improving Decision Making in Extreme Situations: The Case of a Military Decision Support System. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (1), pp. 1-17; Griol, D., Callejas, Z., López-Cózar, R., Conversational Metabots for Educational Applications in Virtual Worlds (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1405-1433. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Griol Barres, D., Callejas Carrión, Z., Molina López, J.M., Sanchis de Miguel, A., Towards the Use of Dialog Systems to Facilitate Inclusive Education (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1292-1312. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Groba, B., Pousada, T., Nieto, L., Assistive Technologies, Tools and Resources for the Access and Use of Information and Communication Technologies by People with Disabilities (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 246-260. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Groß, M., Personal Knowledge Management and Social Media: What Students Need to Learn for Business Life (2013) Social Media in Higher Education: Teaching in Web 2.0, pp. 124-143. , M. Pătruţ & B. Pătruţ (Eds.), Hershey, PA: Information Science Reference;; Gu, L., Aiken, M., Wang, J., Wibowo, K., The Influence of Information Control upon Online Shopping Behavior. [IJTHI] (2011) International Journal of Technology and Human Interaction, 7 (1), pp. 56-66; Hainz, T., Value Lexicality and Human Enhancement. [IJT] (2012) International Journal of Technoethics, 3 (4), pp. 54-65; Harnesk, D., Lindström, J., Exploring Socio-Technical Design of Crisis Management Information Systems (2014) Crisis Management: Concepts, Methodologies, Tools and Applications, pp. 514-530. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Hicks, D., Ethics in the Age of Technological Change and its Impact on the Professional Identity of Librarians (2014) Technology and Professional Identity of Librarians: The Making of the Cybrarian, pp. 168-187. , Hershey, PA: Information Science Reference;; Hicks, D., Technology, Profession, Identity (2014) Technology and Professional Identity of Librarians: The Making of the Cybrarian, pp. 1-20. , Hershey, PA: Information Science Reference;; Hirata, M., Yanagisawa, T., Matsushita, K., Sugata, H., Kamitani, Y., Suzuki, T., Yoshimine, T., Brain-Machine Interface Using Brain Surface Electrodes: Real-Time Robotic Control and a Fully Implantable Wireless System (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1535-1548. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Hodge, B., Critical Electronic Discourse Analysis: Social and Cultural Research in the Electronic Age (2014) Innovative Methods and Technologies for Electronic Discourse Analysis, pp. 191-209. , H. Lim & F. Sudweeks (Eds.), Hershey, PA: Information Science Reference;; Hoey, J., Poupart, P., Boutilier, C., Mihailidis, A., POMDP Models for Assistive Technology (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 120-140. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Hogg, S., An Informal Use of Facebook to Encourage Student Collaboration and Motivation for Off Campus Activities (2014) The Social Classroom: Integrating Social Network Use in Education, pp. 23-39. , G. Mallia (Ed.), Hershey, PA: Information Science Reference;; Holmqvist, E., Buchholz, M., A Model for Gaze Control Assessments and Evaluation (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 332-343. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Hsiao, S., Chen, D., Yang, C., Huang, H., Lu, Y., Huang, H., Lin, Y., Chemical-Free and Reusable Cellular Analysis: Electrochemical Impedance Spectroscopy with a Transparent ITO Culture Chip. [IJTHI] (2013) International Journal of Technology and Human Interaction, 8 (3), pp. 1-9; Hsu, M., Yang, C., Wang, C., Lin, Y., Simulation-Aided Optimal Microfluidic Sorting for Monodispersed Microparticles. [IJTHI] (2013) International Journal of Technology and Human Interaction, 8 (3), pp. 10-18; Huang, W.D., Tettegah, S.Y., Cognitive Load and Empathy in Serious Games: A Conceptual Framework (2014) Gamification for Human Factors Integration: Social, Education, and Psychological Issues, pp. 17-30. , J. Bishop (Ed.), Hershey, PA: Information Science Reference;; Huseyinov, I.N., Fuzzy Linguistic Modelling in Multi Modal Human Computer Interaction: Adaptation to Cognitive Styles using Multi Level Fuzzy Granulation Method (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1481-1496. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Hwa, S.P., Weei, P.S., Len, L.H., The Effects of Blended Learning Approach through an Interactive Multimedia E-Book on Students' Achievement in Learning Chinese as a Second Language at Tertiary Level. [IJCALLT] (2012) International Journal of Computer-Assisted Language Learning and Teaching, 2 (1), pp. 35-50; Iglesias, A., Ruiz-Mezcua, B., López, J.F., Figueroa, D.C., New Communication Technologies for Inclusive Education in and outside the Classroom (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1675-1689. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Inghilterra, X., Ravatua-Smith, W.S., Online Learning Communities: Use of Micro Blogging for Knowledge Construction (2014) E-Learning 2.0 Technologies and Web Applications in Higher Education, pp. 107-128. , J. Pelet (Ed.), Hershey, PA: Information Science Reference;; Ionescu, A., Cyber Identity: Our Alter-Ego? (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 189-203. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Jan, Y., Lin, M., Shiao, K., Wei, C., Huang, L., Sung, Q., Development of an Evaluation Instrument for Green Building Literacy among College Students in Taiwan. [IJTHI] (2013) International Journal of Technology and Human Interaction, 8 (3), pp. 31-45; Jawadi, N., E-Leadership and Trust Management: Exploring the Moderating Effects of Team Virtuality. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (3), pp. 18-35; Jiménez-Castillo, D., Fernández, R.S., The Impact of Combining Video Podcasting and Lectures on Students' Assimilation of Additional Knowledge: An Empirical Examination (2014) E-Learning 2.0 Technologies and Web Applications in Higher Education, pp. 65-87. , J. Pelet (Ed.), Hershey, PA: Information Science Reference;; Jin, L., A New Trend in Education: Technoself Enhanced Social Learning (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 456-473. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Johansson, L., The Functional Morality of Robots (2012) Ethical Impact of Technological Advancements and Applications in Society, pp. 254-262. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Johansson, L., Robots and the Ethics of Care. [IJT] (2013) International Journal of Technoethics, 4 (1), pp. 67-82; Johri, A., Dufour, M., Lo, J., Shanahan, D., Adwiki: Socio-Technical Design for Mananging Advising Knowledge in a Higher Education Context. [IJSKD] (2013) International Journal of Sociotechnology and Knowledge Development, 5 (1), pp. 37-59; Jones, M.G., Schwilk, C.L., Bateman, D.F., Reading by Listening: Access to Books in Audio Format for College Students with Print Disabilities (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 454-477. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Kaba, B., Osei-Bryson, K., An Empirical Investigation of External Factors Influencing Mobile Technology Use in Canada: A Preliminary Study. [IJTHI] (2012) International Journal of Technology and Human Interaction, 8 (2), pp. 1-14; Kampf, C.E., Revealing the Socio-Technical Design of Global E-Businesses: A Case of Digital Artists Engaging in Radical Transparency. [IJSKD] (2012) International Journal of Sociotechnology and Knowledge Development, 4 (4), pp. 18-31; Kandroudi, M., Bratitsis, T., Classifying Facebook Usage in the Classroom or Around It (2014) The Social Classroom: Integrating Social Network Use in Education, pp. 62-81. , G. Mallia (Ed.), Hershey, PA: Information Science Reference;; Kidd, P.T., Social Networking Technologies as a Strategic Tool for the Development of Sustainable Production and Consumption: Applications to Foster the Agility Needed to Adapt Business Models in Response to the Challenges Posed by Climate Change (2014) Sustainable Practices: Concepts, Methodologies, Tools and Applications, pp. 974-987. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Kirby, S.D., Sellers, D.M., The Live-Ability House: A Collaborative Adventure in Discovery Learning (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1626-1649. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Kitchenham, A., Bowes, D., Voice/Speech Recognition Software: A Discussion of the Promise for Success and Practical Suggestions for Implementation (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1005-1011. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Konrath, S., The Empathy Paradox: Increasing Disconnection in the Age of Increasing Connection (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 204-228. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Koutsabasis, P., Istikopoulou, T.G., Perceived Website Aesthetics by Users and Designers: Implications for Evaluation Practice. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (2), pp. 39-52; Kraft, E., Wang, J., An Exploratory Study of the Cyberbullying and Cyberstalking Experiences and Factors Related to Victimization of Students at a Public Liberal Arts College (2012) Ethical Impact of Technological Advancements and Applications in Society, pp. 113-131. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Kulman, R., Stoner, G., Ruffolo, L., Marshall, S., Slater, J., Dyl, A., Cheng, A., Teaching Executive Functions, Self-Management, and Ethical Decision-Making through Popular Videogame Play (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 771-785. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Kunc, L., Míkovec, Z., Slavík, P., Avatar and Dialog Turn-Yielding Phenomena. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (2), pp. 66-88; Kuo, N., Dai, Y., Applying the Theory of Planned Behavior to Predict Low-Carbon Tourism Behavior: A Modified Model from Taiwan. [IJTHI] (2012) International Journal of Technology and Human Interaction, 8 (4), pp. 45-62; Kurt, S., Accessibility Issues of Educational Web Sites (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 54-62. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Kuzma, J., Empirical Study of Cyber Harassment among Social Networks. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (2), pp. 53-65; Kyriakaki, G., Matsatsinis, N., Pedagogical Evaluation of E-Learning Websites with Cognitive Objectives (2014) Evaluating Websites and Web Services: Interdisciplinary Perspectives on User Satisfaction, pp. 224-240. , D. Yannacopoulos, P. Manolitzas, N. Matsatsinis, & E. Grigoroudis (Eds.), Hershey, PA: Information Science Reference;; Lee, H., Baek, E., Facilitating Deep Learning in a Learning Community. [IJTHI] (2012) International Journal of Technology and Human Interaction, 8 (1), pp. 1-13; Lee, W., Wu, T., Cheng, Y., Chuang, Y., Sheu, S., Using the Kalman Filter for Auto Bit-rate H.264 Streaming Based on Human Interaction. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (4), pp. 58-74; Li, Y., Guo, N.Y., Ranieri, M., Designing an Online Interactive Learning Program to Improve Chinese Migrant Children's Internet Skills: A Case Study at Hangzhou Minzhu Experimental School (2014) Transforming K-12 Classrooms with Digital Technology, pp. 249-265. , Z. Yang, H. Yang, D. Wu, & S. Liu (Eds.), Hershey, PA: Information Science Reference;; Lin, C., Chu, L., Hsu, H., Study on the Performance and Exhaust Emissions of Motorcycle Engine Fuelled with Hydrogen-Gasoline Compound Fuel. [IJTHI] (2013) International Journal of Technology and Human Interaction, 8 (3), pp. 69-81; Lin, L., Multiple Dimensions of Multitasking Phenomenon. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (1), pp. 37-49; Lin, T., Li, X., Wu, Z., Tang, N., Automatic Cognitive Load Classification Using High-Frequency Interaction Events: An Exploratory Study. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (3), pp. 73-88; Lin, T., Wu, Z., Tang, N., Wu, S., Exploring the Effects of Display Characteristics on Presence and Emotional Responses of Game Players. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (1), pp. 50-63; Lin, T., Xie, T., Mou, Y., Tang, N., Markov Chain Models for Menu Item Prediction. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (4), pp. 75-94; Lin, X., Luppicini, R., Socio-Technical Influences of Cyber Espionage: A Case Study of the GhostNet System. [IJT] (2011) International Journal of Technoethics, 2 (2), pp. 65-77; Linek, S.B., Marte, B., Albert, D., Background Music in Educational Games: Motivational Appeal and Cognitive Impact (2014) Gamification for Human Factors Integration: Social, Education, and Psychological Issues, pp. 259-271. , J. Bishop (Ed.), Hershey, PA: Information Science Reference;; Lipschutz, R.D., Hester, R.J., We Are the Borg! Human Assimilation into Cellular Society (2014) Uberveillance and the Social Implications of Microchip Implants: Emerging Technologies, pp. 366-407. , M. Michael & K. Michael (Eds.), Hershey, PA: Information Science Reference;; Liu, C., Zhong, Y., Ozercan, S., Zhu, Q., Facilitating 3D Virtual World Learning Environments Creation by Non-Technical End Users through Template-Based Virtual World Instantiation. [IJVPLE] (2013) International Journal of Virtual and Personal Learning Environments, 4 (1), pp. 32-48; Liu, F., Lo, H., Su, C., Lou, D., Lee, W., High Performance Reversible Data Hiding for Mobile Applications and Human Interaction. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (4), pp. 41-57; Liu, H., From Cold War Island to Low Carbon Island: A Study of Kinmen Island. [IJTHI] (2012) International Journal of Technology and Human Interaction, 8 (4), pp. 63-74; Lixun, Z., Dapeng, B., Lei, Y., Design of and Experimentation with a Walking Assistance Robot (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1600-1605. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Low, R., Jin, P., Sweller, J., Instructional Design in Digital Environments and Availability of Mental Resources for the Aged Subpopulation (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1131-1154. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Luczak, H., Schlick, C.M., Jochems, N., Vetter, S., Kausch, B., Touch Screens for the Elderly: Some Models and Methods, Prototypical Development and Experimental Evaluation of Human-Computer Interaction Concepts for the Elderly (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 377-396. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Luor, T., Lu, H., Johanson, R.E., Yu, H., Minding the Gap Between First and Continued Usage of a Corporate E-Learning English-language Program. [IJTHI] (2012) International Journal of Technology and Human Interaction, 8 (1), pp. 55-74; Luppicini, R., The Emerging Field of Technoself Studies (TSS) (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 1-25. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Magnani, L., Material Cultures and Moral Mediators in Human Hybridization (2012) Ethical Impact of Technological Advancements and Applications in Society, pp. 1-20. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Maher, D., Learning in the Primary School Classroom using the Interactive Whiteboard (2014) K-12 Education: Concepts, Methodologies, Tools, and Applications, pp. 526-538. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Manolache, M., Patrut, M., The Use of New Web-Based Technologies in Strategies of Teaching Gender Studies (2013) Social Media in Higher Education: Teaching in Web 2.0, pp. 45-74. , M. Pătruţ & B. Pătruţ (Eds.), Hershey, PA: Information Science Reference;; Manthiou, A., Chiang, L., Tang, L.R., Identifying and Responding to Customer Needs on Facebook Fan Pages. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (3), pp. 36-52; Marengo, A., Pagano, A., Barbone, A., An Assessment of Customer's Preferences and Improve Brand Awareness Implementation of Social CRM in an Automotive Company. [IJTD] (2013) International Journal of Technology Diffusion, 4 (1), pp. 1-15; Martin, I., Kear, K., Simpkins, N., Busvine, J., Social Negotiations in Web Usability Engineering (2013) Cases on Usability Engineering: Design and Development of Digital Products, pp. 26-56. , M. Garcia-Ruiz (Ed.), Hershey, PA: Information Science Reference;; Martins, T., Carvalho, V., Soares, F., An Overview on the Use of Serious Games in Physical Therapy and Rehabilitation (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 758-770. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Mathew, D., Online Anxiety: Implications for Educational Design in a Web 2.0 World (2013) Social Media in Higher Education: Teaching in Web 2.0, pp. 305-317. , M. Pătruţ & B. Pătruţ (Eds.), Hershey, PA: Information Science Reference;; Mazzanti, I., Maolo, A., Antonicelli, R., E-Health and Telemedicine in the Elderly: State of the Art (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 693-704. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Mazzara, M., Biselli, L., Greco, P.P., Dragoni, N., Marraffa, A., Qamar, N., de Nicola, S., Social Networks and Collective Intelligence: A Return to the Agora (2013) Social Network Engineering for Secure Web Data and Services, pp. 88-113. , L. Caviglione, M. Coccoli, & A. Merlo (Eds.), Hershey, PA: Information Science Reference;; McColl, D., Nejat, G., A Human Affect Recognition System for Socially Interactive Robots (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 554-573. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; McDonald, A., Helmer, S., A Comparative Case Study of Indonesian and UK Organisational Culture Differences in IS Project Management. [IJTHI] (2011) International Journal of Technology and Human Interaction, 7 (2), pp. 28-37; McGee, E.M., Neuroethics and Implanted Brain Machine Interfaces (2014) Uberveillance and the Social Implications of Microchip Implants: Emerging Technologies, pp. 351-365. , M. Michael & K. Michael (Eds.), Hershey, PA: Information Science Reference;; McGrath, E., Lowes, S., McKay, M., Sayres, J., Lin, P., Robots Underwater! Learning Science, Engineering and 21st Century Skills: The Evolution of Curricula, Professional Development and Research in Formal and Informal Contexts (2014) K-12 Education: Concepts, Methodologies, Tools, and Applications, pp. 1041-1067. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Meissonierm, R., Bourdon, I., Amabile, S., Boudrandi, S., Toward an Enacted Approach to Understanding OSS Developer's Motivations. [IJTHI] (2012) International Journal of Technology and Human Interaction, 8 (1), pp. 38-54; Melius, J., The Role of Social Constructivist Instructional Approaches in Facilitating Cross-Cultural Online Learning in Higher Education (2014) Cross-Cultural Online Learning in Higher Education and Corporate Training, pp. 253-270. , J. Keengwe, G. Schnellert, & K. Kungu (Eds.), Hershey, PA: Information Science Reference;; Melson, G.F., Building a Technoself: Children's Ideas about and Behavior toward Robotic Pets (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 592-608. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Mena, R.J., The Quest for a Massively Multiplayer Online Game that Teaches Physics (2014) Psychology, Pedagogy, and Assessment in Serious Games, pp. 292-316. , T. Connolly, T. Hainey, E. Boyle, G. Baxter, & P. Moreno-Ger (Eds.), Hershey, PA: Information Science Reference;; Meredith, J., Potter, J., Conversation Analysis and Electronic Interactions: Methodological, Analytic and Technical Considerations (2014) Innovative Methods and Technologies for Electronic Discourse Analysis, pp. 370-393. , H. Lim & F. Sudweeks (Eds.), Hershey, PA: Information Science Reference;; Millán-Calenti, J.C., Maseda, A., Telegerontology ®: A New Technological Resource for Elderly Support (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 705-719. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Miscione, G., Telemedicine and Development: Situating Information Technologies in the Amazon. [IJSKD] (2011) International Journal of Sociotechnology and Knowledge Development, 3 (4), pp. 15-26; Miwa, N., Wang, Y., Online Interaction Between On-Campus and Distance Students: Learners' Perspectives. [IJCALLT] (2011) International Journal of Computer-Assisted Language Learning and Teaching, 1 (3), pp. 54-69; Moore, M.J., Nakano, T., Suda, T., Enomoto, A., Social Interactions and Automated Detection Tools in Cyberbullying (2013) Social Network Engineering for Secure Web Data and Services, pp. 67-87. , L. Caviglione, M. Coccoli, & A. Merlo (Eds.), Hershey, PA: Information Science Reference;; Morueta, R.T., Gómez, J.I., Gómez, A.H., B-Learning at Universities in Andalusia (Spain): From Traditional to Student-Centred Learning. [IJTHI] (2012) International Journal of Technology and Human Interaction, 8 (2), pp. 56-76; Mosindi, O., Sice, P., An Exploratory Theoretical Framework for Understanding Information Behaviour. [IJTHI] (2011) International Journal of Technology and Human Interaction, 7 (2), pp. 1-8; Mott, M.S., Williams-Black, T.H., Media-Enhanced Writing Instruction and Assessment (2014) Literacy Enrichment and Technology Integration in Pre-Service Teacher Education, pp. 1-16. , J. Keengwe, G. Onchwari, & D. Hucks (Eds.), Hershey, PA: Information Science Reference;; Mulvey, F., Heubner, M., Eye Movements and Attention (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1030-1054. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Muro, B.F., Delgado, E.C., RACEM Game for PC for Use as Rehabilitation Therapy for Children with Psychomotor Disability and Results of its Application (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 740-757. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Muwanguzi, S., Lin, L., Coping with Accessibility and Usability Challenges of Online Technologies by Blind Students in Higher Education (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1227-1244. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Najjar, M., Courtemanche, F., Hamam, H., Dion, A., Bauchet, J., Mayers, A., DeepKøver: An Adaptive Intelligent Assistance System for Monitoring Impaired People in Smart Homes (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 634-661. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Nap, H.H., Diaz-Orueta, U., Rehabilitation Gaming (2014) Gamification for Human Factors Integration: Social, Education, and Psychological Issues, pp. 122-147. , J. Bishop (Ed.), Hershey, PA: Information Science Reference;; Neves, J., Pinheiro, L.D., Cyberbullying: A Sociological Approach (2012) Ethical Impact of Technological Advancements and Applications in Society, pp. 132-142. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Nguyen, P.T., Peer Feedback on Second Language Writing through Blogs: The Case of a Vietnamese EFL Classroom. [IJCALLT] (2012) International Journal of Computer-Assisted Language Learning and Teaching, 2 (1), pp. 13-23; Ninaus, M., Witte, M., Kober, S.E., Friedrich, E.V., Kurzmann, J., Hartsuiker, E., Wood, G., Neurofeedback and Serious Games (2014) Psychology, Pedagogy, and Assessment in Serious Games, pp. 82-110. , T. Connolly, T. Hainey, E. Boyle, G. Baxter, & P. Moreno-Ger (Eds.), Hershey, PA: Information Science Reference;; Olla, V., An Enquiry into the use of Technology and Student Voice in Citizenship Education in the K-12 Classroom (2014) K-12 Education: Concepts, Methodologies, Tools, and Applications, pp. 892-913. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Orange, E., Understanding the Human-Machine Interface in a Time of Change (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 703-719. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Palmer, D., Warren, I., Miller, P., ID Scanners and Überveillance in the Night-Time Economy: Crime Prevention or Invasion of Privacy? (2014) Uberveillance and the Social Implications of Microchip Implants: Emerging Technologies, pp. 208-225. , M. Michael & K. Michael (Eds.), Hershey, PA: Information Science Reference;; Papadopoulos, F., Dautenhahn, K., Ho, W.C., Behavioral Analysis of Human-Human Remote Social Interaction Mediated by an Interactive Robot in a Cooperative Game Scenario (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 637-665. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Patel, K.K., Vij, S.K., Unconstrained Walking Plane to Virtual Environment for Non-Visual Spatial Learning (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1580-1599. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Patrone, T., In Defense of the 'Human Prejudice'. [IJT] (2013) International Journal of Technoethics, 4 (1), pp. 26-38; Peevers, G., Williams, R., Douglas, G., Jack, M.A., Usability Study of Fingerprint and Palmvein Biometric Technologies at the ATM. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (1), pp. 78-95; Pellas, N., Theoretical Foundations of a CSCL Script in Persistent Virtual Worlds According to the Contemporary Learning Theories and Models (2014) Collaborative Communication Processes and Decision Making in Organizations, pp. 72-107. , E. Nikoi & K. Boateng (Eds.), Hershey, PA: Business Science Reference;; Perakslis, C., Willingness to Adopt RFID Implants: Do Personality Factors Play a Role in the Acceptance of Uberveillance? (2014) Uberveillance and the Social Implications of Microchip Implants: Emerging Technologies, pp. 144-168. , M. Michael & K. Michael (Eds.), Hershey, PA: Information Science Reference;; Pereira, G., Brisson, A., Dias, J., Carvalho, A., Dimas, J., Mascarenhas, S., Paiva, A., Non-Player Characters and Artificial Intelligence (2014) Psychology, Pedagogy, and Assessment in Serious Games, pp. 127-152. , T. Connolly, T. Hainey, E. Boyle, G. Baxter, & P. Moreno-Ger (Eds.), Hershey, PA: Information Science Reference;; Pérez Pérez, A., Callejas Carrión, Z., López-Cózar Delgado, R., Griol Barres, D., On the Use of Speech Technologies to Achieve Inclusive Education for People with Intellectual Disabilities (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1106-1117. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Peschl, M.F., Fundneider, T., Theory U and Emergent Innovation: Presencing as a Method of Bringing Forth Profoundly New Knowledge and Realities (2014) Perspectives on Theory U: Insights from the Field, pp. 207-233. , O. Gunnlaugson, C. Baron, & M. Cayer (Eds.), Hershey, PA: Business Science Reference;; Petrovic, N., Jeremic, V., Petrovic, D., Cirovic, M., Modeling the Use of Facebook in Environmental Higher Education (2014) The Social Classroom: Integrating Social Network Use in Education, pp. 100-119. , G. Mallia (Ed.), Hershey, PA: Information Science Reference;; Phua, C., Roy, P.C., Aloulou, H., Biswas, J., Tolstikov, A., Foo, V.S., Xu, D., Stateof-the-Art Assistive Technology for People with Dementia (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1606-1625. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Potts, L., Balancing McLuhan With Williams: A Sociotechnical View of Technological Determinism. [IJSKD] (2011) International Journal of Sociotechnology and Knowledge Development, 3 (2), pp. 53-57; Potts, L., Balancing McLuhan With Williams: A Sociotechnical View of Technological Determinism (2013) Knowledge and Technological Development Effects on Organizational and Social Structures, pp. 109-114. , J. Abdelnour-Nocera (Ed.), Hershey, PA: Information Science Reference;; Potts, L., Sociotechnical Uses of Social Web Tools during Disasters (2014) Crisis Management: Concepts, Methodologies, Tools and Applications, pp. 531-541. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Proença, R., Guerra, A., Campos, P., A Gestural Recognition Interface for Intelligent Wheelchair Users. [IJSKD] (2013) International Journal of Sociotechnology and Knowledge Development, 5 (2), pp. 63-81; Quilici-Gonzalez, J.A., Kobayashi, G., Broens, M.C., Gonzalez, M.E., Ubiquitous Computing: Any Ethical Implications? (2012) Ethical Impact of Technological Advancements and Applications in Society, pp. 47-59. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Rambaree, K., Computer-Aided Deductive Critical Discourse Analysis of a Case Study from Mauritius with ATLAS-ti 6.2 (2014) Innovative Methods and Technologies for Electronic Discourse Analysis, pp. 346-368. , H. Lim & F. Sudweeks (Eds.), Hershey, PA: Information Science Reference;; Ratan, R., Self-Presence, Explicated: Body, Emotion, and Identity Extension into the Virtual Self (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 322-336. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Rechy-Ramirez, E.J., Hu, H., A Flexible Bio-Signal Based HMI for Hands-Free Control of an Electric Powered Wheelchair. [IJALR] (2014) International Journal of Artificial Life Research, 4 (1), pp. 59-76; Reiners, T., Wood, L.C., Dron, J., From Chaos Towards Sense: A Learner-Centric Narrative Virtual Learning Space (2014) Gamification for Human Factors Integration: Social, Education, and Psychological Issues, pp. 242-258. , J. Bishop (Ed.), Hershey, PA: Information Science Reference;; Reinhardt, J., Ryu, J., Using Social Network-Mediated Bridging Activities to Develop Socio-Pragmatic Awareness in Elementary Korean. [IJCALLT] (2013) International Journal of Computer-Assisted Language Learning and Teaching, 3 (3), pp. 18-33; Revuelta, P., Jiménez, J., Sánchez, J.M., Ruiz, B., Automatic Speech Recognition to Enhance Learning for Disabled Students (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 478-493. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Ribeiro, J.C., Silva, T., Self, Self-Presentation, and the Use of Social Applications in Digital Environments (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 439-455. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Richet, J., From Young Hackers to Crackers. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (3), pp. 53-62; Rigas, D., Almutairi, B., An Empirical Investigation into the Role of Avatars in Multimodal E-government Interfaces. [IJSKD] (2013) International Journal of Sociotechnology and Knowledge Development, 5 (1), pp. 14-22; Rodríguez, W.R., Saz, O., Lleida, E., Experiences Using a Free Tool for Voice Therapy based on Speech Technologies (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 508-523. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Rothblatt, M., Mindclone Technoselves: Multi-Substrate Legal Identities, Cyber-Psychology, and Biocyberethics (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 105-122. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Rowe, N.C., The Ethics of Cyberweapons in Warfare (2012) Ethical Impact of Technological Advancements and Applications in Society, pp. 195-207. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Russo, M.R., Emergency Management Professional Development: Linking Information Communication Technology and Social Communication Skills to Enhance a Sense of Community and Social Justice in the 21st Century (2014) Crisis Management: Concepts, Methodologies, Tools and Applications, pp. 651-665. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Sajeva, S., Towards a Conceptual Knowledge Management System Based on Systems Thinking and Sociotechnical Thinking. [IJSKD] (2011) International Journal of Sociotechnology and Knowledge Development, 3 (3), pp. 40-55; Sajeva, S., Towards a Conceptual Knowledge Management System Based on Systems Thinking and Sociotechnical Thinking (2013) Knowledge and Technological Development Effects on Organizational and Social Structures, pp. 115-130. , J. Abdelnour-Nocera (Ed.), Hershey, PA: Information Science Reference;; Saleeb, N., Dafoulas, G.A., Assistive Technologies and Environmental Design Concepts for Blended Learning and Teaching for Disabilities within 3D Virtual Worlds and Learning Environments (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1382-1404. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Salvini, P., Presence, Reciprocity and Robotic Mediations: The Case of Autonomous Social Robots. [IJT] (2012) International Journal of Technoethics, 3 (2), pp. 9-16; Samanta, I., The Impact of Virtual Community (Web 2.0) in the Economic, Social, and Political Environment of Traditional Society (2013) Business Strategies and Approaches for Effective Engineering Management, pp. 262-274. , S. Saeed, M. Khan, & R. Ahmad (Eds.), Hershey, PA: Business Science Reference;; Samanta, S.K., Woods, J., Ghanbari, M., Automatic Language Translation: An Enhancement to the Mobile Messaging Services. [IJTHI] (2011) International Journal of Technology and Human Interaction, 7 (1), pp. 1-18; Sarkar, N.I., Kuang, A.X., Nisar, K., Amphawan, A., Hospital Environment Scenarios using WLAN over OPNET Simulation Tool. [IJICTHD] (2014) International Journal of Information Communication Technologies and Human Development, 6 (1), pp. 69-90; Sarré, C., Technology-Mediated Tasks in English for Specific Purposes (ESP): Design, Implementation and Learner Perception. [IJCALLT] (2013) International Journal of Computer-Assisted Language Learning and Teaching, 3 (2), pp. 1-16; Saykili, A., Kumtepe, E.G., Facebook's Hidden Potential: Facebook as an Educational Support Tool in Foreign Language Education (2014) The Social Classroom: Integrating Social Network Use in Education, pp. 120-146. , G. Mallia (Ed.), Hershey, PA: Information Science Reference;; Sayoud, H., Biometrics: An Overview on New Technologies and Ethic Problems. [IJT] (2011) International Journal of Technoethics, 2 (1), pp. 19-34; Scott, C.R., Timmerman, C.E., Communicative Changes Associated with Repeated Use of Electronic Meeting Systems for Decision-Making Tasks (2014) Collaborative Communication Processes and Decision Making in Organizations, pp. 1-24. , E. Nikoi & K. Boateng (Eds.), Hershey, PA: Business Science Reference;; Scott, K., The Human-Robot Continuum of Self: Where the Other Ends and Another Begins (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 666-679. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Shasek, J., ExerLearning®: Movement, Fitness, Technology, and Learning (2014) Gamification for Human Factors Integration: Social, Education, and Psychological Issues, pp. 106-121. , J. Bishop (Ed.), Hershey, PA: Information Science Reference;; Shen, J., Eder, L.B., An Examination of Factors Associated with User Acceptance of Social Shopping Websites. [IJTHI] (2011) International Journal of Technology and Human Interaction, 7 (1), pp. 19-36; Shrestha, P., Teacher Professional Development Using Mobile Technologies in a Large-Scale Project: Lessons Learned from Bangladesh. [IJCALLT] (2012) International Journal of Computer-Assisted Language Learning and Teaching, 2 (4), pp. 34-49; Silvana de Rosa, A., Fino, E., Bocci, E., Addressing Healthcare On-Line Demand and Supply Relating to Mental Illness: Knowledge Sharing About Psychiatry and Psychoanalysis Through Social Networks in Italy and France (2014) Dynamics of Competitive Advantage and Consumer Perception in Social Marketing, pp. 16-55. , A. Kapoor & C. Kulshrestha (Eds.), Hershey, PA: Business Science Reference;; Smith, M., Murray, J., Augmentative and Alternative Communication Devices: The Voices of Adult Users (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 991-1004. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Smith, P.A., Strengthening and Enriching Audit Practice: The Socio-Technical Relevance of "Decision Leaders" (2013) Knowledge and Technological Development Effects on Organizational and Social Structures, pp. 97-108. , J. Abdelnour-Nocera (Ed.), Hershey, PA: Information Science Reference;; So, J.C., Lam, S.Y., Using Social Networks Communication Platform for Promoting Student-Initiated Holistic Development Among Students. [IJISSS] (2014) International Journal of Information Systems in the Service Sector, 6 (1), pp. 1-23; Söderström, S., Assistive ICT and Young Disabled Persons: Opportunities and Obstacles in Identity Negotiations (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1084-1105. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Son, J., Rossade, K., Finding Gems in Computer-Assisted Language Learning: Clues from GLoCALL 2011 and 2012 Papers. [IJCALLT] (2013) International Journal of Computer-Assisted Language Learning and Teaching, 3 (4), pp. 1-8; Sone, Y., Robot Double: Hiroshi Ishiguro's Reflexive Machines (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 680-702. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Spillane, M., Assistive Technology: A Tool for Inclusion (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1-11. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Stahl, B.C., Heersmink, R., Goujon, P., Flick, C., van den Hoven, J., Wakunuma, K., Rader, M., Identifying the Ethics of Emerging Information and Communication Technologies: An Essay on Issues, Concepts and Method (2012) Ethical Impact of Technological Advancements and Applications in Society, pp. 61-79. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Stern, S.E., Grounds, B.E., Cellular Telephones and Social Interactions: Evidence of Interpersonal Surveillance. [IJT] (2011) International Journal of Technoethics, 2 (1), pp. 43-49; Stinson, J., Gill, N., Internet-Based Chronic Disease Self-Management for Youth (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 224-245. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Stockwell, G., Online Approaches to Learning Vocabulary: Teacher-Centred or Learner-Centred? [IJCALLT] (2011) International Journal of Computer-Assisted Language Learning and Teaching, 1 (1), pp. 33-44; Stradella, E., Personal Liability and Human Free Will in the Background of Emerging Neuroethical Issues: Some Remarks Arising From Recent Case Law. [IJT] (2012) International Journal of Technoethics, 3 (2), pp. 30-41; Stubbs, K., Casper, J., Yanco, H.A., Designing Evaluations for K-12 Robotics Education Programs (2014) K-12 Education: Concepts, Methodologies, Tools, and Applications, pp. 1342-1364. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Suki, N.M., Ramayah, T., Ming, M.K., Suki, N.M., Factors Enhancing Employed Job Seekers Intentions to Use Social Networking Sites as a Job Search Tool. [IJTHI] (2011) International Journal of Technology and Human Interaction, 7 (2), pp. 38-54; Sweeney, P., Moore, C., Mobile Apps for Learning Vocabulary: Categories, Evaluation and Design Criteria for Teachers and Developers. [IJCALLT] (2012) International Journal of Computer-Assisted Language Learning and Teaching, 2 (4), pp. 1-16; Szeto, A.Y., Assistive Technology and Rehabilitation Engineering (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 277-331. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Tamim, R., Technology Integration in UAE Schools: Current Status and Way Forward (2014) K-12 Education: Concepts, Methodologies, Tools, and Applications, pp. 41-57. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Tan, R., Wang, S., Jiang, Y., Ishida, K., Fujie, M.G., Motion Control of an Omni-Directional Walker for Walking Support (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 614-622. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Tankari, M., Cultural Orientation Differences and their Implications for Online Learning Satisfaction (2014) Cross-Cultural Online Learning in Higher Education and Corporate Training, pp. 20-61. , J. Keengwe, G. Schnellert, & K. Kungu (Eds.), Hershey, PA: Information Science Reference;; Tchangani, A.P., Bipolarity in Decision Analysis: A Way to Cope with Human Judgment (2014) Exploring Innovative and Successful Applications of Soft Computing, pp. 216-244. , A. Masegosa, P. Villacorta, C. Cruz-Corona, M. García-Cascales, M. Lamata, & J. Verdegay (Eds.), Hershey, PA: Information Science Reference;; Tennyson, R.D., Computer Interventions for Children with Disabilities: Review of Research and Practice (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 841-864. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Terrell, S.S., Integrating Online Tools to Motivate Young English Language Learners to Practice English Outside the Classroom. [IJCALLT] (2011) International Journal of Computer-Assisted Language Learning and Teaching, 1 (2), pp. 16-24; Tiwary, U.S., Siddiqui, T.J., Working Together with Computers: Towards a General Framework for Collaborative Human Computer Interaction (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 141-162. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Tomas, J., Lloret, J., Bri, D., Sendra, S., Sensors and their Application for Disabled and Elderly People (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 357-376. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Tomasi, A., A Run for your [Techno]Self (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 123-136. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference; Tootell, H., Freeman, A., The Applicability of Gaming Elements to Early Childhood Education (2014) Gamification for Human Factors Integration: Social, Education, and Psychological Issues, pp. 225-241. , J. Bishop (Ed.), Hershey, PA: Information Science Reference;; Tsai, C., How Much Can Computers and Internet Help?: A Long-Term Study of Web-Mediated Problem-Based Learning and Self-Regulated Learning. [IJTHI] (2011) International Journal of Technology and Human Interaction, 7 (1), pp. 67-81; Tsai, W., An Investigation on Undergraduate's Bio-Energy Engineering Education Program at the Taiwan Technical University. [IJTHI] (2013) International Journal of Technology and Human Interaction, 8 (3), pp. 46-53; Tsiakis, T., Using Social Media as a Concept and Tool for Teaching Marketing Information Systems (2013) Social Media in Higher Education: Teaching in Web 2.0, pp. 24-44. , M. Pătruţ & B. Pătruţ (Eds.), Hershey, PA: Information Science Reference;; Tu, C., McIsaac, M.S., Sujo-Montes, L.E., Armfield, S., Building Mobile Social Presence for U-Learning (2014) Technology Platform Innovations and Forthcoming Trends in Ubiquitous Learning, pp. 77-93. , F. Neto (Ed.), Hershey, PA: Information Science Reference;; Valeria, N., Lu, M.V., Theng, L.B., Collaborative Virtual Learning for Assisting Children with Cerebral Palsy (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 786-810. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Van Leuven, N., Newton, D., Leuenberger, D.Z., Esteves, T., Reaching Citizen 2.0: How Government Uses Social Media to Send Public Messages during Times of Calm and Times of Crisis (2014) Crisis Management: Concepts, Methodologies, Tools and Applications, pp. 839-857. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Vargas-Hernández, J.G., International Student Collaboration and Experiential Exercise Projects as a Professional, Inter-Personal and Inter-Institutional Networking Platform. [IJTEM] (2013) International Journal of Technology and Educational Marketing, 3 (1), pp. 28-47; Velicu, A., Marinescu, V., Usage of Social Media by Children and Teenagers: Results of EU KIDS Online II (2013) Social Media in Higher Education: Teaching in Web 2.0, pp. 144-178. , M. Pătruţ & B. Pătruţ (Eds.), Hershey, PA: Information Science Reference;; Vidaurre, C., Kübler, A., Tangermann, M., Müller, K., Millán, J.D., Brain-Computer Interfaces and Visual Activity (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1549-1570. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Viswanathan, R., Augmenting the Use of Mobile Devices in Language Classrooms. [IJCALLT] (2012) International Journal of Computer-Assisted Language Learning and Teaching, 2 (2), pp. 45-60; Wallgren, L.G., Hanse, J.J., A Two-Wave Study of the Impact of Job Characteristics and Motivators on Perceived Stress among Information Technology (IT) Consultants. [IJTHI] (2012) International Journal of Technology and Human Interaction, 8 (4), pp. 75-91; Wang, H., A Guide to Assistive Technology for Teachers in Special Education (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 12-25. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Wang, S., Ku, C., Chu, C., Sustainable Campus Project: Potential for Energy Conservation and Carbon Reduction Education in Taiwan. [IJTHI] (2013) International Journal of Technology and Human Interaction, 8 (3), pp. 19-30; Wang, Y., Tian, J., Negotiation of Meaning in Multimodal Tandem Learning via Desktop Videoconferencing. [IJCALLT] (2013) International Journal of Computer-Assisted Language Learning and Teaching, 3 (2), pp. 41-55; Wareham, C., On the Moral Equality of Artificial Agents. [IJT] (2011) International Journal of Technoethics, 2 (1), pp. 35-42; Warwick, K., Gasson, M.N., Practical Experimentation with Human Implants (2014) Uberveillance and the Social Implications of Microchip Implants: Emerging Technologies, pp. 64-132. , M. Michael & K. Michael (Eds.), Hershey, PA: Information Science Reference;; Welch, K.C., Lahiri, U., Sarkar, N., Warren, Z., Stone, W., Liu, C., Affect-Sensitive Computing and Autism (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 865-883. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Wessels, B., Dittrich, Y., Ekelin, A., Eriksén, S., Creating Synergies between Participatory Design of E-Services and Collaborative Planning (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 163-179. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; White, E.L., Technology-Based Literacy Approach for English Language Learners (2014) K-12 Education: Concepts, Methodologies, Tools, and Applications, pp. 723-740. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Whyte, K.P., List, M., Stone, J.V., Grooms, D., Gasteyer, S., Thompson, P.B., Bouri, H., Uberveillance, Standards, and Anticipation: A Case Study on Nanobiosensors in U.S. Cattle (2014) Uberveillance and the Social Implications of Microchip Implants: Emerging Technologies, pp. 260-279. , M. Michael & K. Michael (Eds.), Hershey, PA: Information Science Reference;; Wilson, S., Haslam, N., Reasoning about Human Enhancement: Towards a Folk Psychological Model of Human Nature and Human Identity (2013) Handbook of Research on Technoself: Identity in a Technological Society, pp. 175-188. , R. Luppicini (Ed.), Hershey, PA: Information Science Reference;; Woodhead, R., What is Technology? [IJSKD] (2012) International Journal of Sociotechnology and Knowledge Development, 4 (2), pp. 1-13; Woodley, C., Dorrington, P., Facebook and the Societal Aspects of Formal Learning: Optional, Peripheral, or Essential (2014) The Social Classroom: Integrating Social Network Use in Education, pp. 269-291. , G. Mallia (Ed.), Hershey, PA: Information Science Reference;; Yamazaki, T., Assistive Technologies in Smart Homes (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 663-678. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Yan, Z., Chen, Q., Yu, C., The Science of Cell Phone Use: Its Past, Present, and Future. [IJCBPL] (2013) International Journal of Cyber Behavior, Psychology and Learning, 3 (1), pp. 7-18; Yang, Y., Wang, X., Li, L., Use Mobile Devices to Wirelessly Operate Computers. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (1), pp. 64-77; Yartey, F.N., Ha, L., Like, Share, Recommend: Smartphones as a Self-Broadcast and Self-Promotion Medium of College Students. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (4), pp. 20-40; Yaseen, S.G., Al Omoush, K.S., Investigating the Engage in Electronic Societies via Facebook in the Arab World. [IJTHI] (2013) International Journal of Technology and Human Interaction, 9 (2), pp. 20-38; Yeo, B., Sustainable Economic Development and the Influence of Information Technologies: Dynamics of Knowledge Society Transformation. [IJSKD] (2012) International Journal of Sociotechnology and Knowledge Development, 4 (3), pp. 54-55; Yu, L., Ureña, C., A Review of Current Approaches of Brain Computer Interfaces (2014) Assistive Technologies: Concepts, Methodologies, Tools, and Applications, pp. 1516-1534. , I. Management Association (Ed.), Hershey, PA: Information Science Reference; Zelenkauskaite, A., Analyzing Blending Social and Mass Media Audiences through the Lens of Computer-Mediated Discourse (2014) Innovative Methods and Technologies for Electronic Discourse Analysis, pp. 304-326. , H. Lim & F. Sudweeks (Eds.), Hershey, PA: Information Science Reference;},
document_type={Book},
source={Scopus},
}

@ARTICLE{ElMesbahi2015590,
author={El Mesbahi, M.},
title={Human-robot interaction ethics in sci-fi movies: Ethics are not ‘there’, we are the ethics!},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2015},
volume={9186},
pages={590-598},
doi={10.1007/978-3-319-20886-2_55},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947213624&doi=10.1007%2f978-3-319-20886-2_55&partnerID=40&md5=ed8133ac620ea3e9ba277776e3424aae},
abstract={Human-Robot interaction is a field seeing massive growth, and as robots gain more and more capabilities they will play an increasingly prominent part in our everyday lives. But, as robotic development continues to grow, one subfield of robotics research is lagging behind other areas: roboethics or ensuring that robot behavior adheres to certain moral standards. This paper explores robot ethics through the lens of some popular sci-fi movies involving robots as characters in their storyline. Different ethical issues related to human-robot interaction are cast and discussed. To overcome those issues, a survey was conducted to detect everyone’s duty. Its results and implications are presented and may be of benefit to HRI researchers. © Springer International Publishing Switzerland 2015.},
author_keywords={Ethics;  Human-Robot interaction;  Science-Fiction movies},
keywords={Human computer interaction;  Man machine systems;  Motion pictures;  Philosophical aspects;  Robotics;  Robots, Ethical issues;  Ethics;  Robot behavior;  Robot ethics;  Robotics research;  Science fictions;  Storylines;  Through the lens, Human robot interaction},
references={Asimov, I., Runaround (1950) Astounding Science Fiction, , March 1942. Reprinted in I, Robot; Ingram, B., Jones, D., Lewis, A., Richards, M., Rich, C., Schachterle, L., A code of ethics for robotics engineers (2010) Proceedings of the 5Th ACM/IEEE International Conference on Human-Robot Interaction (HRI); Anya, O., Tawfik, H., Nagar, A., Westaby, C., An ethics-informed approach to the development of social robotics (2011) From Critique to Action: The Practical Ethics of The Organizational World, 231 (253), p. 23; Calo, M.R., Robots and privacy (2012) Robot Ethics: The Ethical and Social Implications of Robotics, , In: Lin, P., Bekey, G., Abney, K. (eds.), MIT Press, Cambridge; Nourbakhsh, I.R., (2013) Robot Futures, , MIT Press, Cambridge; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press, Oxford},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lü201534,
author={Lü, C.},
title={Robot Ethics in Western Science Fiction},
journal={Foreign Literature Studies},
year={2015},
volume={37},
number={1},
pages={34-40},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926151840&partnerID=40&md5=4d21e860f2217ca3230318a73d865184},
abstract={Robot Ethics in Western Science Fiction Ethical literary criticism has natural close ties with science fiction, and robot ethics is an important research field. In Western literature, human's attitude toward robots has generally undergone three stages: refusing to accept them, confining them to the servant role, and blending human and robot into post-human Cyborg. On the one hand, the prospective description about robots in science fiction can predict the development of related technology, and promote people to rethink the ethical limitations; on the other hand, development in technology also affects the evolution of robot ethics in science fiction. ©, 2015, Central China Normal University. All right reserved.},
author_keywords={Ethical literary criticism;  Robot ethics;  Science fiction},
references={Čapek, K., (2011) Rossum's Universal Robots, , Trans. Paul Selver. London: Gollancz; Deitch, J., (1992) Post Human, , New York: DAP; Haraway, D., "Manifeso for Cyborgs: Science, Technology, and Socialist Feminism in the 1980s." (1985) Socialist Review, 15, pp. 65-108; Hegel, G., (1981) The Phenomenology of Spirit, 1. , Trans. He Lin and Wang Jiuxing. Beijing: The Commercial Press; Lyotard, J.F., (2001) The Inhuman: Reflection on Time, , Trans. Luo Guoxiang. Beijing: The Commercial Press; Nie, Z., "Ethical Approach to Literary Studies: A New Perspective." (2004) Foreign Literature Studies, 5, pp. 16-24; Piercy, M., (1991) He, She and It, , New York: Fawcett Crest; Roberts, A., (2005) The History of Science Fiction, , Basingstoke: Palgrave Macmillan},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Cortese20147,
author={Cortese, F.A.B.},
title={The maximally distributed intelligence explosion},
journal={AAAI Spring Symposium - Technical Report},
year={2014},
volume={SS-14-03},
pages={7-16},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904916768&partnerID=40&md5=cd4a95735d5c6bff186856c16752799a},
abstract={We argue that the most effective solution paradigm in machine ethics aiming to maximize safe relations between humans and recursively self-improving AI is to maximize the approximate equality between humans and AGI. We subsequently argue that embedding the concomitant intelligence-amplification of biological humans as a necessary intermediary goal between each successive iteration of recursive self-improvement - such that the AGI conceives of such an intermediary step as a necessary subgoal of its own self-modification - constitutes the best logistical method of maintaining approximate intelligence equality amongst biological humans and recursively self-improving AGI. We ultimately argue that this approach bypasses the seeming impasse of needing to design, develop and articulate a motivational system possessing a top-level utility function that doesn't decay over repeated iterations of recursive self-improvement in order to have a safe recursively self-modifying AGI. Copyright © 2014, Association for the Advancement of Artificial Intelligence. All rights reserved.},
keywords={Distributed intelligence;  Effective solution;  Self-modification;  Subgoals;  Successive iteration;  Utility functions, Iterative methods},
references={Arel, I., The threat of a reward-driven adversarial artificial general intelligence (2012) Singularity Hypotheses, pp. 43-60. , Springer; Johnson, N., Zhao, G., Hunsader, E., Qi, H., Johnson, N., Meng, J., Tivnan, B., Abrupt rise of new machine ecology beyond human response time (2013) Scientific Reports, 3; Legg, S., Hutter, M., Universal intelligence: A definition of machine intelligence (2007) Minds and Machines, 17 (4), pp. 391-444. , DOI 10.1007/s11023-007-9079-x; Legg, S., (2008) Machine Super Intelligence, 3 (6), p. 43. , Department of Informatics, University of Lugano; McCarthy, J., (2007) What Is Artificial Intelligence, , http://www-formal.Stanford.edu/jmc/whatisai.html; Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., Riedmiller, M., (2013) Playing Atari with Deep Reinforcement Learning, , arXiv preprint arXiv: 1312.5602; Russell, S.J., Rationality and intelligence (1997) Artificial Intelligence, 94 (1-2), pp. 57-77. , PII S000437029700026X},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Pontier2013502,
author={Pontier, M.A. and Van Gelder, J.-L. and De Vries, R.E.},
title={A computational model of affective moral decision making that predicts human criminal choices},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2013},
volume={8291 LNAI},
pages={502-509},
doi={10.1007/978-3-642-44927-7_40},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893080485&doi=10.1007%2f978-3-642-44927-7_40&partnerID=40&md5=0a84ceeefb6f8738c4a527dd7505cbb4},
abstract={In the present paper we show that a computational model of affective moral decision making can fit human behavior data obtained from an empirical study on criminal decision making. By applying parameter tuning techniques on data from an initial sample, optimal fits of the affective moral decision making model were found supporting the influences of honesty/humility, perceived risk and negative state affect on criminal choice. Using the parameter settings from the initial sample, we were able to predict criminal choices of participants in the holdout sample. The prediction errors of the full model were fairly low. Moreover, they compared favorably to the prediction errors produced by constrained variants of the model where either the moral, rational or affective influences or a combination of these had been removed. © 2013 Springer-Verlag.},
author_keywords={Affective Decision Making;  Cognitive Modeling;  Criminal Decision Making;  Empirical Data;  Machine Ethics;  Mathematical Modeling;  Moral Reasoning},
keywords={Cognitive model;  Computational model;  Decision making models;  Empirical data;  Empirical studies;  Moral reasoning;  Parameter setting;  Prediction errors, Computational methods;  Crime;  Data privacy;  Errors;  Forecasting;  Mathematical models;  Multi agent systems;  Network security, Decision making},
references={Athens, L., Violent encounters, violent engagements, and tiffs (2005) Journal of Contemporary Ethnography, 34, pp. 631-678; Bosse, T., Brenninckmeyer, J., Kalisch, R., Paret, C., Pontier, M.A., Matching Skin Conductance Data to a Cognitive Model of Reappraisal (2011) Proceedings of of the 33th International Annual Conference of the Cognitive Science Society, CogSci 2011, pp. 1888-1893; Bosse, T., Pontier, M., Siddiqui, G.F., Treur, J., Incorporating emotion regulation into virtual stories (2007) Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 4722 LNCS, pp. 339-347. , Intelligent Virtual Agents - 7th International Conference, IVA 2007, Proceedings; Bosse, T., Pontier, M.A., Treur, J., A Computational Model based on Gross' Emotion Regulation Theory (2010) Cognitive Systems Research Journal, 11, pp. 211-230; Chaiken, S., Yaacov, T., (1999) Dual-Process Theories in Social Psychology, , Guilford Press, New York; De Vries, R.E., Ashton, M.C., Lee, K., De zes belangrijkste persoonlijkheidsdimensies en de HEXACO Persoonlijkheidsvragenlijst (2009) Gedrag en Organisatie, 22, pp. 232-274; Hoorn, J.F., Pontier, M.A., Siddiqui, G.F., When the user is instrument to robot goals (2008) Proceedings of the Seventh IEEE/WIC/ACM International Conference on Intelligent Agent Technology, IAT 2008, pp. 296-301; Hoorn, J.F., Pontier, M.A., Siddiqui, G.F., Coppélius' Concoction: Similarity and Complementarity Among Three Affect-related Agent Models (2012) Cognitive Systems Research Journal, pp. 33-49; Lee, E., Leets, L., Persuasive storytelling by hate groups online: Examining its effects on adolescents (2002) American Behavioral Scientist, 45, pp. 927-957; Ohnsorge, K., Widdershoven, G.A.M., Monological versus dialogical consciousness - two epistemological views on the use of theory in clinical ethical practice (2011) Bioethics, 25 (7), pp. 361-369; Painter, L.T., Cook, J.W., Silverman, P.S., The effects of therapeutic storytelling and behavioral parent training on noncompliant behavior in young boys (1999) Child and Family Behavior Therapy, 21 (2), pp. 47-66; Pontier, M.A., Hoorn, J.F., Toward machines that behave ethically better than humans do (2012) Proceedings of of the 34th International Annual Conference of the Cognitive Science Society, CogSci 2012, pp. 2198-2203. , Miyake, N., Peebles, B., Cooper, R.P. (eds.); Pontier, M.A., Siddiqui, G.F., An Affective Agent Playing Tic-Tac-Toe as Part of a Healing Environment (2009) LNCS, 5925, pp. 33-47. , Yang, J.-J., Yokoo, M., Ito, T., Jin, Z., Scerri, P. (eds.) PRIMA 2009. Springer, Heidelberg; Pontier, M.A., Widdershoven, G.A.M., Robots that stimulate autonomy (2013) IFIP AICT, 412, pp. 195-204. , Papadopoulos, H., Andreou, A.S., Iliadis, L., Maglogiannis, I. (eds.) AIAI 2013. Springer, Heidelberg; Pontier, M.A., Widdershoven, G., Hoorn, J.F., Moral Coppélia - Combining Ratio with Affect in Ethical Reasoning (2012) LNCS, 7637, pp. 442-451. , Pavón, J., Duque-Méndez, N.D., Fuentes-Fernández, R. (eds.) IBERAMIA 2012. Springer, Heidelberg; Schlosser, R.W., Lloyd, L.L., Effects of initial element teaching in a story-telling context on Blissymbol acquisition and generalization (1993) J. of Speech and Hearing Research, 36, pp. 979-995; Steel, R.G.D., Torrie, J.H., (1960) Principles and Procedures of Statistics, pp. 187-287. , McGraw-Hill, New York; Van Gelder, J.L., Beyond rational choice: The hot/cool perspective of criminal decision making (2013) Psychology, Crime & Law, 19, pp. 745-763; Van Gelder, J.L., De Vries, R.E., Traits and states: Integrating personality and affect into a model of criminal decision making (2012) Criminology, 50, pp. 637-671; Van Gelder, J.L., De Vries, R.E., Rational misbehavior? Evaluating an integrated dual-process model of criminal decision making (2012) Journal of Quantitative Criminology; Van Gelder, J.L., De Vries, R.E., Van Der Pligt, J., Evaluating a dual-process model of risk: Affect and cognition as determinants of risky choice (2009) J. Behavioral Decision Making, 22, pp. 45-61},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Dougherty20131,
author={Dougherty, M.},
title={Something old, something new, something borrowed, something blue part 2: From Frankenstein to Battlefield drones; A perspective on machine ethics},
journal={Journal of Intelligent Systems},
year={2013},
volume={22},
number={1},
pages={1-7},
doi={10.1515/jisys-2013-001},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875425909&doi=10.1515%2fjisys-2013-001&partnerID=40&md5=50f0b1701d5d711c931ac192c5528a9d},
abstract={Intelligent systems are reaching the point where they can take very significant decisions on behalf of humans and society. The moral and ethical impact of such systems needs to be taken very seriously, both internally and externally in respect of such systems. Although some work into defining and systematizing machine ethics has begun, a great deal of work remains to be done and many research questions remain open. © 2013 by Walter de Gruyter Berlin Boston.},
author_keywords={Drones;  Machine Ethics;  Robots},
keywords={Drones;  Machine Ethics;  On-machines;  Research questions, Intelligent systems;  Robots;  Target drones, Philosophical aspects},
references={Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) J. Exp. Theor. Artif. Intell., 12, pp. 251-261; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-26; Asimov, I., Robot, I., (2008) Spectra, , Reprint of the Original from 1950; Bergadanoa, F., Gunetti, D., (1995) Inductive Logic Programming: From Machine Learning to Software Engineering, , MIT Press; Dougherty, M., Something old, something new, something borrowed, something blue. Part 1: Alan Turing, hypercomputation, Adam Smith and next generation intelligent systems (2012) J. Intell. Syst., 21, pp. 325-330; French, R., Moving beyond the Turing test (2012) Commun. ACM, 55 (12), pp. 74-77; Moor, J.H., The nature importance and difficulty of machine ethics (2006) IEEE Intell. Syst., 21 (4), pp. 18-21; Shelley, M., Frankenstein or the modern prometheus (2012) CreateSpace Independent Publishing Platform, , First edition originally published in 1818},
document_type={Review},
source={Scopus},
}

@CONFERENCE{McBride2012,
author={McBride, N.},
title={A robot ethics: The EPSRC principles and the ethical gap},
journal={AISB/IACAP World Congress 2012: Framework for Responsible Research and Innovation in AI, Part of Alan Turing Year 2012},
year={2012},
page_count={6},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893204810&partnerID=40&md5=8520740747a6c1d07beeff0f99d8f955},
abstract={This paper posits a practice-based approach to robot ethics in which the ethics is understood with the boundary of the practice and the community of practitioners within which the robot acts. The approach involves creating a taxonomy of robot practice, identifying boundaries of practice, and creating a robot ethics ontology. The approach is set in the context of current robot ethics principles, a discussion of the limits of robot ethics and the limits that the uncodability of moral decision making.},
keywords={Robot ethics, Philosophical aspects},
references={Blackford, R., (2012) Robots and Reality: A Reply to Robert Sparrow Ethics and Information Technology, 14, pp. 41-51; (2010) EPSRC Principles of Robotics, , http://www.epsrc.ac.uk/ourportfolio/themes/engineering/activities/Pages/ principlesofrobotics.aspx; Hursthouse, R., (1999) On Virtue Ethics Oxford, , University Press; Ivandic, M., Hoffman, W., Guder, W.G., The use of knowledgebased systems to improve medical knowledge about urine analysis (2000) Clinica Chemica Acta, 297, pp. 251-260; Macintyre, A., (1981) After Virtue, , Duckworth; Peterson, S., The ethics of robot servitude (2010) Journal of Experimental and Theoretical Artificial Intelligence, 19 (1), pp. 43-54; Von Neumann, J., (1957) The Computer and the Brain, , Yale University Press; Young, J.E., Hawkins, R., Sharlin, E., Ugarashi, T., Toward acceptable domestic robots: Applying insights from social psychology (2009) International Journal of Social Robotics, 1, pp. 95-108. , 2009},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wilks2012,
author={Wilks, Y.},
title={Cognitive issues of sentiment in Machine and Human Ethics},
journal={AISB/IACAP World Congress 2012: Moral Cognition and Theory of Mind, Part of Alan Turing Year 2012},
year={2012},
page_count={5},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893199089&partnerID=40&md5=7280038e9826670309a4cb3f9b6747b3},
abstract={Although referring to some philosophical work on the "machine ethics" issue, the paper is largely concerned with contribution made by those working within the AI-tradition, where the author himself also belongs. The paper argues that an Ethical Machine is a real possibility but might not be based on a traditional core-AI view in which rationality is central, but might be better based on a moral sentiment (or even virtue) account of the origins and function of ethics.},
keywords={Philosophical aspects},
references={Wilks, Y., Is a Companion a distinctive kind of relationship with a machine? (2010) Proc. ACL 2010 Workshop on Companionable Dialogue Agents, , Uppsala, Sweden; Moor, J.H., The nature, importance and difficulty of machine ethics (2006) IEEE Intelligent Systems; Leibniz, G.W., Opinion on the principles of pufendorf (1988) Political Writings, p. 71. , Second edition. Translated and edited by Patrick Riley. Cambridge University Press, Cambridge; Wilks, Y., Understanding without proofs (1973) Proc. of the International Conference on Artificial Intelligence, , Stanford, CA; Wason, P., Johnson-Laird, P., (1972) Psychology of Reasoning: Structure and Content, , Harvard University Press: Cambridge, MA; Hume, D., An enquiry concerning the principles of morals (1751) Essays Moral, Political, and Literary, , David Hume, edited with preliminary dissertations and notes by T.H. Green and T.H. Grose, Longmans, Green : London; Smith, A., The Theory of Moral Sentiments, 1759. , Millar: London; Anderson, M., Anderson, S., Robot be good (2010) Scientific American; Wilks, Y., Your friends and your machines (1975) Mind, 12 (332); Waldrop, M.M., A question of responsibility (1987) AI Magazine; Thompson, H.S., Computational systems, responsibility and moral sensibility (1999) Technology in Society; Marsella, S., Gratch, J., Petta, P., Computational models of emotion (2010) A Blueprint for An Affectively Competent Agent: Cross-fertilization between Emotion Psychology, Affective Neuroscience, and Affective Computing, , In Scherer, K.R., Bänziger, T., & Roesch, E. (Eds). Oxford,University Press: Oxford; Levy, D., (2007) Love and Sex with Robots, , Harper Collins: New York; Glymour, C., Ford, K., (2008) Prosthetic Pensees, , IHMC-Florida research report; McDermott, D., Why ethics is a high hurdle for AI (2008) Proc. North American Conference on Computers and Philosophy (NA-CAP), , Bloomington, Indiana; Anderson, M., Anderson, S., (2011) Machine Ethics, , Cambridge University Press: Cambridge; Moore, G.E., (1903) Principia Ethica, , Cambridge University Press: Cambridge; Asimov, I., (1950) I Robot, , Doubleday: New York; Anderson, M., Anderson, S., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine; Dreyfus, H., (1972) What Computers Can't Do, , MIT Press: New York; Wilks, Y., Responsible computers? Invited contribution to panel on computers and legal responsibility (1985) Proc. of International Joint Conference on Artificial Intelligence, , Los Angeles, CA; Wilks, Y., Ballim, A., Liability and consent (1990) Law, Computers and Artificial Intelligence, , In Narayanan & Bennun (eds). Norwood, NJ: Ablex; Macintyre, A., (1985) After Virtue, , second edition Duckworth, London; Foot, P., (1978) The Problem of Abortion and the Doctrine of the Double Effect in Virtues and Vices, , Oxford: Basil Blackwell},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Briggs2012,
author={Briggs, G.},
title={Machine ethics, the frame problem, and theory of mind},
journal={AISB/IACAP World Congress 2012: Moral Cognition and Theory of Mind, Part of Alan Turing Year 2012},
year={2012},
page_count={4},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893174154&partnerID=40&md5=991967de610c523e7181d524fe20948f},
abstract={Work in machine ethics has thus far been focused on giving autonomous agents the ability to select morally-correct behaviors given well-formed moral problems. While this is a necessary component to enable an agent to comport to standards of moral behavior, it is not sufficient. In this paper, we present a simple task-domain to illustrate this point.We show that even in simple domains, the potential for deception and trickery on the part of the humans interacting with morally-sensitive agents will require these agents to have sophisticated cognitive faculties in order to avoid unethical behavior.},
keywords={Cognitive faculty;  Frame problems;  Theory of minds, Autonomous agents, Philosophical aspects},
references={Arkin, R., Governing lethal behavior: Embedding ethics in a hybrid deliberative/reactive robot architecture (2009) Technical Report GITGVU-07-11, , Georgia Institute of Technology; Bridewell, W., Issac, A., Recognizing deception: A model of dynamic belief attribution (2011) AAAI 2011 Fall Symposium on Advances in Cognitive Systems; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intelligent Systems, 21 (5), pp. 38-44. , July/Aug; Dennett, D., (1984) Cognitive Wheels: The Frame Problem of Ai in Mind, Machines, and Evolution, , Cambridge University Press; Grice, P., (1975) Logic and Conversation in Syntax and Semantics 3: Speech Acts, , eds., P. Cole and J. Morgan Academic Press, New York; Guarin, M., Bello, P., Robotic warfare: Some challenges in moving from noncivilian to civilian theaters (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 129-144. , MIT Press, Cambridge, MA; Guarini, M., Particularism and the classification and reclassification of moral cases (2006) IEEE Intelligent Systems, 21 (4), pp. 22-28. , July/August; Guarini, M., Particularism, analogy, and moral cognition (2010) Minds and Machines, 20 (3), pp. 385-422; Schermerhorn, P., Scheutz, M., The utility of affect in the selection of actions and goals under real-world constraints (2009) Proceedings of the 2009 International Conference on Artificial Intelligence, , July; Turing, A.M., Computing machinery and intelligence (1950) Mind, 59 (236), pp. 433-460. , Oct; Wallach, W., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford,University Press, New York, NY; Zaibert, L., (2005) Five Wars Patricia Can Kill Her Husband: A Theory of Intentionality and Blame, , Open Court Press, Peru, IL},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Bello2012,
author={Bello, P. and Bringsjord, S.},
title={Machine ethics, folk intuitions, and the cognitive architecture of moral judgments},
journal={AISB/IACAP World Congress 2012: Moral Cognition and Theory of Mind, Part of Alan Turing Year 2012},
year={2012},
page_count={5},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893155558&partnerID=40&md5=cb2b73e57684a0c3b51e914b91c3d8c2},
abstract={This paper begins the exploration of a new research paradigm for machine ethicists: a systematic focus on the mental representations and processes that produce commonsense moral judgments of the variety that all normally developed humans seem to be capable of. We assume that formally capturing the relevant conceptual repertoire along with developing properly parameterized inference mechanisms satisfy the necessary and sufficient conditions for building a machine equipped with something like robust moral commonsense. After discussing the various advantages and challenges of taking this particular tack on machine ethics, we explore a case study involving the interplay of intuitions about freedom, responsibility, and the self. Specifically, we examine recent results in experimental philosophy that provides a richer picture of the set of concepts involved in moral judgment, and speculate that some of the trends existing across the data are explicable in light of the cognitive architecture of mental state attribution or mindreading, as we shall refer to it. We suggest that along with machine ethicists working on the implementation of meta-ethical principles generated in the armchair, we ought to pursue the formalization of folk intuitions about freedom and agency to move us closer toward moral machines. So long as a robot has something like human folk beliefs about freedom and agency, and can deploy these believably in service of moral evaluation, it looks as if we might avoid the dispute about the correct (meta)ethic to adopt in favor of outright trickery: a fitting strategy for this celebration of Alan Turing's life and work.},
keywords={Cognitive architectures;  Inference mechanism;  Mental representations;  Mental state;  Moral judgment;  On-machines;  Parameterized, Philosophical aspects, Cognitive systems},
references={Arkin, R., (2009) Governing Lethal Behavior in Autonomous Robots, , Chapman and Hall/CRC; Arkoudas, K., Bringsjord, S., Propositional attitudes and causation (2009) International Journal of Software and Informatics, 3 (1), pp. 47-65; Bringsjord, S., Taylor, J., The divine-command approach to robot ethics (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 85-108. , eds., P. Lin, G. Bekey, and K. Abney, MIT Press, Cambridge, MA; Bringsjord, S., Free will (1992) What Robots Can and Can't Be, pp. 266-327. , Kluwer, Dordrecht, The Netherlands; Bringsjord, S., Declarative/logic-based cognitive modeling (2008) The Handbook of Computational Psychology, pp. 127-169. , ed., Ron Sun, Cambridge University Press, Cambridge, UK; Goldman, A., (2006) Simulating Minds, , Oxford,University Press; Harris, P., (2000) The Work of the Imagination, , Blackwell Publishers Ltd; Knobe, J., Nichols, S., Free will and the bounds of the self (2011) Oxford Handbook of Free Will: Second Edition, pp. 530-554. , ed., R. Kane, Oxford,University Press; Nahmias, E., Morris, S., Nadelhoffer, T., Turner, J., Is incompat-ibilism intuitive? (2008) Experimental Philosophy, pp. 81-104. , eds., J. Knobe and S. Nichols, Oxford; Nichols, S., Knobe, J., Moral responsibility and determinism: The cognitive science of folk intuitions (2008) Experimental Philosophy, pp. 105-128. , eds., J. Knobe and Nichols, Oxford},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Danielson2011239,
author={Danielson, P.},
title={Engaging the public in the ethics of robots for war and peace},
journal={Philosophy and Technology},
year={2011},
volume={24},
number={3},
pages={239-249},
doi={10.1007/s13347-011-0025-8},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052626482&doi=10.1007%2fs13347-011-0025-8&partnerID=40&md5=161d03af19ebb6b5f54da8407f77d134},
abstract={Emerging technologies like robotics for war and peace stress our moral norms and generate much public interest and controversy. We use this interest to attract participants to an innovative on-line survey platform, designed for experimenting with public engagement in the ethics of technology. In particular, the N-Reasons platform addresses several issues in democratic ethics: the cost of public participation, the methodological issue of feasible reflective ethical equilibrium (how can individuals in a large group, take into account the ethical views of all others?), and the reliability of public participation processes. We sketch the motivation and design of the N-Reasons platform, stressing the need for a practical (fast, low-cost) instrument that makes equilibrium feasible. We focus on the Robot Ethics Survey that featured a set of nine ethical challenges raised by robotics for war and peace. Over 400 people in five disjoint groups participated in this on-line survey experiment. We analyze the results, both quantitatively and qualitatively, the participants' decisions taken and the reasons supporting these decisions. Both decisions and reasons strongly distinguished lethal military robotics from peace-related robotics. Methodologically, both decisions and reasons over five distinct groups were remarkably consistent. © 2011 Springer-Verlag.},
author_keywords={Applied ethics;  Mixed methods;  Public participation;  Reflective equilibrium;  Robot ethics;  Survey research},
references={Ahmad, R., The risks of cognitive enhancers: A normative theory (2009) The 4th International Conference on Applied Ethics, , Paper presented at the Sapporo; Ahmad, R., Bornik, Z., Danielson, P., Dowlatabadi, H., Levy, E., Longstaf, H., Innovations in web-based public consultation: Is public opinion on genomics influenced by social feedback? (2005) First International Conference on E-Social Science, , Paper presented at the National Centre for e-Social Science, University of Manchester; Ahmad, R., Bailey, J., Bornik, Z., Danielson, P., Dowlatabadi, H., Levy, E., A web-based instrument to model social norms: NERD design and results (2006) Integrated Assessment, 6 (2), pp. 9-36; Ahmad, R., Bailey, J., Danielson, P., Analysis of an innovative survey platform: Comparison of the public's responses to human health and salmon genomics surveys (2010) Public Understanding of Science, 19 (2), pp. 155-165. , 10.1177/0963662508091806; Arkin, R.C., (2010) Governing Lethal Behavior in Autonomous Robots, , Chapman and Hall/CRC Boca Raton; Danielson, P., From artificial morality to NERD: Models, experiments, & robust reflective equilibrium (2006) Artificial Life 10: Achievements and Future Challenges for Artificial Life, , Paper presented at the Bloomington, Indiana; Danielson, P., Metaphors and models for data mining ethics (2009) Social Implications of Data Mining and Information Privacy: Interdisciplinary Frameworks and Solutions, pp. 33-47. , E. Eyob (eds). IGI Global Hershey. 10.4018/978-1-60566-196-4.ch003; Danielson, P.A., Review of Wendell Wallach and Colin Allen, moral machines: Teaching robots right from wrong (2009) Notre Dame Philosophical Reviews, 2009.03.01; Danielson, P.A., Can robots have a conscience? Review of Wendell Wallach and Colin Allen, moral machines: Teaching robots right from wrong (2009) Nature, 457 (29), p. 540. , 10.1038/457540a; Danielson, P., A collaborative platform for experiments in ethics and technology (2010) Philosophy and Engineering: An Emerging Agenda, pp. 239-252. , I. van der Poel D.E. Goldberg (eds). Springer Berlin; Danielson, P., Designing a machine to learn about the ethics of robotics: The N-reasons platform (2010) Ethics and Information Technology, 12 (3), pp. 251-261. , 10.1007/s10676-009-9214-x; Danielson, P., Ahmad, R., Bornik, Z., Dowlatabadi, H., Levy, E., Deep, cheap, and improvable: Dynamic democratic norms & the ethics of biotechnology (2007) Ethics and the Life Sciences, , F. Adams (eds). Philosophy Documentation Center Charlottesville; Danielson, P., Mesoudi, A., Stanev, R., NERD and norms: Framework and experiments (2008) Philosophy of Science, 75 (5), pp. 830-842. , 10.1086/594527; Danielson, P.A., Longstaff, H., Ahmad, R., Van Der Loos, H.F.M., Mitchell, I.M., Oishi, M.M.K., Case study: An assistive technology ethics survey (2010) Design and Use of Assistive Technology: Social, Technical, Ethical, and Economic Challenges, pp. 75-93. , M.M.K. Oishi I.M. Mitchell H.F.M. Van der Loos (eds). Springer New York; Danielson, P.A., N-Reasons: Computer mediated ethical decision support for public participation (2011) Publics & Emerging Technologies: Cultures, Contexts, and Challenge, , E. Einsiedel & K. O'Doherty (eds.) Vancouver: UBC Press; Danielson, P.A., Prototyping N-Reasons: A computer mediated ethics machine (2011) Machine Ethics, p. 9. , M. Anderson E. Anderson (eds). Cambridge University Press New York; Fishkin, J.S., (1997) The Voice of the People: Public Opinion and Democracy, , Yale University Press New Haven; Fishkin, J.S., Strategies of public consultation (2006) Integrated Assessment, 6 (2), pp. 57-72; Ormandy, E.H., Schuppli, C.A., Weary, D.M., Regulation increases public acceptance of animal-based science (2009) 7th World Congress on Alternatives & Animal Use in the Life Sciences, , Paper presented at Rome, Italy; Schuppli, C.A., Weary, D.M., Multiple uses of pigs: An interactive survey to assess people's attitudes towards animal use and genetic modification (2007) Moving Mountains, 46th Annual Symposium of the Association for Laboratory Animal Science, , Paper presented at the Calgary, Alberta; Solove, D.J., (2008) The Future of Reputation: Gossip, Rumor, and Privacy on the Internet, , Yale University Press New Haven},
document_type={Article},
source={Scopus},
}

@BOOK{NoAuthor20091,
title={Learning Inverse Dynamics by Gaussian Process Regression Under the Multi-task Learning Framework},
journal={The Path to Autonomous Robots: Essays in Honor of George A. Bekey},
year={2009},
pages={1-177},
doi={10.1007/978-0-387-85774-9},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043073879&doi=10.1007%2f978-0-387-85774-9&partnerID=40&md5=42a826e2b88afa6158586852fa6ef44d},
abstract={This collection of technical articles, written by leading international researchers in robotics, presents threads of modern robotics research. Also included are brief reminiscences of the former students of Professor George A. Bekey, reflecting on his remarkable 50-year career as an innovative educator and authority on Autonomous Robots. Together, these words pay tribute to Bekey's stature as a pioneer in the field, particularly in the areas of medical and rehabilitation robotics, human robot interaction and robot ethics. Topics explored in these chapters include:Mobile robots in extreme environmentsAutonomous spacecraftThe design of networked robotic systems Robotic grasping using inputs from vision systemsAdvances in manipulation and mobility inspired by human control systems New directions in human-robot interaction A biomimetic approach to autonomous robot design Applying multi-task learning to inverse dynamics Researchers and students will be inspired both by these contributions and Professor Bekey's accomplishments, and the volume will undoubtedly spur further reading and research in the field. © 2009 Springer Science+Business Media, LLC.},
references={http://en.wikipedia.com/wiki/Moore's\_law; http://nvidia.com/cuda; (1977) 20th Century Fox: Star Wars (The Movie), , en.wikipedia.org/wiki/Star Wars; Guccione, E.A., Development and testing of a self-report instrument to measure actions: Outpatient physical therapy improvement in movement assessment log (optimal) (2005) Physical Therapy, 85, pp. 515-530; Açikmeşe, B., Carson, J., Hadaegh, F., Distributed estimation for spacecraft formationsover time-varying sensing topologies (2008) Proceedings of the 17th IFAC World Congress, pp. 2123-2130; Açimeşe, B., Scharf, D., Murray, E., Hadaegh, F., A convex guidance algorithm for formation reconfiguration (2006) AIAA Guidance, Navigation and Control Conference; Acikmese, B., Hadaegh, F., Scharf, D.S.R.P., Formulation and analysis of stability for spacecraft formations (2007) IET Control Theory and Application, Special Issue on Cooperative Control of Multiple Spacecraft Flying in Formation, 1 (2), pp. 461-474; Agah, A., Bekey, G.A., Phylogenetic and ontogenetic learning in a colony of interacting robots (1997) Autonomous Robots, 4 (1), pp. 85-100; Akers, E.L., Agah, A., Design and simulation of a polar mobile robot (2008) Journal of Intelligent Systems, 17 (4), pp. 379-404; Akers, E.L., Harmon, H.P., Stansbury, R.S., Agah, A., Design fabrication and evaluation of a mobile robot for polar environments (2004) IEEE International Geoscience and Remote Sensing Symposium (IGARSS), pp. 109-112. , Proceedings of the IEEE International Geoscience and Remote Sensing Symposium, Anchorage, Alaska; Akers, E.L., Stansbury, R.S., Agah, A., Long-term survival of polar mobile robots (2006) Proceedings of the 4th International Conference on Computing Communications and Control Technologies (CCCT), 2, pp. 329-333. , Orlando, FL; Akers, E.L., Stansbury, R.S., Agah, A., Akins, T.L., Mobile robots for harsh environments: Lessons learned from field experiments (2006) Proceedings of the 11th International Symposium on Robotics and Applications (ISORA), pp. 1-6. , Budapest, Hungary; Ambrose, R.O., Aldridge, H., Askew, R.S., Burridge, R.R., Bluethmann, W., Diftler, M., Lovchik, C., Rehnmark, F., Robonaut: Nasa's space humanoid (2000) IEEE Intelligent Systems, 15 (4), pp. 57-63; Arbib, M., (1989) The Metaphorical Brain 2: Neural Networks and beyond, , Wiley - Interscience, New York; Arcone, S., (2003), Personal Communications. Cold Regions Research and Engineering Lab (CRREL), Hanover, New Hampshire; Arkin, R., (1998) Behavior-Based Robotics, , The MIT Press, Cambridge; Asada, H., Slotine, J., (1986) Robot Analysis and Control, , John Wiley and Sons, New York; Plaisant, C.B.S., (2004) Designing the User Interface, , Addison Wesley; Baxter, J., A Bayesian/information theoretic model of bias learning (1996) Proceedings of the Ninth Annual Conference on Computational Learning Theory, pp. 77-88. , Desenzano del Garda, Italy; Baxter, J., A Bayesian/information theoretic model of learning to learn via multiple task sampling (1997) Machine Learning, 28 (1), pp. 7-39; Beard, R., McLain, T., Hadaegh, F., Fuel optimization for constrained rotation of spacecraft formations (2001) Journal of Guidance, Control and Dynamics, 23 (2), pp. 339-346; Beer, R., Chiel, H.J., Quinn, R., Ritzmann, R., Biorobotic approaches to the study of motor systems (1998) Current Opinion in Neurobiology, 8, pp. 777-782; Beer, R., Chiel, H.J., Ritzmann, R., Biologically-inspired approaches to robotics (1997) Communication of the ACM, 40 (3); Beer, R.D., Chiel, H.J., Gallagher, J., Evolution and analysis of model cpgs for walking ii. general princ iples and individual variability (1999) Journal of Computational Neuroscience, 7, pp. 119-147; Beer, R.D., Chiel, H.J., Gallagher, J.C., Evolution and analysis of model cpgs for walking i. dynamic modules (1999) Journal of Computational Neuroscience, 7, pp. 99-118; Bekey, G., (2005) Autonomous Robots, , MIT Press, Cambridge, Massachusetts; Bekey, G., (2005) Autonomous Robots: From Biological Inspiration to Implementation A Nd Control, , Blackwell Scientific Publications, The MIT PRESS; Bekey, G.A., Agah, A., Group behavior of robots (1999) Handbook of Industrial Robotics, pp. 439-445. , second edn. Shimon Y. Nof (Ed.). John Wiley &amp; Sons Inc., New York, New York; Biernacki, C., Celeux, G., Govaert, G., Assessing a mixture model for clustering with the integrated completed likelihood (2000) IEEE Transactions on Pattern Analysis and Machine Intelligence, 22 (7), pp. 719-725; Bingham, C., Mardia, K.V., A small circle distribution on the sphere (1978) Biometrika, 65 (2), pp. 379-389; Blum, A., Chawla, S., Karger, D.R., Lane, T., Meyerson, A., Minkoff, M., Approximation algorithms for orienteering and discounted-reward tsp (2003) Proceedings of the 44th Annual IEEE Symposium on Foundations of Computer Science, pp. 46-55; Bonilla, E., Agakov, F., Williams, C., Kernel multi-task learning using taskspecific features (2007) Proceedings of the Eleventh International Conference on Artificial Intelligence and Statistics, , San Juan, Puerto Rico; Bonilla, E., Chai, K., Williams, C., Multi-task Gaussian process prediction (2008) Advances in Neural Information Processing Systems, 20, pp. 153-160. , J. Platt, D. Koller, Y. Singer, S. Roweis (eds.). MIT Press, Cambridge, MA, USA; Brock, O., Fagg, A.H., Grupen, R.A., Karuppiah, D., Platt, R., Rosenstein, M., A framework for humanoid control and intelligence (2005) International Journal of Humanoid Robotics, 2 (3), pp. 301-336; Brooks, R., Achieving artificial intelligence through building robots (1986) Tech. Rep., Massachusetts Institute of Technology; Brooks, R., Stein, A., Building brains for bodies (1994) Autonomous Robots, 1, pp. 7-25; Brown, T.G., The intrinsic factors in the act of progression in the mammal (1911) Proc. of the Royal Soc. Lond., Ser. B., 84, pp. 309-319; Burgard, W., Moors, M., Stachniss, C., Schneider, F.E., Coordinated multirobot exploration (2005) IEEE Transactions on Robotics, 21 (3); Burridge, R.R., Graham, J., Shillcutt, K., Hirsh, R., Kortenkamp, D., Experiments with an EVA assistant robot (2003) Proceedings of the 7th International Symposium on Artificial Intelligence Robotics and Automation in Space (ISAIRAS- 03); Canny, J., Reif, J., Donald, B., Xavier, P., On the complexity of kinodynamic planning (1988) 29th IEEE Annual Symp. on Foundations of Computer Science, pp. 306-316; Carmichael, B.L., Gifford, C.M., Modeling and simulation of the seismic TETwalker concept (2007) Tech. Rep. CReSIS-TR-134; Chaudhuri, K., Godfrey, B., Rao, S., Talwar, K., Paths, trees and minimum latency tours (2003) Proceedings of the 44th Annual IEEE Symposium on Foundations of Computer Science, pp. 36-45; Ciocarlie, M., Goldfeder, C., Allen, P., Dexterous grasping via eigengrasps: A low-dimensional approach to a high-complexity problem (2007) Proceedings of the Robotics: Science &amp; Systems 2007 Workshop - Sensing and Adapting to the Real World, , Electronically published; Coelho Jr., J.A., Grupen, R.A., A control basis for learning multifingered grasps (1997) Journal of Robotic Systems, 14 (7), pp. 545-557; Coelho Jr., J.A., Piater, J., Grupen, R.A., Developing haptic and visual perceptual categories for reaching and grasping with a humanoid robot (2000) Robotics and Autonomous Systems Journal, Special Issue on Humanoid Robots, 37 (2-3), pp. 195-219; Craig, J., (2004) Introduction to Robotics: Mechanics and Control, , third edn. Prentice Hall; Craig, J.J., (2004) Introduction to Robotics: Mechanics and Control, , Printice Hall; (2006), http://www.cresis.ku.edu; Curtis, S., Mica, J., Nuth, J., Marr, G., ANTS (autonomous nano technology swarm): An artificial intelligence approach to asteroid belt resource exploration (2000) Proceedings of the 51st International Astronautical Congress, , Rio de Janeiro, Brazil; Walshaw, C., Cross, M., Mesh partitioning: A multilevel balancing and refinement algorithm (2000) SIAM Journal on Scientific Computing, 22 (1), pp. 63-80; (2006), http://www.cyberbotics.com; Dautenhahn, K., Billard, A., Games children with autism can play with robota, a humanoid robotic doll (2002) Proceedings of Cambridge Workshop on Universal Access and Assistive Technology, pp. 179-190; Dayan, P., Abbott, L.F., (2001) Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems, , The MIT Press, Cambridge, MA; De Granville, C., Fagg, A.H., Learning Grasp Affordances Through Human Demonstration, , submitted; De Granville, C., Southerland, J., Fagg, A.H., Learning grasp affordances through human demonstration (2006) Proceedings of the International Conference on Development and Learning, , Electronically published; Delcomyn, F., Neural basis of rhythmic behavior in animals (1980) Science, 210, pp. 492-498; Dempster, A., Laird, N., Rubin, D., Maximum likelihood estimation from incomplete data via the em algorithm (1977) Journal of the Royal Statistical Society, Series B, 39 (1), pp. 1-38; Deo, N., (1974) Graph Theory with Applications to Engineering and Computer Science, , Prentice-Hall; Dhariwal, A., Zhang, B., Oberg, C., Stauffer, B., Requicha, A., Caron, D., Sukhatme, G.S., Networked aquatic microbial observing system (2006) Proceedings of the IEEE International Conference of Robotics and Automation (ICRA); Eiken, O., Degutsch, M., Riste, P., Rod, K., Snowstreamer: An efficient tool in seismic acquisition (1989) First Break, 7 (9), pp. 374-378; Ekeberg, O., Grillner, S., Simulations of neuromuscular control in lamprey swimming (1999) Philos Trans R Soc Lond B Biol Sci., 354 (1385); Ellis, H., (1965) The Transfer of Learning, , Macmillan, New York; Escobedo, T.H., Play at the art table: A study of children's play behaviors while drawing (1996) Annual Conference of the Association for the Study of Play; Fagg, A.H., Rosenstein, M.T., Platt Jr., R., Grupen, R.A., Extracting user intent in mixed initiative teleoperator control (2004) Proceedings of the American Institute of Aeronautics and Astronautics Intelligent Systems Technical Conference, , Electronically published; Fox, D., Ko, J., Konolige, K., Limketkai, B., Schulz, D., Stewart, B., Distributed multirobot exploration and mapping (2006) IEEE Proceeding, 94 (7), pp. 1325-1339; Galloway, J., Rhu, J., Agrawal, S., Babies driving robots: Self-generated mobility in very young infants (2008) Journal of Intelligent Service Robotics; (2005), http://www.garmin.com/products/gpsmap76s; Gates, W., (2007) A Robot in Every Home, , Scientific American; Gibson, J.J., (1966) The Senses Considered As Perceptual Systems, , Allen and Unwin; Gibson, J.J., The theory of affordances (1977) Perceiving, Acting, and Knowing, , R.E. Shaw, J. Bransford (eds.), Lawrence Erlbaum, Hillsdale; Gifford, C.M., (2006) Robotic Seismic Sensors for Polar Environments, , Master's Thesis, Department of Electrical Engineering and Computer Science, University of Kansas; Gifford, C.M., Agah, A., Robotic deployment and retrieval of seismic sensors for polar environments (2006) Proceedings of the 4th International Conference on Computing Communications and Control Technologies (CCCT), 2, pp. 334-339. , Orlando, FL; Gifford, C.M., Agah, A., Precise formation of multi-robot systems (2007) Proceedings of the IEEE International Conference on Systems of Systems Engineering (SoSE), pp. 1-6. , San Antonio, TX; Gifford, C.M., Agah, A., Tsoflias, G.P., Hybrid streamers for polar seismic (2006) Eos Trans. AGU, 87 (52); Ginsburg, K.R., (2006) The Importance of Play in Promoting Healthy Child Development and Maintaining Strong Parent-child Bonds; Ginsburg, K.R., The importance of play in promoting healthy child development and maintaining strong parent-child bonds (2007) Pediatrics, 119; Gockley, R., Mataric, M., Encouraging physical therapy compliance with a hands-off mobile robot (2006) Proc. of Human-Robot Interaction; De Granville, C., (2008) Learning Grasp Affordances, , Master's thesis, School of Computer Science, University of Oklahoma, Norman, OK; Grillner, S., Zangger, P., On the central generation of locomotion in the low spinal cat (1979) Exp. Brain Res., 34, pp. 241-261; Hand, D.J., Smyth, P., Mannila, H., (2001) Principles of Data Mining, , MIT Press, Cambridge, MA, USA; Harmon, H.P., Stansbury, R.S., Akers, E.L., Agah, A., Sensing and actuation for a polar mobile robot (2004) Proceedings of the International Conference on Computing Communications and Control Technologies (CCCT), 4, pp. 371-376; Hille, B., (1984) Ionic Channels of Excitable Membranes, , Sinauer, Sunderland; Hodgkin, A.L., Huxley, A.F., A quantitative description of membrane current and its application to conduction and excitation in nerve (1952) J. Physiol., 117 (4), pp. 500-544; Hollis, J., Iseli, J., Williams, M., Hoenmans, S., The future of land seismic (2005) Hart's e &amp; P, 78 (11), pp. 77-81; Hornik, K., White, M.S.H., Multilayer feedforward networks are universal approximators (1989) Neural Networks, 2, pp. 359-366; Howard, A., Bekey, G., Intelligent learning for deformable object manipulation (2000) Autonomous Robots, 9, pp. 51-58; Howard, A., Park, H., Kemp, C., Extracting play primitives for a robot playmate by sequencing low-level motion behavior (2008) Int. Symp. on Robot and Human Interactive Communication (RO-MAN)., , IEEE, Munich, Germany; Howard, A., Remy, S., Park, H., Learning of arm exercise behaviors: Assistive therapy based on therapist-patient observation (2008) RSS: Workshop on Interactive Robot Learning, , Zurich, Switzerland; Hussein, I., Schaub, H., Invariant shape solutions of the spinning three craft coulomb tether problem (2006) Advances in the Astronautical Sciences, Spaceflight Mechanics, Proceedings of the AAS/AIAA Space Flight Mechnaics Meeting, 124, pp. 2015-2033; Izhikevich, E., Simple model of spiking neurons (2003) IEEE Transactions on Neural Networks, 14 (6), pp. 1569-1572; Izhikevich, E., Which model to use for cortical spiking neurons? (2004) IEEE Transactions on Neural Networks, 15 (5), pp. 1063-1070; (2006), http://www.kgs.ku.edu/Geophysics2/Equip/LandStreamer/LandS4.htm; Kimura, H., Fukuoka, Y., Hada, Y., Takase, K., Adaptive dynamic walking of a quadruped robot on irregular terrain using a neural system model (2001) ISRR, pp. 88-97. , Lorne, Australia; Kimura, H., Fukuoka, Y., Konaga, K., Hada, Y., Takase, K., Towards 3d adaptive dynamic walking of a quadruped robot on irregul ar terrain by using neural system model (2001) IEEE and RSJ IROS 2001, , IEEE, Hawaii; King, E.C., Bell, A.C., A towed geophone system for use in snow-covered terrain (1996) Geophysical Journal International, 126 (1), pp. 54-62; King, L., Parker, G., Deshmukh, S., Chong, J.H., Study of interspacecraft coulomb forces and implications for formation flying (2003) Journal of Propulsion and Power, 19 (3), pp. 497-505; Kong, E., Kwon, D., Schweighart, S., Elias, L., Sedwick, R., Miller, D., Electromagnetic formation flight for multisatellite arrays (2005) Journal of Guidance, Control and Dynamics, 41 (4), pp. 659-666; Krause, A., Guestrin, C., Gupta, A., Kleinberg, J., Near-optimal sensor placements: Maximizing information while minimizing communiction cost (2006) Proccedings of the Fifth International Conference on Information Processing in Sensor Networks (IPSN'06), pp. 2-10; Kronreif, G., Prazak, B., Mina, S., Kornfeld, M., Meindl, M., Furst, F., Games children with autism can play with robota, a humanoid robotic doll (2002) Proceedings of Cambridge Workshop on Universal Access and Assistive Technology, pp. 179-190; (2004) PRISM Home: Polar Radar for Ice Sheet Measurements, , http://www.ku-prism.org; Kurz, D., Hantsch, F., Grosse, M., Schiewe, A., Bimber, O., Laser pointer tracking in projector-augmented architectural environments (2007) Proc. of ISMAR, pp. 19-26; Lawrence, N., Platt, J., Learning to learn with the informative vector machine (2004) Proceedings of the Twenty-First International Conference on Machine Learning, pp. 65-72. , Banff, Alberta, Canada; Lawson, P.R., (2001) The Terrestrial Planet Finder, pp. 2005-2011. , International Aeronautical Congress; Lewis, M.A., Perception driven robot locomotion (2002) Robot Society of Japan Journal; Lewis, M.A., Etienne-Cummings, R., Hartmann, M., Cohen, A., Toward biomorphic control using custom avlsi chips (2000) 2000 International Conference on Robotics and Automation, , IEEE, San Francisco; Lewis, M.A., Etienne-Cummings, R., Hartmann, M., Xu, Z.R., Cohen, A.H., An in silico central pattern generator: Oscillator, entrainment, m otor neuron adaptation &amp; Biped mechanism control (2003) Biological Cybernetics, 88 (2), pp. 137-151; Lewis, M.A., Nelson, M.E., Look before you leap: Peering behavior for depth perception (1998) Simulation of Adaptive Behavior, , Zurich; Lindblom, J., Ziemke, T., Analysis of the back-propagation algorithm with momentum (1994) IEEE Transactions on Neural Networks, 5, pp. 505-506; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) International Journal of Computer Vision, 60 (2), pp. 91-110; Mardia, K.V., Jupp, P.E., Directional statistics (1999) Wiley Series in Probability and Statistics, , Wiley, Chichester, West Sussex, England; Matsuoka, K., Mechanisms of frequency and pattern control in the neural rhythm ge nerators (1987) Biol. Cybern, 56, pp. 345-353; Metchev, S., Grindlay, J., A two-dimensional kolmogorov-smirnov test for crowded field source detection: Rosat sources in ngc 6397 (2002) Mon Not R Astron Soc., 335, pp. 73-83; (2006) Mars Manipulator, , http://www.metricanet.com/mars.htm; Michaud, F., Assistive technologies and child-robot interaction (2007) Proceedings of American Association for Artificial Intelligence Spring Symposium on Multidisciplinary Collaboration for Socially Assistive Robotics; Minka, T., Picard, R., Learning how to learn is learning with point sets (1999) Tech. Rep., MIT Media Lab; (2002) VisualNastran 4D R2 User Manual, , MSC Software; M̈uller, W.G., (2001) Collecting Spatial Data, , Physica-Verlag; (2006), http://www.nsf.gov/od/opp/support/southp.jsp; Nguyen-Tuong, D., Peters, J., Seeger, M., Scḧolkopf, B., Learning inverse dynamics: A comparison (2008) Proceedings of the European Symposium on Artificial Neural Networks, , Bruges, Belgium; Nguyen-Tuong, D., Seeger, M., Peters, J., Computed torque control with nonparametric regression models (2008) Proceedings of the 2008 American Control Conference, , Seattle, Washington, USA; (2005), http://www.glaciology.gfy.ku.dk/ngrip/index_eng.htm, Niels Bohr Institute; Nourbakhsh, I., (2007) Course Notes for Principles of Human Robot Interaction, , Unpublished; Park, C., Howard, A., Haptically guided teleoperation for learning manipulation tasks (2007) Robotics: Science and Systems: Workshop on Robot Manipulation, , Atlanta, GA; Park, C., Howard, A., Vision-based force guidance for improved human performance in a teleoperative manipulation system (2007) Int. Conf. on Intelligent Robots and Systems (IROS), , IEEE/RSJ, San Diego, CA; Paul, R., (1981) Robot Manipulators, , MIT Press, Cambridge, Massachusetts, USA; Paul, R.P., (1982) Robot Manipulators: Mathematics Programming and Control, , The MIT Press, Cambridge; Phansalkar, V.V., Sastry, P.S., Analysis of the back-propagation algorithm with momentum (1994) IEEE Transactions on Neural Networks, 5, pp. 505-506; Piaget, J., (1951) Play, Dreams and Imitation in Childhood, , Routledge and Kegan Paul Ltd, London, UK; Piater, J.H., Grupen, R.A., Feature learning for recognition with Bayesian networks (2000) Proceedings of the Fifteenth International Conference on Pattern Recognition, , Barcelona, Spain; Piater, J.H., Grupen, R.A., Learning appearance features to support robotic manipulation (2002) Proceedings of the Cognitive Vision Workshop, , Electronically published; Pinhanez, C., Creating ubiquitous interactive games using everywhere display projectors Proc. of IWEC; Platt Jr., R., (2006) Learning and Generalizing Control-based Grasping and Manipulation Skills, , Ph.D. thesis, Department of Computer Science, University of Massachusetts, Amherst; Platt Jr., R., Fagg, A.H., Grupen, R.A., Nullspace composition of control laws for grasping (2002) Proceedings of the International Conference on Intelligent Robots and Systems, pp. 1717-1723; Platt Jr., R., Fagg, A.H., Grupen, R.A., Whole body grasping (2003) Proceedings of International Conference on Robotics and Automation (ICRA'03); Ploen, S., Scharf, D., Hadaegh, F., Dynamics and control of drag-free formations for earth imaging applications SPIE International Asia-Pacific Symposium: Remote Sensing of the Atmosphere, Environment and Space; Sheriff, R.E., Geldart, L.P., (1995) Exploration Seismology, , second edn. Cambridge University Press; Rahimi, M.H., (2005) Bioscope: Actuated Sensor Network for Biological Science., , Ph.D. thesis, Computer Science Department, Viterbi School of Engineering, USC; Rancourt, D., Rivest, L.P., Asselin, J., Using orientation statistics to investigate variations in human kinematics (2000) Applied Statistics, 49 (1), pp. 81-94; Raskar, R., Cutts, M., Welch, G., Stuerzlinger, W., Efficient image generation for multiprojector and multisurface displays (1998) Ninth EuroGraphics Rendering Workshop; Rasmussen, C., Williams, C., (2006) Gaussian Processes for Machine Learning, , MIT Press, Cambridge, Massachusetts, USA; (2004), http://www.maxatvs.com; Remy, S., Howard, A., In situ interactive teaching of trustworthy robotic assistants (2007) IEEE Int. Conf. on Systems, Man, and Cybernetics; Ren, W., Beard, R.W., Decentralized scheme for spacecraft formation flying via the virtual structure approach (2004) Journal of Guidance, Control and Dynamics, 27 (1), pp. 73-82; Rivest, L.P., A directional model fo the statistical analysis of movement in three dimensions (2001) Biometrika, 88 (3), pp. 779-791; Ruiz-Carrion, I., Gifford, C.M., Detailed modeling of designs for the polar seismic TETwalker (2007) Tech. Rep. CReSIS-TR-132; Ruppert, D., Wand, M.P., Multivariate locally weighted least squares regression (1994) The Annals of Statistics, 22 (3), pp. 1346-1370; Sandhu, J., Mesbahi, M., Tsukamaki, T., Relative sensing networks: Observability, estimation, and the control structure (2005) Proceedings of the IEEE Conference on Decision and Control, pp. 6400-6405; Santello, M., Flanders, M., Soechting, J.F., Postural hand synergies for tool use (1998) Journal of Neuroscience, 18 (23), pp. 10105-10115; Scassellati, B., How social robots will help us to diagnose, treat, and understand autism (2005) 12th International Symposium of Robotics Research; Scharf, D., Acikmese, B., Ploen, S., Hadaegh, F., A direct solution for fueloptimal reactive collision avoidance of collaborating spacecraft (2006) American Control Conference, pp. 5201-5206; Scharf, D., Hadaegh, F., Ploen, S., A survey of spacecraft formation flying guidance and control (part i): Guidance (2003) American Control Conference; Scharf, D., Hadaegh, F., Ploen, S., A survey of spacecraft formation flying guidance and control (part ii): Control (2004) American Control Conference, p. 153; Scḧolkopf, B., Smola, A., (2002) Learning with Kernels, , MIT Press, Cambridge, MA, USA; Schwaighofer, A., Tresp, V., Yu, K., Learning Gaussian process kernels via hierarchical Bayes (2005) Advances in Neural Information Processing Systems, 17, pp. 1209-1216. , L. Saul, Y.Weiss, L. Bottou (eds.). MIT Press, Cambridge, MA, USA; Sen, V., Stoffa, P.L., Dalziel, I.W.D., Blankenship, D.D., Smith, A.M., Anandakrishnan, S., Seismic surveys in central west Antarctica: Data processing examples from the ANTALITH field tests (1999) Terra Antarctica, 5 (4), pp. 761-772; Sethares, W.A., Staley, T.W., Periodicity transforms (1999) IEEE Trans. on Signal Processing, pp. 2953-2964; Simmons, R.G., Apfelbaum, D., Burgard, W., Fox, D., Moors, M., Thrun, S., Younes, H., Coordination for multi-robot exploration and mapping (2000) AAAI, pp. 852-858; Singh, A., Krause, A., Guestrin, C., Kaiser, W., Batalin, M., Efficient planning of informative paths for multiple robots (2007) Proceedings of the International Joint Conference on Artificial Intelligence, pp. 2204-2211; Singh, G., Hadaegh, F., Collision avoidance guidance for formation-flying applications (2001) AIAA Guidance, Navigation and Control Conference; Smith, R., A distributed parallel estimation architecture for cooperative vehicle control (2006) American Control Conference, pp. 4219-4224; Smith, R., Hadaegh, F., Control of deep space formation flying spacecraft: Relative sensing and switched information (2005) AIAA Journal of Guidance, Control and Dynamics; Smith, R., Hadaegh, F., Closed-loop dynamics of cooperative vehicle formations with parallel estimators and communication (2007) IEEE Transactions on Automatic Control, 52 (8), pp. 1404-1414; Smith, R.S., Distributed estimation, communication and control for deep space formations (2007) IET Control Theory and Application, Special Issue on Cooperative Control of Multiple Spacecraft Flying in Formation, 1 (2), pp. 445-451; Speece, M.A., Miller, C.R., Miller, P.F., Link, C.A., Flynn, K.F., Dolena, T.M., A rapid-deployment three dimensional (3-D) seismic reflection system (2004) Montana Tech. Prototype Design Proposal; Spikes, K., Steeples, D., Ralston, M., Blair, J., Tian, G., (2001) Common Midpoint Seismic Reflection Data Recorded with Automatically Planted Geophones, , http://www.dot.ca.gov/hq/esc/geotech/gg/geophysics2002/ 037spikes_cmp_auto_plants.pdf; Stansbury, R.S., Akers, E.L., Harmon, H.P., Agah, A., Survivability, mobility, and functionality of a rover for radars in polar regions (2004) International Journal of Control, Automation, and Systems, 2 (3), pp. 334-353; Stroupe, A.W., Ravichandran, R., Balch, T., Value-based action selection for exploration and dynamic target observation with robot teams (2004) Proceedings of the IEEE International Conference on Robotics and Automation, pp. 4190-4197; Sukhatme, G.S., Dhariwal, A., Zhang, B., Oberg, C., Stauffer, B., Caron, D.A., The design and development of a wireless robotic networked aquatic microbial observing system (2006) Environmental Engineering Science, 24 (2), pp. 205-215; Swaroop, D., Hedrick, J., String stability of interconnected systems (1996) IEEE Transactions on Automatic Control, 41 (3), pp. 349-357; Taga, G., A model of the neuro-musculo-skeletal system for human locomotion. I. Emergence of basic gait (1995) Biological Cybernetics, 73, pp. 97-111; Taga, G., A model of the neuro-musculo-skeletal system for human locomotion. ii. real-time adaptability under various constraints (1995) Biological Cybernetics, 73, pp. 113-121; Taga, G., A model of the neuro-musculo-skeletal system for anticipatory adjus tment of human locomotion during obstacle avoidance (1998) Biological Cybernetics, 78, pp. 9-17; Taga, G., Yamaguchi, Y., Shimizu, H., Self-organized control of bipedal locomotion by neural oscillators in unpredictable environment (1991) Biol. Cybern., 65, pp. 147-159; (2005) RangeRunner by TerraTrack, , http://www.terratrack.com; Thrun, S., Is learning the n-th thing any easier than learning the first? (1996) Advances in Neural Information Processing Systems, 8, pp. 640-646. , D. Touretzky, M. Mozer, M. Hasselmo (eds.). MIT Press; Thrun, S., Burgard, W., Fox, D., (2005) Probabilistic Robotics, , MIT Press; Tien, J., Purcell, G., Amaro, L., Young, L., Aung M, M., Srinivasan, J., Archer, E., Chong, Y., Technology validation of the autonomous formation flying sensor for precision formation flying (2003) Aerospace Conference Proceedings, 1, pp. 1-140. , IEEE; Tokuda, Y., Iwasaki, S., Sato, Y., Nakanishi, Y., Koike, H., Ubiquitous display for dynamically changing environments Proc. of CHI; (2008) Legacy GPS+ Receiver, , http://www.topconeurope.com/index.asp?pageid= 12166e1461284b7ca5e68c4f0257448d; Tsoflias, G.P., Steeples, D.W., Czarnecki, G.P., Sloan, S.D., Eslick, R.C., Automatic deployment of a 2-D geophone array for efficient ultra-shallow seismic imaging (2006) Geophysical Research Letters; Van Der Veen, M., Green, A., Land streamer for shallow seismic data acquisition: Evaluation of gimbal-mounted geophones (1998) Geophysics, 63, pp. 1408-1413; Van Der Veen, M., Wild, P., Spitzer, R., Green, A., Design characteristics of a seismic land streamer for shallow data acquisition (1999) Extended Abstracts of the 61st European Association of Geoscientists and Engineers Conference and Technical Exhibition, pp. 40-41; Vapnik, V., (1998) Statistical Learning Theory, , Wiley, New York, NY, USA; Vidyasagar, M., (1993) Nonlinear System Analysis, , 2nd edn. Prentice-Hall, Inc., Englewood Cliffs, NJ; Vijayakumar, S., D'souza, A., Schaal, S., Incremental online learning in high dimensions (2005) Neural Computation, 17 (12), pp. 2602-2634; Vijayakumar, S., D'souza, A., Shibata, T., Conradt, J., Schaal, S., Statistical learning for humanoid robots (2002) Autonomous Robots, 12 (1), pp. 55-69; Vijayakumar, S., Schaal, S., Locally weighted projection regression: An o(n) algorithm for incremental real time learning in high dimensional space (2000) Proceedings of the Seventeenth International Conference on Machine Learning, pp. 1079-1086. , Stanford, CA, USA; Vogt, F., Wong, J., Fels, S., Cavens, D., Tracking multiple laser pointers for large screen interaction (2003) Proc. of UIST; Wade, U.B., Gifford, C.M., Investigation of power sources for the polar seismic TETwalker (2007) Tech. Rep. CReSIS-TR-133; Wakiji, E., Mapping the literature of physical therapy (1997) Bull Med Libr Assoc., 85, pp. 284-288; Wang, D., (2007) A 3D Feature-based Object Recognition System for Grasping, , Master's thesis, School of Computer Science, University of Oklahoma, Norman, OK; Wang, D., Watson, B.T., Fagg, A.H., A switching control approach to haptic exploration for quality grasps (2007) Proceedings of the Workshop on Robot Manipulation: Sensing and Adapting to the RealWorld at the 2007 Robotics: Science and Systems Conference, , Electronically published; Webb, B., Can robots make good models of biological behavior? (2001) Behav. Brain Sci, pp. 1033-1050; (2001) International Classification of Functioning, Disability and Health, , WHO: World Health Organization; Willett, R., Martin, A., Nowak, R., Backcasting: Adaptive sampling for sensor networks (2004) Proceedings of the Third International Symposium on Information Processing in Sensor Networks, pp. 124-133; Woronowicz, M., Selected afternoon constellation transient plume impingement model results 3rd International Symposium on Formation Flying Missions &amp; Technologies, , Noordwijk, The Netherlands; (2005) Xilinx: Virtex-II Pro FPGAs, , http://www.xilinx.com/products/silicon_solutions/fpgas/virtex/ virtex_ii_pro_fpgas/index.htm; Yanofsky, P., (2005) President Wowwee Robotics, , personal communication; Yeung, D., (1989) Handling Dimensionality and Nonlinearity in Connectionist Learning, , Ph.D. thesis, Department of Computer Science, University of Southern California, Los Angeles, California, USA; Yeung, D., Bekey, G., Using a context-sensitive learning network for robot arm control (1989) Proceedings of the IEEE International Conference on Robotics and Automation, pp. 1441-1447; Yu, K., Chu, W., Gaussian process models for link analysis and transfer learning (2008) Advances in Neural Information Processing Systems, 20, pp. 1657-1664. , J. Platt, D. Koller, Y. Singer, S. Roweis (eds.), MIT Press, Cambridge, MA, USA; Yu, K., Tresp, V., Schwaighofer, A., Learning Gaussian processes from multiple tasks (2005) Proceedings of the Twenty-Second International Conference on Machine Learning, pp. 1012-1019. , Bonn, Germany; Zhang, B., Sukhatme, G.S., Adaptive sampling for estimaing a scalar field using a mobile robot and a sensor network (2007) IEEE International Conference on Robotics and Automation, pp. 3673-3680; Zlot, R., Stentz, A., Dias, M.B., Thayer, S., Multi-robot exploration controlled by a market economy (2002) Proceedings of the IEEE International Conference on Robotics and Automation},
document_type={Book},
source={Scopus},
}

@ARTICLE{Arkin200851,
author={Arkin, R.C.},
title={Governing lethal behavior: Embedding ethics in a hybrid deliberative/reactive robot architecture: Part 2: Formalization for ethical control},
journal={Frontiers in Artificial Intelligence and Applications},
year={2008},
volume={171},
number={1},
pages={51-62},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875942608&partnerID=40&md5=d8e30938846476466c33657bd70dea7a},
abstract={This paper, the second in a series, provides the theory and formalisms for the implementation of an ethical control and reasoning system potentially suitable for constraining lethal actions in an autonomous robotic system. so that they fall within the bounds prescribed by the Laws of War and Rules of Engagement. It is based upon extensions to existing deliberative/reactive autonomous robotic architectures. © 2008 The authors and IOS Press. All rights reserved.},
author_keywords={Autonomous systems;  Machine ethics;  Unmanned vehicles},
keywords={Philosophical aspects;  Unmanned vehicles, Autonomous robotic systems;  Autonomous robotics;  Autonomous systems;  Reasoning system;  Robot architecture;  Rules of engagements, Robotics},
references={Governing lethal behavior: Embedding ethics in a hybrid deliberative/reactive robot architecture-Part 1: Motivation and philosophy (2008) Proc. HRI, , Amsterdam, NL; Walzer, M., (1977) Just and Unjust Wars, , 4th Ed. Basic Books; (2007) Governing Lethal Behavior: Embedding Ethics in A Hybrid Deliberative/Reactive Robot Architecture, , GVU Technical Report, GIT-GVU-07-11, Georgia Tech; Arkin, R.C., (1998) Behavior-based Robotics, , MIT Press; MacKenzie, D., Arkin, R.C., Cameron, J., Multiagent mission specification and execution" (1997) Autonomous Robots, 4 (1), pp. 29-57. , Jan. 1997; Balch, T., Arkin, R.C., Behavior-based formation control for multi-robot teams (1998) IEEE Transactions on Robotics and Automation, 14 (6), pp. 926-939. , December; Arkin, R.C., Collins, T.R., Endo, T., Tactical mobile robot mission specification and execution (1999) Mobile Robots XIV, pp. 150-163. , Boston, MA, Sept. 1999; Collins, T.R., Arkin, R.C., Cramer, M.J., Endo, Y., Field results for tactical mobile robot missions (2000) Unmanned Systems 2000, , Orlando, FL, July; Wagner, A., Arkin, R.C., Multi-robot communication-sensitive reconnaissance (2004) Proc. 2004 IEEE International Conference on Robotics and Automation, , New Orleans; Gibson, J.J., (1979) The Ecological Approach to Visual Perception, , Houghton Mifflin, Boston, MA; Horty, J., (2000) Agency and Deontic Logic, , Oxford University Press; Moshkina, L., Arkin, R.C., On TAMeing robots (2003) Proc. 2003 IEEE International Conference on Systems, Man and Cybernetics, , Washington, D.C., October},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Anderson20071,
author={Anderson, S.L. and Anderson, M.},
title={The consequences for human beings of creating ethical robots},
journal={AAAI Workshop - Technical Report},
year={2007},
volume={WS-07-07},
pages={1-4},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-51849086264&partnerID=40&md5=71f5d39e9e98fc8ad7bb4275edf3b6d7},
abstract={We consider the consequences for human beings of attempting to create ethical robots, a goal of the new field of AI that has been called Machine Ethics. We argue that the concerns that have been raised are either unfounded, or can be minimized, and that many benefits for human beings can come from this research. In particular, working on machine ethics will force us to clarify what it means to behave ethically and thus advance the study of Ethical Theory. Also, this research will help to ensure ethically acceptable behavior from artificially intelligent agents, permitting a wider range of applications that benefit human beings. Finally, it is possible that this research could lead to the creation of ideal ethical decision-makers who might be able to teach us all how to behave more ethically.},
keywords={Decision-makers;  Human beings;  Human-robot interaction;  Machine ethics;  Technical reports;  Wider range, Artificial intelligence;  Computer software;  Intelligent agents;  Philosophical aspects;  Robots, Robotics},
references={Anderson, S.L., Asimov's 'Three Laws of Robotics' and Machine Metaethics (2007) AI & Society: Journal of Human-Centered Systems and Machine Intelligence, , Special Issue on Ethics and Artificial Intelligence; Anderson, S. L., 1995. Being Held Morally Responsible for an Action versus Acting Responsibly/ Irresponsibly, Journal of Philosophical Research; (2006) IEEE Intelligent Systems Special Issue on Machine Ethics, 21 (4). , Anderson, M. and Anderson, S. L, eds, July/August; Beauchamp, T.L., Childress, J.F., (1979) Principles of Biomedical Ethics, , Oxford University Press; Hall, J, S., 2007. Chapter 20, The Age of Virtuous Machines, in Beyond AI: Creating the Conscience of the Machine, Prometheus Books; Moor, J.H., The Nature, Importance, and Difficulty of Machine Ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21. , July/August; Reagan, T., (1983) The Case for Animal Rights, , University of California Press},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Guarini200727,
author={Guarini, M.},
title={Computation, coherence, and ethical reasoning},
journal={Minds and Machines},
year={2007},
volume={17},
number={1},
pages={27-46},
doi={10.1007/s11023-007-9056-4},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547282544&doi=10.1007%2fs11023-007-9056-4&partnerID=40&md5=424862d565f27cea5508af7cb6ac838e},
abstract={Theories of moral, and more generally, practical reasoning sometimes draw on the notion of coherence. Admirably, Paul Thagard has attempted to give a computationally detailed account of the kind of coherence involved in practical reasoning, claiming that it will help overcome problems in foundationalist approaches to ethics. The arguments herein rebut the alleged role of coherence in practical reasoning endorsed by Thagard. While there are some general lessons to be learned from the preceding, no attempt is made to argue against all forms of coherence in all contexts. Nor is the usefulness of computational modelling called into question. The point will be that coherence cannot be as useful in understanding moral reasoning as coherentists may think. This result has clear implications for the future of Machine Ethics, a newly emerging subfield of AI. © 2007 Springer Science+Business Media.},
author_keywords={Coherentism;  Ethical reasoning;  Foundationalism;  Machine ethics;  Practical reasoning;  Robot ethics;  Underdetermination;  Unsupervised neural network},
keywords={Artificial intelligence;  Computational methods;  Computer simulation;  Learning systems;  Robots, Coherentism;  Ethical reasoning;  Foundationalism;  Machine ethics;  Practical reasoning;  Robot ethics;  Underdetermination;  Unsupervised neural network, Formal logic},
references={Bonjour, L., (1985) The structure of empirical knowledge, , Cambridge, MA: Harvard University Press; Guarini, M., Boulos, P., Can ECHO support TEC? (2005) Proceedings of the 2005 International Conference on Artificial Intelligence, 2, pp. 676-681. , H. R. Arabnia & R. Joshua Eds, Las Vegas: CSREA Press; Guarini, M., Boulos, P., Problems with simplicity and analogy in ECHO and TEC (2005) Computing, philosophy, and cognition, pp. 99-112. , L. Magnani & R. Dossena Eds, London: College Publications; Hare, R.M., (1981) Moral thinking: Its levels, methods, and point, , Oxford: Clarendon Press; Holyoak, K., Thagard, P., (1995) Mental leaps: Analogy in creative thought, , Cambridge, MA: MIT Press; Millgram, E., Coherence: The price of the ticket (2000) The Journal of Philosophy, XCVII, 2, pp. 82-93; Millgram, E., Thagard, P., Deliberative coherence (1996) Synthese, 108 (1), pp. 63-88; Nowak, G., & Thagard, P. (1992a). Copernicus, Ptolemy, and explanatory coherence. In R. N. Giere (Ed.), Minnesota studies in the philosophy of science, 15: Cognitive models of science (pp. 271-309). Minneapolis: University of Minnesota Press; Nowak, G., Thagard, P., Newton, Descartes, and explanatory coherence (1992) Philosophy of science, cognitive science, and educational theory and practice, pp. 69-115. , R. A. Duschl & R. J. Hamilton Eds, Albany: SUNY Press; Sosa, E., Reflective knowledge in the best circles (1997) The Journal of Philosophy XCIV, 8, pp. 410-430; Thagard, P., Ethical coherence (1998) Philosophical Psychology, 11, pp. 405-422; Thagard, P. (1992a). Computing coherence. In R. N. Giere (Ed.), Minnesota studies in the philosophy of science, 15: Cognitive models of science (pp. 485-488). Minneapolis: University of Minnesota Press; Thagard, P., (1992) Conceptual revolutions, , Princeton, NJ: Princeton University Press; Thagard, P., (2000) Coherence in thought and action, , Cambridge, Massachusetts: MIT Press; Thagard, P., Millgram, E., Inference to the best plan: A coherence theory of decision (1995) Goal-driven learning, pp. 439-454. , D. Leake & A. Ram Eds, Cambridge, MA: MIT Press},
document_type={Article},
source={Scopus},
}

@ARTICLE{Rieder2020120,
author={Rieder, T.N. and Hutler, B. and Mathews, D.J.H.},
title={Artificial Intelligence in Service of Human Needs: Pragmatic First Steps Toward an Ethics for Semi-Autonomous Agents},
journal={AJOB Neuroscience},
year={2020},
volume={11},
number={2},
pages={120-127},
doi={10.1080/21507740.2020.1740354},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082791478&doi=10.1080%2f21507740.2020.1740354&partnerID=40&md5=95ba678e79a2ab668cec6df8ab39eb7f},
abstract={The ethics of robots and artificial intelligence (AI) typically centers on “giving ethics” to as-yet imaginary AI with human-levels of autonomy in order to protect us from their potentially destructive power. It is often assumed that to do that, we should program AI with the true moral theory (whatever that might be), much as we teach morality to our children. This paper argues that the focus on AI with human-level autonomy is misguided. The robots and AI that we have now and in the near future are “semi-autonomous” in that their ability to make choices and to act is limited across a number of dimensions. Further, it may be morally problematic to create AI with human-level autonomy, even if it becomes possible. As such, any useful approach to AI ethics should begin with a theory of giving ethics to semi-autonomous agents (SAAs). In this paper, we work toward such a theory by evaluating our obligations to and for “natural” SAAs, including nonhuman animals and humans with developing and diminished capacities. Drawing on research in neuroscience, bioethics, and philosophy, we identify the ways in which AI semi-autonomy differs from semi-autonomy in humans and nonhuman animals. We conclude on the basis of these comparisons that when giving ethics to SAAs, we should focus on principles and restrictions that protect human interests, but that we can only permissibly maintain this approach so long as we do not aim at developing technology with human-level autonomy. © 2020, © 2020 Taylor & Francis Group, LLC.},
author_keywords={Agency;  AI;  artificial intelligence;  autonomy;  machine ethics;  neuroethics},
keywords={article;  artificial intelligence;  bioethics;  controlled study;  drawing;  human;  human experiment;  human needs;  neuroscience;  robotics},
references={Anderson, M., Anderson, S.L., (2011) Machine ethics, , Cambridge: Cambridge University Press; Asimov, I., (1950) Runaround. I, Robot., , New York: Doubleday; Beauchamp, T.L., Childress, J.F., (2012) Principles of biomedical ethics, , 7th ed, New York: Oxford University Press; Bekey, G.A., Current trends in in robotics: Technology and ethics (2012) Robot ethics: The ethical and social implications of Robotics, , Lin P., Abney K., Bekey G.A., (eds), Cambridge, MA: The MIT Press,. ed; Bostrom, N., (2014) Superintelligence: Paths, dangers, strategies, , New York: Oxford University Press; Bratman, M.E., Autonomy and hierarchy (2003) Social Philosophy and Policy, 20 (2), pp. 156-176; Buss, S., Westlund, A., (2018), http://plato.stanford.edu/entries/personal-autonomy, Personal autonomy., Stanford Encyclopedia of Philosophy; Carse, A., Bok, H., Mathews, D.J.H., Free will, self-governance and neuroscience: An overview (2018) Neuroethics, 11 (3), pp. 237-244; Francis, L.P., Understanding autonomy in light of intellectual disability (2009) Disability and disadvantage, pp. 200-215. , Brownlee K., Cureton A., (eds), Oxford, UK: Oxford University Press,. ed; Grandin, T., Deesing, M.J., Behavioral genetics and animal science (2014) Genetics and the behavior of domestic animals, pp. 1-40. , Grandin T., Deesing M.J., (eds), 2nd ed, London, UK: Academic Press, and; Gunkel, D.J., The other question: Can and should robots have rights? (2018) Ethics and Information Technology, 20 (2), pp. 87-99; Jaworska, A., Respecting the margins of agency: Alzheimer’s patients and the capacity to value (1999) Philosophy & Public Affairs, 28 (2), pp. 105-138; Johnson, L.S.M., Neuroethics of the nonhuman (2019) The American Journal of Bioethics Neuroscience, 10 (3), pp. 111-113; Kant, I., (1785) Groundwork of the metaphysics of morals, , Gregor M., (ed), Cambridge, UK: Cambridge University Press, /2012., trans. and ed.]; Korsgaard, C.M., (1996) The sources of normativity, , Cambridge UK: Cambridge University Press; Korsgaard, C.M., (2018) Fellow creatures: Our obligations to the other animals, , Oxford, UK: Oxford University Press; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Nussbaum, M.C., (2009) Frontiers of justice: Disability, nationality, species membership, , Cambridge, MA: Harvard University Press; Osvath, M., Osvath, H., Chimpanzee (Pan troglodytes) and orangutan (Pongo abelii) forethought: self-control and pre-experience in the face of future tool use (2008) Animal Cognition, 11 (4), pp. 661-674; Ripstein, A., (1998) Equality, responsibility, and the law, , Cambridge, UK: Cambridge University Press; Roskies, A.L., Decision-making and self-governing systems (2018) Neuroethics, 11 (3), pp. 245-257; Silver, D., Hubert, T., Schrittwieser, J., Antonoglou, I., Lai, M., Guez, A., Lanctot, M., Hassabis, D., (2017), Mastering chess and Shogi by self-play with a general reinforcement learning algorithm; Stuphorn, V., Schall, J.D., Neuronal control and monitoring of initiation of movements (2002) Muscle & Nerve, 26 (3), pp. 326-339; Tasioulas, J., First steps towards an ethics of robots and artificial intelligence (2019) Journal of Practical Ethics, 7 (1), pp. 49-83; Teichmann, M., Daigmorte, C., Funkiewiez, A., Moral emotions in frontotemporal dementia (2019) Journal of Alzheimer's Disease, 69 (3), pp. 887-896},
document_type={Article},
source={Scopus},
}

@ARTICLE{Tafani202081,
author={Tafani, D.},
title={On artificial morality. Machine decisions between ethics and right [Sulla moralità artificiale Le decisioni delle macchine tra etica e diritto]},
journal={Rivista di Filosofia},
year={2020},
volume={111},
number={1},
pages={81-103},
doi={10.1413/96338},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083581038&doi=10.1413%2f96338&partnerID=40&md5=f52d82ac6df25376087829361c8e8ff0},
abstract={In the contemporary debate on artificial morality, the trolley problem has found a new field of application, in the “ethics of crashes” with self-driving cars. The paper aims to show that the trolley dilemma is out of place, the context of automated traffic, not only with regard to the object of the dilemma (which human being should be sacrificed, in crashes with inevitable fatal consequences), but also with regard to the subject to whom it is up to decide. In States whose constitutional charters protect fundamental individual rights, laws have definite constraints on solving dilemmas regarding self-driving cars. The idea that crashes of self-driving cars raises extraordinary moral questions, rather than safety, transparency, caution and control issues, as any other machine, derives perhaps from the human inclination to consider anthropomorphic objects as agents, or even as moral agents. The development of autonomous machines can lead to believe that three crowdsourcing and subrogation operations, variously intertwined, are possible and allowed: of law with ethics, in the first place; of moral evaluation, secondly, with a computational model of aggregated social preferences and, finally, of human moral agency with the autonomous, unpredictable and opaque functioning of machines. © 2020 Societa Editrice il Mulino. All rights reserved.},
author_keywords={Artificial Morality;  Ethics of Crashes;  Machine Ethics;  Moral Machines;  Self-Driving Cars;  Trolley Problem},
references={Brown, J.R., Fehige, Y., Stuart, M., Per un quadro delle tesi alternative su cosa sia, e a cosa possa servire, un esperimento di pensiero (2018) Routledge Companion to Thought Experiments, pp. 195-210. , cfr. a cura di Abingdon/New York, Routledge, e in particolare il contributo di G. Brun, Thought Experiments in Ethics; Dennett, D.C., (2013) Intuition Pumps and Other Tools for Thinking, pp. 2-3. , Cfr. New York, London, Norton & Company; (2014) S. Frediani Con Il Titolo Strumenti Per Pensare, p. 3. , trad. it. a cura di Milano, Cortina; Anderson, M., Anderson, S.L., (2011) L'Etica Delle Macchine «Si Occupa Di Dare Alle Macchine Principi Etici O Una Procedura Per Scoprire Un Modo Di Risolvere I Dilemmi Etici in Cui Potrebbero Imbattersi, p. 1. , consentendo loro di operare in modo eticamente responsabile attraverso il proprio processo decisionale etico» Machine Ethics, a cura di e Cambridge, Cambridge University Press; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Cfr. anche Oxford, Oxford University Press; Foot, P., The problem of abortion and the doctrine of the double effect (1967) Oxford Review, pp. 5-15; D'Aquino, T., (2014) La Somma Teologica, 3, pp. 650-651. , trad. it. a cura dei Frati Domenicani, Bologna, Edizioni Studio Domenicano, IIa IIæ, Q. 64, A. 8; Foot, P., The Problem of Abortion and the Doctrine of the Double Effect, p. 8. , cit; Salmond, J., (1989) Historisches Wörterbuch Der Philosophie, 7, pp. 433-439. , Foot rimandava alla formulazione di Jurisprudence, London, Sweet & Maxwell, 11a ed. 1957, senza ricordare che la tesi della priorità dei doveri negativi su quelli positivi era stata sostenuta, ad esempio, da Kant, quale priorità dei doveri di giustizia, detti anche perfetti o essenziali, sui doveri di bontà, imperfetti o accidentali; cfr. W. Kersting, voce «Pflichten, unvollkommene/vollkommene», in a cura di K. Gründer, Basel/Stuttgart, coll; Thomson, J.J., Killing, letting die and the trolley problem (1976) The Monist, 59, pp. 204-217; Kamm, F.M., (2016) The Trolley Problem Mysteries, Con Commenti Di, , Cfr. J.J. Thomson, T. Hurka, S. Kagan, a cura di E. Rakowski, New York, Oxford University Press; Edmonds, D., (2013) Would You Kill the Fat Man? The Trolley Problem and What Your Answer Tells Us about Right and Wrong, , un'introduzione divulgativa in Princeton, Princeton University Press; Guerrerio, G., (2014) Con Il Titolo Uccideresti l'Uomo Grasso? Il Dilemma Etico Del Male Minore, , trad. it. a cura di Milano, Cortina; Greene, J.D., Solving the trolley problem (2016) A Companion to Experimental Philosophy, pp. 175-189. , Cfr. a cura di J. Sytsma e W. Buckwalter, Chichester, Wiley-Blackwell; Beyond point-and-shoot morality: Why cognitive (neuro) science matters for ethics (2014) Ethics, 124, pp. 695-726. , Id; https://archive.org/details/SafestPl1935, ultimo accesso, a questo e agli altri indirizzi web citati nel presente articolo, il 13 dicembre 2019; Kröger, F., Automated driving in its social, historical and cultural contexts (2016) Autonomous Driving. Technical, Legal and Social Aspects, pp. 41-68. , a cura di M. Maurer, J. Gerdes, B. Lenz, H. Winner, Berlin/Heidelberg, Springer; Cui la Guida È Interamente Automatizzata e l'Occupante Umano Della Vettura È Un Mero Passeggero, , https://www.sae.org/standards/content/j3016_201806/, L'autonomia dei veicoli è stata classificata dalla Society of Automotive Engineers in sei livelli, dal livello 0, in cui è il conducente umano a svolgere tutte le operazioni di guida, al livello 5, in; Agenzia Del Dipartimento Dei Trasporti Statunitense, , https://www.nhtsa.gov/technology-innovation/automated-vehicles-safety, Cfr; Bertoncello, M., Wee, D., Ten ways autonomous driving could redefine the automotive world McKinsey&Company, , https://www.mckinsey.com/industries/automotive-and-assembly/our-insights/ten-ways-autonomous-driving-could-redefine-the-automotive-world, anche; Misselhorn, C., (2018) Grundfragen Der Machinenethik, pp. 198-200. , Tematizza invece la questione Ditzingen, Reclam; Operto, V.F., Elementi di roboetica. Analisi di alcune metaetiche nella progettazione e programmazione di veicoli autonomi (2018) InCircolo, 6, pp. 89-108. , 98; Il Resoconto Di Tesla, l'Azienda Produttrice Del Veicolo Coinvolto Nell'Incidente, , https://www.tesla.com/it_IT/blog/tragic-loss, Cfr; Lin, P., Why ethics matters for autonomous cars Autonomous Driving, pp. 69-85. , Cfr. ad esempio, tra gli innumerevoli articoli comparsi in meno di un decennio, cit; Keeling, G., Why trolley problems matter for the ethics of automated vehicles Science and Engineering Ethics, 26 (2020), pp. 293-307; Nyholm, S., The ethics of crashes with self-driving cars: A roadmap, I e II (2018) Philosophy Compass, 13 (7). , https://onlinelibrary.wiley.com/doi/epdf/10.1111/phc3.12507e/phc3.12506, Un'utile ricognizione in; Bonnefon, J.-F., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2016) Science», CCCLII, 6293, pp. 1573-1576; Lin, P., Why Ethics Matters for Autonomous Cars, pp. 69-70. , cit; http://moralmachine.mit.edu; Awad, E., Dsouza, S., Kim, R., Schulz, J., Henrich, J., Shariff, A., Bonnefon, J.-F., Rahwan, I., The Moral Machine experiment (2018) Nature, 563, pp. 59-64; Noothigattu, R., Gaikwad, S.S., Awad, E., Dsouza, S., Rahwan, I., Ravikumar, P., Procaccia, A.D., (2017) A Voting-Based System for Ethical Decision Making, , https://arxiv.org/pdf/1709.06692.pdf; Greene, J., Rossi, F., Tasioulas, J., Venable, K.B., Williams, B.C., Embedding ethical principles in collective decision support systems (2016) Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence and the Twenty-Eighth Innovative Applications of Artificial Intelligence Conference, 6, pp. 4147-4151. , L'idea che la scelta sociale computazionale, ossia l'utilizzo di algoritmi per aggregare le preferenze individuali, possa fornire gli strumenti per giungere a decisioni etiche collettive, è tratta da a cura di D. Schuurmans, M. Wellmam, Phoenix, AAAI; Awad, E., The Moral Machine Experiment, p. 59. , cit; Noothigattu, R., A Voting-Based System for Ethical Decision Making, , cit; Sütfeld, L.R., Gast, R., König, P., Pipa, G., Using Virtual, , Cfr; Reality to assess ethical decisions in road traffic scenarios: Applicability of value-of-life-based models and influences of time pressure (2017) Frontiers in Behavioral Neuroscience, 11. , https://www.frontiersin.org/articles/10.3389/fnbeh.2017.00122/full; Lin, P., Why Ethics Matters for Autonomous Cars, p. 70. , cit; Sütfeld, L.R., Using Virtual Reality to Assess Ethical Decisions in Road Traffic Scenarios, p. 5. , Lo propongono cit; Leben, D., (2019) Utilizzando Proprietà Sociali Come Criteri Per I Giudizi Morali, l'Esperimento Del MIT Esamina I Pregiudizi Discriminatori Delle Persone, Più Che Il Loro Giudizio Morale Ethics for Robots. How to Design a Moral Algorithm, p. 112. , osserva che, London/New York, Routledge; Ethik-Kommission, (2017) Automatisiertes und Vernetztes Fahren. Eingesetzt Durch Den Bundesminister Für Verkehr und Digitale Infrastruktur, p. 11. , https://www.bmvi.de/SharedDocs/DE/Publikationen/DG/bericht-der-ethik-kommission.html, Bericht, Juni; (2006) Urteil Des Ersten Senats Vom 15, , http://www.bverfg.de/e/rs20060215_1bvr035705.html, Februar - 1 BvR 357/05 - Rn. 1-156; (1900) Kant's Gesammelte Schriften, a Cura Dell'Accademia Prussiana Delle Scienze, 4, p. 429. , Berlin, de Gruyter, ss; Chiodi, P., Con il titolo Fondazione della metafisica dei costumi (1970) Scritti Morali, p. 88. , trad. it. a cura di I. Kant, Torino, Utet, Agisci in modo da trattare l'umanità, sia nella tua persona sia in quella di ogni altro, sempre anche come fine e mai semplicemente come mezzo; Loh, W., Loh, J., Autonomy and responsibility in hybrid systems. The example of autonomous cars (2017) Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence, pp. 35-50. , a cura di Lin, K. Abney and R. Jenkins, New York, Oxford University Press, 46; Millar, J., Ethics settings for autonomous vehicles Robot Ethics, 2, pp. 20-34. , anche. 0, cit; Lin, C.P., Here's a terrible idea: Robot cars with adjustable ethics settings (2014) Wired, , https://www.wired.com/2014/08/heresa-terrible-idea-robot-cars-with-adjustable-ethics-settings; Contissa, G., Lagioia, F., Sartor, G., The ethical knob: Ethically customisable automated vehicles and the law (2017) Artificial Intelligence and Law, 25 (3), pp. 365-378. , Iid., La manopola etica: i veicoli autonomi eticamente personalizzabili e il diritto, «Sistemi intelligenti», III, 2017, 601-14; Santoni De Sio, F., Killing by autonomous vehicles and the legal doctrine of necessity (2017) Ethical Theory and Moral Practice, 20, pp. 411-429. , Cfr., sul tema; Nyholm, S., Smids, J., The ethics of accident-algorithms for self-driving cars: An applied trolley problem? (2016) Ethical Theory and Moral Practice, 19, pp. 1275-1289. , sulla differenza radicale tra una decisione assunta da un singolo individuo in una situazione d'emergenza e una decisione assunta da vari portatori di interessi su come programmare un certo tipo di tecnologia a rispondere alle situazioni che potrebbero verificarsi; Ethik-Kommission, Automatisiertes und Vernetztes Fahren, p. 11. , cit; Hübner, D., White, L., Crash algorithms for autonomous cars: How the trolley problem can move us beyond harm minimisation (2018) Ethical Theory and Moral Practice, 21, pp. 685-698. , sulla rilevanza della distinzione tra soggetti coinvolti e non, cfr; Etzioni, A., Etzioni, O., Incorporating ethics into artificial intelligence (2017) The Journal of Ethics, 21, pp. 403-418. , Cfr; Nyholm, V.S., Smids, J., The Ethics of Accident-Algorithms for Self-Driving Cars: An Applied Trolley Problem?, , cit; Etzioni, A., Etzioni, O., Incorporating ethics into artificial intelligence (2017) The Journal of Ethics, 21, pp. 403-418; Gogoll, N.J., Müller, J.F., Autonomous cars: In favor of a mandatory ethics setting (2017) Science and Engineering Ethics, 23, pp. 681-700; Johansson, V.R., Nilsson, J., Disarming the trolley problem - why self-driving cars do not need to choose whom to kill (2016) Workshop CARS 2016 - Critical Automotive Applications: Robustness & Safety, , https://hal.archives-ouvertes.fr/hal-01375606/document; Goodall, N.J., Away from trolleys and toward risk-management (2016) Applied Artificial Intelligence, 30 (8), pp. 810-821; Tamburrini, G., Autonomia delle macchine e filosofia dell'intelligenza artificiale (2017) Rivista Di Filosofia, 58, pp. 263-275. , Propone di prevedere una circolazione separata dei veicoli autonomi; Davnall, R., Solving the single-vehicle self-driving car trolley problem using risk theory and vehicle dynamics Science and Engineering Ethics, 26 (2020), pp. 431-449. , https://link.springer.com/content/pdf/10.1007/s11948-019-00102-6.pdf; Misselhorn, C., Grundfragen Der Machinenethik, , Cfr., oltre ai volumi citati più indietro, alla nota 3, l'ottimo contributo di cit; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds and Machines, 14, pp. 349-379; Misselhorn, C., Grundfragen Der Machinenethik, p. 14. , cit.,. 133; Johnson, D.G., Computer systems: Moral entities, but not moral agents Machine Ethics, pp. 168-183. , cit,. 183; Fossa, F., Fare e funzionare. Sull'analogia di robot e organismo (2018) InCircolo, 6, pp. 73-88. , Cfr; Moro, P., Libertà del robot? Sull'etica delle machine intelligenti (2015) Filosofia Del Diritto e Nuove Tecnologie. Prospettive Di Ricerca Tra Teoria e Pratica, pp. 525-544. , Cfr. a cura di R. Brighi, S. Zullo, Roma, Aracne; Nagel, T., What is it like to be a bat? (1974) The Philosophical Review, 58, pp. 435-450. , Sulla questione, non si può, qui, che limitarsi a rinviare a due testi classici; (2013) T. Falchi Con Il Titolo Che Cosa Si Prova Ad Essere Un Pipistrello, , trad. it. a cura di Roma, Castelvecchi; Searle, J.R., Minds, brains, and programs (1980) The Behavioral and Brain Sciences, 3, pp. 417-424; Tonfoni, G., (1984) Con Il Titolo Menti, Cervelli e Programmi: Un Dibattito Sull'Intelligenza Artificiale, , trad. it. a cura di Milano, CLUP - CLUED; Wallach, W., Allen, C., Moral Machines: Teaching Robots Right from Wrong, p. 66. , cit.,. la comprensione è talvolta equiparata alla coscienza - un altro termine con connotazioni magiche; Gunkel, D.J., Bryson, J.J., Torrance, S., (2012) The Machine Question: AI, Ethics and Moral Responsibility, , http://events.cs.bham.ac.uk/turing12/proceedings/14.pdf, Per una discussione a più voci sulla proposta di Floridi e Sanders, cfr. a cura di Birmingham; Brhdadi, D., Munthe, C., (2019) Artificial Moral Agency: Philosophical Assumptions, Methodological Challenges, and Normative Solutions, , https://www.researchgate.net/publication/311196481, Tra i contributi più recenti, of-frono una sintetica ricognizione delle alternative teoriche; Floridi, L., Sanders, J.W., On the Morality of Artificial Agents, , cit; Bryson, J., Kime, P., Just an artifact: Why machines are perceived as moral agents (2011) Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence, pp. 1641-1646. , a cura di T. Walsh, Menlo Park, AAAI Press, 1642: «la tendenza alla sovraidentificazione con le macchine deriva da una concezione errata della vita umana, che pone come sue caratteristiche chiave le facoltà del linguaggio, della matematica e della ragione; Damasio, A., (1994) Descartes' Error: Emotion, Reason and the Human Brain, , New York, Grosset/Putnam; Macaluso, F., (1995) L'Errore Di Cartesio. Emozione, Ragione e Cervello Umano, , trad. it. a cura di con il titolo Milano, Adelphi; (2018) The Strange Order of Things: Life, Feeling, and the Making of Cultures, , Id, New York, Pantheon; Ferraresi, S., (2018) Con Il Titolo Lo Strano Ordine Delle Cose, , trad. it. a cura di Milano, Adelphi; Shoham, Y., Perrault, R., Brynjolfsson, E., Clark, J., Manyika, J., Niebles, J.C., Lyons, T., Bauer, Z., (2018) The AI Index 2018 Annual Report, p. 64. , Stanford, Stanford University; Baron-Cohen, S., (2011) The Science of Evil: On Empathy and the Origins of Cruelty, , New York, Basic Books; Guerrerio, G., (2012) Con Il Titolo la Scienza Del Male: L'Empatia e le Origini Della Crudeltà, , trad. it. a cura di Milano, Cortina; Nowak-Juchacz, E., Das Anerkennungsprinzip bei Kant, Fichte und Hegel (2003) Fichte-Studien, 23, pp. 75-84. , Cfr., ad esempio; Floridi, L., Sanders, J.W., On the Morality of Artificial Agents, , cit; Baron-Cohen, S., La Scienza Del Male, pp. 1-5. , cit.,. collega la sua volontà di capire, da scienziato, «i fattori che inducono le persone a trattare gli altri come oggetti» a un episodio biografico: il racconto di una reale trasformazione di persone in oggetti quando aveva sette anni, il padre gli disse che i nazisti avevano trasformato gli ebrei in saponette; Henry, B., (2013) Dal Golem Ai Cyborgs: Trasmigrazioni Nell'Immaginario, , Cfr. Livorno, Belforte; Battaglia, F., Weidenfeld, N., (2015) Roboethics in Film, , a cura di Pisa, Pisa University Press; Battaglia, F., Macchine morali (2015) Scienza e Filosofia, 13, pp. 193-202; Weber, K., Autonomie und Moralität als Zuschreibung: Über die begriffliche und inhaltliche Sinnlosigkeit einer Maschinenethik (2019) Maschinenethik. Normative Grenzen Autonomer Systeme, pp. 193-208. , a cura di M. Rath, F. Krotz, M. Karmasin, Wiesbaden, Springer; Nell'ambito della «global initiative on ethics of autonomous and intelligent systems (2018) A Vision for Prioritizing Human Well-Being with Autonomous and Intelligent Systems, pp. 194-195. , https://standards.ieee.org/content/dam/ieee-standards/standards/web/documents/other/ead_v2.pdf, Una raccomandazione a includere nella discussione sull'etica dei sistemi autonomi e intelligenti una valutazione critica delle assunzioni antropomorfiche è contenuta nella seconda versione del documento sottoposto alla discussione pubblica dall'Institute of Electrical and Electronics Engineers IEEE, Ethically Aligned Design; Musiał, M., (2019) Enchanting Robots. Intimacy, Magic, and Technology, pp. 63-113. , Cfr. Cham, Palgrave Macmillan; Fossa, F., Creativity and the machine: How technology reshapes language (2017) ODRADEK. Studies in Philosophy of Literature, Aesthetics and New Media Theories, 3 (1-2), pp. 177-208; When computers decide: European recommendations on machine-learned automated decision making (2018) Informatics Europe & EUACM, p. 11. , https://www.acm.org/binaries/content/assets/public-policy/ie-euacmadm-report-2018.pdf; Sirgiovanni, E., Corbellini, G., IA e neuroetica: Evoluzione spontanea e valori morali, «Giornale italiano di psicologia (2018) Fascicolo, 1, pp. 147149-152149. , Cfr. marzo; Floridi, L., Cowls, J., Beltrametti, M., Chatila, R., Chazer, P., Dignum, V., Luetge, C., Vayena, E., AI4People - An ethical framework for a good AI society: Opportunities, risks, principles, and recommendations (2018) Minds and Machines, 28, pp. 689-707. , ad es; (2019) Ethics Guidelines for Trustworthy AI, p. 13. , https://ec.europa.eu/newsroom/dae/document.cfm?doc_id=60430; Comment permettre à l'homme de garder la main? (2017) Les Enjeux Éthiques Des Algorithmes et de l'Intelligence Artificielle, p. 51. , https://www.cnil.fr/sites/default/files/atoms/files/cnil_rapport_garder_la_main_web.pdf, Commission National Informatique & Libertés CNIL; Fabris, A., La filosofia e lo specchio delle macchine (2018) InCircolo, 6, pp. 28-38. , Cfr. 33; Fossa, F., Artificial moral agents: Moral mentors or sensible tools? (2018) Ethics and Information Technologies, 20, pp. 115-126. , Sull'alternativa tra la tesi della continuità e quella della discontinuità, tra agenti morali umani e artificiali, cfr; van Wynsberghe, A., Robbins, S., Critiquing the reasons for making artificial moral agents (2018) Science and Engineering Ethics, , https://doi.org/10.1007/s11948-018-0030-8, Cfr; Poulsen, A., Anderson, M., Anderson, S.L., Byford, B., Fossa, F., Neely, E.L., Rosas, A., Winfield, A., (2019) Responses to a Critique of Artificial Moral Agents, , https://arxiv.org/ftp/arxiv/papers/1903/1903.07021.pdf; Fabris, A., Etica delle macchine (2016) Teoria, 36, pp. 119-136. , Cfr; Verdicchio, M., An analysis of machine ethics from the perspective of autonomy (2017) Philosophy and Computing: Essays in Epistemology, Philosophy of Mind, Logic, and Ethics, pp. 179-191. , a cura di T. Powers, Cham, Springer; O'Neil, C., (2016) Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy, , Cfr. New York, Crown; (2017) D. Cavallini Con Il Titolo Armi Di Distruzione Matematica: Come I Big Data Aumentano la Disuguaglianza e Minacciano la Democrazia, , trad. it. a cura di Milano, Bompiani; Morale delle macchine” (2019) Allude a Un Setting Che Gli Uomini Hanno, e Si Vogliono, , https://wirtschaftslexikon.gabler.de/definition/moralische-maschinen-119940, È corretta la definizione fornita da Oliver Bendel è un'espressione tecnica, come “intelligenza artificiale. imitare o simulare componenti di esso. Le macchine morali e immorali non sono buone o cattive, non hanno libero arbitrio né coscienza, né intuizione né empatia» voce «Moralische Maschinen», in Gabler Wirtschaftslexikon, Wiesbaden, Springer Gabler; Vaccarezza, M.S., Macchine morali: Responsabilità e saggezza pratica degli agenti artificiali (2018) Etica e Responsabilità, pp. 309-318. , Cfr. anche a cura di F. Miano, Napoli, Orthotes},
document_type={Review},
source={Scopus},
}

@CONFERENCE{Williams202025,
author={Williams, T. and Zhu, Q. and Wen, R. and De Visser, E.J.},
title={The confucian matador: Three defenses against the mechanical bull},
journal={ACM/IEEE International Conference on Human-Robot Interaction},
year={2020},
pages={25-33},
doi={10.1145/3371382.3380740},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083282693&doi=10.1145%2f3371382.3380740&partnerID=40&md5=aa43b47481985dad549a298c7bdddb81},
abstract={It is critical for designers of language-capable robots to enable some degree of moral competence in those robots. This is especially critical at this point in history due to the current research climate, in which much natural language generation research focuses on language modeling techniques whose general approach may be categorized as "fabrication by imitation" (the titular mechanical "bull"), which is especially unsuitable in robotic contexts. Furthermore, it is critical for robot designers seeking to enable moral competence to consider previously under-explored moral frameworks that place greater emphasis than traditional Western frameworks on care, equality, and social justice, as the current sociopolitical climate has seen a rise of movements such as libertarian capitalism that have undermined those societal goals. In this paper we examine one alternate framework for the design of morally competent robots, Confucian ethics, and explore how designers may use this framework to enable morally sensitive human-robot communication through three distinct perspectives: (1) How should a robot reason? (2) What should a robot say? and (3) How should a robot act? © 2020 ACM.},
author_keywords={Confucian ethics;  Human-robot interaction;  Natural language generation;  Robot ethics},
keywords={Agricultural robots;  Machine design;  Man machine systems;  Modeling languages;  Natural language processing systems, Confucian ethics;  Confucians;  Human-robot communication;  Language model;  Natural language generation;  Research focus;  Robot designers;  Social justice, Social robots},
references={Alexander, L., Moore, M., (2007) Deontological Ethics, , 2007; Ames, R.T., Rosemont, H., The analects of confucius: A philosophical translation (2010) Ballantine Books; Aschenbrenner, K., Moral judgment (1971) The Concepts of Value. Springer; Asimov, I., Runaround (1942) Astounding Science Fiction, 29 (1), pp. 94-103. , 1942; Baroni, I., Nalin, M., Coti Zelati, M., Oleari, E., Sanna, A., Designing motivational robot: How robots might motivate children to eat fruits and vegetables (2014) Int'l Symp. Robot and Human Interactive Communication; Belpaeme, T., Baxter, P., Read, R., Wood, R., Cuayáhuitl, H., Kiefer, B., Racioppa, S., Enescu, V., Multimodal child-robot interaction: Building social bonds (2013) Journal of Human-Robot Interaction, 1 (2), pp. 33-53. , 2013; Bicchieri, C., (2005) The Grammar of Society: The Nature and Dynamics of Social Norms, , Cambridge University Press; Bickmore, T.W., Trinh, H., Olafsson, S., O'Leary, T.K., Asadi, R., Rickles, N.M., Cruz, R., Patient and consumer safety risks when using conversational assistants for medical information: An observational study of Siri, Alexa, and Google Assistant (2018) Jour. Medical Internet Research, , 2018; Bigman, Y.E., Waytz, A., Alterovitz, R., Gray, K., Holding robots responsible: The elements of machine morality (2019) Trends in Cognitive Sciences, 23 (5), pp. 365-368. , 2019; Briggs, G., Scheutz, M., How robots can affect human behavior: Investigating the effects of robotic displays of protest and distress (2014) International Journal of Social Robotics, 6 (3), pp. 343-355. , 2014; Michael Briggs, G., Scheutz, M., A hybrid architectural approach to understanding and appropriately generating indirect speech acts (2013) Twenty-Seventh AAAI Conference on Artificial Intelligence; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44. , 2006; Brown, P., Levinson, S.C., Levinson, S.C., (1987) Politeness: Some Universals in Language Usage, 4. , Cambridge university press; Bryson, J.J., Robots should be slaves (2010) Close Engagements with Artificial Companions: Key Social, Psychological, Ethical and Design Issues, pp. 63-74. , 2010; Castellano, G., Peters, C., Socially perceptive robots: Challenges and concerns (2010) Interaction Studies, 11 (2), p. 201. , 2010; Chung-Ying, C., A theory of Confucian selfhood: Self-cultivation and free will in Confucian philosophy (2004) Confucian Ethics: A Comparative Study of Self, Autonomy, and Community, , K. Shun and D. Wong; Chidambaram, V., Chiang, Y., Mutlu, B., Designing persuasive robots: How robots might persuade people using vocal and nonverbal cues (2012) International Conference on Human-Robot Interaction (HRI). ACM; Christman, J., Autonomy in moral and political philosophy (2008) Stanford Encyclopedia of Philosophy, , 2008; Cottine, C., That's what friends are for: A Confucian perspective on the moral significance of friendship (2020) Perspectives in Role Ethics: Virtues, Reasons, and Obligation, pp. 123-142. , T. Dare and C. Swanton; Danaher, J., The philosophical case for robot friendship (2019) Journal of Posthuman Studies, 3 (1), pp. 5-24. , 2019; Dautenhahn, K., Woods, S., Kaouri, C., Walters, M.L., Lee Koay, K., Werry, I., What is a robot companion-friend, assistant or butler (2005) 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, pp. 1192-1197; De Graaf, M.M.A., An ethical evaluation of human-robot relationships (2016) International Journal of Social Robotics, 8 (4), pp. 589-598. , 2016; De Visser, E.J., Peeters, M.M.M., Jung, M.F., Kohn, S., Shaw, T.H., Pak, R., Neerincx, M.A., Towards a theory of longitudinal trust calibration in human-robot teams (2019) Int'l Jour. Social Robotics, , 2019; Edwards, A., Edwards, C., Spence, P.R., Harris, C., Gambino, A., Robots in the classroom: Differences in students' perceptions of credibility and learning between teacher as roboti and robot as teacher (2016) Computers in Human Behavior, 65, pp. 627-634. , 2016; Fei, B., Sing Ng, W., Chauhan, S., Keong Kwoh, C., The safety issues of medical robotics (2001) Reliability Engineering & System Safety, , 2001; Fong, T., Nourbakhsh, I., Kunz, C., Fluckiger, L., Schreiner, J., Ambrose, R., Burridge, R., Schultz, A., The peer-to-peer human-robot interaction project (2005) Space 2005, p. 6750; Francke, E., Alexander, B., The potential influence of artificial intelligence on plagiarism: A higher education perspective (2019) European Conference on the Impact of Artificial Intelligence and Robotics; Harry, G., Frank, F., On bullshit (1986) Princeton University Press Princeton, NJ; Frennert, S., Ostlund, B., Seven matters of concern of social robots and older people (2014) International Journal of Social Robotics, 6 (2). , 2014; Gino, F., Understanding ordinary unethical behavior: Why people who value morality act immorally (2015) Current Opinion in Behavioral Sciences, 3, pp. 107-111. , 2015; Göckeritz, S., Schmidt, M.F.H., Tomasello, M., Young children's creation and transmission of social norms (2014) Cog. Dev, , 2014; Gray, H.M., Gray, K., Wegner, D.M., Dimensions of mind perception (2007) Science, p. 619. , 2007; Gray, K., Young, L., Waytz, A., Mind perception is the essence of morality (2012) Psychological Inquiry, 23 (2), pp. 101-124. , 2012; Ham, J., Bokhorst, R., Cuijpers, R., Van Der Pol, D., Cabibihan, J., Making robots persuasive: The influence of combining persuasive strategies (gazing and gestures) by a storytelling robot on its persuasive power (2011) International Conference on Social Robotics. Springer, pp. 71-83; Hayes, C., Allan Miller, C., Human-computer etiquette (2010) Auerbach; Held, V., (2006) The Ethics of Care: Personal, Political, and Global, , Oxford University Press on Demand; Seodu Herr, R., Is confucianism compatible with care ethics a critique (2003) Philosophy East and West, pp. 471-489. , 2003; Hinds, P.J., Roberts, T.L., Jones, H., Whose job is it anyway A study of human-robot interaction in a collaborative task (2004) Human-Computer Interaction, 19 (1), pp. 151-181. , 2004; Antoine Bosselut, A., Celikyilmaz, A., Choi, Y., (2019) Efficient Adaptation of Pretrained Transformers for Abstractive Summarization, , arXiv preprint arXiv:1906.00138 2019; Hursthouse, R., Pettigrove, G., Virtue ethics (2018) The Stanford Encyclopedia of Philosophy, , Edward N. Zalta (Ed.); Inbar, O., Meyer, J., Politeness counts: Perceptions of peacekeeping robots (2019) IEEE Transactions on Human-Machine Systems, 49 (3). , 2019; Blake Jackson, R., Wen, R., Williams, T., Tact in noncompliance: The need for pragmatically apt responses to unethical commands (2019) Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society; Blake Jackson, R., Williams, T., Robot: Asker of questions and changer of norms (2018) Proceedings of ICRES (2018); Blake Jackson, R., Williams, T., Language-capable robots may inadvertently weaken human moral norms (2019) Companion Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction (Alt.HRI); Jackson, R.B., Williams, T., Smith, N.M., Exploring the role of gender in perceptions of robotic noncompliance (2020) 15th ACM/IEEE International Conference on Human-Robot Interaction (HRI); Kennedy, J., Baxter, P., Belpaeme, T., Children comply with a robot's indirect requests (2014) Proceedings of the 2014 ACM/IEEE International Conference on Human-robot Interaction. ACM, pp. 198-199; Kennedy, J., Baxter, P., Senft, E., Belpaeme, T., Social robot tutoring for child second language learning (2016) The Eleventh ACM/IEEE International Conference on Human Robot Interaction. IEEE Press, pp. 231-238; Kuipers, B., How can we trust a robot Commun (2018) ACM, 61 (3), pp. 86-95. , 2018; Lai, K., Understanding confucian ethics: Reflections on moral development (2007) Australian Journal of Professional and Applied Ethics, 9 (2), pp. 21-27. , 2007; Kyung Lee, M., Kiesler, S., Forlizzi, J., Rybski, P., Ripple effects of an embedded social agent: A field study of a social robot in the workplace (2012) Proceedings of the SIGCHI Conference on Human Factors in Computing Systems; Levinas, E., Totality and infinity: An essay on exteriority (1979) Springer Science & Business Media, 1; Liu, J., Confucian robotic ethics (2017) International Conference on the Relevance of the Classics under the Conditions of Modernity: Humanity and Science; Malle, B.F., Scheutz, M., Moral competence in social robots (2014) International Symposium on Ethics in Engineering, Science, and Technology; Mattice, S., Confucian role ethics: Issues of naming, translation, and interpretation (2019) The Bloomsbury Research Handbook of Early Chinese Ethics and Political Philosophy, p. 25. , 2019; McCauley, L., The frankenstein complex and Asimov's three laws (2007) University of Memphis, , 2007; Midden, C., Ham, J., The illusion of agency: The influence of the agency of an artificial agent on its persuasive power (2012) International Conference on Persuasive Technology. Springer, pp. 90-99; Munro, D.J., (1971) The Concept of Man in Early China, , 1971; Robin, R.M., Trial by fire [rescue robots] (2004) IEEE Robotics & Automation Magazine, 11 (3), pp. 50-61. , 2004; Núñez, R.C., Murthi, M.N., Premaratne, K., Scheutz, M., Bueno, O., Uncertain Logic Processing: Logic-based inference and reasoning using Dempster-Shafer models (2018) Int'l Jour. Approx. Reasoning, , 2018; Núnez, R.C., Scheutz, M., Premaratne, K., Murthi, M.N., Modeling uncertainty in first-order logic: A Dempster-Shafer theoretic approach (2013) Int'l Symp. on Imprecise Probability: Theories and Applications; Pang-White, A.A., (2009) Reconstructing Modern Ethics: Confucian Care Ethics, , 2009; Benites Paradeda, R., José, F.M., Dias, J., Paiva, A., How robots persuasion based on personality traits may affect human decisions (2017) Proceedings of the Companion of the 2017 ACM/IEEE International Conference on Human-Robot Interaction. ACM, pp. 251-252; Parasuraman, R., Miller, C.A., Trust and etiquette in highcriticality automated systems (2004) Commun. ACM, 47 (4), pp. 51-55. , 2004; Pedersen, L., Kortenkamp, D., David, W., Nourbakhsh, I., Korsmeyer, D., (2003) A Survey of Space Robotics, , 2003; Puett, M., Gross-Loh, C., The path: What Chinese philosophers can teach us about the good life (2016) Simon and Schuster; Radford, A., Wu, J., Amodei, D., Amodei, D., Clark, J., Brundage, M., Sutskever, I., (2019) Better Language Models and Their Implications, , https://openai.com/blog/better-language-models/.(Accessedon12/10/2019; Robinette, P., Li, W., Allen, R., Ayanna, M., Howard, A.M., Wagner, A.R., Overtrust of robots in emergency evacuation scenarios (2016) The Eleventh ACM/IEEE International Conference on Human Robot Interaction, pp. 101-108; Rosemont, H., Ames, R.T., Confucian role ethics: A moral vision for the 21st century (2016) Vandenhoeck & Ruprecht, 5; Roy, N., Baltus, G., Fox, D., Gemperle, F., Goetz, J., Hirsch, T., Margaritis, D., Schulte, J., Towards personal service robots for the elderly (2000) Workshop on Interactive Robots and Entertainment (WIRE 2000), 25, p. 184; Benítez Sandoval, E., Brandstetter, J., Bartneck, C., Can a robot bribe a human: The measurement of the negative side of reciprocity in human robot interaction (2016) Int'l Conf. on Human Robot Interaction (HRI); Santiago, J., (2008) Confucian Ethics in the Analects As Virtue Ethics, , 2008; Scheutz, M., The inherent dangers of unidirectional emotional bonds between humans and social robots (2011) Robot Ethics: The Ethical and Social Implications of Robotics, p. 205. , 2011; Scheutz, M., Malle, B., Briggs, G., Towards morally sensitive action selection for autonomous social robots (2015) 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN); Scholtz, J., Theory and evaluation of human robot interactions (2003) 36th Annual Hawaii International Conference on System Sciences, 2003. Proceedings of The. IEEE, p. 10; Shafer, G., (1976) A Mathematical Theory of Evidence, 42. , Princeton university press; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics and Information Technology, 14 (1), pp. 27-40. , 2012; Steven Siegel, M., (2008) Persuasive Robotics: How Robots Change Our Minds, , Ph.D. Dissertation. Massachusetts Institute of Technology; Strait, M., Canning, C., Scheutz, M., Let me tell you! investigating the effects of robot communication strategies in advice-giving situations based on robot appearance, interaction modality and distance (2014) Proceedings of the 2014 ACM/IEEE International Conference on Human-robot Interaction (HRI); Strohkorb Sebo, S., Traeger, M., Jung, M., Scassellati, B., The ripple effects of vulnerability: The effects of a robot's vulnerable behavior on trust in human-robot teams (2018) Int'l Conf. on Human-Robot Interaction (HRI); Wei-Ming, T., Self-cultivation as education embodying humanity (1999) The Proceedings of the Twentieth World Congress of Philosophy, 3, pp. 27-39; Wen, R., Blake Jackson, R., Williams, T., Zhu, Q., Towards a role ethics approach to command rejection (2019) HRI Workshop on the Dark Side of Human-Robot Interaction; Wen, R., Aun Siddiqui, M., Williams, T., Dempster-shafer theoretic learning of indirect speech act comprehension norms (2020) Proceedings of the 34th AAAI Conference on Artificial Intelligence; Winkle, K., Lemaignan, S., Caleb-Solly, P., Leonards, U., Turton, A., Bremner, P., Effective persuasion strategies for socially assistive robots (2019) International Conference on Human-Robot Interaction (HRI); Wong, D., Chinese ethics (2018) The Stanford Encyclopedia of Philosophy, , Edward N. Zalta (Ed.); Yanco, H.A., Drury, J., Classifying human-robot interaction: An updated taxonomy (2004) IEEE International Conference on Systems, Man and Cybernetics, 3, pp. 2841-2846. , IEEE; Yum, J.O., The impact of Confucianism on interpersonal relationships and communication patterns in East Asia (1988) Communications Monographs, , 1988; Zhu, Q., Engineering ethics education, ethical leadership, and Confucian ethics (2018) International Journal of Ethics Education, 3 (2), pp. 169-179. , 2018; Zhu, Q., Williams, T., Blake Jackson, R., Blame-laden moral rebukes and the morally competent robot: A Confucian ethical perspective (2018) Proceedings of the Workshop on Brain-Based and Artificial Intelligence; Zhu, Q., Williams, T., Wen, R., Confucian robot ethics (2019) Computer Ethics-Philosophical Enquiry (CEPE) Proceedings 2019, 1, p. 12. , 2019},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{McKee2020110,
author={McKee, H.A. and Porter, J.E.},
title={Ethics for AI writing: The importance of rhetorical context},
journal={AIES 2020 - Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
year={2020},
pages={110-116},
doi={10.1145/3375627.3375811},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082176219&doi=10.1145%2f3375627.3375811&partnerID=40&md5=c9bbe9e9531ed14cd40f5e65ff91db74},
abstract={Implicit in any rhetorical interaction-between humans or between humans and machines-are ethical codes that shape the rhetorical context, the social situation in which communication happens and also the engine that drives communicative interaction. Such implicit codes are usually invisible to AI writing systems because the social factors shaping communication (the why and how of language, not the what) are not usually explicitly evident in databases the systems use to produce discourse. Can AI writing systems learn to learn rhetorical context, particularly the implicit codes for communication ethics? We see evidence that some systems do address issues of rhetorical context, at least in rudimentary ways. But we critique the information transfer communication model supporting many AI writing systems, arguing for a social context model that accounts for rhetorical context-what is, in a sense, "not there" in the data corpus but that is critical for the production of meaningful, significant, and ethical communication. We offer two ethical principles to guide design of AI writing systems: transparency about machine presence and critical data awareness, a methodological reflexivity about rhetorical context and omissions in the data that need to be provided by a human agent or accounted for in machine learning. © 2020 Copyright held by the owner/author(s).},
author_keywords={AI writing systems;  Communication ethics;  Critical date awareness;  Ethics;  Information transfer model;  Language models;  Machine ethics;  Rhetoric;  Rhetorical context;  Social context model;  Text generation;  Transparency},
keywords={Codes (symbols);  Digital storage;  Ethical aspects;  Transparency, Communication ethics;  Critical date awareness;  Information transfers;  Language model;  Rhetoric;  Rhetorical context;  Social context;  Text generations;  Writing systems, Data communication systems},
references={McKee, H.A., Porter, J.E., AI agents as professional communicators (2017) Professional Communication and Network Interaction: A Rhetorical and Ethical Approach, , Routledge, New York, NY; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds &Machine, 14 (3), pp. 349-379. , https:doi.org/10.1023/B:MIND.0000035461.63578.9d, Aug. 2004; Adam, A., Ethics for things (2008) Ethics and Information Technology, 10 (2-3), pp. 149-154. , https://doi.org/10.1007/s10676-008-9169-3, Sept. 2008; Etzioni, A., Etzioni, O., AI assisted ethics (2016) Ethics and Information Technology, 18 (2), pp. 149-156. , https://doi.org/10.1007/s10676-016-9400-6, June 2016; Malle, B.F., Integrating robot ethics and machine morality: The study and design of moral competence in robots (2016) Ethics and Information Technology, 18 (4), pp. 243-256. , https://doi.org/10.1007/s10676-015-9367-8, Dec. 2016; Dignum, V., Ethics in artificial intelligence: Introduction to the special issue (2018) Ethics and Information Technology, 20 (1), pp. 1-3. , https://doi.org/10.1007/s10676-018-9450-z, March 2018; Fossa, F., Artificial moral agents: Moral mentors or sensible tools? (2018) Ethics and Information Technology, 20 (2), pp. 115-126. , https://doi.org/10.1007/s10676-018-9451-y, June 2018; Leikas, J., Koivisto, R., Gotcheva, N., Ethical framework for designing autonomous intelligent systems (2019) Journal of Open Innovation, 5 (1), p. 18. , https://doi.org/10.3390/joitmc5010018, March 2019; Van Wynsberghe, A., Robbins, S., Critiquing the reasons for making artificial moral agents (2019) Science and Engineering Ethics, 25 (3), pp. 719-735. , https://doi.org/10.1007/s11948-018-0030-8, June 2019; McKee, H.A., Porter, J.E., Digital media ethics and rhetoric (2018) The Routledge Handbook of Digital Writing and Rhetoric, pp. 401-411. , , ed. J. Alexander and J. Rhodes Routledge, New York, NY; (2006) On Rhetoric: A Theory of Civic Discourse (2nd Ed.), , Trans. G.A. Kennedy. Oxford University Press, Oxford, UK Aristotle; Quintilian, M.F., (1920) Institutio Oratoria (Institutes of Oratory), , http://penelope.uchicago.edu/Thayer/E/Roman/Texts/Quintilian/Institutio_Oratoria/home.html, Trans. H.E. Butler; Markham, A.N., (2018) What's the Trolley Problem Got to Do with It: Ethics As Method, , https://annettemarkham.com/2018/07/ethics_as_method_published/, July; Shannon, C.E., A mathematical theory of communication (1948) Bell System Technical Journal, 27 (3), pp. 379-423. , https://doi.org/10.1002/j.1538-7305.1948.tb01338.x, July-Oct 1948, 623-656; Weaver, W., Shannon, C.E., (1949) The Mathematical Theory of Communication, , University of Illinois Press, Normal, IL; Lakoff, G., Johnson, M., (1980) Metaphors We Live by, , University of Chicago Press, Chicago, IL; Open, A.I., (2019) Better Language Models and Their Implications, , https://openai.com/blog/better-language-models/; Radford, A., (2019) Language Models Are Unsupervised Multitask Learners, , https://openai.com/blog/better-language-models/, OpenAI Blog; Dong, D., (2018) Text Generation Using Recurrent Neural Networks, , https://towardsdatascience.com/text-generation-using-rnns-fdb03a010b9f, Medium; Nelson, D., (2019) Text Generation with Python and TensorFlow/Keras, , https://stackabuse.com/text-generation-with-python-and-tensorflow-keras/, Stack Abuse; Suchman, L.A., (1987) Plans and Situated Actions: The Problem of Human Machine Communication, , Cambridge University Press, New York, NY; Bitzer, L.F., The rhetorical situation (1968) Philosophy &Rhetoric, 1 (1), pp. 1-14. , https://www.jstor.org/stable/40236733, Jan. 1968; Poulakos, J., Toward a sophistic definition of rhetoric (1983) Philosophy &Rhetoric, 16 (1), pp. 35-48. , http://www.jstor.org/stable/40237348; Harnad, S., The symbol grounding problem (1990) Physica D, Nonlinear Phenomena, 42 (1-3), pp. 335-346. , https://doi.org/10.1016/0167-2789(90)90087-6; Floridi, L., Semantic capital: Its nature, value, and curation (2018) Philosophy &Technology, 31, pp. 481-497. , https://doi.org/10.1007/s13347-018-0335-1; Chowdhury, R., (2019) The Pitfalls of A "Retrofit Human" in AI, , https://venturebeat.com/2019/11/11/the-pitfalls-of-A-retrofit-human-in-ai-systems/, VentureBeat; Chai, J.Y., Fang, R., Liu, C., She, L., Collaborative language grounding toward situated human-robot dialogue (2016) AI Magazine, 37 (4), pp. 32-45. , https://doi.org/10.1609/aimag.v37i4.2684, Winter 2016; Bengtsson, S., (2018) Ethics Exists in Communication: Human-machine Ethics beyond the Actor-network, , Media@LSE Working Paper Series, London School of Economics and Political Science. OAI: DiVA.org:sh-37239; Patterson, R.E., Robert, G., Eggleston, G.R., Machine synergism in high-level cognitive functioning: The human component (2018) IEEE Transactions on Emerging Topics in Computational Intelligence, 2 (4), pp. 249-257. , https://doi.org/10.1109/TETCI.2018.2816584, July 2018; Russo, F., Digital technologies, ethical questions, and the need of an informational framework (2018) Philosophy &Technology, 31 (4), pp. 655-667. , https://doi.org/10.1007/s13347-018-0326-2, Dec. 2018; http://www.latimes.com/la-me-quakebot-faq-20190517-story.html, Editor. 2019. What is the Quakebot and how does it work? LATimes; Roetzer, P., (2018) This Marketing Tool Uses AI to Create Copy That Converts, , http://www.marketingaiinstitute.com/blog/persado-spotlight, Artificial Intelligence Marketing Institute; https://www.persado.com/how-it-works/, Persado. 2019. Persado-How it works; DiStefano, J.N., (2019) "Machine Learning Is the Path to More Humanity in Marketing": JPMorgan Picks AI to Write Ads, , https://www.inquirer.com/business/phillydeals/jpmorgan-artificial-intelligence-copy-writing-persado-ads-20190730.html, Philadelphia Inquirer, July 30; Markham, A.N., Undermining "data": A critical examination of a core term in scientific inquiry (2013) First Monday, 18 (10). , https:/doi.org/10.5210/fm.v18i10.4868; Markham, A.N., Tiidenberg, K., Herman, A., Ethics as methods: Doing ethics in the era of big data research-Introduction (2018) Social Media + Society, , https://doi.org/10.1177/205630511878450, July-September; Harwell, D., (2019) A Face-scanning Algorithm Increasingly Decides Whether You Deserve the Job, , https://www.washingtonpost.com/technology/2019/10/22/ai-hiring-face-scanning-algorithm-increasingly-decides-whether-you-deserve-job/, Washington Post, November 6; Licklider, J.C.R., Man-computer symbiosis (1960) IRE Transactions on Human Factors in Electronics, 1 (1), pp. 4-11. , https://doi.org/10.1109/THFE2.1960.4503259, March 1960; Leigh, S.-W., Agrawal, H.A., Maes, P., Robotic symbiosis: Interweaving human and machine actions (2018) IEEE Pervasive Computing, 17 (2), pp. 34-43. , https://doi.org/10.1109/MPRV.2018.022511241, June 2018; Wilson, H.J., Daugherty, P.R., (2018) Collaborative Intelligence: Humans and AI Are Joining Forces, , https://hbr.org/2018/07/collaborative-intelligence-humans-and-ai-are-joining-forces, Harvard Business Review; Epstein, S.L., Wanted: Collaborative intelligence (2015) Artificial Intelligence, 221, pp. 36-45. , https://doi.org/10.1016/j.artint.2014.12.006, April 2015; Fügener, A., Grahl, J., Gupta, A., Ketter, W., (2019) Collaboration and Delegation between Humans and AI: An Experimental Investigation of the Future of Work, , http://dx.doi.org/10.2139/ssrn.3368813, ERIM Report Series; Hossein Jarrahi, M., Artificial intelligence and the future of work: Human-AI symbiosis in organizational decision making (2018) Business Horizons, 61 (4), pp. 577-586. , https://doi.org/10.1016/j.bushor.2018.03.007, July-Aug. 2018; Case, N., (2018) How to Become A Centaur, , https://doi.org/10.21428/61b2215c, Journal of Design and Science},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Battistuzzi2020,
author={Battistuzzi, L. and Papadopoulos, C. and Hill, T. and Castro, N. and Bruno, B. and Sgorbissa, A.},
title={Socially Assistive Robots, Older Adults and Research Ethics: The Case for Case-Based Ethics Training},
journal={International Journal of Social Robotics},
year={2020},
doi={10.1007/s12369-020-00652-x},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085578153&doi=10.1007%2fs12369-020-00652-x&partnerID=40&md5=bec36cbaac5fa41d9c7afe4a730e5710},
abstract={Most studies on socially assistive robots (SARs) in elder care are conducted in care homes and recruit participants with some degree of cognitive impairment. The ethical dimension in these studies thus requires careful attention, suggesting that the researchers involved should be offered specific research ethics training. To meet this need in CARESSES—an international multidisciplinary project that aims to design and evaluate the first culturally competent SAR for the care of older adults—a research ethics training module for the project researchers was developed. The training module is largely based on case-based learning (CBL), a widely recognized approach to learning and instruction that is regarded as highly effective across multiple disciplines. In this paper, we argue that research ethics training should be offered to robotics investigators involved in research on SARs in elder care, and we provide an overview of the ethical issues involved in conducting research with SARs and older adults in care homes. Finally, we show how CBL can be used for research ethics training in this context. © 2020, Springer Nature B.V.},
author_keywords={Case-based learning;  Elder care;  Ethics training;  Pepper;  Research ethics;  Robot ethics;  Socially assistive robot},
keywords={Agricultural robots, Case based learning;  Cognitive impairment;  Ethics training;  Multidisciplinary projects;  Multiple disciplines;  Research ethics;  Socially assistive robots;  Training modules, Philosophical aspects},
references={(2019) World Population Prospects 2019; Feil-Seifer, D., Mataric, M.J., Defining socially assistive robotics (2005) Proceedings of the 2005 IEEE 9Th International Conference on Rehabilitation Robotics, , Chicago, IL, USA; Lehmann, H., Syrdal, D., Dautenhahn, K., (2013) What Should a Robot Do for youâ€¯? Evaluating the Needs of the Elderly in the UK. In: ACHI 2013—the Sixth International Conference on Advances in computer–human Interactions, pp. 83-88; Abdi, J., Al-Hindawi, A., Ng, T., Vizcaychipi, M.P., Scoping review on the use of socially assistive robot technology in elderly care (2018) BMJ Open; Lingler, J., Jablonski, R., Bourbonniere, M., Kolanowski, A., Informed consent to research in long-term care settings (2009) Res Gerontol Nurs, 2, pp. 153-161; Maas, M.L., Kelley, L.S., Park, M., Specht, J.P., Issues in conducting research in nursing homes (2002) West J Nurs Res, 24, pp. 373-389; Bruno, B., Chong, N.Y., Kamide, H., Paving the way for culturally competent robotsâ€¯: A position paper (2017) 2017 26Th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), , Lisbon, Portugal; Bruno, B., Chong, N.Y., Kamide, H., The CARESSES EU-Japan project: making assistive robots culturally competent (2019) Lect Not Electr Eng, 540, pp. 151-169; Pandey, A.K., Gelin, R., A mass-produced sociable humanoid robot: pepper: the first machine of its kind (2018) IEEE Robot Autom Mag, 25, pp. 40-48; Papadopoulos, C., Hill, T., Battistuzzi, L., The CARESSES study protocol: testing and evaluating culturally competent socially assistive robots among older adults residing in long term care homes through a controlled experimental trial (2020) Arch Public Heal; Bagdasarov, Z., Thiel, C.E., Johnson, J.F., Case-based ethics instruction: the influence of contextual and individual factors in case content on ethical decision-making (2013) Sci Eng Ethics, 19, pp. 1305-1322; Falkenberg, L., Woiceshyn, J., Enhancing business ethics: using cases to reach moral reasoning (2008) J Bus Ethics, 79, pp. 213-217; Kolodner, J.L., Educational implications of analogy: a view from case-based reasoning (1997) Am Psychol, 52, p. 57; Kalichman, M., Evidence-based research ethics (2009) Am J Bioeth, 9, pp. 85-87; World Medical Association Declaration of Helsinki: ethical principles for medical research involving human subjects (2013) J Am Med Assoc, 310, pp. 2191-2194; (2010) European Textbook on Ethics in Research; College SN Required Education in Protecting Human Research Participants, , https://www.snc.edu/irb/humansubjects.html; Kalichman, M., Rescuing responsible conduct of research (RCR) education (2014) Acc Res, 21, pp. 68-83; Sedenberg, E., Chuang, J., Mulligan, D., Designing commercial therapeutic robots for privacy preserving systems and ethical research practices within the home (2016) Int J Soc Robot, 8, pp. 575-587; Lam, H.R., Chow, S., Taylor, K., Challenges of conducting research in long-term care facilities: a systematic review (2018) BMC Geriatr, 18, p. 242; Ramos, L., van Den Hoven, E., Balancing ethics in research with older adults and persons with dementia (2015) Paper Presented at the Ozchi 2015 Workshop on Ethical Encounters: HCI Research in Sensitive and Complex Settings, pp. 1-3; Mody, L., Miller, D.K., McGloin, J.M., Recruitment and retention of older adults in aging research (2008) J Am Geriatr Soc, 56, pp. 2340-2348; Begun, A.L., Otto-Salaj, L.L., Berger, L., (2018) Participant recruitment and retention in intervention and evaluation research, , Oxford University Press, New York; Glesne, C., Rapport and friendship in ethnographic research (1989) Int J Qual Stud Educ, 2, pp. 45-54; Berkman, B.E., Chandros Hull, S., Eckstein, L., The unintended implications of blurring the line between research and clinical care in a genomic age (2014) Person Med, 11, pp. 285-295; McGuire, J., Ethical considerations when working with older adults in psychology (2009) Int J Aviat Psychol, 19, pp. 112-128; Bonnie, R.J., Wallace, R.B., (2003) Elder mistreatment abuse, neglect and exploitation in an aging America, , The National Academies Press, Washington; Resnik, D.B., Randall, D., Reporting suspected abuse or neglect in research involving children (2018) J Med Ethics; Ragan, A., Bowen, A., Improving attitudes regarding the elderly population: the effects of information and reinforcement for change (2001) Gerontologist, 41, pp. 511-515; van Wynsberghe, A., Designing robots for care: care centered value-sensitive design (2013) Sci Eng Ethics, 19, pp. 407-433; van Wynsberghe, A., (2016) Healthcare robots: ethics, design and implementation, , 1, Routledge, London; Fosch-Villaronga, E., (2019) Robots, healthcare, and the law: regulating automation in personal care, , 1, Routledge, London; Sharkey, A., Sharkey, N., Granny and the robots: ethical issues in robot care for the elderly (2012) Ethics Inf Technol, 14, pp. 27-40; Sharkey, A.J., Robots and human dignity: a consideration of the effects of robot care on the dignity of older people (2015) Ethics Inf Technol, 14, pp. 27-40; Vallor, S., Carebots and caregivers: sustaining the ethical ideal of care in the twenty-first century (2011) Philos Technol, 24, pp. 251-268; Battistuzzi, L., Sgorbissa, A., Papadopoulos, C., Embedding ethics in the design of culturally competent socially assistive robots (2018) IEEE International Conference on Intelligent Robots and Systems; Eur, A., (2010) The Ethical Issues Linked to the Use of Assistive Technology in Dementia care—ethical Issues in practice—ethics—Alzheimer Europe, , http://www.alzheimer-europe.org/Ethics/Ethical-issues-in-practice/2010-The-ethical-issues-linked-to-the-use-of-assistive-technology-in-dementia-care, Accessed 19 Feb 2019; Turkle, S., Authenticity in the age of digital companions (2007) Interact Stud, 8, pp. 501-517; Annas, G.J., HIPAA regulations—a new era of medical-record privacy? (2003) N Engl J Med; European Parliament and of the Council of 27 April 2016 on the Protection of Natural Persons with Regard to the Processing of Personal Data and on the Free Movement of Such Data; Alvseike, H., Brønnick, K., Feasibility of the iPad as a hub for smart house technology in the elderly; effects of cognition, self-efficacy, and technology experience (2012) J Multidiscip Healthc, 5, pp. 299-306; Draucker, C.B., Martsolf, D.S., Poole, C., Developing distress protocols for research on sensitive topics (2009) Arch Psychiatr Nurs, 23, pp. 343-350; Fraser, S.A., Kenyon, V., Lagacé, M., Stereotypes associated with age-related conditions and assistive device use in Canadian media (2016) Gerontologist, 56, pp. 1023-1032; Werhane, P.H., Moral imagination and systems thinking (2002) J Bus Ethics, 38, pp. 33-42; Kolodner, J.L., (2014) Case-based reasoning, , Morgan Kaufmann, Burlington; Kolodner, J., Owensby, J., Guzdial, M., Case-based learning aids (2004) Handbook of research for educational communications and technology, pp. 829-861. , Jonasse(ed), 2, Lawrence Erlbaum Associates, Mahwah; Kim, S., Phillips, W.R., Pinsky, L., A conceptual framework for developing teaching cases: a review and synthesis of the literature across disciplines (2006) Med Educ, 40, pp. 867-876; Johnson, J.F., Bagdasarov, Z., Connelly, S., Case-based ethics education: the impact of cause complexity and outcome favorability on ethicality (2012) J Empir Res Hum Res Ethics, 7, pp. 63-77; Menzel, D.C., Teaching and learning ethical reasoning with cases (2009) Public Integr, 11, pp. 239-250; Harkrider, L.N., MacDougall, A.E., Bagdasarov, Z., Structuring case-based ethics training: how comparing cases and structured prompts influence training effectiveness (2013) Ethics Behav, 23, pp. 179-198; Plinio, A.J., Young, J.M., McCormick Lavery, L., The state of ethics in our society: a clear call for action (2010) Int J Discl Gov, 7, pp. 172-197; Atkinson, T.N., Using creative writing techniques to enhance the case study method in research integrity and ethics courses (2008) J Acad Ethics, 6, pp. 33-50; Currie, G., Moving towards reflexive use of teaching cases (2008) Int J Manag Educ, 7, pp. 41-50; Herreid, C.F., Sorting potatoes for Miss Bonner (1998) J Coll Sci Teach, 27, pp. 236-239; Watts, L.L., Medeiros, K.E., Mulhearn, T.J., Are ethics training programs improving? A meta-analytic review of past and present ethics instruction in the sciences (2017) Ethics Behav, 27, pp. 351-384; Antes, A., Murphy, S., Waples, E., meta-analysis of ethics instruction effectiveness in the sciences (2009) Ethics Behav, 19, pp. 379-402; Velasquez, M., Moberg, D., Meyer, M.J., Shanks, T., McLean, M.R., Decosse, D., André, C., Hanson, K.O., A framework for thinking ethically (2009) Markkula Center for Applied Ethics, , http://www.scu.edu/ethics/practicing/decision/framework.html, at Santa Clara University; Nimon, K., Explaining differences between retrospective and traditional pretest self-assessments: competing theories and empirical evidence (2014) Int J Res Method Educ, 37, pp. 256-269; Geldhof, G.J., Warner, D.A., Finders, J.K., Revisiting the utility of retrospective pre-post designs: the need for mixed-method pilot data (2018) Eval Program Plann, 70, pp. 83-89; Schiekirka, S., Anders, S., Raupach, T., Assessment of two different types of bias affecting the results of outcome-based evaluation in undergraduate medical education (2014) BMC Med Educ, 14, p. 149; Carsten, B., Coeckelbergh, M., Ethics of healthcare robotics: towards responsible research and innovation ethics of healthcare robotics: towards responsible research and innovation (2016) Rob Auton Syst, 86, pp. 152-161},
document_type={Article},
source={Scopus},
}

@ARTICLE{Pereira2020,
author={Pereira, L.M.},
title={The carousel of ethical machinery},
journal={AI and Society},
year={2020},
doi={10.1007/s00146-020-00994-0},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085509798&doi=10.1007%2fs00146-020-00994-0&partnerID=40&md5=b2c56c4ed53502aab56b36364eea26e3},
abstract={Human beings have been aware of the risks associated with knowledge or its associated technologies since the dawn of time. Not just in Greek mythology, but in the founding myths of Judeo-Christian religions, there are signs and warnings against these dangers. Yet, such warnings and forebodings have never made as much sense as they do today. This stems from the emergence of machines capable of cognitive functions performed exclusively by humans until recently. Besides those technical problems associated with its design and conceptualization, the cognitive revolution, brought about by the development of AI also gives rise to social and economic problems that directly impact humanity. Therefore, it is vital and urgent to examine AI from a moral point of view. The moral problems are two-fold: on the one hand, those associated with the type of society we wish to promote through automation, complexification and power of data processing available today; on the other, how to program decision-making machines according to moral principles acceptable to those humans who will share knowledge and action with them. © 2020, Springer-Verlag London Ltd., part of Springer Nature.},
author_keywords={Ethical AI;  Evolutionary morality;  Machine ethics;  Social impacts of AI},
keywords={Data handling;  Decision making, Christians;  Cognitive functions;  Complexification;  Decision making machines;  Economic problems;  Human being;  Share knowledge, Machinery},
references={Cave, S., (2020) AI narratives—a history of imaginative thinking about intelligent machines, , (ed), Oxford University Press, Oxford; Hammerstein, P., Stevens, J.R., (2012) Evolution and the mechanisms of decision making, , (eds), The MIT Press, Cambridge; Han, T.A., Pereira, L.M., Evolutionary machine ethics (2018) Handbuch maschinenethik, pp. 229-253. , Bendel O, (ed), SpringerVS, Wiesbaden; Han, T.A., Pereira, L.M., Lenaerts, T., Markham, A., Modelling and influencing the AI bidding war: A research agenda (2019) Proceedings of the AAAAI/ACM Conference on AI, Ethics, and Society, (AIES 2019), , 27–28 January 2019, Honolulu. AAAI, Palo Alto; Kershaw, S.P., (2007) A brief guide to the Greek myths, , Constable & Robinson Ltd., London; Lee, K.-F., (2018) AI super-powers—China, silicon valley, and the new world order, , Houghton Mifflin Harcourt, New York; Mayor, A., (2018) Gods and robots—myths, machines, and ancient dreams of technology, , Princeton University Press, Princeton; Jobs lost, jobs gained: Workforce transitions in a time of automation (2017) Mckinsey Global Institute, San Francisco, , https://technologyreview.us11.list-manage.com/track/click?u=47c1a9cec9749a8f8cbc83e78&id=66f78fce4f&e=d1762c0ec8, Accessed 1 May 2020; Notes from the AI frontier: Modeling the impact of AI on the world economy (2018) Mckinsey Global Institute, San Francisco, , https://www.mckinsey.com/featured-insights/artificial-intelligence/notes-from-the-ai-frontier-modeling-the-impact-of-ai-on-the-world-economy, Accessed 1 May 2020; Moor, J.H., The Nature, Importance, and Difficulty of Machine Ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21. , http://www.psy.vanderbilt.edu/courses/hon182/The_Nature_Importance_and_Difficulty_of_Machine_Ethics.pdf; (1945) Superior Orders, , https://en.wikipedia.org/wiki/Superior_orders#%22Nuremberg_defense%22, Wikipedia., Accessed 1 May 2020; (2018) Putting Faces to the Jobs at Risk of Automation, , https://www.oecd.org/employment/Automation-policy-brief-2018.pdf, OECD policy brief on the future of work, Accessed 1 May 2020; Parret, H., (1993) The aesthetics of communication: pragmatism and beyond, , Springer, Dordrecht; Pereira, L.M., Lopes, A.B., After All… What is a Machine? (2020) Studies in Applied Philosophy, Epistemology and Rational Ethics, pp. 93-96. , Springer International Publishing, Cham; Pereira, L.M., Santos, F.C., Counterfactual Thinking in Cooperation Dynamics (2019) Model-Based Reasoning in Science and Technology, pp. 69-82. , Springer International Publishing, Cham; Pereira, L.M., Saptawijaya, A., Programming machine ethics (2016) Studies in Applied Philosophy, Epistemology and Rational Ethics (SAPERE), 26. , Springer, Berlin, 978-3-319-29353-0; Pereira, L.M., Saptawijaya, A., Urbaniak, R., Payette, G., Counterfactuals, logic programming and agent morality (2017) Applications of Formal Philosophy: The Road less Travelled, Springer Logic, Argumentation & Reasoning Series, pp. 25-54. , Springer Nature, Cham, 978-3319585055; Pereira, L.M., Lenaerts, T., Martinez-Vaquero, L.A., Han, T.A., Das, S., Social manifestation of guilt leads to stable cooperation in multi-agent systems (2017) Proceedings of the 16Th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2017), pp. 1422-1430. , 8–12 May 2017, São Paulo, Brazil. AAAI, Palo Alto; Pew, R.C., Artificial intelligence and the future of humans (2018) Pew Research Center. Internet & Technology., , https://www.pewresearch.org/internet/2018/12/10/concerns-about-human-agency-evolution-and-survival/, Accessed 1 May 2020; Machine Bias (2016) Propublica., , https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing, Accessed 1 May 2020; How will automation impact jobs? (2020) Pricewaterhousecoopers, , https://www.pwc.co.uk/services/economics-policy/insights/the-impact-of-automation-on-jobs.html#cta-1, Insights., Accessed 1 May 2020; Saptawijaya, A., Pereira, L.M., From logic programming to machine ethics (2018) Handbuch maschinenethik, pp. 209-227. , Bendel O, (ed), SpringerVS, Wiesbaden; White, J., Understanding and augmenting human morality: an introduction to the ACTWith model of conscience (2010) Model-based reasoning in science and technology, 314. , Magnani L, Carnielli W, Pizzi C, (eds), Studies computational intelligence, Springer, Berlin; White, J., Manufacturing morality, a general theory of moral agency grounding computational implementations: the ACTWith model (2012) Computational Intelligence, , Floares A, (ed), Nova Science Publishers, Hauppauge; (2017) Courts are Using AI to Sentence Criminals, , https://www.wired.com/2017/04/courts-using-ai-sentence-criminals-must-stop-now/, That must stop now, WIRED, Accessed 1 May 2020},
document_type={Article},
source={Scopus},
}

@ARTICLE{Noesselt2020,
author={Noesselt, N.},
title={City brains and smart urbanization: regulating ‘sharing economy’ innovation in China},
journal={Journal of Chinese Governance},
year={2020},
doi={10.1080/23812346.2020.1762466},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085386634&doi=10.1080%2f23812346.2020.1762466&partnerID=40&md5=4a7f6cab1a9ce3aa34dcb0d200713860},
abstract={Starting from the officially proclaimed readjustment of the People’s Republic of China’s national development road map, this article engages in a theory-guided evaluation of the country’s artificial intelligence (AI) strategy in connection with its smart city initiatives. The government’s official quest to steer China toward a ‘new mode of urbanization’ has, as this article argues, facilitated the rise of the country’s ‘sharing economy’/’platform economy’, with the mushrooming of a private AI economy offering ‘smart’ algorithm-optimized solutions to complex urban governance dilemmas. To (re)strengthen control and to cement central authority, the Chinese government has set out to regulate and standardize this emerging private platform economy sector—while also attempting not to interrupt the innovation drive of the Chinese AI landscape as such. This article argues that these regulation efforts, contrary to conventional top-down steering approaches, rely on central-local collaboration and network coordination that involves a number of multiple actors operating under the ‘shadow of hierarchy’ of the central party-state. © 2020, © 2020 Zhejiang University.},
author_keywords={Artificial intelligence (AI);  China;  deep learning;  responsible AI;  robot ethics;  sharing economy;  smart city;  standardization},
references={(2018), https://www.abacusnews.com/big-guns/chinese-internet-users-criticize-baidu-ceo-saying-people-china-are-willing-give-data-privacy/article/2139313, Chinese Internet Users Criticize Baidu CEO for Saying People China Are Willing to Give up Data Privacy for Convenience. By Shen Xinmei.,. Accessed April 21, 2018; (2019), https://www.scmp.com/tech/article/3038595/didi-will-soon-roll-out-self-driving-taxi-service-shanghai, Didi Will Soon Roll Out a Self-driving Taxi Service Shanghai. 2019. Accessed December 12; Albino, V., Berardi, U., Dangelico, R.M., Smart Cities: Definitions, Dimensions, Performance, and Initiatives (2015) Journal of Urban Technology, 22 (1), pp. 3-21; Angelidou, M., Smart City Policies: A Spatial Approach (2014) Cities, 41, pp. S3-S11; Arnold, T., Scheutz, M., The ‘Big Red Button’ is Too Late: An Alternative Model for the Ethical Evaluation of AI Systems (2018) Ethics and Information Technology, 20 (1), pp. 59-69; Asimov, I., Runaround (1942) Astounding Science Fiction, 29 (1), pp. 94-103; (2019), https://www.baai.ac.cn/blog/f4d28928ef4, Rengong zhineng Beijing gongshi (Beijing AI Consensus).,. Accessed May 28, 2019; (2019), https://www.baai.ac.cn/blog/beijing-ai-principles, Beijing AI Principles. Accessed May 29, 2019; Bonnemains, V., Saurel, C., Tessier, C., Embedded Ethics: Some Technical and Ethical Challenges (2018) Ethics and Information Technology, 20 (1), pp. 41-58; Borak, M., (2018), https://technode.com/2018/01/26/didi-ai-brain/, Didi Is Using Its New AI Brain to Crack the Toughest Puzzle—Our Cities. Accessed January 15, 2019; Brauneis, R., Goodman, E.P., Algorithmic Transparency for the Smart City (2018) Yale Journal of Law and Technology, 20 (1), pp. 103-176; Bryan-Low, C., Packham, C., Lague, D., Stecklow, S., Stubbs, J., (2019), https://www.reuters.com/article/us-huawei-usa-5g-specialreport/special-report-hobbling-huawei-inside-the-us-war-on-chinas-tech-giant-idUSKCN1SR1EU, Special Report - Hobbling Huawei: Inside the U.S. War on China’s Tech Giant. Accessed September 20, 2019; Brynjolfsson, E., McAfee, A., (2013) The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies, , New York; London: W. W. Norton; Brynjolfsson, E., McAfee, A., (2017) Machine, Platform, Crowd: Harnessing Our Digital Future, , New York; London: W. W. Norton; (2018), http://www.cesi.cn/images/editor/20180124/20180124135528742.pdf, Rengong zhineng biaozhunhua baipishu (White Paper on AI Standardization).,. Accessed January 10, 2019; Chan, J.K.S., Anderson, S., (2015), http://www.cn.undp.org/content/china/en/home/library/democratic_governance/Rethinking-Smart-Cities_ICT-for-New-type-Urbanization-and-Public-Participation-at-the-City-and-Community-Level-in-China.html, Rethinking Smart Cities: ICT for New Type Urbanization and Public Participation at the City and Community Level China. United Nations Development Programme China.,. Accessed October 15, 2018; Chen, J.Y., Thrown under the Bus and Outrunning It! the Logic of DiDi and Taxi Drivers’ Labour and Activism in the on-Demand Economy (2018) New Media & Society, 20 (8), pp. 2691-2711; (2019), http://www.china.org.cn/china/2019-06/18/content_74895077.htm, Principles Set to Regulate AI Research, Applications. Accessed June 22, 2019; Christensen, B., (2009), https://www.livescience.com/10574-robots-learn-lie.html, Robots Learn to Lie. Accessed October 12, 2017; Crawford, K., Schultz, J., Big Data and Due Process: Toward a Framework to Redress Predictive Privacy Harms (2014) Boston College Law Review, 55 (1), pp. 93-128; Cui, X., Cao, Y., Gongxiang jingji haishi linggong jingji: Hou gongye jinrong zibenzhuyi xia de jilei yu guyong guanxi” (Sharing Economy or Gig-Economy: Accumulation and Wage Labor Relations under Post-Industrial Financial Capitalism) (2019) Zhengzhi Jingjixue Pinglun (China Review of Political Economy), 1, pp. 22-35; Dawes, S.S., Governance in the Digital Age: A Research and Action Framework for an Uncertain Future (2009) Government Information Quarterly, 26 (2), pp. 257-264; (2019), https://www.didiglobal.com/news/newsDetail?id=624&type=news, Chuxing Sets up JV with BAIC-BJEV, China’s Largest EV Maker: Connecting AI Mobility Solutions with EV Fleet Operations. Accessed January 31, 2019; (2015), http://www.gov.cn/zhengce/content/2015-05/19/content_9784.htm, Guowuyuan guanyu yunfa ‘Zhongguo zhizao 2025’ de tongzhi (State Council Release Note Made China 2025).,. Accessed May 25, 2015; Hardesty, L., (2016), http://news.mit.edu/2016/making-computers-explain-themselves-machine-learning-1028, Making Computers Explain Themselves: New Training Technique Would Reveal the Basis for Machine-Learning Systems’ Decisions. MIT News,. Accessed December 8, 2017; Heilmann, S., Policy-Making Through Experimentation: The Formation of a Distinctive Policy Process (2011) Mao’s Invisible Hand: The Political Foundations of Adaptive Governance in China, pp. 62-101. , Heilmann S., Perry E.J., (eds), Cambridge: Harvard UP, edited by; Horn, J., Machine-Breaking in England and France During the Age of Revolution (2005) Labour/Le Travail, 55, pp. 143-166; Horwitz, J., (2019), https://www.reuters.com/article/us-china-tech-zao/chinese-face-swapping-app-goes-viral-sparks-privacy-concerns-idUSKCN1VN0G9, Chinese Face-swapping App Goes Viral, Sparks Privacy Concerns. Reuters,. Accessed December 15, 2019; (2016), https://ethicsinaction.ieee.org/#read, Ethically Aligned Design: Vision for Prioritizing Human Well-Being with Autonomous and Intelligent Systems. Accessed May 20, 2018; Kitchen, R., The Real-Time City? Big Data and Smart Urbanism (2014) Geo Journal, 79 (1), pp. 1-14; Kitchen, R., The Ethics of Smart Cities and Urban Science (2016) Philosophical Transactions of the Royal Society, 374 (2983), pp. 1-15; Lee, K.-F., (2018) AI Superpowers: China, Silicon Valley, and the New World Order., , Boston; New York: Houghton Mifflin Harcourt; Li, B., Chen, C., Hu, B., Governing Urbanization and the New Urbanization Plan in China (2016) Environment and Urbanization, 28 (2), pp. 515-534; Li, F., (2018), http://www.xinhuanet.com/english/2019-12/30/c_138667107.htm, Country Issues National Standards for Autonomous Vehicle Testing. China Daily,. Accessed August 25, 2018; Li, K., (2015), http://english.www.gov.cn/archive/publications/2015/03/05/content_281475066179954.htm, Report on the Work of the Government 2015. Accessed October 10, 2018; Li, K., (2016), http://english.www.gov.cn/premier/news/2016/03/17/content_281475309417987.htm, Report on the Work of the Government 2016. Accessed October 10, 2018; Li, K., (2017), http://english.www.gov.cn/premier/news/2017/03/16/content_281475597911192.htm, Report on the Work of the Government 2017. Accessed October 10, 2018; Lin, P., Abney, K., Bekey, G.A., (2012) Robot Ethics: The Ethical and Social Implications of Robotics., , Cambridge; London: MIT Press, and, eds; Lin, P., Jenkins, R., Bekey, G.A., (2017) Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence, , New York: Oxford UP, and, eds; Liu, G., Maerkusai yu Habeimasi jishu tongzhi lun zhi bijiao” (Comparison between Marcuse’s and Habermas’ Theories on Technocracy) (2018) Zhongnan Daxue Xuebao (Journal of Central South University), (6), pp. 55-61. , 24; Liu, Y., Deng, Q., Peng, Y., Da shuju shidai shuju zhuquan yu yinsi baohu mianlin de anquan tiaozhan” (The Security Challenge to Data Sovereignty and Privacy Protection in the Era of Big Data) (2019) Guanli Xiandaihua (Modern Management Science), (1), pp. 104-107; Liu, Y., Nier Boziman lun jishuzhuyi” (Neil Postman on Technocracy) (2013) Kexue Jishu Zhexue Yanjiu (Studies in Philosophy of Science and Technology, (6), pp. 52-56. , 30; (2017), http://www.miit.gov.cn/n1146295/n1652858/n1652930/n3757016/c5960820/content.html, Gongye he xinxihuabu guanyu yinfa ‚tuijin xin yi dai rengong zhineng chanye fazhan san nian xingdong jihua (2018–2020 nian) de tongzhi (MIIT on the Release of the ‘Three-Year Action Plan for Promoting Development of a New Generation Artificial Intelligence Industry (2018–2020)’).,. Accessed May 20, 2018; Moon, M.J., The Evolution of E-Government among Municipalities: Rhetoric or Reality? (2002) Public Administration Review, 62 (4), pp. 424-433; (2019), http://www.clii.com.cn/lhrh/hyxx/201906/t20190619_3935070.html, Kejibu: Xin yi dai rengong zhineng zhili yuanze (MOST: Governance Principles of Next Generation AI).,. Accessed July 12, 2019; (2016), http://www.gov.cn/xinwen/2016-07/28/content_5095584.htm, Wangluo yuyue chuzuche jingying fuwu guanli zanxing banfa gongbu (On the Provisional Regulations of the Online Taxi-Hailing Service Sector).,. Accessed March 10, 2017; (2020), http://www.cac.gov.cn/2020-01/15/c_1580625828451576.htm, Jiaotong yunshubu, gongye he xinxihuabu, gong’anbu, shangwubu, shichang guanli zongju, guojia wangxinban guanyu xiugai ‘wangluo yuyue chuzuche jingying fuwu guanli zanxing banfa’ de jueding, 2019 (Resolution by the the Ministry of Transport, the Ministry of Industry and Information Technology, the Ministry of Public Security, the Ministry of Commerce, the State Administration for Market Regulation, and the Cyberspace Administration of the PRC on the Revision of the ‘Provisional Regulations of the Online Taxi-Hailing Service Sector’, 2019).,. Accessed January 30, 2020; (2014), http://www.ndrc.gov.cn/gzdt/201408/t20140829_624003.html, Guanyu yinfa zujin zhihui chengshi jiankang fazhan de zhidao yijian de tongzhi (Guidelines for Promoting the Healthy Development of Smart Cities),. Accessed December 12, 2017; Noesselt, N., A Presidential Signature Initiative: Xiong’an and Governance Modernization under Xi Jinping Journal of Contemporary China, , Forthcoming; O’Neil, C., (2016) Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy., , New York: Crown; Postman, N., (1993) Technopoly: The Surrender of Culture to Technology, , New York: Vintage Books; Qi, H., Li, Z., Putting Precarity Back to Production: A Case Study of Didi Kuaiche Drivers in the City of Nanjing, China Review of Radical Political Economics, , Forthcoming; Rifkin, J., (2011) The Third Industrial Revolution: How Lateral Power is Transforming Energy, the Economy, and the World, , New York: St. Martin’s Press; Schwab, K., (2016), https://www.weforum.org/agenda/2016/01/the-fourth-industrial-revolution-what-it-means-and-how-to-respond/, The Fourth Industrial Revolution: What It Means, How to Respond. Accessed September 18, 2017; (2011), http://www.shanghai.gov.cn/nw2/nw2314/nw2319/nw22396/nw22403/u21aw544325.html, Shanghai shi tuijin zhihui chengshi jianshe 2011–2013 nian xingdong jihua (Shanghai Action Plan 2011–2013 for the Promotion of Smart City Construction).,. Accessed March 15, 2012; (2018), http://www.smartcitiesworldforums.com/news/smart-cities-europe/smart-infrastructure-eu/920-huawei-launches-platform-to-build-smart-city-applications-in-german-city, Huawei Launches Platform to Build Smart City Applications German City. Accessed January 8, 2019; (2017), https://www.scmp.com/news/china/article/1729846/live-li-keqiang-unveils-chinas-annual-work-report, China Unveils Targets For 2015: Li Keqiang’s Speech as it Happened. 2015. Accessed December 12; (2019), https://www.scmp.com/tech/start-ups/article/3013071/one-year-after-two-deaths-plunged-didi-safety-crisis-whats-changed, One Year After Two Deaths Plunged Didi into a Safety Crisis, What’s Changed at China’s Ride-hailing Giant? Accessed August 15, 2019; Takouleu, J.M., (2018), https://www.afrik21.africa/en/africa-huawei-sets-up-a-1-5-billion-fund-to-boost-african-smart-cities/, AFRICA: Huawei Sets Up a $1.5 Billion Fund to Boost African Smart Cities. Accessed September 25, 2019; The Harbinger (2017) Future of Transportation and Ridesharing.”, , http://www.theharbingerchina.com/blog/interview-with-founder-and-ceo-of-didi-cheng-wei-part-ii-future-of, Accessed January 12, 2019; (2019), https://www.whitehouse.gov/presidential-actions/executive-order-maintaining-american-leadership-artificial-intelligence/, Executive Order on Maintaining American Leadership Artificial Intelligence. Accessed March 20, 2019; Vladek, D.C., Machines without Principals: Liability Rules and Artificial Intelligence (2014) Washington Law Review, 89 (1), pp. 117-150; (2019), https://extranet.who.int/dataform/upload/surveys/183439/files/Draft%20Global%20Strategy%20on%20Digital%20Health.pdf, Global Strategy on Digital Health 2020–2024. Accessed September 25, 2019; (2017), https://www.chinadaily.com.cn/business/2017-11/15/content_34573455.htm, China’s Sharing Economy to Hit 4.5t Yuan This Year. Accessed December 20, 2017; (2017), http://www.chinadaily.com.cn/china/19thcpcnationalcongress/2017-11/04/content_34115212.htm, Full Text of Xi Jinping’s Report at the 19th CPC National Congress. Accessed December 12, 2017; (2018), http://english.xiongan.gov.cn/2018-04/21/c_129855751.htm, China Publishes Master Plan for Xiongan New Area. Accessed April 25, 2018; (2019), http://www.xinhuanet.com/english/2019-06/18/c_138152819.htm, China Issues Principles of Next Generation AI Governance. Accessed June 20, 2019; Zhang, J., Hua, X.-S., Huang, J., Shen, X., Chen, J., Zhou, Q., Fu, Z., Zhao, Y., The City Brain: Practice of Large-Scale Artificial Intelligence in the Real World (2019) IET Research Journal, pp. 1-11. , 1, 1; Zuboff, S., (2019) The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power, , London: Profile Books},
document_type={Article},
source={Scopus},
}

@ARTICLE{Behdadi2020,
author={Behdadi, D. and Munthe, C.},
title={A Normative Approach to Artificial Moral Agency},
journal={Minds and Machines},
year={2020},
doi={10.1007/s11023-020-09525-8},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085308640&doi=10.1007%2fs11023-020-09525-8&partnerID=40&md5=37802c7642e162b5f4afbaa3e941953c},
abstract={This paper proposes a methodological redirection of the philosophical debate on artificial moral agency (AMA) in view of increasingly pressing practical needs due to technological development. This “normative approach” suggests abandoning theoretical discussions about what conditions may hold for moral agency and to what extent these may be met by artificial entities such as AI systems and robots. Instead, the debate should focus on how and to what extent such entities should be included in human practices normally assuming moral agency and responsibility of participants. The proposal is backed up by an analysis of the AMA debate, which is found to be overly caught in the opposition between so-called standard and functionalist conceptions of moral agency, conceptually confused and practically inert. Additionally, we outline some main themes of research in need of attention in light of the suggested normative approach to AMA. © 2020, The Author(s).},
author_keywords={Artificial agency;  Artificial intelligence;  Artificial moral agent;  Consciousness;  Demarcation problem;  Machine consciousness;  Machine ethics;  Moral agency;  Moral machine;  Moral responsibility;  Moral status},
keywords={Artificial intelligence, AI systems;  Human practices;  Technological development, Philosophical aspects},
references={Adams, T.K., Future warfare and the decline of human decisionmaking (2001) Parameters, 31 (4), pp. 57-71; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental & Theoretical Artificial Intelligence, 12 (3), pp. 251-261; Anderson, S.L., Asimov’s “three laws of robotics” and machine metaethics (2008) AI & SOCIETY, 22 (4), pp. 477-493; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), p. 15; Anderson, M., Anderson, S.L., Armen, C., Towards machine ethics (2004) Proceedings of AAAI; Annas, J., (2011) Intelligent virtue, , Oxford University Press, Oxford; Arkin, R.C., The case for ethical autonomy in unmanned systems (2010) Journal of Military Ethics, 9 (4), pp. 332-341; Asaro, P.M., What should we want from a robot ethic? (2006) International Review of Information Ethics, 6 (12), pp. 9-16; Asimov, I., Runaround (1942) Astounding Science Fiction, 29 (1), pp. 94-103; Bahrammirzaee, A., A comparative survey of artificial intelligence applications in finance: artificial neural networks, expert system and hybrid intelligent systems (2010) Neural Computing and Applications, 19 (8), pp. 1165-1195; Beavers, A.F., (2011) Moral Machines and the Threat of Ethical Nihilism, p. 333. , The ethical and social implications of robotics, Robot ethics; Björnsson, G., Persson, K., The explanatory component of moral responsibility (2012) Noûs, 46 (2), pp. 326-354; Björnsson, G., Persson, K., A unified empirical account of responsibility judgments (2013) Philosophy and Phenomenological Research, 87 (3), pp. 611-639; Bringsjord, S., (1992) What Robots can and can’t be, , Kluwer Academic, NEW York; Bringsjord, S., Ethical robots: the future can heed us (2007) AI & Society, 22 (4), pp. 539-550; Bryson, J.J., (2010) Robots should be slaves, pp. 63-74. , Key social, psychological, ethical and design issues, Close Engagements with Artificial Companions; Champagne, M., Tonkens, R., Bridging the responsibility gap in automated warfare (2013) Philosophy & Technology, 28 (1), pp. 125-137; Christman, J., Autonomy in moral and political philosophy (2015) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/spr2015/entries/autonomy-moral, E. N. Zalta (Ed.); Coeckelbergh, M., Virtual moral agency, virtual moral responsibility: on the moral significance of the appearance, perception, and performance of artificial agents (2009) AI & Society, 24 (2), pp. 181-189; Coeckelbergh, M., Moral appearances: emotions, robots, and human morality (2010) Ethics and Information Technology, 12 (3), pp. 235-241; Danaher, J., (2019) Automation and Utopia, , Harvard University Press, Cambridge, Mass; Davis, M., Ain’t no one here but us social forces”: constructing the professional responsibility of engineers (2012) Science and Engineering Ethics, 18 (1), pp. 13-34; Dennett, D.C., Mechanism and responsibility (1973) Essays on freedom of action, pp. 157-184. , Honderich Ed, (ed), Routledge and Kegan Paul, Abingdon; Dennett, D.C., Three kinds of intentional psychology (1987) The intentional stance, pp. 43-68. , Dennett DC, (ed), The MIT Press, Cambridge; Dodig-Crnkovic, G., Çürüklü, B., Robots: ethical by design (2011) Ethics and Information Technology, 14 (1), pp. 61-71; Dodig-Crnkovic, G., Persson, D., Sharing moral responsibility with robots: A pragmatic approach (2008) Frontiers in Artificial Intelligence And Applications, 173, p. 165; Dreyfus, H.L., Hubert, L., (1992) What computers still can’t do: A critique of artificial reason, , MIT press, Cambridge; Eshleman, A., Moral Responsibility (2014) The Stanford Encyclopedia of Philosophy (Summer 2014 Ed.)., , http://plato.stanford.edu/archives/sum2014/entries/moral-responsibility/, E. N. Zalta (Ed.); Etzioni, A., Pros and cons of autonomous weapons systems (with Oren Etzioni) (2018) Happiness is the wrong metric, pp. 253-263. , Springer, Cham; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds and Machines, 14 (3), pp. 349-379; Friedman, B., Kahn, P.H., Human agency and responsible computing: Implications for computer system design (1992) Journal of Systems and Software, 17 (1), pp. 7-14; Gerdes, A., Øhrstrøm, P., Issues in robot ethics seen through the lens of a moral Turing test (2015) Journal of Information, Communication and Ethics in Society, 13 (2), pp. 98-109; Gladden, M.E., The diffuse intelligent other: An ontology of nonlocalizable robots as moral and legal actors (2016) Social robots: Boundaries, potential, challenges, pp. 177-198. , Nørskov M, (ed), Ashgate, Burlington, VT; Grodzinsky, F.S., Miller, K.W., Wolf, M.J., The ethics of designing artificial agents (2008) Ethics and Information Technology, 10 (2-3), pp. 115-121; Gunkel, D.J., A vindication of the rights of machines (2014) Philosophy & Technology, 27 (1), pp. 113-132; Häggström, H., (2016) Here be dragons: science, technology and the future of humanity, , Oxford University Press, Oxford; Hellström, T., On the moral responsibility of military robots (2012) Ethics and Information Technology, 15 (2), pp. 99-107; (2019) Ethics guidelines for trustworthy AI, , https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai, European Commission. Retrieved 2020-04-05 from; Himma, K.E., Artificial agency, consciousness, and the criteria for moral agency: what properties must an artificial agent have to be a moral agent? (2009) Ethics and Information Technology, 11 (1), pp. 19-29; Holroyd, J., Two ways of socializing moral responsibility: Circumstantialism versus scaffolded-responsiveness (2018) Social Dimensions of Moral Responsibility, pp. 137-162. , Hutchison K, Mackenzie C, Oshana M, (eds), Oxford University Press, Oxford; Irrgang, B., Ethical acts in robotics (2006) Ubiquity, 7, p. 34; Johansson, L., The functional morality of robots (2010) International Journal of Technoethics, 1 (4), pp. 65-73; Johnson, D., Computer systems: Moral entities but not moral agents (2006) Ethics and Information Technology, 8 (4), pp. 195-204; Johnson, D.G., Miller, K.W., Un-making artificial moral agents (2008) Ethics and Information Technology, 10 (2-3), pp. 123-133; Johnson, D.G., Powers, T.M., Computer systems and responsibility: A normative look at technological complexity (2005) Ethics and Information Technology, 7 (2), pp. 99-107; Johnson, D., Powers, T.M., Computers as surrogate agents (2008) Information technology and moral philosophy, 2008, pp. 251-269; Kolodny, N., John, A.B., Instrumental rationality (2016) Stanford Encyclopedia of Philosophy., , http://plato.stanford.edu/archives/spr2016/entries/rationality-instrumental/, (,)., In E. N. Zalta (Ed.); Korsgaard, C.M., Fellow creatures: Kantian ethics and our duties to animals (2004) Tanner Lectures on Human Values, 25, p. 77; Lin, P., Bekey, G., Abney, K., (2008) Autonomous military robotics: Risk, ethics, and design, , California Polytechnic State Univ San Luis Obispo, DTIC Document; Lokhorst, G.-J., van den Hoven, J., Responsibility for military robots (2012) Robot ethics: The ethical and social implications of robotics, pp. 145-156. , Lin IP, Bekey GA, Abney K, (eds), MIT Press, Cambridge; Macnamara, C., (2015) Blame, communication, and morally responsible agency, p. 211. , New Essays, The Nature of Moral Responsibility; Matheson, B., (2012) Manipulation, moral responsibility, and machines, p. 11. , AI, Ethics and Moral Responsibility, The Machine Question; Matthias, A., The responsibility gap: Ascribing responsibility for the actions of learning automata (2004) Ethics and Information Technology, 6 (3), pp. 175-183; McDermott, D., (2008) Why Ethics is a High Hurdle for AI, , Citeseer; McGeer, V., Mind-making practices: the social infrastructure of self-knowing agency and responsibility (2015) Philosophical Explorations, 18 (2), pp. 259-281; McKennajustin, M.A.C.D., Compatibilism (2015) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/sum2015/entries/compatibilism/, E. N. Zalta (Ed.); Moor, J.M., The nature, importance, and difficulty of machine ethics (2006) Intelligent Systems, IEEE, 21 (4), pp. 18-21; Moor, J., Four kinds of ethical robots (2009) Philosophy Now, 72, pp. 12-14; Musen, M.A., Middleton, B., Greenes, R.A., Clinical decision-support systems (2014) Biomedical informatics, pp. 643-674. , Springer, Berlin; Nadeau, J.E., (2006) Only androids can be ethical (Thinking about android epistemology), , (ed), MIT Press, Cambridge; Nagel, T., What is it like to be a bat? (1974) The philosophical review, pp. 435-450; Nagenborg, M., Artificial moral agents: an intercultural perspective (2007) International Review of Information Ethics, 7 (9), pp. 129-133; Noone, G.P., Noone, D.C., The debate over autonomous weapons systems (2015) Case W. Res. J. Int’l L., 47, p. 25; Noorman, M., Responsibility practices and unmanned military technologies (2014) Science and Engineering Ethics, 20 (3), pp. 809-826; Noorman, M., Johnson, D.G., Negotiating autonomy and responsibility in military robots (2014) Ethics and Information Technology, 16 (1), pp. 51-62; Nyholm, S., Attributing Agency to Automated Systems: Reflections on Human-Robot Collaborations and Responsibility-Loci (2018) Science and Engineering Ethics, 24 (4), pp. 1201-1219; Nyhom, S., (2020) Humans and robots: Ethics, agency, and anthropomorphism, , Rowman & Littlefield, New York; O’Connor, T., (2016) Free Will, , http://plato.stanford.edu/archives/sum2016/entries/freewill, E. N. Zalta (Ed.); Parthemore, J., Whitby, B., What makes any agent a moral agent? Reflections on machine consciousness and moral agency (2013) International Journal of Machine Consciousness, 5 (2), pp. 105-129; Picard, R.W., (1997) Affective computing, 252. , MIT Press, Cambridge; Pontier, M., Hoorn, J., Toward machines that behave ethically better than humans do (2012) Proceedings of the Annual Meeting of the Cognitive Science Society, 34 (34). , (Vol, No,); Powers, T.M., Prospects for a Kantian machine (2006) Intelligent Systems, IEEE, 21 (4), pp. 46-51; Powers, T.M., On the moral agency of computers (2013) Topoi, 32 (2), pp. 227-236; Purves, D., Jenkins, R., Strawser, B.J., Autonomous machines, moral judgment, and acting for the right reasons (2015) Ethical Theory and Moral Practice, 18 (4), pp. 851-872; Samuelsson, L., On the demarcation problem and the possibility of environmental ethics: A refutation of “a refutation of environmental ethics (2010) Environmental Ethics, 32 (3), pp. 247-265; Schulzke, M., Autonomous weapons and distributed responsibility (2013) Philosophy & Technology, 26 (2), pp. 203-219; Shaw, E., Pereboom, D., Caruso, G.D., (2019) Free will skepticism in law and society, , (eds), Cambridge University Press, Cambridge; Sheikhtaheri, A., Sadoughi, F., Dehaghi, Z.H., Developing and using expert systems and neural networks in medicine: a review on benefits and challenges (2014) Journal of Medical Systems, 38 (9), p. 110; Shen, S., The curious case of human-robot morality (2011) Proceedings of the 6Th International Conference on Human-Robot Interaction, pp. 249-250. , ACM; Singer, P., (2011) Practical ethics, , 3, Cambridge University Press, Cambridge; Singer, A.E., (2013) Corporate and Artificial Moral Agency, pp. 4525-4531; Sliwa, P., Moral Worth and Moral Knowledge (2015) Philosophy and Phenomenological Research; Sparrow, R., Killer robots (2007) Journal of applied philosophy, 24 (1), pp. 62-77; Stahl, B.C., Information, ethics, and computers: The problem of autonomous moral agents (2004) Minds and Machines, 14 (1), pp. 67-83; Stahl, B.C., Responsible computers? A case for ascribing quasi-responsibility to computers independent of personhood or agency (2006) Ethics and Information Technology, 8 (4), pp. 205-213; Sullins, J.P., When is a robot a moral agent? (2006) International Review of Information Ethics, 6 (12), pp. 23-30; Sullins, J.P., RoboWarfare: can robots be more ethical than humans on the battlefield? (2010) Ethics and Information Technology, 12 (3), pp. 263-275; Swiatek, M.S., Intending to err: the ethical challenge of lethal, autonomous systems (2012) Ethics and Information Technology, 14 (4), pp. 241-254; Tonkens, R., A challenge for machine ethics (2009) Minds and Machines, 19 (3), pp. 421-438; Tonkens, R., Out of character: on the creation of virtuous machines (2012) Ethics and Information Technology, 14 (2), pp. 137-149; Torrance, S., Ethics and consciousness in artificial agents (2007) AI & SOCIETY, 22 (4), pp. 495-521; Vargas, M., (2013) Building better beings: A theory of moral responsibility, , OUP Oxford, Oxford; Verbeek, P.P., (2011) Moralizing technology: Understanding and designing the morality of things, , University of Chicago Press, Chicago; Versenyi, L., Can robots be moral? (1974) Ethics, 84 (3), pp. 248-259; Veruggio, G., Operto, F., Roboethics: Social and ethical implications of robotics (2008) Springer handbook of robotics, pp. 1499-1524. , Springer, Berlin; Wallace, R.J., Practical Reason (2014) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/sum2014/entries/practical-reason/, E. N. Zalta; Wallach, W., Allen, C., (2008) Moral machines: Teaching robots right from wrong, , Oxford University Press, Oxford; Wang, F.-Y., Let’s Go: From AlphaGo to parallel intelligence (2016) Science & Technology Review, 34 (7), pp. 72-74; Warren, M.A., (1997) Moral status: Obligations to persons and other living things, , Clarendon Press, Oxford; Yampolskiy, R.V., Artificial intelligence safety engineering: Why machine ethics is a wrong approach (2013) Philosophy and theory of artificial intelligence, pp. 389-396. , Springer, Berlin},
document_type={Article},
source={Scopus},
}

@ARTICLE{Swanepoel2020,
author={Swanepoel, D.},
title={The possibility of deliberate norm-adherence in AI},
journal={Ethics and Information Technology},
year={2020},
doi={10.1007/s10676-020-09535-1},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084970526&doi=10.1007%2fs10676-020-09535-1&partnerID=40&md5=66177d9c6e26998be0ebf3b14e5cc2b2},
abstract={Moral agency status is often given to those individuals or entities which act intentionally within a society or environment. In the past, moral agency has primarily been focused on human beings and some higher-order animals. However, with the fast-paced advancements made in artificial intelligence (AI), we are now quickly approaching the point where we need to ask an important question: should we grant moral agency status to AI? To answer this question, we need to determine the moral agency status of these entities in society. In this paper I argue that to grant moral agency status to an entity, deliberate norm-adherence must be possible (at a minimum). In this paper I argue that, under the current status quo, AI systems are unable to meet this criterion. The novel contribution this paper makes to the field of machine ethics is first, to provide at least two criteria with which we can determine moral agency status. We do this by determining the possibility of deliberate norm-adherence through examining the possibility of deliberate norm-violation. Second, to show that establishing moral agency in AI suffer the same pitfalls as establishing moral agency in constitutive accounts of agency. © 2020, Springer Nature B.V.},
author_keywords={Artificial intelligence;  Constitutivism;  Moral agency;  Norm-adherence;  Norm-violation},
keywords={Information technology, AI systems;  Current status;  Higher-order;  Human being;  Norm violation, Social sciences},
references={Bratman, M., (2007) Structures of agency, , Oxford University Press, New York; Castelfranchi, C., Dignum, F., Jonker, C., Treur, J., (2000) Deliberative normative agents: Principles and architecture. Intelligent agents, pp. 364-378. , Springer, Berlin; Coeckelbergh, M., Virtual moral agency, virtual moral responsibility: On the moral significance of the appearance, perception, and performance of artificial agents (2009) AI and Society, 1, pp. 10-25; Davidson, D., Actions, reasons, and causes (1963) The Journal of Philosophy, 60 (23), pp. 685-700; Enoch, D., Agency, Shmagency: Why normativity won't come from what is constitutive of action (2006) Philosophical Review, 115 (2), pp. 31-60; Ferrero, L., Constitutivism and the inescapability of agency (2009) Oxford Studies in Metaethics, 4, pp. 303-333; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds and Machines, 14, pp. 349-379; Frankfurt, H., Alternative possibilities and moral responsibility (1969) Journal of Philosophy, 66 (23), pp. 829-839; Gunkel, D., (2012) The machine question: Critical perspectives on AI, robots, and ethics, , MIT Press, Cambridge; Hansson, S., (1994) Decision theory: A brief introduction, , Royal Institute of Technology, Stockholm; Huffer, B., Actions and outcomes: Two aspects of agency (2007) Synthese, 157, pp. 241-265; Johnson, A., Hathcock, D., ; Kant, I., (1785) Groundwork for the Metaphysics of Morals, , A. Wood, Groundwork for the metaphysics of morals, New York; Katsafanas, P., (2013) Agency and the foundation of ethics: Nietzschean constitutivism, , Oxford University Press, Oxford; Korsgaard, C., (2008) The constitution of agency. Essays on practical reason and moral psychology, , Oxford University Press, Oxford; Korsgaard, C., (2009) Self-constitution: Agency, identity, and integrity, , Oxford University Press, Oxford; McKenna, M., Coates, J., Compatibilism. [Online]. Retrieved March 25, 2019 (2018) From, , https://plato.stanford.edu/archives/win2018/entries/compatibilism/; Moor, J., The nature, importance, and difficulty of machine ethics (2011) Anderson & Anderson, pp. 13-20. , Ethics M, (ed), Cambridge University Press, New York; Muller, V., Ethics of AI and robotics. Retrieved August 15, 2019 (2019) From, , https://www.researchgate.net/project/Ethics-of-AI-and-Robotics-for-Stanford-Encyclopedia-of-Philosophy; Railton, P., On the hypothetical and non-hypothetical in reasoning about belief and action (2003) Ethics and practical reason, pp. 53-80. , Clarendon Press, Oxford; Rosati, C., Naturalism, normativity, and the open argument question (1995) Nous, 29 (1), pp. 46-70; Rosati, C., Agency and the open question argument (2003) Ethics, 113 (3), pp. 490-527; Rosati, C., Agents and "shmagents" an essay on agency and normativity (2016) Oxford studies in metaethics 11, pp. 182-213. , Shafer-Landau R, (ed), Oxford University Press, Oxford; Tiffany, E., Why be an agent? (2012) Australasia Journal of Philosophy, 90 (2), pp. 223-233; Velleman, D., The possibility of practical reason (1996) Ethics, 106 (4), pp. 694-726; Velleman, D., Replies to discussion on the possibility of practical reason (2004) Philosophical Studies, 121, pp. 225-238; Warfield, T., Causal determination and human freedom is incompatible: A new argument for incompatibilism (2000) Nous, 34, pp. 167-180},
document_type={Article},
source={Scopus},
}

@ARTICLE{Donhauser2020,
author={Donhauser, J. and van Wynsberghe, A. and Bearden, A.},
title={Steps Toward an Ethics of Environmental Robotics},
journal={Philosophy and Technology},
year={2020},
doi={10.1007/s13347-020-00399-3},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084362385&doi=10.1007%2fs13347-020-00399-3&partnerID=40&md5=e6def42f985075f2eaa54a171a61a615},
abstract={New robotics technologies are being used for environmental research, and engineers and ecologists are exploring ways of integrating an array of different sorts of robots into ecosystems as a means of responding to the unprecedented environmental changes that mark the onset of the Anthropocene. These efforts introduce new roles that robots may play in our environments, potentially crucial new forms of human dependence on such robots, and new ways that robots can enhance life quality and environmental health. These efforts at once introduce a variety of new and unprecedented ethical concerns. This work uses a previously developed functional taxonomy of kinds of environmental robots to develop a list of key ethical questions to push forward the sub-field and study of Environmental Robot Ethics. By identifying unique concerns raised by the different sorts of existing environmental robotics technologies, this paper aims to provide resources for further critical analysis of the ethical issues and tradeoffs environmental robots present. © 2020, Springer Nature B.V.},
author_keywords={Anthropocene;  Ecological robots;  Environmental justice;  Environmental robotics;  Robot ethics;  Sustainability},
references={Aravind, K.R., Raja, P., Pérez-Ruiz, M., Task-based agricultural mobile robots in arable farming: A review (2017) Spanish Journal of Agricultural Research, 15 (1), pp. 01-02; Asaro, P., What should we want from a robot ethic? (2006) International Review of Information Ethics, 6, pp. 8-16; Autonomous Flying Microrobots (Robobees) (2017) Wyss Institute, , https://wyss.harvard.edu/technology/autonomous-flying-microrobots-robobees/, Retrieved from; Blersch, D.M., (2010) Towards an Autonomous Algal Turf Scrubber: Development of an Ecologically-Engineered Technoecosystem; Burger, A.E., Shaffer, S.A., Application of tracking and data-logging technology in research and conservation of seabirds (2008) Auk, 125, pp. 253-264; Burken, J., Schnoor, J., Predictive relationships for uptake of organic contaminants by hybrid poplar trees (1998) Environmental Science and Technology, 32 (21), pp. 3379-3385; Cai, T.T., Montague, C.L., Davis, J.S., The maximum power principle: An empirical investigation (2006) Ecological Modelling, 190 (3), pp. 317-335; Capurro, R., (2009) Ethics and robotics, pp. 117-123. , Capurro R, Nagenborg M, (eds), IOS Press, Amsterdam; Chechetka, S.A., Yu, Y., Tange, M., Miyako, E., Materially engineered artificial pollinators (2017) Chem, 2 (2), pp. 224-239; Chen, Y., Wang, H., Helbling, E.F., Jafferis, N.T., Zufferey, R., Ong, A., A biologically inspired, flapping-wing, hybrid aerial-aquatic microrobot (2017) Science robotics, 2 (11), p. eaao5619; Choi-Fitzpatrick, A., Drones for good: Technological innovations, social movements, and the state (2014) Journal of International Affairs, pp. 19-36; Clark, O.G., Kok, R., Lacroix, R., Mind and autonomy in engineered biosystems (1999) Engineering Applications of Artificial Intelligence, 12 (3), pp. 389-399; Clark, C.M., Forney, C., Manii, E., Shinzaki, D., Gage, C., Farris, M., Tracking and following a tagged leopard shark with an autonomous underwater vehicle (2013) Journal of Field Robotics, 30 (3), pp. 309-322; Dhariwal, A., Sukhatme, G.S., Requicha, A.A.G., Bacterium-inspired robots for environmental monitoring. Paper presented at the Robotics and Automation, 2004 (2004) Proceedings. ICRA'04. 2004 IEEE International Conference On.; Ditmer, M.A., Vincent, J.B., Werden, L.K., Tanner, J.C., Laske, T.G., Iaizzo, P.A., Bears show a physiological but limited behavioral response to unmanned aerial vehicles (2015) Current Biology, 25 (17), pp. 2278-2283; Dunbabin, M., Marques, L., Robots for environmental monitoring: Significant advancements and applications (2012) IEEE Robotics and Automation Magazine, 19 (1), pp. 24-39; Elliott, O., Gray, S., McClay, M., Nassief, B., Nunnelley, A., Vogt, E., Design and manufacturing of high surface area 3D-printed media for moving bed bioreactors for wastewater treatment (2017) Journal of Contemporary Water Research & Education, 160 (1), pp. 144-156; Grémillet, D., Puech, W., Véronique, G., Thierry, B., Le, Y., Maho. (2012). Robots in ecology: Welcome to the machine. Open (2012) Journal of Ecology; Griggs, M.B., Sorry, but these pollinating robots can’t replace bees (2017) Popular Science, , https://www.popsci.com/forgotten-gel-could-help-future-robot-pollination-bee-drone, Retrieved from; Hart, J.K., Martinez, K., Environmental sensor networks: A revolution in the earth system science? (2006) Earth-Science Reviews, 78 (3), pp. 177-191; Hegde, M., Kim, J., Hong, S.H., Wood, T.K., Jayaraman, A., Designer biofilms (2011) Paper Presented at the 15Th International Conference on Miniaturized Systems for Chemistry and Life Sciences, Seattle.; Hodgson, J.C., Baylis, S.M., Mott, R., Herrod, A., Clarke, R.H., Precision wildlife monitoring using unmanned aerial vehicles (2016) Scientific Reports, p. 6; (2020) Robots and Robotic Devices — Coordinate Systems and Motion Nomenclatures, , https://www.iso.org/obp/ui/#iso:std:iso:8373:ed-2:v1:en, Accessed 17 Apr; Ivošević, B., Han, Y.-G., Cho, Y., Kwon, O., The use of conservation drones in ecology and wildlife research (2015) Ecology and Environment, 38, pp. 113-118; Kangas, P., (2004) Ecological Engineering: Principles and Practice, , CRC Press; Kardel, K., Carrano, A.L., Blersch, D.M., Kaur, M., Preliminary development of 3D-printed custom substrata for benthic algal biofilms (2015) 3D Printing and Additive Manufacturing, 2 (1), pp. 12-19; Klein, B.A., Stein, J., Taylor, R.C., Robots in the service of animal behavior (2012) Communicative & Integrative Biology, 5 (5), pp. 466-472; Koh, L.P., Wich, S.A., Dawn of drone ecology: Low-cost autonomous aerial vehicles for conservation (2012) Tropical Conservation Science, 5 (2), pp. 121-132; Lam, T.L., Xu, Y., (2012) Tree Climbing Robot: Design, Kinematics and Motion Planning, 78. , Springer; Lampton, C., (1993) Nanotechnology Playhouse: Building Machines from Atoms, , Waite Group Press; Leibovici, D.G., Rosser, J.F., Hodges, C., Evans, B., Jackson, M.J., Higgins, C.I., On data quality assurance and conflation entanglement in crowdsourcing for environmental studies (2017) ISPRS International Journal of Geo-Information, 6 (3), p. 78; Lin, P., Abney, K., Bekey, G.A., (2011) Robot ethics: The ethical and social implications of robotics, , MIT Press, Cambridge; https://robotsise.com/lionfish-project/, The Lionfish Project: This Invasive Predator From The Pacific Is Rapidly Destroying Our Reefs.) (n.d.). Robots in the Service of the Environment. Retrieved 5/24/2017, from; Maho, L., Yvon, W., Jason, D., Hanuise, N., Pereira, L., Boureau, M., Brucker, M., Rovers minimize human disturbance in research on wild animals (2014) Nature Methods, 11 (12), pp. 1242-1244; Menon, C., Murphy, M., Sitti, M., Gecko inspired surface climbing robots (2004) Paper Presented at the 2004 IEEE International Conference on Robotics and Biomimetics; Mineraud, J., Lancerin, F., Balasubramaniam, S., Conti, M., Tarkoma, S., You are AIRing too much: Assessing the privacy of users in crowdsourcing environmental data (2015) Paper Presented at the Trustcom/Bigdatase/Ispa, 2015 IEEE; Robots in the Service of the Environment, , https://robotsise.com/mission-vision/, Retrieved 5/25/17, from; Myers, J., Clark, L.B., Culture conditions and the development of the photosynthetic mechanism: II. An apparatus for the continuous culture of Chlorella (1944) The Journal of General Physiology, 28 (2), p. 103; Odum, H.T., (1993) Ecological and General Systems: An Introduction to Systems Ecology, , University Press of Colorado; Olivito, J., Beyond the fourth amendment: Limiting drone surveillance through the constitutional right to informational privacy (2013) Ohio State Law Journal, 74 (4), pp. 669-701; Parrott, L., (1996) The Ecocyborg Project: A Model of an Artificial Ecosystem, , McGill University; University of Maryland: Department of Environmental Science & Technology, , https://enst.umd.edu/people/faculty/patrick-kangas/past-projects, Retrieved 5/25/2017, from; Peckham, S.H., Maldonado Diaz, D., Walli, A., Ruiz, G., Crowder, L.B., Nichols, W.J., Small-scale fisheries bycatch jeopardizes endangered Pacific loggerhead turtles (2007) PLoS One, 2 (10); Petersen, J.E., Adding artificial feedback to a simple aquatic ecosystem: The cybernetic nature of ecosystems revisited (2001) Oikos, pp. 533-547; Wyss Institute, , https://wyss.harvard.edu/technology/programmable-robot-swarms/, Retrieved 5/25/2017, 2017, from; Rundel, P.W., Graham, E.A., Allen, M.F., Fisher, J.C., Harmon, T.C., Environmental sensor networks in ecological research (2009) New Phytologist, 182 (3), pp. 589-607; Rutz, C., Hays, G.C., New frontiers in biologging science (2009) The Royal Society, pp. 289-292; Siegwart, R., Nourbakhsh, I.R., Scaramuzza, D., Autonomous mobile robots (2004) Massachusetts Institute of Technology, , http://mars.umhb.edu/*wgt/cisc3361/redbook/5b_Summary_Add-on_Slides.pdf, Accessed 8 Oct 2017; Succuro, J., McDonald, S., Lu, C., Phytoremediation: The wave of the future (2009) Recent Advances in Plant Biotechnology, pp. 119-135; Sullins, J.P., Introduction: Open questions in roboethics (2011) Philosophy & Technology, 24 (3), pp. 233-238; (2017) Robots in the Service of the Environment, , https://robotsise.com/todays-eco-robots/; Todd, J., Ecological engineering, living machines and the visionary landscape (1991) Ecological Engineering for Wastewater Treatment, pp. 335-343. , C. Etnier and B. Guterstam (eds.), BokSkogen, Stensurd Folk College, Trosh, Sweden; Todd, N.J., Todd, J., (1994) From Eco-Cities to Living Machines: Principles of Ecological Design: North Atlantic Books; Tripathi, R., Srivastava, S., Mishra, S., Dwivedi, S., 7 strategies for phytoremediation of environmental contamination (2008) Developments in Physiology, Biochemistry and Molecular Biology of Plants, pp. 175-220. , In B. Bose & A. Hemantaranjan (Eds.), New India Publishing; Vangronsveld, J., Herzig, R., Weyens, N., Boulet, J., Adriaensen, K., Ruttens, A., Phytoremediation of contaminated soils and groundwater: Lessons from the field (2009) Environmental Science and Pollution Research, 16 (7), pp. 765-794; Vas, E., Lescroël, A., Duriez, O., Boguszewski, G., Grémillet, D., Approaching birds with drones: First experiments and ethical guidelines (2015) Biology Letters, 11 (2), p. 20140754; Volovelsky, U., (2016) Civilian Use of Drones as a Test Case for the Right to Privacy: An Israeli Perspective the Future of Drone Use, pp. 261-288. , Springer; Wadhams, P., Wilkinson, J.P., McPhail, S.D., A new view of the underside of Arctic sea ice (2006) Geophysical Research Letters, 33 (4); West, G., Drone on: The sky’s the limit-if the FAA will get out of the way (2015) Foreign Affairs, 94 (3), pp. 90-97; Whitcomb, L.L., Underwater robotics: Out of the research laboratory and into the field (2000) In IEEE International Conference on Paper Presented at the Robotics and Automation, Proceedings. ICRA’00; Willcox, B.K., Aizen, M.A., Cunningham, S.A., Mayfield, M.M., Rader, R., Deconstructing pollinator community effectiveness (2017) Current Opinion in Insect Science, 21, pp. 98-104; Yaghoubi, S., Akbarzadeh, N.A., Bazargani, S.S., Bazargani, S.S., Bamizan, M., Asl, M.I., Autonomous robots for agricultural tasks and farm assignment and future trends in agro robots (2013) International Journal of Mechanical and Mechatronics Engineering, 13 (3), pp. 1-6; Yoerger, D.R., Kelley, D.S., Delaney, J.R., Fine-scale three-dimensional mapping of a deep-sea hydrothermal vent site using the Jason ROV system (2000) The International Journal of Robotics Research, 19 (11), pp. 1000-1014},
document_type={Article},
source={Scopus},
}

@ARTICLE{Haas2020,
author={Haas, J.},
title={Moral Gridworlds: A Theoretical Proposal for Modeling Artificial Moral Cognition},
journal={Minds and Machines},
year={2020},
doi={10.1007/s11023-020-09524-9},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084153579&doi=10.1007%2fs11023-020-09524-9&partnerID=40&md5=3aa27a3d14d7f2a9bd1a5be6c260455b},
abstract={I describe a suite of reinforcement learning environments in which artificial agents learn to value and respond to moral content and contexts. I illustrate the core principles of the framework by characterizing one such environment, or “gridworld,” in which an agent learns to trade-off between monetary profit and fair dealing, as applied in a standard behavioral economic paradigm. I then highlight the core technical and philosophical advantages of the learning approach for modeling moral cognition, and for addressing the so-called value alignment problem in AI. © 2020, Springer Nature B.V.},
author_keywords={Artificial intelligence;  Fairness;  Machine ethics;  Moral AI;  Moral cognition;  Moral psychology;  Reinforcement learning},
references={Adamson, G., Havens, J.C., Chatila, R., Designing a value-driven future for ethical autonomous and intelligent systems (2019) Proceedings of the IEEE, 107 (3), pp. 518-525; Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics and Information Technology, 7 (3), pp. 149-155; Allen, C., Wallach, W., Moral machines: Contradiction in terms or abdication of human responsibility (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 55-68. , Cambridge, MIT Press; Alvard, M.S., The ultimatum game, fairness, and cooperation among big game hunters (2004) Foundations of human sociality, pp. 413-435. , Henrich J, Boyd R, Bowles S, Camerer C, Fehr E, Gintis H, (eds), Oxford University Press, Oxford; Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., Mané, D., (2016) Concrete Problems in AI Safety.; Anderson, M., Anderson, S.L., GenEth: a general ethical dilemma analyzer (2018) Paladyn, Journal of Behavioral Robotics, 9 (1), pp. 337-357; Anderson, M., Anderson, S.L., Armen, C., MedEthEx: A prototype medical ethics advisor (2006) Proceedings of the National Conference on Artificial Intelligence, 21 (2), p. 1759. , Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press, 1999; Anderson, M., Anderson, S.L., Berenz, V., A value-driven eldercare robot: Virtual and physical instantiations of a case-supported principle-based behavior paradigm (2019) Proceedings of the IEEE, 107 (3), pp. 526-540; Arnold, T., Kasenberg, D., Scheutz, M., (2017) Value Alignment Or misalignment—What Will Keep Systems Accountable?, , In; Barocas, S., Selbst, A.D., Big data’s disparate impact (2016) California Law Review, 104, p. 671; Bechtel, W., Mundale, J., Multiple realizability revisited: Linking cognitive and neural states (1999) Philosophy of Science, 66 (2), pp. 175-207; Bengio, Y., LeCun, Y., Scaling learning algorithms towards AI (2007) Large-scale Kernel Machines, 34 (5), pp. 1-41; Berns, G.S., Bell, E., Capra, C.M., Prietula, M.J., Moore, S., Anderson, B., Ginges, J., Atran, S., The price of your soul: Neural evidence for the non-utilitarian representation of sacred values (2012) Philosophical Transactions of the Royal Society B: Biological Sciences, 367 (1589), pp. 754-762; Bigman, Y.E., Waytz, A., Alterovitz, R., Gray, K., Holding robots responsible: The elements of machine morality (2019) Trends in Cognitive Sciences, 23 (5), pp. 365-368; Boksem, M.A., De Cremer, D., Fairness concerns predict medial frontal negativity amplitude in ultimatum bargaining (2010) Social Neuroscience, 5 (1), pp. 118-128; Bonnefon, J.F., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2016) Science, 352 (6293), pp. 1573-1576; Borenstein, J., Arkin, R., Berkich, D., D’Alfonso, M.V., Robots, ethics, and intimacy: The need for scientific research (2019) On the Cognitive, Ethical, and Scientific Dimensions of Artificial Intelligence, 134, pp. 299-309; Botvinick, M., Ritter, S., Wang, J.X., Kurth-Nelson, Z., Blundell, C., Hassabis, D., Reinforcement learning, fast and slow (2019) Trends in Cognitive Sciences; Bremner, P., Dennis, L.A., Fisher, M., Winfield, A.F., On proactive, transparent, and verifiable ethical reasoning for robots (2019) Proceedings of the IEEE, 107 (3), pp. 541-561; Brown, D., (1991) Human universals, , McGraw-Hill, New York; Brumbaugh, S.M., Sanchez, L.A., Nock, S.L., Wright, J.D., Attitudes toward gay marriage in states undergoing marriage law transformation (2008) Journal of Marriage and Family, 70 (2), pp. 345-359; Cave, S., Nyrup, R., Vold, K., Weller, A., Motivations and risks of machine ethics (2018) Proceedings of the IEEE, 107 (3), pp. 562-574; Cervantes, J.A., López, S., Rodríguez, L.F., Cervantes, S., Cervantes, F., Ramos, F., Artificial moral agents: A survey of the current status (2019) Science and Engineering Ethics; Corradi-Dell’Acqua, C., Civai, C., Rumiati, R.I., Fink, G.R., Disentangling self-and fairness-related neural mechanisms involved in the ultimatum game: an fMRI study (2013) Social Cognitive and Affective Neuroscience, 8 (4), pp. 424-431; Crawford, K., Calo, R., There is a blind spot in AI research (2016) Nature, 538 (7625), pp. 311-313; Crockett, M.J., Models of morality (2013) Trends in Cognitive Sciences, 17 (8), pp. 363-366; Crockett, M.J., How formal models can illuminate mechanisms of moral judgment and decision making (2016) Current Directions in Psychological Science, 25 (2), pp. 85-90; Crockett, M.J., Siegel, J.Z., Kurth-Nelson, Z., Dayan, P., Dolan, R.J., Moral transgressions corrupt neural representations of value (2017) Nature Neuroscience, 20 (6), p. 879; Cushman, F., From moral concern to moral constraint (2015) Current Opinion in Behavioral Sciences, 3, pp. 58-62; Debove, S., Baumard, N., André, J.B., Models of the evolution of fairness in the ultimatum game: A review and classification (2016) Evolution Andhuman Behavior, 37 (3), pp. 245-254; De Sio, F.S., Killing by autonomous vehicles and the legal doctrine of necessity (2017) Ethical Theory and Moral Practice, 20 (2), pp. 411-429; Dennis, L., Fisher, M., Slavkovik, M., Webster, M., Formal verification of ethical choices in autonomous systems (2016) Robotics and Autonomous Systems, 77, pp. 1-14; Dietrich, F., List, C., What matters and how it matters: a choice-theoretic representation of moral theories (2017) Philosophical Review, 126 (4), pp. 421-479; Doran, D., Schulz, S., Besold, T.R., (2017) What does explainable AI really mean? A new conceptualization of perspectives. arXiv preprint, , arXiv:1710.00794; Doris, J.M., (2002) Lack of character: Personality and moral behavior, , Cambridge University Press, Cambridge; Dretske, F., If you can't make one, you don't know how it works (1994) Midwest Studies in Philosophy, 19, pp. 468-482; Driver, J., Normative ethics (2005) The Oxford Handbook of Contemporary Philosophy, pp. 31-62. , Jackson F, Smith M, (eds), Oxford University Press, Oxford; Elgin, C.Z., (2017) True enough, , MIT Press, Cambridge; Everitt, T., Krakovna, V., Orseau, L., Hutter, M., Legg, S., (2017) Reinforcement Learning with a Corrupted Reward Channel.; Everitt, T., Lea, G., Hutter, M., (2018) AGI Safety Literature Review.; Farrell, J., Cheap talk, coordination, and entry (1987) The Rand Journal of Economics, 18 (1), pp. 34-39; Fehr, E., Schmidt, K., Theories of fairness and reciprocity–evidence and economic applications (2003) Advances in Economics and Econometrics, , 8th World Congress, Econometric Society Monographs; Feng, C., Luo, Y.J., Krueger, F., Neural signatures of fairness-related normative decision making in the ultimatum game: A coordinate-based meta-analysis (2015) Human Brain Mapping, 36 (2), pp. 591-602; Flanagan, O., Sarkissian, H., Wong, D., Naturalizing ethics (2007) Moral psychology, Vol. 1. The evolution of morality: Adaptations and innateness, pp. 1-25. , Sinnott-Armstrong W, (ed), MIT Press, Cambridge; Fleetwood, J., Public health, ethics, and autonomous vehicles (2017) American Journal of Public Health, 107 (4), pp. 532-537; Forsythe, R., Horowitz, J.L., Savin, N.E., Sefton, M., Fairness in simple bargaining experiments (1994) Games and Economic Behavior, 6 (3), pp. 347-369; Gábor, Z., Kalmár, Z., Szepesvári, C., Multi-criteria reinforcement learning (1998) In ICML, 98, pp. 197-205. , July; Glimcher, P.W., (2011) Foundations of neuroeconomic analysis, , OUP USA, Oxford; Gogoll, J., Müller, J.F., Autonomous cars: in favor of a mandatory ethics setting (2017) Science and Engineering Ethics, 23 (3), pp. 681-700; Güth, W., Schmittberger, R., Schwarze, B., An experimental analysis of ultimatum bargaining (1982) Journal of Economic Behavior & Organization, 3 (4), pp. 367-388; Hadfield-Menell, D., Milli, S., Abbeel, P., Russell, S.J., Dragan, A., Inverse reward design (2017) Advances in Neural Information Processing Systems, pp. 6765-6774; Hartmann, S., The world as a process: Simulations in the natural and social sciences (1996) In Hegselmann, Mueller, and Troitzsch 1996, pp. 77-100; Hass, J., Valuation mechanisms in moral cognition (2019) Behavioral and Brain Sciences, , https://doi.org/10.1017/S0140525X18002686; Henrich, J., Ensminger, J., McElreath, R., Barr, A., Barrett, C., Bolyanatz, A., Cardenas, J.C., Lesorogol, C., Markets, religion, community size, and the evolution of fairness and punishment (2010) Science, 327 (5972), pp. 1480-1484; Henrich, J., Heine, S.J., Norenzayan, A., The weirdest people in the world? (2010) Behavioral and Brain Sciences, 33 (2-3), pp. 61-83; Henrich, J., Heine, S.J., Norenzayan, A., Most people are not WEIRD (2010) Nature, 466 (7302), p. 29; Himmelreich, J., Never mind the trolley: The ethics of autonomous vehicles in mundane situations (2018) Ethical Theory and Moral Practice, 21 (3), pp. 669-684; Holstein, K., Wortman Vaughan, J., Daumé, H., Dudik, M., Wallach, H., Improving fairness in machine learning systems: What do industry practitioners need? (2019) Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, pp. 1-16; Honarvar, A.R., Ghasem-Aghaee, N., Casuist BDI-agent: A new extended BDI architecture with the capability of ethical reasoning (2009) International Conference on Artificial Intelligence and Computational Intelligence, pp. 86-95. , Berlin, Heidelberg, Springer; Hoppenbrouwers, S.S., Van der Stigchel, S., Slotboom, J., Dalmaijer, E.S., Theeuwes, J., Disentangling attentional deficits in psychopathy using visual search: Failures in the use of contextual information (2015) Personality and Individual Differences, 86, pp. 132-138; Howard, D., Muntean, I., Artificial moral cognition: Moral functionalism and autonomous moral agency (2017) Philosophy and Computing, pp. 121-159. , Cham, Springer; Iyer, R., Li, Y., Li, H., Lewis, M., Sundar, R., Sycara, K., Transparency and explanation in deep reinforcement learning neural networks (2018) Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society, pp. 144-150; Jobin, A., Ienca, M., Vayena, E., The global landscape of AI ethics guidelines (2019) Nature Machine Intelligence, 1 (9), pp. 389-399; Kahneman, D., Knetsch, J.L., Thaler, R., Fairness as a constraint on profit seeking: Entitlements in the market (1986) The American Economic Review, pp. 728-741; Kamm, F.M., (2008) Intricate ethics: Rights, responsibilities, and permissable harm, , Oxford University Press, Oxford; Ku, H.H., Hung, Y.C., Framing effects of per-person versus aggregate prices in group meals (2019) Journal of Consumer Behaviour, 18 (1), pp. 43-52; Larson, J., Mattu, S., Kirchner, L., Angwin, J., How we analyzed the COMPAS recidivism algorithm (2016) ProPublica, 5, p. 9; Leike, J., Martic, M., Krakovna, V., Ortega, P.A., Everitt, T., Lefrancq, A., Orseau, L., Legg, S., (2017) AI safety gridworlds; Liu, C., Xu, X., Hu, D., Multiobjective reinforcement learning: A comprehensive overview (2014) IEEE Transactions on Systems, Man, and Cybernetics: Systems, 45 (3), pp. 385-398; Lugo, L., Cooperman, A., (2013) A Portrait of Jewish Americans: Findings from a Pew Research Center Survey of U.S. Jews, , https://www.pewforum.org/2013/10/01/jewish-american-beliefs-attitudes-culture-survey/, Available online at; Malle, B.F., Integrating robot ethics and machine morality: The study and design of moral competence in robots (2016) Ethics and Information Technology, 18 (4), pp. 243-256; Mannor, S., Shimkin, N., A geometric approach to multi-criterion reinforcement learning (2004) Journal of Machine Learning Research, 5, pp. 325-360; Marchetti, A., Baglio, F., Massaro, D., Griffanti, L., Rossetto, F., Sangiuliano Intra, F., Valle, A., Castelli, I., Can psychological labels influence the decision-making process in an unfair condition? Behavioral and neural evidences using the ultimatum game task (2019) Journal of Neuroscience, Psychology, and Economics, 12 (2), p. 105; May, J., (2018) Regard for reason in the moral mind, , Oxford University Press, Oxford; May, J., Defending optimistic rationalism: A reply to commentators (2019) Behavioral and Brain Sciences; Millar, J., Lin, P., Abney, K., Bekey, G.A., (2017) Ethics settings for autonomous vehicles, pp. 20-34. , MIT Press, Cambridge; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Morgan, M.S., Learning from models (1999) Ideas in Context, 52, pp. 347-388; Nowak, M.A., Page, K.M., Sigmund, K., Fairness versus reason in the ultimatum game (2000) Science, 289 (5485), pp. 1773-1775; Nyholm, S., Smids, J., The ethics of accident-algorithms for self-driving cars: An applied trolley problem? (2016) Ethical Theory and Moral Practice, 19 (5), pp. 1275-1289; Omohundro, S.M., The basic AI drives (2008) In AGI, 171, pp. 483-492; Padoa-Schioppa, C., Neurobiology of economic choice: A good-based model (2011) Annual Review of Neuroscience, 34, pp. 333-359; Picard, R., (1997) Affective computing, , MIT Press, Cambridge; Rand, D.G., Tarnita, C.E., Ohtsuki, H., Nowak, M.A., Evolution of fairness in the one-shot anonymous Ultimatum Game (2013) Proceedings of the National Academy of Sciences, 110 (7), pp. 2581-2586; Roff, H., Expected Utilitarianism, Manuscript; Rosen, J.B., Rott, E., Ebersbach, G., Kalbe, E., Altered moral decision-making in patients with idiopathic Parkinson’s disease (2015) Parkinsonism & Related Disorders, 21 (10), pp. 1191-1199; Russell, S., Dewey, D., Tegmark, M., Research priorities for robust and beneficial artificial intelligence (2015) Ai Magazine, 36 (4), pp. 105-114; Russell, S.J., Norvig, P., (2016) Artificial intelligence: A modern approach, , Pearson Education Limited, Malaysia; Sanfey, A.G., Rilling, J.K., Aronson, J.A., Nystrom, L.E., Cohen, J.D., The neural basis of economic decision-making in the ultimatum game (2003) Science, 300 (5626), pp. 1755-1758; Scheutz, M., Malle, B.F., (2017) Moral Robots. the Routledge Handbook of Neuroethics, , Nueva York, Routledge/Taylor & Francis; Schroeder, T., Roskies, A.L., Nichols, S.B., Moral motivation (2010) The Moral Psychology Handbook, , Doris J, (ed), Oxford University Press, Oxford; Shenhav, A., Greene, J.D., Moral judgments recruit domain-general valuation mechanisms to integrate representations of probability and magnitude (2010) Neuron, 67 (4), pp. 667-677; Shevlin, H., De-Skilling and Social Necessity, , manuscript; Sinnott-Armstrong, W., Mallon, R., Mccoy, T., Hull, J.G., Intention, temporal order, and moral judgments (2008) Mind & Language, 23 (1), pp. 90-106; Soares, N., Fallenstein, B., Armstrong, S., Yudkowsky, E., Corrigibility (2015) Workshops at the Twenty-Ninth AAAI Conference on Artificial Intelligence; Sripada, C.S., Stich, S., A framework for the psychology of norms (2005) The Innate Mind, 2, pp. 280-301; Sripada, C.S., Stich, S., A framework for the psychology of norms (2006) The Innate Mind, 2, pp. 280-301; Sterelny, K., Fraser, B., Evolution and moral realism (2017) The British Journal for the Philosophy of Science, 68 (4), pp. 981-1006; Sutton, R.S., (2019) The Bitter Lesson, , http://www.incompleteideas.net/IncIdeas/BitterLesson.html; Sutton, R.S., Barto, A.G., (1998) Introduction to Reinforcement Learning, 135. , Cambridge, MIT press; Sutton, R.S., Barto, A.G., (2018) Reinforcement Learning: An Introduction, , MIT press; Taylor, J., Yudkowsky, E., LaVictoire, P., Critch, A., (2016) Alignment for advanced machine learning systems, , Machine Intelligence Research Institute, Berkeley; Thaler, R.H., Anomalies: The ultimatum game (1988) Journal of economic perspectives, 2 (4), pp. 195-206; Tracer, D., Market integration, reciprocity and fairness in rural papua new guinea: Results from a twovillage ultimatum game study (2004) Artefactual Field Experiments 00112, , https://ideas.repec.org/p/feb/artefa/00112.html, The Field Experiments Website. Available online at; Vallor, S., Moral deskilling and upskilling in a new machine age: Reflections on the ambiguous future of character (2015) Philosophy & Technology, 28 (1), pp. 107-124; Vamplew, P., Dazeley, R., Foale, C., Firmin, S., Mummery, J., Human-aligned artificial intelligence is a multiobjective problem (2018) Ethics and Information Technology, 20 (1), pp. 27-40; Vanderelst, D., Winfield, A., An architecture for ethical robots inspired by the simulation theory of cognition (2018) Cognitive Systems Research, 48, pp. 56-66; Moffaert, K., Drugan, M.M., Nowé, A., Hypervolume-based multi-objective reinforcement learning (2013) International Conference on Evolutionary Multi-Criterion Optimization, pp. 352-366. , Springer, Berlin, Heidelberg; Van Moffaert, K., Nowé, A., Multi-objective reinforcement learning using sets of pareto dominating policies (2014) The Journal of Machine LearningResearch, 15 (1), pp. 3483-3512; Wallach, W., Allen, C., (2008) Moral machines: Teaching robots right from wrong, , Oxford University Press, Oxford; Wallach, W., Franklin, S., Allen, C., A conceptual and computational model of moral decision making in human and artificial agents (2010) Topics in Cognitive Science, 2 (3), pp. 454-485; Wallach, W., Marchant, G., Toward the agile and comprehensive international governance of AI and Robotics (2019) Proceedings of the IEEE, 107 (3), pp. 505-508; Wei, C., Zheng, L., Che, L., Cheng, X., Li, L., Guo, X., Social support modulates neural responses to unfairness in the ultimatum game (2018) Frontiers in Psychology, 9, p. 182; Winfield, A., (2019) An Updated round up of Ethical Principles of Robotics and AI [Blog Post], , http://alanwinfield.blogspot.com/2019/04/an-updated-round-up-of-ethical.html?m=1, Retrieved from; Winfield, A.F., Michael, K., Pitt, J., Evers, V., Machine ethics: the design and governance of ethical AI and autonomous systems (2019) Proceedings of the IEEE, 107 (3), pp. 509-517; Wolf, S., Moral saints (1982) The Journal of Philosophy, 79 (8), pp. 419-439; Woodward, J., (2003) Making things happen: A theory of causal explanation, , Oxford University Press, Oxford; Yang, R., Sun, X., Narasimhan, K., A Generalized Algorithm for Multi-Objective Reinforcement Learning and Policy Adaptation (2019) Advances in Neural Information Processing Systems, pp. 14610-14621; Zhong, S., Israel, S., Shalev, I., Xue, H., Ebstein, R.P., Dopamine D4 receptor gene associated with fairness preference in ultimatum game (2010) PLoSONE, 5 (11)},
document_type={Article},
source={Scopus},
}

@ARTICLE{Mabaso2020,
author={Mabaso, B.A.},
title={Artificial Moral Agents Within an Ethos of AI4SG},
journal={Philosophy and Technology},
year={2020},
doi={10.1007/s13347-020-00400-z},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083990530&doi=10.1007%2fs13347-020-00400-z&partnerID=40&md5=7ce3954aa27b1868e5b46ea7ed511b39},
abstract={As artificial intelligence (AI) continues to proliferate into every area of modern life, there is no doubt that society has to think deeply about the potential impact, whether negative or positive, that it will have. Whilst scholars recognise that AI can usher in a new era of personal, social and economic prosperity, they also warn of the potential for it to be misused towards the detriment of society. Deliberate strategies are therefore required to ensure that AI can be safely integrated into society in a manner that would maximise the good for as many people as possible, whilst minimising the bad. One of the most urgent societal expectations of artificial agents is the need for them to behave in a manner that is morally relevant, i.e. to become artificial moral agents (AMAs). In this article, I will argue that exemplarism, an ethical theory based on virtue ethics, can be employed in the building of computationally rational AMAs with weak machine ethics. I further argue that three features of exemplarism, namely grounding in moral exemplars, meeting community expectations and practical simplicity, are crucial to its uniqueness and suitability for application in building AMAs that fit the ethos of AI4SG. © 2020, Springer Nature B.V.},
author_keywords={AI4SG;  Artificial moral agency;  Exemplarism;  Machine ethics},
references={Abel, D., Macglashan, J., Littman, M.L., Reinforcement learning as a framework for ethical decision making (2016) AAAI Workshop - Technical Report. Www.Aaai.Org, pp. 54-61. , WS-16-01; Abney, K., Robotics, ethical theory, and metaethics: A guide for the perplexed (2012) Robot Ethics, the Ethical and Social Implications of Robotics, 3, pp. 35-52. , . In Lin, P, Abney, K, & Bekey, G (Eds.), (Vol, pp,): The MIT Press, chap; Aghion, P.J., Benjamin, F., Jones, C.I., (2017) Artificial Intelligence and Economic Growth, , Tech. rep, National Bureau of Economic Research; Allen, C., Wallach, W., Moral machines: Contradiction in terms, or abdication of human responsibility? (2011) Robot Ethics, p. 4. , Lin, P., Abney, K., & Bekey, G.A, The MIT Press, chap; Alzahrani, H., Artificial intelligence: uses and misuses (2016) Global Journal of Computer Science and Technology, 16 (1s); Anderson, M., Anderson, S.L., Machine ethics: creating an ethical intelligent agent (2007) AI Magazine, 28 (4), p. 15. , https://doi.org/10.1609/aimag.v28i4.2065 http://www.aaai.org/ojs/index.php/aimagazine/article/view/2065; Anderson, S.L., Anderson, M., A prima facie duty approach to machine ethics and its application to elder care (2011) Workshops at the Twenty-Fffth AAAI Conference on Artificial Intelligence., , In; Annas, J., (2011) Intelligent virtue, , Oxford University Press, Oxford; Argall, B.D., Chernova, S., Veloso, M., Browning, B., A survey of robot learning from demonstration (2009) Robotics and autonomous systems, 57 (5), pp. 469-483; Baum, S.D., (2017) Social choice ethics in artificial intelligence, pp. 1-12. , https://doi.org/10.1007/s00146-017-0760-1, AI and Society (October); Brys, T., Harutyunyan, A., Suay, H.B., Chernova, S., Taylor, M.E., Nowé, A., Reinforcement learning from demonstration through shaping (2015) Twenty-Fourth International Joint Conference on Artificial Intelligence., , In; Churchland, P.S., The neurobiological platform for moral values (2014) Behaviour, 151 (2-3), pp. 283-296; Cloos, C., The utilibot project: An autonomous mobile robot based on utilitarianism (2005) Machine Ethics: Papers from the 2005 AAAI Fall Symposium, pp. 38-45. , http://philpapers.org/archive/CLOTUP.2.pdf; Conitzer, V., Sinnott-Armstrong, W., Borg, J.S., Deng, Y., Kramer, M., Moral decision making frameworks for artificial intelligence (2017) ISAIM, pp. 4831-4835. , www.aaai.org; Cowls, J., Floridi, L., Prolegomena to a white paper on an ethical framework for a good AI society (2018) SSRN Electronic Journal, , https://ssrn.com/abstract=3198732; Dameski, A., A comprehensive ethical framework for AI entities: Foundations (2018) International Conference on Artificial General Intelligence, pp. 42-51. , https://doi.org/10.1007/978-3-319-97676-1, Iklé, M., Franz, A., Rzepka, R., & Goertzel, B, July, Springer; Dignum, V., Responsible autonomy (2017) Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI-17)., , https://doi.org/10.24963/ijcai.2017/655; Duan, Y., Andrychowicz, M., Stadie, B., Jonathan, H., Open, A.I., Schneider, J., Sutskever, I., Zaremba, W., One-Shot Imitation Learning (2017) Advances in Neural Information Processing Systems, 30, pp. 1087-1098. , http://papers.nips.cc/paper/6709-one-shot-imitation-learning.pdf, I. Guyon, U.V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, & R. Garnett, Curran Associates, Inc; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds and machines, 14 (3), pp. 349-379; Gershman, S.J., Horvitz, E.J., Tenenbaum, J.B., Computational rationality: a converging paradigm for intelligence in brains, minds, and machines (2015) Science, 349 (6245), pp. 273-278; Gips, J., Towards the ethical robot (1995) Android Epistemology, pp. 243-252. , MIT Press; Himma, K.E., Artificial agency, consciousness, and the criteria for moral agency: what properties must an artificial agent have to be a moral agent? (2008) Ethics and Information Technology, 11 (1), pp. 19-29; Horvitz, E.J., Reasoning about beliefs and actions under computational resource constraints (1987) Proceedings of the Third Workshop on Uncertainty in Artificial Intelligence, AAAI and Association for Uncertainty in Artificial Intelligence, pp. 429-444. , http://erichorvitz.com/u87.htm, July, (pp,); Howard, D., Muntean, I., A minimalist model of the artificial autonomous moral agent (AAMA) (2016) AAAI Spring Symposium Series., , In; Hursthouse, R., Pettigrove, G., Virtue ethics (2018) The Stanford Encyclopedia of Philosophy, Winter 2018, , Zalta, E N (Ed.), edn, Metaphysics Research Lab, Stanford University; Johnson, D.G., Computer systems: moral entities but not moral agents (2006) Machine Ethics, pp. 168-183. , 9780521112; Kiela, D., (2017) Deep embodiment: Grounding semantics in perceptual modalities, , http://www.cl.cam.ac.uk/, Tech. rep., University of Cambridge, Computer Laboratory; Kuipers, B., (2016) Human-Like Morality and Ethics for Robots; van Lent, M., Laird, J.E., Learning procedural knowledge through observation (2001) K-CAP, pp. 179-186. , https://doi.org/10.1145/500737.500765, to appear in print; Levinson, M., Fay, J., (2016) Dilemmas of educational ethics: cases and commentaries, , Harvard Education Press, Cambridge; Liao, S.M., The basis of human moral status (2010) Journal of Moral Philosophy, 7 (2), pp. 1-31; Mayo, M.J., Symbol grounding and its implications for artificial intelligence (2003) Proceedings of the 26Th Australasian Computer Science Conference-Volume 16., 16, pp. 55-60. , http://portal.acm.org/citation.cfm?id=783106.783113&type=series, (Vol, pp,). Darlinghurst: Australian Computer Society, Inc; Miller, F.D., Aristotle on rationality in action (1984) The Review of Metaphysics, 37 (3), pp. 499-520. , https://www.jstor.org/stable/20128047; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE intelligent systems, 21 (4), pp. 18-21; Parthemore, J., Whitby, B., What makes any agent a moral agent? Reflections on machine consciousness and moral agency (2013) International Journal of Machine Consciousness, 5 (2), pp. 105-129. , https://pdfs.semanticscholar.org/3ff2/49fe3c8b3a2c94ae762b76b2dd0203f1f789.pdf; Parthemore, J., Whitby, B., Moral agency, moral responsibility, and artifacts: what existing artifacts fail to achieve (and why), and why they, nevertheless, can (and do!) make moral claims upon us (2014) International Journal of Machine Consciousness, 6 (2), pp. 141-161; Peterson, M., An introduction to decision theory (2009) Cambridge Introductions to Philosophy, , https://doi.org/10.1017/CBO9780511800917, Cambridge, Cambridge University Press, to appear in print; Pontier, M., Hoorn, J., Toward machines that behave ethically better than humans do (2012) Proceedings of the Annual Meeting of the Cognitive Science Society, 34. , Vol; Prasad, M., Social choice and the value alignment problem (2018) Artificial Intelligence Safety and Security, pp. 291-314. , London, Chapman and Hall/CRC; Rottschaefer, W.A., Naturalizing ethics: the biology and psychology of moral agency (2000) Zygon®;, 35 (2), pp. 253-286; Russell, S.J., Norvig, P., (2009) Artifical intelligence: a modern approach, , 3rd edn., Prentice Hall, Upper Saddle River: https://doi.org/10.1017/S0269888900007724. arXiv: http://arxiv.org/abs/1707.02286, arXiv: http://arxiv.org/abs/1011.1669v3; Scheutz, M., Malle, B.F., Moral robots (2017) The Routledge Handbook of Neuroethics, p. 24. , https://doi.org/10.4324/9781315708652.ch24, Johnson, L.S.M., & Rommelfanger, K.S. (Eds.), Routledge, chap; Simon, H.A., A behavioral model of rational choice (1955) The Quarterly Journal of Economics, 69 (1), pp. 99-118; Slote, M., Agent-based virtue ethics (1995) Midwest Studies in Philosophy, 20 (1), pp. 83-101; Sullins, J.P., When is a robot a moral agent (2006) IRIE: International Review of Information Ethics, , http://sonoma-dspace.calstate.edu/handle/10211.1/427; Szutta, N., Exemplarist moral theory–some pros and cons (2019) Journal of Moral Education, 48 (3), pp. 280-290; Torrance, S., Ethics and consciousness in artificial agents (2008) AI and Society, 22 (4), pp. 495-521; Vamplew, P., Dazeley, R., Foale, C., Firmin, S., Mummery, J., Human-aligned artificial intelligence is a multiobjective problem (2018) Ethics and Information Technology, 20 (1), pp. 27-40; Wallach, W., Franklin, S., Allen, C., A conceptual and computational model of moral decision making in human and artificial agents (2010) Topics in Cognitive Science, 2 (3), pp. 454-485; Zagzebski, L., Exemplarist virtue theory (2010) Metaphilosophy, 41 (1-2), pp. 41-57},
document_type={Article},
source={Scopus},
}

@ARTICLE{Tolksdorf2020,
author={Tolksdorf, N.F. and Siebert, S. and Zorn, I. and Horwath, I. and Rohlfing, K.J.},
title={Ethical Considerations of Applying Robots in Kindergarten Settings: Towards an Approach from a Macroperspective},
journal={International Journal of Social Robotics},
year={2020},
doi={10.1007/s12369-020-00622-3},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078902756&doi=10.1007%2fs12369-020-00622-3&partnerID=40&md5=5031bb5ba04e7849342827c6c7783458},
abstract={In child–robot interaction (cHRI) research, many studies pursue the goal to develop interactive systems that can be applied in everyday settings. For early education, increasingly, the setting of a kindergarten is targeted. However, when cHRI and research are brought into a kindergarten, a range of ethical and related procedural aspects have to be considered and dealt with. While ethical models elaborated within other human–robot interaction settings, e.g., assisted living contexts, can provide some important indicators for relevant issues, we argue that it is important to start developing a systematic approach to identify and tackle those ethical issues which rise with cHRI in kindergarten settings on a more global level and address the impact of the technology from a macroperspective beyond the effects on the individual. Based on our experience in conducting studies with children in general and pedagogical considerations on the role of the institution of kindergarten in specific, in this paper, we enfold some relevant aspects that have barely been addressed in an explicit way in current cHRI research. Four areas are analyzed and key ethical issues are identified in each area: (1) the institutional setting of a kindergarten, (2) children as a vulnerable group, (3) the caregivers’ role, and (4) pedagogical concepts. With our considerations, we aim at (i) broadening the methodology of the current studies within the area of cHRI, (ii) revalidate it based on our comprehensive empirical experience with research in kindergarten settings, both laboratory and real-world contexts, and (iii) provide a framework for the development of a more systematic approach to address the ethical issues in cHRI research within kindergarten settings. © 2020, The Author(s).},
author_keywords={Child–robot interaction;  Early childhood education;  Kindergarten settings;  Robot ethics},
keywords={Philosophical aspects, Early childhood educations;  Ethical considerations;  Institutional setting;  Interactive system;  Procedural aspects;  Robot ethics;  Robot interactions;  Vulnerable groups, Human robot interaction},
references={Jensen, J.J., Skov, M.B., A review of research methods in children’s technology design (2005) Proceeding of the 2005 Conference on Interaction Design and children—IDC ’, 5, pp. 80-87. , ACM Press, Boulder; Hood, D., Lemaignan, S., Dillenbourg, P., When children teach a robot to write: An autonomous teachable humanoid which uses simulated handwriting (2015) Proceedings of the Tenth Annual ACM/IEEE International Conference on human–robot interaction—HRI ’15, pp. 83-90. , ACM Press, Portland; Leite, I., Hajishirzi, H., Andrist, S., Lehman, J., Managing chaos: Models of turn-taking in character-multichild interactions (2013) Proceedings of the 15Th ACM on International Conference on Multimodal interaction—ICMI ’13, pp. 43-50. , ACM Press, Sydney; Bethel, C.L., Burke, J.L., Murphy, R.R., Salomon, K., Psychophysiological experimental design for use in human–robot interaction studies (2007) 2007 International Symposium on Collaborative Technologies and Systems, pp. 99-105. , IEEE, Orlando; Hong, D., Chiu, D.K.W., Shen, V.Y., Requirements elicitation for the design of context-aware applications in a ubiquitous environment (2005) Proceedings of the 7Th International Conference on Electronic commerce—ICEC ’05, pp. 590-596. , ACM Press, Xi’an; Vogt, P., van Den Berghe, R., de Haas, M., Second language tutoring using social robots: A large-scale study (2019) 2019 14Th ACM/IEEE International Conference on human–robot Interaction (HRI). IEEE, Daegu, pp. 497-505; Kory Westlund, J.M., Jeong, S., Park, H.W., Flat vs. expressive storytelling: Young children’s learning and retention of a social robot’s narrative (2017) Front Hum Neurosci, 11, pp. 1-20; Gordon, G., Spaulding, S., Westlund, J.K., Affective personalization of a social robot tutor for children’s second language skills (2016) AAAI. Phoenix, pp. 3951-3957; Hsiao, H.-S., Chang, C.-S., Lin, C.-Y., Hsu, H.-L., iRobiQ”: the influence of bidirectional interaction on kindergarteners’ reading motivation, literacy, and behavior (2015) Interact Learn Environ, 23, pp. 269-292; Rintjema, E., van Den Berghe, R., Kessels, A., A robot teaching young children a second language: The effect of multiple interactions on engagement and performance (2018) Companion of the 2018 ACM/IEEE International Conference on human–robot interaction—HRI ’18, pp. 219-220. , Press ACM, Chicago; Conti, D., Cirasa, C., Di Nuovo, S., Di Nuovo, A., Robot, tell me a tale!”: a social robot as tool for teachers in kindergarten (2019) Interact Stud, 20, pp. 1-16; Tanaka, F., Matsuzoe, S., Learning verbs by teaching a care-receiving robot by children: An experimental report (2012) Proceedings of the 7Th ACM/IEEE International Conference on human–robot Interaction, pp. 253-254. , ACM Press, New York; Mertens, U., Rohlfing, K., Bergmann, K., Can the reduction of an iconic gesture aid long-term learning? A pilot child–robot-study (2018) Conference of the International Society for Gesture Studies: Gesture and Diversity, , Cape Town; Rohlfing, K.J., Grimminger, A., Wrede, B., The caregiver’s role in keeping a child–robot interaction going (2020) International perspectives on digital media and early literacy: the impact of digital devices on learning, language acquisition and social interaction, , Rohlfing KJ, Müller-Brauers C, (eds), Routledge, London; Lücking, P., Rohlfing, K., Wrede, B., Schilling M (2016) Preschoolers’ engagement in social interaction with an autonomous robotic system Development and Learning and Epigenetic Robotics (Icdl-Epirob), 2016 Joint IEEE International Conference, pp. 210-216. , IEEE, Cergy-Pontoise; Tolksdorf, N.F., Rohlfing, K.J., Reconceptualising early childhood literacy facing child–robot interaction (2019) Reconceptualising Early Childhood Literacies: An International Conference, , Manchester; Hegel, F., Muhl, C., Wrede, B., Understanding social robots (2009) Second International Conferences on Advances in computer–human Interactions. IEEE, Cancun, pp. 169-174; Breazeal, C., Toward sociable robots (2003) Robot Auton Syst, 42, pp. 167-175; Charisi, V., Davison, D., Wijnen, F., Towards a child–robot symbiotic co-development: a theoretical approach (2015) Proceedings of the AISB 2015 Symposium on AI and Games, pp. 30-35. , Salem M, Weiss A, Baxter P, Dautenhahn K, (eds), Curran, Red Hook; Woods, S., Exploring the design space of robots: children’s perspectives (2006) Interact Comput, 18, pp. 1390-1418; de Graaf, M.M.A., An ethical evaluation of human–robot relationships (2016) Int J Soc Robot, 8, pp. 589-598; Breazeal, C., Harris, P.L., DeSteno, D., Young children treat robots as informants (2016) Top Cogn Sci, 8, pp. 481-491; Vollmer, A.-L., Read, R., Trippas, D., Belpaeme, T., Children conform, adults resist: a robot group induced peer pressure on normative social conformity (2018) Sci Robot, 3, p. eaat7111; Nutbrown, C., (2006) Key concepts in early childhood education and care, , SAGE, Thousand Oaks; Belsky, J., Vandell, D.L., Burchinal, M., Are there long-term effects of early child care? (2007) Child Dev, 78, pp. 681-701; Foot, H., Howe, C., Cheyne, B., Pre-school education: parents’ preferences, knowledge and expectations Enseignement (2000) Int J Early Years Educ, 8, pp. 189-204; Hägglund, S., Samuelsson, I.P., Early childhood education and learning for sustainable development and citizenship (2009) Int J Early Child, 41, pp. 49-63; Robson, S., Parent perspectives on services and relationships in two English early years centres (2006) Early Child Dev Care, 176, pp. 443-460; Vogt, P., de Haas, M., de Jong, C., Child–robot interactions for second language tutoring to preschool children (2017) Front Hum Neurosci, 11, pp. 1-6; Gödden, S., (2018) Helfer Oder Last?, , Roboter als Familienmitglieder, Prosieben; Ma, F., Wylie, B.E., Luo, X., Apologies repair children’s trust: the mediating role of emotions (2018) J Exp Child Psychol, 176, pp. 1-12; Cameron, D., Collins, E., Cheung, H., Don’t worry, we’ll get there: developing robot personalities to maintain user interaction after robot error (2016) Biomimetic and biohybrid systems, pp. 409-412. , Lepora NF, Mura A, Mangan M, (eds), Springer, Edinburgh; Brandes, H., (2008) Selbstbildung in Kindergruppen: die Konstruktion sozialer Beziehungen, , 1, Reinhardt, Munich; Belpaeme, T., Kennedy, J., Ramachandran, A., Social robots for education: a review (2018) Sci Robot, 3, p. eaat5954; Williams, P., Williams, P., Preschool routines, peer learning and participation (2001) Scand J Educ Res, 45, pp. 317-339; Sharkey, A.J.C., Should we welcome robot teachers? (2016) Ethics Inf Technol, 18, pp. 283-297; Vasic, M., Billard, A., Safety issues in human–robot interactions (2013) 2013 IEEE International Conference on Robotics and Automation, pp. 197-204. , IEEE, Karlsruhe; Bethel, C.L., Stevenson, M.R., Scassellati, B., Secret-sharing: Interactions between a child, robot, and adult (2011) 2011 IEEE International Conference on Systems, Man, and Cybernetics, pp. 2489-2494. , . IEEE, Anchorage; Ahmad, M.I., Mubin, O., Orlando, J., Adaptive social robot for sustaining social engagement during long-term children–robot interaction (2017) Int J Hum-Comput Interact, 33, pp. 943-962; (2007), UN General Assembly, Convention on the rights of persons with disabilities; Groß, D.-P., (2017) Lead user in der medical homecare-Industrie in Deutschland, , Springer Fachmedien Wiesbaden, Wiesbaden; Tolksdorf, N.F., Mertens, U., Beyond words: children’s multimodal responses during word learning with a robot (2020) International perspectives on digital media and early literacy: the impact of digital devices on learning, language acquisition and social interaction, , Rohlfing KJ, Müller-Brauers C, (eds), Routledge, London; Kennedy, J., Lemaignan, S., Montassier, C., Child speech recognition in human–robot interaction: Evaluations and recommendations (2017) Proceedings of the 2017 ACM/IEEE International Conference on human–robot interaction—HRI ’17, pp. 82-90. , ACM Press, Vienna; Levinson, S.C., Turn-taking in human communication—origins and implications for language processing (2016) Trends Cogn Sci, 20, pp. 6-14; Doherty-Sneddon, G., Kent, G., Visual signals and the communication abilities of children (1996) J Child Psychol Psychiatry, 37, pp. 949-959; Kennedy, J., Baxter, P., Belpaeme, T., The impact of robot tutor nonverbal social behavior on child learning (2017) Front ICT; Belpaeme, T., Baxter, P.E., Read, R., Multimodal child–robot interaction: building social bonds (2013) J Hum-Robot Interact, 1, pp. 34-53; Baxter, P., Ashurst, E., Read, R., Robot education peers in a situated primary school study: personalisation promotes child learning (2017) PLOS ONE, 12; Serholt, S., Breakdowns in children’s interactions with a robotic tutor: a longitudinal study (2018) Comput Hum Behav, 81, pp. 250-264; Yont, K.M., Hewitt, L.E., Miccio, A.W., What did you say?” Understanding conversational breakdowns in children with speech and language impairments (2002) Clin Linguist Phon, 16, pp. 265-285; Siebert, S., Tolksdorf, N., Rohlfing, K., Zorn, I., Raising robotic natives? Persuasive potentials of social robots in early education (2019) J Commun Media Stud, 4, pp. 21-35; Coeckelbergh, M., Pop, C., Simut, R., A survey of expectations about the role of robots in robot-assisted therapy for children with ASD: ethical acceptability, trust, sociability, appearance, and attachment (2016) Sci Eng Ethics, 22, pp. 47-65; Genesee, F., Boivin, I., Nicoladis, E., Talking with strangers: a study of bilingual children’s communicative competence (1996) Appl Psycholinguist, 17, pp. 427-442; Horwath, I., Kolossa, D., Rohlfing, K.J., Critical technological thinking in early education CRICKET (2018) Volkswagen Foundation Funding Initiative (“Artificial Intelligence—impacts on Tomorrow’s Society”), , Hannover; Haun, D.B.M., Tomasello, M., Conformity to peer pressure in preschool children: peer pressure in preschool children (2011) Child Dev, 82, pp. 1759-1767; Moses, A.M., Impacts of television viewing on young children’s literacy development in the USA: a review of the literature (2008) J Early Child Lit, 8, pp. 67-102; Baldwin, D.A., Understanding the link between joint attention and language (1995) Joint attention: its origins and role in development, pp. 131-158. , Moore C, Dunham PJ, (eds), Lawrence Erlbaum, Hillsdale; Kauschke, C., Klann-Delius, G., How mothers introduce a new, surprising object—a study on early word learning in discourse (2010) Proceedings of the XIV European Conference on Developmental psychology—ECDP, pp. 117-122. , Vilnius, Lithuania; Cao, H.-L., Esteban, P.G., Bartlett, M., Robot-enhanced therapy: development and validation of supervised autonomous robotic system for autism spectrum disorders therapy (2019) IEEE Robot Automat Mag, 26, pp. 49-58; Esteban, P.G., Baxter, P., Belpaeme, T., How to build a supervised autonomous system for robot-enhanced therapy for children with autism spectrum disorder (2017) Paladyn J Behav Robot, 8, pp. 18-38; Kanero, J., Geçkin, V., Oranç, C., Social robots for early language learning: current evidence and future directions (2018) Child Dev Perspect, 12, pp. 146-151; Fridin, M., Belokopytov, M., Acceptance of socially assistive humanoid robot by preschool and elementary school teachers (2014) Comput Hum Beha, 33, pp. 23-31; Serholt, S., Barendregt, W., Leite, I., Teachers’ views on the use of empathic robotic tutors in the classroom (2014) The 23Rd IEEE International Symposium on Robot and Human Interactive Communication., pp. 955-960. , IEEE, Edinburgh; Westlund, J.K., Gordon, G., Spaulding, S., Lessons from teachers on performing HRI studies with young children in schools (2016) 2016 11Th ACM/IEEE International Conference on human–robot Interaction (HRI, pp. 383-390. , IEEE, Christchurch},
document_type={Article},
source={Scopus},
}

@ARTICLE{Funk202059,
author={Funk, M. and Coeckelbergh, M.},
title={(Technical) Autonomy as Concept in Robot Ethics},
journal={Biosystems and Biorobotics},
year={2020},
volume={25},
pages={59-65},
doi={10.1007/978-3-030-24074-5_12},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070506471&doi=10.1007%2f978-3-030-24074-5_12&partnerID=40&md5=5764c6fbd729c0b20044212fedbf4348},
abstract={This paper aims to contribute to the debate about ethical, legal, and social implications of robotics by discussing the meaning of autonomy. Robots are often labeled as autonomous, but what does “autonomy” in robotics actually mean? In order to answer this question, methods of conceptual analysis and language critique are applied. It turns out that the empirical-descriptive application of the word autonomy in technical context is different to the normative usage of autonomy in human life and human societies. Following this insight, and an embodied approach in philosophy of technology, six forms of technical tools are briefly introduced which could be used to describe several levels of technical autonomy. The different forms are summarized in a heuristic scheme, which can be used to set up clearer applications of the word “autonomy” in ethical, legal and social debates concerning robotic technologies. © 2020, Springer Nature Switzerland AG.},
references={Viola, R., The future of robotics and artificial intelligence in Europe (2017) European Comission, Digital Single Market Blog Post, 16; (2000), http://www.europarl.europa.eu/RegData/etudes/STUD/2016/571379/IPOL_STU(2016)571379_EN.pdf.Accessed, Sept 2018; Veruggio, G., Abney, K., Roboethics: The applied ethics for a new science (2012) Robot Ethics. the Ethical and Social Implications of Robotics, pp. 347-363. , Lin, P., Abney, K., Bekey, G.A. (eds.), pp., MIT Press, Cambridge/London; Nida-Rümelin, J., Ethik des risikos (2005) Angewandte Ethik. Die Bereichsethiken Und Ihre Theoretische Fundierung. Ein Handbuch. 2., Aktualisierte Auflage, pp. 862-885. , Nida-Rümelin, J. (ed.), pp., Kröner Verlag, Stuttgart; Ropohl, G., Verantwortung und risiko (2017) Handbuch Verantwortung, pp. 887-908. , Heidbrink, L., et al. (eds.), pp., Springer, Wiesbaden; Lenk, H., Maring, M., Verantwortung in technik und wissenschaft (2017) Handbuch Verantwortung, pp. 715-731. , Heidbrink, L., et al. (eds.), pp., Springer, Wiesbaden; Hume, D., Ein Traktat über die menschliche Natur (2013) Teilband 2. Buch II Über Die Affekte. Buch III Über Moral, pp. 546-547. , der Grundlage der, A., von Theodor Lipps, Ü., herausgegeben von, n., Brandt, H.D. (eds.), pp., Felix Meiner, Hamburg; Viola, R., The future of robotics and artificial intelligence in Europe (2017) European Comission, Digital Single Market Blog Post, 16; Coeckelbergh, M., Funk, M., Wittgenstein as a philosopher of technology: Tool use, forms of life, technique, and a transcendental argument (2018) Hum. Stud., 41 (2), pp. 165-191; Funk, M., Fritzsche, A., Engineering Practice from the Perspective of Methodical Constructivism and Culturalism, , Michelfelder, D.P., Doorn, N. (eds.); Janich, P., Substitution kommunikativer Kompetenz? (1999) Robotik. Einführung in Eine interdisziplinäre Diskussion, pp. 17-31. , Decker, M. (ed.), pp., Graue Reihe, Bad Neuenahr-Ahrweiler; Janich, P., (2006) Kultur Und Methode. Philosophie in Einer Wissenschaftlich geprägten Welt, , Suhrkamp, Frankfurt a.M; Janich, P., Was ist Information? Kritik einer Legende. Suhrkamp, Frankfurt a (2006) Kultur Und Methode. Philosophie in Einer Wissenschaftlich geprägten Welt; Funk, M., Humanoid robots and human knowing – perspectivity and hermeneutics in terms of material culture (2014) Robotics in Germany and Japan. Philosophical and Technical Perspectives, pp. 69-87. , Funk, M., Irrgang, B. (eds.), pp., Peter Lang, Frankfurt am Main a.o; Borgmann, A., (1984) Technology and the Character of Contemporary Life: A Philosophical Inquiry, , The University of Chicago Press, Chicago/London; (2012) Robot Ethics: The Ethical and Social Implications of Robotics, , Lin, P., Abney, K., Bekey, G.A. (eds.), MIT Press, Cambridge/London; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press, Oxford; Funk, M., Paleoanthropology and social robotics. Old and new ways in mediating alterity relations (2018) Aagaard, J., Friis, J.K.B., Sorenson, J., Tafdrup, O., Hasse, C. (Eds.) Postphenomenological Methodologies. New Ways in Mediating Techno-Human Relationships, Pp. 125–149. Rowman & Littlefield/Lexington; Viola, R., The future of robotics and artificial intelligence in Europe (2017) European Comission, Digital Single Market Blog Post, 16; Viola, R., The future of robotics and artificial intelligence in Europe (2017) European Comission, Digital Single Market Blog Post, 16; Rentsch, T., (2003) Heidegger Und Wittgenstein. Existenzial-Und Sprachanalysen Zu Den Grundlagen Philosophischer Anthropologie, Pp. 75Ff, , Klett-Cotta, Stuttgart; Abel, G., Knowledge research: Extending and revising epistemology (2012) Rethinking Epistemology, 1, pp. 1-52. , Abel, G., Conant, J. (eds.), vol., pp., De Gruyter, Berlin/Boston; Wittgenstein, L., Philosophische Untersuchungen (2006) Werkausgabe Band 1. Tractatus Logico-Philosophicus. Tagebücher 1914–1916. Philosophische Untersuchungen, pp. 225-577. , Wittgenstein, L. (ed.), pp., Suhrkamp, Frankfurt a.M; Gabriel, G., Logisches und analogisches Denken. Zum Verhältnis von wissenschaftlicher und ästhetischer Weltauffassung (1995) Vernunft Und Lebenspraxis. Philosophische Studien Zu Den Bedingungen Einer Rationalen Kultur, pp. 157-174. , Demmerling, C., Gabriel, G., Rentsch, T. (eds.), pp., Suhrkamp, Frankfurt a.M},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Nieuważny2020387,
author={Nieuważny, J. and Masui, F. and Ptaszynski, M. and Araki, K. and Rzepka, R. and Nowakowski, K.},
title={Emotional and Moral Impressions Associated with Buddhist Religious Terms in Japanese Blogs-Preliminary Analysis},
journal={Advances in Intelligent Systems and Computing},
year={2020},
volume={948},
pages={387-392},
doi={10.1007/978-3-030-25719-4_50},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070188536&doi=10.1007%2f978-3-030-25719-4_50&partnerID=40&md5=8c7c610089c4625fb6d488ee8672b568},
abstract={This paper is an attempt at analyzing how much religious vocabulary (in this case Buddhist vocabulary taken from a large scale dictionary of Buddhist terms available online) is present in everyday Japanese social space (in this case in a repository of blog entries form the Ameba blog service) and thus in the consciousness of people. We also investigate and what associations (positive or negative) it generates, thus indicating the connotations associated with several Buddhist terms – whether expressions containing Buddhist vocabulary are considered proper or not from a moral point of view – as well as the emotional response of Internet users to Buddhist terminology. © 2020, Springer Nature Switzerland AG.},
author_keywords={Automated moral reasoning;  Buddhist terminology;  Machine ethics},
keywords={Behavioral research;  Terminology, Emotional response;  Internet users;  Moral reasoning;  Preliminary analysis;  Social spaces, Blogs},
references={Komuda, R., Ptaszynski, M., Momouchi, Y., Rzepka, R., Araki, K., Machine moral development: Moral reasoning agent based on wisdom of web-crowd and emotions (2010) Int J Comput Linguist Res, 1 (3), pp. 155-163; Nakamura, A., (1993) Kanjō hyōgen Jiten, , Dictionary of Emotive Expressions]. Tokyodo, Tokyo; Ptaszynski, M., Dybala, P., Rzepka, R., Araki, K., Momouchi, Y., YACIS: A five-billion-word corpus of japanese blogs fully annotated with syntactic and affective information (2012) Proceedings of the AISB/IACAP World Congress 2012 in Honour of Alan Turing, 2Nd Symposium on Linguistic and Cognitive Approaches to Dialog Agents, Lacatoda, 2012, pp. 40-49. , University of Birmingham, Birmingham, pp; Rzepka, R., Araki, K., What statistics could do for ethics?-the idea of common sense processing based safety valve (2005) AAAI Fall Symposium on Machine Ethics, Technical Report FS-05-06. the AAAI Press, pp. 85-87. , Menlo Park, California, pp},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Gary2019478,
author={Gary, E.},
title={Ethics to prepare educators for professional service robots in classrooms},
journal={Proceedings - International Joint Conference on Information, Media, and Engineering, IJCIME 2019},
year={2019},
pages={478-484},
doi={10.1109/IJCIME49369.2019.00102},
art_number={9066393},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084033975&doi=10.1109%2fIJCIME49369.2019.00102&partnerID=40&md5=5037a577addb8a00708684458042543b},
abstract={This paper outlines ethical principles for educators preparing for service robots in the classroom (professional service robots). At the dawn of artificial intelligence (AI) as service robots arrive in education systems, we first define robots and professional service robots. We then review and suggest a conduct-focused ethics path over individual moral path to guide educators to consider ethics and key ethical issues involved in professional service robot design, development, implementation and partnering efforts for education settings. Borrowing from the robot ethics (roboethics) fields that has emerged from computer science and bioethics, we suggest that educators new to classroom robots and AI can ethically reduce the complexity of their work by considering simple social impact issues, specifically human relations and job issues at this early stage in professional robot thinking. We conclude by offering ethics of care principles and culture research to help educators who may adopt a caring stance to work in the diverse global context of robotics and education today. © 2019 IEEE.},
author_keywords={Artificial intelligence;  Care ethics;  Education leadership;  Education technology;  Ethics;  Learning design;  Service robots},
keywords={Educational robots;  Engineering research;  Ethical aspects;  Intelligent robots;  Machine design;  Mobile robots;  Social computing;  Social robots, Education systems;  Ethical issues;  Ethical principles;  Global context;  Human relations;  Professional services;  Service robots;  Social impact, Economic and social effects},
references={Kowch, E., Do we plan the journey or read the compass? An argument for preparing educational technologists to lead organizational change (2005) Brit. J. Educ. Tech, 35 (6), pp. 1067-1075; Kowch, E., Liu, C., Principles for teaching, leading and participatory learning with a new participant: Ai" (2018) 2018 Intl. Joint Conf. On Info, Media and Engineering (ICIME), pp. 235-320. , Osaka, JY; Kowch, E., A new paradigm for teaching, leading and learning in participatory learning environments (2018) Actions of Their Own to Learn B. Shapiro, pp. 225-251. , London, UK: Sense Publishers; Reigeluth, C.M., Duffy, F.M., The aect futuremmds initiative:transforming america's school systems (2008) Educ. Technology, 5 (49), pp. 41-65; Veruggio, G., Operto, F., Roboethics: Social and ethical implications of robotics (2008) The Springer Handbook of Robotics, pp. 1499-1522. , B. Siciliano and O. Khatib, Berlin, Germany, Sprmger-Verlag; Wilson, J.H., Daugherty, P.R., Colaborative intelligence: Humans and ai are jomgmg forces (2018) Harvard Bus. Review, , https://hbr.org/2018/07/collaborative-mtelhgence-humans-And-Ai-Arejommg-forces, July; Lin, P., Abney, K., Bekey, G., Robot ethics: Mapping the issues for a mechanized world" (2011) Artificial Intelligence, 174, pp. 942-949; (2019) Service Robots: Pioneering Technology for the Challenges of Today's Marketplace", , https://www.robotics.org/service-robots/what-Are-professional-sece-robots, Robotics Industries Association, accessed June; Van Wynsberghe, A., Service robots, care ethics, and design" Ethics Inf. Technol, 13 (2016), pp. 311-321; Wyatt, S., Executive Summary World Robotics 2018 Service Robots, , https://ifr.org/downloads/press2018/ExecutiveSummaryWRServiceRobots-2018.pdf, Accessed August, 2019; Stock, R., Merkle, M., A service robot acceptance modeller acceptance of humanoid robots during service" (2017) IEEE PerCom, , https://ieeexplore.ieee.org/document/7917585, Kona, HI, USA March 13-17. [online]; Mehta, D., Siddiqui, M., Javaid, A., Facial emotion recognition" (2018) Sensors, 416; Serholt, S., (2017) Child-Robot Interaction in Education", , PhD. dissertation, Dept. of Appl. Info. Technol., U. Gothenburg, Sweden; Noddings, N., The carina reltion in teaching Oxford Rev. Of Educ, 38 (6), pp. 771-781; Enz, S., Diruf, M., Speilhagen, C., Zoll, C., Vargas, P., The social role of robots in the future" (2011) Int. J. Soc. Robot, pp. 263-271; Coeckelbergh, M., Is ethics of robotics about robots-philosophy or robotics beyond realism and individiualism (2011) Law, Innov. & Technol., 3 (2), pp. 241-250; Kowch, Whither thee educational technology? Suggesting a critical expansion of our epistemology for emerging leaders (2013) TechTrends, 57 (5), pp. 25-34; Blackburn, S., (2016) Oxford Dictionary of Philosophy, , Oxford UK: Oxford University Press; Etziom, A., Etziom, O., Incorporating ethics into artificial intelligence" (2017) J Ethics, 21, pp. 403-418; Wilson, J.H., Daugherty, P.R., Colaborative intelligence: Humans and ai are jomgmg forces (2018) Harvard Bus. Review, , https://hbr.org/2018/07/collaborative-intelligence-humans-And-Ai-Arejommg-forces, July; Sullms, J., Introduction: Open questions in roboethics" (2011) Philos. Technol, 24, pp. 233-238; Sharkey, A., Should we welcome robot teachers?" (2017) Ethics Info. Technol., 18, pp. 283-297; Miller, D.P., Nourbaksh, I.R., Siegwart, R., Robots for education (2008) The Springer Handbook of Robotics, pp. 1283-1301. , B. Siciliano and O. Khatib, Berlin, Germany, Springer-Verlag; Hashimoto, T., Kato, N., Kobayashi, H., Development of education system with android robot saya and evaluation (2011) Intl. J Adv. Robotic Systems, 8 (3), pp. 51-61; Miller, D.P., Nourbaksh, I.R., Siegwart, R., (2008) Robots for Education N the Springer Handbook of Robotics, pp. 1283-1301. , B. Siciliano and O. Khatib, Berlin, Germany, Sponger-Verlag; Tanaka, F., Cicourel, A., Movellan, J., Socialization between todders and robots at an ece center" Proc. Natl Acad Sci, 194 (46), pp. 17594-17598; Kant, I., Lectures on pedagogy (2007) Anthropology, History, and Education, 2007, pp. 437-485. , G. Zoller, Cambridge: Cambridge University Press; Cherry, N.C., Exapndmg stroke telerehabihtaion services to rural veterans" (2017) Disabil RhabilAssist Technol, 12 (1), pp. 21-27},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Aliman2019283,
author={Aliman, N.-M. and Kester, L. and Werkhoven, P.},
title={Xr for augmented utilitarianism},
journal={Proceedings - 2019 IEEE International Conference on Artificial Intelligence and Virtual Reality, AIVR 2019},
year={2019},
pages={283-285},
doi={10.1109/AIVR46125.2019.00065},
art_number={8942355},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078064929&doi=10.1109%2fAIVR46125.2019.00065&partnerID=40&md5=3c75833d6ecbb18b4588c0549c65a6f5},
abstract={Steady progresses in the AI field create enriching possibilities for society while simultaneously posing new complex challenges of ethical, legal and safety-relevant nature. In order to achieve an efficient human-centered governance of artificial intelligent systems, it has been proposed to harness augmented utilitarianism (AU), a novel non-normative ethical framework grounded in science which can be assisted e.g. by Extended Reality (XR) technologies. While AU provides a scaffold to encode human ethical and legal conceptions in a machine-readable form, the filling in of these conceptions requires a transdisciplinary amalgamation of scientific insights and preconditions from manifold research areas. In this short paper, we present a compact review on how XR technologies could leverage the underlying transdisciplinary AI governance approach utilizing the AU framework. Towards that end, we outline pertinent needs for XR in two hereto related contexts: As experiential testbed for AU-relevant moral psychology studies and as proactive AI Safety measure and enhancing policy-by-simulation method preceding the deployment of AU-based ethical goal functions. © 2019 IEEE.},
author_keywords={AI Safety;  AR;  Intelligent Systems;  Machine Ethics;  Moral Psychology;  Positive Technology;  VR},
keywords={Argon;  Intelligent systems;  Metals;  Scaffolds;  Virtual reality, Artificial intelligent;  Filling in;  Goal functions;  Machine readable form;  Moral Psychology;  Safety measures, Philosophical aspects},
references={Dafoe, A., AI governance: A research agenda Governance of AI Program, Future of Humanity Institute, University of Oxford: Oxford, UK, 2018; Gasser, U., Almeida, V.A., A layered model for ai governance (2017) IEEE Internet Computing, 21 (6), pp. 58-62; Russell, S., Dewey, D., Tegmark, M., Research priorities for robust and beneficial artificial intelligence (2015) Ai Magazine, 36 (4), pp. 105-114; Elands, P., Huizing, A., Kester, L., Oggero, S., Peeters, M., Governing ethical and effective behaviour of intelligent systems Military Spectator, 2019, p. 2019; Aliman, N.-M., Kester, L., Werkhoven, P., Yampolskiy, R., Orthogonality-Based Disentanglement of Responsibilities for Ethical Intelligent Systems International Conference on Artificial General Intelligence, 2019, pp. 22-31. , Springer; Werkhoven, P., Kester, L., Neerincx, M., Telling autonomous systems what to do Proceedings of the 36th European Conference on Cognitive Ergonomics, 2018, p. 2. , ACM; Schein, C., Hester, N., Gray, K., The visual guide to morality: Vision as an integrative analogy for moral experience, variability and mechanism (2016) Social and Personality Psychology Compass, 10 (4), pp. 231-251; Schein, C., Gray, K., The theory of dyadic morality: Reinventing moral judgment by redefining harm (2018) Personality and Social Psychology Review, 22 (1), pp. 32-70; Aliman, N., Kester, L., Requisite Variety in Ethical Utility Functions for AI Value Alignment (2019) Proceedings of the Workshop on Artificial Intelligence Safety 2019 Co-located with the 28th International Joint Conference on Artificial Intelligence, AISafety@IJCAI 2019, Macao, China, August 11-12 2019, , http://ceur-ws.org/Vol-2419/paper.12.pdf; Aliman, N.-M., Kester, L., Transformative AI governance and AI-Empowered ethical enhancement through preemptive simulations (2019) Delphi Interdisc. Rev. Emerg. Technol, 2 (1), pp. 23-29; Rotsidis, A., Theodorou, A., Bryson, J.J., Wortham, R.H., Improving robot transparency: An investigation with mobile augmented reality (2019) 28th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), New Delhi. IEEE; Aliman, N.-M., Kester, L., Augmented utilitarianism for agi safety (2019) Artificial General Intelligence, pp. 11-21. , P. Hammer, P. Agrawal, B. Goertzel, and M. Ikĺe, Eds. Cham Springer International Publishing; Hester, N., Gray, K., The moral psychology of raceless genderless strangers To Appear in Perspectives on Psychological Science, 2019; Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge, University Press; Awad, E., Dsouza, S., Kim, R., Schulz, J., Henrich, J., Shariff, A., Bonnefon, J.-F., Rahwan, I., The moral machine experiment (2018) Nature, 563 (7729), p. 59; Bonnefon, J.-F., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2016) Science, 352 (6293), pp. 1573-1576; Faulhaber, A.K., Dittmer, A., Blind, F., Wächter, M.A., Timm, S., Sütfeld, L.R., Stephan, A., König, P., Human decisions in moral dilemmas are largely described by utilitarianism: Virtual car driving study provides guidelines for autonomous driving vehicles (2019) Science and Engineering Ethics, 25 (2), pp. 399-418; Kallioinen, N., Pershina, M., Zeiser, J., Nezami, F.N., Stephan, A., Pipa, G., König, P., Moral judgements on the actions of self-driving cars and human drivers in dilemma situations from different perspectives (2019) OSF Preprints; Li, S., Zhang, J., Li, P., Wang, Y., Wang, Q., Influencing factors of driving decision-making under the moral dilemma IEEE Access, 2019; Sütfeld, L.R., Gast, R., König, P., Pipa, G., Using virtual reality to assess ethical decisions in road traffic scenarios: Applicability of value-of-life-based models and influences of time pressure Frontiers in Behavioral Neuroscience, 11 (2017), p. 122; Wilson, H., Theodorou, A., Bryson, J.J., Slam the brakes: Perceptions of moral decisions in driving dilemmas (2019) International Workshop in Artificial Intelligence Safety (AISafety), IJCAI, Macau; Bhagavathula, R., Williams, B., Owens, J., Gibbons, R., The reality of virtual reality: A comparison of pedestrian behavior in real and virtual environments Proceedings of the Human Factors and Ergonomics Society Annual Meeting, 62 (1), pp. 2056-2060. , SAGE Publications Sage CA: Los Angeles, CA, 2018; Dubljevíc, V., Sattler, S., Racine, E., Deciphering moral intuition: How agents, deeds, and consequences influence moral judgment (2018) PloS One, 13 (10), p. e0204631; Bigman, Y.E., Gray, K., People are averse to machines making moral decisions Cognition, 181 (2018), pp. 21-34; Liu, P., Du, Y., Xu, Z., Machines versus humans: Peoples biased responses to traffic accidents involving self-driving vehicles Accident Analysis & Prevention, 125 (2019), pp. 232-240; Bigman, Y., Waytz, A., Alterovitz, R., Gray, K., Holding robots responsible: The elements of machine morality Trends in Cognitive Sciences, 4, p. 2019; Hutchinson, J.B., Barrett, L.F., The power of predictions: An emerging paradigm for psychological research Current Directions in Psychological Science, 2019, p. 831992; Schein, C., Gray, K., Moralization and harmification: The dyadic loop explains how the innocuous becomes harmful and wrong (2016) Psychological Inquiry, 27 (1), pp. 62-65; Yampolskiy, R.V., Artificial Intelligence Safety and Security, 2018. , Chapman and Hall/CRC; Calvo, R.A., Peters, D., Introduction to positive computing: Technology that fosters wellbeing (2015) Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems, pp. 2499-2500. , ACM; Chirico, A., Ferrise, F., Cordella, L., Gaggioli, A., Designing awe in virtual reality: An experimental study Frontiers in Psychology, 8 (2018), p. 2351; Gaggioli, A., Riva, G., Peters, D., Calvo, R.A., Positive technology, computing, and design: Shaping a future in which technology promotes psychological well-being Emotions and Affect in Human Factors and Human-computer Interaction, 2017, pp. 477-502. , Elsevier; Gaggioli, A., Villani, D., Serino, S., Banos, R., Botella, C., Positive technology: Designing e-experiences for positive change Frontiers in Psychology, 10, p. 2019; Quesnel, D., Riecke, B.E., Are You Awed Yet? How Virtual Reality Gives Us Awe and Goose Bumps Frontiers in Psychology, 9, p. 2018; Recupero, A., Triberti, S., Modesti, C., Talamo, A., Mixed reality for cross-cultural integration: Using positive technology to share experiences and promote communication Frontiers in Psychology, 9 (2018), p. 1223; Rosenberg, R.S., Baughman, S.L., Bailenson, J.N., Virtual superheroes: Using superpowers in virtual reality to encourage prosocial behavior (2013) PloS One, 8 (1), p. e55003; Stepanova, E.R., Quesnel, D., Riecke, B., Transformative experiences become more accessible through virtual reality (2018) 2018 IEEE Workshop on Augmented and Virtual Realities for Good (VAR4Good). IEEE, pp. 1-3; Yampolskiy, R.V., (2019) Personal Universes: A Solution to the Multi-Agent Value Alignment Problem, , arXiv preprint arXiv 1901 01851; Zuromski, D., Fedyniuk, A., Maria, E., Can New Technologies Make Us More Human? An Inquiry on VR Technologies in Social Cognition Frontiers in Psychology, 9 (2018), p. 705; Kester, L., Ditzel, M., Maximising effectiveness of distributed mobile observation systems in dynamic situations (2014) 17th International Conference on Information Fusion (FUSIon, pp. 1-8. , IEEE; Aliman, N.-M., Kester, L., Hybrid strategies towards safe "self-Aware Superintelligent Systems, " in International Conference on Artificial General Intelligence, pp. 1-11. , Springer, 2018; Kester, L., Van Willigen, W., De Jongh, J., Critical headway estimation under uncertainty and non-ideal communication conditions (2014) 17th International IEEE Conference on Intelligent Transportation Systems (ITSC). IEEE, pp. 320-327},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Loh2019575,
author={Loh, W. and Misselhorn, C.},
title={Autonomous Driving and Perverse Incentives},
journal={Philosophy and Technology},
year={2019},
volume={32},
number={4},
pages={575-590},
doi={10.1007/s13347-018-0322-6},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075204282&doi=10.1007%2fs13347-018-0322-6&partnerID=40&md5=5943f6361292215d12aa3d318322a6f5},
abstract={This paper discusses the ethical implications of perverse incentives with regard to autonomous driving. We define perverse incentives as a feature of an action, technology, or social policy that invites behavior which negates the primary goal of the actors initiating the action, introducing a certain technology, or implementing a social policy. As a special form of means-end-irrationality, perverse incentives are to be avoided from a prudential standpoint, as they prove to be directly self-defeating: They are not just a form of unintended side effect that must be balanced against the main goal or value to be realized by an action, technology, or policy. Instead, they directly cause the primary goals of the actors—i.e., the goals that they ultimately pursue with the action, technology, or policy—to be “worse achieved” (Parfit). In this paper, we elaborate on this definition and distinguish three ideal-typical phases of adverse incentives, where only in the last one the threshold for a perverse incentive is crossed. In addition, we discuss different possible relevant actors and their goals in implementing autonomous vehicles. We conclude that even if some actors do not pursue traffic safety as their primary goal, as part of a responsibility network they incur the responsibility to act on the common primary goal of the network, which we argue to be traffic safety. © 2018, Springer Nature B.V.},
author_keywords={Autonomous driving;  Perverse incentives;  Responsibility networks;  Robot ethics},
references={Aven, T., (2016). Risk assessment and risk management: Review of recent advances on their foundation (2016) European Journal of Operational Research, 253, pp. 1-13; Bonnefon, J.-F., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2016) Science, 352, pp. 1573-1576; Borenstein, J., Howard, A., Wagner, A., Pediatric robotics and ethics: The robot is ready to see you now, but should it be trusted? (2017) Robot ethics 2.0: New challenges in philosophy, law, and society, pp. 127-141. , Lin P, Abney K, Jenkins R, (eds), Oxford Univ. Press, Oxford; Boudette, N., (2017) Tesla's Self-Driving System Cleared in Deadly Crash. the New Yorck Times, , https://www.nytimes.com/2017/01/19/business/tesla-model-s-autopilot-fatal-crash.html?_r=0, Accessed 27 February 2017; Bratman, M., (1999) Faces of Intention: Selected Essays on Intention and Agency, , Cambridge Univ. Press, Cambridge; Dennett, D., (1989) The intentional stance, , MIT Press, Cambridge Mass; (2017) Automated Driving Roadmap, , http://www.ertrac.org/uploads/documentsearch/id48/ERTRAC_Automated_Driving_2017.pdf, Version 7.0, Accessed 25 November 2017; Frewer, L.J., Howard, C., Shepherd, R., Public concerns in the United Kingdom about general and specific applications of genetic engineering: Risk, benefit, and ethics (1997) Science Technology Hum n Values, 22, pp. 98-124; Gibson, J.J., (1986) The ecological approach to visual perception, , Psychology Press, New York; Gilbert, M., Walking together: A paradigmatic social phenomenon (1990) Midwest Studies in Philosophy, 15, pp. 1-14; Goddard, T., Dill, J., Monsere, C., (2016) Driver Attitudes About Bicyclists: Negative Evaluations of Rule-Following and Predictability. Transportation Research Board 95th Annual Meeting; Golson, J., Driver in fatal tesla autopilot crash had seven seconds to take action (2017) The Verge, , http://www.theverge.com/2017/1/19/14326604/tesla-autopilot-crash-driver-seven-seconds-inattentive-nhtsa, Accessed 23 March 2017; Goodall, N., Machine Ethics and automated vehicles (2014) Road vehicle automation, pp. 93-102. , Meyer G, Beiker S, (eds), Springer, Cham: Lecture Notes Mobility; Goodrich, M.A., Schultz, A.C., Human-robot interaction: A survey (2007) Foundations and Trends in Human-Computer Interaction, 1, pp. 203-275; Gosepath, S., (1992) Aufgeklärtes Eigeninteresse: Eine Theorie theoretischer und praktischer Rationalität, , Suhrkamp, Frankfurt/Main; Habermas, J., Three normative models of democracy (1994) Constellations, 1 (1), pp. 1-10; Hancock, P., (2014). Automation: How much is too much? (2014) Ergonomics, 57, pp. 449-454; Hansson, S.O., (2013) The ethics of risk: Ethical analysis in an uncertain world, , Palgrave Macmillan, New York; Jennings, N., Sycara, K., Woolridge, M., A roadmap of agent Research and Development (1998) Autonomous Agents and Multi-Agent Systems, 1, pp. 7-38; Kirkpatrick, J., Hahn, E., Haufler, A., Trust and human-robot interactions (2017) Robot ethics 2.0: New challenges in philosophy, law, and society, pp. 142-156. , Lin P, Abney K, Jenkins R, (eds), Oxford Univ. Press, Oxford; Kyriakidis, M., Happee, R., de Winter, J.C.F., Public opinion on automated driving: Results of an international questionnaire among 5000 respondents (2015) Transportation Research Part F: Traffic Psychology and Behaviour, 32, pp. 127-140; Kyriakidis, M., de Winter, J.C.F., Stanton, N., Bellet, T., van Arem, B., Brookhuis, K., A human factors perspective on automated driving (2017) Theoretical Issues in Ergonomics Science, 53, pp. 1-27; Levin, S., Woolf, N., (2016) Tesla Driver Killed while Using Autopilot was Watching Harry Potter, Witness Says, , https://www.theguardian.com/technology/2016/jul/01/tesla-driver-killed-autopilot-self-driving-car-harry-potter, July 1, The Guardian, Accessed 2 June 2018; Lin, P., The ethics of saving lives with autonomous cars is far murkier than you think (2013) Wired, , https://www.wired.com/2013/07/the-surprising-ethics-of-robot-cars/, Accessed 16 August 2017; Lin, P., (2014) Here’s a Terrible Idea: Robot Cars with Adjustable Ethics Settings. Wired, , http://www.wired.com/2014/8/heres-a-terrible-idea-robotcars-with-adjustable-ethics-settings/, August 18, Accessed 30 November 2017; Lin, P., Is tesla responsible for the deadly crash on auto-pilot? Maybe (2016) Forbes, , https://www.forbes.com/sites/patricklin/2016/07/01/is-tesla-responsible-for-the-deadly-crash-on-auto-pilot-maybe/#23ec768b1c07, Accessed 27 February 2017; Lin, P., Abney, K., Jenkins, R., (2017) Robot Ethics 2.0: New Challenges in Philosophy, Law, and Society, , (eds), Oxford Univ. Press, Oxford; List, C., Pettit, P., (2011) Group agency: The possibility, design, and status of corporate agents, , Oxford Univ. Press, Oxford; Loh, J., Loh, W., Autonomy and responsibility in hybrid systems: The example of autonomous cars (2017) Robot ethics 2.0: New challenges in philosophy, law, and society, , Lin P, Abney K, Jenkins R, (eds), Oxford Univ. Press, Oxford UK; Madigan, R., Louw, T., Dziennus, M., Graindorge, T., Ortega, E., Graindorge, M., Acceptance of automated road transport systems (ARTS): An adaptation of the UTAUT model (2016) Transportation Research Procedia, 14, pp. 2217-2226; Merton, R., The unanticipated consequences of purposive social action (1936) American Sociological Review, 1 (6), pp. 894-904; Meyer, G., Beiker, S., (2016) Road Vehicle Automation 3, , (eds), Lecture notes mobility, Springer International Publishing; Imprint; Springer, Cham; Misselhorn, C., Robots as Moral Agents (2013) Ethics in Science and Society: German and Japanese Views, pp. 30-42. , Rövekamp F, Friederike B, (eds), Iudicum, München; Misselhorn, C., Collective agency and cooperation in natural and artificial systems (2015) Collective agency and cooperation in natural and artificial systems: Explanation, implementation and simulation, pp. 3-24. , Misselhorn C, (ed), Springer, London; Neuhäuser, C., Some Sceptical remarks regarding robot responsibility and a way forward (2015) Collective agency and cooperation in natural and artificial systems: Explanation, implementation and simulation, pp. 131-146. , Misselhorn C, (ed), Springer, London; (2014) Fatalities by State and Road Function Class, , https://www-fars.nhtsa.dot.gov/States/StatesCrashesAndAllVictims.aspx, Accessed 23 April 2017; Norcross, A., Great harms from small benefits grow: How death can be outweighed by headaches (1998) Analysis, 58 (2), pp. 152-158; Norman, D.A., (1988) The psychology of everyday things, , Basic Books, New York, NY; (1966) National Traffic and Motor Vehicle Safety Act: Public Law, pp. 89-563; Nyholm, S., Attributing agency to automated systems: Reflections on human–robot collaborations and responsibility-loci (2017) Science and Engineering Ethics; Nyholm, S., Smids, J., (2016) The ethics of accident-algorithms for self-driving cars: An applied trolley problem? Ethical Theory and Moral Practice, 19, 1275–1289n.d, , https://doi.org/10.1007/s10677-016-9745-2; Nyholm, S., Smids, J., Automated cars meet human drivers: Responsible human-robot coordination and the ethics of mixed traffic (2018) Ethics and Information Technology, 9, p. 332; Parasuraman, R., Riley, V., Humans and automation: Use, misuse, disuse, abuse (1997) Human Factors, 39, pp. 230-253; Parfit, D., (1984) Reasons and persons, , Oxford Univ. Press, Oxford; Parfit, D., (2011) On what matters, , Oxford University Press, Oxford; Peden, M., Scurfield, R., Sleet, D., Mohan, D., Hyder, A., Jarawan, E., (2004) World Report on Road Traffic Injury Prevention. Geneva, , http://cdrwww.who.int/violence:injury_prevention/publications/road_traffic/world_report/intro.pdf, Accessed 30 November 2017; Rayna, T., Striukova, L., Landau, S., Crossing the chasm or being crossed out: The case of digital audio players (2009) International Journal of Actor-Network Theory and Technological Innovation, 1 (3), pp. 36-54; Raz, J., The myth of instrumental rationality (2005) Journal of Ethics and Social Philosophy, 1, pp. 1-28; Renn, O., (2008) Risk governance: Coping with uncertainty in a complex world, , Earthscan, London u.A; Robinette, P., Li, W., Allen, R., Howard, A.M., Wagner, A.R., (2016) Overtrust of Robots in Emergency Evacuation Scenarios, pp. 101-108. , IEEE Press, Piscataway NJ; Roeser, S., Hillerbrand, R., Sandin, P., Peterson, M., (2012) Handbook of risk theory, , (eds), Springer Netherlands, Dordrecht; Rogers, E.M., (1962) Diffusion of innovations, , Free Press of Glencoe, New York; (2016) Taxonomy and Definitions for Terms Related to Driving Automation Systems for On-Road Motor Vehicles, , Washington DC, SAE International; Santoni De Sio, F., (2016) Ethics and Self-Driving Cars: A White Paper on Responsible Innovation in Automated Driving Systems. Dutch Ministry of Infrastructure and Environment Rijkswaterstaat; Scanlon, T., (1998) What we owe to each other, , Belknap Press of Harvard Univ. Press, Cambridge MA; Scanlon, T., Structural irrationality (2007) Common minds: Themes from the philosophy of Philip Pettit, pp. 84-103. , Brennan G, Goodin R, Jackson F, Smith M, (eds), Clarendon, Oxford; Searle, J., Collective intentions and actions (1990) Intentions in communication, pp. 401-415. , Cohen P, Morgan J, Pollack M, (eds), MIT Press, Cambridge MA; Siebert, H., (2001) Der Kobra-Effekt: Wie man Irrwege der Wirtschaftspolitik vermeidet, , Deutsche Verlags-Anstalt, München; Smith, M., (1994) The moral problem, , Philosophical theory, Blackwell, Oxford; Stilgoe, J., (2017) Tesla Crash Report Blames Human Error - This is a Missed Opportunity. the Guardian, , https://www.theguardian.com/science/political-science/2017/jan/21/tesla-crash-report-blames-human-error-this-is-a-missed-opportunity.Accessed23March2017; Taebi, B., Bridging the gap between social acceptance and ethical acceptability (2017) Risk Analysis, 37, pp. 1817-1827; Taurek, J., Should the numbers count? (1977) Philosophy and Public Affairs, 6 (4), pp. 293-316; Tennant, C., Howard, S., Franks, B., Bauer, M., Stares, S., Pansegrau, P., (2016) Autnonomous Vehicles - Negotiating A Place on the Road: A Study on How Drivers Feel about Interacting with Autonomous Vehicles on the Road, , http://www.lse.ac.uk/website-archive/newsAndMedia/PDF/AVs-negociating-a-place-on-the-road-1110.pdf.Accessed16August2017; Motors, T., (2016) A Tragic Loss, , https://www.tesla.com/blog/tragic-loss.Accessed23March2017; van de Poel, I., Fahlquist, J.N., Doorn, N., Zwart, S., Royakkers, L., The problem of many hands: Climate change as an example (2011) Science and Engineering Ethics, 18 (1), pp. 49-67; Voorhoeve, A., How should we aggregate competing claims? (2014) Ethics, 125 (1), pp. 64-87; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press, Oxford, New York; Weber, M., (1978) Economy and Society, , University of California Press, Berkeley CA; Winter, J., Happee, R., Martens, M.H., Stanton, N.A., Effects of adaptive cruise control and highly automated driving on workload and situation awareness: A review of the empirical evidence (2014) Transportation Research Part F: Traffic Psychology and Behaviour, 27, pp. 196-217},
document_type={Article},
source={Scopus},
}

@ARTICLE{Dorobantu20191004,
author={Dorobantu, M. and Wilks, Y.},
title={MORAL ORTHOSES: A NEW APPROACH TO HUMAN AND MACHINE ETHICS},
journal={Zygon},
year={2019},
volume={54},
number={4},
pages={1004-1021},
doi={10.1111/zygo.12560},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075171196&doi=10.1111%2fzygo.12560&partnerID=40&md5=256b365bd80fe11eac9cd45f31e683c4},
abstract={Machines are increasingly involved in decisions with ethical implications, which require ethical explanations. Current machine learning algorithms are ethically inscrutable, but not in a way very different from human behavior. This article looks at the role of rationality and reasoning in traditional ethical thought and in artificial intelligence, emphasizing the need for some explainability of actions. It then explores Neil Lawrence's embodiment factor as an insightful way of looking at the differences between human and machine intelligence, connecting it to the theological understanding of embodiment, relationality, and personhood. Finally, it proposes the notion of artificial moral orthoses, which could provide ethical explanations for both artificial and human agents, as a more promising unifying approach to human and machine ethics. © 2019 by the Joint Publication Board of Zygon},
author_keywords={artificial companions;  artificial intelligence;  David Hume;  embodiment;  ethics;  explainable AI;  machine learning;  Neil Lawrence;  relationality;  theology},
references={Akoudas, K., Bringsjord, S., Bello, P., Towards Ethical Robots via Mechanized Deontic Logic (2005) AAAI Fall Symposium on Machine Ethics, pp. 17-23. , edited by, Geert-Jan M Kruijff, Fiora Pirri, Menlo Park, CA, The AAAI Press; Ananthanarayanan, R., Esser, S.K., Simon, H.D., Modha, D.S., The Cat Is Out of the Bag: Cortical Simulations with 109 Neurons, 1013 Synapses (2009) Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis, , https://doi.org/10.1145/1654059.1654124, —-sc ’09, Article 63; Anderson, M., Anderson, S.L., Robot Be Good (2010) Scientific American, pp. 72-77. , 303; Asimov, I., Runaround (1950) I, Robot, , edited by, Isaac Asimov, 25–45., New York, NY, Doubleday; Awad, E., Dsouza, S., Kim, R., Schulz, J., Henrich, J., Shariff, A., Bonnefo, J.-F., Rahwan, I., The Moral Machine Experiment (2018) Nature, 563, pp. 59-64; Bostrom, N., Yudkowsky, E., The Ethics of Artificial Intelligence (2014) The Cambridge Handbook of Artificial Intelligence, pp. 316-334. , edited by, Keith Frankish, William M. Ramsey, Cambridge, UK, Cambridge University Press; Charniak, E., (1996) Statistical Language Learning, , Cambridge, MA, Bradford Books; Clocksin, W.F., (2002) Artificial Intelligence and Theological Anthropology, , ” Report on Theological Anthropology, Faith and Order Commission, World Council of Churches FO 33. Grand-Saconnex, Switzerland World Council of Churches; Dennett, D., Intentional Systems (1971) The Journal of Philosophy, 68, pp. 87-106; Dorobantu, M., Recent Advances in Artificial Intelligence (AI) and Some of the Issues in the Theology and AI Dialogue (2019) ESSSAT News and Reviews, 29, pp. 4-17; Eubanks, V., (2018) Automating Inequality, , New York, NY, Macmillan; Foot, P., (2002) Moral Dilemmas, , Oxford, UK, Clarendon Press; Ford, K.M., Hayes, P.J., Glymour, C., Allen, J., Cognitive Orthoses: Towards Human-centered AI (2015) AI Magazine, 36, pp. 5-8; Gergen, K.J., (1991) The Saturated Self: Dilemmas of Identity in Contemporary Life, , New York, NY, Basic Books; Gide, A., (1914) Les caves du Vatican, , Paris, France, Editions de la nouvelle revue; Gray, J., (2002) Straw Dogs, , London, UK, Granta Books; Haidt, J., (2006) The Happiness Hypothesis: Finding Modern Truth in Ancient Wisdom, , New York, NY, Basic Books; Herzfeld, N., Co-creator or co-Creator? The Problem with Artificial Intelligence (2005) Creative Creatures: Values and Ethical Issues in Theology, Science and Technology, pp. 45-52. , edited by, Ulf Görman, Willem Drees, Hubert Meisinger, London, UK, T&T Clark; Hume, D., (1751) An Enquiry Concerning the Principles of Morals, , 1907., London, UK, Longman, GreenCo; Hume, D., (2007) A Treatise of Human Nature, (1738). , Oxford, UK, Clarendon Press; Jaynes, J., (1976) The Origin of Consciousness in the Breakdown of the Bicameral Mind, , Boston, MA, Houghton Mifflin; Kahneman, D., (2011) Thinking, Fast and Slow, , New York, NY, Farrar, Straus and Giroux; Lawrence, N., (2017) Living Together: Mind and Machine Intelligence, , https://arxiv.org/abs/1705.07996; Leibniz, G.W., Opinion on the Principles of Pufendorf (1988) Leibniz: Political Writings, pp. 64-76. , edited by, Patrick Riley, Cambridge, UK, Cambridge University Press; Levy, D., (2007) Love and Sex with Robots, , New York, NY, Harper Collins; MacIntyre, A., (1985) After Virtue, , 2nd ed., London, UK, Duckworth; Marsella, S., Gratch, J., Petta, P., Computational Models of Emotion (2010) A Blueprint for Affective Computing: A Sourcebook, pp. 21-46. , edited by, Klaus R. Scherer, Tanja Bänziger, Etienne B. Roesch, Oxford, UK, Oxford University Press; McDermott, D., Why Ethics Is a High Hurdle for AI (2008) Proceedings of the North American Conference on Computers and Philosophy (NACAP), , Bloomington, IN; McFadyen, A., (1990) The Call to Personhood: A Christian Theory of the Individual in Social Relationships, , Cambridge, UK, Cambridge University Press; Moor, J.H., The Nature, Importance, and Difficulty of Machine Ethics (2006) IEEE Intelligent Systems, 21, pp. 18-21; Mueller, S.T., Hoffman, R.R., Clancey, W., Emrey, A., Klein, G., (2019) Explanation in Human-AI Systems: A Literature Meta-Review Synopsis of Key Ideas and Publications and Bibliography for Explainable AI, , https://arxiv.org/pdf/1902.01876.pdf, ” DARPA XAI Program; Parisi, D., Mental Robotics (2007) Artificial Consciousness, pp. 191-211. , edited by, Antonio Chella, Riccardo Manzotti, Exeter, UK, Imprint Academic; Pearl, J., (2018) The Book of Why: The New Science of Cause and Effect, , New York, NY, Basic Books; Shults, F.L., (2003) Reforming Theological Anthropology: After the Philosophical Turn to Relationality, , Grand Rapids, MI, William B. Eerdmans; Vincent, J., (2019) World's Fastest Supercomputer Will Be Built by AMD and Cray for US Government, , https://www.theverge.com/2019/5/7/18535078/worlds-fastest-exascale-supercomputer-frontier-amd-cray-doe-oak-ridge-national-laboratory, The Verge; Waldrop, M.M., A Question of Responsibility (1987) AI Magazine, 8, pp. 29-39; Wason, P.C., Johnson-Laird, P., (1972) Psychology of Reasoning: Structure and Content, , Cambridge, MA, Harvard University Press; Wilks, Y., Understanding without Proofs (1973) Proceedings of the 3rd International Joint Conference on Artificial Intelligence, pp. 270-277. , San Francisco, CA, Morgan Kaufmann Publishers; Wilks, Y., Machines and Consciousness (1984) Minds, Machines and Evolution, pp. 105-129. , edited by, Christopher Hookway, Cambridge, UK, Cambridge University Press; Wilks, Y., (2010) Artificial Companions, , ed., Amsterdam, The Netherlands, John Benjamins; Wilks, Y., Ballim, A., Liability and Consent (1990) Law, Computers and Artificial Intelligence, , edited by, Ajit Narayanan, Mervyn Bennun, Norwood, NJ, Ablex; Yudkowsky, E., (2016) The AI Alignment Problem: Why It's Hard and Where to Start. Machine Intelligence Research Institute (MIRI) website, , https://intelligence.org/files/AlignmentHardStart.pdf; Zittrain, J., (2019) The Hidden Costs of Automated Thinking, , The New Yorker, July 23},
document_type={Article},
source={Scopus},
}

@ARTICLE{Beharrell2019984,
author={Beharrell, W.H.},
title={TRANSFORMATION AND THE WAKING BODY: A RETURN TO TRUTH VIA OUR BODIES: with Fraser Watts, “Mutual Enhancement between Science and Religion: In the Footsteps of the Epiphany Philosophers”; William H. Beharrell, “Transformation and the Waking Body: A Return to Truth via our Bodies”; Marius Dorobantu and Yorick Wilks, “Moral Orthoses: A New Approach to Human and Machine Ethics”; Galen Watts, “Religion, Science, and Disenchantment in Late Modernity”; and Rowan Williams, “Epiphany Philosophers: Afterword.”},
journal={Zygon},
year={2019},
volume={54},
number={4},
pages={984-1003},
doi={10.1111/zygo.12553},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075050460&doi=10.1111%2fzygo.12553&partnerID=40&md5=bc40d1f760cd6eb2f577e92d562a2599},
abstract={This article considers the kind of knowledge that is constituted through embodied sensory perception and makes the case for a form of knowledge that is embodied, relational, and potentially transformational. Such knowledge is encountered through our physiological senses and cultivated by reestablishing connections to our bodies. The discussion starts by exploring the literature on sensory perception and interoception and moves on to the role of human agency, which is implicit in the idea of top-down causation. It is argued that this process can be explained by a top-down predictive model within which a sense of greater interoceptive accuracy may be cultivated while reducing interoceptive perturbation. The roles of active and perceptual inference are discussed with regard to the regulatory opportunities that these types of attention yield. By being more interoceptively aware, through a practice of contemplation, it is argued, we open ourselves to an encounter with divine presence that is immanent in the world around us. © 2019 by the Joint Publication Board of Zygon},
author_keywords={contemplation;  interoception;  perception;  sense},
references={Bennett, M.R., Hacker, P.M.S., (2003) Philosophical Foundations of Neuroscience, , Oxford, UK, Blackwell Publishing; Cacioppo, J., Joseph, P., Gary, B., Rudimentary Determination of Attitudes: II. Arm Flexion and Extension Have Differential Effects on Attitudes (1993) Journal of Personality and Social Psychology, 65, pp. 5-17; Carter, L., McNeil, D.W., Vowles, K., Sorrell, J.T., Turk, C.L., Reiss, B.J., Hopko, D.R., Effects of Emotion on Pain Reports, Tolerance and Physiology (2001) Pain Research and Management, 7, pp. 21-30; Clark, S., (1998) God, Religion, and Reality, , London, UK, SPCK; Cook, C., (2011) The Philokalia and the Inner Life, , Cambridge, UK, James Clarke & Co; Critchley, H., Sarah, G., Interactions between Visceral Afferent Signaling and Stimulus Processing (2015) Frontiers in Neuroscience, 9, p. 286; Critchley Hugo, D., Garfinkel, S.N., Interoception and Emotion (2017) Current Opinion in Psychology, 17, pp. 7-14; Edwards, T., Stern, A., Clarke, D., Ivbijaro, G., Kasney, M.L., The Treatment of Patients with Medically Unexplained Symptoms in Primary Care: A Review of the Literature (2010) Mental Health in Family Medicine, 7, pp. 209-221; Farb, N., Daubenmier, J., Price, C., Gard, T., Kerr, C., Dunn, B.D., Klein, A.C., Mehling, W.R., Interoception, Contemplative Practice, and Health (2015) Frontiers in Psychology, 6. , https://www.frontiersin.org/article/10.3389/fpsyg.2015.00763; Fleming, U., (1990) Grasping the Nettle: A Positive Approach to Pain, , London, UK, Fount; Jones, J.W., (2019) Living Religion: Embodiment, Theology, and the Possibility of a Spiritual Sense, , New York, NY, Oxford University Press; Kang, Y., Williams, L.E., Clark, M.S., Gray, J.R., Bargh, J.A., Physical Temperature Effects on Trust Behavior: The Role of Insula (2011) Social Cognitive and Affective Neuroscience, 6, pp. 507-515; McGilchrist, I., (2009) The Master and His Emissary, , New Haven, CT, Yale University Press; Morgan, M.J., (1977) Vision, Touch and the Philosophy of Perception, , Cambridge, UK, Cambridge University Press; Nieuwenhuis, M., Knight, C., Postmes, T., Haslam, S.A., The Relative Benefits of Green versus Lean Office Space: Three Field Experiments (2014) Journal of Experimental Psychology, 20, pp. 199-214; Peterson, S.R., (1998) Why Is the Sound of a Pipe Organ Better?, , ” PipeOrgans.com; Petzschner, F.H., Weber, L.A.E., Gard, T., Klaas, S.E., Computational Psychosomatics and Computational Psychiatry: Toward a Joint Framework for Differential Diagnosis (2017) Biological Psychiatry, 82, pp. 421-430; Piekarski, M., Commentary: Brain, Mind, World: Predictive Coding, Neo-Kantianism, and Transcendental Idealism (2017) Frontiers in Psychology, 8. , https://doi.org/10.3389/fpsyg.2017.02077; Ring, K., Near Death Experiences and Out of Body Experiences in the Blind: A Study of Apparent Eyeless Vision in the Blind (1997) Journal of Near Death Studies, 16 (2), pp. 101-147; Schroeder, F.M., (1992) Form and Transformation: A Study in the Philosophy of Plotinus, , Montreal, Canada, McGill Queen's University Press; Seth, A.K., Suzuki, K., Critchley, H.D., An Interoceptive Predictive Coding Model of Conscious Presence (2011) Frontiers in Psychology, 2. , https://doi.org/10.3389/fpsyg.2011.00395; Sheldrake, R., (2017) Science and Spiritual Practices, , London, UK, Coronet; Smith, B., (2019) The Art and Science of Blending, , https://www.bbc.co.uk/programmes/m0004cq1, BBC Radio 4, 26th April,,) and 24th April 2019,, https://www.bbc.co.uk/news/uk-47980485 https://www.bbc.co.uk/programmes/m0004f48; Stepper, S., Fritz Strack, Proprioceptive Determinants of Emotional and Non-Emotional Feelings (1993) Journal of Personality and Social Psychology, 64, pp. 211-220; Strack, F., Leonard, M., Sabine, S., Inhibiting and Facilitating Conditions of the Human Smile: A Nonobtrusive Test of the Facial Feedback Hypothesis (1988) Journal of Personality and Social Psychology, 54, pp. 768-777; Tallis, R., What Neuroscience Cannot Tell Us about Ourselves (2010) The New Atlantis: A Journal of Technology and Society, 29, pp. 3-25; Ward, D., Silverman, D., Villalobos, M., Introduction: The Varieties of Enactivism (2017) Topoi, 36, pp. 365-375. , https://doi.org/10.1007/s11245-017-9484-6; Watts, F., Dual System Theories of Religious Cognition (2013) Head and Heart: Perspectives from Religion and Psychology, pp. 125-154. , edited by, Fraser Watts, G. Dumbreck, West Conshohocken, PA, Templeton Press; Wells, G., Richard, P., The Effects of Overt Head Movements on Persuasion: Compatibility and Incompatibility of Responses (1980) Basic and Applied Social Psychology, 1, pp. 219-230; Zanna, M.P., Cooper, J., Dissonance and the Pill: An Attribution Approach to Studying the Arousal Properties of Dissonance (1974) Journal of Personality and Social Psychology, 29, pp. 703-709; Zweyer, K., Velker, B., Ruch, W., Do Cheerfulness, Exhilaration, and Humor Production Moderate Pain Tolerance? A FACS Study (2004) Humor: International Journal of Humor Research, 17, pp. 85-119},
document_type={Article},
source={Scopus},
}

@ARTICLE{Watts2019965,
author={Watts, F.},
title={MUTUAL ENHANCEMENT BETWEEN SCIENCE AND RELIGION: IN THE FOOTSTEPS OF THE EPIPHANY PHILOSOPHERS: with Fraser Watts, “Mutual Enhancement between Science and Religion: In the Footsteps of the Epiphany Philosophers”; William H. Beharrell, “Transformation and the Waking Body: A Return to Truth via our Bodies”; Marius Dorobantu and Yorick Wilks, “Moral Orthoses: A New Approach to Human and Machine Ethics”; Galen Watts, “Religion, Science, and Disenchantment in Late Modernity”; and Rowan Williams, “Epiphany Philosophers: Afterword.”},
journal={Zygon},
year={2019},
volume={54},
number={4},
pages={965-983},
doi={10.1111/zygo.12558},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075042379&doi=10.1111%2fzygo.12558&partnerID=40&md5=ef1d60377eb6adc2181c057e1f3ea40e},
abstract={This article describes some key features of the distinctive approach to issues in science and religion of the Epiphany Philosophers (EPs), and introduces a set of articles from a recent meeting. The objective of the EPs is not merely to establish harmonious coexistence between science and religion. Rather, they are dissatisfied with both, and have a reformist agenda. They see science as unduly constrained by arbitrary metaphysical assumptions, predominantly of an atheist kind, and wish to see it liberated from such constraints. They are also interested in the potential contribution of contemplative enquiry to scientific research. They see no reason why science should not engage with the transcendent, but they do not support any simplistic argument from scientific research to religious belief. They wish to see an approach to religion that is rooted more firmly in the contemplative path. © 2019 by the Joint Publication Board of Zygon},
author_keywords={contemplation;  metaphysics;  religion;  science;  transcendence},
references={Barbour, I.G., (1966) Issues in Science and Religion, , New York, NY, Prentice-Hall; Barbour, I.G., (1974) Myths, Models and Paradigms, , New York, NY, HarperCollins; Bortoft, H., (1996) Wholeness of Nature: Goethe's Way of Science, , Edinburgh, UK, Floris Books; Bowler, P.J., (2001) Reconciling Science and Religion: The Debate in Early Twentieth Century Britain, , Chicago, IL, University of Chicago Press; Braithwaite, R.B., Emmet, D.M., (1954) Epiphany Philosophers: Conference Report, , Privately printed; Brooke, J.H., (1991) Science and Religion: Some Historical Perspectives, , Cambridge, UK, Cambridge University Press; Burtt, E.A., (1952) The Metaphysical Foundations of Modern Physical Science, , Atlantic Highlands, NJ, Humanities Press International; Clarke, C., (2005) Ways of Knowing: Science and Mysticism Today, , Exeter, UK, Imprint Academic; Clarke, I., (2008) Madness, Mystery and the Survival of God, , Winchester, UK, O Books; Coles, A., Collicutt, J., Neurology and Religion, , In press., Cambridge, UK, Cambridge University Press; Conway Morris, S., (2015) The Runes of Evolution: How the Universe Became Self-Aware, , West Conshohocken, PA, Templeton Press; Davies, P., (1990) God and the New Physics, , London, UK, Penguin; Davy, C., (1978) Towards a Third Culture, , Edinburgh, UK, Floris Books; Dein, S., Schizophrenia, Evolution and Self-transcendence (2019) Dunbar's Number, , edited by, David Shankland, ch. 10., London, UK, Royal Anthropological Institute; Depew, D.J., Darwinism, Evolutionary Biology, and Organisms Rethinking Biology: Public Understandings, , In press. “, edited by, Michael J. Reiss, Fraser Watts, Harris Wiseman, London, UK, World Scientific; Emmet, D., (1979) The Moral Prism, , London, UK, Palgrave Macmillan; Eysenck, H.J., Sargant, C., (1993) Explaining the Unexplained: Mysteries of the Paranormal, , London, UK, Prion Books; Force, J.E., (2002) William Whiston: Honest Newtonian, , Cambridge, UK, Cambridge University Press; Gilbert, P., Evolved Minds and Compassion-Focused Imagery in Depression (2009) Imagery and the Threatened Self, pp. 206-233. , edited by, Lusia Stopa, London, UK, Routledge; Gould, S.J., (1999) Rock of Ages: Science and Religion in the Fullness of Life, , New York, NY, Ballantine Books; Harré, R., (1972) The Philosophies of Science, , Oxford, UK, Oxford University Press; Hay, D., (1982) Exploring Inner Space: Scientists and Religious Experience, , Harmondsworth, UK, Penguin; Hesse, M., (1963) Models and Analogies in Science, , London, UK, Sheed and Ward; Hodgson, P.E., (2005) Theology and Modern Physics, , London, UK, Routledge; James, W., (2012) The Varieties of Religious Experience: A Study in Human Nature, , [1902], New York, NY, Oxford University Press; Lash, N., Observation, Revelation, and the Posterity of Noah (1988) Physics, Philosophy, and Theology: A Common Quest for Understanding, , edited by, Robert J. Russell, William R. Stoeger, SJ, George V. Coyne, Vatican City, Vatican Observatory; Masterman, M., Ascetical Theology and the Psychology of Mysticism: Theological and Scientific Terminologies (1954) Epiphany Philosophers: Conference Report, , http://epiphanyphilosophers.org, edited by, Richard B. Braithwaite, Dorothy M. Emmet, Privately printed; Masterman, M., Theism as a Scientific Hypothesis. Part III (1967) Theoria to Theory, 1, pp. 232-250; Masterman, M., (1978) The Eternal Logos: Thinking at the Boundaries of Thought, , http://epiphanyphilosophers.org/wp-content/uploads/2016/12/Full_RE_2.pdf; Masterman, M., Wilks, Y., (2005) Language, Cohesion and Form, , Cambridge, UK, Cambridge University Press; McLeish, T., (2014) Faith and Wisdom in Science, , Oxford, UK, Oxford University Press; Murphy, N., (1990) Theology in an Age of Scientific Reasoning, , Ithaca, NY, Cornell University Press; Nagel, T., (1986) The View from Nowhere, , New York, NY, Oxford University Press; Nowak, M., Coakley, S., (2013) Evolution, Games and God: The Principle of Cooperation, , Cambridge, MA, Harvard University Press; Pannenberg, W., (1993) Towards a Theology of Nature: Essays on Science and Faith, , edited by, Ted Peters, Louisville, KY, Westminster John Knox Press; Polanyi, M., (1958) Personal Knowledge: Towards a Post-Critical Philosophy, , London, UK, Routledge; Polkinghorne, J., (1991) Reason and Reality, , London, UK, SPCK; Polkinghorne, J., (1996) Scientists as Theologians: A Comparison of the Writings of Ian Barbour, Arthur Peacocke, and John Polkinghorne, , London, UK, SPCK; Polkinghorne, J., (2007) Quantum Physics and Theology: An Unexpected Kinship, , New Haven, CT, Yale University Press; Rahner, K., (1982) Theological Investigations XX: Concern for the Church, , New York, NY, Crossroad/Continuum; Rahner, K., Christology within an Evolutionary View of the World (1997) Foundations of Christian Faith: An Introduction to the Idea of Christianity, , New York, NY, Crossroad; Ruse, M., (2000) Can a Darwinian Be a Christian? The Relationship between Science and Religion, , Cambridge, UK, Cambridge University Press; Ruse, M., (2017) On Purpose, , Princeton, NJ, Princeton University Press; Sheldrake, R., (2003) The Sense of Being Stared At: And Other Unexplained Powers of Human Minds, , New York, NY, Crown; Sheldrake, R., (2011) Dogs That Know When Their Owners Are Coming Home: And Other Unexplained Powers of Animals, , revised edition), New York, NY, Three Rivers Press; Sheldrake, R., (2017) Science and Spiritual Practices: Reconnecting through Direct Experience, , London, UK, Coronet; Sheldrake, R., (2019) Ways to Go Beyond and Why They Work: Seven Spiritual Practices in a Scientific Age, , London, UK, Coronet; Taylor, C., (1989) Sources of the Self: The Making of the Modern Identity, , Cambridge, MA, Harvard University Press; Tipler, F.J., (1995) The Physics of Immortality: Modern Cosmology, God and the Resurrection of the Dead, , New York, NY, Anchor; Watts, F., Clinical Judgment and Clinical Training (1980) British Journal of Medical Psychology, 53, pp. 95-108; Watts, F., Morphic Fields and Extended Mind: An Examination of the Theoretical Concepts of Rupert Sheldrake (2011) Journal of Consciousness Studies, 18, pp. 203-224; Watts, F., Dual System Theories of Religious Cognition (2013) Head and Heart: Perspectives from Religion and Psychology, , edited by, Fraser Watts, Geoff Dumbreck, West Conshohocken, PA, Templeton Press; Watts, F., Embodied Cognition and Religion (2013) Zygon: Journal of Religion and Science, 48, pp. 745-758; Watts, F., Towards a Bolder Engagement between Theology and Science: Learning from the Epiphany Philosophers (2016) Forty Years of Science and Religion: Looking Back, Looking Forward, , edited by, Neil Spurway, Louise Hickman, Newcastle upon Tyne, UK, Cambridge Scholars Press; Watts, F., (2017) Psychology, Religion and Spirituality: Concepts and Applications, , Cambridge, UK, Cambridge University Press; Watts, F., Williams, M., (1988) The Psychology of Religious Knowing, , Cambridge, UK, Cambridge University Press; Westphal, J., (1987) Colour, , Oxford, UK, Wiley-Blackwell; Wilks, Y., (2019) Artificial Intelligence: Modern Magic or Dangerous Future, , London, UK, Icon Books; Williams, H.A., (1965) The True Wilderness, , London, UK, Constable; Wolpert, L., (2006) Six Impossible Things before Breakfast: Evolutionary Origins of Belief, , New York, NY, W. W. Norton},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Narayanan2019231,
author={Narayanan, A.},
title={Ethical judgement in intelligent control systems for autonomous vehicles},
journal={2019 Australian and New Zealand Control Conference, ANZCC 2019},
year={2019},
pages={231-236},
doi={10.1109/ANZCC47194.2019.8945790},
art_number={8945790},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078736870&doi=10.1109%2fANZCC47194.2019.8945790&partnerID=40&md5=e79fe13aa10ff0b71f83ba705a0cc586},
abstract={The role of ethical judgement in autonomous control systems is gaining increasing prominence. In particular, there is increasing concern about 'killer robots', drones that can kill on their own, and intelligent autonomous vehicles such as driverless cars. Recent incidents involving autonomous vehicles in which humans have been killed or injured have raised questions about whether such vehicles can have an ethical dimension to their behavior so that they know when it is right or wrong to take over control from a human driver or hand control back, no matter how advanced their embedded artificial intelligence and sensor technology. This paper describes a fuzzy control approach to machine ethics that shows how it is possible for an ethics architecture to be part of a control system to calculate when taking over from a human driver is morally justified. One major advantage of the approach is that such an ethical reasoning architecture can generate its own data for learning moral rules and thereby reduce the possibility of picking up human biases and prejudices. © 2019 IEEE.},
keywords={Control systems;  Fuzzy control;  Intelligent robots;  Man machine systems;  Philosophical aspects, Autonomous control systems;  Control approach;  Ethical judgements;  Hand control;  Human drivers;  Intelligent autonomous vehicles;  Picking up;  Sensor technologies, Autonomous vehicles},
references={(2017) The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems. Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems, Version 2, , http://standards.ieee.org/develop/indconn/ec/autonomous-systems.html; https://standards.ieee.org/develop/indconn/ec/ead-executive-summary-v2.pdf; Russell, S.N., Norvig, P., (2009) The Ethics and Risks of Developing Artificial Intelligence., , 3rd Edition Prentice Hall; Anderson, M., Anderson, S.L., (2011) Machine Ethics.; Arvan, M., Mental time-travel, semantic flexibility, and ai ethics (2018) AI & Society, , https://doi.org/10.1007/s00146-018-0848-2, Accessed 24 August 2018; McLaren, B.M., Computational models of ethical reasoning: Challenges, initial steps, and future directions (2006) IEEE Intelligent Systems., 21 (4), pp. 29-37; Anderson, Anderson, (2011) Ma-chine Ethics, , Reprinted. CUP; Guarini, M., Computational neural modelling and the philosophy of ethics: Reflections on the particu-larism-generalism debate (2011) Machine Ethics., , In Anderson and Anderson (Eds.). CUP; Arkin, R.C., Ulam, P., Duncan, B., (2009) An Ethical Governor for Constraining Lethal Action in An Autonomous System, , http://digitalcommons.unl.edu/cstechreports/163, CSE Technical Reports. 163. Accessed April 2019 from; MacKworth, A.K., Architectures and ethics for robots: Constraint satisfaction as a unitary design framework (2011) Machine Ethics., , In Anderson and Anderson (Eds.). CUP; Bringsjord, S., Arkoudas, K., Bello, P., Towards a general logicist methodology for engineering ethically correct robots (2006) IEEE Intelligent Systems., 21 (4), pp. 38-44; Bringsjord, S., Taylor, J., Van Heuveln, B., Arkoudas, K., Clark, M., Wojtowicz, R., Piagetian roboethics via category theory: Moving beyond mere formal operations to engineer robots whose decisions are guaranteed to be ethically correct (2011) Machine Ethics., , In Anderson and Anderson (Eds.). CUP; Pereira, L.M., Saptawijaya, A., Modeling morality with prospective logic (2011) Machine Ethics., , In Anderson and Anderson (Eds.). CUP; Anderson, S.L., Anderson, M., A prima-facie duty approach to machine ethics: Machine learning of features of ethical dilemmas, prima facie duties, and decision principles through a dialogue with ethicists (2011) Machine Ethics., , In Anderson and Anderson (Eds.). CUP; Anderson, S.L., Anderson, M., A prima facie duty approach to machine ethics (2011) Machine Ethics., , In Anderson and An-derson (Eds.). CUP; Garcia, M., Racist in the machine: The disturbing implications of algorithmic bias (2016) World Policy Journal, 33 (4), pp. 111-117. , http://muse.jhu.edu/article/645268/pdf, Accessed October 2018, from; Wettschereck, D., Dietterich, T.G., An experimental comparison of the nearest-neighbor and nearest-hyperrectangle algorithms (1995) Machine Learning., 19, pp. 1-25; Arkin, R.C., Governing lethal behaviour: Embedding ethics in a hybrid deliberative/reactive robot architecture (2007) Part 1: Motivation and Philosophy, , https://www.cc.gatech.edu/ai/robot-lab/online-publications/formalizationv35.pdf, Technical Report GIT-GVU-07-11. Georgia Institute of Technology. accessed August 2019},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Donhauser2019176,
author={Donhauser, J.},
title={Environmental robot virtues and ecological justice},
journal={Journal of Human Rights and the Environment},
year={2019},
volume={10},
number={2},
pages={176-192},
doi={10.4337/jhre.2019.02.02},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073470460&doi=10.4337%2fjhre.2019.02.02&partnerID=40&md5=dbb47649dd6fc46ff87c8a2019bc86e4},
abstract={Robotics technologies are being used for environmental research, and engineers and ecologists are exploring ways of integrating an array of new robots into ecosystems as a means of responding to mounting environmental problems. These efforts introduce new roles that robots may play in our environments, potentially crucial new forms of human dependence on such robots, and new ways that robots can promote and enhance well-being. Such approaches at once bring up questions about when the use of robots for repairing or mitigating ecological problems is ethically permissible and when it is not. This article builds on recent work on the ethics of such ‘environmental robots’, and advances a virtue-centred framework for guiding the development and use of robots for environmental engineering and for addressing ecological justice issues. © 2019 The Author.},
author_keywords={Anthropocene;  Ecological justice;  Ecological robots;  Environmental robotics;  Robot ethics},
references={Van Wynsberghe, A., Donhauser, J., The Dawning of the Ethics of Environmental Robots (2018) Science and Engineering Ethics, 24 (6), pp. 1777-1800; Aravind, K.R., Raja, P., Pérez-Ruiz, M., Task-Based Agricultural Mobile Robots in Arable Farming: A Review (2017) Spanish Journal of Agricultural Research, 15 (1), pp. 01-02; Yaghoubi, S., Akbarzadeh, N.A., Bazargani, S.S., Bamizan, M., Asl, M.I., Autonomous Robots for Agricultural Tasks and Farm Assignment and Future Trends in Agro Robots (2013) International Journal of Mechanical and Mechatronics Engineering, 13 (3), pp. 1-6; Lam, T.L., Yangsheng, X., (2012) Tree Climbing Robot: Design, Kinematics and Motion Planning, p. 140. , Springer, Heidelberg; Hart, J.K., Martinez, K., Environmental Sensor Networks: A Revolution in the Earth System Science? (2006) Earth-Science Reviews, 78 (3), pp. 177-191; Rundel, P.W., Graham, E.A., Allen, M.F., Fisher, J.C., Harmon, T.C., Environmental Sensor Networks in Ecological Research (2009) New Phytologist, 182 (3), pp. 589-607; Grémillet, D., Puech, W., Garcon, V., Boulinier, T., Maho, Y.L., Robots in Ecology: Welcome to the Machine (2012) Open Journal of Ecology, 2 (2), pp. 49-57; Ivoševic, B., Han, Y.-G., Cho, Y., Kwon, O., The Use of Conservation Drones in Ecology and Wildlife Research (2015) Ecology and Environment, 38, pp. 113-118; Dunbabin, M., Marques, L., Robots for Environmental Monitoring: Significant Advancements and Applications (2012) IEEE Robotics and Automation Magazine, 19 (1), pp. 24-39; Koh, L.P., Wich, S., Dawn of Drone Ecology: Low-Cost Autonomous Aerial Vehicles for Conservation (2012) Tropical Conservation Science, 5 (2), pp. 121-132; Desjardins, E., Donhauser, J., Barker, G., Ecological Historicity, Functional Goals, and Novelty in the Anthropocene (2019) Environmental Values, 28 (3), pp. 275-303},
document_type={Article},
source={Scopus},
}

@ARTICLE{Maouche2019447,
author={Maouche, S.},
title={Google AI: Opportunities, Risks, and Ethical Challenges},
journal={Contemporary French and Francophone Studies},
year={2019},
volume={23},
number={4},
pages={447-455},
doi={10.1080/17409292.2019.1705012},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082558011&doi=10.1080%2f17409292.2019.1705012&partnerID=40&md5=f8ddf6876d91ab24a5a3bb5380cb1c79},
abstract={Emerging technologies (ET) are novel and relatively fast-growing technologies that can have massive socio-economic impact and bring new ethical and regulatory challenges. Although they cannot be considered as new technologies, artificial intelligence (AI) and related data driven technologies are examples of ET. AI is advancing at a rapid pace, in both public and private sectors, and being more widely deployed in different domains, including healthcare and education. In today’s digital age, our societies are facing rapid and massive technological transformations. It is important to ensure that the behavior of AI systems is beneficial to humanity. Policymakers and the research community need to identify the greatest barriers to AI adoption and related risks. In recent years, Google’s plans and visions to use ET gained serious and intense criticism. This situation pushed Google in March 2019 to announce an AI ethics panel which is supposed to offer guidance on ethical issues relating to AI, machine learning, and related technologies. This AI ethics panel was shut down just days after it was launched. The episode illustrates how ethical debates relating to ET are often characterized by ambiguity, dishonesty, and demagoguery. In this paper, I discuss the ethics of ET, focusing on Google and its AI platform. © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={artificial intelligence;  Emerging technologies;  ethics of technology;  Google AI;  machine ethics;  technology adoption},
references={Baum, R.J., Ethics and Engineering Curricula (1980) The Hastings Center; Bostrom, N., Yudkowsky, E., The Ethics of Artificial Intelligence (2014) The Cambridge Handbook of Artificial Intelligence, pp. 316-334. , Frankish K., Ramsey W.M., (eds), Cambridge: Cambridge UP, and, edited by; Brey, P.A.E., Ethics of Emerging Technologies (2017) Methods for the Ethics of Technology (Philosophy, Technology and Society), Rowman & Littlefield International, pp. 175-192; Butler, D., “Publishers Irritated by Google’s Digital Library (2005) Nature, 433 (7025), p. 446. , p; Corvol, P., https://royalsociety.org/-/media/about-us/international/g-science-statements/2019-g7-declaration-artificial-intelligence-and-society.pdf?la=en-GB&hash=0F5AC7386F43088FF9A5E55BBB3E56BE, Artificial Intelligence and Society. Summit of the G7 Science Academies, 25–26 March 2019, The, Royal Society,. Accessed 9 Dec. 2019; Halaweh, M., Emerging Technology: What is it? (2013) Journal of Technology Management and Innovation, 8 (3), pp. 108-115. , –, ResearchGate, :,. Accessed 9 Dec. 2019; Hourdeaux, J., (2019), https://www.mediapart.fr/journal/france/020119/la-justice-se-prepare-l-arrivee-des-algorithmes?onglet=full, La Justice se prépare à l’arrivée des algorithmes. Mediapart, 2 Jan.,. Accessed 18 Sept. 2019; Lecher, C., (2019), https://www.theverge.com/2019/4/1/18290341/google-heritage-foundation-ai-kay-coles-james, Inside the Google Employee Backlash Against the Heritage Foundation. The Verge, 1 Apr.,. Accessed 18 Sept. 2019; Lin, P., (2017) Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence, , Oxford UP:, editors; Martin, K., “Business and the Ethical Implications of Technology: Introduction to the Symposium (2019) Journal of Business Ethics, 160 (2), pp. 307-317; Mittelstadt, B.D., “The Ethics of Algorithms: Mapping the Debate (2016) Big Data & Society, 3 (2), pp. 1-21. , 1 Dec. Sage, :,. Accessed 9 Dec. 2019; Moor, J.H., “What is Computer Ethics? (1985) Metaphilosophy, 16 (4), pp. 266-275. , Oct. ResearchGate, :,. Accessed 9 Dec. 2019; Di Nucci, E., Santoni de Sio, F., (2016) Drones and Responsibility: Legal, Philosophical and Socio-Technical Perspectives on Remotely Controlled Weapons, , London & New York: Routledge, and, editors; Rotolo, D., “What is an Emerging Technology? (2015) Research Policy, 44 (10), pp. 1827-1843; Sager, H., Implications for Bibliographic Instruction (1995) The Impact of Emerging Technologies on Reference Service and Bibliographic Instruction, pp. 49-62. , Pikin G.M., (ed), Greenwood P,. edited by; Stone, P., (2019), http://ai100.stanford.edu/2016-report, Artificial Intelligence and Life 2030. One Hundred Year Study on Artificial Intelligence: Report of the 2015–2016 Study Panel, Stanford University, Stanford, CA, September 2016. Stanford.edu, 2016,. Accessed 2 Sept},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Noori201943,
author={Noori, F.M. and Uddin, Z. and Torresen, J.},
title={Robot-Care for the Older People: Ethically Justified or Not?},
journal={2019 Joint IEEE 9th International Conference on Development and Learning and Epigenetic Robotics, ICDL-EpiRob 2019},
year={2019},
pages={43-47},
doi={10.1109/DEVLRN.2019.8850706},
art_number={8850706},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073698708&doi=10.1109%2fDEVLRN.2019.8850706&partnerID=40&md5=09891cc97cea780e5955d1389b5d9fdb},
abstract={With the growing popularity of robotics technology, robots have also been introduced to take care of older people. Robots can assist seniors in their daily life tasks, monitor their health or provide them companionship. Despite the benefits of robots, several ethical concerns arise in elderly-robot interaction. The old people might get lonely due to less human interaction, or they feel less control in their lives. The elderly might lose their personal liberty. In this paper, we try to highlight the ethical concerns and provide some preliminary suggestions which would be helpful to reduce the ethical concerns by using customized systems with proper guidelines and consultation with older people. © 2019 IEEE.},
author_keywords={assistive robots;  companions;  elder care;  ethics;  robot ethics;  technology risk},
keywords={Philosophical aspects;  Robotics, Assistive robots;  companions;  Elder care;  ethics;  Robot ethics;  Technology risks, Robots},
references={Mller, V.C., (2013) Philosophy and Theory of Artificial Intelligence, , Heidelberg; New York: Springer; (2017) Department of Economic and Social Affairs in United Nations, , New York; (2016) Health Topics : Ageing, , http://www.who.int/topics/ageing/en/WHO; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics Inf. Technol., 14 (1), p. 2740. , Mar; Sharkey, N.E., The ethical frontiers of robotics (2008) Science, 322, p. 18001801; Sharkey, N., Sharkey, A., Living with robots: Ethical tradeoffs in eldercare (2010) Close Engagements with Artificial Companions: Key Psychological, Social, Ethical and Design Issues, p. 245256. , Y. Wilks (Ed.), Amsterdam: John Benjamins; Shibata, T., Inoue, K., Irie, R., Emotional robot for intelligent system-artificial emotional creature project (1996) Proceedings 5th IEEE International Workshop on Robot and Human Communication. ROMAN96 TSUKUBA, p. 466471. , Tsukuba, Japan; Holt-Lunstad, J., Smith, T.B., Layton, J.B., Social relationships and mortality risk: A meta-analytic review (2010) PLoS Med., 7 (7), p. 20; Wang, H.-X., Late-life engagement in social and leisure activities is associated with a decreased risk of dementia: A longitudinal study from the kungsholmen project (2002) Am. J. Epidemiol., 155 (12), p. 10811087. , Jun; Katz, J., Peace, S., Spurr, S., (2011) Adult Lives: A Life Course Perspective, , 1st ed. Bristol University Press; Cayton, H., From Childhood to Childhood? Autonomy, Dignity and Dependence Through the Ages of Life, p. 44; Wada, K., Shibata, T., Robot therapy in a care house-its sociopsychological and physiological effects on the residents (2006) Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006, p. 39663971. , Orlando, FL, USA; Turkle, S., Taggart, W., Kidd, C.D., Dast, O., Relational artifacts with children and elders: The complexities of cybercompanionship (2006) Connect. Sci., 18 (4), p. 347361. , Dec; http://www.reuters.com/news/globalcoverage/agingjapan; http://www.google.com/hostednews/afp/article/ALeqM5juSqhZryHpsVuY6mf93nr92g1qdA; Thomas, J., (2015) Insights into Loneliness, Older People and Well-being, p. 110. , http://backup.ons.gov.uk/wp-content/uploads/sites/3/2015/10/Insights-into-Loneliness-Older-People-and-Well-being-2015.pdf; http://www.technovelgy.com/ct/Science-Fiction-News.asp?NewsNum=3368; http://www.technovelgy.com/ct/Science-Fiction-News.asp?NewsNum=1567; https://www.cyberdyne.jp/english/products/HAL/; http://asimo.honda.com/innovations/feature/stride-management-assist/; Pollack, M.E., Brown, L., Colbry, D., Orosz, C., Peintner, B., Ramakrishnan, S., Thrun, S.S., Pearl: A mobile robotic assistant for the elderly (2002) AAAI Workshop on Automation As Eldercare, pp. 85-91; Deegan, P., Grupen, R., Hanson, A., Horrell, E., Ou, S., Riseman, E., Xie, D., Mobile manipulators for assisted living in residential settings (2008) Autonomous Robots, 24 (2), pp. 179-192; http://www.geckosystems.com/markets/CareBot.php; Uddin, M.Z., Khaksar, W., Torresen, J., Ambient sensors for elderly care and independent living: A survey (2018) Sensors, 18 (7), p. 2027. , Jun; Noori, F.M., Ceja, E.G., Uddin, M.Z., Riegler, M., Torresen, J., Fusion of multiple representations extracted from a single sensors data for activity recognition using cnns (2019) Proceedings of IEEE International Joint Conference on Neural Networks (IJCNN), , 14-19 July; Noori, F.M., Wallace, B., Uddin, M.Z., Torresen, J., A robust human activity recognition approach using openpose, motion features, and deep recurrent neural network Image Analysis. SCIA 2019. Lecture Notes in Computer Science, , Felsberg M., Forssn PE., Sintorn IM., Unger J. (eds) . Springer, Cham 11482; Rouvroy, A., Poullet, Y., The right to informational self-determination and the value of self-development: Reassessing the importance of privacy for democracy (2009) Reinventing Data Protection?, p. 4576; Torresen, J., A review of future and ethical perspectives of robotics and AI (2018) Frontiers in Robotics and AI, 4, p. 75},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Chomanski2019993,
author={Chomanski, B.},
title={What’s Wrong with Designing People to Serve?},
journal={Ethical Theory and Moral Practice},
year={2019},
volume={22},
number={4},
pages={993-1015},
doi={10.1007/s10677-019-10029-3},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072027055&doi=10.1007%2fs10677-019-10029-3&partnerID=40&md5=ac275c26bc0cc3e31e92e2a868e3d9ca},
abstract={In this paper I argue, contrary to recent literature, that it is unethical to create artificial agents possessing human-level intelligence that are programmed to be human beings’ obedient servants. In developing the argument, I concede that there are possible scenarios in which building such artificial servants is, on net, beneficial. I also concede that, on some conceptions of autonomy, it is possible to build human-level AI servants that will enjoy full-blown autonomy. Nonetheless, the main thrust of my argument is that, in building such artificial agents, their creators cannot help but evince an objectionable attitude akin to the Aristotelian vice of manipulativeness. © 2019, Springer Nature B.V.},
author_keywords={Artificial intelligence;  Autonomy;  Manipulativeness;  Robot ethics},
references={Baron, M., (2003) Manipulativeness. Paper Presented at the Proceedings and Addresses of the American Philosophical Association; Benthall, S., (2017) Don't Fear the Reaper: Refuting Bostrom's Superintelligence Argument; Bloom, P., Harris, S., It’s Westworld (2018) What’s Wrong with Cruelty to Robots?, , The New York Times; Borjas, G., Immigration (2009) The Concise Encyclopedia of Economics, , http://www.econlib.org/library/Enc/Immigration.html, Accessed 20 Jan 2019; Boubtane, E., Dumont, J.C., Rault, C., Immigration and economic growth in the OECD countries 1986–2006 (2015) Oxford Economic Papers, 68 (2), pp. 340-360; Brennan, J., Jaworski, P., (2016) Markets without limits: moral virtues and commercial interests, , Routledge, New York and London; Bryson, J.J., Robots should be slaves (2010) Close engagements with artificial companions, pp. 63-74. , Wilks Y, (ed), John Benjamins, Amsterdam; Bryson, J.J., Patiency is not a virtue: the design of intelligent systems and systems of ethics (2018) Ethics and Information Technology, 20 (1), pp. 15-26; Bryson, J.J., Diamantis, M.E., Grant, T.D., Of, for, and by the people: the legal lacuna of synthetic persons (2017) Artificial Intelligence and Law, 25 (3), pp. 273-291; Burkeman, O., Why you should be nice to your robots (2016) The Guardian, , https://www.theguardian.com/lifeandstyle/2016/jul/08/how-to-relate-to-robots, Retrieved from, Accessed 20 Jan 2019; Buss, S., Westlund, A., Personal autonomy (2018) Stanford Encyclopedia of Philosophy, , https://plato.stanford.edu/archives/spr2018/entries/personal-autonomy/, Retrieved from, Accesseed 20 Jan 2019; Card, D., The impact of the Mariel boatlift on the Miami labor market (1990) ILR Rev, 43 (2), pp. 245-257; Chalmers, D., The singularity: a philosophical analysis (2010) J Conscious Stud, 17 (9-10), pp. 7-65; Chomanski, B., Massive Technological Unemployment Without Redistribution: A Case for Cautious Optimism (2018) Science and Engineering Ethics, 25 (5), pp. 1389-1407; Danaher, J., Welcoming robots into the moral Circle: A Defence of Ethical Behaviourism (2019) Science and Engineering Ethics; Darling, K., Extending legal protection to social robots: the effects of anthropomorphism, empathy, and violent behavior towards robotic objects (2014) Robot law, pp. 212-232. , Calo R, Froomkin AM, Kerr I, (eds), Edward Elgar, Cheltenham; di Giovanni, J., Levchenko, A.A., Ortega, F., A GLOBAL VIEW OF CROSS-BORDER MIGRATION (2014) Journal of the European Economic Association, 13 (1), pp. 168-202; Floridi, L., (2013) The Ethics of Information, , first edition. ed.) edn, Oxford University Press, Oxford; Foddy, B., Savulescu, J., A Liberal account of addiction (2010) Philosophy, Psychiatry, & Psychology, 17 (1), pp. 1-22. , https://www.ncbi.nlm.nih.gov/pubmed/24659901, Retrieved from https://www.ncbi.nlm.nih.gov/pubmed/24659901; Foged, M., Peri, G., Immigrants' effect on native workers: new analysis on longitudinal data (2016) Am Econ J Appl Econ, 8 (2), pp. 1-34; Frankfurt, H.G., Freedom of the will and the concept of a person (1971) J Philos, 68 (1), pp. 5-20; Gunkel, D.J., The other question: can and should robots have rights? (2018) Ethics Inf Technol, 20 (2), pp. 87-99; Hakli, R., Mäkelä, P., Moral responsibility of robots and hybrid agents (2019) Monist, 102 (2), pp. 259-275; Hanson, R., Meet the new conflict, same as the old conflict (2012) J Conscious Stud, 19 (1-2), pp. 119-125; Krugman, P., Obstfeld, M., (2009) International economics: theory and policy, , Pearson, London; LaBossiere, M., Testing the moral status of artificial beings; or “I’m going to ask you some questions … (2017) Robot ethics 2.0, pp. 293-306. , Lin P, Jenkins R, Abney K, (eds), Oxford University Press, New York; Levy, D., The ethical treatment of artificially conscious robots (2009) Int J Soc Robot, 1 (3), pp. 209-216; Longhi, S., Nijkamp, P., Poot, J., A meta-analytic assessment of the effect of immigration on wages (2005) J Econ Surv, 19 (3), pp. 451-477; McDermott, D., Response to 'The Singularity' by David Chalmers (2012) J Conscious Stud, 19 (1-2), pp. 167-172; Mele, A.R., (1995) Autonomous agents: from self-control to autonomy, , Oxford University Press, New York; Müller, V., Bostrom, N., Future progress in artificial intelligence: a survey of expert opinion (2014) Fundamental issues of artificial intelligence, , Müller V, (ed), Springer, Berlin; Musiał, M., Designing (artificial) people to serve–the other side of the coin (2017) Journal of Experimental & Theoretical Artificial Intelligence, 29 (5), pp. 1087-1097; Omohundro, S.M., The basic AI drives (2008) Artificial general intelligence, 2008: proceedings of the first AGI conference, pp. 483-492. , Wang P, Goertzel B, Franklin S, (eds), IOS Press, Amsterdam; Ottaviano, G.I., Peri, G., Rethinking the effect of immigration on wages (2012) J Eur Econ Assoc, 10 (1), pp. 152-197; Peters, F., Cognitive self-management requires the phenomenal registration of intrinsic state properties (2019) Philosophical Studies, pp. 1-23; Petersen, S., Designing people to serve (2011) Robot ethics, pp. 283-298. , Lin P, Bekey G, Abney K, (eds), MIT Press, Cambridge; Purves, D., Jenkins, R., Strawser, B.J., Autonomous machines, moral judgment, and acting for the right reasons (2015) Ethical Theory Moral Pract, 18 (4), pp. 851-872; Raz, J., The morality of freedom (1986) Oxford Oxfordshire; New York: Clarendon press, , Press, Oxford University; Schneider, S., Artificial intelligence, consciousness, and moral status (2018) Routledge handbook of Neuroethics, , Johnson LSM, Rommelfanger K, (eds), Routledge, New York; Schwitzgebel, E., Garza, M., A defense of the rights of artificial intelligences (2015) Midwest Studies in Philosophy, 39 (1), pp. 98-119; Sparrow, R., The ethics of terraforming (1999) Environ Ethics, 21 (3), pp. 227-245; Thaler, R.H., Sunstein, C.R., (2008) Nudge: improving decisions about health, wealth, and happiness, , Yale University Press, New Haven; Turner, J., (2019) Robot rules, , Pagrave Macmillan, Chaim; Walker, M., A moral paradox in the creation of artificial intelligence: Mary Poppins 3000s of the world unite! (2006) Human implications of human-robot interaction: papers from the AAAI workshop, pp. 23-28. , Metzler T, (ed), AAAI Press, Menlo Park; Walker, M., (2016) Free money for all: a basic income guarantee solution for the twenty-first century, , Palgrave Macmillan, New York; Wellman, C.H., Immigration (2015) The Stanford Encyclopedia of Philosophy Summer 2015, , https://plato.stanford.edu/archives/sum2015/entries/immigration/, Retrieved from, Accessed 1 May 2019; Ziesche, S., Yampolskiy, R., Towards AI Welfare Science and Policies (2018) Big Data and Cognitive Computing, 3 (1), p. 2},
document_type={Article},
source={Scopus},
}

@ARTICLE{Indurkhya2019107,
author={Indurkhya, B.},
title={Is morality the last frontier for machines?},
journal={New Ideas in Psychology},
year={2019},
volume={54},
pages={107-111},
doi={10.1016/j.newideapsych.2018.12.001},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059668226&doi=10.1016%2fj.newideapsych.2018.12.001&partnerID=40&md5=c60e7463654934d56129b2d42c286fd6},
abstract={This paper examines some ethical and cognitive aspects of machines making moral decisions in difficult situations. We compare the situations when humans have to make tough moral choices with those in which machines make such decisions. We argue that in situations where machines make tough moral choices, it is important to produce justification for those decisions that are psychologically compelling and acceptable by people. © 2019 Elsevier Ltd},
author_keywords={Autonomous decision making;  Machine ethics;  Machine morality},
references={Aha, D., (2017) IJCAI-97 workshop on explainable AI (XAI). 20 August 2017. Melbourne, Australia, , http://www.intelligentrobots.org/files/IJCAI2017/IJCAI-17_XAI_WS_Proceedings.pdf, (Accessed 13 January 2018); Ariely, D., Predictably irrational: The hidden forces that shape our decisions (2009), Harper Perennial (exp. rev. edition New York; Arkin, R.C., Ulam, P., Wagner, A.R., Moral decision making in autonomous systems: Enforcement, moral emotions, dignity, trust and deception (2012) Proceedings of the IEEE, 100 (3), pp. 577-589; Bauman, C.W., McGraw, A.P., Bartels, D.M., Warren, C., Revisiting external validity: Concerns about trolley problems and other sacrificial dilemmas in moral psychology (2014) Social and Personality Psychology Compass, 8, pp. 536-554; Ben-Ary, G., Ben-Ary, G., Bio-engineered brains and robotic bodies: From embodiment to self-portraiture (2016) Robots and art, pp. 307-326. , D. Herath C. Kroos Stelarc Springer Singapore; Bonnefon, J.-F., Shariff, A., Rahwan, I., The social dilemma of autonomous vehicles (2017) Science, 352 (6293), pp. 1573-1576; Brogan, J., Should a self-driving car kill two jaywalkers or one law-abiding citizen? (2016), http://www.slate.com/blogs/future_tense/2016/08/11/moral_machine_from_mit_poses_self_driving_car_thought_experiments.html/, Accessed 5.9.16; Browner, W.S., Decision analysis (2006) Hospital medicine, pp. 43-50. , R.M. Wachter L. Goldman H. Hollander 2nd ed. Lippincott, Williams &amp; Wilkins Philadelphia; Bruers, S., Braeckman, J., A review and systematization of the trolley problem (2014) Philosophia, 42 (2). , 251 –169; Bryson, J.J., Patiency is not a virtue:&#x2028;AI and the design of ethical systems (2016) Proceedings of the AAAI spring symposium on ethical and moral considerations in nonhuman agents, pp. 202-207. , AAAI Press Palo Alto, CA; Bryson, J.J., Diamantis, M.E., Grant, T.D., Of, for, and by the people: The legal lacuna of synthetic persons (2017) Artificial Intelligence and Law, 25, pp. 273-291; Christ, M., Grossmann, F., Winter, D., Bingisser, R., Platz, E., Modern triage in the emergency department (2010) Deutsches Ärzteblatt International, 107 (50), pp. 892-898; Dawes, R.M., Faust, D., Meehl, P.E., Clinical versus actuarial judgment (1989) Science, 243 (4899), pp. 1668-1674; Gladwell, M., Blink: The power of thinking without thinking (2005), Little Brown & Co New York; Gracheva, A., The Beslan mum who could only save one of her children (2016), http://www.bbc.com/news/magazine-36378981, 12 June 2016 BBC News (Magazine)(Accessed 12 April 2017); Gunning, D., Explainable artificial intelligence (XAI) (2016), https://www.cc.gatech.edu/∼alanwags/DLAI2016/(Gunning)%20IJCAI-16%20DLAI%20WS.pdf, (Accessed 15 January 2018); Hamilton, P., Google-bombing - manipulating the PageRank algorithm. Class white paper (2009), http://userpages.umbc.edu/∼pete5/ir_paper.pdf/, (Accessed 11 January 2017); Hunter, D., Indurkhya, B., ‘Don't think, but look’ a gestalt interactionist approach to legal thinking (1998) Advances in Analogy research: Integration of theory and data from the cognitive, computational, and neural sciences, pp. 345-353. , K.J. Holyoak D. Gentner B. Kokinov NBU Press Sofia (Bulgaria); Indurkhya, B., A cognitive perspective on norms (2016) The normative mind, pp. 35-63. , J. Stelmach B. Broźek Ł. Kwiatek Copernicus Center Press Kraków (Poland); Indurkhya, B., Misztal-Radecka, J., Incorporating human dimension in autonomous decision-making on moral and ethical issues (2016) Proceedings of the AAAI spring symposium on ethical and moral considerations in nonhuman agents, pp. 226-230. , AAAI Press Palo Alto, CA; Iserson, K.V., Moskop, J.C., Triage in medicine, part I: Concept, history and types (2007) Annals of Emergency Medicine, 49 (3), pp. 275-281; Krauss, D.A., Sales, B.D., The effects of clinical and scientific expert testimony on juror decision making in capital sentencing (2001) Psychology, Public Policy, and Law, 7 (2), pp. 267-310; Kuang, K., Can A.I. Be taught to explain itself? The New York times magazine (2017), https://www.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-explain-itself.html, Nov. 21, 2017 (Accessed 25 November 2017); Larsen, K.T., Jr., Vickery, D.M., Collis, P.B., Folland, E.D., Triage: A logical algorithmic alternative to a non-system (1973) Journal of the American College of Emergency Physicians, 2 (3), pp. 183-187; Levy, D., Love and sex with robots: The evolution of human-robot relationships (2007), HarperCollins New York; Lin, P., Introduction to robot ethics (2011) Robot ethics: The ethical and social implications of robotics, pp. 3-16. , P. Lin K. Abney G.A. Bekey MIT Press Cambridge (Mass; Lin, P., Abney, K., Bekey, G.A., (2011) Robot ethics: The ethical and social implications of robotics, , MIT Press Cambridge (Mass; Linhares, A., The emergence of choice: Decision-making and strategic thinking through analogies (2014) Information Sciences, 259, pp. 36-56; Litwack, T.R., Actuarial versus clinical assessments of dangerousness (2001) Psychology, Public Policy, and Law, 7 (2), pp. 409-443; Mann, T.E., Polarizing the house of representatives: How much does gerrymandering matter? (2006) Red and blue nation? Characteristics and causes of America's polarized politics, pp. 263-300. , P.S. Nivola D.W. Brady Brookings Institution Press Baltimore; Martindale, C., The clockwork muse: The predictability of artistic change (1990), Basic Books New York; Morton, L., The decision to use the atomic bomb (1960) Command Decisions. Office of the chief of the military history of the army. Washington D.C, pp. 493-518. , http://www.dod.mil/pubs/foi/Reading_Room/NCB/361.pdf, L. Morton (Accessed 5 November 2016); Moskop, J.C., Iserson, K.V., Triage in medicine, part II: Underlying values and principles (2007) Annals of Emergency Medicine, 49 (3), pp. 282-287; Navarrete, C.D., McDonald, M.M., Mott, M.L., Asher, B., Virtual morality: Emotion and action in a simulated three-dimensional “trolley problem” (2012) Emotion, 12 (2), pp. 364-370; Ni, Y., Santos-Rodriguez, R., Mcvicar, M., De Bie, T., Hit song science once again a &#x2028;science? (2011) Fourth International Workshop on Machine Learning and Music: &#x2028;Learning from Musical Structure, Sierra Nevada, Spain; Nucci, E.D., Self-sacrifice and the trolley problem (2013) Philosophical Psychology, 26 (5), pp. 662-672; Olah, C., Mordvinstev, A., Schubert, L., Feature visualization: How neural networks build up their understanding of images (2017); Pandey, A.K., Gelin, R., Ruocco, M., Monforte, M., Siciliano, B., When a social robot might learn to support potentially immoral behaviors in the name of privacy: The dilemma of privacy vs. Ethics for a socially intelligent robot (2017) Proceedings of the workshop on privacy-sensitive robotics, HRI 2017; Peng, H., Hu, H., Chao, F., Zhou, C., Li, J., Autonomous robotic choreography creation via semi-interactive evolutionary computation (2016) Int J of Soc Robotics, 8, pp. 649-661; Robertson-Steel, I., Evolution of triage system (2006) Emergency Medical Journal, 23 (2), pp. 154-155; Sample, I., AI watchdog needed to regulate automated decision-making, say experts (2017), https://www.theguardian.com/technology/2017/jan/27/ai-artificial-intelligence-watchdog-needed-to-prevent-discriminatory-automated-decisions/, The Guardian 27 January 2017 (Accessed 28 January 2017); Schwartzman, M., See yourself sensing: Redefining human perception (2011), Black Dog Publishing London; Schwiep, J., The state of explainable AI (2017), https://medium.com/@jschwiep/the-state-of-explainable-ai-e252207dc46b, (Accessed 15 December 2017); Searle, J., Watson doesn't know it won on “Jeopardy” (2011) Wall Street Journal, , 23 February 2011; Shortliffe, E.H., Computer-based medical consultations: MYCIN (1976), Elsevier/North Holland New York; Starr, S.B., Evidence-based sentencing and the scientific rationalization of discrimination (2014) Stanford Law Review, 66; Ulug, F., Emycin-Prolog expert system shell (1986), Master's Thesis Naval Postgraduate School Monterey, California; Wall, M., Would you bully a driverless car or show it respect? (2016), http://www.bbc.com/news/business-37706666/, (Accessed 21 October 2016); Warwick, K., Cyborg morals, cyborg values, cyborg ethics (2003) Ethics and Information Technology, 5 (3), pp. 131-137; Warwick, K., Implications and consequences of robots with biological brains (2010) Ethics and Information Technology, 12 (3), pp. 223-234; Warwick, K., The cyborg revolution (2014) Nanoethics, 8 (3), pp. 263-273},
document_type={Article},
source={Scopus},
}

@ARTICLE{Klein2019183,
author={Klein, W.E.J.},
title={Exceptionalisms in the ethics of humans, animals and machines},
journal={Journal of Information, Communication and Ethics in Society},
year={2019},
volume={17},
number={2},
pages={183-195},
doi={10.1108/JICES-11-2018-0089},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067900141&doi=10.1108%2fJICES-11-2018-0089&partnerID=40&md5=2428f29f783726c384797024b8af444e},
abstract={Purpose: This paper aims to examine exceptionalisms in ethics in general and in the fields of animal and technology ethics in particular. Design/methodology/approach: This paper reviews five sample works in animal/technology ethics it considers representative for particularly popular forms of “exceptionalism”. Findings: The shared feature of the exceptionalisms exhibited by the chosen samples appears to be born out of the cultural and biological history, which provides powerful intuitions regarding the on “specialness”. Research limitations/implications: As this paper is mostly a critique of existing approaches, it contains only a limited amount of counter-proposed alternative approaches. Practical implications: This is a discussion worth having because arguments based on (human or biological) exceptionalism have more chance of resulting in significantly altered theoretical conclusions and practical suggestions for normative guidance than non-exceptionalist perspectives. Social implications: The approaches critiqued in this paper have a significant effect on the way the authors approach animals, machines/technologies and each other. Originality/value: The paper identifies intuitive notions of exceptionalism and argues in favour of a reformist, ethical expansionist stance, which views humanity as residing (and other biological organisms) on the same plane of ethical significance as any other entity regardless of its material composition. © 2019, Emerald Publishing Limited.},
author_keywords={Computer ethics;  Consciousness;  Determinism;  Ethics;  Exceptionalism;  Information ethics;  IT Ethics;  Machine ethics;  Materialism;  Moral psychology;  Philosophy of technology;  Technology ethics},
references={Anderson, S.L., How machines might help us achieve breakthroughs in ethical theory and inspire us to behave better (2011) Machine Ethics, pp. 151-160. , Anderson, M. and Anderson, S.L.,(Eds), Cambridge University Press, New York, NY; Birch, T.H., Moral considerability and universal consideration (1993) Environmental Ethics, 15 (4), pp. 313-332; Bostrom, N., Yudkowsky, E., The ethics of artificial intelligence (2014) The Cambridge Handbook of Artificial Intelligence, pp. 316-334. , Frankish, K. and Ramsey, W.M. and,(Eds), Cambridge University Press; Bourget, D., Chalmers, D.J., What do philosophers believe? (2013) Philosophical Studies, 170 (3), pp. 465-500; Bryson, J.J., Robots should be slaves (2010) Close Engagements with Artificial Companions: Key Social, Psychological, Ethical and Design Issues, 8, pp. 63-74. , Wilks, Y. (Ed.), John Benjamins, Amsterdam; Coeckelbergh, M., Robot rights? towards a social-relational justification of moral consideration (2010) Ethics and Information Technology, 12 (3), pp. 209-221; Darling, K., (2012) Extending legal protection to social robots: the effects of anthropomorphism, empathy, and violent behavior towards robotic objects, , SSRN Scholarly Paper ID 2044797, Social Science Research Network, Rochester, New York, NY; Dennett, D., Are we explaining consciousness yet? (2001) Cognition, 79 (1-2), pp. 221-237; Dennett, D.C., Animal consciousness: what matters and why (1995) Social Research, 62 (3), pp. 691-710; Dennett, D.C., (1995) Darwin’s Dangeorus Idea: Evolution and the Meanings of Life, , Simon and Schuster Paperbacks, New York, NY; Dennett, D.C., Computers as prostheses for the imagination (2006) presented at the The International Computers and Philosophy Conference, , Laval, France; Ellegard, A., (1958) Darwin and the General Reader: The Reception of Darwin’s Theory of Evolution in the British Periodical Press, 1859-1872, , University of Chicago Press, Chicago; Finocchiaro, M., (2010) Defending Copernicus and Galileo: Critical Reasoning in the Two Affairs, , Springer Science and Business Media, Berlin; Floridi, L., Information ethics: on the philosophical foundation of computer ethics (1999) Ethics and Information Technology, 1 (1), pp. 33-52; Floridi, L., The method of levels of abstraction (2008) Minds and Machines, 18 (3), pp. 303-329; Floridi, L., (2014) The Fourth Revolution: How the Infosphere is Reshaping Human Reality, , Oxford University Press, Oxford; FunkRainieSmithOlmsteadDuggan, C., Page, D., (2015) Public and scientists’ views on science and society, , www.pewinternet.org/2015/01/29/public-and-scientists-views-on-science-and-society/, (accessed, Pew Research Center: 13 July 2016; Gunkel, D.J., (2012) The Machine Question: Critical Perspectives on AI, Robots, and Ethics, , The MIT Press, Cambridge, Mass; Gunkel, D.J., The other question: can and should robots have rights? (2017) Ethics and Information Technology, pp. 1-13; Helmreich, S., The spiritual in artificial life: recombining science and religion in a computational culture medium (1997) Science as Culture, 6 (3), pp. 363-395; Himma, K.E., (2015) Design arguments for the existence of god, , SSRN Scholarly Paper ID 2628858, Social Science Research Network, Rochester, New York, NY; Hoorens, V., Self-enhancement and superiority biases in social comparison (1993) European Review of Social Psychology, 4 (1), pp. 113-139; Klein, W.E.J., Problems with moral intuitions regarding technologies (2016) IEEE Potentials, 35 (5), pp. 40-42; Klein, W.E.J., (2017) Vector Utilitarianism – Concept and Application of an Ethic for a Technological Present and Future, , City University of Hong Kong, Hong Kong; Leopold, A., (1986) A Sand County Almanac Publisher, , Ballantine Books; Naess, A., The shallow and the deep, long-range ecology movement. A summary (1973) Inquiry, 16 (1-4), pp. 95-100; Newport, F., (2014) In US, 42% believe creationist view of human origins, , www.gallup.com/poll/170822/believe-creationist-view-human-origins.aspx, (accessed, Gallup: 25 June 2015; PaleyLynam, W., (1823) Natural Theology; Tracts, , William Baynes and Son; Prinz, J., Is empathy necessary for morality (2011) Empathy: Philosophical and Psychological Perspectives, 1, pp. 211-229; Rolston, H., Respect for life: counting what singer finds of no account (1999) Singer and His Critics, pp. 247-268. , Jamieson, D. (Ed.), Blackwell, Oxford; Ross, L., The intuitive psychologist and his shortcomings: distortions in the attribution process (1977) Advances in Experimental Social Psychology, 10, pp. 173-220. , Berkowitz, L. (Ed.), Academic Press; Singer, P., (2011) Practical Ethics, , 3rd ed, Cambridge University Press, Cambridge; Singer, P., (2011) The Expanding Circle: Ethics, Evolution, and Moral Progress, , Princeton University Press, Princeton; Sparrow, R., The turing triage test (2004) Ethics and Information Technology, 6 (4), pp. 203-213; Taylor, P.W., (2011) Respect for Nature: A Theory of Environmental Ethics, , Princeton University Press, Princeton; Westman, R.S., (2011) The Copernican Question: Prog`stication, Skepticism, and Celestial Order, , University of CA Press, Berkeley; Yudkowsky, E., (2009) Three worlds collide, , http://lesswrong.com/lw/y4/three_worlds_collide_08/, (accessed, LessWrong, 30 January: 26 May 2017},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Yilmaz2019,
author={Yilmaz, L. and Sivaraj, S.},
title={A cognitive architecture for verifiable system ethics via explainable autonomy},
journal={SysCon 2019 - 13th Annual IEEE International Systems Conference, Proceedings},
year={2019},
doi={10.1109/SYSCON.2019.8836896},
art_number={8836896},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073166793&doi=10.1109%2fSYSCON.2019.8836896&partnerID=40&md5=a2441df44bdc51137b4da89a62625f48},
abstract={Immersing autonomous technologies into our technical and social infrastructures has profound implications and hence requires instilling confidence in their behavior to avoid potential harm. In this paper, we present Cogent, an interactive coherence-driven agent specification and simulation platform and demonstrate its use in ethical decision-making. To advance the theory, methodology, and applications of autonomous system verification, Cogent leverages a cognitive model to bear on the challenges of reasoning about trust, ethics, and intentions. The underlying strategy of the cognitive model is based on the concept of a connectionist, interactive activation model that implements the theory of coherence. To illustrate the practical utility of Cogent, we explore a machine ethics case study. © 2019 IEEE.},
author_keywords={Cognitive agent;  Explainable model;  Machine ethics;  Verification},
keywords={Decision making;  Simulation platform;  Verification, Agent specification;  Autonomous systems;  Autonomous technology;  Cognitive agents;  Cognitive architectures;  Ethical decision making;  Interactive activation;  Social infrastructure, Philosophical aspects},
references={Grogan, A., Driverless trains: It's the automatic choice (2012) Engineering & Technology, 7 (5), pp. 54-57; Tucker, P., (2014) Now the Military Is Going to Build Robots That Have Morals, , http://www.defenseone.com/technology/2014/05/now-military-going-build-robots-have-morals/84325, [Online]; Simmons, R., Pecheur, C., Srinivasan, G., Towards automatic verification of autonomous systems (2000) Intelligent Robots and Systems, 2000.(IROS 2000). Proceedings. 2000 IEEE/RSJ International Conference on, 2, pp. 1410-1415. , ieee; Brat, G., Jonsson, A., Challenges in verification and validation of autonomous systems for space exploration (2005) Neural Networks 2005. IJCNN'05. Proceedings. 2005 IEEE International Joint Conference on, 5, pp. 2909-2914. , ieee; Brat, G., Denney, E., Giannakopoulou, D., Frank, J., Jónsson, A., Verification of autonomous systems for space applications (2006) Aerospace Conference 2006 IEEE, 11p. , ieee; Dennis, L.A., Fisher, M., Lincoln, N.K., Lisitsa, A., Veres, S.M., Practical verification of decision-making in agent-based autonomous systems (2016) Automated Software Engineering, 23 (3), pp. 305-359; Dennis, L., Fisher, M., Slavkovik, M., Webster, M., Formal verification of ethical choices in autonomous systems (2016) Robotics and Autonomous Systems, 77, pp. 1-14; Clarke, E., Garlan, D., Krogh, B., Simmons, R., Wing, J., (2001) Formal Verification of Autonomous Systems Nasa Intelligent Systems Program; Fisher, M., Dennis, L., Webster, M., Verifying autonomous systems (2013) Communications of the ACM, 56 (9), pp. 84-93; Callow, G., Watson, G., Kalawsky, R., System modelling for run-time verification and validation of autonomous systems (2010) System of Systems Engineering SoSE 2010 5th International Conference on, pp. 1-7. , ieee; Lussier, B., Lampe, A., Chatila, R., Guiochet, J., Ingrand, F., Killijian, M.-O., Powell, D., Fault tolerance in autonomous systems: How and how much? (2005) 4th IARP-IEEE/RAS-EURon Joint Workshop on Technical Challenges for Dependable Robots in Human Environments (DRHE; Kuipers, B., How can we trust a robot? (2018) Communications of the ACM, 61 (3), pp. 86-95; Biran, O., Cotton, C., Explanation and justification in machine learning: A survey (2017) IJCAI-17 Workshop on Explainable AI (XAI, p. 8; Hoffman, R.R., Klein, G., Mueller, S.T., Explaining explanation for explainable ai (2018) Proceedings of the Human Factors and Ergonomics Society Annual Meeting, 62 (1), pp. 197-201. , sage Publications Sage ca: Los Angeles, ca; Chen, J.Y.C., Barnes, M.J., Humanagent teaming for multirobot control: A review of human factors issues (2014) IEEE Transactions on Human-Machine Systems, 44 (1), pp. 13-29. , feb; Jennings, N.R., Moreau, L., Nicholson, D., Ramchurn, S., Roberts, S., Rodden, T., Rogers, A., Human-Agent collectives (2014) Communications of the ACM, 57 (12), pp. 80-88. , nov; Thagard, P., (1996) Mind: Introduction to Cognitive Science, 4. , MIT press Cambridge MA; Thagard, P., (2000) Coherence in Thought and Action, , MIT Press; Abar, S., Theodoropoulos, G., Lemarinier, P., OHare, G., (2017) Agent Based Modelling and Simulation Tools: A Review of the State-of-Art Software; Laird, J., Extending the soar cognitive architecture (2008) Artificial General Intelligence; Laird, J., (2012) The Soar Cognitive Architecture, , MIT Press; Kieras, D.E., Meyer, D.E., The epic architecture for modeling human information-processing and performance: A brief introduction (1994) Michigan Univ Ann Arbor Div of Research Development and Administration, , Tech. Rep; Rosbe, J., Chong, R.S., Kieras, D.E., Modeling with perceptual and memory constraints: An epic-soar model of a simplified enroute air traffic control task (2001) Soar Technology Inc Ann Arbor Mi, Tech. Rep; Anderson, J., Bothell, D., Byrne, M., Douglass, S., Lebiere, C., Qin, Y., Mason: A multi-Agent simulation environment (2005) Society for Modeling and Simulation International; Ron, S., The clarion cognitive architecture: Extending cognitive modeling to social simulation (2005) Cognition and Multi-Agent Interaction, , S. Ron, Ed. New York: Cambridge University Press ch. 4; Franklin, S., Patterson, F., Jr., The lida architecture: Adding new modes of learning to an intelligent, autonomous, software agent (2006) Pat, 703, pp. 764-1004; Langley, P., Choi, D., A unified cognitive architecture for physical agents (2006) Proceedings of the National Conference on Artificial Intelligence, 21 (2), p. 1469. , Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999; Yilmaz, L., Franco-Watkins, A., Kroecker, S.T., Coherence-driven reflective equilibrium model of ethical decision-making (2016) 2016 IEEE International Multi-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support, pp. 42-48; Yilmaz, L., Franco-Watkins, A., Kroecker, T.S., Computational models of ethical decision-making: A coherence-driven reflective equilibrium model (2017) Cognitive Systems Research, 46, pp. 61-74; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) IEEE Intelligent Systems, 21 (4), pp. 12-17; Arkoudas, K., Bringsjord, S., Bello, P., Toward ethical robots via mechanized deontic logic (2005) AAAI Fall Symposium on Machine Ethics, pp. 17-23; Gips, J., Towards the ethical robot (1995) Android Epistemology, pp. 243-252; Thomson, J.J., The trolley problem (1985) The Yale Law Journal, 94 (6), pp. 1395-1415},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Haring2019689,
author={Haring, K.S. and Novitzky, M.M. and Robinette, P. and De Visser, E.J. and Wagner, A. and Williams, T.},
title={The Dark Side of Human-Robot Interaction: Ethical Considerations and Community Guidelines for the Field of HRI},
journal={ACM/IEEE International Conference on Human-Robot Interaction},
year={2019},
volume={2019-March},
pages={689-690},
doi={10.1109/HRI.2019.8673184},
art_number={8673184},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063997468&doi=10.1109%2fHRI.2019.8673184&partnerID=40&md5=02f2099a3b88af979e7e0ba8185c4482},
abstract={The HRI community is working to develop interactive robots for a wide variety of pro-social tasks and ideals. As such we naturally focus on the positive side of HRI including how robots and humans may collaborate and the benefits of doing so. This workshop, in contrast, will focus on the dark side of HRI with the goal of identifying, understanding and guarding against the potential negative consequences of interactive robots. The primary objective of the workshop is to articulate and discuss the most pertinent ethical issues facing the HRI community and to develop a set of common community guidelines. © 2019 IEEE.},
author_keywords={Consumer Protection;  Data Protection;  Human-Robot Interaction;  Persuasive Robots;  Robot Ethics},
keywords={Consumer protection;  Data privacy;  Man machine systems;  Philosophical aspects;  Robot learning, Ethical considerations;  Ethical issues;  Hri communities;  Interactive robot;  Persuasive robots;  Positive sides;  Primary objective;  Robot ethics, Human robot interaction},
references={Scheutz, M., The need for moral competency in autonomous agent architectures (2016) Fundamental Issues of Artificial Intelligence, pp. 515-525. , Springer; Arnold, T., Scheutz, M., Beyond moral dilemmas: Exploring the ethical landscape in hri (2017) Proc. HRI. ACM, pp. 445-452; Malle, B., Scheutz, M., Moral competence in social robots (2018) Emerging Technologies: Ethics, Education, and Engineering, , C. Hanks and E. K. Hanks, Eds. Springer Verlag; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics and Information Technology, 14 (1), pp. 27-40; Arkin, R.C., Fujita, M., Takagi, T., Hasegawa, R., An ethological and emotional basis for human-robot interaction (2003) Robotics and Autonomous Systems, 42 (3-4), pp. 191-201; Syrdal, D.S., Walters, M.L., Otero, N., Koay, K.L., Dautenhahn, K., He knows when you are sleeping-privacy and the personal robot companion (2007) Proc. AAAI Workshop Human Implications of HRI, pp. 28-33; Howard, A., Borenstein, J., The ugly truth about ourselves and our robot creations: The problem of bias and social inequity (2017) Science and Engineering Ethics, pp. 1-16; Eyssel, F., Loughnan, S., It don't matter if you're black or white (2013) International Conference on Social Robotics; Matthias, A., Robot lies in health care: When is deception morally permissible? (2015) Kennedy Institute of Ethics Journal, 25 (2), pp. 162-169; Shim, J., Arkin, R.C., A taxonomy of robot deception and its benefits in hri (2013) Systems, Man, and Cybernetics (SMC); Terada, K., Ito, A., Can a robot deceive humans? (2010) Proc. HRI; Booth, S., Tompkin, J., Pfister, H., Waldo, J., Gajos, K., Nagpal, R., Piggybacking robots: Human-robot overtrust in university dormitory security (2017) Proc. HRI. ACM, pp. 426-434; Bonaci, T., Herron, J., Yusuf, T., Yan, J., Kohno, T., Chizeck, H.J., (2015) To Make A Robot Secure: An Experimental Analysis of Cyber Security Threats Against Teleoperated Surgical Robots, , arXiv preprint arXiv:1504. 04339; Robinson, H., MacDonald, B., Kerse, N., Broadbent, E., The psychosocial effects of a companion robot: A randomized controlled trial (2013) Journal of the American Medical Directors Association, 14 (9), pp. 661-667; Lee, K.M., Jung, Y., Kim, J., Kim, S.R., Are physically embodied social agents better than disembodied social agents?: The effects of physical embodiment, tactile interaction, and people's loneliness in human-robot interaction (2006) Int. Jour. of Human-Computer Studies, 64 (10); Deng, B., Machine ethics: The robot's dilemma (2015) Nature News; Malle, B.F., Integrating robot ethics and machine morality: The study and design of moral competence in robots (2016) Ethics and Info. Tech.; Malle, B.F., Scheutz, M., Arnold, T., Voiklis, J., Cusimano, C., Sacrifice one for the good of many?: People apply different moral norms to human and robot agents (2015) Proc. HRI. ACM, pp. 117-124; Kahn, P.H., Jr., Kanda, T., Ishiguro, H., Freier, N.G., Severson, R.L., Gill, B.T., Ruckert, J.H., Shen, S., Robovie, you'll have to go into the closet now : Children's social and moral relationships with a humanoid robot (2012) Developmental Psychology, 48 (2), p. 303; Lin, P., Abney, K., Bekey, G.A., (2014) Robot Ethics: The Ethical and Social Implications of Robotics, , The MIT Press; Millar, J., Ethics settings for autonomous vehicles (2017) Robot Ethics 2. 0: From Autonomous Cars to Artificial Intelligence, , P. Lin, K. Abney, and G. A. Bekey, Eds. MIT Press; Darling, K., Calo, R., Introduction to journal of human-robot interaction special issue on law and policy (2016) JHRI, 5 (3), pp. 1-2; Arkin, R.C., Governing lethal behavior: Embedding ethics in a hybrid deliberative/reactive robot architecture (2008) Proc. HRI. ACM, pp. 121-128; Sun, R., Moral judgment, human motivation, and neural networks (2013) Cognitive Computation, 5 (4), pp. 566-579; Scheutz, M., Malle, B., Briggs, G., Towards morally sensitive action selection for autonomous social robots (2015) Proc. RO-MAN; Andrighetto, G., Villatoro, D., Conte, R., Norm internalization in artificial societies (2010) AI Communications, 23 (4), pp. 325-339; Abel, D., MacGlashan, J., Littman, M.L., Reinforcement learning as a framework for ethical decision making (2016) Proceedings of the AAAI Workshop on AI, Ethics, and Society, pp. 54-61; Arnold, T., Kasenberg, D., Scheutz, M., Value alignment or misalignment-what will keep systems accountable? (2017) Proceedings of the AAAI Workshop on AI, Ethics, and Society; Blass, J.A., Forbus, K.D., Moral decision-making by analogy: Generalizations versus exemplars (2015) Proc. AAAI, pp. 501-507; Jackson, R.B., Williams, T., Robot: Asker of questions and changer of norms? (2018) Proc. ICRES; Kennedy, J., Baxter, P., Belpaeme, T., Children comply with a robot's indirect requests (2014) Proc. HRI. ACM, pp. 198-199; Robinette, P., Li, W., Allen, R., Howard, A.M., Wagner, A.R., Overtrust of robots in emergency evacuation scenarios (2016) Proc. HRI},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Jackson2019715,
author={Jackson, R.B.},
title={Toward Morally Sensitive Robotic Communication},
journal={ACM/IEEE International Conference on Human-Robot Interaction},
year={2019},
volume={2019-March},
pages={715-717},
doi={10.1109/HRI.2019.8673209},
art_number={8673209},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063984383&doi=10.1109%2fHRI.2019.8673209&partnerID=40&md5=377d151bb5ade83d7e3031e764a3b12a},
abstract={As robots become more capable, they will become increasingly useful in a widening variety of contexts and applications. Non-roboticists in these diverse contexts will need to interact with their new robotic colleagues to facilitate productive human-robot teaming and comfortable coexistence in social environments. Natural language provides a medium for these interactions that will allow direct and fluid communication between robots and nearly all humans, without requiring specialized protocols or hardware. Indeed, many researchers have been actively investigating the problems of natural language understanding and generation in robots for some time [1]-[3]. © 2019 IEEE.},
author_keywords={Human-Robot Interaction;  Natural Language Generation;  Robot Ethics},
keywords={Man machine systems;  Natural language processing systems;  Robotics, Human robots;  Natural language generation;  Natural language understanding;  Natural languages;  Robot ethics;  Social environment, Human robot interaction},
references={Scheutz, M., Schermerhorn, P., Kramer, J., Anderson, D., First steps toward natural human-like hri (2007) Autonomous Robots, 22 (4), pp. 411-423. , May; Mavridis, N., A review of verbal and non-verbal human-robot interactive communication (2015) Robotics and Autonomous Systems, 63, pp. 22-35; Matuszek, C., Grounded language learning: Where robotics and nlp meet (2018) Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), pp. 5687-5691; Levinson, S.C., (2000) Presumptive Meanings: The Theory of Generalized Conversational Implicature, , MIT press; Gervits, F., Briggs, G., Scheutz, M., The pragmatic parliament: A framework for socially-appropriate utterance selection in artificial agents (2017) Proceedings of the Annual Meeting of the Cognitive Science Society (COGSCI); Briggs, G., Williams, T., Scheutz, M., Enabling robots to understand indirect speech acts in task-based interactions (2017) Journal of Human-Robot Interaction (JHRI); Trott, S., Bergen, B., A theoretical model of indirect request comprehension (2017) Proceedings of the AAAI Fall Symposium Series on Artificial Intelligence for Human-Robot Interaction (AI-HRI); Williams, T., Briggs, G., Oosterveld, B., Scheutz, M., Going beyond literal command-based instructions: Extending robotic natural language interaction capabilities (2015) Proceedings of AAAI; Trott, S., Eppe, M., Feldman, J., Recognizing intention from natural language: Clarification dialog and construction grammar (2016) Workshop on Communicating Intentions in Human-Robot Interaction; Briggs, G., Scheutz, M., How robots can affect human behavior: Investigating the effects of robotic displays of protest and distress (2014) International Journal of Social Robotics; Kahn, P.H., Kanda, T., Ishiguro, H., Gill, B.T., Ruckert, J.H., Shen, S., Gary, H., Severson, R.L., Do people hold a humanoid robot morally accountable for the harm it causes? (2012) Proceedings of the 7th ACM/IEEE International Conference on Human- Robot Interaction (HRI), pp. 33-40. , Boston, MA; Malle, B.F., Scheutz, M., Arnold, T., Voiklis, J., Cusimano, C., Sacrifice one for the good of many?: People apply different moral norms to human and robot agents (2015) Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction, pp. 117-124. , Portland, OR; Simmons, R., Makatchev, M., Kirby, R., Lee, M.K., Believable robot characters (2011) AI Magazine, (4); Malle, B.F., Scheutz, M., Austerweil, J.L., Networks of social and moral norms in human and robot agents (2017) A World with Robots; Ghose, A., Savarimuthu, T.B.R., Norms as objectives: Revisiting compliance management in multi-agent systems (2012) Proceedings of the 14th International Conference on Coordination, Organizations, Institutions, and Norms in Agent Systems VIII, pp. 105-122. , Springer-Verlag; Barraquand, R., Crowley, J.L., Learning polite behavior with situation models (2008) Proceedings of the 3rd ACM/IEEE International Conference on Human Robot Interaction, ser. HRI '08, pp. 209-216. , ACM; Gino, F., Understanding ordinary unethical behavior: Why people who value morality act immorally (2015) Current opinion in behavioral sciences, 3, pp. 107-111; Göckeritz, S., Schmidt, M.F., Tomasello, M., Young children's creation and transmission of social norms (2014) Cognitive Development; Verbeek, P.-P., Technology, M., (2011) Understanding and Designing the Morality of Things, , University of Chicago Press; Kennedy, J., Baxter, P., Belpaeme, T., Children comply with a robot's indirect requests (2014) Proceedings of HRI, pp. 198-199. , Bielefeld, Germany: ACM; Eyssel, F., Kuchenbrandt, D., Social categorization of social robots: Anthropomorphism as a function of robot group membership (2012) British Journal of Social Psychology, (4); Wen, J., Stewart, A., Billinghurst, M., Dey, A., Tossell, C., Finomore, V., He who hesitates is lost (⋯in thoughts over a robot) (2018) Proceedings of the Technology, Mind, and Society, ser. TechMindSociety '18, pp. 431-436. , http://doi.acm.org/10.1145/3183654.3183703, New York, NY, USA: ACM; Briggs, G., Scheutz, M., Sorry, i can't do that": Developing mechanisms to appropriately reject directives in human-robot interactions (2015) Proceedings of the AAAI Fall Symposium Series; Jung, M.F., Martelaro, N., Hinds, P.J., Using robots to moderate team conflict: The case of repairing violations (2015) Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI), pp. 229-236. , ACM; Williams, T., Jackson, R.B., Lockshin, J., A Bayesian analysis of moral norm malleability during clarification dialogues (2018) Proceedings of the Annual Meeting of the Cognitive Science Society (COGSCI). Madison, WI: Cognitive Science Society; Jackson, R.B., Williams, T., Robot: Asker of questions and changer of norms? (2018) Proceedings of the International Conference on Robot Ethics and Standards (ICRES). Troy, NY: CLAWAR Association; Bainbridge, W., Hart, J., Kim, E., Scassellati, B., The benefits of interactions with physically present robots over video-displayed agents (2011) International Journal of Social Robotics, 3 (1), pp. 41-52; Fischer, K., Lohan, K., Foth, K., Levels of embodiment: Linguistic analyses of factors influencing hri (2012) Proceedings of the 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI), pp. 463-470. , Boston, MA; Li, J., The benefit of being physically present: A survey of experimental works comparing copresent robots, telepresent robots and virtual agents (2015) International Journal of Human-Computer Studies, 77, pp. 23-37; Tanaka, K., Nakanishi, H., Ishiguro, H., Comparing video, avatar, and robot mediated communication: Pros and cons of embodiment (2014) Proceedings of the International Conference on Collaboration Technologies (ICCT). Minneapolis, MN, pp. 96-110. , Springer; Brown, P., Levinson, S., (1987) Politeness: Some Universals in Language Usage, , Cambridge University Press},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Halibas2019,
author={Halibas, A.S. and Al Bulushi, T.A.R.M. and Soriano, R.C. and Al Shaqsi, A.S.M.},
title={Ethical Design Perspectives of Intelligent UAVs},
journal={2019 1st International Conference on Unmanned Vehicle Systems-Oman, UVS 2019},
year={2019},
doi={10.1109/UVS.2019.8658305},
art_number={8658305},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063952563&doi=10.1109%2fUVS.2019.8658305&partnerID=40&md5=a8ba9b69e5a0ecb1fa892f9f4ce7adbc},
abstract={Intelligent systems are progressively used and are significantly impacting every aspect of the society. This paper discusses relevant ethical principles, approaches, and architectures for UAV design. This paper also presents challenges in the application of ethical design in collision avoidance and autonomous weapons systems for drones. Finally, this paper recommends the convergence of technologies and principles in building robust ethical UAVs. © 2019 IEEE.},
author_keywords={Ethical Drone;  Intelligent Agent;  Machine Ethics;  UAV},
keywords={Drones;  Intelligent agents;  Intelligent systems;  Unmanned aerial vehicles (UAV), Convergence of technologies;  Ethical designs;  Ethical principles;  In-buildings;  UAV designs;  Weapons systems, Philosophical aspects},
references={Business Insider, , online: goo.gl/uUJRWD (accessed on 8 April 18); Koubaa, A., Qureshi, B., Dronetrack: Cloud-based real-time object tracking using unmanned aerial vehicles over the internet (2018) IEEE Access, 6, pp. 13810-13824; Khan, M., Heurtefeux, K., Mohamed, A., Harras, K.A., Hassan, M.M., Mobile target coverage and tracking on drone-be-gone uav cyber-physical testbed (2018) IEEE Systems Journal, 12, pp. 3485-3496. , Dec; Ding, G., Wu, Q., Zhang, L., Lin, Y., Tsiftsis, T.A., Yao, Y., An amateur drone surveillance system based on the cognitive internet of things (2018) IEEE Communications Magazine, 56, pp. 29-35. , Jan; Tariq, A., Osama, S.M., Gillani, A., Development of a low cost and light weight uav for photogrammetry and precision land mapping using aerial imagery (2016) 2016 International Conference on Frontiers of Information Technology (FIT), pp. 360-364. , Dec; Kouba, A., Qureshi, B., Sriti, M.-F., Allouch, A., Javed, Y., Alajlan, M., Cheikhrouhou, O., Tovar, E., Dronemap planner: A service-oriented cloud-based management system for the internet-ofdrones (2019) Ad Hoc Networks, 86, pp. 46-62; Chaari, R., Ellouze, F., Koubaa, A., Qureshi, B., Pereira, N., Youssef, H., Tovar, E., Cyber-physical systems clouds: A survey (2016) Computer Networks, 108, pp. 260-278; Koubaa, A., Qureshi, B., Sriti, M., Javed, Y., Tovar, E., A serviceoriented cloud-based management system for the internet-of-drones (2017) 2017 IEEE International Conference on Autonomous Robot Systems and Competitions, ICARSC 2017, pp. 329-335. , Coimbra, Portugal, April 26-28, 2017; Redmon, J., Divvala, S.K., Girshick, R.B., Farhadi, A., You only look once: Unified, real-time object detection (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, pp. 779-788. , Las Vegas, NV, USA, June 27-30, 2016; Redmon, J., Farhadi, A., YOLO9000: Better, faster, stronger (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, pp. 6517-6525. , Honolulu, HI, USA, July 21-26, 2017; Redmon, J., Farhadi, A., Yolov3: An incremental improvement (2018) CoRR, ABS180402767; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp. 580-587; Girshick, R., Fast R-CNN (2015) Proceedings of the IEEE International Conference on Computer Vision; Girshick, R., Fast R-CNN (2015) Proceedings of the IEEE International Conference on Computer Vision; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards real-time object detection with (2017) IEEE Transactions on Pattern Analysis and Machine Intelligence; Chen, X.Y., Xiang, S.M., Liu, C.L., Pan, C.H., Vehicle detection in satellite images by hybrid deep convolutional neural networks (2014) Ieee Geoscience and Remote Sensing Letters; Ammour, N., Alhichri, H., Bazi, Y., Benjdira, B., Alajlan, N., Zuair, M., Deep learning approach for car detection in UAV imagery (2017) Remote Sensing, 9, p. 312. , mar; Comaniciu, D., Meer, P., Mean shift: A robust approach toward feature space analysis (2002) IEEE Transactions on Pattern Analysis and Machine Intelligence; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) International Conference on Learning Representations (ICRL); Szegedy, C., Ioffe, S., Vanhoucke, V., Inception-v4, inceptionresnet and the impact of residual connections on learning (2016) CoRR, ABS160207261; Everingham, M., Eslami, S.M., Van Gool, L., Williams, C.K., Winn, J., Zisserman, A., The pascal visual object classes challenge: A retrospective (2014) International Journal of Computer Vision; Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.Y., Berg, A.C., SSD: Single shot multibox detector (2016) Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics); Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) CoRR, ABS150203167; Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) Journal of Machine Learning Research, 15, pp. 1929-1958; He, K., Zhang, X., Ren, S., Sun, J., (2015) Deep Residual Learning for Image Recognition, , Arxiv.Org; Video Demonstration of Real Time Car Detection from Uav Images, , https://www.youtube.com/watch?v=rlpuhjmkcv4, online [accessed on 18-12-2018]; Aerial-car-dataset, , https://github.com/jekhor/aerial-cars-dataset, online accessed on (16-10-2018); Tensorflow-object-detection-api, , https://github.com/tensorflow/models/tree/master/research/objectdetection, accessed on (16-10-2018). http://www.skyhopper.biz/autonomous-uavs online [Accessed: 04-May-2018]; (2014) The Security Impact of Drones: Challenges and Opportunities for the UK, , Birmingham; Churchill, R.R., Ulfstein, G., Autonomous institutional arrangements in multilateral environmental agreements: A little-noticed phenomenon in international law (2000) Am. J. Int. Law; Etzioni, A., The great drone debate (2013) Mil. Rev., (APRIL), pp. 2-13; Hexmoor, H., McLaughlan, B., Tuli, G., Natural human role in supervising complex control systems (2009) J. Exp. Theor. Artif. Intell.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Wilks201933,
author={Wilks, Y.},
title={Moral orthoses: A new approach to human and machine ethics},
journal={AI Magazine},
year={2019},
volume={40},
number={1},
pages={33-34},
doi={10.1609/aimag.v40i1.2854},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064809289&doi=10.1609%2faimag.v40i1.2854&partnerID=40&md5=4c050e8608a3dadba01b9f4e084ed0c0},
abstract={I argue that both human and machine actions are more opaque than is generally realized and that the actions of both require explanation that an ethical orthosis might provide as aspects of artificial Companions for both human and machine actors. These explanations might well be closer to ethical accounts based on moral sentiment or emotion in the tradition of the primacy of sentiment over reason in this area of human and machine action. Copyright © 2019, Association for the Advancement of Artificial Intelligence. All rights reserved.},
keywords={Artificial intelligence, Artificial companions;  New approaches;  Orthoses;  Orthosis, Philosophical aspects},
references={Bostrom, N., Yudkowsky, E., The ethics of artificial intelligence (2014) The Handbook of Artificial Intelligence, , Cambridge, UK: Cambridge University Press; Eubanks, V., (2018) Automating Inequality, , New York: Macmillan; Gray, J., (2002) Straw Dogs, , London: Granta Books; MacIntyre, A., (1985) After Virtue, , London: Duckworth; McDermott, D., Why ethics is a high hurdle for AI (2008) The North American Conference on Computers and Philosophy, , Paper Bloomington, IN, July 10–12; Pearl, J., (2018) The Book of Why: The New Science of Cause and Effect, , New York: Basic Books; Wilks, Y., (2010) Artificial Companions, , ed. Amsterdam, Netherlands: John Benjamins},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Malle201921,
author={Malle, B.F. and Bello, P. and Scheutz, M.},
title={Requirements for an artificial agent with norm competence},
journal={AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
year={2019},
pages={21-27},
doi={10.1145/3306618.3314252},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070593986&doi=10.1145%2f3306618.3314252&partnerID=40&md5=221925bc832f82c263883fb78a559397},
abstract={Human behavior is frequently guided by social and moral norms, and no human community can exist without norms. Robots that enter human societies must therefore behave in norm-conforming ways as well. However, currently there is no solid cognitive or computational model available of how human norms are represented, activated, and learned. We provide a conceptual and psychological analysis of key properties of human norms and identify the demands these properties put on any artificial agent that incorporates norms-demands on the format of norm representations, their structured organization, and their learning algorithms. © 2019 Copyright is held by the owner/author(s). Publication rights licensed to ACM.},
author_keywords={ArtiXicial agents;  Cognition;  Learning;  Norms;  Robot ethics},
keywords={Learning algorithms;  Philosophical aspects, Cognition;  Computational model;  Human communities;  Learning;  Norms;  Psychological analysis;  Robot ethics;  Structured organization, Behavioral research},
references={Aarts, H., Dijksterhuis, A., The silence of the library: Environment, situational norm, and social behavior (2003) Journal of Personality and Social Psychology, 84 (1), pp. 18-28. , https://doi.org/10.1037/0022-3514.84.1.18, Jan. 2003; Abel, D., Reinforcement learning as a framework for ethical decision making (2016) AAAI Workshop: AI, Ethics, and Society, Volume WS-16-02 of 13th AAAI Workshops, , 2016; Allen, C., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics and Information Technology, 7 (3), pp. 149-155. , https://doi.org/10.1007/s10676-006-0004-4, Sep. 2005; Anderson, M., A value-driven eldercare robot: Virtual and physical instantiations of a case-supported principle-based behavior paradigm (2018) Proceedings of the IEEE, pp. 1-15. , https://doi.org/10.1109/JPROC.2018.2840045, 2018; Arai, S., Suzuki, K., Encouragement of right social norms by inverse reinforcement learning (2014) Journal of Information Processing, 22 (2), pp. 299-306. , https://doi.org/10.2197/ipsjjip.22.299, 2014; Arnold, T., Value alignment or misalignment - What will keep systems accountable? (2017) The Workshops of the Thirty-First AAAI Conference on Artificial Intelligence: Technical Reports, WS-17-02: AI, Ethics, and Society, pp. 81-88. , The AAAI Press; Bello, P., An attention-driven computational model of human causal reasoning (2018) Proceedings of the 40th Annual Meeting of the Cognitive Science Society, pp. 1353-1358. , Austin, TX, 2018; Bendor, J., Swistak, P., The evolution of norms (2001) American Journal of Sociology, 106 (6), pp. 1493-1545. , 2001; Bicchieri, C., (2006) The Grammar of Society: The Nature and Dynamics of Social Norms, , Cambridge University Press; Brauer, M., Chaurand, N., Descriptive norms, prescriptive norms, and social control: An intercultural comparison of people's reactions to uncivil behaviors (2010) European Journal of Social Psychology, 40 (3), pp. 490-499. , https://doi.org/10.1002/ejsp.640, Apr. 2010; Brennan, G., (2013) Explaining Norms, , Oxford University Press; Bringsjord, S., Toward a general logicist methodology for engineering ethically correct robots (2006) Intelligent Systems, IEEE, 21 (4), pp. 38-44. , 2006; Chisholm, R.M., Contrary-to-duty imperatives and deontic logic (1963) Analysis, 24 (2), pp. 33-36. , https://doi.org/10.2307/3327064, 1963; Cialdini, R.B., A focus theory of normative conduct: Recycling the concept of norms to reduce littering in public places (1990) Journal of Personality and Social Psychology, 58 (6), pp. 1015-1026. , https://doi.org/10.1037/0022-3514.58.6.1015, 1990; Gasparini, L., Severity-sensitive norm-governed multi-agent planning (2018) Autonomous Agents and Multi-Agent Systems, 32 (1), pp. 26-58. , https://doi.org/10.1007/s10458-017-9372-x, Jan. 2018; Gibbs, J.P., Norms: The problem of definition and classification (1965) American Journal of Sociology, 70 (5), pp. 586-594. , https://doi.org/10.1086/223933, 1965; Hechter, M., Opp, K.-D., (2001) Social Norms, , Russell Sage Foundation; Henrich, J., The evolution of costly displays, cooperation and religion: Credibility enhancing displays and their implications for cultural evolution (2009) Evolution and Human Behavior, 30 (4), pp. 244-260. , https://doi.org/10.1016/j.evolhumbehav.2009.03.005, Jul. 2009; Kasenberg, D., Scheutz, M., Interpretable apprenticeship learning with temporal logic specifications (2017) Proceedings of the 56th IEEE Conference on Decision and Control (CDC 2017), pp. 4914-4921. , IEEE Press; Kasenberg, D., Scheutz, M., Norm conflict resolution in stochastic domains (2018) Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, , 2018; Kim, J., Not-So-ClevR: Learning same-different relations strains feed-forward neural networks (2018) Interface Focus, 8, p. 4. , https://doi.org/10.1098/rsfs.2018.0011, 2018); Kollingbaum, M.J., Managing conflict resolution in norm-regulated environments (2008) Engineering Societies in the Agents World VIII, pp. 55-71. , A. Artikis et al., eds. Springer Berlin Heidelberg; Li, J., Reinforcement learning of normative monitoring intensities (2015) Proceedings of the International Workshop on Coordination, Organisation, Institutions and Norms in Multi-Agent Systems, , 2015; Mack, A., Changing social norms (2018) Social Research: An International Quarterly, 85 (1), pp. 1-271. , ed. 2018; Mahmoud, M.A., A review of norms and normative multiagent systems (2014) The Scientific World Journal, 2014, pp. 1-23. , https://doi.org/10.1155/2014/684587, 2014; Malle, B.F., (2018) From Binary Deontics to Deontic Continua: The Nature of Human (and Robot) Norm Systems; Malle, B.F., Networks of social and moral norms in human and robot agents (2017) A World with Robots: International Conference on Robot Ethics: ICRE 2015, pp. 3-17. , M.I. Aldinhas Ferreira et al., eds. Springer International Publishing; Milgram, S., Note on the drawing power of crowds of different size (1969) Journal of Personality and Social Psychology, 13 (2), pp. 79-82. , https://doi.org/10.1037/h0028070, Oct. 1969; Nickles, M., Towards a logic of graded normativity and norm adherence (2007) Normative Multi-Agent Systems: Dagstuhl Seminar Proceedings, , Dagstuhl, Germany, 2007; Nyga, D., Beetz, M., Everything robots always wanted to know about housework (but were afraid to ask) (2012) 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 243-250. , IEEE Press; Parsons, T., (1951) The Social System, , Free Press; Pereira, L.M., Saptawijaya, A., Modelling morality with prospective logic (2007) Progress in Artificial Intelligence, pp. 99-111. , J. Neves et al., eds. Springer Berlin Heidelberg; Prentice, D.A., Miller, D.T., Pluralistic ignorance and the perpetuation of social norms by unwitting actors (1996) Advances in Experimental Social Psychology, pp. 161-209. , M. Zanna, ed. Academic Press; Rakoczy, H., The sources of normativity: Young children's awareness of the normative structure of games (2008) Developmental Psychology, 44 (3), pp. 875-881. , https://doi.org/10.1037/0012-1649.44.3.875, May 2008; Russell, S., (2016) Research Priorities for Robust and Beneficial Artificial Intelligence, , arXiv preprint 2016; Savarimuthu, B.T.R., Identifying prohibition norms in agent societies (2013) Artificial Intelligence and Law, 21 (1), pp. 1-46. , 2013; Schelling, T.C., (1960) The Strategy of Conflict, , Harvard University Press; Scheutz, M., Spoken instruction-based one-shot object and action learning in a cognitive robotic architecture (2017) Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems, pp. 1378-1386. , International Foundation for Autonomous Agents and Multiagent Systems; Serramia, M., Moral values in norm decision making (2018) Proceedings of the 17th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2018), pp. 1294-1302. , Richland, SC, 2018; Shams, Z., Practical reasoning with norms for autonomous software agents (2017) Engineering Applications of Artificial Intelligence, 65, pp. 388-399. , https://doi.org/10.1016/j.engappai.2017.07.021, Oct. 2017; Steyvers, M., Tenenbaum, J.B., The large-scale structure of semantic networks: Statistical analyses and a model of semantic growth (2005) Cognitive Science, 29 (1), pp. 41-78. , https://doi.org/10.1207/s15516709cog2901_3, Jan. 2005; Telesford, Q.K., The ubiquity of small-world networks (2011) Brain Connectivity, 1 (5), pp. 367-375. , https://doi.org/10.1089/brain.2011.0038, Dec. 2011; Ullman, S., Visual routines (1984) Cognition, 18 (1-3), pp. 97-159. , Dec. 1984; Ullmann-Margalit, E., (1977) The Emergence of Norms, , Clarendon Press; Wilson, D.S., (2002) Darwin's Cathedral: Evolution, Religion, and the Nature of Society, , University of Chicago Press; Wright, J.C., Bartsch, K., Portraits of early moral sensibility in two children's everyday conversations (2008) Merrill-Palmer Quarterly, 54 (1), pp. 56-85. , https://doi.org/10.1353/mpq.2008.0010, Mar. 2008; Yuan, L., Are categorical spatial relations encoded by shifting visual attention between objects? (2016) PLOS ONE, 11 (10), pp. 1-22. , https://doi.org/10.1371/journal.pone.0163141, 2016},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wright20193,
author={Wright, A.T.},
title={Rightful machines and dilemmas},
journal={AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
year={2019},
pages={3-4},
doi={10.1145/3306618.3314261},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070588176&doi=10.1145%2f3306618.3314261&partnerID=40&md5=bf4a99317a8c5873201daff61ad804fc},
abstract={In a recent massive experiment conducted online, millions of subjects were asked what a self-driving car whose brakes have failed should do when its only choices were to swerve or stay on course under various accident conditions (Awad, et al, 2018). Should the car swerve and kill one person in order to avoid killing five people on the road ahead? Most subjects agreed that it should. Most subjects also agreed, however, that the car should generally spare younger people over older people, females over males, those of higher status over those of lower status, and the fit over the overweight, with some variations in preferences correlated with subjects' cultural backgrounds. But while such results may be interesting, they seem to me irrelevant to the question as to what a self-driving car faced with such dilemmas should be programmed to do. Efforts to build explicitly moral machine agents such as self-driving cars should focus on duties of right, or justice, which are in principle legitimately enforceable, rather than on duties of virtue, or ethics, which are not. While dilemmas such as the (in)famous "trolley problem"-which inspired the experiment above-have received enormous attention in machine ethics, there will likely never be an ethical consensus as to their correct resolution, and even if one could be achieved, it would be largely irrelevant to the task at hand. What matters normatively is whether machine agents charged with making decisions that affect human beings act rightfully, that is, in ways that respect real persons' equal rights of freedom and basic principles of justice. Whatever private ethical resolution one prefers of dilemmas such as in the trolley problem, it is public law that should determine when makers or users of semi-autonomous machines such as self-driving cars are liable or culpable for the machine's decisions, and law must conform to principles of justice, not the partial ethical preferences of one group or another. The first goal of machine ethics, therefore, should be to build rightful machines, machines that respect public law and basic principles of justice In this paper I set out a new, Kantian approach to resolving conflicts and dilemmas of obligation for semi-autonomous machine agents such as self-driving cars. First, I set out the modern Kantian rationale for the distinction between law and ethics, and the priority of right. In a society where everyone is morally equal, no one individual or group has the normative authority to unilaterally decide how moral conflicts should be resolved for everyone. Only public institutions to which everyone can consent have the authority to define, enforce, and adjudicate our rights and obligations with respect to one another. Hence the determinations of legitimate public institutions as to our respective obligations take normative priority over individual ethical judgments in cases of conflict between them. The coordinated relationship between law and ethics, and the priority of right, have important implications for builders of explicitly moral machine agents. The most important is that machine agents that act morally must first of all act rightfully. I then show how shifting the focus to law and a standard of justice resolves the conflicts of obligation in the main variations of the trolley problem for rightful machine agents. Only one such variation, Driver, cannot be resolved by appeal to the priority of right, as it presents a true conflict (dilemma) of legal obligations. But from the point of view of justice, such dilemmas are little different from other conflicts of legal obligation. Unlike a system of ethical duties, the system of legal duties must be made consistent; otherwise, enforcement would be arbitrary and thus unjust. Hence dilemmas must be resolved in public law, even if there is no decisive rational resolution of the conflict at issue. Finally, I consider how a deontic logic suitable for governing rightful machines can meet the normative demands of justice/ I argue that the role of a deontic logic of the law is not to neutralize or work around conflicts but to expose them so that civil institutions can authoritatively qualify the rights or duties that generate inconsistencies. I propose that non-monotonic logics can meet the normative demand for consistency, although a logic of belief revision may be preferred. © 2019 Copyright is held by the owner/author(s).},
author_keywords={Autonomous Vehicles;  Belief Revision;  Conflicts;  Deontic Logic;  Dilemmas;  Kant;  Law;  Machine Agents;  Machine Ethics;  Moral Machines;  Non-monotonic Logic;  Priority of Right;  Rightful Machines;  Trolley Problem},
keywords={Accidents;  Autonomous agents;  Computer circuits;  Formal logic;  Philosophical aspects, Belief revision;  Conflicts;  Deontic Logic;  Dilemmas;  Kant;  Nonmonotonic logic;  Priority of Right;  Trolley Problem, Autonomous vehicles},
references={Alchourron, C., Conflicts of norms and the revision of normative systems (1991) Law and Philosophy, 10, pp. 413-425; Alchourron, C., Gardenfors, P., Makinson, D., On the logic of theory change (1985) Journal of Symbolic Logic, 50 (2), pp. 510-530; (1985) Model Penal Code: Official Draft and Explanatory Notes: Complete Text of Model Penal Code as Adopted at the 1962 Annual Meeting of the American Law Institute at Washington, , American Law Institute. D.C., May 24, 1962. The Institute, Philadelphia, MPC; Aqvist, L., Alchourron and Bulygin on deontic logic and the logic of norm-propositions, axiomatization, and representability results (2008) Logique & Analyse, 203, pp. 225-261; Awad, E., Dsouza, S., Kim, R., Schulz, J., Henrich, J., Shariff, A., Bonnefon, J.F., The moral machine experiment (2018) Nature, 563, pp. 59-64; Foot, P., The problem of abortion and the doctrine of double effect (1967) Oxford Review, 5, pp. 5-15; Gelfond, M., Chapter 1: Answer sets (2008) Foundations of Artificial Intelligence, 3, pp. 285-316; Goble, L., A logic for deontic dilemmas (2005) Journal of Applied Logic, 3, pp. 461-483; Guarini, M., Conative dimensions of machine ethics: A defense of duty (2012) IEEE Transactions on Affective Computing, 3 (4), pp. 434-442; Hart, H., Rawls on liberty and its priority (1973) The University of Chicago Law Review, 40, pp. 534-555; Hohfeld, W., (1919) Fundamental Legal Conceptions as Applied in Judicial Reasoning, , Walter Wheeler Cook. Yale University Press, New Haven, CT; Kant, I., The doctrine of right, part one of the metaphysics of morals (1992) The Cambridge Edition of the Works of Immanuel Kant, , 1797) trans. M. Gregor DR In Guyer and A. Wood eds, Cambridge University Press, Cambridge. All references to Kant's work are from the Cambridge edition unless otherwise noted. Citations are according to standard Academy pagination; Kant, I., Groundwork of the Metaphysics of Morals, , trans. M. Gregor GM; Kant, I., On the Common Saying: 'That May Be Correct in Theory but It is of No Use in Practice, , trans. M. Gregor. T; Kant, I., Toward Perpetual Peace, , trans M. Gregor; Liao, S., Wiegmann, A., Alexander, J., Vong, G., Putting the trolley in order: Experimental philosophy and the loop case (2012) Philosophical Psychology, 25 (5), pp. 661-671; Maranhao, J., Why was Alchourron afraid of snakes? (2006) Analisis Filosofico, 26 (1), pp. 62-92; Mikhail, J., Universal moral grammar: Theory, evidence, and the future (2007) Trends in Cognitive Sciences, 11 (4), pp. 143-152; Mill, J.S., On liberty (1859), in essays on politics and society (1977) The Collected Works of John Stuart Mill, 18. , J.M. Robson, ed, University of Toronto Press, Toronto; Navarro, P., Rodriguez, J., (2014) Deontic Logic and Legal Systems, , Cambridge University Press, Cambridge; O'Neill, O., (2011) Constructing Authorities, , Cambridge University Press, Cambridge; Petrinovich, L., O'Neill, P., Influence of wording and framing effects on moral intuitions (1996) Ethology and Sociobiology, 17, pp. 145-171; Rawls, J., (1993) Political Liberalism, , Columbia University Press, New York; Thomson, J., Killing, letting die, and the trolley problem (1976) The Monist, 59, pp. 204-217; Thomson, J., Turning the trolley (2008) Philosophy & Public Affairs, 36 (4), pp. 359-374; Tonkens, R., A challenge for machine ethics (2009) Minds & Machines, 19, pp. 421-438},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Jackson2019523,
author={Jackson, R.B.},
title={Generating appropriate responses to inappropriate robot commands},
journal={AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
year={2019},
pages={523-524},
doi={10.1145/3306618.3314306},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070573342&doi=10.1145%2f3306618.3314306&partnerID=40&md5=2a94be428c18aaf2194ad0d53057b83e},
abstract={This paper describes early work at the intersection of robot ethics and natural language generation investigating two overarching questions: (1) how might current language generation algorithms generate utterances with unintended implications or otherwise accidentally alter the ecosystem of human norms, and (2) how can we design future language systems such that they purposefully influence the human normative ecosystem as productively as possible. © 2019 Copyright held by the owner/author(s).},
author_keywords={Human-robot interaction;  Natural language generation;  Robot ethics},
keywords={Ecosystems;  Machine design;  Natural language processing systems;  Philosophical aspects, Language generation;  Natural language generation;  Robot commands;  Robot ethics, Human robot interaction},
references={Barraquand, R., Crowley, J.L., Learning polite behavior with situation models (2008) Proceedings of HRI; Briggs, G., Scheutz, M., How robots can affect human behavior: Investigating the effects of robotic displays of protest and distress (2014) Int'L Journal of Social Robotics, , 2014; Briggs, G., Scheutz, M., Sorry, I can't do that”: Developing mechanisms to appropriately reject directives in human-robot interactions (2015) AAAI Fall Symposium Series; Brown, P., Levinson, S., (1987) Politeness: Some Universals in Language Usage, , Cambridge University Press; Eyssel, F., Kuchenbrandt, D., Social categorization of social robots: Anthropomorphism as a function of robot group membership (2012) British Journal of Social Psych, , 2012; Gervits, F., Briggs, G., Scheutz, M., The pragmatic parliament: A framework for socially-appropriate utterance selection in artificial agents (2017) COGSCI; Ghose, A., Roy Savarimuthu, T.B., Norms as objectives: Revisiting Compliance Management in Multi-agent Systems (2012) Proc. COIN. Springer-Verlag, pp. 105-122; Gino, F., Understanding ordinary unethical behavior: Why people who value morality act immorally (2015) Current Opinion in Behavioral Sciences, 3, pp. 107-111. , 2015; Jackson, R.B., Williams, T., Robot: Asker of questions and changer of norms? (2018) Proceedings of ICRES; Jung, M.F., Martelaro, N., Hinds, P.J., Using robots to moderate team conflict: The case of repairing violations (2015) Proceedings of HRI, pp. 229-236; Kahn, P.H., Kanda, T., Ishiguro, H., Gill, B.T., Ruckert, J.H., Shen, S., Gary, H., Severson, R.L., Do people hold a humanoid robot morally accountable for the harm it causes? (2012) HRI, pp. 33-40. , Boston, MA; Levinson, S.C., (2000) Presumptive Meanings: The Theory of Generalized Conversational Implicature, , MIT press; Malle, B.F., Scheutz, M., Austerweil, J.L., Networks of social and moral norms in human and robot agents (2017) A World with Robots, pp. 3-17. , Springer; Verbeek, P.-P., (2011) Moralizing Technology: Understanding and Designing the Morality of Things; Williams, T., Jackson, R.B., Lockshin, J., A Bayesian analysis of moral norm malleability during clarification dialogues (2018) Proceedings of COGSCI},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Baum201934,
author={Baum, K. and Hermanns, H. and Speith, T.},
title={Towards a framework combining machine ethics and machine explainability},
journal={Electronic Proceedings in Theoretical Computer Science, EPTCS},
year={2019},
volume={286},
pages={34-49},
doi={10.4204/EPTCS.286.4},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060391061&doi=10.4204%2fEPTCS.286.4&partnerID=40&md5=8ef6c86da4105112da255afd36414950},
abstract={We find ourselves surrounded by a rapidly increasing number of autonomous and semi-autonomous systems. Two grand challenges arise from this development: Machine Ethics and Machine Explainability. Machine Ethics, on the one hand, is concerned with behavioral constraints for systems, so that morally acceptable, restricted behavior results; Machine Explainability, on the other hand, enables systems to explain their actions and argue for their decisions in a way that human users can understand and justifiably trust them. In this paper, we try to motivate and work towards a framework combining Machine Ethics and Machine Explainability. Starting from a toy example, we detect various desiderata of such a framework and argue why they should and how they could be incorporated in autonomous systems. Our main idea is to apply a framework of formal argumentation theory both, for decision-making under ethically motivated constraints and for the task of generating useful explanations based on these constraints given only limited knowledge of the world. The result of our deliberations can be described as a first version of an ethically motivated, principle-governed framework combining Machine Ethics and Machine Explainability. c K. Baum, H. Hermanns & T. Speith This work is licensed under the Creative Commons Attribution License.},
keywords={Decision making;  Decision theory, Autonomous systems;  Creative Commons;  Formal argumentation;  Grand Challenge;  Human users;  Semi-autonomous systems, Philosophical aspects},
references={Alonso, J.M., Trivino, G., An Essay on Self-explanatory Computational Intelligence: A Linguistic Model of Data Processing Systems (2017) Proceedings of The 1st Workshop on Explainable Computational Intelligence (XCI 2017); Amgoud, L., Prade, H., Using arguments for making and explaining decisions (2009) Artificial Intelligence, 173 (3), pp. 413-436; Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge University Press; Anscombe, G.E.M., Modern Moral Philosophy (1958) Philosophy, 33 (124), pp. 1-19; Aristotle, The Nicomachean Ethics; Barthe, G., D'Argenio, P.R., Finkbeiner, B., Hermanns, H., Facets of software doping (2016) International Symposium on Leveraging Applications of Formal Methods, pp. 601-608. , Springer; Baum, K., What the Hack Is Wrong with Software Doping? (2016) International Symposium on Leveraging Applications of Formal Methods, pp. 633-647. , Springer; Baum, K., Hermanns, H., Speith, T., (2018) From Machine Ethics To Machine Explainability and Back, , http://isaim2018.cs.virginia.edu/papers/ISAIM2018_Ethics_Baum_etal.pdf; Baum, K., Köhl, M.A., Schmidt, E., Two challenges for ci trustworthiness and how to address them (2017) Proceedings of The 1st Workshop on Explainable Computational Intelligence (XCI 2017); Bentham, J., (1789) An Introduction to The Principles of Morals and Legislation; Bykvist, K., (2009) Utilitarianism: A Guide for The Perplexed, , Bloomsbury Publishing; Conitzer, V., Sinnott-Armstrong, W., Borg, J.S., Deng, Y., Kramer, M., (2017) Moral Decision Making Frameworks for Artificial Intelligence; Dancy, J., (2004) Ethics Without Principles, , Oxford: Claredon Press; Dancy, J., Moral particularism (2017) The Stanford Encyclopedia of Philosophy, , Edward N. Zalta, editor: winter 2017 edition, Metaphysics Research Lab, Stanford University; Davidson, D., Actions, reasons, and causes (1963) The Journal of Philosophy, 60 (23), pp. 685-700; Dennis, L., Fisher, M., (2018) Practical Challenges in Explicit Ethical Machine Reasoning, , arXiv preprint; Dietrich, F., List, C., What matters and how it matters: A choice-theoretic representation of moral theories (2017) Philosophical Review, 126 (4), pp. 421-479; Dung, P.M., On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games (1995) Artificial Intelligence, 77 (2), pp. 321-357; D'Argenio, P.R., Barthe, G., Biewer, S., Finkbeiner, B., Hermanns, H., Is Your Software on Dope? (2017) European Symposium on Programming, pp. 83-110. , Springer; Foot, P., (1967) The Problem of Abortion and The Doctrine of Double Effect; Franklin, B., (1887) Letter to J. B. Priestley, 1772, p. 522. , Putnam, New York; Gardiner, S.M., A core precautionary principle (2006) Journal of Political Philosophy, 14 (1), pp. 33-60; Hempel, C.G., Deductive-Nomological Explanation (1965) Aspects of Scientific Explanation, pp. 335-376; Hempel, C.G., Inductive-Statistical Explanation (1965) Aspects of Scientific Explanation, pp. 381-393; Hengstler, M., Enkel, E., Duelli, S., Applied artificial intelligence and trust—The case of autonomous vehicles and medical assistance devices (2016) Technological Forecasting and Social Change, 105, pp. 105-120; Horacek, H., Requirements for Conceptual Representations of Explanations and How Reasoning Systems Can Serve Them (2017) Proceedings of The 1st Workshop on Explainable Computational Intelligence (XCI 2017); Horty, J., Reasons as Defaults (2007) Philosophers' Imprint, 7, pp. 1-28; Kant, I., (1785) Groundwork for The Metaphysics of Morals; Karl, P., (1963) Conjectures and Refutations: The Growth of Scientific Knowledge; Kolodny, N., Brunero, J., Instrumental rationality (2016) The Stanford Encyclopedia of Philosophy, , Edward N. Zalta, editor: winter 2016 edition, Metaphysics Research Lab, Stanford University; Langley, P., Meadows, B., Sridharan, M., Choi, D., (2017) Explainable Agency for Intelligent Autonomous Systems; Lord, E., Maguire, B., (2016) Weighing Reasons, , Oxford University Press USA; Mantel, S., Worldly reasons: An ontological inquiry into motivating considerations and normative reasons (2017) Pacific Philosophical Quarterly; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Portmore, D.W., (2011) Commonsense Consequentialism: Wherein Morality Meets Rationality, , Oxford University Press USA; Ross, W.D., (1930) The Right and The Good, , Oxford University Press; Smart, J.J.C., Williams, B., (1973) Utilitarianism: For and Against, , Cambridge University Press; Wallach, W., Allen, C., (2008) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2019,
title={Electronic Proceedings in Theoretical Computer Science, EPTCS},
journal={Electronic Proceedings in Theoretical Computer Science, EPTCS},
year={2019},
volume={286},
page_count={80},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060375258&partnerID=40&md5=d9dd1027523b26134b6df195a420a06e},
abstract={The proceedings contain 6 papers. The topics discussed include: causality for general LTL-definable properties; interventionist counterfactuals on causal teams; causality analysis for concurrent reactive systems; towards a framework combining machine ethics and machine explainability; the challenges in specifying and explaining synthesized implementations of reactive systems; and interactions between causal structures in graph rewriting systems.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Schwarz2019232,
author={Schwarz, E.C.},
title={Human vs. Machine: A framework of responsibilities and duties of transnational corporations for respecting human rights in the use of artificial intelligence},
journal={Columbia Journal of Transnational Law},
year={2019},
volume={58},
number={1},
pages={232-277},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082483343&partnerID=40&md5=3ce5f8870b527dcbf424523a5fbdf6d8},
abstract={The use of artificial intelligence is spreading rapidly through all types of industries, and with this expansion comes various implications for international human rights standards. This Note analyzes the current responsibilities, if any, of transnational corporations deploying artificial intelligence through products and services to avoid human rights violations, and then proposes a framework for what their responsibilities should be. First, this Note explores the current uses of artificial intelligence in the global business setting and enumerates the human rights standards that could potentially be violated by such practices. Then, this Note argues for using several international mechanisms to be used to hold transnational corporations responsible and accountable for the harmful use of artificial intelligence. Specifically, the World Bank should adopt policies that limit loans for development projects that plan to use products that could negatively impact human rights through their application of artificial intelligence. Further, this Note proposes expanding the use of the Global Magnitsky Act's permission to impose asset freezes and travel bans on transnational corporations that cause or perpetrate human rights abuses through artificial intelligence, which can serve as both a deterrent and a tool for accountability. This Note also discusses the prospects of a new international treaty to regulate the corporate use of artificial intelligence. Separately, the use of voluntary, private international arbitration could settle cases outside of international judicial settings, especially given that transnational corporations may be more willing to comply with such a mechanism. Finally, this Note explores and then rejects the idea of holding the actual technology accountable, i.e., robot ethics. © 2019 Columbia Law Review Association. All rights reserved.},
references={Violino, B., Risky AI business: Navigating regulatory and legal dangers to come (2018) CIO, , https://www.cio.com/article/3256031/artificialintelligence/risky-ai-business-navigating-regulatory-and-legal-dangers-to-come.html, Feb. 19, 3:00 AM, https://perma.cc/TT7D-3VM9; Erdelyi, O.J., Goldsmith, J., Regulating artificial intelligence: Proposal for a global solution (2018) 2018 AAAI/ACM Conf. On AI, Ethics & Soc'y, , https://ssrn.com/abstract=3263992, Feb. 2-3, https://perma.cc/G78P-D8D7; (2016) Executive Off. Of the President Nat'l Sci. & Tech. Council Committee on Tech., Preparing for the Future of Artificial Intelligence, 6. , https://obamawhitehouse.archives.gov/sites/default/files/whitehouse_files/microsites/ostp/NSTC/preparing_for_the_future_of_ai.pdf, https://perma.cc/9GGV-ERRH; Merriam-Webster Online Dictionary, , https://www.merriam-webster.com/dictionary/artificial%20intelligence, Artificial intelligence, https://perma.cc/RKM7-UC26 last visited Oct. 19,2019; Sharma, A., Difference between machine learning and artificial intelligence Geeksforgeeks, , https://www.geeksforgeeks.org/difference-between-machine-learningand-artificial-intelligence/, https://perma.cc/H66D-6NUH last visited Oct. 18,2019; Davenport, T.H., Ronanki, R., Artificial intelligence for the real world (2018) Harv. Bus. Rev., , https://hbr.org/2018/01/artificial-intelligence-forthe-real-world, Jan.-Feb. https://perma.cc/SN94-SKZZ; Ramaswamy, S., How companies are already using AI (2017) Harv. Bus. Rev., , https://hbr.org/2017/04/how-companies-are-already-using-ai, Apr. 14, https://perma.cc/ 33Y8-AP5N; SpecialReport:Non-techbusinessesarebeginningtouseartificialintelligenceat scale (2018) Economist, , https://www.economist.com/special-report/2018/03/31/non-tech-businesses-are-beginning-to-use-artificial-intelligence-at-scale, Mar. 31, https://perma.cc/T6MQ-UKJF; Denyer, S., China's watchful eye (2018) Wash. Post, , https://www.washingtonpost.com/news/world/wp/2018/01/07/feature/in-china-facialrecognition-is-sharp-end-of-a-drive-for-total-surveillance/?utm_term=.2dl3860262cb, Jan. 7, https://perma.cc/J2W9-3MYW; (2015) Tractica Artificial Intelligence for Enterprise Applications, , https://www.tractica.com/wp-content/uploads/2015/04/AIE-15-Brochure.pdf, https://perma.cc/V9T7-BM4A; The Foundation of International Human Rights Law, , http://www.un.org/en/sections/universal-declaration/foundation-international-human-rightslaw/index.html, U.N, https://perma.cc/2EHH-LHQP last visited Oct. 19,2019; Hannum, H., The UDHR in national and international law (1998) Harv. J. Health & Hum.Rts., 3, p. 144. , 145; The covenant on civil & political rights (ICCPR) Am. Civ. Liberties Union, , https://www.aclu.org/other/faq-covenant-civil-political-rights-iccpr, https://perma.cc/D3QC-AGJJ last visited Oct. 19, 2019; Office of the U.N. High Comm'r for Human Rights [Ohchr], , https://www.ohchr.org/EN/HRBodies/CESCR/Pages/CESCRIndex.aspx, https://perma.cc/9C9K-XBGW last visited Oct. 19,2019; Human Rights Bodies - Complaints Procedures, , https://www.ohchr.org/en/hrbodies/tbpetitions/pages/hrtbpetitions.aspx, https://perma.cc/58P8-E7V8 last visited Oct. 19,2019; Collins, T., Spy cameras could soon know what we 're thinking and feeling simply by scanning our BODIES - And there may be no way to opt-out (2018) Daily Mail, , https://www.dailymail.co.uk/sciencetech/article-5611645/Future-devices-letcompanies-scan-body-detect-mood-health.html, Apr. 13, 11:45 AM, https://perma.cc/797S-NN9L; Perspective Api, , https://perspectiveapi.eom/#/home, https://perma.ee/HVN4-L7UV last visited Oct. 19,2019; Prabhu, M., Security and privacy in artificial intelligence and machine learning - Part 1: Lay of the land (2018) Medium, , https://towardsdatascience.corn/security-and-privacy-in-artificial-intelligence-and-machine-learning-part-l-c6f607feb94b, July 28, https://perma.cc/MTH9-7XKP; Lohr, S., Facial recognition is accurate, if you 're a white guy (2018) N.Y. Times, , https://www.nytimes.com/2018/02/09/technology/facial-recognition-raceartificial-intelligence.html, Feb. 9, https://perma.cc/X8AG-BCLR; Dastin, J., Amazon scraps secret AI recruiting tool that showed bias against women (2018) Reuters, , https://www.reuters.com/article/us-amazoncom-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-biasagainst-women-idUSKCNlMK08G, Oct. 9, 11:12 PM, https://perma.cc/48TC-XNPR; Swire, P., Social networks, privacy, and freedom of association, 2011 CTR For American Progress, 1 (7), pp. 16-17. , https://cdn.americanprogress.org/wpcontent/uploads/issues/2011/02/pdf/social_networks_privacy.pdf, https://perma.cc/46W6442K; Robitzski, D., Former Google Exec: AI will replace 40 percent of jobs in 15 years (2019) Futurism, , https://futurism.com/the-byte/google-ai-jobs, Jan. 10, https://perma.cc/W83D-BQFP; Elliott, C., Chatbots are killing customer service. Here's why (2018) Forbes, , https://www.forbes.com/sites/christopherelliott/2018/08/27/chatbots-are-killing-customer-service-heres-why/#7776b93fl3c5, Aug. 27, 8:19 AM, https://perma.cc/G6R9-CR9G; The Danish Tech Ambassador, , supra note 43; Bossmann, J., Top 9 ethical issues in artificial intelligence (2016) World Econ. F., , https://www.weforum.org/agenda/2016/10/top-10-ethical-issues-inartificial-intelligence/, Oct. 21, https://perma.cc/R7D7-NV4E; Does regulating artificial intelligence save humanity or just stifle innovation? (2017) The Conversation, , https://theconversation.com/does-regulating-artificial-intelligence-save-humanity-or-just-stifle-innovation-85718, Oct. 22, 7:48 PM, https://perma.cc/68EBXVXS; Henkin, L., Cleveland, S., Helfer, L., Neuman, G., Orentlicher, D., (2009) Human Rights, 213. , 2d ed; Djelic, M.-L., Quack, S., Globalization and business regulation (2018) Ann. Rev. Sociol., 44, p. 123. , 124; (2017) Automated Driving Systems 2.0: A Vision for Safety, , https://www.nhtsa.gov/sites/nhtsa.dot.gov/files/documents/13069aads2.0_090617_v9a_tag.pdf, https://perma.cc/G5HK-P7JG; Nguyen, H., Artificial intelligence law is here, part one (2018) Above the Law, , https://abovethelaw.com/legal-innovation-center/2018/07/26/artificialintelligence-law-is-here-part-one/#fl, July 26, 2:22 PM, https://perma.cc/7FQE-4YCU; GM settles first-known suit over self-driving car crash (2018) Medium, , https://medium.com/@marcdgrossman/gm-settles-first-known-suit-over-self-drivingcar-crash-b749db81d32d, June 12, https://perma.cc/ZA34-5B73; Straub, J., Does regulating artificial intelligence save humanity or just stifle innovation? (2017) The Conversation, , https://theconversation.com/does-regulating-artificial-intelligence-save-humanity-or-just-stifle-innovation-85718, Oct. 22, 7:48 PM, https://perma.cc/68EB-XVXS; Hintze, A., What an artificial intelligence researcher fears about AI (2017) The Conversation, , https://theconversation.com/what-an-artificial-intelligence-researcher-fears-about-ai-78655, July 13, 10:51 PM, https://perma.cc/UHQ6-KJV4; Angwin, J., Larson, J., Mattu, S., Kirchner, L., Machine bias (2016) Propublica, , https://www.propublica.org/article/machine-bias-riskassessments-in-criminal-sentencing, May 23, https://perma.cc/BJN9-6G9N; The alien tort statute Part I: What is the ATS? Ctr. For Just. & Accountability, , https://cja.org/what-we-do/litigation/legal-strategy/the-alien-tort-statute/, https://perma.cc/JE84-7ALX last visited Oct. 19, 2019; Kiobel v. Royal Dutch petroleum (2010) F.3d, 621, p. 111. , 145 2d Cir. emphasis added; Kiobel v. Royal Dutch petroleum CO (2013) U.S., 569, p. 108. , 127; Jesner v. Arab Bank, PLC (2018) S. Ct., 138, p. 1386; Quijano, G., Okpabi v Royal Dutch Shell: An opportunity to honour international standards or another instance of corporate impunity? Bus. & Hum. Rts. Res. Ctr., , https://www.business-humanrights.org/en/okpabi-v-royal-dutch-shell-an-opportunityto-honour-international-standards-or-another-instance-of-corporate-impunity, https://perma.cc/7Z77-G8XK last visited Sept. 27,2019; (2013) Bus. & Hum. Rts. Res. Ctr, , https://www.business-hurnanrights.org/en/rana-plaza-building-collapse-april-2013, Rana Plaza building collapse, April https://perma.cc/L8HG-RXJC last visited Jan. 28, 2019; Westervelt, A., Two years after Rana Plaza, have conditions improved in Bangladesh's factories? (2015) Guardian, 6, p. 41. , https://www.theguardian.com/sustainable-business/2015/apr/24/bangladesh-factories-building-collapse-garment-dhaka-rana-plaza-brands-hm-gap-workersconstruction, April 24, PM, https://penna.cc/82MW-KGPU; Yardley, J., Report on deadly factory collapse in Bangladesh finds widespread blame (2013) N.Y. Times, , https://www.nytimes.com/2013/05/23/world/asia/report-on-bangladesh-building-collapse-finds-widespread-blame.html, May 22, https://perma.cc/ UB98-VDJQ; Graham, J., The perils of the precautionary principle: Lessons from the American and European experience (2004) Heritage Found, , https://www.heritage.org/government-regulation/report/the-perils-the-precautionaryprinciple-lessons-the-american-and, Jan. 15, https://perma.cc/3 GXD-GL33; (2013) Wingspread Conference on the Precautionary Principle, Sci. & Envtl. Health Network, , https://sehn.org/wingspread-conference-on-the-precautionary-principle, Aug. 5, https://perma.cc/PT4S-PNHE (last visited Feb. 1,2019) (emphasis added; Weissbrodt, D., Kruger, M., Norms on the responsibilities of transnational corporations and other business enterprises with regard to human rights (2003) Am. J. Int'l L., 97, p. 901. , 903; Raso, F., Hilligoss, H., Krishnamurthy, V., Bavitz, C., Kim, L., (2018) Artificial Intelligence & Human Rights: Opportunities & Risks, 55. , https://cyber.harvard.edu/sites/default/files/2018-09/2018-09_AIHumanRightsSmall.pdf, https://perma.cc/SQZ7-V4F5; West, D.M., The role of corporations in addressing AI's ethical dilemmas (2018) Brookings Inst, , https://www.brookings.edu/research/how-to-address-aiethical-dilemmas/, Sept. 13, https://perma.cc/4JY4-ASJX; Int'l Ct. J., , https://www.icj-cij.org/en/list-of-allcases, generally List of All Cases, https://perma.cc/3XEZ-LL8N last visited Oct. 24, 2019; Verdonck, L., How the European court of human rights evaded the business and human rights debate in Ozel v. Turkey (2016) Tur. Com. L. Rev., 2, p. 111. , 118; World Bank, , http://web.worldbank.org/archive/website00903FAVEB/OTHER/70483401.HTM, https://perma.cc/77SS-3CGN last visited Sept. 11,2019; Projects & Operations, , http://projects.worldbank.org/, https://perma.cc/HS9H-AW2H last visited Sept. 11,2019; (2018) World Bank, Annual Report 2018, pp. 83-84. , http://documents.worldbank.org/curated/en/630671538158537244/pdf7The-World-Bank-Annual-Report-2018.pdf, at https://perma.cc/P86F-FNRN; World Bank, p. 82. , supra note 134, at; (2013) Operational Manual OP 4.12: Involuntary Resettlement, , https://policies.worldbank.org/sites/ppO/PPFDocuments/090224b0822f89db.pdf, rev. https://perma.cc/SVK3-WQXM; Maskey, S., AI for humanity: Using AI to make a positive impact in developing countries (2018) Forbes, , https://www.forbes.com/sites/forbestechcouncil/2018/08/23/ai-for-humanity-using-ai-to-make-a-positive-impact-indeveloping-countries-2/#e694dcc1b08a, Aug. 23, https://perma.cc/AD5H-XB63; Lee, K.-F., Opinion, AI could devastate the developing world (2018) Bloomberg, , https://www.bloomberg.com/opinion/articles/2018-09-17/artificialintelligence-threatens-jobs-in-developing-world, Sept. 17, https://perma.ee/WG6L-KXJA; Bambury, B., Canada is getting its own Magnitsky act and Vladimir Putin is not impressed (2017) CBC Radio, , https://www.cbc.ca/radio/day6/episode-358-outsmarting-the-nra-canada-s-magnitsky-act-ham-radios-for-puerto-rico-music-in-dna-and-more-1.4329733/canada-is-getting-its-own-magnitsky-act-and-vladimir-putin-is-notimpressed-1.4329831, Oct. 6, https://perma.cc/GHW2-CLYS; Forty-four European politicians, OPinion, a magnitsky act for Europe would punish human rights abusers and despots (2018) CNN, , https://www.cnn.com/2018/12/06/opinions/a-magnitsky-act-foreurope-opinion-intl/index.html, Dec. 6, https://perma.cc/99CZ-7BWQ; Treasury sanctions fourteen entities affiliated with corrupt businessman dan Gertler under global magnitsky (2018) U.S. Dep't of the Treasury, , https://home.treasury.gOv/news/press-releases/sm0417thttps://perma.cc/A726-L5MT, June 15; (2014) U.S. Dep't of the Treasury, Revised Guidance on Entities Owned by Persons Whose Property and Interests in Property are Blocked, , https://www.treasury.gov/resource-center/sanctions/Documents/licensing_guidance.pdf, https://perma.cc/WN6M-XNAJ; The U.S. Global magnitsky act: Questions and answers (2017) Human Rights Watch, , https://www.hrw.org/news/2017/09/13/us-global-magnitsky-act, Sept. 13, https://perma.cc/SYB4-CH8M; Baltag, C., Human rights and environmental disputes in international arbitration (2018) Kluwer Arbitration Blog, , http://arbitrationblog.kluwerarbitration.corn/2018/07/24/human-rights-and-environmental-disputes-in-intemational-arbitration/, July 24, https://perma.cc/4GH2-7APE; Henin, P.F., The jurisdiction of investment treaty tribunals over investors' human rights claims: The case against Roussalis v. Romania (2012) Colum. J. Transnat'l L., 51, p. 224. , 226-27; de Brabandere, E., Human rights and international investment law Research Handbook on Foreign Direct Investment, , https://ssrn.com/abstract=3149387, Markus Krajewski & Rhea Hoffmann eds.) (forthcoming) (manuscript at 2, https://penna.cc/4H8F-D7VH; Int'l Chamber of Commerce, , https://iccwbo.org/disputeresolution-services/arbitration/arbitration-clause/, https://perma.cc/CM2W-RES5; (2018) Permanent Mission of Ecuador to the United Nations, Note 4-7-158/2018 to United Nations High Commissioner for Human Rights, , https://www.ohchr.org/Documents/HRBodies/HRCouncilAVGTransCorp/Session3/NoteVerbaleLBI.PDF, July 19, https://perma.cc/P7FL-LVPQ; U.N. Hum. Rts. Council, , https://www.ohchr.org/EN/HRBodies/HRCAVGTransCorp/Session4/Pages/Session4.aspx, Fourth session of the open-ended intergovernmental working group on transnational corporations and other business enterprises with respect to human rights, https://perma.cc/MM8F-28DD hereinafter Fourth Session; Yanes, L.F., A business and human rights treaty: The risks of human rights counter-diplomacy (2018) Opinio Juris, , https://opiniojuris.org/2018/08/09/abusiness-and-human-rights-treaty-the-risks-of-human-rights-counter-diplomacy/, Sept. 8, https://perma.cc/H9GX-BPLE; Lopez, C., Towards an international convention on business and human rights (part I) (2018) Opinio Juris, , https://opiniojuris.org/2018/07/23/towards-aninternational-convention-on-business-and-human-rights-part-i/, July 23, https://perma.cc/9ACP5GRF; On transnational corporations and other business enterprises with respect to human rights, legally binding instrument to regulate (2018) International Human Rights Law, the Activities of Transnational Corporations and Other Business Enterprises Zero Draft, p. 3. , https://www.ohchr.org/documents/hrbodies/hrcouncil/wgtranscorp/session3/draftlbi.pdf, at July 7, https://perma.cc/J9C4-LPUM emphasis added; About Gni, Global Network Initiative, , https://globalnetworkinitiative.org/about-gni/, https://perma.cc/7V7L-3QMM last visited Jan. 15, 2019; Global Network Initiative, p. 2. , https://globalnetworkinitiative.org/govemance-charter/, GNI Governance Charier, at https://perma.cc/9SWL-5NGZ last visited Jan. 15,2019; (2018) Global Network Initiative, GNI Principles on Freedom of Expression and Privacy, p. 1. , https://globalnetworkinitiative.org/wp-content/uploads/2018/04/GNI-Principles-on-Freedom-of-Expression-and-Privacy.pdf, https://perma.cc/ 49U2-DXGG; Liu, H.-Y., Zawieska, K., From responsible robotics towards a human rights regime oriented to the challenges of robotics and artificial intelligence (2017) Ethics & Info. Tech., p. 1. , at 2 2017; Yampolskiy, R.V., Artificial intelligence safety engineering: Why machine ethics is a wrong approach (2013) Philosophy and Theory of Artificial Intelligence, 389, p. 393. , Vincent C. Muller ed; Open Letter to the European Commission Artificial Intelligence and Robots, pp. 2-3. , https://g8fiplkplyr33r3krz5b97dl-wpengine.netdna-ssl.com/wp-content/uploads/2018/04/RoboticsOpenLetter.pdf, Apr. 5, 2018), at https://perma.cc/3VX5-W3HK; (2019) Office for Hum. Res. Protections, U.S. Dep't of Health & Human Servs., International Compilation of Human Research Standards, , https://www.hhs.gov/ohrp/international/compilation-human-research-standards/index.html, https://perma.cc/48NL-8EL5},
document_type={Article},
source={Scopus},
}

@ARTICLE{Broughton2019596,
author={Broughton, V.},
title={The respective roles of intellectual creativity and automation in representing diversity: Human and machine generated bias},
journal={Knowledge Organization},
year={2019},
volume={46},
number={8},
pages={596-606},
doi={10.5771/0943-7444-2019-8-596},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081596639&doi=10.5771%2f0943-7444-2019-8-596&partnerID=40&md5=c0b6754e83719ffd3d204fcdadae518e},
abstract={The paper traces the development of the discussion around ethical issues in artificial intelligence, and considers the way in which humans have affected the knowledge bases used in machine learning The phenomenon of bias or discrimination in machine ethics is seen as inherited from humans, either through the use of biased data or through the semantics inherent in intellectually-built tools sourced by intelligent agents. The kind of biases observed in AI are compared with those identified in the field of knowledge organization, using religious adherents as an example of a community potentially marginalized by bias. A practical demonstration is given of apparent religious prejudice inherited from source material in a large database deployed widely in computational linguistics and automatic indexing Methods to address the problem of bias are discussed, including the modelling of the moral process on neuroscientific understanding of brain function. The question is posed whether it is possible to model religious belief in a similar way, so that robots of the future may have both an ethical and a religious sense and themselves address the problem of prejudice. © 2019 International Society for Knowledge Organization. All rights reserved.},
author_keywords={Artificial intelligence;  Bias;  Data;  Human;  Machine intelligence},
references={Adler, M., Harper, L.M., Race and ethnicity in classification systems: Teaching knowledge or ganization from a social justice perspective (2018) IJbrary Trends, 67 (1), pp. 52-73; Adolphs, R., Cognitive neuroscience of human social behavior (2003) Nature Neuroscience Reviews, 4, pp. 165-178; Albrecht, S.V., Barreto, A.M.S., Braziunas, D., Buckeridge, D.L., Cuayahuitl, H., Dethlefs, N., Reports of the AAAI 2014 conference workshops (2015) Al Magazine, 36, pp. 87-98; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) Al Magazine, 28 (4), pp. 15-26; Anderson, M., Anderson, S.L., Armen, C., Towards machine ethics: Implementing two action-based ethical theories (2005) Machine 'Ethics: Papers from the Aaai Fall Symposium, pp. 1-7. , https://pdfs.semanticscholar.org/B6b/82aOee77c9a870010f9d0335270dla24687.pdf?_ga=2.66400620.357820807.1574389742-1902475365.1566693535, ed. Michael Anderson, Susan Leigh Anderson and Chris Armen. Menlo Park, CA: AAAI Press; Aula, A., Kaki, M., Findex: Improving search result use through automatic filtering categories (2005) Interacting with Computers, 17, pp. 187-206; Bader, C., Demaris, A., A test of the stark-bainbridge theory of affiliation with cults and sects (1996) Journal for the Scientific Study of Religion, 35, pp. 285-303; Bainbridge, W.S., Neural network models of religious belief (1995) Sociological Perspectives, 38, pp. 483-495; Bainbridge, W.S., (2006) God from the Machine: Artificial Intelligence Models of Religious Cognition, , Lanham, MD: Altmira; Barocas, S., Hardt, M., Narayanan, A., (2018) Fairness and Machine Learning: Limitations and Opportunities, , http://www.fairmlbook.org; Bentham, J., (1789) An Introduction to the Principles of Morals and Legislation, , Oxford: Clarendon; Bertrand, M., Mullainathan, S., Are emily and greg more employable than lakisha and jamal? (2004) American Economic Review, 94, pp. 991-1013; Binns, R., Fairness in machine learning: Lessons from political philosophy (2018) Journal of Machine Learning Research, 81, pp. 1-11; Blair, A., (2010) Too Much to Know, , New Haven, CT: Yale University Press; Boyett, J., (2016) 12 Major World Religions: The Beliefs, Rituals, and Traditions of Humanity's Most Influential Faiths, , Berkeley, CA: Zephyros; Brachman, R., Getting back to 'the very idea' (2005) Al Magazine, 26 (4), pp. 48-50; Broughton, V., A new classification for the literature of religion (2000) International Cataloguing and Bibliographic Control, 4, pp. 2-4; Broughton, V., Palfreyman, M., Wilson, A., (2008) Automatic Metadata Generation for Resource Discovery, , http://www.jisc.ac.uk/media/documents/programmes/resourcediscovery/metgenreport_final_v5.doc; Caliskan, A., Bryson, J.J., Narayanan, A., Semantics derived automatically from language corpora contain human-like biases (2017) Science, 356 (6334), pp. 183-186; Cheung, C.F., Lee, W.B., Wang, Y., A multi-facet taxonomy system with applications in unstructured knowledge management (2005) Journal of Knowledge Management, 9 (6), pp. 76-91; Copeland, B.J., Artificial intelligence (2019) Encyclopaedia Britannica, , Accessed April 14; Cranford, K., (2016) Artificial Intelligence's White Guy Problem, , "New York Times. 25 June; Criado-Perez, C., (2019) Invisible Women: Exposing Data Bias in a World Designed for Men, , London: Vintage Digital; Damasio, A., (1994) Descartes' Error: Emotion, Reason and the Human Brain, , New York: Grosset/Putnam; Drabinski, E., Queering the catalog: Queer theory and the politics of correction (2013) Library Quarterly, 83, p. 94; Duarte, M.E., Belarde-Lewis, M., Imagining: Creating spaces for indigenous ontologies (2015) Cataloging and Classification Quarterly, 53 (5-6), pp. 677-702; Dumsday, T., Transhumanism, theological anthropology, and modern biological taxonomy (2017) Zygott: Journal of Religion and Science, 52, pp. 601-622; Field, M., This Japanese robot can host low-cost buddhist funerals (2017) Daily Telegraph, , August 24; Foskett, A.C., Misogynists all: A study in critical classification (1971) Library Resources and Technical Services, 15, pp. 117-121; Fox, M.J., Legal discourse's epistemic interplay with sex and gender classification in the dewey decimal classification system (2016) Library Trends, 64 (4), pp. 687-713; Gorg, C., Liu, Z., Stasko, J., Reflections on the evolution of the jigsaw visual analytics system (2014) Information Visualisation, 13, pp. 336-345; Greenberg, J., Spurgin, K., Crystal, A., (2005) Final Report for the AMeGA (Automatic Metadata Generation Applications Project), , http://www.locgov/catdir/bibcontrol/lc_amega_final_report.pdf; Greenwald, A.G., McGhee, D.E., Schwartz, J.L.K., Measuring individual differences in implicit cognition: The implicit association test (1998) Journal of Personality and Social Psychology, 74, pp. 1464-1480; Hannay, T., The digital academy and augmented intelligence (2014) Information Today, 31, p. 25; Herzfeld, N., Creating in our own image: Artificial intelligence and the image of god (2003) Zygon, 37, pp. 303-316; Hinnells, J., (2017) A New Handbook of Living Religions, , Wiley Online; Howard, S.A., Knowlton, S.A., Browsing through bias: The library of congress classification and subject headings for african American studies and lgbtqia studies (2018) Library Trends, 67 (1), pp. 74-88; Hurwitz, J., Kirsch, D., (2018) Machine Learning for Dummies, , Hoboken, NJ: Wiley; (2019) Data Science and Machine Learning, , https://www.ibm.com/analytics/machine-learning; Khamis, R.Y., Ammari, T., Mikhail, G.W., Gender differences in coronary heart disease (2016) Heart, 102, pp. 1142-1149; Kirchner, J., Angpsin, S., Mattu, J., Larson, I., Machine bias: There's software used across the country to predict future criminals. And it's biased against blacks (2016) ProPublica (Blog), , https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-senfencing, 23 May; Ko, Y., Park, J., Seo, J., Improving text categorization using the importance of sentences (2004) Information Processing and Management, 40, pp. 65-79; Kochi, E., Ai is already learning how to discriminate (2018) Quartz (Blog), , https://qz.com/author/erica-kochi/, March 15; Kozlowski, A.C., Taddy, M., Evans, J.A., The geometry of culture: Analyzing meaning through word embeddings (2019) American Sociological Review, 84 (5), pp. 905-949; Kurzweil, R., (1999) The Age of Spiritual Machines: When Computers Exceed Human Intelligence, , New York: Penguin; Lacey, E., Aliens in the library: The classification of migration (2018) Knowledge Organisation, 45, pp. 358-379; Liang, C.-Y., Guo, L., Xia, Z.-J., Nie, F.-G., Li, X.-X., Su, L., Yang, Z.-Y., Dictionary-based text categorization of chemical web pages (2006) Information Processing and Management, 42, pp. 1017-1029; Liao, S.M., (2016) Moral Brains: The Neuroscience of Morality, , Oxford: Oxford University Press; Mai, J.-E., Classification in a social world: Bias and trust (2010) Journal of Documentation, 66, pp. 627-642; Mai, J.-E., Ethics, values, and morality in contemporary library classifications (2013) Knowledge Organisation, 40, pp. 242-253; Mai, J.-E., (2013) Ethics and Epistemology of Classification, , http://jenserik-mai.info/Papers/2013_EEofClass.pdf, PowerPoint slides for presentation at II Congresso Brasileiro em Organizafao e Representafao do Conhecimento 29 de maio de 2013; Mai, J.-E., Marginalization and exclusion: Unraveling systemic bias in classification (2016) Knowledge Organisation, 43, pp. 324-330; Mancuhan, K., Clifton, C., Combating discrimination using Bayesian networks (2014) Artificial Intelligence Law, 22, pp. 211-238; Marshall, J.K., (1977) On Equal Terms: A Thesaurus for Non-Sexist Indexing and Cataloging, , New York: Neal Schuman; (2019) The Most Popular Muslim App!, , www.muslimpro.com, Muslim Pro; Nosek, B.A., Banaji, M.R., Greenwald, A.G., Harvesting implicit group attitudes and beliefs from a demonstration website (2002) Group Dynamics, 6, pp. 101-115; Nosek, B.A., Banaji, M.R., Greenwald, A.G., Math = Male, Me = Female, therefore math A= Me (2002) Journal of Personality and Social Psychology, 83, pp. 44-59; (2016) Big Data: A Report on Algorithmic Systems, Opportunity, and Civil "rights, , https://obamawhitehouse.archives.gov/sites/default/files/microsites/ostp/2016_0504_data_discrimination.pdf, Obama Whitehouse. Executive Office of the President; Ojala, M., Digital ethics in the stm publishing world (2018) Information Today, 35, pp. 10-11; Olson, H.A., Mapping beyond dewey's boundaries: Constructing classificatory space for marginalized knowledge domains (1998) Ubrary Trends, 47, pp. 233-254; Olson, H.A., (2002) The Power to Name: Locating the IJmits of Subject Representation in Libraries, , Dordrecht: KJuwer; Olson, H.A., How we construct subjects: A feminist analysis (2007) Ubrary Trends, 56 (2), pp. 509-541; Olson, H.A., Ward, D.B., Feminist locales in dewey's landscape: Mapping a marginalized knowledge domain (1997) Knowledge Organisation for Information Retrieval: Proceedings of the Sixth International Study Conference on Information Research, pp. 129-133. , Hague: International Federation for Information and Documentation; Pinnow, E., Herz, N., Loyo-Berrios, N., Tarver, M., Enrollment and monitoring of women in post-approval studies for medical devices mandated by the food and drug administration (2014) Journal of Women's Health, 23 (3); Poole, D., Mackworth, A., Goebel, R., (1998) Computational Intelligence: A Logical Approach, , New York: Oxford University Press; (2010) About WordNet, , https://wordnet.princeton.edu/, Princeton University. ", " WordNet. Princeton University; Quartz, S.R., Reason, emotion and decision-making: Risk and reward computation with feeling (2009) Trends in Cognitive Sciences, 13, pp. 209-215; Rau, A., Should we use a confession app? (2011) Think Christian (Blog), , https://thinkchristian.re-framemedia.com/should-we-use-a-confession-app, February 24; Sawe, B.E., Religious beliefs in Bangladesh (2017) WorldAtlas, , Apr. 25, worldadas.com/articles/re-ligious-beliefs-in-Bangladesh.html; Sears, M., Ai bias and the 'people factor' in ai development (2018) Forbes, , https://www.forbes.com/sites/marksearsl/2018/11/13/ai-bias-and-the-people-factor-in-ai-development/#555088e59134, November 13; Sherwood, H., Robot priest unveiled in Germany to mark 500 years since reformation (2017) Guardian, , https://www.theguardian.com/technology/2017/may/30/robot-priest-blessu-2-germany-reformation-exhibition, May 20; Shoemaker, W.J., The social brain network and human moral behaviour (2012) Zygon: Journal of Religion and Science Ai, pp. 806-820; Smith, M., Patil, D., Muiioz, C., Big risks, big opportunities: The intersection of big data and civil rights (2016) Obama White House (Blog), , https://obamawhitehouse.archives.gov/blog/2016/05/04/big-risks-big-opportunities-intersection-big-data-and-civil-rights, May 4; Stark, R., Bainbridge, W.S., (1987) A Theory of Religion, , New York: David Lang; Szostak, R., Classifying for social diversity (2014) Knowledge Organisation, 41, pp. 160-170; Tatlow, D.K., A robot monk captivates China, mixing spirituality with artificial intelligence (2016) New York Times, , https://www.nytimes.com/2016/04/28/world/asia/china-robot-monk-temple,html, April 27; Vidal, D., Anthropomorphism or sub-anthropomorphism? An anthropological approach to gods and robots (2007) The Journal of the Royal Anthropological Institute, 13, pp. 917-933; (2018) How to Prevent Discriminatory Outcomes in Machine Learning, , http://www3.weforum.org/docs/WEF_40065_White_Paper_How_to_Prevent_Discriminatory_Outcomes_in_Machine_Learning.pdf, World Economic Forum. Global Future Council on Human Rights 2016-2018; Woodward, J., Emotion versus cognition in moral decision-making: A dubious dichotomy (2016) Moral Brains: The Neuroscience of Morality, pp. 87-118. , ed. S. Matthew Liao. Oxford: Oxford University Press},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Gunkel201918,
author={Gunkel, D.},
title={The relational turn: Rethinking ethics in the face of the robot},
journal={2019 AISB Convention},
year={2019},
pages={18-21},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075306945&partnerID=40&md5=5daecc6ed82f848b61e5f706f7a20281},
abstract={The question concerning the moral and/or legal status of others is typically decided on the basis of pre-existing ontological properties, e.g. whether the entity in question possesses consciousness or sentience or has the capacity to experience suffering. In what follows, I contest this standard operating procedure by identifying three philosophical problems with the properties approach (i.e. substantive, terminological, and epistemological complications), and I propose an alternative method for defining and deciding moral status that is more empirical and less speculative in its formulation. This alternative shifts the emphasis from internal, ontological properties to extrinsic social relation-ships, and can, therefore, be called a “relational turn” in robot ethics. © 2019 AISB Convention.All right reserved.},
author_keywords={AI;  Consciousness;  Emmanuel Levinas;  Ethics;  Philosophy;  Robot},
keywords={Artificial intelligence;  Ontology;  Robots, Consciousness;  Emmanuel Levinas;  Ethics;  Legal status;  Philosophy;  Robot ethics;  Social relations;  Standard operating procedures, Philosophical aspects},
references={Cocekelbergh, M., (2013) Growing Moral Relations: Critique of Moral Status Ascription, , New York: Palgrave Macmillan; Kant, I., (1985) Critique of Practical Reason, , Trans. by L. W. Beck. New York: Macmillan; Bentham, J., (2005) An Introduction to the Principles of Morals and Legislation, , Oxford: Oxford University Press; Singer, P., (1975) Animal Liberation: A New Ethics for Our Treatment of Animals, , New York: New York Review of Books; Floridi, L., (2013) The Ethics of Information, , Oxford: Oxford University Press; Himma, K.E., Artificial agency, consciousness, and the criteria for moral agen-cy: What properties must an artificial agent have to be a moral agent? (2009) Ethics and Information Technology, 11 (1), pp. 19-29; Velmans, M., (2000) Understanding Consciousness, , London, UK: Routledge; Benford, G., Malartre, E., (2007) Beyond Human: Living with Robots and Cyborgs, , New York: Tom Doherty; Dennett, D.C., (1998) Brainstorms, , Cambridge, MA: MIT Press; Bates, J., The role of emotion in believable agents (1994) Communications of the ACM, 37, pp. 122-125; Blumberg, B., Todd, P., Maes, M., No bad dogs: Ethological lessons for learn-ing (1996) Proceedings of the 4th International Conference on Simulation of Adaptive Behavior (SAB96), pp. 295-304. , Cambridge, MA: MIT Press; Breazeal, C., Brooks, R., Robot emotion: A functional perspective (2004) Who Needs Emotions: The Brain Meets the Robot, pp. 271-310. , edited by J. M. Fellous and M. Arbib, Oxford: Oxford University Press; Churchland, P.M., (1999) Matter and Consciousness, , Cambridge, MIT Press; Torrance, S., Artificial consciousness and artificial ethics: Between realism and social relationism (2013) Philosophy & Technology, 27 (1), pp. 9-29; Haraway, D.J., (2008) When Species Meet, , Minneapolis, MN: University of Minnesota Press; Gunkel, D.J., (2012) The Machine Question, , Cambridge, MA: MIT Press; Levinas, E., (1969) Totality and Infinity, , Trans. by A. Lingis. Pittsburgh, PA: Duquesne University Press; Reeves, B., Nass, C., (1996) The Media Equation, , Cambridge: Cambridge University Press; Rosenthal-Von Der Pütten, A.M., Krämer, N.C., Hoffmann, L., Sobieraj, S., Eimler, S.C., An experimental study on emotional reactions towards a robot (2013) International Journal of Social Robotics, 5, pp. 17-34; Suzuki, Y., Galli, L., Ikeda, A., Itakura, S., Kitazaki, M., Measuring empathy for human and robot hand pain using electroencephalography (2015) Scientific Reports, 5, p. 15924; Cohen, R.A., (2001) Ethics, Exegesis, and Philosophy: Interpretation after Levinas, , Cambridge: Cambridge University Press; Žižek, S., (2008) For They Know Not What They Do: Enjoyment as a Political Factor, , London: Verso},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Lindner2019216,
author={Lindner, F. and Möllney, K.},
title={Extracting Reasons for Moral Judgments Under Various Ethical Principles},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11793 LNAI},
pages={216-229},
doi={10.1007/978-3-030-30179-8_18},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072863802&doi=10.1007%2f978-3-030-30179-8_18&partnerID=40&md5=4dffcb595f35c422f3332e00c49f44c5},
abstract={We present an approach to the computational extraction of reasons for the sake of explaining moral judgments in the context of an hybrid ethical reasoning agent (HERA). The HERA agent employs logical representations of ethical principles to make judgments about the moral permissibility or impermissibility of actions, and uses the same logical formulae to come up with reasons for these judgments. We motivate the distinction between sufficient reasons, necessary reasons, and necessary parts of sufficient reasons yielding different types of explanations, and we provide algorithms to extract these reasons. © Springer Nature Switzerland AG 2019.},
author_keywords={Explainable AI;  Machine ethics;  Reasons},
keywords={Artificial intelligence, Ethical principles;  Logical formulas;  Logical representations;  Moral judgment;  Reasons, Philosophical aspects},
references={Lindner, F., Bentzen, M.M., The hybrid ethical reasoning agent IMMANUEL (2017) HRI, pp. 187-188. , pp., 2017; Lindner, F., Bentzen, M.M., Nebel, B., The HERA approach to morally competent robots (2017) IROS, pp. 6991-6997. , pp., 2017; Halpern, Y., (2016), Causality. MIT Press, Cambridge; Kuhnert, B., Lindner, F., Bentzen, M.M., Ragni, M., Perceived difficulty of moral dilemmas depends on their causal structure: A formal model and preliminary results (2017) In: Cogsci, 2017, pp. 2494-2499. , pp; Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge University Press, Cambridge; Wachter, S., Mittelstadt, B., Floridi, L., Transparent, explainable, and accountable AI for robotics (2017) Sci. Robot., 2 (6); Mittelstadt, B., Russel, C., Wachter, S., Explaining explanations in AI (2019) FAT*, pp. 279-288. , pp., 2019; Miller, T., Explanation in artificial intelligence: insights from the social sciences (2019) Artif. Intell., 267, pp. 1-38; Mackie, J.L., Causes and conditions (1965) Am. Philos. Q., 12, pp. 245-265; Lewis, D., (1973) Causation. J. Philos., 70, pp. 556-567; Dannenhauer, D., Floyd, M.W., Magazzeni, D., Aha, D.W., Explaining rebel behavior in goal reasoning agents (2018) ICAPS 2018 Workshop on Explainable Planning, pp. 12-18. , pp; Langley, P., Meadows, B., Sridharan, M., Choi, D., Explainable agency for intelligent autonomous systems (2017) Twenty-Ninth Annual Conference on Innovative Applications of Artificial Intelligence, pp. 4762-4763. , pp; Russell, C., Efficient search for diverse coherent explanations (2019) FAT* 2019, pp. 20-28. , pp; Shih, A., Choi, A., Darwiche, A., A symbolic approach to explaining Bayesian network classifiers (2018) IJCAI/ECAI 2018 Workshop on Explainable Artificial Intelligence (XAI), pp. 144-150. , pp; Ignatiev, A., Morgado, A., Marques-Silva, J., PySAT: A Python toolkit for prototyping with SAT oracles (2018) SAT 2018. LNCS, 10929, pp. 428-437. , https://doi.org/10.1007/978-3-319-94144-826, Beyersdorff, O., Wintersteiger, C.M. (eds.), pp., Springer, Cham; Jabbour, S., Marques-Silva, J., Sais, L., Salhi, Y., Enumerating prime implicants of propositional formulae in conjunctive normal form (2014) JELIA 2014. LNCS (LNAI), 8761, pp. 152-165. , https://doi.org/10.1007/978-3-319-11558-011, Fermé, E., Leite, J. (eds.), pp., Springer, Cham; Rosenthal, S., Selvaraj, S.P., Veloso, M., Verbalization: Narration of autonomous robot experience (2016) IJCAI 2016, pp. 862-868. , pp; Baum, K., Hermanns, H., Speith, T., From machine ethics to explainability and back (2018) International Symposium on Artificial Intelligence and Mathematics (ISAIM 2018; Hölldobler, S., Ethical decision making under the weak completion semantics (2018) Proceedings of the Workshop on Bridging the Gap between Human and Automated Reasoning, pp. 1-5. , pp; Pereira, L.M., Saptawijaya, A., (2016) Programming Machine Ethics, , https://doi.org/10.1007/978-3-319-29354-7, Springer, Cham; Shanahan, M., Prediction is deduction but explanation is abduction (1989) IJCAI 1989, pp. 1055-1060. , pp; Borgo, R., Cashmore, M., Magazzeni, D., Towards providing justifications for planner decisions (2018) Proceedings of IJCAI 2018 Workshop on Explainable AI; Previti, A., Ignatiev, A., Morgado, A., Marques-Silva, J., Prime compilation of non-clausal formulae (2015) IJCAI 2015, pp. 1980-1987. , pp; Stocker, M., The schizophrenia of modern ethical theories (1976) J. Philos., 73 (14), pp. 453-466},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Bussmann2019,
author={Bussmann, B. and Heinerman, J. and Lehman, J.},
title={Towards empathic deep q-learning},
journal={CEUR Workshop Proceedings},
year={2019},
volume={2419},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071013649&partnerID=40&md5=bbed63babea47b622b436078cf880e60},
abstract={As reinforcement learning (RL) scales to solve increasingly complex tasks, interest continues to grow in the fields of AI safety and machine ethics. As a contribution to these fields, this paper introduces an extension to Deep Q-Networks (DQNs), called Empathic DQN, that is loosely inspired both by empathy and the golden rule ("Do unto others as you would have them do unto you"). Empathic DQN aims to help mitigate negative side effects to other agents resulting from myopic goal-directed behavior. We assume a setting where a learning agent coexists with other independent agents (who receive unknown rewards), where some types of reward (e.g. negative rewards from physical harm) may generalize across agents. Empathic DQN combines the typical (self-centered) value with the estimated value of other agents, by imagining (by its own standards) the value of it being in the other's situation (by considering constructed states where both agents are swapped). Proof-of-concept results in two gridworld environments highlight the approach's potential to decrease collateral harms. While extending Empathic DQN to complex environments is non-trivial, we believe that this first step highlights the potential of bridge-work between machine ethics and RL to contribute useful priors for norm-abiding RL agents. © 2019 CEUR-WS. All rights reserved.},
keywords={Artificial intelligence;  Complex networks;  Philosophical aspects;  Reinforcement learning, Bridge works;  Complex environments;  Complex task;  Goal-directed behavior;  Independent agents;  Learning agents;  Negative side effects;  Proof of concept, Deep learning},
references={Abbeel, P., Ng, A.Y., Apprenticeship learning via inverse reinforcement learning (2004) Proceedings of the Twenty-first International Conference on Machine Learning, p. 1; Amodei, D., Olah, C., Steinhardt, J., Christiano, P., Schulman, J., Mané, D., (2016) Concrete Problems in Ai Safety, , arXiv preprint arXiv:1606.06565; Anderson, M., Leigh Anderson, S., (2011) Machine Ethics, , Cambridge University Press; Armstrong, S., Levinstein, B., (2017) Low Impact Artificial Intelligences, , arXiv preprint arXiv:1705.10720; Chentanez, N., Barto, A.G., Singh, S.P., Intrinsically motivated reinforcement learning (2005) Advances in Neural Information Processing Systems, pp. 1281-1288; Demski, A., Garrabrant, S., (2019) Embedded Agency, , arXiv preprint arXiv:1902.09469; Everitt, T., Lea, G., Hutter, M., (2018) Agi Safety Literature Review, , arXiv preprint arXiv:1805.01109; Hadfield-Menell, D., Russell, S.J., Abbeel, P., Dragan, A., Cooperative inverse reinforcement learning (2016) Advances in Neural Information Processing Systems, pp. 3909-3917; Hadfield-Menell, D., Milli, S., Abbeel, P., Russell, S.J., Dragan, A., Inverse reward design (2017) Advances in Neural Information Processing Systems, pp. 6765-6774; Ho, J., Ermon, S., Generative adversarial imitation learning (2016) Advances in Neural Information Processing Systems, pp. 4565-4573; Kng, H., Kuschel, K., (1993) Global Ethic: The Declaration of the Parliament of the World's Religions, , Bloomsbury Publishing; Krakovna, V., Orseau, L., Martic, M., Legg, S., (2018) Measuring and Avoiding Side Effects Using Relative Reachability, , arXiv preprint arXiv:1806.01186; Lehman, J., Clune, J., Misevic, D., Adami, C., Altenberg, L., Beaulieu, J., Bentley, P.J., Bryson, D.M., (2018) The Surprising Creativity of Digital Evolution: A Collection of Anecdotes from the Evolutionary Computation and Artificial Life Research Communities, , arXiv preprint arXiv:1803.03453; Leike, J., Krueger, D., Everitt, T., Martic, M., Maini, V., Legg, S., (2018) Scalable Agent Alignment Via Reward Modeling: A Research Direction, , arXiv preprint arXiv:1811.07871; Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Ostrovski, G., Human-level control through deep reinforcement learning (2015) Nature, 518 (7540), p. 529; Panait, L., Luke, S., Cooperative multi-agent learning: The state of the art (2005) Autonomous Agents and Multiagent Systems, 11 (3), pp. 387-434; Raileanu, R., Denton, E., Szlam, A., Fergus, R., (2018) Modeling Others Using Oneself in Multi-agent Reinforcement Learning, , arXiv preprint arXiv:1802.09640; Saunders, W., Sastry, G., Stuhlmueller, A., Evans, O., Trial without error: Towards safe reinforcement learning via human intervention (2018) Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems, pp. 2067-2069. , International Foundation for Autonomous Agents and Multiagent Systems; Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., Van Den Driessche, G., Schrittwieser, J., Lanctot, M., Mastering the game of go with deep neural networks and tree search (2016) Nature, 529 (7587), p. 484; Stadie, B.C., Abbeel, P., Sutskever, I., (2017) Third-person Imitation Learning, , arXiv preprint arXiv:1703.01703; Sutton, R.S., Barto, A.G., (1998) Introduction to Reinforcement Learning, 135. , MIT press Cambridge; Price Tangney, J., Stuewig, J., Mashek, D.J., Moral emotions and moral behavior (2007) Annu. Rev. Psychol., 58, pp. 345-372; Matt Turner, A., Hadfield-Menell, D., Tadepalli, P., (2019) Conservative Agency Via Attainable Utility Preservation, , arXiv preprint arXiv:1902.09725; Wallach, W., Allen, C., (2008) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press; Winfield, A.F.T., Blum, C., Liu, W., Towards an ethical robot: Internal models, consequences and ethical action selection (2014) Conference towards Autonomous Robotic Systems, pp. 85-96. , Springer},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Hunyadi201959,
author={Hunyadi, M.},
title={Artificial moral agents. Really?},
journal={Springer Tracts in Advanced Robotics},
year={2019},
volume={130},
pages={59-69},
doi={10.1007/978-3-030-17974-8_5},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070742050&doi=10.1007%2f978-3-030-17974-8_5&partnerID=40&md5=5440bb7082a0ce0aa86dd8ef5d6c50d6},
abstract={How can we plausibly refer to robots as artificial moral agents? Considering the useful classification of the philosopher of the field of artificial intelligence James H. Moor, who identified four different kinds of ethical, I will argue that the term of artificial moral agent is philosophically illegitimate. My argumentation is developed in three stages: the first stage addresses the actual choice of the ethical principles to be programmed into the machine; the second stage explores the difficulties inherent in giving these principles an algorithmic form; and the third focuses on the supreme difficulty arising from the very nature of moral reasoning. This analysis aims at encouraging the research on the concepts of moral reasoning and judgement. Indeed, a fine understanding of these notions should reveal the full extent of the problem with artificial moral agents; before we can discuss machine ethics or artificial ethics, we must, if we are to avoid speculation and ideology, have a clear understanding of what ethics is, what type of rationality it implements, and what is the nature of ethics and ethical conduct in general. © Springer Nature Switzerland AG 2019.},
author_keywords={Agent;  Artificial;  Ethics;  Moore;  Moral},
keywords={Agents;  Behavioral research;  Mooring;  Robotics, Artificial;  Ethical principles;  Ethics;  Moral;  Moral agents;  Moral reasoning, Philosophical aspects},
references={Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intell. Syst., 21 (4), pp. 18-21; Moor, J.H., Four kinds of ethical robots (2009) Philosophy Now, 72, pp. 12-14; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford University Press, Oxford; Anderson, M., Anderson, S., Machine ethics: Creating an ethical intelligent agent (2007) AI Mag, 28 (4), pp. 15-26; Hunyadi, M., (2012) : L’Homme En Contexte, , Cerf, Paris; Laumond, J.-P., Interview; La méthode Scientifique, , France Culture radio, 14 June 2017},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Rowthorn20199,
author={Rowthorn, M.},
title={How should autonomous vehicles make moral decisions? Machine ethics, artificial driving intelligence, and crash algorithms},
journal={Contemporary Readings in Law and Social Justice},
year={2019},
volume={11},
number={1},
pages={9-14},
doi={10.22381/CRLSJ11120191},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070408924&doi=10.22381%2fCRLSJ11120191&partnerID=40&md5=e092dbf717b9fd59aef0d43b330b3aae},
abstract={This research investigates the relationship between machine ethics, artificial driving intelligence, and crash algorithms. Building my argument by drawing on data collected from AUVSI, Ipsos, Nature, Pew Research Center, Perkins Coie, Statista, and YouGov, I performed analyses and made estimates regarding U.S. adults who say they would/would not want to ride in a driverless vehicle (%), statements closest to international drivers’ opinion (I am in favor of self-driving cars and cannot wait to use them/I am unsure about self-driving cars, but I find the idea interesting/I am against self-driving cars and would never use them), U.S. adults that would feel (un)safe as a pedestrian in a city with self-driving cars (%), countries that are most prepared for autonomous vehicles (policy and legislation, technology and innovation, infrastructure, and consumer acceptance), and the top data infrastructure requirements in smart cities to facilitate autonomous vehicle testing (wireless connectivity to other cars, parking meters, traffic lights and other smart infrastructure, wireless connectivity to nearby towers/antennas, and data centers to perform analytics on large volumes of data received from vehicles). The data for this research were gathered via an online survey questionnaire and were analyzed through structural equation modeling on a sample of 5,400 respondents. © 2019, Addleton Academic Publishers. All rights reserved.},
author_keywords={Artificial driving intelligence;  Autonomous vehicle;  Crash algorithm;  Moral decision},
references={Carter, S., Yeo, A.C.-M., Internet-enabled Collective Intelligence as a Precursor and Predictor of Consumer Behaviour (2018) Economics, Management, and Financial Markets, 13 (4), pp. 11-38; Chessell, D., The Jobless Economy in a Post-Work Society: How Automation Will Transform the Labor Market (2018) Psychosociological Issues in Human Resource Management, 6 (2), pp. 74-79; Coca-Vila, I., Self-driving Cars in Dilemmatic Situations: An Approach Based on the Theory of Justification in Criminal Law (2018) Criminal Law and Philosophy, 12 (1), pp. 59-82; Cowger, A.R., Jr., Liability Considerations when Autonomous Vehicles Choose the Accident Victim (2018) Journal of High Technology Law, 19 (1), pp. 1-60; Jouët, J., Digital Feminism: Questioning the Renewal of Activism (2018) Journal of Research in Gender Studies, 8 (1), pp. 133-157; Hübner, D., White, L., Crash Algorithms for Autonomous Cars: How the Trolley Problem Can Move Us Beyond Harm Minimisation (2018) Ethical Theory and Moral Practice, 21 (3), pp. 685-698; Katz, L., Dark Dreams and Malign Creativity (2018) Knowledge Cultures, 6 (2), pp. 64-75; Kaur, K., Rampersad, G., Trust in Driverless Cars: Investigating Key Factors Influencing the Adoption of Driverless Cars (2018) Journal of Engineering and Technology Management, 48, pp. 87-96; Lăzăroiu, G., Postmodernism as an Epistemological Phenomenon (2018) Educational Philosophy and Theory, 50 (14), pp. 1389-1390; Lukasik, Z., Kusminska-Fijalkowska, A., Kozyra, J., Olszanska, S., Evolution of Costs in the Activity of a Transport Company Operating within the European Union (2017) Ekonomicko-Manazerske Spektrum, 11 (2), pp. 53-63; Moser, K., Michel Serres’s Encyclopedic Philosophical Vision of an Ever-Changing Human Landscape (2017) Review of Contemporary Philosophy, 16, pp. 11-37; Nica, E., Will Robots Take the Jobs of Human Workers? Disruptive Technologies that May Bring About Jobless Growth and Enduring Mass Unemployment (2018) Psychosociological Issues in Human Resource Management, 6 (2), pp. 56-61; Nyholm, S., Smids, J., Automated Cars Meet Human Drivers: Responsible Human-Robot Coordination and the Ethics of Mixed Traffic (2018) Ethics and Information Technology; Pilkington, O.A., Presented Discourse in Popular Science Narratives of Discovery: Communicative Side of Thought Presentation (2018) Linguistic and Philosophical Investigations, 17, pp. 7-28; Popescu Ljungholm, D., Sharing Economy, Regulatory Arbitrage, and Urban Governance: How City Space Shapes Economic Growth and Innovation (2018) Geopolitics, History, and International Relations, 10 (1), pp. 174-180; Popescu, G.H., Has Postmodernism the Potential to Reshape Educational Research and Practice? (2018) Educational Philosophy and Theory, 50 (14), pp. 1490-1491; Smith, A., Stirling, A., Innovation, Sustainability and Democracy: An Analysis of Grassroots Contributions (2018) Journal of Self-Governance and Management Economics, 6 (1), pp. 64-97; Taeihagh, A., Lim, H.S.M., Governing Autonomous Vehicles: Emerging Responses for Safety, Liability, Privacy, Cybersecurity, and Industry Risks (2019) Transport Reviews, 39 (1), pp. 103-128},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kim2019319,
author={Kim, W. and Lee, K.},
title={A Data-Driven Strategic Model of Common Sense in Machine Ethics of Cares},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11566 LNCS},
pages={319-329},
doi={10.1007/978-3-030-22646-6_23},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069715108&doi=10.1007%2f978-3-030-22646-6_23&partnerID=40&md5=926dcedf777a24cd1c663408ab5e0ed1},
abstract={When adopting artificial intelligence in organizations, we face machine behaviors that are problematic ethically. Tay, a chatter robot in Twitter, learned what and how to speak from twitter users without having ethical common sense. Eventually, Tay was shut down after it tweeted segregative and violent words to people. Besides, Amazon’s AI recruit system showed a sexist behavior that it preferred male than female candidates. The present studies focus on how to apply the ethics of justice to artificial intelligence by feeding data on standards and rules in our society. However, we claim that the ethics of cares is also necessary to have artificial intelligence in our daily life. While one-way data is necessary in the ethics of justice, two-way data is required in the ethics of cares. Namely, one learns how to care others by having feedback from others after taking an action. The one learns if the action is offensive to others or not. © 2019, Springer Nature Switzerland AG.},
author_keywords={Artificial intelligence;  Chat bot;  Data-driven design;  Ethics},
keywords={Artificial intelligence;  Philosophical aspects;  Social networking (online), Chat bots;  Common sense;  Daily lives;  Data driven;  Data-driven design;  Ethics;  Machine behavior;  Strategic modeling, Human computer interaction},
references={ARM Ltd[Gb], , https://pages.arm.com/rs/312-SAX-488/images/arm-ai-survey-report.pdf, Accessed 15 Feb 2019; Cambria, E., Olsher, D., Rajagopal, D., SenticNet 3: A common and common-sense knowledge base for cognition-driven sentiment analysis (2014) Twenty-Eighth AAAI Conference on Artificial Intelligence; Cambria, E., SenticNet 5: Discovering conceptual primitives for sentiment analysis by means of context embeddings (2018) Thirty-Second AAAI Conference on Artificial Intelligence; CNBC Elon Musk: ‘Mark My Words – A.I is Far More Dangerous than nukes’, , https://www.cnbc.com/2018/03/13/elon-musk-at-sxsw-a-i-is-more-dangerous-than-nuclear-weapons.html, Accessed 15 Feb 2019; Colah’s Blog Understanding LSTM Networks, , http://colah.github.io/posts/2015-08-Understanding-LSTMs/, Accessed 15 Feb 2019; Dezeen MIT Surveys Two Million People to Set out Ethical Framework for Driverless Cars, , https://www.dezeen.com/2018/10/26/mit-moral-machine-survey-driverless-cars-technology/, Accessed 15 Dec 2019; Ethic Sages Common Sense Ethics, , https://www.ethicssage.com/2016/11/common-sense-ethics.html, Accessed 15 Feb 2019; Forbes Google’s Mysterious AI Ethics Board Should Be Transparent like Axon’s, , https://www.forbes.com/sites/samshead/2018/04/27/googles-mysterious-ai-ethics-board-should-be-as-transparent-as-axons/#7fb25ccd19d1, Accessed 15 Feb 2019; Gilligan, C., (1982) In a Different Voice, , Harvard University Press, Cambridge; Kensinger, E.A., Negative emotion enhances memory accuracy: Behavioral and neuroimaging evidence (2007) Curr. Dir. Psychol. Sci., 16 (4), pp. 213-218; Keras: The Python Deep Learning Library, , https://keras.io/, Accessed 15 Feb 2019; Large Movie Review Data Set, , http://ai.stanford.edu/~amaas/data/sentiment/, Accessed 15 Feb 2019; Machine Learning Mastery, Brownlee Jason, , https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/, Accessed 28 Feb 2019; Reddit I’m Bill Gates, co-chair of the Bill & Melinda Gates Foundation Ask Me Anything, , https://www.reddit.com/r/IAmA/comments/5whpqs/im_bill_gates_cochair_of_the_bill_melinda_gates/, Accessed 15 Feb 2019; Simola, S., Ethics of justice and care in corporate crisis management (2003) J. Bus. Ethics, 46 (4), pp. 351-361; https://github.com/taspinar/twitterscraper, taspinar/twitterscraper, Accessed 15 Feb 2019; Textblob Simplified Text Processing, , https://textblob.readthedocs.io/en/dev/, Accessed 15 Feb 2019; TIME Would You Kill One Person to save Five? New Research on a Classic Debate, , http://healthland.time.com/2011/12/05/would-you-kill-one-person-to-save-five-new-research-on-a-classic-debate/, Accessed 15 Feb 2019; Tronto, J., (2001) An Ethic of Care. Ethics in Community-Based Elder Care, pp. 60-68. , pp; Walker, L.J., Sex differences in the development of moral reasoning: A critical review (1984) Child Dev, 55, pp. 677-691},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2019,
title={Thematic Area on Human Computer Interaction, HCI 2019, held as part of the 21st International Conference on Human-Computer Interaction, HCI International 2019},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2019},
volume={11566 LNCS},
page_count={1666},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069666623&partnerID=40&md5=d5eb8ae280cfa06999c5ac9041191817},
abstract={The proceedings contain 125 papers. The special focus in this conference is on Thematic Area on Human Computer Interaction. The topics include: Examining Social Desirability Bias in Online and Offline Surveys; Can UX Over Time Be Reliably Evaluated? - Verifying the Reliability of ERM; a Set of Usability Heuristics for Mobile Applications; characterizing End-User Development Solutions: A Systematic Literature Review; towards a Set of Design Guidelines for Multi-device Experience; gameful Design Heuristics: A Gamification Inspection Tool; a New Method of Banner Color Design; supporting Life History Research with Interactive Visualizations; towards the Ontology of Becoming in Self-tracking Research; interactive Search Profiles as a Design Tool; Do Humans STILL Have a Monopoly on Creativity or Is Creativity Overrated?; the Effects of Robot Voice and Gesture Types on the Perceived Robot Personalities; Preliminary Evaluation Between Conscious Feeling and Unconscious Emotion Estimated by Bio-Signals Applied to CMC Comparison; a Data-Driven Strategic Model of Common Sense in Machine Ethics of Cares; how Do Humans Identify Human-Likeness from Online Text-Based Q&A Communication?; influence of Presence of Operator of Humanoid Robot on Personal Space; redefining Audience Role in Live Performances; a Cross-Cultural Comparison of Perceptions of Cuteness and Kawaii Between American and Japanese College Students; emotional Design for Children’s Electronic Picture Book; design Criteria for Kansei-Oriented Elderly Products; Trends and Changes in the Field of HCI the Last Decade from the Perspective of HCII Conference; research on Chemical Experimental Instrument Design Mode Based on Kansei Engineering; a Study in Elderly Fashion and Zero Waste Clothing Design.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Sivaraj201936,
author={Sivaraj, S. and Yilmaz, L.},
title={Cogent: A coherence-driven cognitive agent modelling and experimentation framework},
journal={International Journal of Simulation and Process Modelling},
year={2019},
volume={14},
number={1},
pages={36-50},
doi={10.1504/IJSPM.2019.097707},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061299669&doi=10.1504%2fIJSPM.2019.097707&partnerID=40&md5=ee3b550097ca2d2a0d316e35168b0b5e},
abstract={Most agent modelling and simulation languages lack high-level syntactic features necessary for cognitive modelling. In this paper, we present Cogent, an interactive coherence-driven agent specification and simulation platform and demonstrate its use in ethical decision making. The underlying strategy is based on the concept of a connectionist, interactive activation model that implements the theory of coherence. Agents in the Cogent language are specified by a domain-specific language (DSL). The DSL provides the syntax for specifying the decision-making strategy along with its cognitive coherence model. The framework also provides the ability to model complex hierarchical cognitive network structures. To illustrate the utility of Cogent, we explore a machine ethics case study. Copyright © 2019 Inderscience Enterprises Ltd.},
author_keywords={Cognitive agent;  Cognitive computing;  Coherence;  Domain-specific language;  DSL;  Ethical decision making},
keywords={Coherent light;  Computation theory;  Computer aided software engineering;  Computer simulation languages;  Decision making;  Digital subscriber lines;  DSL;  Intelligent agents;  Philosophical aspects;  Problem oriented languages;  Simulation platform;  Syntactics, Agent specification;  Cognitive agents;  Cognitive Computing;  Cognitive modelling;  Decision-making strategies;  Domain specific languages;  Ethical decision making;  Interactive activation, Modeling languages},
references={Abar, S., Theodoropoulos, G., Lemarinier, P., O'Hare, G., (2017) Agent-Based Modelling and Simulation Tools: A Review of the State-of-Art Software, , ELSEVIER; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) IEEE Intelligent Systems, 21 (4), pp. 12-17; Anderson, J., Bothell, D., Byrne, M., Douglass, S., Lebiere, C., Qin, Y., Mason: A multi-agent simulation environment (2005) Society for Modeling and Simulation International; Arkoudas, K., Bringsjord, S., Bello, P., Toward ethical robots via mechanized deontic logic (2005) AAAI Fall Symposium on Machine Ethics, pp. 17-23; Bézivin, J., Gerbé, O., Towards a precise definition of the omg/mda framework (2001) Proceedings 16th Annual International Conference on Automated Software Engineering, (ASE 2001), pp. 273-280. , IEEE; Bellifemine, F., Poggi, A., Rimassa, G., Jade - A fipa-compliant agent framework (1999) Fourth International Conference on Practical Application of Intelligent Agents and Multi-Agent Technology; Braubach, L., Lamersdorf, W., Pokahr, A., (2003) Jadex: Implementing a BDI-Infrastructure for Jade Agents, 3 (3), pp. 76-85. , exp, September; Collier, N., (2003) RePast: An Extensible Framework for Agent Simulation, , Social Science Research Computing University of Chicago; Foundation for Intelligent Physical Agents, Specifications, , http://www.fipa.org, online accessed 15 August 2018; Franklin, S., Patterson, F., Jr., The lida architecture: Adding new modes of learning to an intelligent, autonomous, software agent (2006) PAT, 703, pp. 764-1004; Gips, J., Towards the ethical robot (1995) Android Epistemology, pp. 243-252; Grogan, A., Driverless trains: It's the automatic choice (2012) Engineering and Technology, 7 (5), pp. 54-57; Kieras, D.E., Meyer, D.E., (1994) The Epic Architecture for Modeling Human Information-Processing and Performance: A Brief Introduction, , Michigan Univ Ann Arbor Div of Research Development and Administration, Tech. Rep; Laird, J., (2012) The Soar Cognitive Architecture, , MIT Press; Laird, J.E., Extending the soar cognitive architecture (2008) Frontiers in Artificial Intelligence and Applications, 18, pp. 171-224. , February; Langley, P., Choi, D., A unified cognitive architecture for physical agents (2006) Proceedings of the National Conference on Artificial Intelligence, 21 (2), p. 1469. , AAAI Press, MIT Press, 1999, 2006, Menlo Park, CA, Cambridge, MA, London; Liddle, S.W., Model-driven software development (2011) Handbook of Conceptual Modeling, pp. 17-54. , Springer, Berlin, Heidelberg; Luke, S., Cioffi-Revilla, C., Panait, L., Sullivan, K., Balan, G., Mason: A multi-agent simulation environment (2005) Society for Modeling and Simulation International; Minar, N., Burkhart, R., Langton, C., Askenazi, M., (1996) The Swarm Simulation System: A Toolkit for Building Multi-Agent Simulations, pp. 96-106. , Technical report,. Sante Fe Institute; North, M.J., Collier, N.T., Ozik, J., Tatara, E.R., Macal, C.M., Bragen, M., Sydelko, P., Complex adaptive systems modeling with repast simphony (2013) Complex Adaptive Systems Modeling, 1 (1), p. 3. , March; Ozik, J., Collier, N., Murphy, J., North, M., The relogo agent-based modeling language (2013) Winter Simulation Conference; Papert, S., (1980) Mindstorms: Children, Computers, and Powerful Ideas, , 1 January, Basic Books, Inc., New York, NY; Railsback, S., Lytinen, S., Jackson, S., Agent-based simulation platforms: Review and development recommendations (2006) Society for Modeling and Simulation International; Resnick, M., Starlogo: An environment for decentralized modeling and decentralized thinking (1996) Conference Companion on Human Factors in Computing Systems, pp. 11-12. , ACM; Ron, S., The clarion cognitive architecture: Extending cognitive modeling to social simulation (2005) Cognition and Multi-Agent Interaction, , Ron, S. Ed: chapter 4, Cambridge University Press, New York; Rosbe, J., Chong, R.S., Kieras, D.E., (2001) Modeling with Perceptual and Memory Constraints: An Epic-Soar Model of a Simplified Enroute Air Traffic Control Task, , Tech. rep., SOAR Technology Inc., Ann Arbor, MI; Schmidt, D.C., Model-driven engineering (2006) IEEE Computer Society Computer, 39 (2), p. 25; Thagard, P., (2000) Coherence in Thought and Action, , MIT Press, Cambridge, MA, USA; Thomson, J.J., The trolley problem (1985) The Yale Law Journal, 94 (6), pp. 1395-1415; Tisue, S., Wilensky, U., Netlogo: A simple environment for modeling complexity (2004) International Conference on Complex Systems; Tobias, R., Hofmann, C., Evaluation of free Java-libraries for social-scientific agent based simulation (2004) Journal of Artificial Societies and Social Simulation, 7 (1). , http://jasss.soc.surrey.ac.uk/7/1/6.html, online; Völter, M., Stahl, T., Bettin, J., Haase, A., Helsen, S., (2013) Model-Driven Software Development: Technology, Engineering, Management, , John Wiley and Sons, Heidelberg, Germany; Warnke, T., Reinhardt, O., Klabunde, A., Willekens, F., Uhrmacher, A.M., Modelling and simulating decision processes of linked lives: An approach based on concurrent processes and stochastic race (2017) Population Studies, 71, pp. 69-83; Yilmaz, L., Franco-Watkins, A., Timothy, S.K., Coherence-driven reflective equilibrium model of ethical decision-making (2016) CogSIMA},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bassetti2019,
author={Bassetti, T. and Luvison, A.},
title={Apology of scientific reason - IV: Dilemmas of choice and ethics of artificial intelligence (AI) [Apologia della ragione scientifica - IV: Dilemmi di scelta ed etica dell'IA]},
journal={Mondo Digitale},
year={2019},
volume={18},
number={82},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049873059&partnerID=40&md5=2cf967359b8872e31275f75c58b693dd},
abstract={Science and technology are two major drivers for development in the most advanced countries. Methodologically, critical thinking, motivated reasoning and cognitive reflection provide the conceptual framework and operational toolbox for decision making under uncertainty. The inherent limits (i.e., biases) of human bounded rationality can be overcome, so that scientific rationality is enhanced even more. Two cases are discussed to support this assumption. The first is the Newcomb's paradox, a logical and philosophical thought experiment entailing a game between two players, one of whom claims to be able to predict the future. The solution to this brainteaser is based on elementary algebra involving simple probabilities. By starting from the trolley problem, the focus of the second case is on ethical issues of artificial intelligence (AI), e.g., autonomous systems, such as driverless cars, or other disruptive and pervasive AI applications. Here, the term accountability applies to a designer who considers the question of how intelligent systems should be imbued with ethical values. The underlying argument is that the two cultures - humanities and techno-science - thanks to the many intersection and cross-fertilization points, are both faces of the same coin, i.e., interdisciplinary knowledge. This type of knowledge should belong to the education and training background of any leader, executive, or opinion maker, responsible for facing the incumbent challenges of the digital society. © 2019 Associazione Italiana per l'Informatica e il Calcolo Automatico. All rights reserved.},
author_keywords={AI and machine ethics;  Critical decision making;  Logical conundrums;  Newcomb's paradox revisited;  Science and humanities;  Trolley problem},
keywords={Behavioral research;  Decision making;  Decision support systems;  Intelligent systems, Decision making under uncertainty;  Education and training;  Logical conundrums;  Newcomb's paradox revisited;  Science and humanities;  Science and Technology;  Scientific rationalities;  Trolley problem, Philosophical aspects},
references={Tomasin, L., La tecnologia salverà le lingue? (2018) Domenica-Il Sole 24 Ore, 96, p. 23. , 8 aprile; Barone, V., (2016) Albert Einstein. Il Costruttore di Universi, , Laterza; Harris, J., Il mondo salvato dai robot (2017) Domenica-Il Sole 24 Ore, 167 (25), p. 27. , giugno; Luvison, A., Apologia della ragione scientifica (2013) Mondo Digitale - Rassegna Critica Del Settore ICT, 45, pp. 1-28. , http://mondodigitale.aicanet.net/2013-1/articoli/05_LUVISON.pdf, (marzo), (ultimo accesso marzo 2019); Luvison, A., Apologia della ragione scientifica - II: Strumenti per decidere (2014) Mondo Digitale - Rassegna Critica Del Settore ICT, 55, pp. 1-31. , http://mondodigitale.aicanet.net/2014-7/articoli/03_Apologia_della_ragione_scientifica_II.pdf, (dicembre), (ultimo accesso marzo 2019); Bassetti, T., Luvison, A., Apologia della ragione scientifica - III: Decisioni e giochi strategici (2018) Mondo Digitale - Rassegna Critica Del Settore ICT, 76, pp. 1-30. , http://mondodigitale.aicanet.net/2018-3/Articoli/MD76_01_Apologia_della_ragione_scientifica-III.pdf, (maggio), (ultimo accesso marzo 2019); Kahneman, D., (2012) Pensieri Lenti e Veloci, , Mondadori; Lewis, M., (2017) Un'Amicizia da Nobel. Kahneman e Tversky, l'Incontro Che Ha Cambiato Il Nostro Modo di Pensare, , Raffaello Cortina Editore; Thaler, R.H., (2018) Misbehaving. La Nascita dell'Economia Comportamentale, , Einaudi; Hagstrom, R.G., (2014) Il Metodo Warren Buffett. I Segreti Del Più Grande Investitore Del Mondo, , 3a edizione, Hoepli; Stanovich, K.E., (2009) What Intelligence Tests Miss: The Psychology of Rational Thought, , Yale University Press; Rosenhouse, J., (2009) The Monty Hall Problem: The Remarkable Study of Math's Most Contentious Brain Teaser, , Oxford University Press; Herbranson, W.T., Schroeder, T., Are birds smarter than mathematicians? Pigeons (Columbia livia) perform optimally on a version of the monty hall dilemma (2010) Journal of Comparative Psychology, 1, pp. 1-13. , https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3086893/, (febbraio), (ultimo accesso marzo 2019); Nozick, R., Newcomb's problem and two principles of choice (1969) Essays in Honor of Carl G. Hempel: A Tribute on the Occasion of His Sixty-Fifth Birthday, pp. 114-146. , Rescher, N., et al. (a cura di), D. Reidel Publishing Company; Gardner, M., Mathematical games. Free will revisited with a mindbending paradox by william newcomb (1973) Scientific American, 1, pp. 104-109. , (luglio), Tr. it. (1974). "Giochi matematici. Ancora sul libero arbitrio, con un affascinante paradosso di William Newcomb", Le Scienze, 65 (gennaio), 100-104; Nozick, R., Mathematical games. Reflections on Newcomb's problem: A prediction and free-will dilemma (1974) Scientific American, 3, pp. 102-108. , (marzo), Tr. it. (1974). "Giochi matematici. Riflessioni sul paradosso di Newcomb: un dilemma sulla predizione e il libero arbitrio", Le Scienze, 72 (agosto), 106-111; Gardner, M., Newcomb's paradox (2001) The Colossal Book of Mathematics, pp. 580-591. , W. W. Norton & Company; Rasetti, M., (2019) Big Data, Scienza Dei Dati, Intelligenza Artificiale: Sfide, Prospettive, Sogni e Pericoli, , https://www.youtube.com/watch?v=E3jmwD_sjsM, relazione al Convegno "Saperi e metodologie a confronto", Accademia delle Scienze di Torino, 22 gennaio, (ultimo accesso marzo 2019); Luvison, A., L'ecosistema dell'innovazione digitale: Analisi critica (2017) AEIT, 3 (4), pp. 6-27. , http://www.aeit.it/aeit/edicola/aeit/aeit2017/aeit2017_02_cisa/aeit2017_02_riv.pdf, (marzo/aprile), (ultimo accesso marzo 2019); Wildberger, N.J., (2013) Famous Math Problems 7: Newcomb's Paradox, , https://www.youtube.com/watch?v=aR5GYeZkgvY, 19 febbraio, (ultimo accesso marzo 2019); Gallucci, M., (2007) Paradosso di Newcomb e Dilemma Del Prigioniero: Quando Il Problema Non è la Scelta da Compiere, Bensì la Teoria in Cui Credere, , https://core.ac.uk/download/pdf/14695341.pdf, Tesi di laurea specialistica in Scienze economiche (anno accademico 2006-2007), Università di Pisa, (ultimo accesso marzo 2019); Wilson, H.J., Daugherty, P.R., Collaborative intelligence: Humans and AI are joining forces (2018) Harvard Business Review, 4, pp. 114-123. , luglio-agosto; Davenport, T.H., (2018) The AI Advantage: How to Put the Artificial Intelligence to Work, , The MIT Press; Luvison, A., La società e l'ecosistema digitale (2019) Immagini Del Digitale. Dopo Il Bit Bang, , Pozzi, P. (a cura di), Nemapress Edizioni, in corso di stampa; Special report: Can We copy the brain? (2017) IEEE Spectrum, 6. , https://spectrum.ieee.org/static/special-report-can-we-copy-thebrain, AA. VV. (giugno), (ultimo accesso marzo 2019); Bryson, B., Persi a cyberlandia (2017) Notizie da un Grande Paese, pp. 315-319. , Guanda; Anderson, C., (2008) La Coda Lunga. Da un Mercato di Massa A Una Massa di Mercati, , Codice Edizioni; Levesque, H.J., (2018) Common Sense, the Turing Test, and the Quest for Real AI, , The MIT Press; Edmonds, D., (2014) Uccideresti l'Uomo Grasso? Il Dilemma Etico Del Male Minore, , Raffaello Cortina Editore; Awad, E., The moral machine experiment (2018) Nature, 563, pp. 59-64. , https://www.nature.com/articles/s41586-018-0637-6.pdf, (1 novembre), (ultimo accesso marzo 2019); Hao, K., Should a self-driving car kill the baby or the grandma? Depends where you're from (2018) MIT Technology Review, , https://www.technologyreview.com/s/612341/a-global-ethics-study-aims-to-help-aisolve-the-self-driving-trolley-problem/, 24 ottobre, (ultimo accesso marzo 2019); Floridi, L., (2017) L'Intelligenza Artificiale. Cosa Cambierà Nella Nostra Società e Nella Nostra Vita, , https://www.fondazionescuola.it/costruire-futuro/intelligenza-artificiale, 14 novembre, Politecnico di Torino, (ultimo accesso marzo 2019); Dossier Intelligenza artificiale - Auto senza guidatore (2016) Le Scienze, 576, pp. 38-55. , AA. VV. (agosto); Special issue: Machine law (2017) Artificial Intelligence and Law, 3, pp. 251-378. , https://www.springerprofessional.de/en/artificialintelligence-and-law-3-2017/15085774, AA. VV. (settembre), (ultimo accesso marzo 2019); Special issue: Machine ethics: The design and governance of ethical AI and autonomous systems (2019) Proceedings of the IEEE, p. 3. , AA. VV. (marzo); Trussell, H.J., Point of view: Why a special issue on machine ethics (2018) Proceedings of the IEEE, 10, pp. 1774-1778. , https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8472909, (ottobre), (ultimo accesso marzo 2019); Bonnefon, J.-F., Shariff, A., Rawhan, I., Point of view: The trolley, the bull bar, and why engineers should care about the ethics of autonomous cars (2019) Proceedings of the IEEE, 3, pp. 502-504. , https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8662742, (marzo), (ultimo accesso marzo 2019); (2018) Draft Ethics Guidelines for Trustworthy AI: Working Document for Stakeholders' Consultation, , https://ec.europa.eu/digital-single-market/en/news/draft-ethics-guidelines-trustworthy-ai, 18 dicembre, (ultimo accesso marzo 2019); Floridi, L., AI4People - An ethical framework for good AI society: Opportunities, risks, principles, and recommendations (2018) Minds and Machines, 4, pp. 689-707. , https://link.springer.com/content/pdf/10.1007%2Fs11023-018-9482-5.pdf, (dicembre), (ultimo accesso marzo 2019); Floridi, L., Consapevolezza per un'etica dell'intelligenza artificiale (2019) Il Sole 24 Ore, 12, p. 11. , 13 gennaio; Domingos, P., (2016) L'Algoritmo Definitivo. La Macchina Che Impara da Sola e Il Futuro Del Nostro Mondo, , Bollati Boringhieri; Defez, R., (2018) Scoperta. Come la Ricerca Scientifica Può Aiutare A Cambiare l'Italia, , Codice Edizioni; Panarari, M., Se la scienza diventa ideologia (2018) La Stampa, 307, p. 21. , 7 novembre; Tipaldo, G., (2019) La Società della Pseudoscienza. Orientarsi Tra Buone e Cattive Spiegazioni, , il Mulino; Rosling, H., Con Rosling, O., Rosling Rönnlund, A., (2018) Factfulness. Dieci Ragioni per Cui Non Capiamo Il Mondo e Perché le Cose Vanno Meglio di Come Pensiamo, , Rizzoli; Luvison, A., Editoriale. L'ecosistema digitale: Le responsabilità di chi sviluppa l'ICT (2018) AEIT, 7-8, pp. 4-5. , https://www.aeit.it/aeit/edicola/aeit/aeit2018/aeit2018_04_cisa/aeit2018_04_riv.pdf, (luglio-agosto), (ultimo accesso marzo 2019); Nichols, T., (2018) La Conoscenza e i Suoi Nemici. L'era dell'Incompetenza e i Rischi per la Democrazia, , LUISS University Press; Hagstrom, R.G., (2013) Investing: The Last Liberal Art, , seconda edizione, Columbia Business School; Snow, C.P., (2005) Le Due Culture, , (a cura di Lanni, A.), I libri di Reset-Marsilio; Bucchi, M., (2018) Sbagliare da Professionisti. Storie di Errori e Fallimenti Memorabili, , Rizzoli; Baumol, W.J., Errors in economics and their consequences (2005) Social Research, 1, pp. 169-194. , primavera; Bar-Hillel, M., Noha, T., Frederick, S., Learning psychology from riddles: The case of stumpers (2018) Judgement and Decision Making, 1, pp. 112-122. , http://www.ratio.huji.ac.il/sites/default/files/publications/dp714.pdf, (gennaio), (ultimo accesso marzo 2019); Luvison, A., La crittologia da arte a scienza: L'eredità di Shannon e Turing (2015) Mondo Digitale - Rassegna Critica Del Settore ICT, 60, pp. 1-31. , http://mondodigitale.aicanet.net/2015-5/articoli/03_crittologia_da_arte_a_scienza.pdf, anno XIV, (novembre), (ultimo accesso marzo 2019); Mancini, F., Il dilemma del trolley, il conflitto tra colpa deontologica e colpa altruistico/umanitaria e il disturbo ossessivo (2015) State of Mind, , http://www.stateofmind.it/2015/05/colpa-disturbo-ossessivo/, 25 maggio, (ultimo accesso marzo 2019)},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Scheessele2018251,
author={Scheessele, M.R.},
title={A Framework for Grounding the Moral Status of Intelligent Machines},
journal={AIES 2018 - Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society},
year={2018},
pages={251-256},
doi={10.1145/3278721.3278743},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061060640&doi=10.1145%2f3278721.3278743&partnerID=40&md5=daff7bf64436e792f3d1f6bddc0a34a1},
abstract={I propose a framework, derived from moral theory, for assessing the moral status of intelligent machines. Using this framework, I claim that some current and foreseeable intelligent machines have approximately as much moral status as plants, trees, and other environmental entities. This claim raises the question: what obligations could a moral agent (e.g., a normal adult human) have toward an intelligent machine? I propose that the threshold for any moral obligation should be the "functional morality" of Wallach and Allen [20], while the upper limit of our obligations should not exceed the upper limit of our obligations toward plants, trees, and other environmental entities. © 2018 ACM.},
author_keywords={Machine Ethics},
keywords={Forestry, Intelligent machine;  Moral agents;  Moral obligations;  Moral theory;  Upper limits, Philosophical aspects},
references={Basl, J., Sandler, R., Three puzzles regarding the moral status of synthetic organisms (2013) Synthetic Biology and Morality: Artificial Life and the Bounds of Nature, pp. 89-106. , G. E. Kaebnick & T. H. Murray (Eds.), Cambridge, MA: MIT Press; Boldt, J., Müller, O., Newtons of the leaves of grass (2008) Nature Biotechnology, 26 (4), pp. 387-389; Briggs, G., Scheutz, M., The case for robot disobedience (2017) Scientific American, 316 (1), pp. 44-47; De-Grazia, D., (2002) Animal Rights: A Very Short Introduction, , New York: Oxford University Press; Dennett, D.C., (1978) Brainstorms: Philosophical Essays on Mind and Psychology, , Montgomery, VT: Bradford Books; Floridi, L., Information ethics: Its nature and scope (2008) Information Technology and Moral Philosophy, , J. Van Den Hoven & J. Weckert (Eds.), (Ch. 3). New York: Cambridge University Press; Gert, B., Gert, J., The definition of morality (2017) The Stanford Encyclopedia of Philosophy (Fall 2017 Edition), , https://plato.stanford.edu/archives/fall2017/entries/morality-definition/, E. N. Zalta (Ed.), URL; Gunkel, D., (2012) The Machine Question: Critical Perspectives on AI, Robots, and Ethics, , Cambridge, MA: MIT Press; Jaworska, A., Tannenbaum, J., The grounds of moral status (2017) The Stanford Encyclopedia of Philosophy (Fall 2017 Edition), , https://plato.stanford.edu/archives/fall2017/entries/grounds-moral-status/, E. N. Zalta (Ed.), URL; Kant, I., (1998) Groundwork of the Metaphysics of Morals, , 1785/. (M. Gregor, Trans. and Ed.). Cambridge, UK: Cambridge University Press; Kaufman, F., Machines, sentience, and the scope of morality (1994) Environmental Ethics, 16 (1), pp. 57-70; Kolak, D., Hirstein, W., Mandik, P., Waskan, J., (2006) Cognitive Science: An Introduction to Mind and Brain, , New York: Routledge; Lu, T.K., Purcell, O., Machine life (2016) Scientific American, 314 (4), pp. 58-63; Moor, J., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, pp. 18-21. , (July/August, 2006); Rachels, J., Drawing lines (2004) Animal Rights: Current Debates and New Directions, pp. 162-174. , C. R. Sunstein & M. C. Nussbaum (Eds.), New York: Oxford University Press; Sandler, R., Is artefactualness a value-relevant property of living things? (2012) Synthese, 185, pp. 89-102; Singer, P., All animals are equal (1974) Philosophic Exchange, 5 (1), pp. 103-116; Sterba, J.P., (2005) The Triumph of Practice over Theory in Ethics, , New York: Oxford University Press; Torrance, S., Ethics and consciousness in artificial agents (2008) AI & Society, 22, pp. 495-521; Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , New York: Oxford University Press; Zahavi, D., (2003) Husserl's Phenomenology, , Stanford, CA: Stanford University Press},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Sengupta2018226,
author={Sengupta, E. and Garg, D. and Choudhury, T. and Aggarwal, A.},
title={Techniques to elimenate human bias in machine learning},
journal={Proceedings of the 2018 International Conference on System Modeling and Advancement in Research Trends, SMART 2018},
year={2018},
pages={226-230},
doi={10.1109/SYSMART.2018.8746946},
art_number={8746946},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070490422&doi=10.1109%2fSYSMART.2018.8746946&partnerID=40&md5=01155aa83a36abbe33948dd9ded07b7e},
abstract={In an era where human lives have certain dependence on artificial intelligence and machine learning, it is essential for them to make unbiased and accurate predictions. This paper addresses the issue of the inclusion of a human bias in a machine learning algorithm and how it goes to produce skewed results. It goes through the prominent types of human biases and real life incidents where the inclusion of a human bias has had a negative impact. This paper provides a comprehensive review of the methods that can be incorporated to eliminate a human bias focusing on the use of machine ethics making mention of community groups working towards the same. © 2018 IEEE.},
author_keywords={Artificial Intelligence;  Bias dataset;  Human Bias;  Machine Learning;  Skewed results},
keywords={Artificial intelligence;  Learning algorithms;  Learning systems, Accurate prediction;  Bias dataset;  Community group;  Human bias;  Human lives;  Skewed results, Machine learning},
references={Larya, D.J., Alavib, A.H., Gandomic, A.H., Walkerd, A.L., Machine learning in geosciences and remote sensing (2016) Geoscience Frontiers, 7 (1), pp. 3-10. , January; Chakravorty, T., (2016) How Machine Learning Works: An Overview, , https://thenewstack.io/how-machine-learningworks-an-overview/; Daniel James Fuchs Missouri University of Science and Technology, , May 2018"The Dangers of Human-Like Bias in Machine Learning Algorithms"; Buolamwini, J., (2018) Facial Recognition Software is Biased Towards White Men, Researcher Finds, , MIT Media Labs Feb. 11, 2018, retrieved 30th September; Albayrak, N., Ozdemir, A., Zeydan, E., An overview of artificial intelligence based chatbots and an example chatbot application (2018) 2018 26th Signal Processing and Communications Applications Conference (SIU); Meng, J., Zhang, J., Zhao, H., Overview of the speech recognition technology (2012) 2012 Fourth International Conference on Computational and Information Sciences; Gender and Dialect Bias in Youtube's Automatic Captions", , Rachael Tatman Department of Lingusitics University of Washington; Buscema, P.M., Tastle, W.J., (2013) Intelligent Data Mining in Law Enforcement Analytics New Neural Networks Applied to Real Problems, , (Eds.) (Springer); Lum, K., Predictive policing reinforces police bias (2016) October, 10; (2013) Discrimination in Online Ad Delivery, 28. , Latanya Sweeney, Harvard University January; Ellis, G., (2018) Cognitive Biases in Visualizations, , (Springer); Howard, A., Zhang, C., Horvitz, E., Addressing bias in machine learning algorithms: A pilot study on emotion recognition for intelligent systems (2017) 2017 IEEE Workshop on Advanced Robotics and Its Social Impacts (ARSO); IBM Research IBM-MIT Watson Labs Blog},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Howard2018,
author={Howard, A. and Borenstein, J.},
title={Hacking the Human Bias in Robotics},
journal={ACM Transactions on Human-Robot Interaction},
year={2018},
volume={7},
number={1},
doi={10.1145/3208974},
art_number={3208974},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083717537&doi=10.1145%2f3208974&partnerID=40&md5=db00e3ca620671e14b2d91e011309fdc},
author_keywords={Artificial intelligence;  bias;  professional responsibility;  robot ethics},
references={Bartneck, C., Yogeeswaran, K., Ser, Q.M., Woodward, G., Sparrow, R., Wang, S., Eyssel, F., Robots and racism (2018) Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction (HRI'18). ACM, pp. 196-204. , Chicago, IL; Byrne, W., Now is the time to act to end bias in AI (2018) Fast Company, , https://www.fastcompany.com/40536485/now-is-the-time-to-act-to-stop-bias-in-ai, (28 February 2018). Retrieved April 19 2018 from; Carpenter, J., Google's algorithm shows prestigious job ads to men, but not to women (2015) Independent, , http://www.independent.co.uk/life-style/gadgets-and-tech/news/googlesalgorithm-shows-prestigious-job-ads-to-men-but-not-to-women-10372166.html, (7 July 2015). Retrieved April 19 2018 from; Hall, W., Chapman, M., Lee, K.M., Merino, Y.M., Thomas, T.W., Payne, B.K., Implicit racial/ethnic bias among health care professionals and its influence on health care outcomes: A systematic review (2015) American Journal of Public Health, 105 (12), pp. e60-e76; Howard, A., Borenstein, J., The ugly truth about ourselves and our robot creations: The problem of bias and social inequity (2017) Science and Engineering Ethics Journal, , http://dx.doi.org/10.1007/s11948-017-9975-2; Hunt, E., Tay, Microsoft's AI chatbot, gets a crash course in racism from Twitter (2016) The Guardian, , https://www.theguardian.com/technology/2016/mar/24/tay-microsofts-ai-chatbotgets-a-crash-course-in-racism-from-twitter, (24 March 2016). Retrieved April 19, 2018 from; Joy, B., Why the future doesn't need us (2000) Wired, , https://www.wired.com/2000/04/joy-2/, (1 April 2000); Kurzweil, R., (2001) Promise and Peril, , http://www.kurzweilai.net/promise-and-peril, Retrieved April 19, 2018 from; Lohr, S., (2018) Facial Recognition Is Accurate, if you'Re A White Guy, , https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html, New York Times (9 February 2018). Retrieved April 19, 2018 from},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Sabili2018465,
author={Sabili, A.F. and Saptawijaya, A. and Pereira, L.M.},
title={Intelligent agents via joint tabling of logic program abduction and updating},
journal={2017 International Conference on Advanced Computer Science and Information Systems, ICACSIS 2017},
year={2018},
volume={2018-January},
pages={465-470},
doi={10.1109/ICACSIS.2017.8355075},
art_number={8355075},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051141908&doi=10.1109%2fICACSIS.2017.8355075&partnerID=40&md5=42e56a0059f210b87babd770ce56f320},
abstract={Reasoning is an important aspect for an intelligent agent to come to a rational decision. With the same importance is the ability of such an agent to adapt itself to the environment by learning new knowledge from its observations. When the agent's knowledge base is represented by a logic program, goal-directed deliberative reasoning and the adaptive ability of such an agent can be achieved by abduction and updating on logic programs, respectively. Furthermore, the tabling feature in logic programming, which affords solutions reuse rather than recomputing them, enables an agent to make an immediate decision based on past reasoning, thus avoiding repetitive deliberative reasoning. Joint tabling of logic program abduction and updating is an approach first proposed by Pereira and Saptawijaya, motivated by its application in machine ethics, enabling an agent to make moral decisions, using their system Qualm. In this paper, we provide a complete program transformation which has not been detailed on that approach. We also resolve previously unidentified issues with respect to its implementation aspects. A prototype, Qualm∗, is implemented as a proof of concept using XSB Prolog. Furthermore, an application is detailed, using Qualm', emphasizing the importance of joint tabling of logic program abduction and updating, in the context of intelligent agents, specifically in ambient intelligence for eldercare. © 2017 IEEE.},
keywords={Application programs;  Information use;  Intelligent agents;  Knowledge based systems;  Logic programming;  PROLOG (programming language), Adaptive ability;  Decision-based;  Implementation aspects;  ITS applications;  Knowledge base;  Logic programs;  Program transformations;  Proof of concept, Computer circuits},
references={Caruso, C., (2017) Grandmas Little Robot, , https://www.scientiiicamerican.com/article/grandma-rsquo-s-little-robot/, May; Kakas, A.C., Kowalski, R.A., Toni, F., Abductive logic programming (1992) Journal of Logic and Computation, 2 (6), pp. 719-770; Alferes, J.J., Pereira, L.M., Swift, T., Abduction in well-founded semantics and generalized stable models via tabled dual programs (2004) Theory and Practice of Logic Programming, 4 (4), pp. 383-428; Pereira, L.M., DellAcqua, P., Lopes, G., On preferring and inspecting abductive models (2009) Procs. PADL 2009, , A. Gill and T. Swift, eds Springer; Kakas, A.C., Mancarella, P., Database updates through abduction (1990) 16th Very Large Database Conference, pp. 650-661; Kakas, A.C., Mancarella, P., Knowledge assimilation and abduction (1990) International Workshop on Truth Maintenance, 515, pp. 54-71. , Springer; Alferes, J., Leite, J., Pereira, L., Przymusinska, H., Przymusinski, T., Dynamic updates of non-monotonic knowledge bases (2000) The Journal of Logic Programming, 45 (1), pp. 43-70; Alferes, J.J., Brogi, A., Leite, J.A., Pereira, L.M., Evolving logic programs (2002) Procs. JELIA, pp. 50-61. , Springer; Leite, J.A., (2003) Evolving Knowledge Bases: Specification and Semantics, , IOS Press; Cushman, F., Young, L., Greene, J.D., Multi-system moral psychology (2010) The Moral Psychology Handbook, , (J. M. Doris, ed.), Oxford University Press; Pereira, L.M., Saptawijaya, A., Abduction and beyond in logic programming with application to morality (2016) IfCoLog Journal of Logics and Their Applications, 3 (1), pp. 37-71; Pereira, L.M., Saptawijaya, A., (2016) Programming Machine Ethics, 26. , of SAPERE Springer; Swift, T., Warren, D.S., XSB: Extending prolog with tabled logic programming (2012) Theory and Practice of Logic Programming, 12 (1-2), pp. 157-187; Hartshome, C., Weiss, P., (1932) Collected Papers of Charles Sanders Peirce, , Harvard University Press; Van Gelder, A., Ross, K.A., Schlipf, J.S., The well-founded semantics for general logic programs (1991) Journal of ACM, 38 (3), pp. 620-650; Saptawijaya, A., Pereira, L.M., TABDUAL: A tabled abduction system for logic programs (2015) IfCoLog Journal of Logics and Their Applications, 2 (1), pp. 69-123; Saptawijaya, A., Pereira, L.M., Incremental tabling for query-driven propagation of logic program updates (2013) Procs. LPAR-19, 8312, pp. 694-709. , Springer; Perkasa, S.M.A., Saptawijaya, A., Pereira, L.M., Tabling in contextual abduction with answer subsumption (2017) Procs. 9th Inti. Conf on Advanced Computer Science and Information Systems (ICACSIS)},
document_type={Conference Paper},
source={Scopus},
}

@BOOK{Pavaloiu2018219,
author={Pavaloiu, A.},
title={Artificial intelligence ethics in biomedical-engineering-oriented problems},
journal={Nature-Inspired Intelligent Techniques for Solving Biomedical Engineering Problems},
year={2018},
pages={219-231},
doi={10.4018/978-1-5225-4769-3.ch010},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046598133&doi=10.4018%2f978-1-5225-4769-3.ch010&partnerID=40&md5=92962fd9479cef153ce8139d3c2a76e9},
abstract={The field of artificial intelligence has recently encountered some ethical questions associated with the future of humankind. Although it is a common question that has been asked for years, the existence of humankind against badly configured intelligent systems is more important nowadays. As a result of rapid developments in intelligent systems and their increasing role in our life, there is a remarkable anxiety about dangerous artificial intelligence. Because of that, some research interests gathered under some topics like machine ethics, future of artificial intelligence, and even existential risks are drawing researchers' interest. As associated with this state, the objective of this chapter is to examine ethical factors in using intelligent systems for biomedical-engineering-oriented purposes. The chapter firstly gives essential information about the background and then considers possible scenarios that may require ethical adjustments during design and development of artificial-intelligence-oriented systems for biomedical engineering problems. © 2018, IGI Global. All rights reserved.},
keywords={Biomedical engineering;  Biophysics;  Intelligent systems, Design and Development;  Ethical question;  Oriented systems;  Research interests, Philosophical aspects},
references={Austin, W., Lemermeyer, G., Goldberg, L., Bergum, V., Johnson, M.S., Moral distress in healthcare practice: The situation of nurses (2005) HEC Forum, 17 (1), pp. 33-48. , PMID:15957267; Bostrom, N., The concept of existential risk (2002) Journal of Evolution and Technology / WTA, p. 9; Bostrom, N., Ethical issues in advanced artificial intelligence (2003) Science Fiction and Philosophy:From Time Travel to Superintelligence, pp. 277-284; Bostrom, N., (2014) Superintelligence: Paths, Dangers, Strategies, , OUP Oxford; Bostrom, N., Yudkowsky, E., The ethics of artificial intelligence (2014) The Cambridge Handbook of Artificial Intelligence, pp. 316-334; Cohen, J.S., Erickson, J.M., Ethical dilemmas and moral distress in oncology nursing practice (2006) Clinical Journal of Oncology Nursing, 10 (6), pp. 775-780. , PMID:17193943; Farkas, I., Artificial intelligence in agriculture (2003) Computers and Electronics in Agriculture, 1 (40), pp. 1-3; Førde, R., Aasland, O.G., Moral distress among Norwegian doctors (2008) Journal of Medical Ethics, 34 (7), pp. 521-525. , PMID:18591286; Hamric, A.B., Davis, W.S., Childress, M.D., Moral distress in health care professionals (2006) Pharos, 69 (1), pp. 16-23. , PMID:16544460; Hawking, S., Russell, S., Tegmark, M., Wilczek, F., Stephen Hawking: Transcendence looks at the implications of artificial intelligence-but are we taking AI seriously enough? (2014) The Independent, 2014 (1-5), p. 9313474; Kälvemark, S., Höglund, A.T., Hansson, M.G., Westerholm, P., Arnetz, B., Living with conflicts-ethical dilemmas and moral distress in the health care system (2004) Social Science & Medicine, 58 (6), pp. 1075-1084. , PMID:14723903; Kose, U., Pavaloiu, A., Dealing with Machine Ethics in Daily Life: A View with Examples (2017) International Virtual Conference on Advanced Scientific Results / Online Scientific Conference 2017 (ScieConf 2017), pp. 200-205; Kurzweil, R., (2005) The Singularity is Near: When Humans Transcend Biology, , Penguin; McArthur, D., Lewis, M., Bishary, M., The Roles of Artificial Intelligence in Education: Current Progress and Future Prospects (2005) Journal of Educational Technology, 1 (4), pp. 42-80; Do we need Asimov's laws? (2016) MIT Technology Review, , https://www.technologyreview.com/s/527336/do-we-need-asimovs-laws/, Retrieved on July 29, 2017 from; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Negnevitsky, M., (2005) Artificial intelligence: a guide to intelligent systems, , Pearson Education; Pham, D.T., Pham, P.T.N., Artificial intelligence in engineering (1999) International Journal of Machine Tools & Manufacture, 39 (6), pp. 937-949; Ramesh, A.N., Kambhampati, C., Monson, J.R.T., Drew, P.J., Artificial intelligence in medicine (2004) Annals of the Royal College of Surgeons of England, 86 (5), pp. 334-338. , PMID:15333167; Russell, S., Dewey, D., Tegmark, M., Research priorities for robust and beneficial artificial intelligence (2015) AI Magazine, 36 (4), pp. 105-114; (2012) Ray Kurzweil on the singularity, , https://www.youtube.com/watch?v=EXVrTCjetLg, Retrieved on July 28, 2017 from; Stahovich, T.F., Artificial intelligence for design (2001) Formal engineering design synthesis, pp. 228-269; Vasant, P., Kose, U., Moral Dilemma Scenarios Considering Possible Actions by Humans and Artificial Intelligence Based Systems (2017) Journal of Multidisciplinary Developments, 2 (2), pp. 39-49; Yudkowsky, E., Artificial intelligence as a positive and negative factor in global risk (2008) Global Catastrophic Risks, 1 (303), p. 184; Allen, C., Wallach, W., Smit, I., Why Machine Ethics? (2011) Machine Ethics, pp. 51-60; Amigoni, F., Schiaffonati, V., Machine ethics and human ethics: A critical view (2005) Proceedings of the AAAI 2005 Fall Symposium on Machine Ethics, pp. 103-104; Anderson, M., (2005) Machine Ethics: Papers from the 2004 AAAI Fall Symposium;, , [November 4-6, 2005, Arlington, Virginia]. AAAI Press; Anderson, M., Anderson, S.L., Guest Editors' Introduction: Machine Ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 10-11; Anderson, M., Anderson, S.L., Armen, C., Toward machine ethics (2004) Proceedings of AAAI 2004 Workshop on Agent Organizations: Theory and Practice; Anderson, M., Anderson, S.L., Armen, C., MedEthEx: a prototype medical ethics advisor (1999) Proceedings Of The National Conference On Artificial Intelligence, 21 (2), p. 1759. , Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; Anderson, M., Anderson, S.L., Armen, C., An approach to computing ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 56-63; Anderson, S.L., (2011) Machine metaethics. Machine ethics, pp. 21-27. , Cambridge: Cambridge University Press; Anderson, S.L., Anderson, M., (2011) A Prima Facie Duty Approach to Machine Ethics and Its Application to Elder Care, , Human-Robot Interaction in Elder Care; Beavers, A.F., 21 Moral Machines and the Threat of Ethical Nihilism (2011) Robot ethics: The ethical and social implications of robotics, p. 333; Bendel, O., Surgical, therapeutic, nursing and sex robots in machine and information ethics (2015) Machine Medical Ethics, pp. 17-32. , Springer International Publishing; Brundage, M., Limitations and risks of machine ethics (2014) Journal of Experimental & Theoretical Artificial Intelligence, 26 (3), pp. 355-372; Casey, B.J., (2017) Amoral machines, or: How roboticists can learn to stop worrying and love the law; Conitzer, V., Sinnott-Armstrong, W., Borg, J.S., Deng, Y., Kramer, M., Moral Decision Making Frameworks for Artificial Intelligence (2017) AAAI, pp. 4831-4835; Crnkovic, G.D., Çürüklü, B., Robots: Ethical by design (2012) Ethics and Information Technology, 14 (1), pp. 61-71; Danielson, P., Prototyping N-reasons: a computer mediated ethics machine (2011) Machine ethics, pp. 442-450; Etzioni, A., Etzioni, O., Incorporating Ethics into Artificial Intelligence (2017) The Journal of Ethics, pp. 1-16; Goodall, N.J., Machine ethics and automated vehicles (2014) Road vehicle automation, pp. 93-102. , Springer International Publishing; Guarini, M., Introduction: Machine ethics and the ethics of building intelligent machines (2013) Topoi, 32 (2), pp. 213-215; Gunkel, D.J., (2012) The machine question: critical perspectives on AI, robots, and ethics, , MIT Press; Jebari, K., Existential risks: Exploring a robust risk reduction strategy (2015) Science and Engineering Ethics, 21 (3), pp. 541-554. , PMID:24891130; Johnson, D.G., Computer Systems--Moral Entities but Not Moral Agents (2011) Machine Ethics, pp. 151-160; Jonsen, A.R., Siegler, M., Winslade, W.J., Clinical ethics: a practical approach to ethical decisions in clinical medicine (2006) Univerza v Mariboru, Fakulteta za zdravstvene vede; Komuda, R., Rzepka, R., Araki, K., Social Factors in Kohlberg's Theory of Stages of Moral Development the Utility of (Web) Crowd Wisdom for Machine Ethics Research (2010) Proceedings of the 5th International Conference on Applied Ethics, p. 14; LaGrandeur, K., Hughes, J.J., (2017) Surviving the Machine Age: Intelligent Technology and the Transformation of Human Work, , Springer; Leben, D., A Rawlsian algorithm for autonomous vehicles (2017) Ethics and Information Technology, 19 (2), pp. 107-115; Lim, H.C., Stocker, R., Larkin, H., Review of trust and machine ethics research: Towards a bio-inspired computational model of ethical trust (CMET) (2008) Proceedings of the 3rd International Conference on Bio-Inspired Models of Network, Information and Computing Sytems, p. 8. , ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering); Lindner, F., Bentzen, M.M., The Hybrid Ethical Reasoning Agent IMMANUEL (2017) Proceedings of the Companion of the 2017 ACM/IEEE International Conference on Human-Robot Interaction, pp. 187-188. , ACM; Mappes, T.A., Zembaty, J.S., (1981) Biomedical ethics, p. 54. , New York: McGraw-Hill; McDermott, D., Why ethics is a high hurdle for AI (2008) North American Conference on Computers and Philosophy, , Bloomington, IN; McDermott, D., What matters to a machine (2011) Machine ethics, pp. 88-114; McIntyre-Mills, J., Wellbeing and existential risk (2012) CASS research conference sustainable environmental policy and global governance, pp. 18-19. , Beijing; McLaren, B., Lessons in machine ethics from the perspective of two computational models of ethical reasoning (2005) 2005 AAAI Fall Symposium on Machine Ethics; McLaren, B.M., Extensionally defining principles and cases in ethics: An AI model (2003) Artificial Intelligence, 150 (1-2), pp. 145-181; Medsker, L., AI policy: Organizations, resources, and recent symposia (2017) AI Matters, 3 (1), pp. 9-11; Muehlhauser, L., Helm, L., The singularity and machine ethics (2012) Singularity Hypotheses, pp. 101-126. , Springer Berlin Heidelberg; Pereira, L.M., Saptawijaya, A., Bridging two realms of machine ethics (2016) Programming Machine Ethics, pp. 159-165. , Springer International Publishing; Pereira, L.M., Saptawijaya, A., (2016) Programming machine ethics, , (Vol. 26). Springer; Persson, D., Erlandsson, L.K., Time to Reevaluate the Machine Society: Post-industrial Ethics from an Occupational Perspective (2002) Journal of Occupational Science, 9 (2), pp. 93-99; Powers, T.M., Incremental machine ethics (2011) IEEE Robotics & Automation Magazine, 18 (1), pp. 51-58; Powers, T.M., One way to view the puzzle of machine ethics is to consider how (2011) Machine Ethics, p. 464; Price, H., Cambridge, cabs and Copenhagen: My route to existential risk (2013) The New York Times, 27, p. 2013; Shulman, C., Jonsson, H., Tarleton, N., Machine ethics and superintelligence (2009) Reynolds and Cassinelli, pp. 95-97; Sullins, J.P., When is a robot a moral agent (2006) Machine Ethics, pp. 151-160; Tonkens, R., A challenge for machine ethics (2009) Minds and Machines, 19 (3), pp. 421-438; Torrance, S., Machine ethics and the idea of a more-than-human moral world (2011) Machine ethics, pp. 115-137; Veruggio, G., Solis, J., van der Loos, M., Roboethics: Ethics applied to robotics [from the guest editors] (2011) IEEE Robotics & Automation Magazine, 18 (1), pp. 21-22; Wallach, W., Robot minds and human ethics: The need for a comprehensive model of moral decision making (2010) Ethics and Information Technology, 12 (3), pp. 243-250; Whitby, B., On Computable Morality An Examination of Machines (2011) Machine ethics, p. 138; Winter-Levy, S., Trefethen, J., Safety First Entering the Age of Artificial Intelligence (2016) World Policy Journal, 33 (1), pp. 105-111; Yampolskiy, R.V., Artificial intelligence safety engineering: Why machine ethics is a wrong approach (2013) Philosophy and theory of artificial intelligence, pp. 389-396; Yampolskiy, R.V., Taxonomy of Pathways to Dangerous Artificial Intelligence (2016) AAAI Workshop:AI, Ethics, and Society; Yampolskiy, R.V., Spellchecker, M.S., (2016) Artificial Intelligence Safety and Cybersecurity: a Timeline of AI Failures},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Karppi2018107,
author={Karppi, T. and Böhlen, M. and Granata, Y.},
title={Killer Robots as cultural techniques},
journal={International Journal of Cultural Studies},
year={2018},
volume={21},
number={2},
pages={107-123},
doi={10.1177/1367877916671425},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042866939&doi=10.1177%2f1367877916671425&partnerID=40&md5=5f46bdba75895ad94756b73809f58e50},
abstract={In October 2012 a group of non-governmental organizations formed a Campaign to Stop Killer Robots. The aim of this campaign was to preemptively ban fully autonomous weapons capable of selecting and engaging targets without human intervention. The campaign gained momentum swiftly, leading to different legal and political discussions and decision-makings. In this article, we use the framework of cultural techniques to analyze the different operational processes, tactics, and ethics underlying the debates surrounding developments of autonomous weapon systems. From reading the materials of the Campaign to Stop Killer Robots and focusing on current robotic research in the military context we argue that, instead of demonizing Killer Robots as such, we need to understand the tools, processes and operating procedures that create, support and validate these objects. The framework of cultural techniques help us to analyze how autonomous technologies draw distinctions between life and death, human and machine, culture and technology, and what it means to be in control of these systems in the 21st century. © 2016, © The Author(s) 2016.},
author_keywords={automation;  cultural techniques;  Killer Robots;  robot ethics;  war},
references={Abney, K., Robotics, ethical theory, and metaethics: a guide for the perplexed (2011) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 35-54. , Lin P., Abney K., Bekey G., (eds), Cambridge, MA, MIT Press, In:, (eds); Agamben, G., (2009) What Is an Apparatus? And Other Essays, , Stanford, CA, Stanford University Press; Andrejevic, M., The droning of experience (2015) The Fibreculture Journal, 25, pp. 202-217; Arkin, R., (2009) Governing lethal behavior: embedding ethics in a hybrid deliberative/reactive robot architecture, , http://www.cc.gatech.edu/ai/robot-lab/online-publications/Le_arkin.pdf, accessed September 2016, Technical Report GIT-GVU-07-11; Arkin, R., Ulman, P., (2012) Overriding ethical constraints in lethal autonomous systems, , http://www.cc.gatech.edu/ai/robot-lab/online-publications/BICA-Overridesv12.pdf, accessed September 2016, Technical Report GIT-MRL-12-01; Asaro, P., Ban Killer Robots before They Become Weapons of Mass Destruction (2015) Scientific American, , http://www.scientificamerican.com/article/ban-killer-robots-before-they-become-weapons-of-mass-destruction/, August, 7, Accessed Feb 11, 2016; Atherton, K., You shouldn’t be afraid of that killer Volkswagen robot (2015) Popular Science, , http://www.popsci.com/murder-robot-mundane-industrial-accident, 2, July, accessed 11 February 2016; Barad, K., Posthumanist performativity: toward an understanding of how matter comes to matter (2003) Signs, 28 (3), pp. 801-831; Chronology, , http://www.stopkillerrobots.org/chronology/, accessed 11 February 2016, (. a); Act, , http://www.stopkillerrobots.org/act/, accessed 11 February 2016, (. b); Call to action, , http://www.stopkillerrobots.org/call-to-action/, accessed 11 February 2016, (. c); The problem, , http://www.stopkillerrobots.org/the-problem/, accessed 11 February 2016, (. d); The solution, , http://www.stopkillerrobots.org/the-solution/, accessed 11 February 2016, (. e); Explosives Used on US Police Robot to Kill, , https://www.stopkillerrobots.org/2016/07/explosives-used-on-us-police-robot-to-kill/, accessed 20 September 2016, (. f); Experts on killer robots at Davos, , https://www.stopkillerrobots.org/2016/01/davos-2/, accessed 20 September 2016, (. g); Coeckelbergh, M., From killer machines to doctrines and swarms, or why ethics of military robotics is not (necessarily) about robots (2011) Philosophy & Technology, 24 (3), pp. 269-278; Elsaesser, T., (2000) Weimar Cinema and After: Germany’s Historical Imaginary, , New York, Routledge; Foucault, M., The confession of the flesh (1980) Power/Knowledge: Selected Interviews and Other Writings, pp. 194-228. , Gordon C., (ed), New York, Pantheon Books, In:, edited by; Foucault, M., (2009) Security, Territory, Population, , Houndmills, Palgrave Macmillan; Franklin, S., (2015) Control: Digitality as Cultural Logic, , Cambridge, MA, MIT Press; Goldberg, S., The changing face of death: computers, consciousness and Nancy Cruzan (1991) Stanford Law Review, 43 (3), pp. 659-684; Guizzo, E., Ackerman, E., Do we want robot warriors to decide who lives or dies? (2016) IEEE Spectrum, , http://spectrum.ieee.org/robotics/military-robots/do-we-want-robot-warriors-to-decide-who-lives-or-dies, 31, May, accessed 7 June 2016; Hall, S., Critcher, C., Jefferson, T., Clarke, J., Roberts, B., (2013) Policing the Crisis: Mugging, the State and Law and Order, , 2nd edn., New York, Palgrave Macmillan; Higginson, I., Astin, P., Dolan, S., Where do cancer patients die? Ten-year trends in the place of death of cancer patients in England (1998) Palliative Medicine, 12, pp. 353-363; Jenkins, H., Ford, S., Green, J., (2013) Spreadable Media: Creating Value and Meaning in a Networked Culture, , New York, New York University Press; Lake, B., Salakhutdinov, R., Tenenbaum, J., Human-level concept learning through probabilistic program induction (2015) Science, 350 (6266), pp. 1332-1338; Law, J., Urry, J., Enacting the social (2004) Economy and Society, 33 (3), pp. 390-410; Lin, P., Bekey, G., Keith, A., (2008) Autonomous Military Robotics: Risk, Ethics, and Design, , http://ethics.calpoly.edu/onr_report.pdf, Office of Naval Research, accessed September 2016, Report for US Department of Navy, Ver. 1.0.9; Marx, K., (1973) Grundrisse, , Harmondsworth, Penguin; Matthias, A., (2004) The Responsibility Gap, , Dordrecht, Kluwer Academic Publishers; Mikkelson, D., SeppuKuma (2015) Snopes.com, , http://www.snopes.com/politics/science/suicidebear.asp, 6, May, accessed 20 September 2016; Noys, B., Drone metaphysics (2015) Culture Machine, 16, pp. 1-22; (2015) Autonomous weapons: an open letter from AI & Robotics Researchers, , http://futureoflife.org/open-letter-autonomous-weapons/, Future of Life Insitiute, accessed 11 February 2016; Parikka, J., Afterword: cultural techniques and media studies (2013) Theory, Culture & Society, 30 (6), pp. 147-159; Parikka, J., Cultural techniques of cognitive capitalism: metaprogramming and the labour of code (2015) Cultural Studies Review, 20 (1), pp. 30-52; Pfeifer, R., Scheier, C., (2001) Understanding Intelligence, , Cambridge, MA, MIT Press; Reeves, S.R., Johnson, W.J., Autonomous weapons: are you sure these are killer robots? Can we talk about it? (2014) The Army Lawyer, , http://ssrn.com/abstract=2427923, 1, April, accessed 11 February 2016, : SSRN; (2015) The strong robot with the gentle touch, , http://www.riken.jp/en/pr/press/2015/20150223_2/, Riken RIKEN research institute, 23, February, accessed 20 September 2016, Press release; Siegert, B., Cultural techniques: or the end of the intellectual postwar era in German media theory (2013) Theory, Culture & Society, 30 (6), pp. 48-65; Siegert, B., (2015) Cultural Techniques: Grids, Filters, Doors, and Other Articulations of the Real, , New York, Fordham University Press; Smolensky, P., Symbolic functions from neural computation (2012) Philosophical Transactions of the Royal Society A, 370, pp. 3543-3569; Sparrow, R., Twenty seconds to comply: autonomous weapons systems and the recognition of surrender (2015) International Law Studies, 91, pp. 699-728; Tamburrini, G., Robot ethics: a view from the philosophy of science (2008) Ethics and Robotics, pp. 11-23. , Capurro R., Nagenborg M., (eds), Heidelberg, IOS Press, 2009, In:, (eds); Wheatley, V., Baker, J., ‘Please, I want to go home’: ethical issues raised when considering choice of place of care in palliative care (2007) Postgraduate Medical Journal, 83 (984), pp. 643-648; Winthrop-Young, G., Cultural techniques: preliminary remarks (2013) Theory, Culture & Society, 30 (6), pp. 3-19},
document_type={Article},
source={Scopus},
}

@ARTICLE{Bendel2018204,
author={Bendel, O.},
title={Towards animal-friendly machines},
journal={Paladyn},
year={2018},
volume={9},
number={1},
pages={204-213},
doi={10.1515/pjbr-2018-0019},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053273786&doi=10.1515%2fpjbr-2018-0019&partnerID=40&md5=95b4e53307e47a72891fd4e339993ced},
abstract={Semi-Autonomous machines, autonomous machines and robots inhabit closed, semi-closed and open environments. There they encounter domestic animals, farm animals, working animals and/or wild animals. These animals could be disturbed, displaced, injured or killed. Within the context of machine ethics, the School of Business FHNW developed several design studies and prototypes for animal-friendly machines,which can be understood as moral machines in the spirit of this discipline. They were each linked with an annotated decision tree containing the ethical assumptions or justifications for interactions with animals. Annotated decision trees are seen as an important basis in developing moral machines. They are not without problems and contradictions, but they do guarantee well-founded, secure actions that are repeated at a certain level. This article documents completed and current projects, compares their relative risks and benefits, and makes proposals for future developments in machine ethics. The findings in this article and proposals for the future hope to systemically promote animal well-being and prevent animal suffering in encounters between machines and animals. © by Oliver Bendel, published by De Gruyter 2018.},
author_keywords={animal ethics;  animal welfare;  annotated decision trees;  artificial intelligence;  decision trees;  machine ethics;  roboethics;  robotics},
references={Azad-Manjiri, M., A new architecture for making moral agents based on C4.5 decision tree algorithm (2014) International Journal of Information Technology and Computer Science (IJITCS), 6 (5), pp. 50-57; Bendel, O., Einfache moralische Maschinen: Vom Design zur Konzeption (2015) Prozesse, Technologie, Anwendungen, Systeme und Management, Mana-Buch, pp. 171-180. , T. Barton, B. Erdlenbruch, F. Herrmann et al. (Eds); Bendel, O., Considerations about the relationship between animal and machine ethics (2016) AI & SOCIETY, 31 (1), pp. 103-108; Bendel, O., Advanced driver assistance systems and animals (2014) Könstliche Intelligenz, 28 (4), pp. 263-269; Mancini, C., Animal-Computer Interaction (ACI) a manifest (2011) Interactions, 18 (4), pp. 69-73; Anderson, M., Anderson, S.L., (2011) Machine Ethics Cambridge, , University Press; Bendel, O., Wirtschaftliche und technische Implikationen der Maschinenethik (2014) Die Betriebswirtschaft, 4, pp. 237-248; Bendel, O., (2012) Maschinenethik Gabler Wirtschaftslexikon, , http://wirtschaftslexikon.gabler.de/Definition/maschinenethik.html, Springer Gabler; Bendel, O., (2014) Tierethik Gabler Wirtschaftslexikon, , http://wirtschaftslexikon.gabler.de/Definition/tierethik.html, Springer Gabler; Donaldson, S., Kymlicka, W., (2011) Zoopolis: A Political Theory of Animal Rights, , Oxford University Press; Singer, P., (2011) Practical Ethics Third Edition, , Cambridge University Press; Wolf, U., (2012) Ethik der Mensch-Tier-Beziehung Klostermann; Fossgreen, A., (2017) Bei Den Köhen Piepts, , https://www.tagesanzeiger.ch/wissen/bei-denkuehen-piepts/story/26203583, Tages-Anzeiger, September 9; Eichler, S., (2013) Sitzen Statt Böcken DRadio Wissen, , http://www.dradiowissen.de/erdbeerernte-sitzen-stattbuecken35.de.html?dram:article_id=239972, March 13; Pluta, W., (2017) Roboterwolf Vertreibt Wildschweine, , https://www.golem.de/news/landwirtschaftroboterwolf-vertreibt-wildschweine-1708-129719.html, Golem August 28; Bendel, O., Die Roboter sind unter uns (2014) Netzwoche, 22, p. 28; Mondada, F., Halloy, J., Martinoli, A., A general methodology for the control of mixed natural-Artificial societies (2013) Handbook of Collective Robotics: Fundamentals and Challenges, , S. Kernbach (Ed) Taylor & Francis; Bendel, O., Annotated Decision Trees for Simple Moralmachines, the 2016 AAAI Spring Symposium Series, AAAI Press, pp. 195-201; Kolhagen, J., Autopiloten auf Rädern (2013) Versicherungswirtschaft, 11 (70). , June 1; Stoller, D., Vollautomatisch und ohne Fahrer in der Stadt unterwegs (2013) Ingenieur.De, , http://www.ingenieur.de/Themen/Automobil/Vollautomatisch-Fahrer-in-Stadt-unterwegs, July 15; Bendel, O., Fahrerassistenzsysteme aus ethischer Sicht (2014) Zeitschrift för Verkehrssicherheit, 2, pp. 108-110; Bendel, O., (2013) Ich Bremse Auch för Tiere: Überlegungen zu Einfachen MoralischenMaschinen Inside-it.ch, , http://www.insideit.ch/articles/34646, December 4; Kopf, M., (1994) Ein Beitrag Zur Modellbasierten Adaptiven Fahrerunterstötzung för das Fahren Auf Deutschen Autobahnen, , PhD thesis VDI-Verlag; Lorenz, L.M., (2014) Entwicklung und Bewertung Aufmerksamkeitslenkender Warn-und Informationskonzepte för Fahrerassistenzsysteme: Aufmerksamkeitssteuerung in der Fröhen Phase Kritischer Verkehrssituationen, , PhD thesis, TU Mönchen, Mönchen; Pluta, W., (2017) EU-Projekt Timon Vernetzt Fußgänger, Autofahrer und Radler, Golem, , https://www.golem.de/news/verkehrssicherheit-eu-projekt-Timon-vernetztfussgaenger-Autofahrer-und-radler-1709-129669.html, September 1; Bendel, O., LADYBIRD the Animal-friendly Robot Vacuumcleaner, pp. 2-6. , The 2017 AAAI Spring Symposium Series, AAAI Press; Hueber, J., (2013) Wir Sehen Farbe-das Können Sensoren Auch! SENSOR MAGAZIN, 1, pp. 8-11; Brisevac, A., Calcagno, S., Stierli, B., (2017) LADYBIRD Projektdokumentation, , School of Business FHNW; Bendel, O., (2018) Das LADYBIRD-Projekt Handbuch Maschinenethik, , O. Bendel (Ed) Springer Reference Geisteswissenschaften, Springer VS; Bendel, O., Service robots in public spaces (2017) Telepolis, , https://www.heise.de/tp/features/Service-Robotsin-Public-Spaces-3754173.html, June 25; Zhou, N., Volvo admits its self-driving cars are confused by kangaroos (2017) The Guardian, , https://www.theguardian.com/technology/2017/jul/01/volvoadmits-its-self-driving-cars-Are-confused-by-kangaroos, July 1; Wimmer, T., Israel, M., Haschberger, P., Rehkitzrettung mit dem Fliegenden Wildretter: Erfahrungen der ersten Feldeinsätze (2013) Bornimer Agrartechnische Berichte, 81, pp. 85-95; Binder, U., (2017) Der Bauer Wird Digitalisiert, , https://www.swisscom.ch/de/storys/technologie/smarte-landwirtschaft.html, Swisscom October 11; Federle, S., Radar soll Zugvögel schötzen Tierwelt, (10), pp. 22-23. , March 5 2014},
document_type={Article},
source={Scopus},
}

@ARTICLE{Béla20188,
author={Béla, P.},
title={The layers of human existence and the questions of robot ethics [Az emberi lét rétegei és a robotetika kérdései]},
journal={Informacios Tarsadalom},
year={2018},
volume={18},
number={3-4},
pages={8-24},
doi={10.22503/inftars.XVIII.2018.3-4.1},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064346680&doi=10.22503%2finftars.XVIII.2018.3-4.1&partnerID=40&md5=ed9523811e6b3957f75ceefa7d75d6f6},
abstract={The paper seeks to analyse the new ethical dilemmas that arise in the social contexts of the robot world. It is based on the theoretical foundation of the ontology of Nicolai Hartmann, which finds the place of ever-increasing artificial intelligence among the layers of being of reality. From this starting point, it examines the summative studies of the massive robotics analysis already developed in English and looks at their correction that needs to be made in the theory of four-layered human existence in comparison with the analyses so far. © 2018 Infonia. All rights reserved.},
author_keywords={Artificial intelligence;  Evolution;  Nicolai Hartmann;  Ontology},
references={Abney, K., Robotics, ethical theory and metaethics: A guide for the perplexed (2011) Robotethics, pp. 35-54. , Patrick Lin, Keith Abney and George A. Bekey (eds.) The MIT Press, Cambridge-Massachusets-London; Allen, C., Wallach, W., Moral Machines: Contradiction in term or abdication of human responsibility? (2011) Robotethics, pp. 55-68. , Patrick Lin, Keith Abney and George A. Bekey (eds.) The MIT Press, Cambridge-Massachusets-London; DiGiovanna, J., Artificial identity (2017) Robot Ethics 2.0, pp. 307-321. , Patrick Lin, Ryan Jenkins and Keith Abney (eds.) Oxford University Press, New York; Doherty Jason, P., (2016) AI Civil Rights: Addressing Artificial Intelligence and Robot Rights, , Kindle Edition; Ford, M., (2016) the Rise of Robots: Technology and the Threat of a Jobless Future, , Basic Books; Galliott, J., the unabomber on robots (2017) Robot Ethics 2.0, pp. 369-385. , Patrick Lin, Ryan Jenkins and Keith Abney (eds.) Oxford University Press, New York; Hartmann, N., (1962) Das Problem des Geistigen Seins. Zur Grundlegung der Geschichtsphilosophie und der Geisteswissenschaften, , Walter de Gruyter Verlag, Berlin; Hegel, G.W.F., (1971) A Jogfilozófia Alapjai, , Akadémia Kiadó, Budpest; Henschke, A., the internet of things and dual layers of ethical concern (2017) Robot Ethics 2.0, pp. 229-243. , Patrick Lin, Ryan Jenkins and Keith Abney (eds.) Oxford University Press, New York; Kaku, M., (2015) Az Elme Jövoje, , Akkord Kiadó, Budapest; Kelly, K., (2014) the Inevitable: Understanding the 12 Technological Forces that Shape our Future, , Penguin Books, New York; Klinewicz, M., Challenges to engineering moral reasoners (2017) Robot Ethics 2.0, pp. 244-257. , Patrick Lin, Ryan Jenkins and Keith Abney (eds.) Oxford University Press, New York; Loh, W., Loh, J., Autonomy and responsibility in hybrid system (2017) Robot Ethics 2.0, pp. 35-50. , Patrick Lin, Ryan Jenkins and Keith Abney (eds.) Oxford University Press, New York; Luhmann, N., (1994) Liebe Als Passion: Zur Codierung von Intimität, , Suhrkamp, Frankfurt am Main; Béla, P., (2010) Morálelméleti Vizsgálódások, , Kairosz, Budapest; Béla, P., Mesterséges intelligencia: Egy új létréteg kialakulása? (2017) Információs Társadalom, 17, p. 4. , http://dx.doi.org/10.22503/inftars.XVII.2017.4.3, évf szám, 39-53. old; Splengler, O., (1995) A Nyugat Alkonya. A Világtörténelem Morfológiájának Körvonalai, 1-2. , kötet, Európa Könyvkiadó, Budapest; Talbot, B., Jenkins, R., Purves, D., When robots should do the wrong thing (2017) Robot Ethics 2.0, pp. 258-273. , Patrick Lin, Ryan Jenkins and Keith Abney (eds.) Oxford University Press, New York; Vallor, S., Bekey, G.A., Artificial intelligfnce and the ethics of self-learning robots (2017) Robot Ethics 2.0, pp. 338-353. , Patrick Lin, Ryan Jenkins and Keith Abney (eds.) Oxford University Press, New York; White Trevor, N., Baum, S.D., Liability for present and future robotics technology (2017) Robot Ethics 2.0, pp. 66-79. , Patrick Lin, Ryan Jenkins and Keith Abney (eds.) Oxford University Press, New York; Zoller, D., Skilled perception, authenticity, and the case against automation (2017) Robot Ethics 2.0, pp. 55-68. , Patrick Lin, Ryan Jenkins and Keith Abney (eds.) Oxford University Press, New York},
document_type={Article},
source={Scopus},
}

@ARTICLE{Chakraborty201849,
author={Chakraborty, S.},
title={Can humanoid robots be moral?},
journal={Ethics in Science and Environmental Politics},
year={2018},
volume={18},
pages={49-60},
doi={10.3354/ESEP00186},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062352745&doi=10.3354%2fESEP00186&partnerID=40&md5=92211a75943de429488f349905d8db49},
abstract={The concept of morality underpins the moral responsibility that not only depends on the outward practices (or 'output', in the case of humanoid robots) of the agents but on the internal attitudes ('input') that rational and responsible intentioned beings generate. The primary question that has initiated extensive debate, i.e. 'Can humanoid robots be moral?', stems from the normative outlook where morality includes human conscience and socio-linguistic background. This paper advances the thesis that the conceptions of morality and creativity interplay with linguistic human beings instead of non-linguistic humanoid robots, as humanoid robots are indeed docile automata that cannot be responsible for their actions. To eradicate human ethics in order to make way for humanoid robot ethics highlights the moral actions and adequacy that hinges the myth of creative agency and self-dependency, which a humanoid robot can scarcely express. © The author 2018.},
author_keywords={Artificial intelligence;  Conscience;  Consciousness;  Docility;  Humanoid robots;  Morality;  Responsibility},
keywords={artificial intelligence;  conceptual framework;  ethics;  morality;  robotics},
references={Arkin, R.C., (1998) Behavior-based robotics, , MIT Press, Cambridge, MA; Bentham, J., (2000) An introduction to the principles of morals and legislation, , Batoche Books, Kitchener; Bostrom, N., (2016) Superintelligence, , Oxford University Press, Oxford; Chakraborty, S., Understanding moral values: subjective or objective (2017) Morality, objectivity and defeasibility, pp. 93-103. , In: Majhi RM, Patra BP, Sahoo BC (eds). Concept Publishing Company, New Delhi; Chakraborty, S., The fact/value dichotomy: revisiting Putnam and Habermas (2018) Philosophia, , (in press); Chomsky, N., Explanatory models in linguistics (1962) Logic methodology and philosophy of science, pp. 528-550. , In: Nagel E, Suppes P, Tarski A (eds). Stanford University Press, Stanford, CA; Chomsky, N., (1980) Rules and representations, , Basil Blackwell, Oxford; Davidson, D., (1984) Inquiries into truth and interpretation, , Oxford University Press, New York, NY; Davidson, D., (2001) Subjective, intersubjective, objective, , Clarendon Press, Oxford; Dennett, D., (2012) Content and consciousness, , Routledge, London; Fodor, J., (1987) Psychosemantics: the problem of meaning in the philosophy of mind, , The MIT Press, Cambridge, MA; Graham, L.R., (1981) Between science and values, , Columbia University Press, New York, NY; Haldane, E.S., Ross, G.R.T., (1934) The philosophical works of Descartes, Vol 1, , Cambridge University Press, Cambridge; Harris, Z., (1951) Structural linguistics, , University of Chicago Press, Chicago, IL; Mackie, J.L., (1977) Ethics: inventing right and wrong, , Penguin Books, London; McCarthy, J., Minsky, M.L., A proposal for the Dartmouth summer research project on artificial intelligence (2006) AI Mag, 27, pp. 12-14; Nagel, T., (2013) Moral questions, , Cambridge University Press, New Delhi; Niv, Y., Reinforcement learning in the brain (2009) J Math Psychol, 53, pp. 139-154; Pinker, S., (1997) How the mind works, , Penguin Books, New York, NY; Putnam, H., (1979) Mind, language and reality, , Philosophical Papers Vol 2. Cambridge University Press, Cambridge; Putnam, H., (1992) Renewing philosophy, , Harvard University Press, Cambridge, MA; Putnam, H., (2002) The collapse of the fact/value dichotomy, , Harvard University Press, Cambridge, MA; Putnam, H., What is innate and why: comments on the debate The philosophy of mind: classical problems/contemporary issues, (2013), pp. 757-771. , In: Beakley B, Ludlow P (eds). New Phil Learning Private Limited, Delhi; Rawls, J., (1971) A theory of justice, , Harvard University Press, Cambridge, MA; Ruse, M., (1986) Taking Darwin seriously, , Basil Blackwell Publishing, Oxford; Russell, S., Rationality and intelligence' (1997) Artif Intell, 94, pp. 57-77; Russell, S., Norvig, P., (2016) Artificial intelligence: a modern approach, 3rd edn, , Pearson, Delhi; Scassellati, B., Theory of mind for a humanoid robot (2002) Autonomous Robots, 12, pp. 13-24; Searle, J.R., Minds, brains, and programs (1980) Behav Brain Sci, 3, pp. 417-457; Singer, P., (1979) Practical ethics, , Cambridge University Press, Cambridge; Stove, D., On Hume's is-ought thesis (1978) Hume Stud, 4, pp. 64-72; Tanimoto, S., (1987) The elements of artificial intelligence, , Computer Science Press, Rockville, MD; Turing, A.M., Computing machinery and intelligence (1950) Mind, 59, pp. 433-460; Wilczek, F., Three observations on artificial intelligence (2015) What do you think about machines that think?, pp. 121-123. , In: Brockman J (ed) Harper Perennial, New York, NY; Wilson, R.A., Keil, F.C., (1999) The MIT encyclopedia of the cognitive sciences, , The MIT Press, Cambridge, MA; Winston, P.H., (1992) Artificial intelligence, , Addison-Wesley, Boston, MA; Zimmerman, M.J., Value and normativity (2015) The Oxford handbook of value theory, pp. 13-29. , In: Hirose I, Olson J (eds). Oxford University Press, Oxford},
document_type={Article},
source={Scopus},
}

@ARTICLE{Baniasadi2018481,
author={Baniasadi, Z. and Parent, X. and Max, C. and Cramer, M.},
title={A model for regulating of ethical preferences in machine ethics},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10901 LNCS},
pages={481-506},
doi={10.1007/978-3-319-91238-7_39},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061529235&doi=10.1007%2f978-3-319-91238-7_39&partnerID=40&md5=b3e007b395251433c9a785b45013961f},
abstract={Relying upon machine intelligence with reductions in the supervision of human beings, requires us to be able to count on a certain level of ethical behavior from it. Formalizing ethical theories is one of the plausible ways to add ethical dimensions to machines. Rule-based and consequence-based ethical theories are proper candidates for Machine Ethics. It is debatable that methodologies for each ethical theory separately might result in an action that is not always justifiable by human values. This inspires us to combine the reasoning procedure of two ethical theories, deontology and utilitarianism, in a utilitarian-based deontic logic which is an extension of STIT (Seeing To It That) logic. We keep the knowledge domain regarding the methodology in a knowledge base system called IDP. IDP supports inferences to examine and evaluate the process of ethical decision making in our formalization. To validate our proposed methodology we perform a Case Study for some real scenarios in the domain of robotics and automatous agents. © Springer International Publishing AG, part of Springer Nature 2018.},
keywords={Decision making;  Knowledge based systems;  Philosophical aspects, Ethical behavior;  Ethical decision making;  Ethical preference;  Ethical theories;  Knowledge base system;  Knowledge domains;  Machine intelligence;  Reasoning procedures, Human computer interaction},
references={Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , Oxford Scholarship Online, Oxford; Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge University Press, Cambridge; Arkoudas, K., Bringsjord, S., Bello, P., Toward ethical robots via mechanized deontic logic (2005) AAAI Fall Symposium on Machine Ethics; Balbiani, P., Herzig, A., Troquard, N., Alternative axiomatics and complexity of deliberative STIT theories (2008) J. Philos. Log., 37 (4), pp. 387-406; Belnap, N.D., (2001) Facing the Future: Agents and Choices in Our Indeterminist World, , Oxford University Press, Oxford; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intell. Syst., 21 (4), pp. 38-44; Broersen, J., Deontic epistemic stit logic distinguishing modes of mens rea (2011) J. Appl. Log., 9 (2), pp. 127-152; Denecker, M., Ternovska, E., A logic of nonmonotone inductive definitions (2008) ACM Trans. Comput. Log. (TOCL), 9 (2), p. 14; Denecker, M., Vennekens, J., Building a knowledge base system for an integration of logic programming and classical logic (2008) ICLP 2008. LNCS, 5366, pp. 71-76. , https://doi.org/10.1007/978-3-540-89982-212, Garcia de la Banda, M., Pontelli, E. (eds.), Springer, Heidelberg; Gabbay, D., Horty, J., Parent, X., van der Meyden, R., van der Torre, L., (2013) Handbook of Deontic Logic and Normative Systems; Goble, L., Multiplex semantics for deontic logic (2000) Nord. J. Philos. Log., 5 (2), pp. 113-134; Goodall, N., Ethical decision making during automated vehicle crashes (2014) Transp. Res. Rec. J Transp. Res. Board, (2424), pp. 58-65; Goodall, N.J., Machine ethics and automated vehicles (2014) Road Vehicle Automation. LNM, pp. 93-102. , https://doi.org/10.1007/978-3-319-05990-79, Meyer, G., Beiker, S. (eds.), Springer, Cham; Harsanyi, J.C., Cardinal welfare, individualistic ethics, and interpersonal comparisons of utility (1976) Essays on Ethics, Social Behavior, and Scientific Explanation, pp. 6-23. , https://doi.org/10.1007/978-94-010-9327-92, Harsanyi, J.C. (ed.), Springer, Dordrecht; Herzig, A., Schwarzentruber, F., Properties of logics of individual and group agency (2008) Adv. Modal Log., 7, pp. 133-149; Horty, J., (2001) Agency and Deontic Logic, , Oxford University Press, New York; Horty, J., Belnap, N., The deliberative stit: A study of action, omission, ability, and obligation (1995) J. Philos. Log., 24, pp. 583-644; Johnson, D.G., Computer ethics (1985) The Philosophy of Computing and Information, p. 65; Lang, J., van der Torre, L., From belief change to preference change (2008) ECAI, 178, pp. 351-355; Lorini, E., Temporal logic and its application to normative reasoning (2013) J. Appl. Non-Class. Log., 23 (4), pp. 372-399; Lorini, E., Sartor, G., A STIT logic analysis of social influence (2014) Proceedings of the 2014 International Conference on Autonomous Agents and Multi-Agent Systems, pp. 885-892. , International Foundation for Autonomous Agents and Multiagent Systems; Mariën, M., Wittocx, J., Denecker, M., The IDP framework for declarative problem solving (2006) Search and Logic: Answer Set Programming and SAT, pp. 19-34; Moor, J.M., The nature, importance, and difficulty of machine ethics (2006) IEEE Intell. Syst., 21 (4), pp. 18-21; Prior, A.N., (1967) Past, Present and Future, 154. , Clarendon Press, Oxford; Shafer-Landau, R., (2012) Ethical Theory: An Anthology, 13. , Wiley, West Sussex; Tzafestas, S.G., Roboethics: A branch of applied ethics (2016) Roboethics: A Navigating Overview. ISCASE, 79, pp. 65-79. , https://doi.org/10.1007/978-3-319-21714-75, Springer, Cham; Wittocx, J., de Cat, B., Denecker, M., The IDP system (2010) Proceedings of the 22Nd Benelux Conference on Artificial Intelligence; Wooldridge, M., Computationally grounded theories of agency (2000) 2000 Proceedings of the Fourth International Conference on Multiagent Systems, pp. 13-20. , IEEE; Yin, R.K., (2003) Case Study Research Design and Methods. Applied Social Research Methods Series, 5. , 3rd edn. Sage Publications, London},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Funk201875,
author={Funk, M. and Dieber, B.},
title={We are living in a social submarine! Children are still the better adults},
journal={Frontiers in Artificial Intelligence and Applications},
year={2018},
volume={311},
pages={75-87},
doi={10.3233/978-1-61499-931-7-75},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058229650&doi=10.3233%2f978-1-61499-931-7-75&partnerID=40&md5=f08857b757b0f2a50b243572b1467b3c},
abstract={In three sections some interactions at the workshop “YuMi in Action! Ethics and Engineering as Transdisciplinary Robotics Performance” and related later reflections are summarized. The primary emphasis is to illustrate what transdisciplinarity is and how transdisciplinarity could work as a certain form of scientific cooperation. Therefore four principles of biomedical ethics are applied to human robot interactions just like the VDI codex of engineering ethics. Methodological fundamentals of transdisciplinary cooperation are discussed related to concrete medical applications of the robot “YuMi.” In the last section the question of transdisciplinary research is (experimentally) related to the metaphor of “social submarines” and concrete practical issues that endanger real transdisciplinarity. Here we close with the question whether children´s more or less unbiased imagination could be seen as a requirement of real transdisciplinarity. © 2018 The authors and IOS Press. All rights reserved.},
author_keywords={Epistemology;  Human-machine-interaction;  Responsibility;  Robot ethics;  Safety;  Security;  Social robots;  Transdisciplinary methodology},
keywords={Accident prevention;  Concretes;  Human computer interaction;  Man machine systems;  Medical applications;  Network security;  Philosophical aspects;  Submarines, Epistemology;  Human machine interaction;  Responsibility;  Robot ethics;  Security;  Social robots;  Transdisciplinary methodology, Human robot interaction},
references={Funk, M., Reichl, P., Dieber, B., Bismarck 4.0': A cross-disciplinary thought experiment on cyber pacifism (Workshop 9) (2018) Robophilosophy 2018: Envisioning Robots in Society – Politics, Power and Public Space. Proceedings of Robophilosohy 2018 / TRANSOR 2018, , M. Coeckelbergh, J. Loh, M. Funk, J. Seibt & M. Nørskov eds, IOS Press, Amsterdam a.o; Seibt, J., Introduction (2014) Sociable Robots and The Future of Social Relations. Proceedings of Robo Philosophy 2014. (Frontiers in Artificial Intelligence and Applications, 273, pp. vii viii. , J. Seibt, R. Hakli & M. Nørskov eds, IOS Press, Amsterdam a.o; Nørskov, M., Editor´s Preface (2016) Social Robots. Boundaries, Potential, Challenges, pp. xv xxii. , M. Nørskov (ed), Ashgate, Farnham & Burlington; Nørskov, M., (2016) Social Robots. Boundaries, Potential, Challenges, , ed, Ashgate, Farnham & Burlington; Seibt, J., Hakli, R., Nørskov, M., Sociable robots and the future of social relations (2014) Proceedings of Robo Philosophy 2014. (Frontiers in Artificial Intelligence and Applications, p. 273. , eds, IOS Press, Amsterdam a.o; Seibt, J., Nørskov, M., Andersen, S.S., What social robots can and should do (2016) Proceedings of Robophilosophy 2016 / TRANSOR 2016. (Frontiers in Artificial Intelligence and Applications, p. 290. , eds, IOS Press, Amsterdam a.o; Decker, M., Who is taking over? Technology assessment of autonomous (service) robots (2014) Robotics in Germany and Japan. Philosophical and Technical Perspectives, pp. 91-110. , M. Funk & B. Irrgang eds, Peter Lang, Frankfurt am Main a.o; Mittelstraß, J., (2003) Transdisziplinarität – Wissenschaftliche Zukunft und Institutionelle Wirklichkeit, , Konstanzer Universitätsreden, UVK, Konstanz; Bergmann, M., (2010) Methoden Transdisziplinärer Forschung. Ein Überblick mit Anwendungsbeispielen, , Campus, Frankfurt a.M. & New York; Pohl, Ch., Hirsch Hadorn, G., (2006) Gestaltungsprinzipien Für Die Transdisziplinäre Forschung, , Ein Beitrag des td-net, Oekom, München; Schmidt, J.C., Schwerpunktthema Method(olog)ische Fragen der Inter- Und Transdisziplinarität – Wege zu einer praxisstützenden Interdisziplinaritätsforschung (2005) Technikfolgenabschätzung. Theorie und Praxis. Nr., 2, pp. 4-74. , 14. Jg., Juni; Goodrich, M.S., Human-robot interaction: A survey (2007) Foundations and Trends in Human-Computer Interaction, pp. 203-275; Velik, R., Yahjanejad, S., Dieber, B., Brandstötter, M., Paar, G., Paletta, L., Hofbaur, M., A step forward in human-robot collaboration. The project Collrob (2016) Proceedings of The OAGM & ARW Joint Workshop on Computer Vision and Robotics; Kirschner, D., Velik, R., Yahyanejad, S., Brandstötter, M., Hofbaur, M., Yumi, Come and play with me! A collaborative robot for piecing together a tangram puzzle (2016) Interactive Collaborative Robotics, pp. 243-251. , A. Ronzhin, G. Rigoll, & R. Meshcheryakov eds, Springer; Nevejans, N., Directorate-general for internal policies. Policy department c: Citizens´ rights and constitutional affairs (2016) LEGAL AFFAIRS. EUROPEAN CIVIL LAW RULES IN ROBOTICS, , http://www.europarl.europa.eu/RegData/etudes/STUD/2016/571379/IPOL_STU(2016)571379_EN.pdf, Oct. 15.04.2018; Salem, M., Lakatos, G., Amirabdollahian, F., Dautenhahn, K., Towards safe and trustworthy social robots: Ethical challenges and practical issues (2015) ICSR, pp. 584-593; (2002) Fundamentals of Engineering Ethics, , https://www.vdi.de/fileadmin/media/content/hg/17.pdf, ed, VDI, Düsseldorf, 15.4.2018; Hubig, C., (2007) Die Kunst Des Möglichen II. Ethik Der Technik Als Provisorische Moral, , transcript, Bielefeld; Beauchamp, T.L., Childress, J.F., (2001) Principles of Biomedical Ethics, , Oxford University Press, Oxford; Majo, G., (2012) Mittelpunkt Mensch: Ethik in Der Medizin, , Ein Lehrbuch, Schattauer, Stuttgart; Pollock, A., Physical rehabilitation approaches for the recovery of function and mobility following stroke (Review) (2014) Cochrane Database of Systematic Reviews, (4). , http://cochranelibrarywiley.com/doi/10.1002/14651858.CD001920.pub3/epdf, 04.07.2018; Mori, M., (2012) The Uncanny Valley: The Original Essay by Masahiro Mori, , https://spectrum.ieee.org/automaton/robotics/humanoids/the-uncanny-valley, Translated by Karl F. MacDorman and Norri Kageki, IEEE Spectrum, June 12, 04.07.2018; Valadao, C.T., Robotics as a tool for physiotherapy and rehabilitation sessions (2015) IFAC-PapersOnLine, 48 (19), pp. 148-153; Seibt, J., Towards an ontology of simulated social interaction: Varieties of the “as if” for robots and humans Sociality and Normativity for Robots. Studies in The Philosophy of Sociality, , R. Hakli R. & J. Seibt eds, Springer, Cham; Kirschner, D., Schlotzhauer, A., Brandstötter, M., Hofbaur, M., Validation of relevant parameters of sensitive manipulators for human-robot collaboration (2017) International Conference on Robotics in Alpe-Adria Danube Region, pp. 242-252; Qualitätsmerkmal “Technische Sicherheit”. Eine Denkschrift Des Vereins Deutscher Ingenieure, , https://www.vdi.de/fileadmin/vdi_de/redakteur_dateien/gbg_dateien/Qualit%C3%A4tsmerkmal%20Technische%20Sicherheit%20-%20%20deutsch.pdf, ed, Düsseldorf 05.07.2018; Kornwachs, K., Von Maschinenherzen, Kamelen und einem Diskurs der zwei Kulturen (2015) Transdisziplinär‘,Interkulturell‘Technikphilosophie Nach Der Akademischen Kleinstaaterei, pp. 209-227. , M. Funk (ed), Königshausen und Neumann, Würzburg; Serholt, S., Students´ normative perspectives on classroom robots (2016) What Social Robots Can and Should Do. Proceedings of Robophilosophy 2016 / TRANSOR 2016. (Frontiers in Artificial Intelligence and Applications, 290, pp. 240-251. , J. Seibt, M. Nørskov & S. S. Andersen eds, IOS Press, Amsterdam a.o; Dreyfus, H., (1972) What Computers Can´T Do: The Limits of Artificial Intelligence, , MIT Press, New York; Weizenbaum, J., (1976) Computer Power and Human Reason. From Judgement to Calculation, , W.H. Freeman and Company, N; Janich, P., Between innovative forms of technology and human autonomy: Possibilities and limitations of the technical substitution of human work Robo- and Informationethics. Some Fundamentals. Hermeneutics and Anthropology, 3, pp. 211-230. , M. Decker & M. Gutmann (eds, LIT Verlag, Berlin a.o.); Wallach, W., Allen, C., (2009) Moral Machines. Teaching Robots Right from Wrong., , Oxford University Press, New York; Ferguson, E.S., (1992) Engineering and The Mind´S Eye, , MIT Press, Cambridge, MA},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={Frontiers in Artificial Intelligence and Applications},
journal={Frontiers in Artificial Intelligence and Applications},
year={2018},
volume={311},
page_count={402},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058220627&partnerID=40&md5=4f8362f560f01356d2f7c8ddf547a569},
abstract={The proceedings contain 38 papers. The topics discussed include: ethics in action - considerations on autonomous and intelligent systems; studies on interactive robots; the precariat in platform capitalism; three challenges of AI for society (and how (not) to address them); the EU perspective on robotics and AI: economic, research, and policy aspects; the moral, legal, and economic hazard of anthropomorphizing robots and AI; service robots from the perspectives of information and machine ethics; on the pertinence of social practices for social robotics; and we are living in a social submarine! children are still the better adults.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Funk2018369,
author={Funk, M. and Seibt, J. and Coeckelbergh, M.},
title={Why do/should we build robots?—Summary of a plenary discussion session},
journal={Frontiers in Artificial Intelligence and Applications},
year={2018},
volume={311},
pages={369-384},
doi={10.3233/978-1-61499-931-7-369},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058218293&doi=10.3233%2f978-1-61499-931-7-369&partnerID=40&md5=ea9f57af8d65edae14438fe77651410f},
abstract={This article is a summary of a joint discussion session that was held impromptu at the RP 2018 conference. The session addressed the two main questions: “Why do we build robots, why should we build robots?” along a series of queries, which were directly posed to, and discussed by, the conference plenum (the audience of a large lecture hall with about 150-200 participants). The session produced concrete answers, but also many further questions, pointers, and useful trajectories. In this summary we try to collect the highlights of this spontaneous yet well-focused event. We reconstruct nine answers to the question of why we do build robots, and nine answers to the question of why we should or should not build robots. In addition, we report on more general and fundamental observations concerning special normative tasks arising with social robotics. We conclude with some reflections on the idea and format of this impromptu session, as a tool for future conferences. © 2018 The authors and IOS Press. All rights reserved.},
author_keywords={Epistemology;  Robot ethics;  Robotics;  Robots;  Social robots},
keywords={Robotics, Epistemology;  Large lecture;  Robot ethics;  Social robotics;  Social robots, Robots},
references={Marsiske, H.-A., Robo-philosophy: Warum bauen wir Roboter? (2018) Heise Online, 16. , https://www.heise.de/newsticker/meldung/Robo-philosophy-Warum-bauen-wir-Roboter-3972203.html, 02. accessed 08.07.2018; Breazeal, C.L., (2004) Designing Sociable Robots, , MIT Press; Breazeal, C.L., Role of expressive behaviour for robots that learn from people (2009) Philosophical Transactions of The Royal Society of London B: Biological Sciences, 364 (1535), pp. 3527-3538; Jozuka, E., The man building robots to better understand humans (2015) Motherboard, , https://motherboard.vice.com/en_us/article/jp5n73/the-man-building-robots-to-better-understand-humans, 15.04. accessed 06.07.2018; Brundage, M., (2018) The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation, , https://arxiv.org/ftp/arxiv/papers/1802/1802.07228.pdf, accessed 08.07.2018},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Shimoyama2018293,
author={Shimoyama, H.},
title={A deconstruction of robot ethics through the concept of the ‘robomot’},
journal={Frontiers in Artificial Intelligence and Applications},
year={2018},
volume={311},
pages={293-301},
doi={10.3233/978-1-61499-931-7-293},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058214547&doi=10.3233%2f978-1-61499-931-7-293&partnerID=40&md5=58f22d1c052de7d7ff2844c3cc71a3a2},
abstract={This paper notes that the discipline of robot ethics has a structural problem and proposes a new concept to address this: the ‘Robomot,’ based on the philosophy of Jacques Derrida. In particular, this article considers the problem of the exclusion and inclusion of others, and that of how to talk about robots. The article deconstructs the discipline of robot ethics and determines the ‘auto-immune’ workings of robots and machines. Using language theory like the speech-act, the article examines robots as ‘the Other. © 2018 The authors and IOS Press. All rights reserved.},
author_keywords={Deconstruction;  Invention;  Robomot;  Robot ethics},
keywords={Patents and inventions;  Philosophical aspects, Deconstruction;  Derrida;  Language theory;  Robomot;  Robot ethics;  Speech acts;  Structural problems, Robots},
references={Gunkel, D.J., (2012) The Machine Question: Critical Perspectives on AI, Robots, and Ethics, , MIT Press; Derrida, J., (2006) L'Animal Que Donc Je Suis, , Galilée; Derrida, J., (2010) Séminaire: La Bête Et Le Souverain, 1: 2001-2002, Galilée, 2008, and Séminaire: La Bête Et Le Souverain, 2, pp. 2002-2003. , Galilée; Llored, P., Derrida, J., (2012) Politique Et Éthique De L'Animalité, , Sils Maria; Deleuze, G., (1968) Différence Et Répétition, , Presses Universitaires de France; Deleuze, G., (2009) Logique Du Sens, , Les Éditions de Minuit; Derrida, J., Savoir, (2001) Suivi De Le Siècle, , et le Pardon, Seuil; Ruyer, R., (1967) La Cybernétique Et L'Origine De L'Information, , Flammarion; (1990) Limited Inc, , Jacques Derrida, Galilée; De Man, P., (1979) Allegories of Reading: Figural Language in Rousseau, , Nietzsche, Rilke, and Proust, Yale University Press; Okada, M., Robo, W., (2012) Igakushoin; Derrida, J., (2001) Papier Machine, , Galilée; Derrida, J., Soussana, G., Nouss, A., (2001) Dire L'Événement, Est-Ce Possible?: Séminaire De Montréal, pour Jacques Derrida, , L'harmattan; Austin, J., (1962) How to Do Things with Words, , Harvard University Press; Bergson, H., (1970) Ouevers, Puf},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Pierce2018,
author={Pierce, B.},
title={Are the notions of agency and responsibility relevant to questions about machine ethics?},
journal={Proceedings of AISB Annual Convention 2018},
year={2018},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056886044&partnerID=40&md5=e027eb6f4547abb86f95ee6cdf01c347},
abstract={Discussions of machine ethics that focus on the capacity of artificial agents to act autonomously and on whether such agents should be held morally responsible for their actions should be abandoned in favour of an approach that prioritises concerns about whether intelligent machines might instead qualify as moral patients. When there is no agreement on whether human agents have free will or moral responsibility, or what this consists in, introducing such theory-laden notions is unhelpful, especially when the avoidance of suffering and the correct ascription of rights are recognised as being more important than who can or should be held accountable when harm is done. I set aside the notion of (moral) agency, focusing instead on the conditions necessary for moral patiency, arguing that this depends on the capacity for conscious affective experience and rejecting functional accounts of emotion that fail to incorporate the function of the qualitative character of affective experience. © Proceedings of AISB Annual Convention 2018. All rights reserved.},
keywords={Philosophical aspects, Artificial agents;  Free Will;  Human agent;  Intelligent machine;  Moral responsibility, Autonomous agents},
references={Arbib, M., Beware the passionate robot‘ (2005) Who Needs Emotions? The Brain Meets The Robot New York, pp. 333-383. , Fellous, J-M & Arbib, M. (Eds.) Oxford University Press; Csibra, G., Gergely, G., Bíró, S., Koós, O., Brockbank, M., Goal attribution without agency cues: The perception of pure reason‘in infancy (1999) Cognition, 72, pp. 237-267; Dennett, D., (1984) Elbow Room, , Oxford: Clarendon Press; Hameroff, S.R., Penrose, R., Orchestrated Reduction Of Quantum Coherence In Brain Microtubules: A Model For Consciousness? (1996) Toward A Science of Consciousness - The First Tucson Discussions and Debates, pp. 507-540. , Hameroff, S.R., Kaszniak, A.W. & Scott, A.C. Eds, Cambridge, Massachusetts: MIT Press; Harnad, S., The symbol grounding problem (1990) Physica, D42, pp. 335-346; Pierce, B., Is the concept of rational agency coherent? (2006) Philosophical Writings, 33, pp. 5-18; Paglieri, F., Is the function of consciousness to act as an interface? (2012) Consciousness in Interaction: The Role of the Natural and Social Context in Shaping Consciousness, pp. 73-88. , Amsterdam: John Benjamins; How Are Robots‘Reasons for Action Grounded, , under review; Sloman, A., Chrisley, R., Scheutz, M., The architectural basis of affective states and processes (2005) Who Needs Emotions? The Brain Meets The Robot New York, pp. 203-244. , Fellous, J-M & Arbib, M. (Eds.) Oxford University Press},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Voiculescu2018,
author={Voiculescu, A.},
title={Runaway concepts for robotics and AI: Law, technology and the posthuman},
journal={Proceedings of AISB Annual Convention 2018},
year={2018},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056830319&partnerID=40&md5=b19af9e8b65601b1d1a653f60ffa8bca},
author_keywords={Agency;  Electronic personality;  Legal agency;  Legal responsibility;  Machine ethics;  Moral agency;  Personhood;  Responsibility},
references={Anderson, S.L., Anderson, M., A prima facie duty approach to machine ethics: Machine learning of features of ethical dilemmas, prima facie duties, and decision principles through a dialogue with ethicists (2011) Machine Ethics, , Michael Anderson and Susan Leigh Anderson (eds.), Cambridge Univ Press; Dyschkant, A., (2015) Legal Personhood: How We Are Getting It Wrong, , 2015 University of Illinois Law Review 2075; Fagundes, D., Note, what we talk about when we talk about persons: The language of a legal fiction (2001) Harvard Law Review, 114, p. 1745; Kapica, S.S., I don’t feel like a copy: Posthuman legal personhood and caprica (2014) 23 Griffith Law Review, p. 612; Koops, B.-J., Hildebrandt, M., Jaquet-Chiffelle, D.-O., Bridging the accountability gap: Rights for new entities in the information society? (2010) Minnesota Journal of Law, Science & Techonology, 11 (2); May, L., (2001) The Morality of Groups, , Reprint edition, University of Notre Dame Press; Zylinska, J., Is there life in cybernetics? designing a post-humanist bioethics’ in Rosi Braidotti (2009) Deleuze and Law: Forensic Futures, , Claire Colebrook and Patrick Hanafin (eds.), 2009th edn, AIAA; Braidotti, R., Colebrook, C., Hanafin, P., (2009) Deleuze and Law: Forensic Futures, , AIAA 2009; Copp, D., The collective moral autonomy thesis (2007) Journal of Social Philosophy, 38, p. 369; Ludwig, K., The argument from normative autonomy for collective agents (2007) Journal of Social Philosophy, 38, p. 410; Stone, C.D., (2010) ShouldTrees Have Standing?: Law, Morality, and The Environment, , 3 edition, Oxford University Press, USA},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Arnold2018,
author={Arnold, T. and Scheutz, M.},
title={HRI ethics and type-token ambiguity: what kind of robotic identity is most responsible?},
journal={Ethics and Information Technology},
year={2018},
doi={10.1007/s10676-018-9485-1},
note={cited By 0; Article in Press},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056313985&doi=10.1007%2fs10676-018-9485-1&partnerID=40&md5=a409033679ad0529f37e1fac6df9029c},
abstract={This paper addresses ethical challenges posed by a robot acting as both a general type of system and a discrete, particular machine. Using the philosophical distinction between “type” and “token,” we locate type-token ambiguity within a larger field of indefinite robotic identity, which can include networked systems or multiple bodies under a single control system. The paper explores three specific areas where the type-token tension might affect human–robot interaction, including how a robot demonstrates the highly personalized recounting of information, how a robot makes moral appeals and justifies its decisions, and how the possible need for replacement of a particular robot shapes its ongoing role (including how its programming could transfer to a new body platform). We also consider how a robot might regard itself as a replaceable token of a general robotic type and take extraordinary actions on that basis. For human–robot interaction robotic type-token identity is not an ontological problem that has a single solution, but a range of possible interactions that responsible design must take into account, given how people stand to gain and lose from the shifting identities social robots will present. © 2018, Springer Nature B.V.},
author_keywords={Artificial moral agents;  Human–robot interaction;  Robot ethics;  Robotic design},
keywords={Human robot interaction;  Machine design;  Networked control systems;  Philosophical aspects;  Robotics, Larger fields;  Moral agents;  Networked systems;  Ontological problems;  Robot ethics;  Robot interactions;  Robotic design;  Specific areas, Robot programming},
references={Arkin, R.C., Ulam, P., Wagner, A.R., Moral decision making in autonomous systems: Enforcement, moral emotions, dignity, trust, and deception (2012) Proceedings of the IEEE, 100 (3), pp. 571-589; Benjamin, W., Arendt, H., Zohn, H., (1970) Illuminations; Edited and with an Introduction by Hannah Arendt. Translated by Harry Zohn, , London, Cape; Bickhard, M.H., Robot sociality: Genuine or Simulation? (2017) Sociality and normativity for robots, pp. 41-66. , Hakli R, Seibt J, (eds), Springer International Publishing, Cham; Biegler, P., The real costs of making friends with robots (2016) The Age, , http://www.theage.com.au/technology/technology-news/the-real-costs-of-making-friends-with-robots-20161027-gscgbe.html, Retrieved 12, December 2016, from; Breazeal, C.L., (2002) Designing sociable robots, , MIT Press, Cambridge; Briggs, G., Scheutz, M., (2015) Sorry, I can’t Do That: Developing Mechanisms to Appropriately Reject Directives in Human-Robot Interactions, , In 2015 AAAI fall symposium series; Bringsjord, S., A 21st-century ethical hierarchy for robots and persons: EH (2015) A World with Robots. International Conference on Robot Ethics: ICRE, 84, p. 47; Bryson, J.J., Patiency is not a virtue:suggestions for co-constructing an ethical framework including intelligent artefacts (2012) The machine question, pp. 73-77. , Gunkel DJ, Bryson JJ, Torrance S, (eds), Society for the Study of Artificial Intelligence and the Simulation of Behaviour, Birmingham; Caine, K., Sabanovic, S., Carter, M., The effect of monitoring by cameras and robots on the privacy enhancing behaviors of older adults (2012) In 7Th ACM/IEEE International Conference on human–robot Interaction (HRI), pp. 343-350; Calo, R., Robotics and the lessons of Cyberlaw (2015) California Law Review, 103, pp. 2008-2014; Carpenter, J., (2016) Culture and human-robot interaction in militarized spaces: A war story, , Routledge, Abingdon; Demiris, Y., Knowing when to assist: Developmental issues in lifelong assistive robotics (2009) 2009 Annual International Conference of the IEEE Engineering in Medicine and Biology Society, pp. 3357-3360. , IEEE; Draper, H., Sorell, T., Ethical values and social care robots for older people: an international qualitative study (2016) Ethics and Information Technology, 19 (1), pp. 49-68; Farmer, H., Tsakiris, M., Touching hands: A neurocognitive review of intersubjective touch (2013) The hand, an organ of the mind: What the manual tells the mental, p. 103. , Radman Z, (ed), MIT Press, Cambridge; Friedmankahn, B., Hagman, J., Jr., Hardware companions? What online AIBO discussion forums reveal about the human-robotic relationship (2003) Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 273-280. , New York, ACM; Ju, W., The design of implicit interactions (2015) Synthesis Lectures on Human-Centered Informatics, 8 (2), pp. 1-93; Kahn, Kanda, T., Jr., Ishiguro, H., Gill, B.T., Shen, S., Gary, H.E., Ruckert, J.H., Will people keep the secret of a humanoid robot? Psychological intimacy in HRI (2015) Proceedings of the 10Th Annual ACM/IEEE International Conference on Human-Robot Interaction, pp. 173-180. , New York, ACM; Knight, W., Google builds a robotic hive-mind kindergarten (2016) MIT Technology Review, , https://www.technologyreview.com/s/602529/google-builds-a-robotic-hive-mind-kindergarten/; Li, J., Ju, W., Reeves, B., Touching a mechanical body: Tactile contact with intimate parts of a humanoid robot is physiologically arousing (2016) Journal of Human-Robot Interaction; Lin, P., We’re building superhuman robots (2016) Will they Be Heroes, Or Villains?, , https://www.washingtonpost.com/news/in-theory/wp/2015/11/02/were-building-superhuman-robots-will-they-be-heroes-or-villains/?utm_term=.a58657bad760, Washington Post, Retrieved 1 December 2016, from; Malle, B.F., Scheutz, M., Moral competence in social robots (2014) In 2014 IEEE International Symposium on Ethics in Science, Technology and Engineering, pp. 1-6. , IEEE; Moor, J., Four Kinds of Ethical Robots (2009) ”Philosophy Now, 72, pp. 12-14; Peirce, C.S., (1998) The essential Peirce: Selected philosophical writings, 2. , Indiana University Press, Bloomington; Scheutz, M., The Inherent Dangers of Unidirectional Emotional Bonds between Humans and Social Robots (2011) Robot Ethics: The Ethical and Social Implications of Robotics, p. 205. , Lin P, Abney K, Bekey GA, (eds), MIT Press, Cambridge; Scheutz, M., Teach One, Teach All’—the explosive combination of instructible robots connected via cyber systems (2014) Proceedings of the 4Th Annual International Conference on Cyber Technology in Automation, Control and Intelligent Systems, pp. 43-48; Scheutz, M., Arnold, T., Feats without heroes: Norms, means, and ideal robotic action (2016) Frontiers in Robotics and AI, 3, p. 32; Seibt, J., Towards an ontology of simulated social interaction: Varieties of the “As If” for robots and humans (2017) Sociality and normativity for robots, pp. 11-39. , Hakli R, Seibt J, (eds), Springer International Publishing, Basel; Strait, M., Briggs, G., Scheutz, M., Some correlates of agency ascription and emotional value and their effects on decision-making (2013) Affective Computing and Intelligent Interaction (ACII), 2013 Humaine Association Conference On, pp. 505-510. , IEEE; Suchman, L., Reconfiguring human-robot relations (2006) ROMAN 2006-The 15Th IEEE International Symposium on Robot and Human Interactive Communication, pp. 652-654. , IEEE; Sung, J., Christensen, H.I., Grinter, R.E., Robots in the wild: Understanding long-term use (2009) 4Th ACM/IEEE International Conference on Human-Robot Interaction (HRI), 2009, pp. 45-52. , IEEE; Sung, J.Y., Guo, L., Grinter, R.E., Christensen, H.I., (2007) My Roomba is Rambo? Intimate Home Appliances, , In International conference on ubiquituous computing; Tapus, A., Mataric, M.J., Scassellati, B., Socially assistive robotics (2007) IEEE Robotics and Automation Magazine, 14 (1), p. 35; Van Wynsberghe, A., Designing robots for care: Care centered value-sensitive design (2013) Science and Engineering Ethics, 19 (2), pp. 407-433; Wetzel, L., (2009) Types and tokens, , MIT Press, Cambridge; Wetzel, L., (2014) Types and tokens, The Stanford Encyclopedia of Philosophy, , https://plato.stanford.edu/archives/spr2014/entries/types-tokens/, Spring 2014 Edition, E. N. Zalta (Ed.); Williams, T., Briggs, P., Pelz, N., Scheutz, M., Is robot telepathy acceptable? Investigating effects of nonverbal robot-robot communication on human-robot interaction. In Robot and human interactive communication (2014) 2014 RO-MAN: The 23Rd IEEE International Symposium, pp. 886-891. , IEEE; Yohanan, S., MacLean, K.E., The role of affective touch in human-robot interaction: Human intent and expectations in touching the haptic creature (2012) International Journal of Social Robotics, 4 (2), pp. 163-180; Young, J.E., Sung, J., Voida, A., Sharlin, E., Igarashi, T., Christensen, H.I., Grinter, R.E., Evaluating human-robot interaction (2011) International Journal of Social Robotics, 3 (1), pp. 53-67},
document_type={Article in Press},
source={Scopus},
}

@ARTICLE{Loh2018101,
author={Loh, J.},
title={On building responsible robots},
journal={Biosystems and Biorobotics},
year={2018},
volume={23},
pages={101-108},
doi={10.1007/978-3-030-01836-8_9},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056312191&doi=10.1007%2f978-3-030-01836-8_9&partnerID=40&md5=50c068ba801efd790cb61fdf2bb0a62d},
abstract={Rapid progress in robotics and AI potentially pose huge challenges regarding several roles that used to be traditionally reserved for human agents: Human core competences such as autonomy, agency, and responsibility might one day apply to artificial systems as well. I will give an overview on the philosophical discipline of robot ethics via the phenomenon of responsibility as a crucial human competence. In a first step I will ask for the traditional understanding of the term “responsibility and formulate a minimal definition that exclusively includes the necessary etymological elements as the ‘lowest common denominator’ of the responsibility concept: Responsibility as the ability to answer is a normative concept that rests on the assumption that the responsible subject in question is equipped with a specific psycho-motivational constitution. In a second step I will outline my understanding of the discipline of robot ethics, in order to ask in a third step how to ascribe responsibility in man-machine-interaction. For these purposes I will elaborate on my concept of responsibility networks. © Springer Nature Switzerland AG 2018.},
references={Brooks, R.A., Breazeal, C., Marjanović, M., Scasselatti, B., Williamson, M.M., The cog project, building a humanoid robot (1999) Computation for Metaphors. Analogy, and Agents, pp. 52-87. , C. Nehaniv (Ed.), Springer, Wiesbaden; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Minds and Machines, 14, pp. 349-379; Foot, P., Moral beliefs (1967) Theories of Ethics, pp. 83-100. , P. Foot (Ed.), Oxford University Press; Frankfurt, H., Freedom of the will and the concept of a person (1971) Journal of Philosophy, 68 (1), pp. 5-20; Loh, J., Strukturen und Relata der Verantwortung (2017) Handbuch Verantwortung, pp. 35-56. , Heidbrink, L., Langbehn, C., & Loh, J., Springer VS, Wiesbaden; Loh, J., (2017) Roboterethik. Information Philosophie, 1, pp. 20-33; Loh, J., Loh, W., Autonomy and responsibility in hybrid systems (2017) The Example of Autonomous Cars, pp. 35-50. , P. Lin, K. Abney, & R. Jenkins (Eds.), Robot ethics 2.0. From autonomous cars to artificial intelligence, Oxford University Press; Neuhäuser, C., Roboter und moralische Verantwortung (2014) Robotik Im Kontext Von Recht Und Moral, pp. 269-286. , E. Hilgendorf (Ed.), Nomos, Baden-Baden; Rawls, J., (2001) Justice as Fairness. a Restatement, , Harvard University Press; Searle, J.R., Minds, brains and programs (1980) Behavioral and Brain Sciences, 3, p. 417; Sombetzki, J., (2014) Verantwortung Als Begriff, Fähigkeit, Aufgabe, , Eine Drei-Ebenen-Analyse. Springer VS, Wiesbaden; Wallach, W., Allen, C., (2009) Moral Machines, , Teaching robots right from wrong. MIT Press, Cambridge, Massachusetts, London},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Boyles2018182,
author={Boyles, R.J.M.},
title={A case for machine ethics in modeling human-level intelligent agents},
journal={Kritike},
year={2018},
volume={12},
number={1},
pages={182-200},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049387382&partnerID=40&md5=c44b11dde550c96e2c4a26d059fc8c9e},
abstract={This paper focuses on the research field of machine ethics and how it relates to a technological singularity-a hypothesized, futuristic event where artificial machines will have greater-than-human-level intelligence. One problem related to the singularity centers on the issue of whether human values and norms would survive such an event. To somehow ensure this, a number of artificial intelligence researchers have opted to focus on the development of artificial moral agents, which refers to machines capable of moral reasoning, judgment, and decision-making. To date, different frameworks on how to arrive at these agents have been put forward. However, there seems to be no hard consensus as to which framework would likely yield a positive result. With the body of work that they have contributed in the study of moral agency, philosophers may contribute to the growing literature on artificial moral agency. While doing so, they could also think about how the said concept could affect other important philosophical concepts. © 2018 Robert James M. Boyles.},
author_keywords={Artificial moral agents;  Machine ethics;  Philosophy of artificial intelligence;  Technological singularity},
references={Anderson, M., Anderson, S.L., (2011) Machine Ethics, , New York: Cambridge University Press; Aquinas, T., (1952) Summa Theologica, , Chicago: Encyclopaedia Britannica, trans. by the Fathers of the English Dominican Province, rev. by Daniel J. Sullivan; Capek, K.R.U.R., (2016), Adelaide: eBooks@Adelaide, University of Adelaide Library trans. by David Wyllie; Carter, M., (2007) Minds and Computers: An Introduction to the Philosophy of Artificial Intelligence, , Edinburgh: Edinburgh University Press, Ltd; Chalmers, D.J., "The Singularity: A Philosophical Analysis," (2010) Journal of Consciousness Studies, 17, pp. 9-10; Counet, J.-M., "Mathematics and the Divine in Nicholas of Cusa," (2005) Mathematics and the Divine: A Historical Study, , ed. by Teun Koetsier and Luc Bergmans Amsterdam: Elsevier B.V; Denis, L., "Kant and Hume on Morality," The Stanford Encyclopedia of Philosophy, , https://plato.stanford.edu/archives/fall2012/entries/kant-hume-morality/, Fall 2012 ed., ed. by Edward N. Zalta (7 December 2015); Denise, T.C., (2008) Great Traditions in Ethics, , California: Thomson Wadsworth; Eshleman, A., "Moral Responsibility," The Stanford Encyclopedia of Philosophy, , https://plato.stanford.edu/archives/sum2014/entries/moral-responsibility/, Summer 2014 ed., ed. by Edward N. Zalta (June 2015); Garrett, B., (1998) Personal Identity and Self-Consciousness, , London: Routledge; Goertzel, B., "Human-level Artificial General Intelligence and the Possibility of a Technological Singularity: A Reaction to Ray Kurzweil's The Singularity is Near, and McDermott's Critique of Kurzweil," (2007) Artificial Intelligence, 171, p. 18; Good, I.J., "Speculations Concerning the First Ultraintelligent Machine," (1966) Advances in Computers, 6. , ed. by Franz L. Alt and Morris Rubinoff (New York: Academic Press); Graesser, A., "Is it an Agent, or just a Program?: A Taxonomy for Autonomous Agents," (1996) Proceedings of the Third International Workshop on Agent Theories, Architectures, and Languages, , (London: Springer-Verlag); Greene, B., (1999) The Elegant Universe: Superstrings, Hidden Dimensions, and the Quest for the Ultimate Theory, , New York: W.W. Norton & Co; Hawking, S.W., (1988) A Brief History of Time, , New York: Bantam Books; Himma, K.E., "Artificial Agency, Consciousness, and the Criteria for Moral Agency: What Properties must an Artificial Agent have to be a Moral Agent?" (2009) Ethics and Information Technology, p. 11; Joaquin, J.J., "Personal Identity and What Matters," (2017) Organon F, 24, p. 2; Kant, I., (2002) Groundwork for the Metaphysic of Morals, , ed. and trans. by Allen W. Wood (Yale University Press); Kurzweil, R., (2005) The Singularity is Near: When Humans Transcend Biology, , New York: Viking; Loosemore, R., Goertzel, B., "Why an Intelligence Explosion is Probable,", , http://hplusmagazine.com/2011/03/07/why-an-intelligence-explosion-is-probable/, in Humanity+ Magazine (7 March 2011); Mabaquiao, N.J., (2012) Mind, Science and Computation, , Manila: Vibal Publishing House, Inc; McInerny, R., "Aquinas's Moral Theory," (1987) in Journal of Medical Ethics, 13 (1); Moor, J.H., "The Nature, Importance, and Difficulty of Machine Ethics," (2011) Machine Ethics, , ed. by Michael Anderson and Susan Leigh Anderson New York: Cambridge University Press; Moravec, H.P., "Rise of the Robots," (2002) Understanding Artificial Intelligence, , ed. by Sandy Fritz New York: Warner Books, Inc; Moser, W., Moyes, C., "Literature-A Storehouse of Knowledge?" (1993) SubStance, p. 22; Muehlhauser, L., Bostrom, N., "Why We Need Friendly AI," (2014) in Think, 36 (13); Nadeau, J.E., "Only Androids Can Be Ethical," (2006) Thinking about Android Epistemology, , ed. by Kenneth M. Ford, Clark Glymour and Patrick Hayes Cambridge: MIT Press; Paipetis, S.A., (2010) The Unknown Technology in Homer, , Dordrecht: Springer Science+Business Media BV; Penrose, R., "Black Holes," (1991) The World Treasury of Physics, Astronomy and Mathematics, , ed. by Timothy Ferris New York: Little, Brown and Company; Shanahan, M., "The Frame Problem," The Stanford Encyclopedia of Philosophy, , https://plato.stanford.edu/archives/win2009/entries/frame-problem/, Winter 2009 ed., ed. by Edward N. Zalta (July 2013); Sullins, J., "Artificial Moral Agency in Technoethics," (2009) Handbook of Research on Technoethics, , ed. by Roccio Luppicini and Rebecca Adell Hershey: IGI Global Information Science; Pfeifer, R., Scheier, C., (1999) Understanding Intelligence, , Cambridge: MIT Press; Vinge, V., "The Coming of Technological Singularity: How to Survive in the Post-Human Era," (1993) Proceedings of A Symposium Cosponsored by NASA Lewis Research Center and the Ohio Aerospace Institute, , in Vision 21: Interdisciplinary Science and Engineering in the Era of Cyberspace (Washington, D.C.: National Aeronautics and Space Administration, Office of Management, Scientific and Technical Information Program); Wallach, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , New York: Oxford University Press; Wittgenstein, L., (1953) Philosophical Investigations, , Oxford: Blackwell Publishing, Ltd},
document_type={Article},
source={Scopus},
}

@BOOK{Welsh20171,
author={Welsh, S.},
title={Ethics and security automata: Policy and technical challenges of the robotic use of force},
journal={Ethics and Security Automata: Policy and Technical Challenges of the Robotic Use of Force},
year={2017},
pages={1-220},
doi={10.4324/9781315168951},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042004918&doi=10.4324%2f9781315168951&partnerID=40&md5=9b0196c566efdee8f0df4f99b096c165},
abstract={Can security automata (robots and AIs) make moral decisions to apply force on humans correctly? If they can make such decisions, ought they be used to do so? Will security automata increase or decrease aggregate risk to humans? What regulation is appropriate? Addressing these important issues this book examines the political and technical challenges of the robotic use of force. The book presents accessible practical examples of the 'machine ethics' technology likely to be installed in military and police robots and also in civilian robots with everyday security functions such as childcare. By examining how machines can pass 'reasonable person' tests to demonstrate measurable levels of moral competence and display the ability to determine the 'spirit' as well as the 'letter of the law', the author builds upon existing research to define conditions under which robotic force can and ought to be used to enhance human security. The scope of the book is thus far broader than 'shoot to kill' decisions by autonomous weapons, and should attract readers from the fields of ethics, politics, and legal, military and international affairs. Researchers in artificial intelligence and robotics will also find it useful. © 2018 Sean Welsh. All rights reserved.},
references={Allen, C., Varner, A., Zinser, J., Prolegomena to Any Future Artificial Moral Agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12 (3), pp. 251-261; Arkin, R.C., (2009) Governing Lethal Behaviour in Autonomous Robots, , Boca Rouge, CRC Press; Arkin, R.C., Ulam, P.D., An Ethical Adaptor: Behavioral Modification Derived from Moral Emotions (2009), http://hdl.handle.net/1853/31469, Retrieved 23rd Oct., 2014; Asimov, I., (1950) I, Robot, , New York, Gnome Press; Baars, B.J., (1997) In the Theatre of Consciousness: The Workspace of the Mind, , New York, Oxford University Press; Beck, K., (2003) Test-Driven Development: By Example, , Boston, MA, Addison-Wesley; Bekey, G.A., (2005) Autonomous Robots: From Biological Inspiration to Implementation and Control, , Cambridge, MA, MIT press; Bentham, J., An Introduction to the Principles of Morals and Legislation (1780), www.econlib.org/library/Bentham/bnthPML.html, Retrieved 8th Oct., 2016; Block, N., On a Confusion about a Function of Consciousness (1995) Behavioral and Brain Sciences, 18 (2), pp. 227-247; Boltuc, P., The Engineering Thesis in Machine Consciousness (2012) Techné: Research in Philosophy and Technology, 16 (2), pp. 187-207; Briggs, G., Scheutz, M., Sorry, I Can't Do That: Developing Mechanisms to Appropriately Reject Directives in Human-Robot Interactions (2015) Proceedings of the 2015 AAAI fall symposium on AI and HRI, , Washington, DC; Chalmers, D., Facing Up to the Problem of Consciousness (1995) Journal of Consciousness Studies, 2 (3), pp. 200-219; Chein, M., Mugnier, M.-L., (2008) Graph-Based Knowledge Representation: Computational Foundations of Conceptual Graphs, , London, Springer-Verlag; Chomsky, N., (1965) Aspects of the Theory of Syntax, , Cambridge, MA, MIT press; Croitoru, M., Oren, N., Miles, S., Luck, M., Graphical Norms via Conceptual Graphs (2012) Knowledge-Based Systems, 29, pp. 31-43; Damasio, A., (2010) Self Comes to Mind: Constructing the Conscious Brain, , New York, Pantheon; Patriot System Performance (2005), www.acq.osd.mil/dsb/reports/ADA435837.pdf, Retrieved 18th Feb., 2015; Principles of Robotics (2010), www.epsrc.ac.uk/research/ourportfolio/themes/engineering/activities/principlesofrobotics/, Retrieved 19th Jan., 2017; Flammini, F., Setola, R., Franceschetti, G., (2013) Effective Surveillance for Homeland Security: Balancing Technology and Social Issues, , Hoboken, Taylor and Francis; Gabbay, D., Horty, J., Parent, X., van der Mayden, R., van der Torre, L., (2013) Handbook of Deontic Logic and Normative Systems, , Milton Keynes, College Publications; Galliott, J., Responsibility and War Machines: Towards a Forward-Looking and Functional Account (2015) Rethinking Machine Ethics in the Age of Ubiquitous Technology, pp. 152-165. , J. White and R. Searle. Hershey, PA, IGI Global; Goldberg, E., (2009) The New Executive Brain: Frontal Lobes in a Complex World, , Oxford; New York, Oxford University Press; Grice, P., (1991) Studies in the Way of Words, , Cambridge, MA, Harvard University Press; Guarini, M., Computational Neural Modeling and the Philosophy of Ethics (2011) Machine Ethics, pp. 316-334. , M. Anderson and S. L. Anderson. Cambridge, Cambridge University Press; Gunkel, D.J., (2012) The Machine Question: Critical Perspectives on AI, Robots, and Ethics, , Cambridge, MA, MIT Press; Haidt, J., (2012) The Righteous Mind, , New York, Pantheon Books; Harnad, S., The Symbol Grounding Problem (1990) Physica D: Nonlinear Phenomena, 42 (1), pp. 335-346; Hauser, M.D., (2006) Moral Minds: How Nature Designed Our Universal Sense of Right and Wrong, , New York, HarperCollins; Heider, F., Simmel, M., An Experimental Study of Apparent Behavior (1944) The American Journal of Psychology, 57 (2), pp. 243-259; Hursthouse, R., (1999) On Virtue Ethics, , Oxford, Oxford University Press; Husserl, E., (1931) Ideas: General Introduction to Pure Phenomenology, , London, Allen & Unwin; Kant, I., Groundwork of the Metaphysics of Morals (1785), www.gutenberg.org/ebooks/5682, Retrieved 29th Nov., 2015; Korsgaard, C.M., (2009) Self-Constitution: Agency, Identity, and Integrity, , Oxford; New York, Oxford University Press; Kurzweil, R., (2012) How to Create a Mind: The Secret of Human Thought Revealed, , New York, Viking Penguin; Leveringhaus, A., (2016) Ethics and Autonomous Weapons, , London, Palgrave Macmillan; Levy, D., (2007) Love and Sex with Robots: The Evolution of Human-Robot Relationships, , New York, HarperCollins; Lucas, G.R., Postmodern War (2010) Journal of Military Ethics, 9 (4), pp. 289-298; Lucas, G.R., Jr., Engineering, Ethics and Industry: The Moral Challenges of Lethal Autonomy (2013) Killing by Remote Control: The Ethics of an Unmanned Military, pp. 211-228. , B. J. Strawser. New York, Oxford University Press; Lucas, J.R., The Philosophy of the Reasonable Man (1963) The Philosophical Quarterly (1950), 13 (51), pp. 97-106; Madl, T., Franklin, S., Constrained Incrementalist Moral Decision Making for a Biologically Inspired Cognitive Architecture (2015) A Construction Manual for Robots', pp. 137-153. , Ethical Systems. R. Trappl. London, Springer; Malle, B.F., Scheutz, M., (2014) Moral Competence in Social Robots, , Ethics in Science, Technology and Engineering, 2014 IEEE International Symposium on, IEEE; McDermott, D., What Matters to a Machine? (2012) Machine Ethics, pp. 88-114. , M. Anderson and S. L. Anderson. Cambridge, Cambridge University Press; Metzinger, T., Two Principles of Robot Ethics (2013), www.blogs.uni-mainz.de/fb05philosophieengl/files/2013/07/Metzinger_RG_2013_penultimate.pdf, Retrieved 22nd Jul., 2015; Mill, J.S., (1863) Utilitarianism, , London, Parker, Son and Bourn; Aircraft Accident to Royal Air Force Tornado GR MK4A ZG710 (2004), www.gov.uk/government/uploads/system/uploads/attachment_data/file/82817/maas03_02_tornado_zg710_22mar03.pdf, Retrieved 6th Jan., 2015; Nagel, T., What Is It Like to Be a Bat? (1974) The Philosophical Review, 83 (4), pp. 435-450; Noddings, N., (1984) Caring: A Feminine Approach to Ethics and Moral Education, , Berkeley, University of California Press; Parfit, D., (2011) On What Matters, , Oxford; New York, Oxford University Press; Penrose, R., (1990) The Emperor's New Mind: Concerning Computers, Minds, and the Laws of Physics, , Oxford, Oxford University Press; Pereira, L.M., Saptawijaya, A., (2016) Programming Machine Ethics, , London, Springer; Picard, R.W., (1997) Affective Computing, , Cambridge, MA, MIT Press; Rachels, S., Rachels, J., (2014) The Elements of Moral Philosophy, , Dubuque, McGraw- Hill Education; Rawls, J., (1972) A Theory of Justice, , Oxford, Clarendon Press; Reader, S., (2007) Needs and Moral Necessity, , London; New York, Routledge; Ross, W.D., (1930) The Right and the Good, , Oxford, The Clarendon Press; Scanlon, T., (1998) What We Owe to Each Other, , Cambridge, MA, Harvard University Press; Scherer, K., Bänziger, T., Roesch, E., (2010) A Blueprint for Affective Computing: A Sourcebook and Manual, , Oxford, Oxford University Press; Scheutz, M., The Inherent Dangers of Unidirectional Emotional Bonds between Humans and Social Robots (2012) Robot Ethics, pp. 205-222. , P. Lin, K. Abney and G. Bekey. Cambridge, MA, MIT Press; Sidgwick, H., The Methods of Ethics (1907), www.gutenberg.org/files/46743/46743-h/46743-h.htm, Seventh Edition. Retrieved 5th Oct., 2016; Singer, P.W., (2009) Wired for War: The Robotics Revolution and Conflict in the Twenty- First Century, , London, Penguin; Stasi, A., An Introduction to the Nature and Role of the Reasonable Person Standard in Asian Civil Law Jurisdictions (2015) American Law Register, 49 (3), pp. 148-164; Steels, L., The Symbol Grounding Problem Has Been Solved. So What's Next (2008) Symbols and Embodiment. Debates on Meaning and Cognition, pp. 223-244. , M. de Vega, A. Glenberg and A. Graesser. Oxford, OUP; Tonkens, R., Out of Character: On the Creation of Virtuous Machines (2012) Ethics and Information Technology, 14 (2), pp. 137-149; Tononi, G., Koch, C., Consciousness: Here, There and Everywhere? (2015) Philosophy Transactions of the Royal Society B, 370 (1668), p. 20140167; Treiber, M., (2010) An Introduction to Object Recognition: Selected Algorithms for a Wide Variety of Applications, , London, Springer; Healthcare at Home Limited (Appellant) v The Common Services Agency (Respondent) (Scotland) (2014), www.supremecourt.uk/decided-cases/docs/UKSC_2013_0108_Judgment.pdf, Retrieved 30th Jan., 2015; (1891) The War of the Rebellion: A Compilation of the Official Records of the Union and Confederate Armies, , Washington, Government Printing Office; Vilmer, J.-B.J., Terminator Ethics: Should We Ban 'Killer Robots'? (2015), www.ethicsandinternationalaffairs.org/2015/terminator-ethics-bankiller-robots/, Retrieved 13th Jan., 2017; Walzer, M., (1977) Just and Unjust Wars: A Moral Argument with Historical Illustrations, , New York, Basic Books; Weizenbaum, J., McCarthy, J., (1977) Computer Power and Human Reason: From Judgment to Calculation, , San Francisco, WH Freeman; Anderson, M., Anderson, S.L.A., (2005) Toward Machine Ethics: Implementing Two Action-Based Ethical Theories, , Machine Ethics: Papers from the AAAI Fall Symposium. Technical Report FS-05-06, Washington DC, Association for the Advancement of Artificial Intelligence, Menlo Park, CA; Arkin, R.C., (2009) Governing Lethal Behaviour in Autonomous Robots, , Boca Rouge, CRC Press; Bekey, G.A., (2005) Autonomous Robots: From Biological Inspiration to Implementation and Control, , Cambridge, MA, MIT press; Bentham, J., An Introduction to the Principles of Morals and Legislation (1780), www.econlib.org/library/Bentham/bnthPML.html, Retrieved 8th Oct., 2016; Brachman, R., Levesque, H., (2004) Knowledge Representation and Reasoning, , Boston, Elsevier; Brock, G., Needs and Global Justice (2005) The Philosophy of Need, pp. 51-72. , S. Reader. Cambridge, Cambridge University Press. Royal Institute of Philosophy Supplement 57; Colyvan, M., Cox, D., Steele, K., Modelling the Moral Dimension of Decisions (2010) Noûs, 44 (3), pp. 503-529; Dancy, J., (2004) Ethics Without Principles, , Oxford, OUP; Defoe, D., Robinsoe Crusoe (1719), www.gutenberg.org/files/521/521-h/521-h.htm, Retrieved 3rd Jan., 2017; Gert, B., (1988) Morality, , Oxford. Oxford University Press; Gigerenzer, G., Moral Intuition = Fast and Frugal Heuristics (2007) Moral Psychology: The Cognitive Science of Morality: Intuition and Diversity, pp. 1-26. , W. Sinnott-Armstrong. Cambridge MA, MIT Press. 2; Gips, J., Towards the Ethical Robot. The Second International Workshop on Human and Machine Cognition: Android Epistemology (1991), Perdido Key, Florida; Goertzel, B., Geisweiller, N., Coelho, L., Janicic, P., Pennachin, C., (2011) Real World Reasoning: Toward Scalable, Uncertain Spatiotemporal, Contextual and Causal Inference, , Paris, Atlantis Press; Gould, S.J., Non-overlapping Magisteria (1997) Natural History, 106, pp. 16-22; Harris, S., (2010) The Moral Landscape: How Science Can Determine Human Values, , London, Bantam; Hobbes, T., Leviathan (1651), www.gutenberg.org/files/3207/3207-h/3207-h.htm, Retrieved 17th Jul., 2015; Hume, D., A Treatise of Human Nature (1738), www.gutenberg.org/files/4705/4705-h/4705-h.htm, Retrieved 17th Jul., 2015; Hursthouse, R., (1999) On Virtue Ethics, , Oxford, Oxford University Press; Protocol Additional to the Geneva Conventions of 12 Aug., 1949, and Relating to the Protection of Victims of International Armed Conflicts (Protocol I), 8 Jun., 1977. Article 36 (1977), www.icrc.org/ihl/WebART/470-750045?OpenDocument, Retrieved 24th Feb., 2015; Kant, I., Groundwork of the Metaphysics of Morals (1785), www.gutenberg.org/ebooks/5682, Retrieved 29th Nov., 2015; Kernighan, B.W., Ritchie, D., (1978) The C Programming Language, , Englewood Cliffs, NJ, Prentice-Hall; Korsgaard, C.M., (2009) Self-Constitution: Agency, Identity, and Integrity, , Oxford; New York, Oxford University Press; Kurzweil, R., (2012) How to Create a Mind: The Secret of Human Thought Revealed, , New York, Viking Penguin; Locke, J., Second Treatise on Government (1689), www.gutenberg.org/files/7370/7370-h/7370-h.htm, Retrieved 1st Dec., 2015; MacIntyre, A.C., Hume on 'Is' and 'Ought' (1959) The Philosophical Review, 68 (4), pp. 451-468; Malle, B.F., Scheutz, M., (2014) Moral Competence in Social Robots, , Ethics in Science, Technology and Engineering, 2014 IEEE International Symposium on Ethics in Science, Technology and Engineering, IEEE, Chicago; Maslow, A., (1954) Motivation and Personality, , New York, Harper & Row; McConnell, S., (2006) Software Estimation: Demystifying the Black Art, , Redmond, WA, Microsoft Press; McCune, W., Prover 9 and Mace 4 (2010), www.cs.unm.edu/~mccune/Prover9; Mill, J.S., (1863) Utilitarianism, , London, Parker, Son and Bourn; Moor, J.H., The Nature, Importance and Difficulty of Machine Ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Nagel, T., What Is It Like to Be a Bat? (1974) The Philosophical Review, 83 (4), pp. 435-450; Noddings, N., (2003) Caring: A Feminine Approach to Ethics and Moral Education, , Berkeley, University of California Press; O'Neill, O., A Simplified Account of Kant's Ethics (2007) The Elements of Philosophy, pp. 112-114. , T. Gendler, S. Siegel and S. M. Cahn. Oxford, OUP; Parfit, D., (2011) On What Matters, , Oxford; New York, Oxford University Press; Penrose, R., (1990) The Emperor's New Mind: Concerning Computers, Minds, and the Laws of Physics, , Oxford, Oxford University Press; Pereira, L.M., Saptawijaya, A., (2016) Programming Machine Ethics, , London, Springer; Rachels, S., Rachels, J., (2014) The Elements of Moral Philosophy, , Dubuque, McGraw- Hill Education; Rand, A., The Objectivist Ethics (1961), http://aynrandlexicon.com/ayn-rand-ideas/the-objectivist-ethics.html, Retrieved 23rd Oct., 2014; Rawls, J., Outline of a Decision Procedure for Ethics (1951) The Philosophical Review, 60 (2), pp. 177-197; Rawls, J., (1972) A Theory of Justice, , Oxford, Clarendon Press; Raz, J., Numbers, with and without Contractualism (2003) Ratio, 16 (4), pp. 346-367; Reader, S., (2007) Needs and Moral Necessity, , London; New York, Routledge; Ross, W.D., (1930) The Right and the Good, , Oxford, The Clarendon Press; Rousseau, J.-J., The Social Contract (1762), www.gutenberg.org/files/46333/46333-h/46333-h.htm, Retrieved 1st Dec., 2015; Russell, S., Norvig, P., (2010) Artificial Intelligence: A Modern Approach, , Upper Saddle River, NJ, Prentice Hall; Scanlon, T., (1998) What We Owe to Each Other, , Cambridge, MA, Harvard University Press; Scheffler, S., Introduction (2011) On What Matters, pp. 19-32. , S. Scheffler. Oxford, Oxford University Press. 1; Scherer, K., The Component Process Model: Architecture for a Comprehensive Computational Model of Emergent Emotion (2010) Blueprint for Affective Computing: A Sourcebook and Manual, pp. 47-84. , K. Scherer, T. Banziger and E. Roesch. Oxford, Oxford University Press; Scherer, K., Bänziger, T., Roesch, E., (2010) A Blueprint for Affective Computing: A Sourcebook and Manual, , Oxford, Oxford University Press; Scheutz, M., The Inherent Dangers of Unidirectional Emotional Bonds between Humans and Social Robots (2012) Robot Ethics, pp. 205-222. , P. Lin, K. Abney and G. Bekey. Cambridge, MA, MIT Press; Sen, A.K., (1985) Commodities and Capabilities, , Amsterdam; New York, North-Holland; Sidgwick, H., The Methods of Ethics (1907), www.gutenberg.org/files/46743/46743-h/46743-h.htm, Seventh Edition. Retrieved 5th Oct., 2016; Singer, P.W., (2009) Wired for War: The Robotics Revolution and Conflict in the Twenty- First Century, , London, Penguin; Sperry, R.W., (1983) Science & Moral Priority: Merging Mind, Brain, and Human Values, , Oxford, Blackwell; Timmons, M., (2002) Moral Theory: An Introduction, , Lanham, Rowman & Littlefield; Tonkens, R., Out of Character: On the Creation of Virtuous Machines (2012) Ethics and Information Technology, 14 (2), pp. 137-149; Turing, A.M., Computing Machinery and Intelligence (1950) Mind, 59 (236), pp. 433-460; von Wright, G.H., Deontic Logic (1951) Mind, 60 (237), pp. 1-15; Wallech, W., Allen, C., (2009) Moral Machines, , Oxford; New York, Oxford University Press; Weizenbaum, J., McCarthy, J., (1977) Computer Power and Human Reason: From Judgment to Calculation, , San Francisco, WH Freeman; Wiggens, D., (1982) Needs, Values and Truth: Essays in the Philosophy of Value, , Oxford, Oxford University Press; Wood, A.W., (2008) Kantian Ethics, , Cambridge; New York, Cambridge University Press; Allen, C., Varner, A., Zinser, J., Prolegomena to Any Future Artificial Moral Agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12 (3), pp. 251-261; Arnold, T., Scheutz, M., Against the Moral Turing Test: Accountable Design and the Moral Reasoning of Autonomous Systems (2016) Ethics and Information Technology, 18 (2), pp. 103-115; Beck, K., (2003) Test-Driven Development: By Example, , Boston, MA, Addison-Wesley; Arkin, R.C., (2009) Governing Lethal Behaviour in Autonomous Robots, , Boca Rouge, CRC Press; Explainable Artificial Intelligence (2016), www.darpa.mil/program/explainable-artificial-intelligence, Retrieved 13th Sep., 2016; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , Cambridge, MA, MIT Press; Goodman, B., Flaxman, S., European Union regulations on algorithmic decisionmaking and a "right to explanation" (2016), https://arxiv.org/abs/1606.08813, Retrieved 14th Sept, 2017; Guarini, M., Particularism and Classification and Reclassification of Moral Cases (2006) IEEE Intelligent Systems [H.W.Wilson-AST], 21 (4), p. 22; Learning from Tay's Introduction (2016), https://blogs.microsoft.com/blog/2016/03/25/learning-tays-introduction/, Retrieved 9th Sep., 2016; Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Ostrovski, G., Human-Level Control through Deep Reinforcement Learning (2015) Nature, 518 (7540), pp. 529-533; Parfit, D., (2011) On What Matters, , Oxford; New York, Oxford University Press; Pereira, L.M., Saptawijaya, A., (2016) Programming Machine Ethics, , London, Springer; Arkin, R.C., (2009) Governing Lethal Behaviour in Autonomous Robots, , Boca Rouge, CRC Press; Belnap, N., Perloff, M., Seeing to It That: A Canonical Form for Agentives (1988) Theoria, 54, pp. 175-199; Bringsjord, S., Arkoudas, C., Bello, P., Toward a General Logicist Methodology for Engineering Ethical Correct Robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44; Bringsjord, S., Naveen Sundar, G., Deontic Cognitive Event Calculus (2013), www.cs.rpi.edu/~govinn/dcec.pdf, Retrieved 11th Nov., 2015; Bringsjord, S., Taylor, J., The Divine-Command Approach to Robot Ethics (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 85-108. , P. Lin, K. Abney and G. Bekey. Cambridge, MIT Press; Bringsjord, S., Arkoudas, C., Bello, P., Toward a General Logicist Methodology for Engineering Ethical Correct Robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44; Brooks, R.A., Elephants Don't Play Chess (1990) Robotics and Autonomous Systems, 6 (1), pp. 3-15; Brooks, R.A., Intelligence without Representation (1991) Artificial Intelligence, 47 (1), pp. 139-159; Castañeda, H.-N., The Paradoxes of Deontic Logic: The Simplest Solution to All of Them in One Fell Swoop (1981) New Studies in Deontic Logic, pp. 37-86. , R. Hilpinen. Dordrecht, D. Reidel Publishing Company; Dancy, J., (2004) Ethics Without Principles, , Oxford, OUP; Franklin, S., (1995) Artificial Minds, , Cambridge, MA, MIT Press; Gert, J., (2012) Normative Bedrock, , Oxford, Oxford University Press; Guarini, M., Particularism, Analogy and Moral Cognition (2010) Minds and Machines, 20, pp. 385-422; Haikonen, P., (2012) Consciousness and Robot Sentience, , Hackensack, NJ, World Scientific; Hansen, J., The Paradoxes of Deontic Logic: Alive and Kicking (2006) Theoria, 72, pp. 221-232; Horty, J.F., (2001) Agency and Deontic Logic, , Oxford, Oxford University Press; Hughes, G.E., Cresswell, M.J., (1996) A New Introduction to Modal Logic, , New York, Routledge; Maslow, A., (1954) Motivation and Personality, , New York, Harper & Row; McLaren, B., Lessons in Machine Ethics from the Perspective of Two Computational Models of Ethical Reasoning, 2005 (2005), AAAI Fall Symposium on Machine Ethics, AAAI Technical Report FS-05-06, 2005; Parfit, D., (2011) On What Matters, , Oxford; New York, Oxford University Press; Pereira, L.M., Saptawijaya, A., (2016) Programming Machine Ethics, , London, Springer; Poole, D.L., Mackworth, A.K., (2010) Artificial Intelligence: Foundations of Computational Agents, , Cambridge, Cambridge University Press; Reader, S., (2007) Needs and Moral Necessity, , London; New York, Routledge; Baxter (2015), www.rethinkrobotics.com/baxter/, Retrieved 17th Feb., 2015; Scanlon, T., How I am Not a Kantian (2011) On What Matters, pp. 119-138. , S. Scheffler. Oxford, Oxford University Press. 2; Wallech, W., Allen, C., (2009) Moral Machines, , Oxford; New York, Oxford University Press; Xu, M., Actions as Events (2012) Journal of Philosophical Logic, 41 (4), pp. 765-809; Arkin, R.C., Integrating Behavioral, Perceptual, and World Knowledge in Reactive Navigation (1990) Robotics and Autonomous Systems, 6 (1-2), pp. 105-122; Arkin, R.C., (2009) Governing Lethal Behaviour in Autonomous Robots, , Boca Rouge, CRC Press; Killer Robots: UK Government Policy on Fully Autonomous Weapons (2013), www.article36.org/wp-content/uploads/2013/04/Policy_Paper1.pdf, Retrieved 26th May, 2015; Beauchamp, Z., Savulescu, J., Robot Guardians: Teleoperated Combat Vehicles in Humanitarian Intervention (2013) Killing by Remote Control: The Ethics of an Unmanned Military, pp. 106-125. , B. J. Strawser. Oxford, USA, Oxford University Press; Belnap, N., Perloff, M., Seeing to It That: A Canonical Form for Agentives (1988) Theoria, 54, pp. 175-199; Bringsjord, S., Arkoudas, C., Bello, P., Toward a General Logicist Methodology for Engineering Ethical Correct Robots (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44; Bringsjord, S., Naveen Sundar, G., Deontic Cognitive Event Calculus (2013), www.cs.rpi.edu/~govinn/dcec.pdf, Retrieved 8th Aug., 2015; Croitoru, M., Oren, N., Miles, S., Luck, M., Graphical Norms via Conceptual Graphs (2012) Knowledge-Based Systems, 29, pp. 31-43; Everett, J.A., Pizarro, D.A., Crockett, M.J., Inference of Trustworthiness from Intuitive Moral Judgments (2016) Journal of Experimental Psychology: General, 145 (6), p. 772; Hansen, J., The Paradoxes of Deontic Logic: Alive and Kicking (2006) Theoria, 72, pp. 221-232; Hansson, S.O., Alternative Semantics for Deontic Logic (2013) Handbook of Deontic Logic and Normative Systems, pp. 445-498. , D. Gabbay, J. Horty, X. Parent, R. Van der Mayden and L. Van der Torre. Milton Keynes, College Publications; Harris, S., (2010) The Moral Landscape: How Science Can Determine Human Values, , London, Bantam; Hilpinen, R., Preface (1981) New Studies in Deontic Logic, pp. 7-9. , R. Hilpinen. Dordrecht, D. Reidel Publishing Company; Horty, J.F., (2001) Agency and Deontic Logic, , Oxford, Oxford University Press; Hursthouse, R., (1999) On Virtue Ethics, , Oxford, Oxford University Press; Protocol on Prohibitions or Restrictions on the Use of Mines, Booby-Traps and Other Devices as amended on 3 May 1996 (Protocol II to the 1980 CCW Convention as amended on 3 May 1996) (1996), www.icrc.org/ihl/INTRO/575, Retrieved 6th Mar., 2015; Convention on the Prohibition of the Use, Stockpiling, Production and Transfer of Anti-Personnel Mines and on Their Destruction, 18 September 1997 (1997), www.icrc.org/ihl/INTRO/580, Retrieved 6th Mar., 2015; Kagan, S., (1989) The Limits of Morality, , Oxford, Oxford University Press; Malle, B., Scheutz, M., Arnold, T., Voiklis, J., Cusimano, C., (2015) Sacrifice One for the Good of Many: People Apply Different Moral Norms to Humans and Robots, , 10th ACM/ IEEE International Conference on Human-Robot Interaction 2015, Portland, ACM; Pereira, L.M., Saptawijaya, A., (2016) Programming Machine Ethics, , London, Springer; Pigden, C.R., Logic and the Autonomy of Ethics (1989) Australasian Journal of Philosophy, 67 (2), pp. 127-151; Rachels, J., Active and Passive Euthanasia (1975) The New England Journal of Medicine, 292 (2), p. 78; Ross, W.D., (1930) The Right and the Good, , Oxford, The Clarendon Press; US Commander Hails Iraqi Forces Beating ISIS Drones and VBIEDs (2017), www.rudaw.net/english/middleeast/iraq/110120171, Retrieved 3rd Feb., 2017; Scharre, P., Autonomous Weapons and Operational Risk (2016), www.cnas.org/autonomous-weapons-and-operational-risk#.VtSsW_l97IU, Retrieved 1st Mar., 2016; Sperry, R.W., (1983) Science & Moral Priority: Merging Mind, Brain, and Human Values, , Oxford, Blackwell; van den Hoven, J., Lokhorst, G.-J., Deontic Logic and Computer-Supported Computer Ethics (2002) Metaphilosophy, 33, pp. 376-386; Nichomachean Ethics http://classics.mit.edu/Aristotle/nicomachaen.html, Retrieved 29th Nov., 2015; Glimscher, P., Fehr, E., (2013) Neuroeconomics, , Burlington, Elsevier Science; Hansson, S.O., The Varieties of Permission (2013) Handbook of Deontic Logic and Normative Systems, pp. 195-240. , D. Gabbay, J. Horty, X. Parent, R. Van der Mayden and L. Van der Torre. Milton Keynes, College Publications. 1; Jackson, F., Critical Notice (1992) Australasian Journal of Philosophy, 70 (4), pp. 475-488; Krotzsch, M., Simanzik, F., Horrocks, I., A Description Logic Primer (2012), http://arxiv.org/pdf/1201.4089.pdf, Retrieved 12th Dec., 2014; Nozick, R., (1981) Philosophical Explanations, , Cambridge, MA, Belknap Press; Robinson, I., Webber, J., Eifrem, E., (2015) Graph Databases, , Sebastapol, CA, O'Reilly; Anderson, S.L., The Unacceptability of Asimov's Three Laws as a Basis for Machine Ethics (2011) Machine Ethics, pp. 285-296. , M. Anderson and S. L. Anderson. Cambridge, Cambridge University Press; Aquinas, T., (1947) Summa Theologica, , (trans. Fathers of the Dominican Province) New York, Benziger Bros; Bourget, D., Chalmers, D., What Do Philosophers Believe? (2014) Philosophical Studies, 170 (3), pp. 465-500; Brock, G., Needs and Global Justice (2005) The Philosophy of Need. S. Reader. Cambridge, Cambridge University Press. Royal Institute of Philosophy Supplement, 57, pp. 51-72; Everett, J.A., Pizarro, D.A., Crockett, M.J., Inference of Trustworthiness from Intuitive Moral Judgments (2016) Journal of Experimental Psychology: General, 145 (6), p. 772; Foot, P., The Problem of Abortion and the Principle of Double Effect (1967) Oxford Review, 5, pp. 5-15; Gert, J., (2012) Normative Bedrock, , Oxford, Oxford University Press; Greene, J.D., The Secret Joke of Kant's Soul (2007) Moral Psychology: The Neuroscience of Morality: Emotion, Brain Disorders, and Development, pp. 35-80. , W. Sinnott-Armstrong. Cambridge, MA, MIT Press. 3; Hauser, M.D., (2006) Moral Minds: How Nature Designed Our Universal Sense of Right and Wrong, , New York, HarperCollins; The Martian (2015), www.imdb.com/title/tt3659388/, Retrieved 14th Oct., 2016; Jackson, F., Critical Notice (1992) Australasian Journal of Philosophy, 70 (4), pp. 475-488; McIntyre, A., Doing Away with Double Effect (2001) Ethics, 111 (2), pp. 219-255; Melaugh, M., The Hunger Strike of 1981-List of Dead and Other Hunger Strikers (2016), http://cain.ulst.ac.uk/events/hstrike/chronology.htm, Retrieved 27th Oct., 2016; Peel, M., Hunger Strikes (1997) BMJ, 315, pp. 829-830; Pereira, L.M., Saptawijaya, A., (2016) Programming Machine Ethics, , London, Springer; Prior, A.N., (1957) Time and Modality, , Oxford, Oxford University Press; Prior, A.N., The Autonomy of Ethics (1960) Australasian Journal of Philosophy, 38 (3), pp. 199-206; Prior, A.N., (1967) Past, Present and Future, , Oxford, Clarendon Press Oxford; Rachels, J., Active and Passive Euthanasia (1975) The New England Journal of Medicine, 292 (2), p. 78; Rawls, J., (1972) A Theory of Justice, , Oxford, Clarendon Press; Reader, S., (2007) Needs and Moral Necessity, , London; New York, Routledge; Ross, A., Imperatives and Logic (1941) Theoria, 7 (1941), pp. 53-71; Scanlon, T., (1998) What We Owe to Each Other, , Cambridge, MA, Harvard University Press; Singer, P., The Drowning Child and the Expanding Circle (1997) New Internationalist, 289, pp. 28-30; (2016) Public Safety and Aquatic Rescue, , Chatswood NSW, Elsevier Australia; Timmons, M., (2002) Moral Theory: An Introduction, , Lanham, Rowman & Littlefield; Weir, A., (2014) The Martian, , London, Del Ray; Wiggens, D., (1982) Needs, Values and Truth: Essays in the Philosophy of Value, , Oxford, Oxford University Press; Wood, A., Trolley Problems (2011) On What Matters, pp. 66-82. , D. Parfit. Oxford, Oxford University Press. 2; Aquinas, T., (1947) Summa Theologica, , (trans. Fathers of the Dominican Province) New York: Benziger Bros; Arntz, M., Gregory, T., Zierahn, U., The Risk of Automation for Jobs in OECD Countries: A Comparative Analysis (2016), http://dx.doi.org/10.1787/5jlz9h56dvq7-en, OECD Social, Employment and Migration Working Papers, No. 189, OECD Publishing, Paris; Ashford, E., Mulgan, T., Contractualism (2012), http://plato.stanford.edu/archives/fall2012/entries/contractualism/, Stanford Encyclopedia of Philosophy. Retrieved 31st Oct., 2016; Brock, G., Needs and Global Justice (2005) The Philosophy of Need, pp. 51-72. , S. Reader. Cambridge, Cambridge University Press. Royal Institute of Philosophy Supplement 57; Dunlop, T., (2016) Why the Future Is Workless, , Sydney, NewSouth; Ford, M., (2015) Rise of the Robots: Technology and the Threat of a Jobless Future, , London, Oneworld; Frey, C.B., Osborne, M.A., Holmes, C., Rahbari, E., Curmi, E., Garlick, R., Chua, J., Wilkie, M., Technology at Work v. 2.0: The Future Is Not What It Used To Be (2016), www.oxfordmartin.ox.ac.uk/downloads/reports/Citi_GPS_Technology_Work_2.pdf, Retrieved 28th Sep., 2016; Frohlich, N., Oppenheimer, J., (1992) Choosing Justice: An Experimental Approach to Ethical Theory, , Berkeley, CA, University of California Press; Hauser, M.D., (2006) Moral Minds: How Nature Designed Our Universal Sense of Right and Wrong, , New York, HarperCollins; The Martian (2015), www.imdb.com/title/tt3659388/, Retrieved 14th Oct., 2016; Kant, I., Groundwork of the Metaphysics of Morals (1785), http://www.gutenberg.org/ebooks/5682, Retrieved 29th Nov, 2015; Nozick, R., (1974) Anarchy, State and Utopia, , Oxford, Blackwell; O'Neill, O., Consequences for Non-Consequentialists (2004) Utilitas, 16 (1), pp. 1-11; Parfit, D., (2011) On What Matters, , Oxford; New York, Oxford University Press; Piketty, T., (2014) Capital in the Twenty-First Century, , Cambridge, MA, Harvard University Press; Weir, A., (2014) The Martian, , London, Del Ray; Korsgaard, C.M., (2009) Self-Constitution: Agency, Identity, and Integrity, , Oxford; New York, Oxford University Press; Rachels, S., Rachels, J., (2014) The Elements of Moral Philosophy, , Dubuque, McGraw- Hill Education; Wolf, S., Hiking the Range (2011) On What Matters, pp. 33-57. , S. Schleffer. Oxford, Oxford University Press. 2; Dancy, J., (2004) Ethics without Principles, , Oxford, Oxford University Press; Arkin, R.C., (2009) Governing Lethal Behaviour in Autonomous Robots, , Boca Rouge, CRC Press; Arkin, R.C., The Case for Ethical Autonomy in Unmanned Systems (2010) Journal of Military Ethics, 9 (4), pp. 332-341; Bekey, G.A., (2005) Autonomous Robots: From Biological Inspiration to Implementation and Control, , Cambridge, MA, MIT press; (2016) Robots and Robotic Devices: Guide to the Ethical Design and Application of Robots and Robotic Systems, , London, BSI Standards Ltd; The COSMIC Functional Size Measurement Method (2015), http://cosmic-sizing.org/publications/introduction-to-the-cosmicmethod-of-measuring-software/, Retrieved 30th Aug., 2015; Croitoru, M., Oren, N., Miles, S., Luck, M., Graphical Norms via Conceptual Graphs (2012) Knowledge-Based Systems, 29, pp. 31-43; The Role of Autonomy in DoD Systems (2012), http://fas.org/irp/agency/dod/dsb/autonomy.pdf; Principles of Robotics (2010), www.epsrc.ac.uk/research/ourportfolio/themes/engineering/activities/principlesofrobotics/, Retrieved 19th Jan., 2017; Galliott, J., Responsibility and War Machines: Towards a Forward-Looking and Functional Account (2015) Rethinking Machine Ethics in the Age of Ubiquitous Technology, pp. 152-165. , J. White and R. Searle. Hershey, PA, IGI Global; Heyns, C., Panel on Human Rights and Lethal Autonomous Weapons Systems (LAWS) Comments by Christof Heyns, United Nations Special Rapporteur on Extrajudicial, Summary or Arbitrary Executions (as Finalised after the Meeting) (2015), http://unog.ch/80256EDD006B8954/(httpAssets)/1869331AFF45728BC1257E2D0050EFE0/$file/2015_LAWS_MX_Heyns_Transcript.pdf, Retrieved 28th May, 2015; Leveringhaus, A., (2016) Ethics and Autonomous Weapons, , London, Palgrave Macmillan; Lin, P., The Right to Life and the Martens Clause (2015), http://unog.ch/80256EDD006B8954/(httpAssets)/2B52D16262272AE2C1257E2900419C50/$file/24+Patrick+Lin_Patrick+SS.pdf, Retrieved 21st Apr., 2015; Madl, T., Franklin, S., Constrained Incrementalist Moral Decision Making for a Biologically Inspired Cognitive Architecture (2015) A Construction Manual for Robots' Ethical Systems, pp. 137-153. , R. Trappl. London, Springer; Scharre, P., Autonomous Weapons and Operational Risk (2016), www.cnas.org/autonomous-weapons-and-operational-risk#.VtSsW_l97IU, Retrieved 1st Mar., 2016; Sparrow, R., Can Machines Be People? Reflections on the Turing Triage Test (2012) Robot Ethics: The Ethical and Social Implications of Robotics, pp. 301-316. , P. Lin, K. Abney and G. Bekey. Cambridge MA, MIT Press},
document_type={Book},
source={Scopus},
}

@CONFERENCE{Yilmaz201763,
author={Yilmaz, L.},
title={Quantum cognition models of ethical decision-making in human behavior simulation},
journal={29th European Modeling and Simulation Symposium, EMSS 2017, Held at the International Multidisciplinary Modeling and Simulation Multiconference, I3M 2017},
year={2017},
pages={63-70},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035141075&partnerID=40&md5=51383da0e78c5c607989ffcb4ca8fc94},
abstract={Ethical decision-making is a unique aspect of human behavior. When confronted with situations that require careful deliberation over multitude of options that have ethical implications, human behavior tends to resolve dilemmas by resorting to a range of heuristics and principles that view the situation from different perspectives. While constraint and utility-driven decision-making strategies are relevant, the incompatibility among these perspectives can invalidate the underlying premises of models of probabilistic utility-based decisions that rely on classic Kolmogorov axioms. In this paper, it is posited that quantum cognition models can provide an alternative and credible representation of human behavior modeling in simulations that involve ethical decision-making.},
author_keywords={Computational ethics;  Ethical decision-making;  Machine ethics;  Quantum cognition},
keywords={Behavioral research;  Philosophical aspects;  Social sciences, Computational ethics;  Decision-making strategies;  Ethical decision making;  Ethical implications;  Human behavior modeling;  Human behaviors;  Kolmogorov;  Quantum cognition, Decision making},
references={Anderson, M., Anderson, S.L., Geneth: A general ethical dilemma analyzer (2014) AAAI, pp. 253-261; Anderson, M., Anderson, S.L., Machine ethics (2011) Cambridge University Press; Anderson, M., Anderson, S.L., Armen, C., An approach to computing ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 56-63; APS Physics, 2017. , https://www.aps.org/programs/education/ethics/, Ethics Case Studies; Arkin, R., (2009) Governing Lethal Behavior in Autonomous Robots, , CRC Press; Arkoudas, S.B., Bello, P., Toward ethical robots via mechanized deontic logic (2005) AAAI Fall Symposium on Machine Ethics; Blutner, R., Beim Graben, P., Quantum cognition and bounded rationality (2016) Synthese, 193 (10), pp. 3239-3291; Bruza, P.D., Wang, Z., Busemeyer, J.R., Quantum cognition: A new theoretical approach to psychology (2015) Trends in Cognitive Sciences, 19 (7), pp. 383-393; Busemeyer, J.R., Bruza, P.D., Quantum models of cognition and decision (2012) Cambridge University Press; Gert, B., (1998) Morality: Its Nature and Justification. Oxford, , University Press on Demand; Greene, J., Rossi, F., Tasioulas, J., Venable, K.B., Williams, B., Embedding ethical principles in collective decision support systems (2016) AAAI, pp. 4147-4151. , February; Dennis, L., Fisher, M., Slavkovik, M., Webster, M., Ethical choice in unforeseen circumstances (2013) Conference Towards Autonomous Robotic Systems, pp. 433-445. , Springer Berlin Heidelberg; Etzioni, A., Etzioni, O., AI assisted ethics (2016) Ethics and Information Technology, 18 (2), pp. 149-156; Gips, J., Towards the ethical robot (1995) Android Epistemology, 1995, pp. 243-252; Herman, M., Moral heuristics and biases (2014) Journal of Cognition and Neuro-ethics, 73 (1), pp. 127-142; Kurland, N.B., Ethical intentions and the theories of reasoned action and planned Behavior1 (1995) Journal of Applied Social Psychology, 25 (4), pp. 297-313; Kurzweil, R., (2012) How to Create A Mind: The Secret of Human Thought Revealed, , Penguin; McLaren, B.M., Computational models of ethical reasoning: Challenges, initial steps, and future directions (2006) IEEE Intelligent Systems, 21 (4), pp. 29-37; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Saptawijaya, A., Pereira, L.M., Moral reasoning under uncertainty Springer Berlin Heidelberg (2012) International Conference on Logic for Programming Artificial Intelligence and Reasoning, pp. 212-227. , March Springer Berlin Heidelberg; Trueblood, J.S., Busemeyer, J.R., (2012) A Quantum Probability Model of Causal Reasoning; Wallach, W., Allen, C., Moral machines: Teaching robots right from wrong (2009) Oxford, , University Press; Yilmaz, L., Franco-Watkins, A., Kroecker, T.S., Coherence-driven reflective equilibrium model of ethical decision-making (2016) Cognitive Methods in Situation Awareness and Decision Support (CogSIMA), 2016, pp. 42-48. , IEEE International Multi-Disciplinary Conference on IEEE; Yilmaz, L., Franco-Watkins, A., Kroecker, T.S., Computational models of ethical decisionmaking: A coherence-driven reflective equilibrium model (2017) Cognitive Systems Research, , http://doi.org/10.1016/j.cogsys.2017.02.005},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor20171,
title={2nd International Conference on Love and Sex with Robots, LSR 2016},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10237 LNAI},
pages={1-147},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017981349&partnerID=40&md5=10e9fd7c78e7bd1617f9f0b71dae28e4},
abstract={The proceedings contain 13 papers. The special focus in this conference is on Love and Sex with Robots. The topics include: Sex robots from the perspective of machine ethics; a lollipop device for remote oral interaction; a robotic 3D-movie theater allowing interaction and multimodal experiences; an empirical study on influences of personality traits and personal characteristics on the intention to buy a sex robot; exploration of relational factors and the likelihood of a sexual robotic experience; the impact of a humanlike communication medium on the development of intimate human relationship; kissenger – development of a real-time internet kiss communication interface for mobile phones; sex with robots for love free encounters; a preliminary study of perceptions, and intimacies with robots.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Welsh201735,
author={Welsh, S.},
title={Formalizing complex normative decisions with predicate logic and graph databases},
journal={Intelligent Systems, Control and Automation: Science and Engineering},
year={2017},
volume={84},
pages={35-45},
doi={10.1007/978-3-319-46667-5_3},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010450462&doi=10.1007%2f978-3-319-46667-5_3&partnerID=40&md5=ee2f714fd0425c598ec64c2865466622},
abstract={This paper argues that the critical work in deontic reasoning is better done in the knowledge representation rather than the reasoning of a normative system. It describes a way to formalize complex normative decisions using predicate logic and graph databases. Simple norms can be mechanized with IF/THEN statements. While often expressed in deontic logic, such statements can be expressed in simpler predicate logic. More complex normative decisions require the ability to make decisions where there are multiple clashing duties. Such decisions could be formalized in graph databases that express state-act transition relations, causal relations, classification relations and evaluation relations. When formalizing complex normative decisions it is more powerful and practical to draw upon concepts from multiple moral theories rather than restricting the system to a single theory. A normative system with extensive knowledge representation of complex relations might be able to pass a series of reasonable person tests. Passing such tests rather than implementing a particular moral theory should be the main design aim of normative systems. © Springer International Publishing AG 2017.},
author_keywords={Artificial moral agent;  Ethical governor;  Knowledge representation;  Machine ethics;  Normative systems;  Robot ethics},
references={Nichomachean Ethics, , http://classics.mit.edu/Aristotle/nicomachaen.html, (c. 350 BC), MIT, Accessed 29 Nov 2015; Asimov, I., Runaround (1942) Astounding Science Fiction, , Street & Smith, New York; Bringsjord, S., Arkoudas, C., Bello, P., Toward a general logicist methodology for engineering ethical correct robots (2006) IEEE Intell Syst, 21 (4), pp. 38-44; Castañeda, H., The paradoxes of deontic logic: The simplest solution to all of them in one fell swoop (1981) New Studies in Deontic Logic, pp. 37-86. , Hilpinen R, D. Reidel Publishing Company, Dordrecht; Gabbay, D., Horty, J., Parent, X., van der Mayden, R., van der Torre, L., (2013) Handbook of Deontic Logic and Normative Systems, 1. , College Publications, Milton Keynes; Hansson, S., The Varieties of Permission (2013) Handbook of Deontic Logic and Normative Systems, 1, pp. 195-240. , Gabbay D, Horty J, Parent X, R V, Van der Torre L, College Publications, Milton Keynes; Horty, J., (2001) Agency and Deontic Logic, , Oxford University Press, Oxford; Jackson, F., Critical notice (1992) Aust J Philos, 70 (4), pp. 475-488; Krotzsch, M., Simanzik, F., Horrocks, I., A description logic primer (2012) Computing Research Repository, , http://arxiv.org/pdf/1201.4089.pdf, Accessed 12 Dec 2014; Maslow, A., (1954) Motivation and Personality, , Harper & Row, New York; McCune, W., (2010) Prover 9 and Mace 4, , http://www.cs.unm.edu/~mccune/Prover9; Noddings, N., (1984) Caring: A Feminine Approach to Ethics and Moral Education, , 1st edn. University of California Press, Berkeley; Nozick, R., (1981) Philosophical Explanations, , Belknap Press, Cambridge, Mass; Pigden, C., Logic and the autonomy of ethics (1989) Aust J Philos, 67 (2), pp. 127-151; Reader, S., (2007) Needs and Moral Necessity, , Routledge, London, New York; Robinson, I., Webber, J., Eifrem, E., (2015) Graph Databases, , O’Reilly, Sebastapol, CA; Ross, W., (1930) The Right and the Good, , The Clarendon Press, Oxford; Sowa, J., Conceptual graphs (1992) Knowl Based Syst, 5 (3), pp. 171-172; Treiber, M., (2010) An Introduction to Object Recognition: Selected Algorithms for a Wide Variety of Applications, , Springer, London},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Kyriakidou2017109,
author={Kyriakidou, M. and Padda, K. and Parry, L.},
title={Reporting robot ethics for children-robot studies in contemporary peer reviewed papers},
journal={Intelligent Systems, Control and Automation: Science and Engineering},
year={2017},
volume={84},
pages={109-117},
doi={10.1007/978-3-319-46667-5_8},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010403611&doi=10.1007%2f978-3-319-46667-5_8&partnerID=40&md5=b91f8266664efd1f100a4d8953945f5c},
abstract={How are robot ethics described in peer-reviewed papers for children-robot studies? Do publications refer to robot ethics such as: (a) gaining children’s assent, (b) providing a robot’s description prior to data collection, (c) having a robot exposure phase before data collection and (d) informing children about a robot’s semi-autonomy or not? A total of 27 peer-reviewed papers with an average impact factor of 1.8 were analysed. 63 % of the studies did not state any ethical procedures followed. In eight studies children gave their assent for the experiment; six studies described the robot to children prior to data collection; two studies provided a robot exposure phase prior to data collection and one study informed children that robots are operated machines. The outcomes indicate problematic applications of robot ethics in peer-reviewed journals and the necessity for the publishing industry to consider stricter actions on this aspect of a publication. © Springer International Publishing AG 2017.},
author_keywords={Children-robot interaction;  Children’s assent;  Ethics;  Robot ethics},
references={(2010) Ethical Principles of Psychologists and Code of Conduct; (2011) Code of Conduct; (1969) Family Law Reform Act; Cristina, P., Andreea, P., Sebastian, P., Ramona, S., Bram, W., Deviel, D., Imitation and social behaviors of chidren with ASD in interaction with Robonova. A series of single case experiments. Transylvanian (2013) J Psychol, 14 (1), p. 71; Kyriakidou, M., Discussing robot crime interviewers for children’s forensic testimonies: A relatively new field for investigation (2014) AI Soc.; Moriguchi, Y., Kanda, T., Ishiguro, H., Shimada, Y., Itajura, S., Can young children learn words from a robot? (2011) Interact Stud, 12 (1), pp. 107-118; Prout, A., Researching children as social actors (2002) Child Soc, 16 (2), pp. 67-76; Sharkey, N., Sharkey, A., The crying shame of robot nannies: An ethical appraisal (2010) J Interact Stud, 11, pp. 161-190; Somanader, M., Saylor, M., Levin, D., Remote control and children’s understanding of robots (2011) J Exp Child Psychol, 109, pp. 239-247; (1989) UN Convention on the Right of the Child; Wood, L., Dautenhahn, K., Rainer, A., Robins, B., Lehmann, H., Syrdal, D., Robot-mediated interviews: How effective is a humanoid robot as a tool for interviewing young children? (2013) PLOS, International Conference on Social Robotics},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Martins2017233,
author={Martins, J.M.},
title={The robot steps in: From normative to prospective ethics},
journal={Intelligent Systems, Control and Automation: Science and Engineering},
year={2017},
volume={84},
pages={233-238},
doi={10.1007/978-3-319-46667-5_19},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010392558&doi=10.1007%2f978-3-319-46667-5_19&partnerID=40&md5=9d13bac6f34caf15724c7e66f5388c58},
abstract={The present paper reports the role played by the cinema cycle associated to the International Conference on Robot Ethics (ICRE 2015), that was open to the general public. Reflecting on the grounding motivations leading to this international conference, the paper analyses the role played by fiction and film industry in the definition and anticipation of a future world where humans and intelligent machines will coexist. © Springer International Publishing AG 2017.},
author_keywords={Ethics;  Fiction;  Robots;  Societal models},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Mansouri2016152,
author={Mansouri, N. and Goher, K.},
title={Towards ethical framework for personal care robots: Review and reflection},
journal={Asian Social Science},
year={2016},
volume={12},
number={10},
pages={152-162},
doi={10.5539/ass.v12n10p152},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989165793&doi=10.5539%2fass.v12n10p152&partnerID=40&md5=b9de6a4f018b9f4b06dd03c1200e607f},
abstract={In recent decades, robots have been used noticeably at various industries. Autonomous robots have been embedded in human lives especially in elderly and disabled lives. Elderly population is growing worldwide significantly; therefore there is an increased need of personal care robots to enhance mobility and to promote independence. A great number of aging and disabled hold appeals for using robots in daily routine tasks as well as for various healthcare matters. It is essential to follow a proper framework in ethics of robot design to fulfill individual needs, whilst considering potential harmful effects of robots. This paper primarily focuses on the existing issues in robot ethics including general ethics theories and ethics frameworks for robots. Consequentialism ethics will be recommended to be applied in robot ethics frameworks. © 2016, Canadian Center of Science and Education. All rights reserved.},
author_keywords={Consequential ethics;  Deontology ethics;  Robot ethics;  Robot ethics framework;  Virtue ethics},
references={Aarts, E., Ambient intelligent: A multimedia perspective (2004) IEEE Multimedia, 11 (1), pp. 12-19. , http://dx.doi.org/10.1007/978-3-540-73281-5_11; Alaiad, A., Zhou, L., The determinants of home healthcare robots adoption: An empirical investigation (2014) International Journal of Medical Informatics, 83 (11), pp. 825-840. , http://dx.doi.org/10.1016/j.ijmedinf.2014.07.003; Albrechtslund, A., (2007) House 2.0: Towards an Ethics for Surveillance in Intelligent Living and Working Environments. Proceedings of the Seventh International Conference of Computer Ethics Philosophical Enquiry, pp. 7-16. , San Diego, USA: University of San Diego; Alexander, L., Moore, M., (2007) Deontological Ethics; Asaro, P., What should we want from a robot ethic? (2006) Ethics and Robotics, , R. Capurro, & M. Nagenborg (Eds.), Amsterdam, the Netherlands: IOS Press; Augusto, J.C., McCullagh, P.J., Augusto-Walkden, J.-A., Living without a safety net in an intelligent environment (2011) ICST Transactions on Ambient Systems, 11 (10-12), pp. e6. , http://dx.doi.org/10.4108/trans.amsys.2011.e6; Ball, M., Callaghan, V., Perceptions of autonomy: A survey of users’ opinions towards autonomy in intelligent environments (2011) Proceedings of the 7Th International Conference on Intelligent Environments, pp. 277-284. , http://dx.doi.org/10.1109/IE.2011.68, Amsterdam: IOS Press; Beauchamp, T.L., Childress, J.F., (2001) Principles of Biomedical Ethics, , Oxford: Oxford University Press; Belloni, A., Berger, A., Besson, V., Boissier, O., Bonnet, G., Bourgne, G., Jaillon, P., June). Towards a Framework to Deal with Ethical Conflicts in Autonomous Agents and Multi-Agent Systems (2014) CEPE, p. 2014. , Well-Being, Flourishing, and ICTs; Bohn, J., Coroama, V., Langheinrich, M., Mattern, F., Rohs, M., Living in a world of smart everyday objects-Social, economic, and ethical implications (2004) Human and Ecological Risk Assessment, 10 (5), pp. 763-785. , http://dx.doi.org/10.1080/10807030490513793; Bowen, S.A., Expansion of ethics as the tenth generic principle of public relations excellence: A Kantian theory and model for managing ethical issues (2004) Journal of Public Relations Research, 16 (1), pp. 65-92. , http://dx.doi.org/10.1207/s1532754xjprr1601_3; Brey, P., Freedom and privacy in ambient intelligent (2005) Ethics and Information Technology, 7 (3), pp. 157-166. , http://dx.doi.org/10.1007/s10676-006-0005-3; Brown, I., Adams, A., Ethical challenges of ubiquitous healthcare (2007) International Review of Information Ethics, 8 (12), pp. 53-60; Caire, P., Moawad, A., Efthymiou, V., Bikakis, A., Le Traon, Y., Privacy challenges in ambient intelligent systems: Lessons learned, gaps and perspectives (2014) Journal of Ambient Intelligent and Smart Environments, 1, pp. 1-23; Callaghan, V., Clarke, G., Chin, J., Some socio-technical aspects of intelligent buildings and pervasive computing research (2009) Intelligent Buildings International, 1 (1), pp. 56-74. , http://dx.doi.org/10.3763/inbi.2009.0006; Chan, M., Campo, E., Estève, D., Fourniols, J.-Y., Smart homes-Current features and future perspectives (2009) Maturitas, 64, pp. 90-97. , http://dx.doi.org/10.1016/j.maturitas.2009.07.014; Coeckelbergh, M., Health care, capabilities, and AI assistive technologies (2010) Ethical Theory and Moral Practice, 13 (2), pp. 181-190. , http://dx.doi.org/10.1007/s10677-009-9186-2; Coughlin, J.F., D’Ambrosio, L.A., Reimer, B., Pratt, M.R., Older adult perceptions of smart home technologies: Implications for research, policy & market innovations in healthcare (2007) Proceedings of the 29Th Annual International Conference of IEEE Engineering in Medicine and Biology Society, pp. 1810-1815. , http://dx.doi.org/10.1109/IEMBS.2007.4352665; Crossan, M., Mazutis, D., Seijts, G., In search of virtue: The role of virtues, values and character strengths in ethical decision making (2013) Journal of Business Ethics, 113 (4), pp. 567-581. , http://dx.doi.org/10.1007/s10551-013-1680-8; Cummiskey, D., Consequentialism (2013) The International Encyclopedia of Ethics, , http://dx.doi.org/10.1002/9781444367072.wbiee428; Draper, H., Sorell, T., Ruiz, S.B.C.G., Lehmann, H., Hervé, M., Gelderblom, G.J., Dautenhahn, K., Amirabdollahian, F., What asking potential users about ethical values adds to our understanding of an ethical framework for social robots for older people (2014) Proceeding of the MEMCA-14; Faden, R.R., Kass, N.E., Goodman, S.N., Pronovost, P., Tunis, S., Beauchamp, T.L., An ethics framework for a learning health care system: A departure from traditional research ethics and clinical ethics (2013) Hastings Center Report, 43 (s1), pp. S16-S27. , http://dx.doi.org/10.1002/hast.134; Friedewald, M., Da Costa, O., Punie, Y., Alahuhta, P., Heinonen, S., Perspectives of ambient intelligent in the home environment (2005) Telematics Informatics, 22, pp. 221-238. , http://dx.doi.org/10.1016/j.tele.2004.11.001; Hert, P.D., Gutwirth, S., Moscibroda, A., Wright, D., González Fuster, G., Legal safeguards for privacy and data protection in ambient intelligent (2009) Personal and Ubiquitous Computing, 13 (6), pp. 435-444. , http://dx.doi.org/10.1007/s00779-008-0211-6; Hewson, D.J., Gutierrez Ruiz, C., Michel, H., Development of a multidimensional evaluation method for the use of a robotic companion as a function of care relationships (2014) Gerontechnology, 13 (2), p. 79; Hoffman, W.M., Frederick, R.E., Schwartz, M.S., (2014) Business Ethics: Readings and Cases in Corporate Morality, , John Wiley & Sons; Hursthouse, R., Normative virtue ethics (2013) ETHICA, p. 645; Ikonen, V., Kaasinen, E., Niemelaa, M., Defining ethical guidelines for ambient intelligent applications on a mobile phone (2009) Proceedings of the 5Th International Conference on Intelligent Environments, pp. 261-268. , Amsterdam: IOS Press; Johnson, R., Kant's moral philosophy (2008) Stanford Encyclopedia of Philosophy; Jones, S., Hara, S., Augusto, J.C., EFRIEND: An ethical framework for intelligent environments development (2015) Ethics and Information Technology, 17 (1), pp. 11-25. , http://dx.doi.org/10.1007/s10676-014-9358-1; Kaasinen, E., Kymäläinen, T., Niemelä, M., Olsson, T., Kanerva, M., Ikonen, V., A user-centric view of intelligent environments: User expectations, user experience and user role in building intelligent environments (2013) Computers, 2, pp. 1-33. , http://dx.doi.org/10.3390/computers2010001; Landau, R., Auslander, G.K., Werner, S., Shoval, N., Heinik, J., Families’ and professional caregivers’ views of using advanced technology to track people with dementia (2010) Qualitative Health Research, 20 (3), pp. 409-419. , http://dx.doi.org/10.1177/1049732309359171; Langheinrich, M., Coroama, V., Bohn, J., Friedemann, M., Living in a smart environment-implications for the coming ubiquitous information society (2004) Telecommunications Review, 15 (1), pp. 132-143. , http://dx.doi.org/10.1109/ICSMC.2004.1401091; Lin, P., Abney, K., Bekey, G., Robot ethics: Mapping the issues for a mechanized world (2011) Artificial Intelligence, 175 (5), pp. 942-949. , http://dx.doi.org/10.1016/j.artint.2010.11.026; Lin, P., Abney, K., Bekey, G.A., (2011) Robot Ethics: The Ethical and Social Implications of Roboticsmit Press; Magnusson, L., Hanson, E.J., Ethical issues arising from a research, technology and development project to support frail older people and their family carers at home (2003) Health and Social Care in the Community, 11 (5), pp. 431-439. , http://dx.doi.org/10.1046/j.1365-2524.2003.00446.x; Mittelstadt, B., Fairweather, N.B., McBride, N., Shaw, M., Privacy, risk and personal health monitoring (2013) Proceedings of ETHICOMP 2013: The Possibilities of Ethical ICT, pp. 340-351; Morin, C., Dick, D.G., The Development of the Ethical Approach Scale: An Operationalization of Moral Theory (2015) In Academy of Management Proceedings, 1, p. 13236. , http://dx.doi.org/10.5465/AMBPP.2015.13236abstract; Nixon, P., Wagealla, W., English, C., Terzis, S., Security, privacy and trust issues in smart environments (2004) Smart Environments: Technology, Protocols and Applications, pp. 220-240. , D. Cook, & S. Das (Eds.); Nussbaum, M.C., (2006) Frontiers of Justice: Disability, Nationality, Species Membership, , http://dx.doi.org/10.1353/mod.2008.0014, London: Harvard University Press; Oishi, M.M.K., Mitchell, I., Machiel Van Der Loos, H.F.M., (2010) Design and Use of Assistive Technology: Social, Technical, Ethical, and Economic Challenges, , New York: Springer; Perry, J., Beyer, S., Holm, S., Assistive technology, telecare and people with intellectual disabilities: Ethical considerations (2009) Journal of Medical Ethics, 35, pp. 81-86. , http://dx.doi.org/10.1136/jme.2008.024588; Peterson, M., (2013) The Dimensions of Consequentialism: Ethics, Equality and Risk, , Cambridge University Press; Price, B.A., Adam, K., Nuseibeh, B., Keeping ubiquitous computing to yourself: A practical model for user control of privacy (2005) International Journal of Human-Computer Studies, 63 (1-2), pp. 228-253. , http://dx.doi.org/10.1016/j.ijhcs.2005.04.008; Rashidi, P., Mihailidis, A., A survey on ambient assisted living tools for older adults (2013) IEEE Journal of Information Technology in Biomedicine, 17 (3), pp. 579-590. , http://dx.doi.org/10.1109/JBHI.2012.2234129; Rouvroy, A., Privacy, data protection, and the unprecedented challenges of ambient intelligent (2008) Studies in Ethics, Law, Technology, 2 (1), pp. 1-51. , http://dx.doi.org/10.2202/1941-6008.1001; Sadri, F., Ambient intelligent: A survey (2011) ACM Computing Surveys, , http://dx.doi.org/10.1145/1978802.1978815; Sandler, R.L., (2013) Environmental Virtue Ethics, , Blackwell Publishing Ltd; Schülke, A., Plischke, H., Kohls, N., Ambient Assistive Technologies (AAT): Socio-technology as a powerful tool for facing the inevitable sociodemographic challenges? (2010) Philosophy, Ethics, and Humanities in Medicine, , http://dx.doi.org/10.1186/1747-5341-5-8; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics and Information Technology, 14 (1), pp. 27-40. , http://dx.doi.org/10.1007/s10676-010-9234-6; Shaw, W., Barry, V., (2015) Moral Issues in Business, , Cengage Learning; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Mind and Machine, 16, pp. 141-161. , http://dx.doi.org/10.1007/s11023-006-9030-6; Sullivan, R.J., (1989) Immanuel Kant’s Moral Theory. Cambridge, , England: Cambridge University Press; Sullivan, R.J., (1994) An Introduction to Kant’s Ethics, , New York: Cambridge University Press; Sun, H., De Florio, V., Gui, N., Blondia, C., Promises and challenges of ambient assisted living systems (2009) Proceedings of the 6Th International Conference on Information Technology: New Generations, pp. 1201-1207. , http://dx.doi.org/10.1109/ITNG.2009.169, IEEE; Van Heerde, H.J.W., Anciaux, N.L.G., Feng, L., Apers, P.M.G., Balancing smartness and privacy for ambient intelligent (2006) Proceedings of the 1St European Conference on Smart Sensing and Context (Eurossc) Lecture Notes in Computer Science, 4272, pp. 255-258; Van Hoof, J., Kort, H.S.M., Markopoulos, P., Soede, M., Ambient intelligent, ethics and privacy (2007) Gerontechnology, 6 (3), pp. 155-163. , http://dx.doi.org/10.4017/gt.2007.06.03.005.00; Van Hoof, J., Kort, H.S.M., Rutten, P.G.S., Duijnstee, M.S.H., Ageing-in-place with the use of ambient intelligent technology: Perspectives of older users (2011) International Journal of Medical Informatics, 80 (5), pp. 310-331. , http://dx.doi.org/10.1016/j.ijmedinf.2011.02.010; Van Hooft, S., (2014) Understanding Virtue Ethics, , Routledge; Van Wynsberghe, A., Designing robots for care: Care centered value-sensitive design (2013) Science and Engineering Ethics, 19 (2), pp. 407-433. , http://dx.doi.org/10.1007/s11948-011-9343-6; Veruggio, G., Operto, F., Roboethics: A bottom-up interdisciplinary discourse in the field of applied ethics in robotics (2006) In International Review of Information Ethics. Ed. Ethics in Robotics, pp. 2-8; Wallach, W., Franklin, S., Allen, C., A conceptual and computational model of moral decision making in human and artificial agents (2010) Topics in Cognitive Science, 2 (3), pp. 454-485. , http://dx.doi.org/10.1111/j.1756-8765.2010.01095.x; Weiser, M., Brown, J.S., Designing calm technology (1996) Power Grid Journal, 1 (1), pp. 75-85; (2016) Health Topics: Ageing, , http://www.who.int/topics/ageing/en/; Wright, D., Gutwirth, S., Friedewald, M., Vildjiounaite, E., Punie, Y., (2010) Safeguards in a World of Ambient Intelligent, , New York: Springer; Yampolskiy, R.V., (2013) Artificial Intelligence Safety Engineering: Why Machine Ethics is a Wrong Approach, pp. 389-396. , http://dx.doi.org/10.1007/978-3-642-31674-6_29, Springer Berlin Heidelberg; Zaad, L., Allouch, S.B., The influence of control on the acceptance of Ambient intelligent by elderly people: An explorative study (2008) Proceedings of Ami European Conference 2008, Nuremberg. Lecture Notes in Computer Science, 5355, pp. 58-74. , http://dx.doi.org/10.1007/978-3-540-89617-3_5},
document_type={Review},
source={Scopus},
}

@ARTICLE{Saptawijaya2016510,
author={Saptawijaya, A. and Moniz Pereira, L.},
title={Logic programming for modeling morality},
journal={Logic Journal of the IGPL},
year={2016},
volume={24},
number={4},
pages={510-525},
doi={10.1093/jigpal/jzw025},
art_number={jzw025},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019955201&doi=10.1093%2fjigpal%2fjzw025&partnerID=40&md5=a118d7c06632574b2b025af51502e157},
abstract={This article investigates the appropriateness of LP-based reasoning to machine ethics, an interdisciplinary field of inquiry that emerges from the need of imbuing autonomous agents with the capacity for moral decision making. The first contribution of the article is that of identifying morality viewpoints, as studied in moral philosophy and psychology, which are amenable to computational modelling, and then mapping them to appropriate LP-based reasoning features. The identified viewpoints are covered by two morality themes: moral permissibility and the dual-process model. In the second contribution, various LP-based reasoning features are applied to model these identified morality viewpoints, via classic moral examples taken offthe-shelf from the literature. For this purpose, our Qualm system, which features a combination of LP abduction, updating and counterfactuals, supported by LP tabling mechanisms, are mainly employed. The applications are also supported by other existing LP-based systems, featuring preference handling and probabilistic reasoning, which complement Qualm in addressing the morality viewpoints in question. © The Author 2016.},
author_keywords={Applications;  Computational morality;  Dual-process model;  Logic programming;  Machine ethics;  QUALM system},
references={Alferes, J.J., Brogi, A., Leite, J.A., Pereira, L.M., Evolving logic programs (2002), 2424, pp. 50-61. , In JELIA 2002 of LNCS. Springer; Alferes, J.J., Pereira, L.M., Swift, T., Abduction in well-founded semantics and generalized stable models via tabled dual programs. (2004) Theory and Practice of Logic Programming, 4, pp. 383-428; Anderson, M., Anderson, S.L., (2008) EthEl: toward a principled ethical eldercare robot., , In Proceedings of AAAI Fall 2008 Symposium on AI in Eldercare; Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge University Press; Anderson, M., Anderson, S.L., Armen, C., (2005) AAAI Fall Symposium on Machine Ethics, , http://www.aaai.org/Library/Symposia/Fall/fs05-06; Boissier, O., Bonnet, G., Tessier, C., Workshop on Rights and Duties of Autonomous Agents (RDA2), , https://rda2-2012.greyc.fr/; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots. (2006) IEEE Intelligent Systems, 21, pp. 38-44; Cushman, F., Young, L., Greene, J.D., Multi-system moral psychology (2010), In The Moral Psychology Handbook. J. M. Doris, ed., Oxford University Press; Dell'Acqua, P., Pereira, L.M., Preferential theory revision. (2007) Journal of Applied Logic, 5, pp. 586-601; Economist, T., Morals and the Machine. (2012) Main Front Cover and Leaders, p. 13. , June 2nd-8th; Epstude, K., Roese, N.J., The functional theory of counterfactual thinking. (2008) Personality and Social Psychology Review, 12, pp. 168-192; Foot, P., The problem of abortion and the doctrine of double effect. (1967) Oxford Review, 5, pp. 5-15; Ganascia, J.-G., Modelling ethical rules of lying with answer set programming. (2007) Ethics and Information Technology, 9, pp. 39-47; Gelfond, M., Lifschitz, V., The stable model semantics for logic programming (1988), In 5th International Logic Programming Conference. MIT Press; Han, T.A., Ramli, C.D.K., Asio, C.V.D., (2008) An implementation of extended P-log using XASP., 5366. , In Proceedings of 24th International Conference on Logic Programming (ICLP'08) of LNCS. Springer; Han, T.A., Saptawijaya, A., Pereira, L.M., (2012) Moral reasoning under uncertainty, 7180, pp. 212-227. , In LPAR-18 of LNCS. Springer; Hauser, M., Cushman, F., Young, L., Jin, R.K., Mikhail, J., A dissociation between moral judgments and justifications. (2007) Mind and Language, 22, pp. 1-21; Higgins, C., (2014) US Navy funds morality lessons for robots, , http://goo.gl/EHNjzz; Kakas, A., Kowalski, R., Toni, F., Abductive logic programming (1992) Journal of Logic and Computation, 2, pp. 719-770; Kamm, F.M., Intricate Ethics: Rights, Responsibilities, and Permissible Harm. (2006), Oxford University Press; Kowalski, R., (2011) Computational Logic and Human Thinking: How to be Artificially Intelligent., , Cambridge University Press; Lopes, G., Pereira, L.M., (2006) Prospective programming with ACORDA., , In ESCoR 2006 Workshop, IJCAR'06; Lopes, G., Pereira, L.M., (2010) Prospective storytelling agents., 5937. , In PADL 2010 of LNCS. Springer; Lopes, G., Pereira, L.M., (2010) Visual demo of 'Princess-saviour Robot, , http://centria.di.fct.unl.pt/lmp/publications/slides/padl10/quick_moral_robot.avi, Available from; Mallon, R., Nichols, S., (2010) Rules. In The Moral Psychology Handbook, , J.M. Doris, ed., Oxford University Press; Markman, K.D., Gavanski, I., Sherman, S.J., McMullen, M.N., The mental simulation of better and worse possible worlds (1993) Journal of Experimental Social Psychology, 29, pp. 87-109; McCloy, R., Byrne, R.M.J., Counterfactual thinking about controllable events (2000) Memory and Cognition, 28, pp. 1071-1078; McIntyre, A., Doctrine of double effect (2004), http://plato.stanford.edu/archives/fall2011/entries/double-effect/, In The Stanford Encyclopedia of Philosophy, E. N. Zalta, ed., Center for the Study of Language and Information, Stanford University, Fall 2011 edition; Migliore, S., Curcio, G., Mancini, F., Cappa, S.F., Counterfactual thinking in moral judgment: an experimental study. (2014) Frontiers in Psychology, 5, p. 451; Newman, J.O., Quantifying the standard of proof beyond a reasonable doubt: a comment on three comments. (2006) Law, Probability and Risk, 5, pp. 267-269; Otsuka, M., Double effect, triple effect and the trolley problem: squaring the circle in looping cases. (2008) Utilitas, 20, pp. 92-110; Pereira, L.M., Software sans emotions but with ethical discernment. (2016), In Morality and Emotion: (Un)conscious Journey to Being, S. G. Silva, ed., Routledge; Pereira, L.M., Dell'Acqua, P., Pinto, A.M., Lopes, G., Inspecting and preferring abductive models. (2013), pp. 243-274. , In The Handbook on Reasoning-Based Intelligent Systems, K. Nakamatsu and L. C. Jain, eds. World Scientific Publishers; Pereira, L.M., Han, T.A., Evolution prospection (2009) Proceedings of KES International Conference on Intelligence Decision Technologies, 199, pp. 139-150; Pereira, L.M., Saptawijaya, A., Modelling morality with prospective logic (2011), pp. 398-421. , In Machine Ethics, M. Anderson and S. L. Anderson, eds. Cambridge University Press; Pereira, L.M., Saptawijaya, A., Bridging two realms of machine ethics (2015) In Rethinking Machine Ethics in the Age of Ubiquitous Technology, , J. B. White and R. Searle, eds, IGI Global; Pereira, L.M., Saptawijaya, A., (2016) Counterfactuals, logic programming and agent morality., , In Logic, Argumentation & Reasoning, R. Urbaniak and G. Payette, eds, Springer; Powers, T.M., Prospects for a Kantian machine (2006) IEEE Intelligent Systems, 21, pp. 46-51; Saptawijaya, A., Pereira, L.M., Incremental tabling for query-driven propagation of logic program updates (2013), 8312, pp. 694-709. , In LPAR-19 of LNCS. Springer; Saptawijaya, A., Pereira, L.M., Tabled abduction in logic programs (Technical Communication of ICLP 2013) (2013) Theory and Practice of Logic Programming, , http://journals.cambridge.org/downloadsup.php?file=/tlp2013008.pdf, Online Supplement, 13; Saptawijaya, A., Pereira, L.M., Joint tabling of logic program abductions and updates (Technical Communication of ICLP 2014) (2014) Theory and Practice of Logic Programming, , http://arxiv.org/abs/1405.2058, Online Supplement, 14. Available from; Saptawijaya, A., Pereira, L.M., Tabdual: a tabled abduction system for logic programs. (2015) IfCoLog Journal of Logics and their Applications, 2, pp. 69-123; Scanlon, T.M., (1998) What We Owe to Each Other., , Harvard University Press; Stanovich, K.E., (2011) Rationality and the Reflective Mind., , Oxford University Press; Swift, T., Tabling for non-monotonic programming. (1999) Annals of Mathematics and Artificial Intelligence, 25, pp. 201-240; (2015) International Grant Competition for Robust and Beneficial AI, , http://futureoflife.org/grants/large/initial; (2015) Research Priorities for Robust and Beneficial Artificial Intelligence, , http://futureoflife.org/static/data/documents/research_priorities.pdf; Thomson, J.J., The trolley problem. (1985) The Yale Law Journal, 279, pp. 1395-1415; van Gelder, A., Ross, K.A., Schlipf, J.S., The well-founded semantics for general logic programs. (1991) Journal of ACM,, 38, pp. 620-650; Wallach, W., Allen, C., Moral Machines: Teaching Robots Right from Wrong. (2009), Oxford University Press; White, J.B., Searle, R., (2015) Rethinking Machine Ethics in the Age of Ubiquitous Technology, , IGI Global; Wiegel, V., (2007) SophoLab: Experimental Computational Philosophy, , PhD Thesis, Delft University of Technology},
document_type={Article},
source={Scopus},
}

@BOOK{Swan201682,
author={Swan, M.},
title={Machine ethics interfaces: An ethics of perception of nanocognition},
journal={Leadership and Personnel Management: Concepts, Methodologies, Tools, and Applications},
year={2016},
volume={1},
pages={82-107},
doi={10.4018/978-1-4666-9624-2.ch004},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982914039&doi=10.4018%2f978-1-4666-9624-2.ch004&partnerID=40&md5=d8bc278d0de97c1789ffc4d11594ec59},
abstract={The purpose of this chapter is to conceptualize cognitive nanorobots, an ethics of perception, and machine ethics interfaces. Three areas are developed as a foundational background. First is the context and definition of cognitive nanorobots (nano-scale machines that could be deployed to facilitate, aid, and improve the processes of cognition like perception and memory as a sort of neural nano-prosthetics). Second is philosophical concepts from Bergson and Deleuze regarding perception and memory, and time, image, difference, becoming, and reality. Third is a summary of traditional models of ethics (Ethics 1.0). These building blocks are then used to connect perception and ethics in the concept of machine ethics interfaces, for which an ethics of perception is required, and where an ethics of immanence (Ethics 2.0) is most appropriate. Finally, killer applications of cognitive nanorobots, and their limitations (neural data privacy rights and cognitive viruses) and future prospects are discussed. © 2016 by IGI Global. All rights reserved.},
references={Ansell-Pearson, K., (2002) Philosophy and the Adventure of the Virtual: Bergson and the Time of Life, , London, UK: Routledge; Asimov, I., (1950) I, Robot, , New York, NY: Doubleday & Company; Bergson, H., (1957) Time and Free Will, , London, UK: Unwin; Bergson, H., (1988) Matter and Memory, , Brooklyn, NY: Zone Books; Bergson, H., (1999) Duration and Simultaneity, , Manchester, UK: Clinamen Press Ltd; Boehm, F., (2013) Nanomedical Device and Systems Design: Challenges, Possibilities, Visions, pp. 654-722. , New York, NY: CRC Press, especially Chapter 17: Nanomedicine in Regenerative Biosystems, Human Augmentation, and Longevity; Bon Jour, L., Epistemological Problems of Perception. (2013) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/spr2013/entries/perception-episprob/, E.N. Zalta (Ed.), Retrieved from; Boysen, E., (2014) Nanotechnology in Medicine - Nanomedicine, , http://www.understandingnano.com/medicine.html, UnderstandingNano.com. Retrieved from; Brey, P., Technology and Embodiment in Ihde and Merleau-Ponty (2000) Metaphysics, Epistemology, and Technology: Research in Philosophy and Technology, , http://www.utwente.nl/bms/wijsb/organization/brey/Publicaties_Brey/Brey_2000_Embodiment.pdf, C. Mitcham (Ed.), Retrieved from; Chiu, C.Y., Hong, Y.Y., Dweck, C.S., Lay dispositionism and implicit theories of personality (1997) Journal of Personality and Social Psychology, 73 (1), pp. 19-30; Clark, A., (1998) Being There: Putting Brain, Body, and World Together Again, , London, UK: Bradford Books; Colebrook, C., (2002) Understanding Deleuze, , Crows Nest, Australia: Allen & Unwin; Crane, T., The Problem of Perception. (2011) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/spr2011/entries/perceptionproblem/, E.N. Zalta (Ed.), Retrieved from; Deleuze, G., (1986) Cinema 1: The-Movement-Image, , Minneapolis, MN: University of Minnesota Press; Deleuze, G., (1989) Cinema 2: The Time-Image, , Minneapolis, MN: University of Minnesota Press; Deleuze, G., Guatarri, F., (1987) A Thousand Plateaus, , Minneapolis, MN: University of Minnesota Press; Deleuze, G., Guatarri, F., (1989) Anti-Oedipus, , Minneapolis, MN: University of Minnesota Press; Deleuze, G., Guatarri, F., (1996) What is Philosophy?, , New York, NY: Columbia University Press; Denning, T., Matsuoka, Y., Kohno, T., Neurosecurity: Security and privacy for neural devices (2009) Neurosurgical Focus, 27 (1), p. E7; Descartes, R., (1637) Dioptrics, , http://science.larouchepac.com/fermat/Descartes%20--%20Dioptrique.pdf, Retrieved from; Foucault, M., (1980) Power/Knowledge, , New York, NY: Pantheon Books; Franssen, M., Lokhorst, G.J., van de Poel, I., Philosophy of Technology. (2013) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/win2013/entries/technology/, E.N. Zalta (Ed.), Retrieved from; Freitas, R., Jr., (2003) Nanomedicine, Vol. IIA: Biocompatibility, , Austin, TX: Landes Bioscience. 1972-1977. Los Angeles CA: Semiotext(e); Heidegger, M., The Question Concerning Technology (1982) The Question Concerning Technology and Other Essays, , W. Lovitt, (Ed.), New York, NY: Harper and Row; Hu, C.M., Fang, R.H., Copp, J., Luk, B.T., Zhang, L., A biomimetic nanosponge that absorbs pore-forming toxins (2013) Nature Nanotechnology, 8 (5), pp. 336-340; Ihde, D., Bodies. (2001) Technology (Electronic Mediations), , Minneapolis, MN: University of Minnesota Press; Ihde, D., A phenomenology of technics. (2010) Technology and Values: Essential Readings, pp. 134-155. , C. Hanks (Ed.), New York, NY: Wiley-Blackwell; Kahneman, D., (2013) Thinking, Fast and Slow, , New York, NY: Farrar, Straus and Giroux; Kateb, B., Heiss, J.D., (2013) The Textbook of Nanoneuroscience and Nanoneurosurgery, , New York, NY: CRC Press; Kelly, K., Conversation: The Technium. (2014) Edge, , http://edge.org/memberbio/kevin_kelly, Retrieved from; Klapoetke, N.C., Murata, Y., Kim, S.S., Pulver, S.R., Birdsey-Benson, A., Cho, Y.K., Independent Optical Excitation of Distinct Neural Populations (2014) Nature Methods, 11 (3), pp. 338-346; Lanier, J., (2013) Who Owns the Future?, , New York, NY: Simon & Schuster; Mavroidis, C., (2014) Nano-Robotics in Medical Applications: From Science Fiction to Reality, , http://www.albany.edu/selforganization/presentations/2-mavroidis.pdf, Northeastern University. Retrieved from; McDonough, J., Descartes' "Dioptrics" and "Optics.". (2003) The Cambridge Descartes Lexicon, , L. Nolan (Ed.), Cambridge: Cambridge University Press; Nordmann, A., Responsible innovation, the art and craft of anticipation (2014) Journal of Responsible Innovation., 1 (1), pp. 87-98; Nummenmaa, L., Glerean, E., Hari, R., Hietanen, J.K., Bodily maps of emotions (2014) Proceedings of the National Academy of Sciences of the United States of America, 111 (2), pp. 646-651; Poell, T., Movement and Time in Cinema, Discernements: Deleuzian Aesthetics. (2004) Rodopi, pp. 1-21; Provenzale, J.M., Mohs, A.M., Nanotechnology in Neurology: Current Status and Future Possibilities (2010) US Neurology., 6 (1), pp. 12-17; Ross, L., Nisbett, R.E., (2011) The Person and the Situation: Perspectives of Social Psychology, , London, UK: Pinter & Martin Ltd; Schulz, M.J., Shanov, V.N., Yun, Y., (2009) Nanomedicine Design of Particles, Sensors, Motors, Implants, Robots, and Devices, , New York, NY: Artech House; Seo, D., Carmena, J.M., Rabaey, J.M., Alon, E., Maharbiz, M.M., Neural Dust: An Ultrasonic, Low Power Solution for Chronic Brain-Machine Interfaces (2013) arXiv, , http://arxiv.org/abs/1307.2196, 1307.2196 [q-bio.NC]. Retrieved from; Swan, M., Neural Data Privacy Rights: An Invitation For Progress (2014) What Should We Be Worried About?: Real Scenarios That Keep Scientists Up at Night, , The Guise Of An Approaching Worry. In J. Brockman (Ed.), New York, NY: Harper Perennial; Vitale, C., Guide to Reading Deleuze's The Movement-Image, Part I: The Deleuzian Notion of the Image, or Worldslicing as Cinema Beyond the Human. (2011) networkologies, , http://networkologies.wordpress.com/2011/04/04/thedeleuzian-notion-of-the-image-a-slice-of-theworld-or-cinema-beyond-the-human/, Retrieved from; Bergson, H., (1944) Creative Evolution, , New York, NY: The Modern Library; Colebrook, C., (2002) Gilles Deleuze, , London, UK: Routledge; Deleuze, G., (1990) Bergsonism, , New York, NY: Zone Books; Deleuze, G., (1994) Difference and Repetition, , New York, NY: Columbia University Press; Deleuze, G., (2000) Proust et les signes, , Minneapolis, MN: University of Minnesota Press; Deleuze, G., Parnet, C., (1987) Dialogues, , New York, NY: Columbia University Press; Guerlac, S., (2006) Thinking in Time: An Introduction to Henri Bergson, , Cornell, NY: Cornell University Press; Meacham, D.E., Medicine and society, new continental perspectives (Preface). (2014) Medicine and Society, New Continental Perspectives, , D. E. Meacham (Ed.), New York, NY: Springer; Wheeler, M., Embodied Cognition and the Extended Mind. (2011) The Continuum Companion to Philosophy of Mind, pp. 220-238. , J. Garvey (Ed.), London, UK: Bloomsbury Companions; Williams, J., (2003) Gilles Deleuze's "Difference and Repetition": A Critical Introduction and Guide, , Edinburgh, UK: Edinburgh University Press},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Wandmacher2016240,
author={Wandmacher, S.F.},
title={The bright line of ethical agency},
journal={Techne: Research in Philosophy and Technology},
year={2016},
volume={20},
number={3},
pages={240-257},
doi={10.5840/techne2016102858},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027000659&doi=10.5840%2ftechne2016102858&partnerID=40&md5=f0b02eaa87639f53869d0e61129a1844},
abstract={In his article "The Nature, Importance, and Difficulty of Machine Ethics," James H. Moor distinguishes two lines of argument for those who wish to draw a "bright line" between full ethical agents, such as human beings, and "weaker" ethical agents, such as machines whose actions have significant moral ramifications. The first line of argument is that only full ethical agents are agents at all. The second is that no machine could have the presumed features necessary for ethical agency. This paper shows why Moor is mistaken in his refutation of the first line of argument; it also makes a positive case that "weaker" ethical agents are not agents at all. This positive case, however, allows Moor's rejection of the second line of argument to stand: Allowing that there could be moral machines, but that these machines would have to be full moral agents and not merely something that models moral behavior or can be used in morally charged ways.},
author_keywords={Machine ethics;  Moor;  Moral agency;  Moral machines;  Tonkens},
references={Michael, A., Leigh Anderson, S., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-26; Susan Leigh, A., Anderson, M., The consequences for human beings of creating ethical Robots (2007) Human Implications of Human-Robot Interaction: Papers from the 2007 AAAI Workshop, pp. 1-4. , http://www.aaai.org/Papers/Workshops/2007/WS-07-07/WS07-07-001.pdf, Menlo Park, CA: AAAI Press, ed. Ted Metzler; Luciano, F., Sanders, J.W., On the morality of artificial agents (2004) Minds and Machines, 14 (3), pp. 349-379. , http://dx.doi.org/10.1023/B:MIND.0000035461.63578.9d; Rosalind, H., (1999) On Virtue Ethics, , Oxford: Oxford University Press; Johnson Deborah, G., Computer systems: Moral entities but not moral agents (2006) Ethics and Information Technology, 8 (4), pp. 195-204. , http://dx.doi.org/10.1007/s10676-006-9111-5; Immanuel, K., (1965) The Metaphysical Elements of Justice, , and trans. John Ladd. New York Macmillan 1797; Immanuel, K., (1990) Foundations of the Metaphysics of Morals, , 2nd ed., trans Lewis W. Beck. New York Macmillan, 1785; John Stuart, M., Remarks on bentham's philosophy (1985) The Collected Works of John Stuart Mill, 10. , Essays on Ethics, Religion, and Society, ed. John M. Robson. Toronto: University of Toronto Press 1833; John Stuart, M., (1991) Utilitarianism on Liberty and Other Essays, , ed. John Gray. Oxford: Oxford University Press1863; Moor James, H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21. , http://dx.doi.org/10.1109/MIS.2006.80; (1997) Plato: Complete Works, , ed. John M. Cooper. Indianapolis Hackett Protagoras Plato; Powers Thomas, M., On the moral agency of computers (2013) Topoi, 32 (2), pp. 227-236. , http://dx.doi.org/10.1007/s11245-012-9149-4; Pritchard Michael, S., Moral machines? (2012) Science and Engineering Ethics, 18 (2), pp. 411-417. , http://dx.doi.org/10.1007/s11948-012-9363-x; Robert, S., Killer robots (2007) Journal of Applied Philosophy, 24 (1), pp. 62-77. , http://dx.doi.org/10.1111/j.1468-5930.2007.00346.x; Sullins John, P., When is a robot a moral agent? (2006) International Review of Information Ethics, 6 (12), pp. 24-30; Ryan, T., A challenge for machine ethics (2009) Minds & Machines, 19 (3), pp. 421-438. , http://dx.doi.org/10.1007/s11023-009-9159-1; Ryan, T., Out of character: On the creation of virtuous machines (2012) Ethics and Information Technology, 14 (2), pp. 137-149. , http://dx.doi.org/10.1007/s10676-012-9290-1; Wendell, W., Allen, C., (2009) Moral Machines: Teaching Robots Right from Wrong, , http://dx.doi.org/10.1093/acprof:oso/9780195374049.001.0001, Oxford: Oxford University Press},
document_type={Article},
source={Scopus},
}

@ARTICLE{Pereira20167,
author={Pereira, L.M. and Saptawijaya, A.},
title={The individual realm of machine ethics: A survey},
journal={Studies in Applied Philosophy, Epistemology and Rational Ethics},
year={2016},
volume={26},
pages={7-18},
doi={10.1007/978-3-319-29354-7_2},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019764215&doi=10.1007%2f978-3-319-29354-7_2&partnerID=40&md5=d10f03482847c30ff6b6baa06506111f},
abstract={In this chapter, a survey of research in machine ethics is presented, providing the context and the motivation for our investigations. The survey concerns the individual realm of machine ethics, whereas the background to other realm, the collective one, is broached in Chap. 9, namely Sects. 9.1 and 9.2.1. The first realm views computation as a vehicle for representing moral cognition of an agent and its reasoning thereof, which motivates our investigation for employing Logic Programming (LP) knowledge representation and reasoning features with respect to the individual realm of machine ethics. On the other hand, the second realm emphasizes the emergence, in a population, of evolutionarily stable moral norms, of fair and just cooperation, that ably discards free riders and deceivers, to the advantage of the whole evolved population. It provides a motivation of our research for introducing cognitive abilities, such as intention recognition, commitment, revenge, apology, and forgiveness, to reinforce the emergence of cooperation in the collective realm of machine ethics. © Springer International Publishing Switzerland 2016.},
references={Alberti, M., Chesani, F., Gavanelli, M., Lamma, E., Torroni, P., Security protocols verification in abductive logic programming (2005) Proceedings of the 6Th International Workshop on Engineering Societies in the Agents World (ESAW), LNCS, 3963. , Springer; Anderson, M., Erson, S.L., EthEl: Toward a principled ethical eldercare robot (2008) Proceeding of the AAAI 2008 Fall Symposium on AI in Eldercare; Anderson, M., Erson, S.L., Robot be good: A call for ethical autonomous machines (2010) Scientific American, pp. 54-59; Anderson, M., Erson, S.L., GenEth: A general ethical dilemma analyzer (2014) Proceeding of the 28Th AAAI Conference on Artificial Intelligence; Anderson, M., Erson, S.L., Toward ensuring ethical behavior from autonomous systems: A case-supported principle based paradigm (2015) Proceeding of the AAAI Workshop on Artificial Intelligence and Ethics (1St International Workshop on AI and Ethics); Anderson, M., Erson, S.L., Armen, C., Towards machine ethics: Implementing two actionbased ethical theories (2005) Proceeding of the AAAI 2005 Fall Symposium on Machine Ethics; Anderson, M., Erson, S.L., Armen, C., An approach to computing ethics (2006) IEEE Intell. Syst, 21 (4), pp. 56-63; Anderson, M., Erson, S.L., Armen, C., MedEthEx: A prototype medical ethics advisor (2006) Proceeding of the 18Th Innovative Applications of Artificial Intelligence Conference (IAAI 2006); Arkoudas, K., Bringsjord, S., Bello, P., Toward ethical robots via mechanized deontic logic (2005) Proceedings of the AAAI 2005 Fall Symposium on Machine Ethics; Balsa, J., Dahl, V., Lopes, J.G.P., Datalog grammars for abductive syntactic error diagnosis and repair (1995) Proceedings of the Natural Language Understanding and Logic Programming Workshop; Baral, C., (2010) Knowledge Representation. Reasoning Anddeclarative Problem Solving, , Cambridge University Press, New York; Baral, C., Gelfond, M., Rushton, N., Probabilistic reasoning with answer sets (2009) Theory Pract. Logic Program, 9 (1), pp. 57-144; Beauchamp, T.L., Childress, J.F., (1979) Principles of Biomedical Ethics, , Oxford University Press, Oxford; Bok, S., (1989) Lying: Moral Choice in Public and Private Life, , Vintage Books, New York; Branting, L.K., (2000) Reasoning with Rules and Precedents, , Springer, Netherlands; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots (2006) IEEE Intell. Syst, 21 (4), pp. 38-44; Cushman, F., Young, L., Greene, J.D., Multi-system moral psychology (2010) The Moral Psychology Handbook, , Doris, J.M. (ed.), Oxford University Press, Oxford; Dancy, J., Moral particularism (2013) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/fall2013/entries/moral-particularism/, E.N. Zalta (ed.), Fall 2013 edn. Center for the Study of Language and Information, Stanford University; Daniels, N., Reflective equilibrium (2013) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/win2013/entries/reflective-equilibrium/, E.N. Zalta (ed.), Winter 2013 edn. Center for the Study of Language and Information, Stanford University; Dell’Acqua, P., Pereira, L.M., Preferential theory revision (2007) J. Appl. Log, 5 (4), pp. 586-601; Eshghi, K., Abductive planning with event calculus (1988) Proceedings of the International Conference on Logic Programming, , The MIT Press; Evans, J.S.B.T., (2010) Thinking Twice: Two Minds in One Brain, , Oxford University Press, Oxford; Ganascia, J.G., Modelling ethical rules of lying with answer set programming (2007) Eth. Inf.Technol., 9 (1), pp. 39-47; Gartner, J., Swift, T., Tien, A., Damásio, C.V., Pereira, L.M., Psychiatric diagnosis from the viewpoint of computational logic (2000) Proceedings of the 1St International Conference on Computational Logic (CL 2000), LNAI, 1861, pp. 1362-1376. , Springer; Guarini, M., Computational neural modeling and the philosophy of ethics: Reflections on the particularism-generalism debate (2011) Machine Ethics, , Anderson, M., Anderson, S.L. (eds.), Cambridge University Press, New York; Horty, J., (2001) Agency and Deontic Logic, , Oxford University Press, Oxford; Kakas, A., Kowalski, R., Toni, F., The role of abduction in logic programming (1998) Handbook of Logic in Artificial Intelligence and Logic Programming, 5. , Gabbay, D., Hogger, C., Robinson, J. (eds.), Oxford University Press, Oxford; Kakas, A.C., Mancarella, P., Knowledge assimilation and abduction (1990) International Workshop on Truth Maintenance, ECAI 1990; Kakas, A.C., Michael, A., An abductive-based scheduler for air-crew assignment (2001) J. Appl. Artif. Intell, 15 (1-3), pp. 333-360; Kant, I., (1981) Grounding for the Metaphysics of Morals, , translated by Ellington, J., Hackett, Indianapolis; Kowalski, R., (2011) Computational Logic and Human Thinking: How to Be Artificially Intelligent, , Cambridge University Press, New York, NY; Kowalski, R., Sadri, F., Abductive logic programming agents with destructive databases (2011) Ann. Math. Artif. Intell, 62 (1), pp. 129-158; Mallon, R., Nichols, S., Rules (2010) The Moral Psychology Handbook, , J.M. Doris (ed.), Oxford University Press, Oxford; McLaren, B.M., Extensionally defining principles and cases in ethics: An (2003) AI Model. Artif. Intell. J, 150, pp. 145-181; McLaren, B.M., Ashley, K.D., Case-based comparative evaluation in truthteller (1995) Proceedings of the 17Th Annual Conference of the Cognitive Science Society; Muggleton, S., Inductive logic programming (1991) New Gener. Comput, 8 (4), pp. 295-318; Murakami, Y., Utilitarian deontic logic (2004) Proceedings of the 5Th Advances in Modal Logic Conference (Aiml); (1996) The NSPE Ethics Reference Guide, , The National Society of Professional Engineers, Alexandria, VA; Pereira, L.M., Dell’Acqua, P., Pinto, A.M., Lopes, G., Inspecting and preferring abductive models (2013) The Handbook on Reasoning-Based Intelligent Systems, pp. 243-274. , K. Nakamatsu, L.C. Jain (eds.), World Scientific Publishers; Powers, T.M., Prospects for a Kantian machine (2006) IEEE Intell. Syst, 21 (4), pp. 46-51; Rawls, J., (1971) A Theory of Justice, , Harvard University Press, Cambridge; Ray, O., Antoniades, A., Kakas, A., Demetriades, I., Abductive logic programming in the clinical management of HIV/AIDS (2006) Proceeding of 17Th European Conference on Artificial Intelligence, , IOS Press; Reiter, R., A logic for default reasoning (1980) Artif. Intell, 13, pp. 81-132; Riguzzi, F., Swift, T., The PITA system: Tabling and answer subsumption for reasoning under uncertainty (2011) Theory Pract. Log. Program, 11 (4-5), pp. 433-449; Ross, W.D., (1930) The Right and the Good, , Oxford University Press, Oxford; Sinnott-Armstrong, W., Consequentialism (2014) The Stanford Encyclopedia of Philosophy, , http://plato.stanford.edu/archives/spr2014/entries/consequentialism/, E.N. Zalta (ed.), Spring 2014 edn. Center for the Study of Language and Information, Stanford University; Stanovich, K.E., (2011) Rationality and the Reflective Mind, , Oxford University Press, Oxford; Swift, T., Tabling for non-monotonic programming (1999) Ann. Math. Artif. Intell, 25 (3-4), pp. 201-240; Swift, T., Incremental tabling in support of knowledge representation and resoning (2014) Theory Pract. Log. Program, 14 (4-5), pp. 553-567; Swift, T., Warren, D.S., XSB: Extending Prolog with tabled logic programming (2012) Theory Pract. of Log. Program, 12 (1-2), pp. 157-187},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Pereira2016169,
author={Pereira, L.M. and Saptawijaya, A.},
title={Conclusions and further work},
journal={Studies in Applied Philosophy, Epistemology and Rational Ethics},
year={2016},
volume={26},
pages={169-171},
doi={10.1007/978-3-319-29354-7_11},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019751581&doi=10.1007%2f978-3-319-29354-7_11&partnerID=40&md5=d9fd714f4a6745db5a02ce97a1e246b7},
abstract={This book discusses the two realms of machine ethics, a field that is now becoming a pressing concern and receiving wide attention due to its growing importance. It makes a number of original inroads that exhibit a proof of possibility to systematically represent and reason about a variety of issues from the chosen moral facets by means of moral examples taken off-the-shelf from the morality literature. Given the broad dimension of the topic, the contributions in the book touch solely on a dearth of morality issues. Nevertheless, it prepares and opens the way for additional research towards employing various features available in LP-based reasoning and EGT to machine ethics. Moreover, we draw attention to some salient philosophical considerations underpinning and surging from our work. © Springer International Publishing Switzerland 2016.},
references={Anderson, M., Erson, S.L., EthEl: Toward a principled ethical eldercare robot (2008) Proceedings of the AAAI 2008 Fall Symposium on AI in Eldercare; Anderson, M., Erson, S.L., Armen, C., MedEthEx: A prototype medical ethics advisor Proceedings of the 18Th Innovative Applications of Artificial Intelligence Conference (IAAI 2006); Boyer, P., From studious irrelevancy to consilient knowledge: Modes of scholarship and cultural anthropology (2012) Creatingconsilience: Evolution, Cognitive Science, and the Humanities, , Slingerland, E.,Collard,M. (eds.), Oxford University Press, New York; Bringsjord, S., Psychometric artificial intelligence (2011) J. Exp. Theor. Artif. Intell, 23 (3), pp. 271-277; Calejo, M., (2014) Interprolog Studio, , http://interprolog.com/interprolog-studio; Ganascia, J.G., Modelling ethical rules of lying with answer set programming (2007) Ethics Inf. Technol, 9 (1), pp. 39-47; Kowalski, R., (2011) Computational Logic and Human Thinking: How to Be Artificially Intelligent, , Cambridge University Press, New York; Krebs, D.L., The evolution of a sense ofmorality (2012) Creating Consilience: Evolution, Cognitive Science, and the Humanities, , Slingerland, E.,Collard,M. (eds.), Oxford University Press, New York; Pereira, L.M., Evolutionary psychology and the unity of sciences-towards an evolutionary epistemology (2012) Special Sciences and the Unity of Science, Logic, Epistemology, and the Unity of Science, 24. , Pombo, O., Torres, J.M., Symons, J., Rahman, S. (eds.), Springer, Dordrecht; Slingerland, E., Collard, M., (2012) Creating Consilience: Evolution, Cognitive Science, and the Humanities, , Oxford University Press, Oxford},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{Wang2016611,
author={Wang, S.},
title={Robot ethical training with dynamic ethical preference logic},
journal={Advances in Cooperative Robotics: Proceedings of the 19th International Conference on Climbing and Walking Robots and the Support Technologies for Mobile Machines, CLAWAR 2016},
year={2016},
pages={611-618},
doi={10.1142/9789813149137_0071},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999711688&doi=10.1142%2f9789813149137_0071&partnerID=40&md5=db5163deb27d9985f7065cde81824368},
abstract={Rarely has ethical training of robots been formally studied. We address this need by introducing Dynamic Ethical Preference Logic (DEPL) as an extension of Deontic Logic. We present ethical training as model updating with respect to some contrary-to-duty (CTD) obligations. © 2016, World Scientific Publishing Co. Pte Ltd. All rights reserved.},
author_keywords={Deontic logic;  Game semantics;  Model checking;  Robot ethics},
keywords={Mobile robots;  Model checking;  Philosophical aspects;  Semantics, Contrary-to-duties;  Deontic Logic;  Ethical preference;  Ethical training;  Game semantics;  Model updating;  Robot ethics, Computer circuits},
references={Ågotnes, T., Van Der Hoek, W., Rodríguez-Aguilar, J.A., Sierra, C., Wooldridge, M., On the logic of normative systems (2007) IJCAI 2007, Proceedings of the 20th International Joint Conference on Artificial Intelligence, Hyderabad, India, January 6-12, 2007, pp. 1175-1180; Baier, C., Katoen, J.-P., (2008) Principles of Model Checking, , MIT Press; Van Benthem, J., Grossi, D., Liu, F., Priority structures in deontic logic (2014) Theoria, 80 (2), pp. 116-152; Van Benthem, J., Liu, F., Dynamic logic of preference upgrade (2007) Journal of Applied Non-Classical Logics, 17 (2), pp. 157-182; Broersen, J., Strategic deontic temporal logic as a reduction to ATL, with an application to chisholm's scenario (2006) Deontic Logic and Artificial Normative Systems, pp. 53-68. , Springer; Carmo, J., Jones, A.J.I., Deontic logic and contrary-to-duties (2002) Handbook of Philosophical Logic, pp. 265-343. , Springer; Chisholm, R.M., Contrary-to-duty imperatives and deontic logic (1963) Analysis, pp. 33-36; Dennis, L.A., Fisher, M., Slavkovik, M., Webster, M., Formal verification of ethical choices in autonomous systems (2016) Robotics and Autonomous Systems, 77, pp. 1-14; Dennis, L.A., Fisher, M., Winfield, A.F.T., Towards verifiably ethical robot behaviour (2015) AAAI Workshop on AI and Ethics (1st International Conference on AI and Ethics), , Austin, TX, January; Dignum, F., Kuiper, R., Combining dynamic deontic logic and temporal logic for the specification of deadlines (1997) System Sciences, 1997, Proceedings of the Thirtieth Hawaii International Conference on, 5, pp. 336-346. , IEEE; Gabbay, D., Temporal deontic logic for the generalised chisholm set of contrary to duty obligations (2012) Deontic Logic in Computer Science, pp. 91-107. , Springer; Hansson, S.O., Preference-based deontic logic (PDL) (1990) Journal of Philosophical Logic, 19 (1), pp. 75-93; Van Den Hoven, J., Lokhorst, G.-J., Deontic logic and computer-supported computer ethics (2002) Metaphilosophy, 33 (3), pp. 376-386; Jones, A.J.I., Pörn, I., Ideality, sub-ideality and deontic logic (1985) Synthese, 65 (2), pp. 275-290; Meyer, J.-J.Ch., A different approach to deontic logic: Deontic logic viewed as a variant of dynamic logic (1988) Notre Dame Journal of Formal Logic, 29 (1), pp. 109-136; Meyer, J.-J.Ch., Wieringa, R.J., (1993) Applications of Deontic Logic in Computer Science: A Concise Overview; Prakken, H., Sergot, M., Contrary-to-duty obligations (1996) Studia Logica, 57 (1), pp. 91-115; Tamminga, A., Deontic logic for strategic games (2013) Erkenntnis, 78 (1), pp. 183-200; Van Der Torre, L., Tan, Y.-H., Contrary-to-duty reasoning with preference-based dyadic obligations (1999) Annals of Mathematics and Artificial Intelligence, 27 (1-4), pp. 49-78; Winfield, A.F.T., Blum, C., Liu, W., Towards an ethical robot: Internal models, consequences and ethical action selection (2014) Advances in Autonomous Robotics Systems, pp. 85-96. , Springer},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Mansouri2016632,
author={Mansouri, N. and Goher, K.M.},
title={Assistive robots and ethical norms: State of the art survey},
journal={Advances in Cooperative Robotics: Proceedings of the 19th International Conference on Climbing and Walking Robots and the Support Technologies for Mobile Machines, CLAWAR 2016},
year={2016},
pages={632-639},
doi={10.1142/9789813149137_0073},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84999635713&doi=10.1142%2f9789813149137_0073&partnerID=40&md5=d54e6c096a2307cc79b096f8ffb23573},
abstract={Over the past decades, autonomous robots have embedded themselves into human lives in various forms. Although there have been limited number of research studies in this discipline, yet the results of scholars' studies reveal that humans especially older adults and people with disabilities have benefited from the use of robots in their daily lives. Over the next decades, number of elderly will be growing; therefore, there will be a high demand for assistive robots to enhance mobility and promote independence. The topic to what extend assistive robots should be empowered in daily life is of great concern in robotic discipline. Robot ethics have a dominant role in forming norms for design, use, disposal, and deployment of assistive robots. This paper reviews design ethics of assistive and autonomous medical robot for elderly and disabled. © 2016, World Scientific Publishing Co. Pte Ltd. All rights reserved.},
author_keywords={Assistive robots;  Older adults and disabilities;  Robot ethics},
keywords={Mobile robots;  Philosophical aspects;  Robotics, Assistive robots;  Design ethics;  Medical robots;  Older adults;  People with disabilities;  Research studies;  Robot ethics;  State of the art, Machine design},
references={Espingardeiro, A., Social Assistive Robots, Reframing the Human Robotics Interaction Benchmark of Social Success (2015) World Academy of Science, Engineering and Technology, International Journal of Social, Behavioral, Educational, Economic, Business and Industrial Engineering, 9 (1), pp. 377-382; Scheutz, M., What Is Robot Ethics? (2013) IEE Robotics and Automation Magazine, , http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6678596; Dahl, T.S., Boulos, M.N.K., Robots in Health and Social Care: A Complementary Technology to Home Care and Telehealthcare? (2013) Robotics, 3 (1), pp. 1-21; Flandorfer, P., Population ageing and socially assistive robots for elderly persons: The importance of sociodemographic factors for user acceptance (2012) Int. J. Popul. Res.; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics Inf. Technol., 14, pp. 27-40; Cornet, G., Robots to empower the elderly's well-being, the French perspective (2014) Gerontechnology, 13 (2), p. 76; Kavathatzopoulos, I., Laaksoharju, M., (2011) What Are Ethical Agents and How Can We Make Them Work Properly?; Maisonnier, B., Gelin, R., Koudelkova Delimoges, P., Humanoid robots for elderly autonomy (2014) Gerontechnology, 13 (2), pp. 77-78; Wada, K., Shibata, T., Living with seal robots - Its sociopsychological and physiological influences on the elderly at a care house (2007) Robotics, IEEE Transactions on, 23 (5), pp. 972-980; Hughes, R., (2008) Patient Safety and Quality: An Evidence-Based Handbook for Nurses, , AHRQ; Alaiad, A., Zhou, L., The determinants of home healthcare robots adoption: An empirical investigation (2014) International Journal of Medical Informatics, 83 (11), pp. 825-840; Wada, K., Shibata, T., Musha, T., Kimura, S., Robottherapy for elders affected by dementia (2013) IEEE Eng. Med. Biol. Mag., 27 (4), pp. 53-60; Bemelmans, R., Gelderblom, G.J., Jonker, P., De Witte, L., Socially assistive robots in elderly care: A systematic review into effects and effectiveness (2012) Journal of the American Medical Directors Association, 13 (2), pp. 114-120; Hewson, D.J., Gutierrez Ruiz, C., Michel, H., Development of a multidimensional evaluation method for the use of a robotic companion as a function of care relationships (2014) Gerontechnology, 13 (2), p. 79; Alami, R., Sidobre, D., A mobile manipulator robot that brings objects to assist people (2014) Gerontechnology, 13 (2), pp. 78-79; Ozguler, A., Loeb, T., Baer, M., Maintaining elderly people at home with a telemedicine platform solution: The QuoVADIS project (2014) Gerontechnology, 13 (2), p. 80; Michaud, F., Boissy, P., Labonte, D., Corriveau, A., Lauria, M., Cloutier, R., Roux, M., Iannuzzi, D., Telepresence robot for homecare assistance (2007) Multidisciplinary Collaboration for Socially Assistive Robotics, , March 26-28; Smarr, C., Fausset, C., Rogers, W., (2010) Understanding the Potential for Robot Assistance for Older Adults in the Home Environment, , Technical Report Georgia Institute of Technology School of Psychology, GA},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Coeckelbergh20167,
author={Coeckelbergh, M.},
title={Is it wrong to kick a robot? towards a relational and critical robot ethics and beyond},
journal={Frontiers in Artificial Intelligence and Applications},
year={2016},
volume={290},
pages={7-8},
doi={10.3233/978-1-61499-708-5-7},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992671993&doi=10.3233%2f978-1-61499-708-5-7&partnerID=40&md5=352bbbd7b3b5e1db471b78a2f5156c30},
author_keywords={Empathy;  Human-robot relations;  Moral status;  Normative ethics;  Relational epistemology;  Robot ethics},
references={Grodzinsky, F., Wolf, M.J., Miller, K., Applying a Social-Relational Model to Explore the Curious Case of hitchBOT (2016) The International Association for Computing and Philosophy Annual Conference IACAP2016, , Paper presented at, June 15th, Ferrara, Italy. (Conference paper.); Levinas, E., (1969) Totality and Infinity, , (A. Lingis, Trans.). Pittsburgh, PA: Duquesne University Press; Derrida, J., (2000) On Hospitality, , (R. Bowlby, Trans.) Stanford: Stanford University Press; Derrida, J., (2008) The Animal That Therefore i Am, , (M.-L. Mallet, Ed., D. Wills, Trans.). New York: Fordham University Press; Coeckelbergh, M., Robot Rights? Towards a Social-Relational Justification of Moral Consideration (2010) Ethics and Information Technology, 12 (3), pp. 209-221; Coeckelbergh, M., (2012) Growing Moral Relations: Critique of Moral Status Ascription, , Basingstoke/New York: Palgrave Macmillan; Coeckelbergh, M., The Moral Standing of Machines: Towards a Relational and Non-Cartesian Moral Hermeneutics (2014) Philosophy & Technology, 27 (1), pp. 61-77; Coeckelbergh, M., Gunkel, D.J., Facing Animals: A Relational, Other-Oriented Approach to Moral Standing (2014) Journal of Agricultural and Environmental Ethics, 27 (5), pp. 715-733; Gunkel, D.J., (2012) The Machine Question: Critical Perspectives on AI, Robots, and Ethics, , Cambridge, MA: MIT Press},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Gerdes2016129,
author={Gerdes, A.},
title={The role of phronesis in robot ethics},
journal={Frontiers in Artificial Intelligence and Applications},
year={2016},
volume={290},
pages={129-135},
doi={10.3233/978-1-61499-708-5-129},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992665476&doi=10.3233%2f978-1-61499-708-5-129&partnerID=40&md5=32b44e41a242d2bdae1d745e586ea2b5},
abstract={aThe Aristotelian concept of phronesis captures the kind of situated knowledge, which is needed in order for us to understand and act morally in the specific situations in which we find ourselves. On this background, it is discussed whether an 'as if' version of phronesis, understood as situational awareness, might enable us to design a virtuous robot with 'as if' capabilities of the phronimos. It is argued that eventually we might see this kind of virtuous robot, but its 'as if' qualities would not be sufficient for the virtuous robot to count as an ethical agent, since phronesis is presumably not computationally tractable. © 2016 The authors and IOS Press. All rights reserved.},
author_keywords={Machine ethics;  Phronesis;  Situational awareness;  Virtue ethics},
keywords={Philosophical aspects;  Robotics;  Robots, Phronesis;  Robot ethics;  Situational awareness;  Virtue ethics, Machine design},
references={Arkin, A.N., (2007) R. C. Governing Lethal Behavior: Embedding Ethics in A Hybrid Deliberative/Reactive Robot Architecture, , http://www.cc.gatech.edu/ai/robot-lab/online-publications/formalizationv35.pdf, Technical Report GIT-GVU-07-11; Gerdes, A., Øhrstrøm, P. Issues in Robot Ethics seen through the Lens of a Moral Turing Test (2015) Journal of Information, Communication and Ethics in Society, 13 (2), pp. 98-109; Anderson, M., Anderson, L.S., Armen, C., (2004) Towards Machine Ethics, , http://www.aaai.org/Papers/Workshops/2004/WS-04-02/WS04-02-008.pdf; Lin, P., Bekey, G., Abney, K., Autonomous Military Robotics: Risk Ethics and Design (2008) CALPOLY, , http://ethics.calpoly.edu/ONR_report.pdf; Wallach, W., Allen, C., (2009) Moral Machines - Teaching Robots Right from Wrong, , New York: Oxford University Press; Abney, K., Autonomous Robots and the Future of Just War Theory (2013) Routledge Handbook of Ethics and War Just War Theory in the 21st Century, , (eds.) F. Allhoff , N. G. Evans and A. Henschke; Anscombe, E., Modern Moral Philosophy (1958) Philosophy, 33, pp. 1-19; MacIntyre, A., (2000) After Virtue, , London UK: Duckworth; (1909) Nicomachean Ethics, , Aristotle., transl. by L. H. G. Greenwood. Cambridge, UK: University Press; MacIntyre, A., (1999) Denpendent Rational Animals - Why Human Beings Need the Virtues, , Illinois: Carus Publishing Company; Arendt, H., (1964) Eichmann in Jerusalem: A Report O the Banality of Evil, , New York: Penguin Books; Arendt, H., Thinking and Moral Consideration: A Lecture (1971) Social Research, 38 (3), pp. 417-446; Arendt, H., (1973) The Origins of Totalitarianism, , New York: Harcourt Brace & Company; McDermott, D., What Matters to a Machine? (2011) Machine Ethics, pp. 88-114. , (eds.) M. Anderson, S. Anderson, Cambridge University Press, New York; Wallach, W., (2015) A Dangerous Master: How to Keep Technology from Slipping beyond Our Control, , Basic Books: New York; Turkle, S., (2011) Alone Together - Why We Expect More from Technology and Less from Each Other, , Basic Books, New York; Nicomachean Ethics (2011) The Philosophy of Aristotle, , Aristotle., Transl. by J.L. Creed and A. E. Wardman, (eds.) R. Bambrough The Philosophy of Aristotle, Penguin Group, New York; Dreyfus, H.L., The Myth of the Mental: How Philosophers Can Profit from the Phenomenology of Everyday Expertise (2005) Proceedings and Addresses of the American Philosophical Association, 79, pp. 47-65. , Nov; Dreyfus, H.L., Dreyfus, S.E., (1986) Mind over Machine, , The Free Press, New York; Anderson, S.L., (2011) How Machines Might Help Us Achieve Breakthroughs in Ethical Theory and Inspire Us to Behave Better, pp. 524-530. , (eds.) M. Anderson, S. Anderson. Machine Ethics, Cambridge University Press, New York; Brooks, R.A., Intelligence without Representation (1997) Mind Design II - Philosophy, Psychology, Artificial Intelligence Revised and Enlarged Version, pp. 395-421. , (ed.) J. Haugeland, The MIT Press, Massachusetts; Tucker, P., Now the Military is Going to Build Robots That Have Morals (2014) Defense One, , http://www.defenseone.com/technology/2014/05/now-the-military-going-build-robotshave-morals/84325/, May 13; Moor, J., The Nature Importance and Difficulty of Machine Ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor2016,
title={Frontiers in Artificial Intelligence and Applications},
journal={Frontiers in Artificial Intelligence and Applications},
year={2016},
volume={290},
page_count={408},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992608997&partnerID=40&md5=34fd80af908456ef95304d92ac2fa910},
abstract={The proceedings contain 57 papers. The topics discussed include: is it wrong to kick a robot? towards a relational and critical robot ethics and beyond; other problems: rethinking ethics in the face of social robots; power in human robot interactions; why and how should robots behave ethically?; robots that have free will; are sex robots as bad as killing robots?; should we place robots in social roles?; artificial phronesis and the social robot; a generic scale for assessment of attitudes towards social robots: the asor-5; are we really addressing the human in human-robot interaction? adopting the phenomenologically-situated paradigm; the role of phronesis in robot ethics; social robots, privacy, and ownership of data: some problems and suggestions; can artificial systems have genuine emotions? the enactive approach to affectivity and artificial systems; motions with emotions?; and robot enhancement of cognitive and ethical capabilities of humans.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Smakman2016184,
author={Smakman, M.},
title={Robots and moral obligations},
journal={Frontiers in Artificial Intelligence and Applications},
year={2016},
volume={290},
pages={184-189},
doi={10.3233/978-1-61499-708-5-184},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992563899&doi=10.3233%2f978-1-61499-708-5-184&partnerID=40&md5=c317042f4b93effc934398f5b95a4bc2},
abstract={Using Roger Crisp's [1] arguments for well-being as the ultimate source of moral reasoning, this paper argues that there are no ultimate, non-derivative reasons to program robots with moral concepts such as moral obligation, morally wrong or morally right. Although these moral concepts should not be used to program robots, they are not to be abandoned by humans since there are still reasons to keep using them, namely: as an assessment of the agent, to take a stand or to motivate and reinforce behaviour. Because robots are completely rational agents they do not need these additional motivations, they can suffice with a concept of what promotes well-being. How a robot knows which action promotes well-being to the greatest degree is still up for debate, but a combination of top-down and bottom-up approaches seem to be the best way. © 2016 The authors and IOS Press. All rights reserved.},
author_keywords={Decision making;  Ethics;  Machine ethics;  Moral concepts;  Moral judgment;  Moral obligation;  Robots;  Well-being},
keywords={Behavioral research;  Decision making;  Philosophical aspects;  Robot programming;  Robotics, Ethics;  Moral concepts;  Moral judgment;  Moral obligations;  Well being, Robots},
references={Crisp, R., (2006) Reasons and the Good, , Oxford: Clarendon Press; McElwee, B., Should We De-moralize Ethical Theory? (2010) Ratio, 23 (3), pp. 308-321; Lin, P., Abney, K., Bekey, G., Robotic ethics: Mapping the issues for a mechanized world (2011) Artificial Intelligence, 175, pp. 942-949; Mitchell, T., (1997) Machine Learning, p. 2. , McGraw Hill; Wallach, W., Allen, C., Moral Machines (2009) Teaching Robots Right from Wrong, , Oxford University Press; Anderson, S.L., Asimov's "three laws of robotics" and machine metaethics (2008) Ai & Society, 22 (4), pp. 477-493; Coeckelbergh, M., Moral appearances: Emotions, robots, and human morality (2010) Ethics and Information Technology, 12 (3), pp. 235-241; Crnkovic, G.D., Çürüklü, B., Robots: Ethical by design (2012) Ethics and Information Technology, 14 (1), pp. 61-71; Malle, B.F., Integrating robot ethics and machine morality: The study and design of moral competence in robots (2015) Ethics and Information Technology, pp. 1-14; Murphy, R., Woods, D.D., Beyond Asimov: The three laws of responsible robotics (2009) IEEE Intelligent Systems, 24 (4), pp. 14-20; Wallach, W., Robot minds and human ethics: The need for a comprehensive model of moral decision making (2010) Ethics and Information Technology, 12, pp. 243-250; Joyce, R., (2001) The Myth of Morality, , Cambridge University Press Ch. 1; Haidt, J., Kesebir, S., Morality (2010) Handbook of Social Psychology 5th Edition, pp. 797-832. , In S. Fiske, D. Gilbert, & G. Lindzey (Eds.) Hobeken, NJ: Wiley},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Reed2016195,
author={Reed, G.S. and Petty, M.D. and Jones, N.J. and Morris, A.W. and Ballenger, J.P. and Delugach, H.S.},
title={A principles-based model of ethical considerations in military decision making},
journal={Journal of Defense Modeling and Simulation},
year={2016},
volume={13},
number={2},
pages={195-211},
doi={10.1177/1548512915581213},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966602579&doi=10.1177%2f1548512915581213&partnerID=40&md5=f29dfa728ac8fdd680a1a5ec1e7fce99},
abstract={When comparing alternative courses of action, modern military decision makers often must consider both the military effectiveness and the ethical consequences of the available alternatives. The basis, design, calibration, and performance of a principles-based computational model of ethical considerations in military decision making are reported in this article. The relative ethical violation (REV) model comparatively evaluates alternative military actions based upon the degree to which they violate contextually relevant ethical principles. It is based on a set of specific ethical principles deemed by philosophers and ethicists to be relevant to military courses of action. A survey of expert and non-expert human decision makers regarding the relative ethical violation of alternative actions for a set of specially designed calibration scenarios was conducted to collect data that was used to calibrate the REV model. Perhaps unsurprisingly, the survey showed that people, even experts, disagreed greatly amongst themselves regarding the scenarios’ ethical considerations. Despite this disagreement, two significant results emerged. First, after calibration the REV model performed very well in terms of replicating the ethical assessments of human experts for the calibration scenarios. The REV model outperformed an earlier model that was based on tangible consequences rather than ethical principles, that earlier model performed comparably to human experts, the experts outperformed human non-experts, and the non-experts outperformed random selection of actions. All of these performance comparisons were measured quantitatively and confirmed with suitable statistical tests. Second, although humans tended to value some principles over others, none of the ethical principles involved—even the principle of not harming civilians—completely overshadowed all of the other principles. © The Author(s) 2015.},
author_keywords={Decision analysis;  Human behavior modeling;  Machine ethics;  Modeling and simulation},
keywords={Behavioral research;  Calibration;  Decision making;  Decision theory;  Military operations;  Surveys, Computational model;  Ethical considerations;  Ethical principles;  Human behavior modeling;  Military decision making;  Model and simulation;  Performance comparison;  Random selection, Philosophical aspects},
references={Milgram, S., Behavioral study of obedience (1963) J Abnormal Social Psychol, 67, pp. 371-378; Zimbardo, P.G., A situationist perspective on the psychology of evil: Understanding how good people are transformed into perpetrators (2004) The social psychology of good and evil: Understanding our capacity for kindness and cruelty, pp. 21-50. , Miller A (ed), New York: Guilford; Baron-Cohen, S., (2011) The science of evil: On empathy and the origins of cruelty, , New York: Basic Books; Baron-Cohen, S., Wheelwright, S., The empathy quotient: An investigation of adults with Asperger syndrome or high functioning autism, and normal sex differences (2004) J Autism Dev Disorders, 34, pp. 163-175; Simon, R.I., Should forensic psychiatrists testify about evil? (2003) J Am Acad Psychiatry Law, 31, pp. 413-416; Knoll, J.L., The recurrence of an illusion: The concept of 'evil' in forensic psychiatry (2008) J Am Acad Psychiatry Law, 36, pp. 105-116; Welner, M., Classifying crimes by severity: From aggravators to depravity (2007) A crime classification manual, pp. 55-72. , Douglas J, Ressler R and Burgess A (eds), San Francisco, CA: Jossey- Bass; Stone, M.H., (2009) The anatomy of evil, , Amherst, NY: Prometheus Books; Irwin, T., (2000) Nicomachean ethics, , Indianapolis, IN: Hackett Publishing; Schelling, T.C., (1980) The strategy of conflict, , Cambridge, MA: Harvard University Press; Gips, J., Towards the ethical robot (1995) Android epistemology, pp. 243-252. , Ford KM, Glymour C and Hayes PJ (eds), Cambridge, MA: MIT Press; McLaren, B., Computational models of ethical reasoning: Challenges, initial steps, and future directions (2006) IEEE Intell Syst, 29 (4), pp. 29-37; Anderson, M., Anderson, S., Armen, C., Towards machine ethics: Implementing two action-based ethical theories (2005) Machine ethics, pp. 1-16. , Menlo Park, CA: AAAI Press; Reed, G.S., Jones, N., Toward modeling and automating ethical decision-making: Design, implementation, limitations, and responsibilities (2013) Topoi, 32, pp. 237-250; Reed, G.S., Tackett, G.B., Petty, M.D., A model of 'evil' for course of action analysis (2013) Mil Oper Res, 18 (4), pp. 61-76; Dawes, R.M., The robust beauty of improper linear models in decision making (1979) Am Psychologist, 34, pp. 571-582; Dawes, R.M., A case study of graduate admissions: Application of three principles of human decision making (1971) Am Psychologist, 26, pp. 180-188; Dawes, R.M., Corrigan, B., Linear models in decision making (1974) Psychol Bull, 81, pp. 95-106; Goodwin, P., Wright, G., (2004) Decision analysis for management judgment, , Chichester, UK: John Wiley and Sons Ltd; Ross, W.D., (1930) The right and the good, , Oxford: Oxford University Press; Professional development guide (2007) AF Pamphlet 36-2241, , United States Air Force, July; Mill, J.S., Utilitarianism (1879) Fraser's magazine, , 7th ed. London: Longmans, Green, and Co; Kant, I., (2011) Fundamental principles of the metaphysic of morals, , translated by Abbot TK. Charleston, SC: BiblioBazaar, LLC; Beauchamp, T., Childress, J.F., (2001) Principles of biomedical ethics, , Oxford: Oxford University Press; Gillon, R., Medical ethics: Four principles plus attention to scope (1994) BMJ, 309, p. 184; Gillon, R., Ethics needs principles—four can encompass the rest—and respect for autonomy should be 'first among equals' (2003) J Med Ethics, 29, pp. 307-312; DiMeglio, R.P., Condron, S.M., Bishop, O.B., (2012) Means and Methods of Warfare, , http://www.loc.gov/rr/frd/Military_Law/pdf/LOACDeskbook-2012.pdf, Johnson WJ and Gillman AD (eds) (accessed 2013); (1999) Law of armed conflict at the operational and tactical level, , http://www.forces.gc.ca/jag/publications/oplaw-loiop/loac-ddca-2004/index-eng.asp, (accessed 2013); (2000) Catechism of the Catholic Church, , Vatican City: Libreria Editrice Vaticana; Likert, R., A technique for the measurement of attitudes (1932) Arch Psychol, 22 (140), pp. 5-55; Goodman, L.A., Kruskal, W.H., Measures of association for cross classifications (1954) J Am Stat Assoc, 49, pp. 732-764; Popping, R., On agreement indices for nominal data (1998) Sociometric research. Volume 1. Data collection and scaling, pp. 90-105. , Saris WE and Gallhofer IN (eds), New York: St. Martin's Press; Brase, C.H., Brase, C.P., (2009) Understandable statistics: Concepts and methods, , Boston MA: Houghton Mifflin},
document_type={Article},
source={Scopus},
}

@ARTICLE{Siler2015200,
author={Siler, C.},
title={Review of Anderson and Anderson's Machine Ethics},
journal={Artificial Intelligence},
year={2015},
volume={229},
pages={200-201},
doi={10.1016/j.artint.2015.08.013},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044124388&doi=10.1016%2fj.artint.2015.08.013&partnerID=40&md5=80bda99d8124c2a7df713377964278e3},
references={Allen, C., , pp. 51-61. , Wendell Wallach, Iva Smit, Why machine ethics?, in: Anderson and Anderson [2]; Anderson, M., Anderson, S.L., (2011) Machine Ethics, , Cambridge University Press; , pp. 162-167. , Susan Leigh Anderson, Philosophical concerns with machine ethics, in: Anderson and Anderson [2]; , pp. 476-492. , Susan Leigh Anderson, Michael Anderson, A prima facie duty approach to machine ethics machine learning of features of ethical dilemmas, prima facie duties, and decision principles through a dialogue with ethicists, in: Anderson and Anderson [2]; Clarke, R., , pp. 254-284. , Asimov's laws of robotics: implications for information technology, in: Anderson and Anderson [2]; Dehghani, M., , pp. 422-441. , Emmett Tomai, Ken Forbus, Matthew Klenk, An integrated reasoning approach to moral decision making, in: Anderson and Anderson [2]; Dietrich, E., , pp. 531-538. , Homo sapiens 2.0: building the better robots of our nature, in: Anderson and Anderson [2]; Gips, J., , pp. 244-253. , Towards the ethical robot, in: Anderson and Anderson [2]; Seville, H., , pp. 499-511. , Debora G. Field, What can AI do for ethics?, in: Anderson and Anderson [2]; Turkle, S., , pp. 62-76. , Authenticity in the age of digital companions, in: Anderson and Anderson [2]; Whitby, B., , pp. 138-150. , On computable morality: an examination of machines as moral advisors, in: Anderson and Anderson [2]},
document_type={Short Survey},
source={Scopus},
}

@BOOK{Gassen201530,
author={Gassen, J. and Seong, N.Y.},
title={Grounding machine ethics within the natural system},
journal={Rethinking Machine Ethics in the Age of Ubiquitous Technology},
year={2015},
pages={30-49},
doi={10.4018/978-1-4666-8592-5.ch003},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957377801&doi=10.4018%2f978-1-4666-8592-5.ch003&partnerID=40&md5=7f1fae6146a37b0789f349c18b769c09},
abstract={This chapter explores machine ethics within the larger context of the natural system from which it springs. While computing power and computing machines have grown exponentially since the twentieth century, the foundation for this growth is the planet's natural resources, which may not be able to sustain this type of continual exponential growth. This chapter explores some of the basic natural limiting factors that may prohibit computing power if solutions are not found. Specifically, the chapter explores limitations from: population growth, e-waste, rare earth minerals, water, oil, and energy production. Within this context, possible solutions for producing machines ethically are briefly explored. © 2015, IGI Global.},
keywords={Philosophical aspects, Computing machines;  Computing power;  Energy productions;  Exponential growth;  Natural systems;  Population growth;  Twentieth century, Population statistics},
references={Ahmed, N., Former BP geologist: peak oil is here and it will 'break economies' (2013) The Guardian, , http://www.theguardian.com/environment/earth-insight/2013/dec/23/britishpetroleum-geologist-peak-oil-break-economy-recession, Dec 23, Retrieved from; Austin, A.A., Where will all the waste go?: Utilizing extended producer responsibility framework laws to achieve zero waste (2013) Golden Gate University Environmental Law Journal, 6 (2), pp. 220-257. , http://digitalcommons.law.ggu.edu/cgi/viewcontent.cgi?article=1101&context=gguelj, Retrieved from; Bamford, J., (2009) The shadow factory: The NSA from 9/11 to the eavesdropping on America, , New York: Anchor; Boren, Z.D., There are officially more mobile devices than people in the world (2014) The Independent, , http://www.independent.co.uk/life-style/gadgets-and-tech/news/there-areofficially-more-mobile-devices-than-people-in-the-world-9780518.html, Oct 7, Retrieved from; Cooper, M., Why the economics don't favor nuclear power in America (2014) Forbes, , http://www.forbes.com/sites/energysource/2014/02/20/why-the-economics-dont-favor-nuclearpower-in-america/, Feb 20, Retrieved from; Desjardins, J., What is the cost of mining gold? (2013) Visual Capitalist, , http://www.visualcapitalist.com/what-is-the-cost-of-mining-gold/, May 21, Retrieved from; Diaz, J., US Army robots will outnumber human soldiers 10 to 1 by 2023 (2013) Gizmodo, , http://sploid.gizmodo.com/us-army-robots-will-outnumber-human-soldiers-10-to-1-by-1465669535, Nov 16, Retrieved from; Eisenhower, D.D., (1953) The Chance for Peace, , Apr 16, Speech to the American Society of Newspaper Editors; (2012) General information on e-waste, , http://www.epa.gov/epawaste/conserve/materials/ecycling/faq.htm, Retrieved from; Fishman, C., The dangerously clean water used to make your iPhone (2011) Fast Company, , http://www.fastcompany.com/1750612/dangerously-clean-water-used-make-your-iphone, Apr 29, Retrieved from; (2012) Coping with water scarcity: An action framework for agriculture and food security, , http://www.fao.org/docrep/016/i3015e/i3015e.pdf, Retrieved from:; (2013) Gartner says worldwide PC, tablet and mobile phone shipments to grow 5.9 percent in 2013 as anytime-anywhere-computing drives buyer behavior, , http://www.gartner.com/newsroom/id/2525515, June 24, Retrieved from; Humphries, M., Rare earth elements: The global supply chain (2012) Congressional Research Service, , http://www.relooney.info/0_New_14118.pdf, June 8, Retrieved from; (2013) Service robot statistics, , www.ifr.org/service-robots/statistics, Retrieved October 7, 2014, from; (2014) IFR: All-time-high for industrial robots in 2013, , http://www.ifr.org/news/ifr-press-release/ifr-all-time-high-for-industrial-robots-in-2013-601/, Retrieved from; Kaiman, J., Rare earth mining in China: The bleak social and environmental costs (2014) The Guardian, , http://www.theguardian.com/sustainable-business/rare-earth-mining-chinasocial-environmental-costs, Mar 20, Retrieved from:; Kshetri, N., Dholakia, N., (2009) Global digital divide, , http://ebooks.narotama.ac.id/files/Encyclopedia%20of%20Information%20Science%20and%20Technology%20%282nd%20Edition%29/Global%20Digital%20Divide.pdf, Retrieved from; Lichocki, P., Kahn, P., Billard, A., The ethical landscape in robotics (2011) IEEE Robotics & Automation Magazine, 18 (1), pp. 39-50; Lin, P., The ethical war machine (2009) Forbes, , http://www.forbes.com/2009/06/18/military-robots-ethics-opinions-contributors-artificial-intelligence-09-patrick-lin.html, June 22, Retrieved from; Lovelock, J., Nuclear power is the only green solution (2004) The Independent, , http://www.independent.co.uk/voices/commentators/james-lovelock-nuclear-power-is-the-only-greensolution-6169341.html, May 24, Retrieved from; Miller, R., Data center water use moves to the forefront (2012) Datacenter Knowledge, , http://www.datacenterknowledge.com/archives/2012/08/14/data-center-water-use-movesto-center-stage/, Aug 14, Retrieved from; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Moore, G.E., Cramming more components onto integrated circuits (1965) Electronics Magazine, 38 (8), pp. 114-117; (2014) On-site storage of nuclear waste, , http://www.nei.org/Knowledge-Center/Nuclear-Statistics/On-Site-Storage-of-Nuclear-Waste, Retrieved from:; (2009) Semiconductor manufacturing, , http://www.pprc.org/hubs/printfriendly.cfm?hub=1004&subsec=14&nav=1, Retrieved from:; Peckham, M., The collapse of Moore's law: Physicist says it's already happening (2012) Time, , http://techland.time.com/2012/05/01/the-collapse-of-moores-law-physicist-says-itsalready-happening/, May 1, Retrieved from; Plus, P.C., The weird and wonderful materials that make up your PC (2012) Techrader, , http://www.techradar.com/us/news/computing/pc/the-weird-and-wonderful-materials-thatmake-up-your-pc-1089510, July 22, Retrieved from; Snead, A., A brief history of warnings about the demise of Moore's Law (2012) Slate, , http://www.slate.com/blogs/future_tense/2012/05/03/michio_kako_and_a_brief_history_of_warnings_about_the_end_of_moore_s_law_.html, May 3, Retrieved from; Stolberg, S.G., Mouawad, J., Saudis rebuff Bush, politely, on pumping more oil (2008) The New York Times, , http://www.nytimes.com/2008/05/17/world/middleeast/17prexy.html?_r=0, May 17, Retrieved from:; Tweed, K., Global e-waste will jump 33 percent in the next five years (2013) IEEE Spectrum, , http://spectrum.ieee.org/energywise/energy/environment/global-ewaste-will-jump-33-in-next-five-years, Dec 17, Retrieved from; (2010) Assessing the environmental impacts of consumption and production: Priority products and materials, , http://www.unep.fr/shared/publications/pdf/DTIx1262xPA-PriorityProductsAndMaterials_Report.pdf, Retrieved from; UN study shows environmental consequences from ongoing boom in personal computer sales (2004) Eurekalert, , http://www.eurekalert.org/pub_releases/2004-03/tca-uss030204.php, Retrieved from; (2014) Census Data, , http://www.census.gov/popclock/, Retrieved from; (2014) Short-term energy outlook, , http://www.eia.gov/forecasts/steo/report/global_oil.cfm, Retrieved from; (2014) How much water is there on, in, and above the Earth?, , http://water.usgs.gov/edu/earthhowmuch.html, Mar 19, Retrieved from:; White, D.J., Danish wind: Too good to be true? (2004) The Utilities Journal, pp. 37-39. , July},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{NoAuthor2015,
title={CEUR Workshop Proceedings},
journal={CEUR Workshop Proceedings},
year={2015},
volume={1510},
page_count={160},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961252477&partnerID=40&md5=95d36c1ebd0b1aa34271f4712047e5a4},
abstract={The proceedings contain 13 papers. The topics discussed include: How many (polymorphic) frames? classic KR in the world wide web; robot ethics: illusions, challenges and rewards; cognitive programming; towards a visual remote associates test and its computational solver; modeling the creation and development of cause-effect pairs for explanation generation in a cognitive architecture; a cognitive view of relevant implication; information theoretic segmentation of natural language; pattern-recognition: a foundational approach; world modeling for tabletop object construction; a network-based communication platform for a cognitive computer; developing initial state fuzzy cognitive maps with self-organizing maps; property-based semantic similarity: what counts?; and do the self-knowing machines dream of knowing their activity?.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Payr201531,
author={Payr, S.},
title={Towards human–robot interaction ethics},
journal={Cognitive Technologies},
year={2015},
volume={40},
pages={31-62},
doi={10.1007/978-3-319-21548-8_3},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948798972&doi=10.1007%2f978-3-319-21548-8_3&partnerID=40&md5=165d3308aadd151782dccba29bf72910},
abstract={Social assistive robots are envisioned as supporting their users not only physically but also by communicating with them. Monitoring medication, reminders, etc., are typical examples of such tasks. This kind of assistance presupposes that such a robot is able to interact socially with a human. The issue that is discussed in this chapter is whether human–robot social interaction raises ethical questions that have to be dealt with by the robot. A tour d’horizon of possibly related fields of communication ethics allows to outline the distinctive features and requirements of such an “interaction ethics”. Case studies on conversational phenomena show examples of ethical problems on the levels of the “mechanics” of conversation, meaning-making, and relationship. Finally, the chapter outlines the possible connections between decision ethics and interaction ethics in a robot’s behaviour control system. © Springer International Publishing Switzerland 2015.},
author_keywords={Human–robot–interaction;  Interaction ethics;  Machine ethics;  Social interaction},
keywords={Philosophical aspects;  Robots;  Social sciences, Assistive robots;  Behaviour controls;  Communication ethics;  Ethical problems;  Ethical question;  Interaction ethics;  Robot interactions;  Social interactions, Human robot interaction},
references={Feil-Seifer, D., Mataric, M., Defining socially assistive robotics (2005) Proceedings of the IEEE 9th International Conference on Rehabilitation Robotics, , Chicago; Fong, T., Nourbakhsh, I., Dautenhahn, K., A survey of socially interactive robots (2003) Robot. Auton. Syst, 42 (3-4), pp. 143-166; Rummel, R.J., (1976) Understanding Conflict and War, 2. , Sage, Beverly Hills; Searle, J.R., Minds, brains and programs (1980) Behav. Brain Sci, 3 (3), pp. 417-457; Nass, C., Brave, S., (2005) Wired for Speech, , MIT Press, Cambridge; Payr, S., Virtual butlers and real people: Styles and practices in long-term use of a companion (2013) Virtual Butlers: The Making of, , Trappl, R. (ed.), Springer, Heidelberg; Anderson, M., Anderson, S.L., Case-supported principle-based behavior paradigm (2015) A Construction Manual for Robots' Ethical Systems: Requirements, Methods, Implementations, , Trappl, R. (ed.), Springer, Heidelberg; Anderson, M., Anderson, S.L., (2010) Robot Be Good, , Scientific American, October; Barnlund, D.C., A transactional model of communication. Transaction (2008) Communication Theory, pp. 47-57. , Mortensen, C. D. (ed.), Transaction, New Brunswick; (1999) NCA Credo for Ethical Communication, , https://www.natcom.org/Tertiary.aspx?id=2119, Edited by National Communication Association; Andersen, K.E., A conversation about communication ethics with Kenneth E. Andersen (2007) Exploring Communication Ethics: Interviews with Influential Scholars in the Field, pp. 131-142. , Arneson, P. (ed.), Peter Lang, New York; Wrench, J.S., Punyanunt-Carter, N., (2012) An Introduction to Organizational Communication, , http://2012books.lardbucket.org/books/an-introduction-to-organizational-communication/; McCroskey, J.C., Wrench, J.S., Richmond, V.P., (2003) Principles of Public Speaking, , The College Network, Indianapolis; Redding, W.C., Ethics and the study of organizational communication: When will we wake up? (1996) Responsible Communication: Ethical Issues in Business, Industry, and the Professions, pp. 17-40. , Jaksa, J. A., Pritchard, M. S. (eds.), Hampton, Cresskill; Watzlawick, P., Bavelas, J.B., Jackson, D.D., (1967) Pragmatics of Human Communication, , W. W. Norton & Company, New York; Arnett, R.C., Harden Fritz, J.M., Bell, L.M., (2009) Communication Ethics Literacy: Dialogue and Difference, , Sage, London; Fearon, D.S., The bond threat sequence: Discourse evidence for the systematic interdependence of shame and social relationships (2004) The Social Life of Emotions, pp. 64-86. , Tiedens, L. Z., Leach, C. W. (eds.), Cambridge University Press, Cambridge; Scheff, T., (1990) Microsociology, , Discourse, Emotion, and Social Structure. University of Chicago Press, Chicago; Kemper, T.D., Social relations and emotions: A structural approach (1990) Research Agendas in the Sociology of Emotions, pp. 207-236. , Kemper, T. D. (ed.), State University of New York Press, New York; Leary, M.R., Affect, cognition, and the social emotions (2000) Feeling and Thinking, pp. 331-356. , Forgas, J. P. (ed.), Cambridge University Press, Cambridge; Sander-Staudt, M., (2014) Care Ethics, , http://www.iep.utm.edu/care-eth/, Internet Encyclopedia of Philosophy. (last visited May 2); Dubreuil, B., Grégoire, J.-F., Are moral norms distinct from social norms? A critical assessment of Jon Elster and Cristina Bicchieri (2013) Theory Decis, 75 (1), pp. 137-152; Huebner, B., Lee, J.L., Hauser, M.D., The moral-conventional distinction in mature moral competence (2010) J. Cogn. Cult, 10, pp. 1-26; Garfinkel, H., (1967) Studies in Ethnomethodology, , Polity Press, Cambridge; ten Have, P., (1999) Doing Conversation Analysis, , Sage, London; ten Have, P., Conversation analysis versus other approaches to discourse (2006) Forum Qual. Soc. Res, 7 (2); Sacks, H., Schegloff, E., Jefferson, G., A simplest systematic for the organization of turn-taking for conversation (1974) Language, 50 (4), pp. 696-735; Eggins, S., Slade, D., (1997) Analysing Casual Conversation, , Equinox, London; Jefferson, G., Notes on 'latency' in overlap onset (1986) Hum. Stud, 9 (2-3), pp. 153-183; Hutchby, I., Participants' orientations to interruptions, rudeness and other impolite acts in talkin-interaction (2008) J. Politeness Res, 4, pp. 221-241; Maynard, D.W., Placement of topic changes in conversation (1980) Semiotica, 30 (3-4), pp. 263-290; Okamoto, D.G., Smith-Lovin, L., Changing the subject: Gender, status, and the dynamics of topic change (2001) Am. Sociol. Rev, 66 (6), pp. 852-873; Schegloff, E.A., On the organization of sequences as a source of "Coherence" in talk-ininteraction (1990) Conversational Organization and its Development, pp. 51-77. , Dorval, B. (ed.), Ablex, Norwood; Creer, S., Cunningham, S., Hawley, M., Wallis, P., Describing the interactive domestic robot setup for the SERA project (2011) Appl. Artif. Intell, 25 (6), pp. 445-473; Brown, P., Levinson, S.C., (1987) Some Universals in Language Usage, , Cambridge University Press, Cambridge; Howe, M., Collaboration on topic change in conversation (1991) Kansas Working Papers in Linguistics, pp. 1-14. , Ichihashi, K., Linn, M. S. (eds.), University of Kansas; Beach, W.A., Conversation analysis: "Okay" as a clue for understanding consequentiality (1995) The Consequentiality of Communication, pp. 121-162. , Sigman, S. J. (ed.), Lawrence Erlbaum Ass, Hillsdale; Searle, J.R., (1969) Speech Acts, , An Essay in the Philosophy of Language. Cambridge University Press, Cambridge; Grice, H.P., Logic and conversation (1975) Syntax and Semantics, , Cole, P., Morgan, J. (eds.), Academic, New York; Finch, G., (2000) Linguistic Terms and Concepts, , Macmillan, London; Bernsen, N.O., Dybkjer, H., Dybkjer, L., Cooperativity in human-machine and human-human spoken dialogue (1996) Discourse Process, 21, pp. 213-236; Davies, B., Grice's Cooperative Principle: Getting the meaning across (2000) Leeds Working Papers in Linguistics and Phonetics, 8, pp. 361-378; Grandy, R.E., On Grice on language (1989) J. Philos, 86, pp. 514-525; Grice, H.P., (1989) Studies in the Way of Words, , Harvard University Press, Cambridge; Wallis, P., Revisiting the DARPA communicator data using conversation analysis (2008) Interact. Stud, 9 (3), pp. 434-457; Seedhouse, P., (2004) The Interactional Architecture of the Language Classroom, , A Conversation Analysis Perspective. Blackwell, Oxford; Drew, P., Contested evidence in court-room cross-examination: The case of a trial for rape (1992) Talk at Work: Interaction in Institutional Settings, pp. 470-520. , Drew, P., Heritage, J. (eds.), Cambridge University Press, Cambridge; Hutchby, I., Wooffitt, R., (2008) Conversation Analysis, 2nd edn, , Polity Press, Cambridge; Fairclough, N., (2001) Language and Power, 2nd edn, , Longman, Harlow; Goffman, E., (1967) Interaction Rituals: Essays on Face-to-Face Interaction, , Pantheon, New York; Malone, M.J., (1997) Worlds of Talk, , The Presentation of Self in Everyday Conversation. Polity Press, Cambridge; Culpepper, J., (2011) Impoliteness, , Using Language to Cause Offence. Cambridge University Press, Cambridge; Burke, P.J., Stets, J.E., (2009) Identity Theory, , Oxford University Press, Oxford; Dennett, D.C., (1987) The Intentional Stance, , MIT Press, Cambridge; Goffman, E., (1959) The Presentation of Self in Everyday Life, , Doubleday, New York},
document_type={Book Chapter},
source={Scopus},
}

@ARTICLE{Chatila20156,
author={Chatila, R.},
title={On the Ethics of Research and Practice in Robotics and Automation [President's Message]},
journal={IEEE Robotics and Automation Magazine},
year={2015},
volume={22},
number={3},
pages={6-8},
doi={10.1109/MRA.2015.2453691},
art_number={7254302},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941919349&doi=10.1109%2fMRA.2015.2453691&partnerID=40&md5=2d6b96215cc810212e26257f8d1a078e},
abstract={Raja Chatila, President of Robotics and Automation, shares his ideas on the ethics of research and practice in the organization. The R&A community started to reflect on the question of the ethical implications of robotic technology and of autonomous robots more than ten years ago, more precisely, in 2002, within a research atelier funded by the European Robotics Research Network (EURON). Robot ethics is today an interdisciplinary research area at the intersection of applied ethics, robotics, and AI. The European Union (EU) funded several projects in the past ten years on this issue, and, recently, Robolaw, the conclusions of which were presented before representatives of the EU Parliament.},
keywords={Philosophical aspects, Ethical implications;  European union;  Interdisciplinary research;  Robot ethics;  Robotic technologies;  Robotics research, Robotics},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Nomura2015,
author={Nomura, T.},
title={General republics' opinions on robot ethics: Comparison between Japan, the USA, Germany, and France},
journal={AISB Convention 2015},
year={2015},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938718813&partnerID=40&md5=5e35396ce031058f952385313ea0e4b6},
abstract={Ethical issues on robots need to be investigated based on international comparison because general publics' conceptualizations of and feelings toward robots differ due to different situations with respect to mass media and historical influences of technologies. As a preliminary stage of this international comparison, a questionnaire survey based on openended questions was conducted in Japan, the USA, Germany and France (N = 100 from each countries). As a result, it was found that (1) people in Japan tended to react to ethical issues of robotics more seriously than those in the other countries, although those in Germany tended not to connect robotics to ethics, (2) people in France tended to specify unemployment as an ethical issue of robotics in comparison with the other countries, (3) people in Japan tended to argue the restriction of using and developing robots as a solution for the ethical problems, although those in France had the opposite trend.},
keywords={Robotics;  Robots;  Surveys, Ethical issues;  Ethical problems;  General publics;  International comparison;  Mass media;  Open-ended questions;  Questionnaire surveys;  Robot ethics, Philosophical aspects},
references={Asaro, P.M., What should we want from a robot ethic? (2006) International Review of Information Ethics, 6, pp. 9-16; Barendregt, W., Paiva, A., Kappas, A., Vasalou, A., Heath, C., Serholt, S., Basedow, C., Patrcia, A.O., Child-robot interaction: Social bonding, learning and ethics (2014) Workshop Proceedings of Interaction Design and Children Conference IDC14; Bartneck, C., Suzuki, T., Kanda, T., Nomura, T., The influence of people's culture and prior experiences with aibo on their attitude towards robots (2007) AI & Society, 21 (1-2), pp. 217-230; Briggs, G., Scheutz, M., How robots can affect human behavior: Investigating the effects of robotic displays of protest and distress (2014) International Journal of Social Robotics, 6 (3), pp. 343-355; Kamide, H., Mae, Y., Kawabe, K., Shigemi, S., Arai, T., Effect of human attributes and type of robots on psychological evaluation of humanoids (2012) Proc. IEEE Workshop on Advanced Robotics and Its Social Impacts, pp. 40-45; Lin, P., Introduction to robot ethics (2011) Robot Ethics: The Ethical and Socia L Implications of Robotics, pp. 3-15. , eds., P. Lin, K. Abney, and G. A. Bekey MIT Press; MacDorman, K.F., Vasudevan, S.K., Ho, C.-C., Does Japan really have robot mania? Comparing attitudes by implicit and explicit measures (2009) AI & Society, 23 (4), pp. 485-510; Moon, A., Danielson, P., Van Der Loos, H.F.M., Survey-based discussions on morally contentious applicati ons of interactive robotics (2012) International Journal of Social Robotics, 4 (1), pp. 77-96; Nomura, T., Sugimoto, K., Syrdal, D.S., Dautenhahn, K., Social acceptance of humanoid robots in Japan: A survey for development of the frankenstein syndrome questionnaire (2012) Proc. 12th IEEE-RAS International Conference on Humanoid Robots, pp. 242-247; Nomura, T., Suzuki, T., Kanda, T., Han, J., Shin, N., Burke, J., Kato, K., What people assume about humanoid and animal-type robots: Cross-cultural analysis between japan, korea, and the USA (2008) International Journal of Humanoid Robotics, 5 (1), pp. 25-46; Oestreicher, L., Eklundh, K.S., User expectations on human-robot co-operation (2006) Proc.IEEE International Symposium on Robot and Human Interactive Communication, pp. 91-96; Riek, L.D., Howard, D., A code of ethics for the human-robot interaction profession (2014) Presented at WeRobot 2014 Conference, , March; Riek, L.D., Mavridis, N., Antali, S., Darmaki, N., Ahmed, Z., Neyadi, M.A., Alketheri, A., Ibn sina steps out: Exploring Arabic attitudes toward humanoid robots (2010) Proc. 36th Annual Convention of the Society for the Study for Artificial Intelligence and the Simulation of Behaviour (AISB 2010, 1, pp. 88-94; Scopelliti, M., Giuliani, M.V., Fornara, F., Robots in a domestic setting: A psychological approach (2005) Universal Access in the Information Society, 4 (2), pp. 146-155; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2012) Ethics and Informati on Technology, 14 (1), pp. 27-40; Shibata, T., Wada, K., Ikeda, Y., Sabanovic, S., Cross-cultural studies on subjective evaluation of a seal robot (2009) Advanced Robotics, 23 (4), pp. 443-458; Takayama, L., Ju, W., Nass, C., Beyond dirty, dangerous and dull: What everyday people think robots should do (2008) Proc. 3rd ACM/IEEE International Conference on Human-Robot Interaction, pp. 25-32; Trovato, G., Zecca, M., Sessa, S., Jamone, L., Ham, J., Hashimoto, K., Takanishi, A., Cross-cultural study on human-robot greeting interaction: Acceptance and discomfort by egyptians and Japanese ', paladyn (2013) Journal of Behavioral Robotics, 4 (2), pp. 83-93; Sabanovíc, S., Robots in society, society in robots (2010) International Journal of Social Robotics, 2 (4), pp. 439-445; Wang, L., Rau, P.-L.P., Evers, V., Krisper, B., Hinds, P., When in Rome: The role of culture & context in adherence to robot recommendations (2010) Proc. 5th ACM/IEEE International Conference on Human-Robot Interaction, pp. 359-366},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Torrance2015291,
author={Torrance, S. and Chrisley, R.},
title={Modelling consciousness-dependent expertise in machine medical moral agents},
journal={Intelligent Systems, Control and Automation: Science and Engineering},
year={2015},
volume={74},
pages={291-316},
doi={10.1007/978-3-319-08108-3_18},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921651232&doi=10.1007%2f978-3-319-08108-3_18&partnerID=40&md5=af7020565a20951b5e4fd8fc95c4f463},
abstract={It is suggested that some limitations of current designs for medical AI systems (be they autonomous or advisory) stem from the failure of those designs to address issues of artificial (or machine) consciousness. Consciousness would appear to play a key role in the expertise, particularly the moral expertise, of human medical agents, including, for example, autonomous weighting of options in (e.g.,) diagnosis; planning treatment; use of imaginative creativity to generate courses of action; sensorimotor flexibility and sensitivity; empathetic and morally appropriate responsiveness; and so on. Thus, it is argued, a plausible design constraint for a successful ethical machine medical or care agent is for it to at least model, if not reproduce, relevant aspects of consciousness and associated abilities. In order to provide theoretical grounding for such an enterprise we examine some key philosophical issues that concern the machine modelling of consciousness and ethics, and we show how questions relating to the first research goal are relevant to medical machine ethics. We believe that this will overcome a blanket skepticism concerning the relevance of understanding consciousness, to the design and construction of artificial ethical agents for medical or care contexts. It is thus argued that it would be prudent for designers of MME agents to reflect on issues to do with consciousness and medical (moral) expertise; to become more aware of relevant research in the field of machine consciousness; and to incorporate insights gained from these efforts into their designs. © Springer International Publishing Switzerland 2015.},
references={Aleksander, I., (2000) How to build a mind: Toward machines with imagination, , Weidenfeld & Nicolson, London; Armer, P., Attitudes toward intelligent machines (2000) Artificial intelligence: Critical concepts, pp. 325-342. , In: Chrisley RL (ed), Routledge, London. (Originally appeared In: Feigenbaum E, Feldman J (eds) Computers and thought. McGraw-Hill, NY, pp 389–405; Anderson, M., Anderson, S.L., (2011) Machine ethics, , Cambridge University Press, Cambridge; Anderson, S.L., Anderson, M., (2011) A prima facie duty approach to machine ethics: Machine learning of features of ethical dilemmas, prima facie duties, and decision principles through a dialogue with ethicists, pp. 476-492. , In: Anderson M, Anderson SL; Baars, B.J., (1988) A cognitive theory of consciousness, , Cambridge University Press, Cambridge; Bentham, J., (1989) An introduction to the principles of morals and legislation, 2005. , In: Burns JH, Hart HL (eds) Oxford University Press, Oxford; Block, N., On a confusion about a function of consciousness (1995) Behav Brain Sci, 18 (2), pp. 227-247; Boltuc, P., The philosophical issue in machine consciousness (2009) Int J Mach Conscious, 1 (1), pp. 155-176; Chalmers, D.J., The singularity: A philosophical analysis (2010) J Conscious Stud, 17 (9-10), pp. 7-65; Chrisley, R.L., Embodied artificial intelligence (2003) Artif Intell, 49, pp. 3-50; Chrisley, R.L., Philosophical foundations of artificial consciousness (2007) Artif Intell Med, 44, pp. 119-137; Clowes, R.W., Seth, A.K., Axioms, properties and criteria: Roles for synthesis in the science of consciousness (2008) Artif Intell Med, 44 (2), pp. 91-104; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Mind Mach, 14 (3), pp. 349-379; Franklin, S., IDA: A conscious artefact? (2003) J Conscious Stud, 10 (4-5), pp. 47-66; Franklin, S., Patterson, F.G.J., The LIDA architecture: Adding new modes of learning to an intelligent, autonomous, software agent. In: IDPT-2006 proceedings (2006) Integrated design and process technology: Society for design and process science; Grau, C., (2011) There is no “I” in “Robot”: Robots and utilitarianism, pp. 451-463. , In: Anderson M, Anderson SL; Gunkel, D., (2012) The machine question: Critical perspectives on AI, robots and ethics, , MIT Press, Cambridges; Gunkel, D., A vindication of the rights of machines (2013) Philos Technol, 27 (1), pp. 113-132; Guzeldere, G., The many faces of consciousness: A field guide (1997) The nature of consciousness: Philosophical debates, pp. 1-67. , In: Block N, Flanagan O, Guzeldere G, MIT Press, Cambridge; Haikonen, P.O., You only live twice: imagination in conscious machines (2005) Proceedings of the AISB05 symposium on machine consciousness, pp. 19-25. , In: Chrisley RL, Clowes RC, Torrance SB, AISB Press, Hatfield; Haikonen, P.O., (2012) Consciousness and robot sentience, , World Scientific, Singapore; Hesslow, G., Conscious thought as simulation of behaviour and perception (2002) Trends Cogn Sci, 6, pp. 242-247; Hesslow, G., Jirenhed, D.A., The inner world of a simple robot (2007) J Conscious Stud, 14, pp. 85-96; Holland, O., Goodman, R., Robots with internal models: A route to machine consciousness? (2003) J Conscious Stud, 10 (4-5), pp. 77-109; Husserl, E., (1952) Ideas pertaining to a pure phenomenology and to a phenomenological philosophy: Second book: Studies in the phenomenology of constitution, 1989. , Trans. Rojcewicz R, Schuwer A, Kluwer Academic Publishers, Dordrecht, The Netherlands; Jaworska, A., Tannenbaum, J., (2013) The grounds of moral status, , http://plato.stanford.edu/archives/sum2013/entries/grounds-moral-status/, In: Zalta EN (ed) The Stanford encyclopedia of philosophy (summer 2013 edn). URL; Kurzweil, R., (2005) The singularity is near: When humans transcend biology, , Viking Press, NY; Latour, B., Morality and technology: The end of the means (2002) Theor Cult Soc, 19 (5-6), pp. 247-260; Lin, P.A., Abney, K., Bekey, G.A., (2012) Robot ethics: The ethical and social implications of robotics, , MIT Press, Cambridge; Merleau-Ponty, M., (1945) The phenomenology of perception (trans Smith C), 1962. , Routledge and Kegan Paul, London; Moor, J.H., The nature, importance and difficulty of machine ethics (2006) IEEE Intell Syst, 21 (4), pp. 18-21; Powers, T.M., (2011) Prospects for a Kantian machine, pp. 464-475. , In: Anderson M, Anderson SL; Regan, T., (1983) The case for animal rights, , The University of California Press, Berkeley; Searle, J.R., (1980) Minds, brains, andprograms. Behav Brain Sci, 3, pp. 417-424; Shanahan, M., A cognitive architecture that combines internal simulation with a global workspace (2006) Conscious Cogn, 15, pp. 433-449; Shanahan, M., (2010) Embodiment and the inner life: Cognition and consciousness in the space of possible minds, , Oxford University Press, Oxford; Sloman, A., The structure of the space of possible minds (1984) The mind and the machine: Philosophical aspects of artificial intelligence, pp. 35-42. , In: Torrance SB, Ellis Horwood, Chichester, Sussex; Sloman, A., Phenomenal and access consciousness and the “Hard” problem: A view from the designer stance (2010) Int J Mach Conscious, 2 (1), pp. 117-169; Sloman, A., Chrisley, R.L., Virtual machines and consciousness (2003) J Conscious Stud, 10 (4-5), pp. 133-172; Sloman, A., Chrisley, R.L., More things than are dreamt of in your biology: Information processing in biologically-inspired robots (2005) Cogn Syst Res, 6 (2), pp. 45-74; Thompson, E., Empathy and consciousness (2001) J Conscious Stud, 8 (5-7), pp. 1-32; Thompson, E., (2007) Mind in life: Biology, phenomenology, and the sciences of mind, , Harvard University Press, Cambridge; Toombs, S.K., (1992) The meaning of illness: A phenomenological account of the different perspectives of physician and patient, , Kluwer Academic Publishers, Norwell; Toombs, S.K., The role of empathy in clinical practice (2001) J Conscious Stud, 8 (5-7), pp. 247-258; Torrance, S.B., Two conceptions of machine phenomenality (2007) J Conscious Stud, 14 (7), pp. 154-166; Torrance, S.B., Ethics and consciousness in artificial agents (2008) Artif Intell Soc, 22 (4), pp. 495-521; Torrance, S.B., Super-intelligence and (super-) consciousness (2012) Int J Mach Conscious, 4 (2), pp. 483-501; Torrance, S.B., Artificial consciousness and artificial ethics: Between realism and socialrelationism (2013) Philos Technol (Special issue on ‘Machines as moral agents and moral patients’), 27 (1), pp. 9-29; Verbeek, P.P., (2011) Moralizing technology: Understanding and designing the morality of things, , Chicago University Press, Chicago; Wallach, W., Allen, C., (2009) Moral machines: Teaching robots right from wrong, , Oxford University Press, Oxford; Wallach, W., Allen, C., Franklin, S., Consciousness and ethics: Artificially conscious moral agents (2011) Int J machine Conscious, 3 (1), pp. 177-192; Whitby, B., Yazdani, M., Artificial intelligence: Building birds out of beer cans (1987) Robotica, 5, pp. 89-92},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kochetkova20153,
author={Kochetkova, T.},
title={An overview of machine medical ethics},
journal={Intelligent Systems, Control and Automation: Science and Engineering},
year={2015},
volume={74},
pages={3-15},
doi={10.1007/978-3-319-08108-3_1},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921347134&doi=10.1007%2f978-3-319-08108-3_1&partnerID=40&md5=b3530154038e99cea853a2fd23d30567},
abstract={This chapter defines the field of medical ethics and gives a brief overview of the history of medical ethics, its main principles and key figures. It discusses the exponential growth of medical ethics along with its differentiation into various subfields since 1960. The major problems and disputes of medical ethics are outlined, with emphasis on the relation between physicians and patients, institutions, and society, as well as on meta-ethical and pedagogic issues. Next, the specific problems of machine ethics as a part of the ethics of artificial intelligence are introduced. Machine ethics is described as a reflection about how machines should behave with respect to humans, unlike roboethics, which considers how humans should behave with respect to robots. A key question is to what extent medical robots might be able to become autonomous, and what degree of hazard their abilities might cause. If there is risk, what can be done to avoid it while still allowing robots in medical care? © Springer International Publishing Switzerland 2015},
references={Allen, C., Smit, I., Wallach, W., Artificial morality: Top-down, bottom-up, and hybrid approaches (2005) Ethics Inf Technol, 7, pp. 149-155; Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) J Exp Theor Artif Intell, 12 (3), pp. 251-261; Allen, C., Wallach, W., Smit, I., Why machine ethics? (2006) Intell Life Syst, 21 (4), pp. 12-17. , www.computer.org; Anderson, M., Anderson, S.L., Armen, C., Machine ethics (2005) AAAI Fall symposium, tech report FS-05-06, , (eds), AAAI Press; Asimov, I., (2004) I-robot, , Bantam Books, New York; Beavers, A.F., Moral machines and the threat of ethical nihilism (2011) Robot ethics: The ethical and social implication on robotics, , In: Lin P, Bekey G, Abney K (eds), MIT Press, Cambridge, Mass; Bringsjord, S., Taylor, J., The divine-command approach to robot ethics (2011) Robot ethics: The ethical and social implication on robotics. MIT Press, , In: Lin P, Bekey G, Abney K (eds), Cambridge, Mass; Campbell, A., Gillet, G., Jones, G., (2005) Medical ethics, , OUP, Oxford; Canters, P., Kochetkova, T., (2013) Ethiek, , Boom Lemma, Damon; Christensen, B., (2009) Can robots make ethical decisions?, , http://www.livescience.com/5729-robots-ethical-decisions.html; Churchland, P., (2011) Braintrust: What neuroscience tells us about morality, pp. 23-26. , Princeton University Press, Princeton; Clarke, A.C., (2000) 2001: A space odyssey, , ROC, New York; Coeckelbergh, M., Robot rights? Toward a social-relational justification of moral consideration (2010) Ethics Inf Technol, 12 (3), pp. 209-221; Damasio, A., (2010) Self comes to mind: Constructing the conscious brain, , Pantheon, New York; Floridi, L., Sanders, J.W., On the morality of artificial agents (2004) Mind Mach, 14 (3), pp. 349-379; Gibson, W., (2004) Neuromancer. ACE, , New York; Gips, J., Towards the ethical robot (1995) Android epistemology, pp. 243-252. , In: Ford K, Glymour C, Hayes P (eds), MIT Press, Cambridge; Jackson, E., (2009) Medical law: Text, cases, and materials, , OUP, Oxford; Jervis, C., Carebots in the community (2005) Br J Healthc Comput Inf Manage, 22 (8), pp. 1-3; Konovalova, L.V., (1998) Prikladnala Etika, , Instituut Filosofii, Moscow; Kurzweil, R., (2005) The singularity is near: When humans transcend biology, , Viking Adult, New York; Moor, J.H., The nature, importance, and difficulty of machine ethics (2006) Intell Life Syst, 8, pp. 18-21; Moravec, H., (2000) Robot: Mere machine to transcendent mind, , Oxford University Press, Oxford; Nissenbaum, H., How computer systems embody values (2001) Computer, 34 (3), p. 120. , 118–119; Picard, R.W., Affective computing: Challenges (2003) Int J Human Comput Stud, 59 (1-2), pp. 55-64; Pineau, J., Montemerloa, M., Pollackb, M., Roya, N., Thruna, S., Towards robotic assistants in nursing homes: Challenges and results (2003) Robot Auton Syst, 42, pp. 271-281; Searle, J.R., Minds, brains, and programs (1980) Behav Brain Sci, 3 (3), pp. 417-457; Swierstra, T., Boenink, M., Walhout, B., Van Est, R., (2009) Leven als bouwpakket, , Ratenau Instituut; Wallach, W., Allen, C., (2010) Moral machines: Teaching robots right from wrong, , The MIT Press, Cambridge; Warren, R., (2011) Paternalism in medical ethics: A critique, p. 10. , In: Journal of The University of York Philosophy Society},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Ferreira2014685,
author={Ferreira, I. and Sequeira, J.},
title={When children interact with robots: Ethics in the MOnarCH project},
journal={Mobile Service Robotics: Proceedings of the 17th International Conference on Climbing and Walking Robots and the Support Technologies for Mobile Machines},
year={2014},
pages={685-692},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007304193&partnerID=40&md5=a5e2bf37fad9dd2bf418e793cb8ccabc},
abstract={The present paper identifies the main ethical issues the EU FP7 MOnarCH Project has to address. The mission of the MOnarCH Project is to contribute to improve the quality of life of inpatient children by having robots interacting with them in distinct contexts in a hospital environment. The paper discusses the ethics challenges in MOnarCH. © 2014 by World Scientific Publishing Co. Pte. Ltd.},
keywords={Mobile robots;  Philosophical aspects, Ethical issues;  Hospital environment;  Quality of life, Robots},
references={Asaro, P., Modeling the Moral User (2009) IEEE Technology and Society Magazine, pp. 20-24; Dautenhahn, K., Werry, I., Towards Interactive Robots in Autism Therapy: Background, Motivation and Challenges (2004) Pragmatics and Cognition, 12 (1), pp. 1-35; Han, J., Jo, M., Jones, V., Jo, J., Comparative study on the educationaluse of home robots for children (2008) Journal of Information Processing Systems, 4 (4), pp. 159-168; Kanda, T., Nishio, S., Ishiguro, H., Hagita N “Interactive Humanoid Robots and Androids in Children's Lives”, Children (2009) Youth and Environments, 19 (1), pp. 12-33; (2013), http://latd.tv/Latitude-Robots-at-School-Findings.pdf, accessed August; Lees, D., Lepage, P., Robots in Education: The Current State of the Art (1996) Journal of Educational Technology Systems, 24 (4), pp. 299-320; Lin, P., Bekey, G., Abney, K., Robots in War: Issues of Risk and Ethics (2009) R Caparro and M Nagenberg (Ed) Ethics and Robotics, AKA Verlagheidelberg; Marti, P., Palma, V., Pollini, A., Rullo, A., Shibata, T., My Gym Robot (2005) Procs. of the Symposium on Robot Companions: Hard Problems and Open Challenges in Robot-Human Interaction, pp. 64-73; Mubin, O., Stevens, C., Shahid, S., Al Mahmud, A., Dong J “A Review ofthe Applicability of Robots in Education” (2013) Technology for Education and Learning, pp. 1-7; Sharkey, A., Sharkey, N., Children, the Elderly, and Interactive Robots (2011) IEEE Robotics & Automation Magazine, pp. 32-38; Sharkey, N., Sharkey, A., Artificial Intelligence and Natural Magic (2006) Artificial Intelligence Review, 25, pp. 9-19; Shibata, T., Mitsui, T., Wada, K., Touda, A., Kumasaka, T., Tagami, K., Tanie, K., Mental Commit Robot and its Application to Therapy of Children (2001) Proc. of 2001 IEEE/ASME Int. Conf. on Advanced Intelligent Mechatronics, pp. 1053-1058; Shin, N., Kim, S., Learning about, from, and with robots: Students' perspectives (2007) Procs. of the RO-MAN'07, pp. 1040-1045; Singer, A., Robotics as Moral Philosophy (2011) Procs. of the 44Th Hawaii Int. Conf. on System Sciences; Tanaka, F., Cicourel, A., Movellan, J., Socialization Between Toddlers and Robots at an Early Childhood Education Center (2007) Procs. of the National Academy of Science, Vol, p. 194; Turkle, S., Breazeal, C., Daste, O., Scassellati, B., First Encounters with Kismet and Cog: Children Respond to Relational Artifacts (2006) Paul Messaris & Leehumphreys, , Digital Media: Transformations in Human Communication, New York: Peter Lang Publishing; Turkle, S., Taggart, W., Kidd, C., Dasté, O., Relational Artifacts with Children and Elders: The Complexities of Cybercompanionship (2006) Connection Science, 18, pp. 347-362},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wohl2014704,
author={Wohl, B.S.},
title={Revealing the ‘face’ of the robot introducing the ethics of Levinas to the field of Robo-ethics},
journal={Mobile Service Robotics: Proceedings of the 17th International Conference on Climbing and Walking Robots and the Support Technologies for Mobile Machines},
year={2014},
pages={704-714},
doi={10.1142/9789814623353_0081},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007289215&doi=10.1142%2f9789814623353_0081&partnerID=40&md5=71564e9e21aaab8745fbfd8871312e56},
abstract={This paper explore the possibility of a new philosophical turn in robot-ethics, considering whether the concepts of Emanuel Levinas particularly his conception of the ‘face of the other’ can be used to understand how non-expert users interact with robots. The term ‘Robot’ comes from fiction and for non-experts and experts alike interaction with robots may be coloured by this history. This paper explores the ethics of robots (and the use of the term robot) that is based on the user seeing the robot as infinitely complex. © 2014 by World Scientific Publishing Co. Pte. Ltd.},
keywords={Mobile robots, Expert users;  Robot ethics, Philosophical aspects},
references={Agamben, G., Heller-Roazen, D., (1998) Homo Sacer. Stanford, , Calif.: Stanford University Press; Asimov, I., (1950), I, robot. New York, N.Y.: Bantam, Spectra; Anderson, N.S., Unhomely at Home: Dwelling with Domestic Robots (2011) Mediatropes, 2 (1), pp. 37-59; Bartneck, C., Forlizzi, J., (2004) A Design-Centred Framework for Social Human-Robot Interaction., pp. 591-594; Bassett, C., Steinmueller, E., Voss, G., (2013) Better Made Up: The Mutual Influence of Science Fiction and Innovation; Galactica, B., (2003) [DVD] Vancouver, British Columbia, Canada: David Eick Productions, R&D TV, Universal Television NBC, Universal Television Studio, , (TV, mini series)., Universal Media Studios, Universal Cable Productions; Ben-Ari, A., Strier, R., 2010. Rethinking cultural competence: What can we learn from Levinas?. British Journal of Social Work, 40 (7), pp. 2155-2167; Breazeal, C., Brooks, A., Chilongo, D., Gray, J., Hoffman, G., Kidd, C.D., Lee, H., Lockerd, A., (2004) Working Collaboratively with Humanoid Robots, 1, pp. 253-272; Brooks, A.G., Gray, J., Hoffman, G., Lockerd, A., Lee, H., Breazeal, C., Robot's play: Interactive games with sociable machines (2004) Computers in Entertainment (CIE), 2 (3), p. 10; Burleigh, T.J., Schoenherr, J.R., Lacroix, G.L., Does the uncanny valley exist? An empirical test of the relationship between eeriness and the human likeness of digitally created faces (2013) Computers in Human Behavior, 29 (3), pp. 759-771; Čapek, K., Selver, P., Playfair, N., (2001), R.U.R. (Rossum's universal robots). Mineola, N.Y.: Dover Publications; Critchley, S., (2001) Continental Philosophy, , Kindle. Oxford: Oxford University Press; Cohen, R.A., Ethics and cybernetics: Levinasian reflections (2000) Ethics and Information Technology, 2 (1), pp. 27-35; Dick, P., (2008) Do Androids Dream of Electric Sheep?., , Kindle. New York: Ballantine Books; Doctorow, C., (2014) Cory Doctorow, "I, Row-Boat,", , http://www.flurb.net/1/doctorow.htm, Flurb #1. [online], Accessed: 9 Apr 2014; Ferri, G., Manzi, A., Salvini, P., Mazzolai, B., Laschi, C., Dario, P., (2011) Dustcart, an Autonomous Robot for Door-To-Door Garbage Collection: From Dustbot Project to the Experimentation in the Small Town of Peccioli., pp. 655-660; Frommer, J., R Osner, D., Lange, J., Haase, M., Giving Computers Personality? Personality in Computers is in the Eye of the User (2013) Coverbal Synchrony in Human-Machine Interaction, p. 41; Gray, K., Wegner, D.M., Feeling robots and human zombies: Mind perception and the uncanny valley (2012) Cognition, 125 (1), pp. 125-130; Hales, C., (2009) An Empirical Framework for Objective Testing for Pconsciousness in an Artificial Agent.Open Artificial Intelligence Journal, 3, pp. 1-15; Hall, J.S., (2012) Towards Machine Agency: A Philosophical and Technological Roadmap; Hinman, L., (2009) Robotic Companions: Some Ethical Questions to Consider; Ho, C., Macdorman, K.F., Pramono, Z.D., Human emotion and the uncanny valley: A GLM (2008) MDS, and Isomap Analysis of Robot Video Ratings, pp. 169-176; Holt, J., The3 Laws of Robotics. (2013) ITNOW, (55), pp. 8-9; Levin, D.T., Saylor, M.M., Lynn, S.D., Distinguishing first-line defaults and second-line conceptualization in reasoning about humans, robots, and computers (2012) International Journal of Human-Computer Studies, 70 (8), pp. 527-534; Levinas, E., (1979) Totality and Infinity, , The Hague: M. Nijhoff Publishers; Levy, D., The ethical treatment of artificially conscious robots (2009) International Journal of Social Robotics, 1 (3), pp. 209-216; Lichocki, P., Billard, A., Kahn, P.H., The ethical landscape of robotics. Robotics \& Automation Magazine (2011) IEEE, 18 (1), pp. 39-50; Macdorman, K.F., (2005) Androids as an experimental apparatus: Why is there an uncanny valley and can we exploit it, pp. 106-118; Mori, M., The uncanny valley (1970) Energy, 7 (4), pp. 33-35; Mudry, P., Degallier, S., Billard, A., (2008) On the Influence of Symbols and Myths in the Responsibility Ascription Problem in Roboethics-A roboticist’s Perspective., pp. 563-568; Nocks, L., The Golem: Between the technological and the divine (1998) Journal of Social and Evolutionary Systems, 21 (3), pp. 281-303; Petersen, S., (2011) Designing People to Serve, p. 283. , Robot Ethics: The Ethical and Social Implications of Robotics; Petersen, S., The ethics of robot servitude (2007) Journal of Experimental \&Theoretical Artificial Intelligence, 19 (1), pp. 43-54; Press, C., Action observation and robotic agents: Learning and anthropomorphism (2011) Neuroscience &Biobehavioral Reviews, 35 (6), pp. 1410-1418; Rae, I., Takayama, L., Mutlu, B., (2013) The Influence of Height in Robotmediated Communication, pp. 1-8; Shelley, M.W., (1831) Frankenstein: Or, a Modern Prometheus., , London: Colburn and Bentley; Smith, K., (2013), http://www.forbes.com/sites/modeledbehavior/2013/05/13/inequalityin-the-robot-future, Inequality In The Robot Future. [online] Forbes., [Accessed 18 Apr. 2014]; Somanader, M.C., Saylor, M.M., Levin, D.T., Remote control and children’s understanding of robots (2011) Journal of Experimental Child Psychology, 109 (2), pp. 239-247; Terada, K., Ito, A., (2010) Can a Robot Deceive Humans?., pp. 191-192; Turing, A.M., Computing machinery and intelligence (1950) Mind, pp. 433-460; Veruggio, G., (2010) Roboethics [Tc Spotlight]. Robotics \&Automation Magazine, IEEE, 17 (2), pp. 105-109; Waldenfels, B., Levinas and the face of the other (2004) 2004. the Cambridge Companion to Levinas, pp. 63-81. , Critchley, S. and Bernasconi, R. eds., Cambridge: Cambridge University Press; Wallach, W., Franklin, S., Allen, C., A conceptual and computational model of moral decision making in human and artificial agents (2010) Topics in Cognitive Science, 2 (3), pp. 454-485; Waytz, A., Gray, K., Epley, N., Wegner, D.M., Causes and consequences of mind perception (2010) Trends in Cognitive Sciences, 14 (8), pp. 383-388; Zwickel, J., Müller, H.J., Eye movements as a means to evaluate and improve robots. (2009) International Journal of Social Robotics, 1 (4), pp. 357-366},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Kukita2014291,
author={Kukita, M.},
title={Another case against killer robots},
journal={Frontiers in Artificial Intelligence and Applications},
year={2014},
volume={273},
pages={291-295},
doi={10.3233/978-1-61499-480-0-291},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922551909&doi=10.3233%2f978-1-61499-480-0-291&partnerID=40&md5=7858248583e398b2dbf2e47179be18e8},
abstract={An intense dispute is now going on around 'killer robots' - lethal autonomous weapons. Typical argument against them are, however, not applicable to other kinds of killer robots, such as euthanasia robots or execution robots. In this article we try to articulate an argument which is more general as to be applicable to any kind of killer robots. We will thereby support the further claim that there are situations in which it is immoral to delegate robots to do morally significant tasks on behalf of human agents. © 2014 The authors and IOS Press. All rights reserved.},
author_keywords={lethal autonomous weapon;  machine ethics;  moral agency;  robot ethics},
keywords={Ontology;  Philosophical aspects, Human agent;  lethal autonomous weapon;  moral agency;  Robot ethics, Robots},
references={Strawser, B.J., Moral predators: The duty to employ uninhabited aerial vehicles Journal of Military Ethics, 9 (4), pp. 342-368; Singer, P.W., (2009) Wired for War:The Robotics Revolution and Conflict in the Twenty-first Century, , Penguin Press HC; Arkin, R., (2009) Governing Lethal Behaviour in Autonomous Robots, , Chapman and Hall/CRC, Boca Raton; (2012), http://www.hrw.org/reports/2012/11/19/losing-humanity-0, Human Rights Watch, Losing humanity: The case against killer robots; Coeckelbergh, M., Drones, information technology, and distance: Mapping the moral epistemology of remote fighting (2013) Ethics and Information Technology, 15 (2), pp. 87-98; Aguiar, F., Branas-Garza, P., Miller, L., Moral distance in dictators games (2008) Judgement and Decision Making, 3 (4), pp. 344-354; Aguilar, P., Brussino, S., Fernádez-Dols, J.-M., Psychological distance increases uncompromising consequentialism (2013) Journal of Experimental Social Psychology, 49 (3), pp. 449-452; Gunkel, D.J., (2012) The Machine Question: Critical Perspective on AI, , Robots, and Ethics, MIT Press, Cambridge; Zizek, S., (2006) Parallax View, , MIT Press, Cambridge; Winograd, T., Thinking machines: Can there be Are we (1991) The Boundaries of Humanity: Humans, pp. 191-218. , J. J. Sheehan and M. Sosna Editors, Animals, Machine. University of California Press, Berkeley},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Coeckelbergh2014,
author={Coeckelbergh, M. and Torrance, S. and Van Wynsberghe, A.},
title={Machine ethics in the context of medical and care agents. (MEMCA-14) Introduction to the symposium proceedings},
journal={AISB 2014 - 50th Annual Convention of the AISB},
year={2014},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907385589&partnerID=40&md5=900bf04ec0deb0a379a3d178f6035acb},
document_type={Editorial},
source={Scopus},
}

@ARTICLE{Strauss20145,
author={Strauss, M.},
title={Patrick Stewart on His Craft, 21st-Century Science and Robot Ethics: The actor whose leading roles in "Star Trek" and X-Men have taken him into the far future, reflects on where present-day society is headed},
journal={Smithsonian},
year={2014},
number={MAY},
pages={5},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899140741&partnerID=40&md5=2f1bfdba7aace13d4e4ab79129bb3783},
document_type={Note},
source={Scopus},
}

@ARTICLE{Guarini2013267,
author={Guarini, M.},
title={Moral Case Classification and the Nonlocality of Reasons},
journal={Topoi},
year={2013},
volume={32},
number={2},
pages={267-289},
doi={10.1007/s11245-012-9130-2},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884522508&doi=10.1007%2fs11245-012-9130-2&partnerID=40&md5=b0ce1bcf5a67d159e46c41ef54b5304b},
abstract={This paper presents the results of training an artificial neural network (ANN) to classify moral situations. The ANN produces a similarity space in the process of solving its classification problem. The state space is subjected to analysis that suggests that holistic approaches to interpreting its functioning are problematic. The idea of a contributory or pro tanto standard, as discussed in debates between moral particularists and generalists, is used to understand the structure of the similarity space generated by the ANN. A spectrum of possibilities for reasons, from atomistic to holistic, is discussed. Reasons are understood as increasing in nonlocality as they move away from atomism. It is argued that contributory standards could be used to understand forms of nonlocality that need not go all the way to holism. It is also argued that contributory standards may help us to understand the kind of similarity at work in analogical reasoning and argument in ethics. Some objections to using state space approaches to similarity are dealt with, as are objections to using empirical and computational work in philosophy. © 2012 Springer Science+Business Media B.V.},
author_keywords={Analogy;  Atomism of reasons;  Holism of reasons;  Machine ethics;  Moral generalism;  Moral particularism;  Nonlocality of reasons;  Similarity},
references={Austin, J.L., (1962) How to do things with words: The William James lectures delivered at Harvard University in 1955, , In: Urmson JO (ed). Oxford, Clarendon; Brewer, S., Exemplary reasoning: semantics, pragmatics, and the rational force of legal argument by analogy (1996) Harvard Law Rev, CIX, pp. 923-1028; Churchland, P., (1989) A Neurocomputational Perspective, , Cambridge: MIT Press, a Bradford Book; Churchland, P., (2007) Neurophilosophy at Work, , Cambridge: Cambridge University Press; Dancy, J., Can a particularist learn the difference between right and wrong? (1999) Proceedings from the 20th World Congress of Philosophy, Volume I: Ethics, , K. Brinkmann (Ed.), Bowling Green: Philosophy Documentation Center; Dancy, J., The particularist's progress (2000) Moral Particularism, pp. 130-156. , B. Hooker and M. Little (Eds.), Oxford: Clarendon-Oxford press; Dancy, J., (2004) Ethics without Principles, , Oxford: Oxford University Press; Gentner, D., Structure mapping: a theoretical framework for analogy (1983) Cogn Sci, 7, pp. 155-170; Goswami, U., Analogical reasoning in children (2001) The Analogical Mind, pp. 437-470. , a Bradford Book, D. Gentner, K. J. Holyoak, and N. B. Kokinov (Eds.), Cambridge: MIT Press; Greene, J., Haidt, J., How (and where) does moral judgment work? (2002) Trends Cogn Sci, 6 (12), pp. 517-523; Guarini, M., A defence of non-deductive reconstructions of analogical arguments (2004) Informal Log, 24 (2), pp. 153-168; Guarini, M., Understanding source blending arguments as arguments from partial analogy (2010) Ratio Juris, 23 (1), pp. 65-100; Guarini, M., Particularism, analogy, and moral cognition (2010) Mind Mach, 20 (3), pp. 385-422; Guarini, M., Computational neural modeling and the philosophy of ethics (2011) Machine Ethics, pp. 316-334. , M. Anderson and S. Anderson (Eds.), Cambridge: Cambridge University Press; Guarini, M., Butchart, A., Smith, P.S., Moldovan, A., Resources for research on analogy: a multi-disciplinary guide (2009) Informal Log, 29 (2), pp. 385-422; Guarini, M., Case classification, similarities, spaces of reasons, and coherences Insights from philosophy, jurisprudence and artificial intelligence, part of the Springer Law and Philosophy series, Coherence, , (forthcoming). In: Araszkiewicz M, Savelka J (eds). Springer, Berlin; Jackson, F., Petit, P., Smith, M., Ethical particularism and patterns (2000) Moral Particularism, , B. Hooker and M. Little (Eds.), Oxford: Oxford University Press; Laakso, A., Cottrell, G., Churchland on connectionism (2006) Paul Churchland, , B. L. Keeley (Ed.), Cambridge: Cambridge University Press; Markman, A.B., Gentner, D., Nonintentional similarity processing (2005) The New Unconscious, , T. Hassin, J. Bargh, and J. Uleman (Eds.), New York: Oxford University Press; McKeever, S., Ridge, M., (2006) Principled Ethics: Generalism as a Regulative Ideal, , Oxford: Oxford University Press; Mikhail, J., (2011) Elements of moral cognition: Rawls' linguistic analogy and the cognitive science of moral and legal judgement, , Cambridge University Press, Cambridge; Nichols, S., (2004) Sentimental Rules: On the Natural Foundations of Moral Judgement, , Oxford: Oxford University Press; O'Reilly, R., Munakata, Y., (2000) Computational Explorations in Cognitive Neuroscience: Understanding the Mind by Simulating the Brain, , Cambridge: MIT Press, a Bradford Book; Postema, G.J., Philosophy of the common law (2002) The Oxford Handbook of Jurisprudence and Philosophy of Law, pp. 588-622. , J. Coleman and S. Shapiro (Eds.), Oxford: Oxford University Press; Postema, G., A similibus ad similia: analogical thinking in law (2007) Common Law Theory, pp. 102-133. , D. Edlin (Ed.), Cambridge: Cambridge University Press; Rissland, E.L., AI and similarity (2006) IEEE Intell Syst, 21 (3), pp. 39-49; Sunstein, C., On analogical reasoning (1993) Harvard Law Rev, 106, pp. 741-791; Sunstein, C., (1996) Legal Reasoning and Political Conflict, , New York: Oxford University Press; Sunstein, C., (1999) One Case at a Time: Judicial Minimalism on the Supreme Court, , Cambridge: Harvard University Press; Sunstein, C., Constitutional agreements without constitutional theories (2000) Ratio Juris, 13 (1), pp. 117-130; Thomson, J.J., A defense of abortion (1971) Philos Public Aff, 1 (1), pp. 47-66; Young, L., Dungan, J., Where in the brain is morality? Everywhere and maybe nowhere (2012) Soc Neurosci, 7 (1), pp. 1-10},
document_type={Article},
source={Scopus},
}

@ARTICLE{Pai20131771,
author={Pai, C.-K. and Lee, R. and Seaton, B. and Hinds, D. and Xia, W.},
title={Assessing deontic trade-offs: A conjoint analysis approach},
journal={Journal of Computers (Finland)},
year={2013},
volume={8},
number={7},
pages={1771-1776},
doi={10.4304/jcp.8.7.1771-1776},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879645048&doi=10.4304%2fjcp.8.7.1771-1776&partnerID=40&md5=8f1593276c36a9ec9754207bbf04fe92},
abstract={Deontic conflicts are situations where you are "damned if you do and damned if you don't" - where each of the available options will lead to an undesirable outcome or violation. How do people reason about deontic conflicts? In this paper we use the experimental technique of conjoint analysis to uncover the relevant decision factors that people use in such situations. Applications are to programming of robots that interact with humans in social situations and which may face deontic conflicts. © 2013 ACADEMY PUBLISHER.},
author_keywords={Conjoint analysis;  Deontic conflict;  Deontology;  Machine ethics;  Robot vehicles;  Robotics},
keywords={Economic and social effects;  Robot programming;  Robotics, Conjoint analysis;  Decision factors;  Deontic;  Deontology;  Experimental techniques;  Robot vehicles;  Trade off, Statistical methods},
references={Within, E., (2008) Kelly's Theory Summarized, , http://www.enquirewithin.co.nz/theoryof.htm#predictable, accessed 27 June; Føllesdal, D., Hilpinen, R., Deontic logic: An introduction (1971) Deontic Logic: Introductory and Systematic Readings, pp. 1-35. , Hilpinen, H., ed., Dordrecht: D. Reidel; Fransella, F., Bannister, D., (1977) A Manual for Repertory Grid Technique, , New York, New York: Academic Press; Fransella, F., Bannister, D., Bell, R., A Manual for Repertory Grid Technique, , 2nd ed; Heller, J., (1961), Catch-22. Simon & Schuster; Hilpinen, R., (1971) Deontic Logic: Introductory and Systematic Readings; Hilpinen, R., (1981) New Studies in Deontic Logic, , Dordrecht: D. Reidel; Jankowicz, D., (2004) The Easy Guide to Repertory Grids, , West Sussex: John Wiley & Sons Ltd; Lee, Ryu, DX: A Deontic Expert System (1995) Journal of Management Information Systems, 12 (1), pp. 145-169; Nute, D., General and special defeasible logic (1989) Proceedings of Tübingen Workshop on Semantic Nets and Nonmonotonic Reasoning, 1989, pp. 114-122; von Wright, G.H., (1951) Deontic Logic. Mind, 60 (237), pp. 1-15; von Wright, G.H., An essay in deontic logic and the general theory of action (1968) Acta Philosophica Fennica, 21, pp. 1-55; Wason, P.C., Reasoning (1966) New Horizons in Psychology, 1, pp. 135-151; (2008) Wikipedia, , http://en.wikipedia.org/wiki/Repertory_grid, Repertory Grid, accessed 27 June},
document_type={Article},
source={Scopus},
}

@CONFERENCE{NoAuthor2012,
title={AISB/IACAP World Congress 2012: Framework for Responsible Research and Innovation in AI, Part of Alan Turing Year 2012},
journal={AISB/IACAP World Congress 2012 - The Machine Question: AI, Ethics and Moral Responsibility, Part of Alan Turing Year 2012},
year={2012},
page_count={107},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893382188&partnerID=40&md5=bfb92df0a39ea9f991b0b502221098d2},
abstract={The proceedings contain 17 papers. The topics discussed include: moral agency, moral responsibility, and artefacts: what existing artefacts fail to achieve (and why), and why they, nevertheless, can (and do!) make moral claims upon us; machines as moral patients we shouldn't care about (yet): the interests and welfare of current machines; manipulation, moral responsibility, and machines; the holy will of ethical machines: a dilemma facing the project of artificial moral agents; behind the mask: machine morality; machines and the moral community; who cares about robots? a phenomenological approach to the moral status of autonomous intelligent machines; a vindication of the rights of machines; the centrality of machine consciousness to machine ethics: between realism and social-relationism; can an unmanned drone be a moral agent? ethics and accountability in military robotics; and bridging the responsibility gap in automated warfare.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Bello2012,
author={Bello, P. and Bringsjord, S.},
title={Machine ethics, mindreading and attributions of responsibility: First computational steps},
journal={AISB/IACAP World Congress 2012: Moral Cognition and Theory of Mind, Part of Alan Turing Year 2012},
year={2012},
page_count={5},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893205007&partnerID=40&md5=ddae868e9efd418df4e8b095ad37222c},
abstract={In a sister paper submitted to this symposium [4], we ex- plored interesting new data generated by experimental philosophers on human attributions of responsibility [10]. This data suggests that human decision-makers deploy multiple concepts of "self" in sup- port of causal attributions. Upon investigating trends in the data, we hypothesize that a significant portion of the variance might be due to the cognitive architecture of the human capacity to mindread. By mindreading, we refer to the human ability to predict and explain the behavior of agents by representing and reasoning about their men- tal states and inferential tendencies. In the present paper, we build on a pre-existing computational model of mindreading [3], showing how the variance in the aforementioned data on causal attributions might well be related to the set of architectural assumptions required to make mindreading tractable.},
keywords={Causal attributions;  Cognitive architectures;  Computational model;  Decision makers;  Human abilities, Philosophical aspects, Cognitive systems},
references={Arkin, R., (2009) Governing Lethal Behavior in Autonomous Robots, , Chapman and Hall/CRC; Bello, P., Shared representations of belief and their effects on action selection: A preliminary computational cognitive model (2011) Proceedings of the 33rd Annual Conference of the Cognitive Science Societyt, pp. 2997-3002. , eds. L Carlson, C. Hoelscher, and T. Shipley. Cogntive Science Society; Bello, P., Bignoli, P., Cassimatis, N., Attention and association explain the emergence of reasoning about false belief in young children (2007) Proceedings of the 8th International Conference on Cognitive Modeling, pp. 169-174. , University of Michigan, Ann Arbor, MI; Bello, P., Bringsjord, S., Machine ethics, folks intuitions and the cognitive architecture of moral judgment (2012) Proceedings of the AISB/IACAP World Congress, , submitted; Bello, P., Guarini, M., Introspection and mindreading as mental simulation (2010) Proceedings Ofthe 32nd Annual Conference Ofthe Cognitive Science Society, pp. 2022-2028. , eds., S. Ohlsson and R. Ca, Austin TX. Cogntive Science Society; Bringsjord, S., Arkoudas, K., Bello, P., Toward a general logicist methodology for engineering ethically correct robots' (2006) IEEE Intelligent Systems, 21 (4), pp. 38-44; Cassimatis, N.L., Murugesan, A., Bignoli, P.G., Inference with relational theories over infinite domains (2009) FLAIRS Conference, , eds., H. Chad Lane and Hans W. Guesgen. AAAI Press; Goldman, A., (2006) Simulating Minds, , Oxford,University Press; Guarini, M., Computational neural modeling and the philosophy of ethics (2011) Machine Ethics, p. 316334. , eds. M. Anderson and S. Anderson, Cambridge University Press; Knobe, J., Nichols, S., Free will and the bounds of the self (2011) Oxford Handbook OfFree Will: Second Edition, pp. 530-554. , ed., R. Kane, Oxford,University Press; McLaren, B., Computational models of ethical reasoning: Challenges, initial steps and future directions (2011) Machine Ethics, pp. 297-315. , eds. M. Anderson and S. Anderson, Cambridge University Press; Mueller, E., (2006) Commonsense Reasoning, , Morgan Kaufmann; Nichols, S., Knobe, J., Moral responsibility and determinism: The cognitive science of folk intuitions (2008) Experimental Philosophy, pp. 105-128. , eds., J. Knobe and Nichols, Oxford; Tversky, A., Kahneman, D., The framing of decisions and the psychology of choice (1981) Science, 211, pp. 453-458},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Komuda201222,
author={Komuda, R. and Rzepka, R. and Araki, K.},
title={RhetorEthics, or - On implementing an aristotelian approach to machine ethics},
journal={AISB/IACAP World Congress 2012: Linguistic and Cognitive Approaches to Dialogue Agents, Part of Alan Turing Year 2012},
year={2012},
pages={22-24},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893201227&partnerID=40&md5=fb5362ce4a6500bc6d3912d0496e88a0},
abstract={We begin this paper with revisiting the differences between descriptive and normative approach to ethics and argue about the usefulness of the latter for the filed of Machine Ethics. We continue this reasoning and present our insights on previous trends in this field and highlight the need for a change in the approach. We justify that experimental approach to Machine Ethics by introducing a moral reasoning system based on Aristotelian identification of civic rhetoric. And present it as a step forward in the Machine Ethics research bypassing theoretical disputes between specialists. We finish this paper with the introduction to the CAMILLA project for adjusting our web-crawling agent and creating an Aristotelian explicit moral agent.},
keywords={Experimental approaches;  Moral agents;  Moral reasoning, Linguistics, Philosophical aspects},
references={Aristotle, Eudemian Ethics, pp. 1216b; Eliezer, Y., (2001) Creating Friendly AI; Waser, M.R., A safe ethical system for intelligent machines (2009) Proceedings of the AAAI 2009 Fall Symposium on Biologically Inspired Cognitive Architectures (BICA-09), , Washington, D.C., USA, November 5-7; Anderson, M., Anderson, S.L., Machine ethics: Creating an ethical intelligent agent (2007) AI Magazine, 28 (4), pp. 15-26; Radoslaw, K., Michal, P., Yoshio, M., Rafal, R., Kenji, A., Machine moral development: Moral reasoning agent based on wisdom of web-crowd and emotions (2010) International Journal of Computational Linguistics Research, 1 (3), pp. 155-163; Ptaszynski, M., Dybala, P., Shi, W., Rzepka, R., Araki, K., Disentangling emotions from the Web. Internet in the service of affect analysis (2008) Proceedings of the Second International Conference on Kansei Engineering & Affective Systems (KEAS'08), pp. 51-56. , Nagaoka, Japan; Shi, W., (2008) Discovering Emotive Content in Utterances Using Web-mining (in Japanese), , Hokkaido University; Ptaszynski, M., Dybala, P., Shi, W., Rzepka, R., Araki, K., Disentangling emotions from the Web. Internet in the service of affect analysis (2008) Proc. of the Second International Conference on Kansei Engineering & Affective Systems (KEAS'08), pp. 51-56. , Nagaoka, Japan; Aristotle, (2001) Rhetorics, , Book I, Chapter 3, 1358b-1359a. In: Arystoteles Dzieła wszystkie, t 6 (in Polish), WN PWN, Warsaw; Joannes Stobaeus, 2.77; St. Thomas Aquinas. De veritate 1.1},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2012,
title={AISB/IACAP World Congress 2012: Linguistic and Cognitive Approaches to Dialogue Agents, Part of Alan Turing Year 2012},
journal={AISB/IACAP World Congress 2012: Linguistic and Cognitive Approaches to Dialogue Agents, Part of Alan Turing Year 2012},
year={2012},
page_count={71},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893200178&partnerID=40&md5=fd48b2ffdf152f03c6c43ca505a19197},
abstract={The proceedings contain 10 papers. The topics discussed include: developing embodied multisensory dialogue agents; augmenting interaction: collecting common sense through AR objects; rhetorethics, or - on implementing an aristotelian approach to machine ethics; a domain analytic method in modular-designed dialogue system: application to a system for Japanese; developments in context-sensitive affect detection in an intelligent agent; YACIS: a five-billion-word corpus of Japanese blogs fully annotated with syntactic and affective information; emotion valence shifts in humorous metaphor misunderstandings generation; affect listeners - from dyads to group interactions with affective dialog systems; and chatterbots with occupation - between non task and task oriented conversational agents.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2012,
title={AISB/IACAP World Congress 2012: Framework for Responsible Research and Innovation in AI, Part of Alan Turing Year 2012},
journal={AISB/IACAP World Congress 2012: Framework for Responsible Research and Innovation in AI, Part of Alan Turing Year 2012},
year={2012},
page_count={21},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893187054&partnerID=40&md5=f8cc455eaadb809a2d954962dd306e31},
abstract={The proceedings contain 3 papers. The topics discussed include: ethical implications for quality of life in robot assisted care of the elderly; a robot ethics: the EPSRC principles and the ethical gap; and good reasons for making bad bots.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2012,
title={AISB/IACAP World Congress 2012: Moral Cognition and Theory of Mind, Part of Alan Turing Year 2012},
journal={AISB/IACAP World Congress 2012: Moral Cognition and Theory of Mind, Part of Alan Turing Year 2012},
year={2012},
page_count={55},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893178529&partnerID=40&md5=85c33d3d0b7888c7287e5f505f0069d4},
abstract={The proceedings contain 10 papers. The topics discussed include: hard problems: framing the Chinese room in which a robot takes a moral turing test; moral action and mechanical models of intelligence: what can we learn from the turing test?; moral cases, moral reasons, and simulation; moral emotions for autonomous agents; cognitive issues of sentiment in machine and human ethics; machine ethics, the frame problem, and theory of mind; towards a theory of mind for ethical software agents; agents modeling agents: incorporating ethics-related reasoning; machine ethics, folk intuitions, & the cognitive architecture of moral judgments; and machine ethics, mindreading & attributions of responsibility: first computational steps.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Roche2012,
author={Roche, D.},
title={Ethical implications for quality of life in robot assisted care of the elderly},
journal={AISB/IACAP World Congress 2012: Framework for Responsible Research and Innovation in AI, Part of Alan Turing Year 2012},
year={2012},
page_count={6},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893172128&partnerID=40&md5=3a19465b25fcc952e6dcbdcbf78365bd},
abstract={As researchers think about Machine Ethics and how ethical decision-making might be implemented in a machine, philosophers such as Torrance[1] and Coecklebergh [2]argue that in order to do so, we must reconsider the boundaries of, and broaden, our moral community. According to Torrance[3] the quest for an ethical 'producer', as a practical research programme involving the engineering of artificial moral agents quickly 'shades into a broader, more theoretical inquiry in to the nature of ethical agency, moral value...and the extent to which autonomous A.I agents can have moral status of different kinds'. That is, those worthy of ethical treatment in order to include them in our ethical or moral community. Taking these ethical debates as a backdrop, I carried out a qualitative survey of the intuitions of nursing staff and care workers regarding their ethical concerns about the use of robots in two care-of-the-elderly facilities in the Republic of Ireland. Using methodology grounded in Experimental Philosophy[4], a semi-structured interview using a- priori themes derived from the literature was used to collect data, which was transcribed and analysed using Template Analysis [5]. Participants were asked to respond to a series of questions in the form of a structured interview which investigated themes such as participant's knowledge of robots and their feelings about the use of robots in care of the elderly. Participants were asked to consider any ethical issues relating to the use of robots, attitudes to robots being solely responsible for clinical care and their attitudes to a humanistic relationship developing between the older person and a robot. Overwhelmingly the concept of patient autonomy was to the fore in all of their considerations and responses and was frequently used as the benchmark against which they weighed their responses.The responses of these naive participants, highlighted and matched a significant number of the deliberations and narratives of philosopher experts. A novel finding from this small-sample- size research was the discovery that if the field is to advance, the methods of Experimental Philosophy will need to be relied on more as a method for deriving the necessary information on the successful implementation of ethical comportment in the design of robots. It was clear from respondents that the contract of care, that they recognized as existing between them and their older charges, extended beyond a mere provision of service. Therefore, the danger in designing robots as service providers lies in the 'not fully grasping' of this concept.},
keywords={Attitudes to robots;  Ethical implications;  Qualitative surveys;  Republic of Ireland;  Research programmes;  Semi structured interviews;  Service provider;  Template analysis, Autonomous agents;  Machine design;  Ontology;  Research;  Robots, Philosophical aspects},
references={Torrance, S., Machine Ethics and the Idea of A More-Than-Human Moral World, pp. 1-24. , To be published in M. and S. Anderson, eds Machine Ethics, Cambridge University Press; Coeckelbergh, M., Moral appearances: Emotions (2010) Robots and Human Morality.Ethics and Information Technology, pp. 235-241. , DOI: 10.1007/s10676-010-9221-y; Knobe, J., Nichols, S., (2008) Experimental Philosophy, , New York: Oxford University Press; King, N., (2006) Essential Guide to Qualitative Methods in Organisational Research, pp. 256-270. , Eds, Cassell, C. and Symon, G. Sage Publications Ltd, London; Luck, M., (2008) Computer Weekly; Moor, J., The nature importance and difficulty of machine ethics (2006) IEEE Intelligent Systems, 21 (4), pp. 18-21; Sparrow, R., Sparrow, L., The hands of machines? The future of aged care (2006) Minds and Machines, 16 (2), pp. 141-161; (2005) CIA World FactBook 2006, , ISBN 1-57488-997-4; Himma, K.E., (2007) Artificial Agency, Consciousness, and the Criteria for Moral Agency: What Properties Must An Artificial Agent Have to Be A Moral Agent?, , http://ssrn.com/abstract=983503; Sharkey, A., Sharkey, N., Granny and the robots: Ethical issues in robot care for the elderly (2010) Ethics and Information Technology; Turkle, S., Taggart, W., Kidd, C.D., Daste, O., Relational artifacts with children and elders: The complexities of cybercompanionship (2006) Connection Science, 18 (4), pp. 347-362; Sparrow, R., Sparrow, L., In the hands of machines? The future of aged care (2006) Minds and Machines, 16 (2), pp. 141-161; Langer, E.J., Rodin, J., The effects of choice and enhanced personal responsibility for the aged: A field experiment in an institutional setting (1976) Journal of Personality and Social Psychology, 34 (2), pp. 191-198; Gaita, R., (1999) A Common Humanity: Thinking about Love & Truth & Justice, pp. 263-268. , Melbourne: Text Publishing; Bazely, P., (2007) Qualitative Data Analysis with NVivo, , Sage, London},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Obodiac2012,
author={Obodiac, E.},
title={Transgenics of the citizen (I)},
journal={Postmodern Culture},
year={2012},
volume={22},
number={3},
doi={10.1353/pmc.2012.0011},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878572084&doi=10.1353%2fpmc.2012.0011&partnerID=40&md5=cd2ebb8d0b61ec8a44e39f0b49d5910a},
abstract={Citizenship exposes non-humans and sub-humans-both animate and inanimate-to abandonment on the far side of its amity line. This essay explores how the figure of the human being designates a technical limit to the isometric principle of limitless access to civil and political rights. As zoon politikon, the human being inhabits a tautegorical enclosure, immuring itself from the claims of all other entities: there is no citizenship for robots or automaton chess players nor even for the wolf of Gubbio with his signatory paw, even while corporations are given rights of personhood. And yet: a pending South Korean Robot Ethics Charter signals that a new planetary order might be afoot. Copyright © 2013 Postmodern Culture & the Johns Hopkins University Press.},
references={Agamben, G., (2004) The Open, , Trans. Kevin Attell. Stanford: Stanford UP, Print; Agamben, G., (2011) The Kingdom and the Glory: For A Theological Geneology of Economy and Government, , Trans. Lorenzo Chiesa. Stanford: Stanford UP, Print; Arendt, H., (1998) The Human Condition, , Introduction by Margaret Canovan. 2nd ed. Chicago: U of Chicago P, Print; Aristotle, (1986) De Anima (On the Soul), , Trans. Hugh Lawson-Tancred. New York: Viking Penguin, Print; Aristotle, Movement in animals (1987) A New Aristotle Reader, , Trans. J. L. Acker. Princeton: Princeton UP, Print; Aristotle, (2000) Politics, , Trans. Benjamin Jowett. New York: Dover Publications, Print; Bakke, M., Zoe-philic desires: Wet media art and beyond (2008) Science and the Political: Parallax, 14 (3), pp. 21-34. , Web; Becker, B., Social robots-emotional agents: Some remarks on naturalizing man machine interaction (2006) International Review of Information Ethics, 6 (12), pp. 37-45. , Web; Benjamin, W., Notes on a theory of gambling (2005) Walter Benjamin: Selected Writings, 2, p. 297. , Ed. Michael William Jennings and Rodney Livingstone. Harvard UP, Print; Čapek, K., (2012) R.U.R. (Rossum's Universal Robots), , Trans. David Wyllie. Adelaide: U of Adelaide P. Web; Catts, O., Zurr, I., (2011) Semi-Living Worry Dolls, , Tissue Culture and Art Project, Australia; Cohen, T., Polemos: 'I am at war with myself' or, Deconstruction ™ in the Anthropocene? (2012) Oxford Literary Review, 34 (2), pp. 239-257. , (Dec.):. Web. 26 Feb; Darling, K., Extending legal rights to social robots (2012) We Robot Conference, , University of Miami. Miami. 23 Apr. Address; Derrida, J., (2008) The Animal That Therefore i Am, , Ed. Marie-Louise Mallet. Trans. David Wills. New York: Fordham UP, Print; Derrida, J., (2009) The Beast and the Sovereign, 1. , Ed. Michel Lisse, Marie-Louise Mallet, and Ginentte Michaud. Trans. Geoffrey Bennington. Chicago: U of Chicago P, Print; Emmeche, C., Does a robot have an Umwelt? Reflections on the qualitative biosemiotics of Jakob von Uexküll (2001) Semiotica, 134 (1-4), pp. 653-693. , Web. 1 Dec; Esposito, R., (2010) Communitas: The Origin and Destiny of Community, , Stanford: Stanford UP, Print; Field, C., South Korean Robot ethics charter 2012 (2012) Enlightenment of An Anchorwoman, , Web. 12 Dec; Grey, W.W., An imitation of life (1950) Scientific American, 182 (5), pp. 42-45. , Web; Haraway, D., When species meet (2007) Posthumanities Series, 3. , Minneapolis: U of Minnesota P, Print; Heidegger, M., (1969) Discourse on Thinking, , Trans. John M. Anderson and E. Hans Freund. New York: Harper and Row, Print; Hobbes, T., (1982) Leviathan, , New York: Penguin Classics, Print; Hobbes, T., (1972) Man and Citizen (de Homine and de Cive), , Garden City: Anchor Books, Print; Lovgren, S., Robot code of ethics to prevent android abuse, protect humans (2007) National Geographic News, , 16 Mar. Web. 1 Dec; Marx, K., Engels, F., (1998) The Communist Manifesto, , New York: Signet Classic, Print; Mori, M., On uncanny valley (2005) Proceedings of the CogSci-2005 Workshop: Toward Social Mechanisms of Android Science, , Stresa, Italy, 18. Aug. Web. 13 Mar; Offray De La Mettrie, J., (2004) Man A Machine, , Whitefish: Kessinger Publications, Print; Schmitt, C., (2006) The Nomos of the Earth, , Trans. G. L. Ulmen. New York: Telos Press, Print; Smith, B., On space and place: The ontology of the eruv Cultures: Conflict Analysis Dialogue, pp. 413-416. , Frankfurt: Ontos. Print},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Tokhi2012871,
author={Tokhi, M.O.},
title={Robot ethics},
journal={Adaptive Mobile Robotics - Proceedings of the 15th International Conference on Climbing and Walking Robots and the Support Technologies for Mobile Machines, CLAWAR 2012},
year={2012},
pages={871-875},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891353382&partnerID=40&md5=31bddbbcd0b44b4ffda4bbee41e0b9cf},
abstract={Robots are developed to provide assistance and support to humans in various sectors of life. However, their development and deployment raises ethical questions that need to be addressed, robot ethics has emerged to encourage developments in robotics in such a way that are shared by different social groups and beliefs. From a socio-technical systems perspective three distinct ethical issues that may be considered in robotics: Ethical action of humans through, or with, robots, designing robots to act ethically, and ethical relationships between humans and robots. The former two involve human ethics of designers, manufacturers and users of robots, and the latter involves how humans treat robots and vice versa. While the intention is to increase the human quality of life with new technological developments, which is ethically good, the responsibility in complying with ethical issues is shared among the various groups involved. This paper discusses robot ethics from a moral perspective and how this may be translated into the design and deployment of a robot and further to distribution of responsibility among the parties concerned. Copyright © 2012 by World Scientific Publishing Co. Pte. Ltd.},
keywords={Mobile robots;  Philosophical aspects;  Robotics, Ethical issues;  Ethical question;  Quality of life;  Robot ethics;  Social groups;  Sociotechnical systems;  Technological development, Machine design},
references={Allen, C., Varner, G., Zinser, J., Prolegomena to any future artificial moral agent (2000) Journal of Experimental and Theoretical Artificial Intelligence, 12, pp. 251-261; Asaro, P.M., What should we want from a robot ethic? (2006) International Review of Information Ethics, 6 (12), pp. 9-16; Kant, I., (1981) Grounding for the Metaphysics of Morals, , J. W. Ellington, Trans.). Indianapolis: Hackett Publishing Company. (Original work published in 1785; Sharkey, N., The ethical frontiers of robotics (2008) Science, 322, pp. 1800-1801; Sullins, J.P., When is a robot a moral agent? (2006) International Review of Information Ethics, 6 (12), pp. 23-30},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2011,
title={Human-Robot Interaction in Elder Care - Papers from the 2011 AAAI Workshop, Technical Report},
journal={AAAI Workshop - Technical Report},
year={2011},
volume={WS-11-12},
page_count={34},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054928132&partnerID=40&md5=9a3593de5dad7e1c60cc3e1d3e5e1ea5},
abstract={The proceedings contain 6 papers. The topics discussed include: a prima facie duty approach to machine ethics and its application to elder care; a general perceptual model for eldercare robots; human-robot interaction research to improve quality of life in elder care - an approach and issues; ethical implications of using the Paro robot with a focus on dementia patient care; the elderly and robots: from experiments based on comparison with younger people; and human-driven spatial language for human-robot interaction.},
document_type={Conference Review},
source={Scopus},
}

@BOOK{Shibata2011345,
author={Shibata, M.},
title={Toward robot ethics through the ethics of autism},
journal={Neuromorphic and Brain-Based Robots},
year={2011},
pages={345-361},
doi={10.1017/CBO9780511994838.016},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931835477&doi=10.1017%2fCBO9780511994838.016&partnerID=40&md5=f446a15810efd2c3f72d5ca8ea17d00b},
abstract={The aim of this chapter is to present an ethical landscape for humans and autonomous robots in the future of a physicalistic world, and which will touch mainly on a framework of robot ethics rather than the concrete ethical problems possibly caused by recent robot technologies. It might be difficult to find sufficient answers to such ethical problems as those occurring with future military robots unless we understand what autonomy in autonomous robots exactly implies for robot ethics. This chapter presupposes that this “autonomy” should be understood as “being able to make intentional decisions from the internal state, and to doubt and reject any rule, ” a definition which requires robots to have at least a minimal folk psychology in terms of desire and belief. And if any agent has a minimal folk psychology, we would have to say that it potentially has the same “right and duties” as we humans with a fully fledged folk psychology, because ethics for us would cover any agent as far as it is regarded to have a folk psychology – even in Daniel C. Dennett's intentional stance (Dennett, 1987). We can see the lack of autonomy in this sense in the famous Asimov's laws (Asimov, 2000) cited by Bekey et al. in Chapter 14 of this volume, which could be interpreted to show the rules any autonomous robots in the future have to obey (see Section 14.3). © Cambridge University Press 2011.},
references={Asimov, I., (2000) I, Robot, , New York: Oxford University Press; Barnbaum, D.R., (2008) The Ethics of Autism, , Bloomington, IN: Indiana University Press; Baron-Cohen, S., (1995) Mindblindness, , Cambridge, MA: MIT Press; Benn, P., Freedom, resentment, and the psychopath (1999) Philosophy, Psychiatry, and Psychology, 6 (1), pp. 29-39; Chalmers, D.J., (1996) The Conscious Mind, , New York: Oxford University Press; Dennett, D.C., (1987) Intentional Stance, , Cambridge, MA: MIT Press; DSM-IV, (1994) Diagnostic and Statistical Manual of Mental Disorders, 4. , Arlington, VA: American Psychiatric Association; Greene, J., Cohen, J., For the law, neuroscience changes nothing and everything (2004) Law and the Brain, , Zeki, S. and Goodenough, O. (eds.), Oxford, UK: Oxford University Press; Hart, H.L.A., (1961) The Concept of Law, , Oxford, UK: Oxford University Press; Insel, T.R., The challenge of translation in social neuroscience: A review of oxytocin, vasopressin, and affiliative behavior (2010) Neuron, 65 (6), pp. 768-779; Ioan, J., (2006) Asperger's Syndrome and High Achievement, , London: Jessica Kingsley Publishers; Kant, I., Critique of practical reason (1996) Practical Philosophy, pp. 153-271. , Gregor, M. J. (ed.), The Cambridge Edition of the Works of Immanuel Kant in Translation. Cambridge, UK: Cambridge University Press; Kant, I., Groundwork of the metaphysics of morals (1996) Practical Philosophy, pp. 37-108. , Gregor, M. J. (ed.), The Cambridge Edition of the Works of Immanuel Kant in Translation. Cambridge, UK: Cambridge University Press; Kass, L.R., (2003) Beyond Therapy: Biotechnology and the Pursuit of Happiness, , New York: HarperCollins; Kim, J., (1993) Supervenience and Mind, , Cambridge, UK: Cambridge University Press; Mill, J.S., Utilitarianism (1969) Collected Works of John Stuart Mill, pp. 202-259. , Robson, J. M. (ed.), Vol. X. Toronto, Canada: University of Toronto Press; Neumann, I.D., Brain oxytocin: A key regulator of emotional and social behaviours in both females and males (2008) Neuroendocrinology, 20 (6), pp. 858-865},
document_type={Book Chapter},
source={Scopus},
}

@BOOK{NoAuthor20111,
title={General introduction},
journal={Machine Ethics},
year={2011},
volume={9780521112352},
pages={1-4},
doi={10.1017/CBO9780511978036.001},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930882107&doi=10.1017%2fCBO9780511978036.001&partnerID=40&md5=46ad95e28064d808024eab60a63bc874},
abstract={The subject of this book is a new field of research: developing ethics for machines, in contrast to developing ethics for human beings who use machines. The distinction is of practical as well as theoretical importance. Theoretically, machine ethics is concerned with giving machines ethical principles or a procedure for discovering a way to resolve the ethical dilemmas they might encounter, enabling them to function in an ethically responsible manner through their own ethical decision making. In the second case, in developing ethics for human beings who use machines, the burden of making sure that machines are never employed in an unethical fashion always rests with the human beings who interact with them. It is just one more domain of applied human ethics that involves fleshing out proper and improper human behavior concerning the use of machines. Machines are considered to be just tools used by human beings, requiring ethical guidelines for how they ought and ought not to be used by humans. Practically, the difference is of particular significance because succeeding in developing ethics for machines enables them to function (more or less) autonomously, by which is meant that they can function without human causal intervention after they have been designed for a substantial portion of their behavior © Cambridge University Press 2011.},
keywords={Behavioral research, Causal intervention;  Ethical decision making;  Ethical dilemma;  Ethical principles;  Human behaviors;  Human being, Philosophical aspects},
document_type={Editorial},
source={Scopus},
}

@CONFERENCE{Salmasi2009209,
author={Salmasi, A.V. and Gillam, L.},
title={Machine ethics for metaverse gambling: No stake in a $24m market?},
journal={Proceedings of the 2009 Conference in Games and Virtual Worlds for Serious Applications, VS-GAMES 2009},
year={2009},
pages={209-212},
doi={10.1109/VS-GAMES.2009.39},
art_number={5116577},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350072351&doi=10.1109%2fVS-GAMES.2009.39&partnerID=40&md5=0f76d934d10ac76b82f8532a573a1336},
abstract={Online gambling produces a substantial turnover. Unfortunately for potential virtual world gamblers and gambling organizations alike, US law had forced the closure of gambling in the Second Life virtual world. However, an Open Grid Protocol could lead to the provision of off-shore gambling in this virtual world. Aside from legal issues, online gambling generally gives rise to ethical issues relating to prevention of harm. We considered the combined legal and ethical issues, and have proposed and begun to construct and evaluate a system with computational oversight: an ethical advisor. The system is grounded in recent research into Machine Ethics, which may offer insights into other legal and ethical matters, and provides a framework for responsible gambling in our EthiCasino (ethical virtual casino) in Second Life. © 2009 IEEE.},
author_keywords={EthiCasino;  Machine ethics;  Online gambling;  Responsible gambling;  Second Life;  Virtual worlds},
keywords={EthiCasino;  Machine ethics;  Online gambling;  Responsible gambling;  Second Life;  Virtual worlds, Virtual reality, Game theory},
references={(2004) "Internet Gambling Estimates," [Online], , http://www.cca-i.com/PrimaryNavigation/Online%20Data%20Store/ internet_gambling_data.htm, Available: August 2008; (2008) "Second Life Grid Open Gird Protocol," [Online], , http://wiki.secondlife.com/wiki/SLGOGP_Draft_1, Linden Research, Inc. Available: March 2008; Ashley, K.D., McLaren, B.M., Reasoning with Reasons in Case- Based Comparisons First International Conference on Case-Based Reasoning (ICCBR-95), Sesimbra, Portual, 1995, pp. 133-144; McLaren, B., Extensionally Defining Principles and Cases in Ethics: An AI Model (2003) Artificial Intelligence Journal, 150, pp. 145-181; Anderson, M., Anderson, S.L., Armen, C., MedEthEx: Toward a Medical Ethics Advisor (2005) Proc. AAAI 2005 Fall Symp. Caring Machines: AI in Elder Care, pp. 9-16. , AAAI Press; Anderson, M., Anderson, S., EthEl: Toward a Principled Ethical Eldercare Robot (2008) Robotic Helpers: User Interaction, Interfaces and Companions in Assistive and Therapy Robotics Workshop at the Third ACM/IEEE Human-Robot Interaction Conference, pp. 33-39. , ACM/IEEE, Amsterdam, NL; Comeau, S., (1997) "Getting High on Gambling," [Online], , http://reporter-archive.mcgill.ca/Rep/r3004/gambling.html, Available: July 2008; Lewis, E., (2003) "Gambling and Islam: Clashing and Co-existing," [Online], , http://www.math.byu.edu/~jarvis/gambling/studentpapers/eric-lewis.pdf, Available: May 2008; (2002) "Internet Gambling: An Overview of the Issues," [Online], , http://www.gao.gov/new.items/d0389.pdf, Available: March 2008; Saha, P., (2005) "Gambling with Responsibilities," [Online], , http://www.ethicalcorp.com/content.asp?ContentID=3774, Available: May 2008; Anderson, M., Anderson, S., Armen, C., Towards Machine Ethics: Implementing Two Action-Based Ethical Theories (2005) Proc. AAAI 2005 Fall Symposiom. Machine Ethics, pp. 1-7. , AAAI Press; McLaren, B., Ashley, K.D., Assessing Relevance with Extensionally Defined Principles and Cases (2000) Proc. of the 17th National Conference of Artificial Intelligence, pp. 316-322. , AAAI press, Austin, Texas; Allen, C., Wallach, W., Smit, I., Why Machine Ethics? (2005) IEEE Intelligent Systems, 21 (4), pp. 12-17; Pasick, A., (2007) "FBI Checks Gambling in Second Life Virtual World," [Online], , http://www.reuters.com/article/technologNews/idUSHUN43981820070405, Available: March 2008; Wagner, M., (2007) "Second Life Casino Owner Left Scrambling after Gambling Ban," [Online], , http://www.informationweek.com/news/management/showArticle.jhtml? articleID=201201449, Available: August 2008; Gardiner, B., (2007) "Band Failure in Second Life Leads to Call for Regulation," [Online], , http://www.wired.com/gaming/virtualworlds/news/2007/08/virtual_bank, Available: August 2008; Ross, W.D., (1930) The Right and the Good, , Oxford University Press; Garrett, J., (2004) A Simple and Usable (Although Incomplete) Ethical Theory Based on the Ethics of W. D. Ross, , Western Kentucky University},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Torrance2006173,
author={Torrance, S.},
title={Machine consciousness and machine ethics},
journal={Proceedings of AISB'06: Adaptation in Artificial and Biological Systems},
year={2006},
volume={1},
pages={173},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858388961&partnerID=40&md5=f809c0e4d382a67ec6e12d95d8c8a3cf},
abstract={Questions about the possibility of genuine consciousness existing in future artificial humanoids are closely tied up with ethical considerations. I discuss how the assumed presence or absence of consciousness in artificial persons might make a difference to our ethical attitudes towards them.},
keywords={Ethical considerations;  Machine consciousness, Biological systems, Philosophical aspects},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2005,
title={Machine Ethics - Papers from the 2005 AAAI Fall Symposium, Technical Report},
journal={AAAI Fall Symposium - Technical Report},
year={2005},
volume={FS-05-06},
page_count={58},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646128972&partnerID=40&md5=2f699f0ff3fdd1daf8ef635eaabe2ddf},
abstract={The proceedings contain 8 papers. The topics discussed include: ethical robots: the future can heed us; additional thoughts concerning the legal status of a non-biological machine; the utilibot project: an autonomous mobile robot based on utilitarianism; particularism and generalism: how IA can help us to better understand moral cognition; technological artifacts as moral carriers and mediators; lessons in machine ethics from the perspective of two computational models of ethical reasoning; the nature and importance of machine ethics; deontological machine ethics; a robust view of machine ethics; moral intelligence for human and artificial intelligence; and the ambitious ethical status of autonomous robots.},
keywords={Artificial intelligence;  Information technology;  Intelligent agents;  Machine design;  Mathematical models;  Mobile robots;  Robots;  Utility programs, Biological machines;  Computational models;  Machine ethics;  Utilibot projects, Autonomous agents},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{NoAuthor2004,
title={Agent Organizations: Theory and Practice - Papers from the AAAI-04 Workshop, Technical Report},
journal={AAAI Workshop - Technical Report},
year={2004},
volume={WS-04-02},
page_count={79},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-32144445779&partnerID=40&md5=236a1627c3b023626e424149057806fd},
abstract={The proceedings contain 10 papers. The topics discussed include: separating domain and coordination knowledge in multi-agent organizational design and instantiation; verifying norm consistency in electronic institutions; role-based access control in MAS using agent coordination contexts; a case study of organizational effects in a distributed sensor network; emergent clique formation in terrorist recruitment; using schemata to model metacognitive social phenomena; proposal for a Vygotsky's theory based approach for learning in MAS; towards machine ethics; an MDP approach for agent self monitoring; and an organizational model for designing adaptive multiagent systems.},
keywords={Artificial intelligence;  Distributed computer systems;  Knowledge acquisition;  Learning systems;  Logic design;  Sensors;  Technical presentations, Adaptive multiagent systems;  Distributed sensor network;  Electronic institutions;  MDP approach;  Organizational effects, Multi agent systems},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Winograd1984264,
author={Winograd, Terry},
title={ETHICS OF MACINES WHICH MIMIC PEOPLE.},
journal={Proceedings of the Annual Conference of the Association for Computing Machinery},
year={1984},
pages={264},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0021695981&partnerID=40&md5=0ba41e491a2fa4de64f96cdca6105ad4},
abstract={In presenting machines as 'intelligent' we produce an illusion which may be beneficial, may lead to breakdown in the interaction, or may be used by parties to deceive and exploit others. This talk examines the ethical and practical choices in developing machines which mimic human behavior.},
keywords={SPEECH - Processing, ABSTRACT ONLY;  HUMAN BEHAVIOR;  LANGUAGE PROCESSING;  MACHINE ETHICS, SYSTEMS SCIENCE AND CYBERNETICS},
document_type={Conference Paper},
source={Scopus},
}
