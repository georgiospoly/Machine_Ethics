
@article{ ISI:000378346500043,
Author = {Bonnefon, Jean-Francois and Shariff, Azim and Rahwan, Iyad},
Title = {{The social dilemma of autonomous vehicles}},
Journal = {{SCIENCE}},
Year = {{2016}},
Volume = {{352}},
Number = {{6293}},
Pages = {{1573-1576}},
Month = {{JUN 24}},
Abstract = {{Autonomous vehicles (AVs) should reduce traffic accidents, but they will
   sometimes have to choose between two evils, such as running over
   pedestrians or sacrificing themselves and their passenger to save the
   pedestrians. Defining the algorithms that will help AVs make these moral
   decisions is a formidable challenge. We found that participants in six
   Amazon Mechanical Turk studies approved of utilitarian AVs (that is, AVs
   that sacrifice their passengers for the greater good) and would like
   others to buy them, but they would themselves prefer to ride in AVs that
   protect their passengers at all costs. The study participants disapprove
   of enforcing utilitarian regulations for AVs and would be less willing
   to buy such an AV. Accordingly, regulating for utilitarian algorithms
   may paradoxically increase casualties by postponing the adoption of a
   safer technology.}},
Publisher = {{AMER ASSOC ADVANCEMENT SCIENCE}},
Address = {{1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Rahwan, I (Reprint Author), MIT, Media Lab, Cambridge, MA 02139 USA.
   Bonnefon, Jean-Francois, Univ Toulouse Capitole, CNRS, Inst Adv Study Toulouse, Toulouse Sch Econ,Ctr Res Management, Toulouse, France.
   Shariff, Azim, Univ Oregon, Dept Psychol, Eugene, OR 97403 USA.
   Rahwan, Iyad, MIT, Media Lab, Cambridge, MA 02139 USA.
   Shariff, Azim, Univ Calif Irvine, Dept Psychol \& Social Behav, Social \& Behav Sci Gateway 4201, Irvine, CA 92697 USA.}},
DOI = {{10.1126/science.aaf2654}},
ISSN = {{0036-8075}},
EISSN = {{1095-9203}},
Keywords-Plus = {{MACHINE ETHICS; LIFE}},
Research-Areas = {{Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Multidisciplinary Sciences}},
Author-Email = {{irahwan@mit.edu}},
ORCID-Numbers = {{Bonnefon, Jean-Francois/0000-0002-4959-188X
   Shariff, Azim/0000-0003-4444-460X}},
Funding-Acknowledgement = {{Agence Nationale de la Recherche-Laboratoires d'Excellence Institute for
   Advanced Study in ToulouseFrench National Research Agency (ANR);
   University of Oregon}},
Funding-Text = {{J.-F.B. gratefully acknowledges support through the Agence Nationale de
   la Recherche-Laboratoires d'Excellence Institute for Advanced Study in
   Toulouse. This research was supported by internal funds from the
   University of Oregon to A.S. I.R. is grateful for financial support from
   R. Hoffman. Data files have been uploaded as supplementary materials.}},
Cited-References = {{Cote S, 2013, J PERS SOC PSYCHOL, V104, P490, DOI 10.1037/a0030931.
   DAWES RM, 1980, ANNU REV PSYCHOL, V31, P169, DOI 10.1146/annurev.ps.31.020180.001125.
   Deng B, 2015, NATURE, V523, P24, DOI 10.1038/523024a.
   Dietz T, 2003, SCIENCE, V302, P1907, DOI 10.1126/science.1091015.
   Everett JAC, 2016, J EXP PSYCHOL GEN, V145, P772, DOI 10.1037/xge0000165.
   Gao P, 2014, MCKINSEY Q.
   Gold N, 2014, JUDGM DECIS MAK, V9, P65.
   Goodall NJ, 2014, LECT N MOBIL, P93, DOI 10.1007/978-3-319-05990-7\_9.
   Gray K, 2012, PSYCHOL INQ, V23, P206, DOI 10.1080/1047840X.2012.686247.
   Greene Joshua, 2014, MORAL TRIBES EMOTION.
   Haidt J., 2012, RIGHTEOUS MIND WHY G.
   Kass NE, 2001, AM J PUBLIC HEALTH, V91, P1776, DOI 10.2105/AJPH.91.11.1776.
   Montemerlo M, 2008, J FIELD ROBOT, V25, P569, DOI 10.1002/rob.20258.
   Posner EA, 2005, U CHICAGO LAW REV, V72, P537.
   Rosen F, 2005, CLASSICAL UTILITARIA.
   Spieser K, 2014, LECT N MOBIL, P229, DOI 10.1007/978-3-319-05990-7\_20.
   Sunstein CR, 2005, STANFORD LAW REV, V58, P703.
   Urmson C, 2008, J FIELD ROBOT, V25, P425, DOI 10.1002/rob.20255.
   van Arem B, 2006, IEEE T INTELL TRANSP, V7, P429, DOI 10.1109/TITS.2006.884615.
   Van Lange PAM, 2013, ORGAN BEHAV HUM DEC, V120, P125, DOI 10.1016/j.obhdp.2012.11.003.
   Vladeck DC, 2014, WASH LAW REV, V89, P116.
   Waldrop MM, 2015, NATURE, V518, P20, DOI 10.1038/518020a.
   Wallach W, 2008, MORAL MACHINES TEACH.}},
Number-of-Cited-References = {{23}},
Times-Cited = {{272}},
Usage-Count-Last-180-days = {{33}},
Usage-Count-Since-2013 = {{220}},
Journal-ISO = {{Science}},
Doc-Delivery-Number = {{DP2TT}},
Unique-ID = {{ISI:000378346500043}},
OA = {{Green Published}},
ESI-Highly-Cited-Paper = {{Y}},
ESI-Hot-Paper = {{N}},
DA = {{2020-06-17}},
}

@article{ ISI:000239386100007,
Author = {Moor, James H.},
Title = {{The nature, importance, and difficulty of machine ethics}},
Journal = {{IEEE INTELLIGENT SYSTEMS}},
Year = {{2006}},
Volume = {{21}},
Number = {{4}},
Pages = {{18-21}},
Month = {{JUL-AUG}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Moor, JH (Reprint Author), Dartmouth Coll, Dept Philosophy, Hanover, NH 03755 USA.
   Dartmouth Coll, Dept Philosophy, Hanover, NH 03755 USA.}},
DOI = {{10.1109/MIS.2006.80}},
ISSN = {{1541-1672}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
Author-Email = {{james.moor@dartmouth.edu}},
Cited-References = {{Anderson M., 2005, MACHINE ETHICS, P1.
   GIPS J, AAAI FALL 2005 S MAC.
   LEWIS J, 2005, WIRED, V13, P188.
   Lokhorst G. J. C., 2002, CYBERPHILOSOPHY INTE, P280.
   Moor J. H., 1979, NATURE SYSTEM, V1, P217.
   MOOR JH, 1995, METAPHILOSOPHY, V26, P1, DOI 10.1111/j.1467-9973.1995.tb00553.x.
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038.
   SIMON H, 1999, DARTM SEM 1956.
   WALLACH W, 2005, MACHINE ETHICS, P94.
   WIEGEL V, 2005, ETHICS NEW INFORMATI, P419.}},
Number-of-Cited-References = {{10}},
Times-Cited = {{132}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{27}},
Journal-ISO = {{IEEE Intell. Syst.}},
Doc-Delivery-Number = {{068PE}},
Unique-ID = {{ISI:000239386100007}},
DA = {{2020-06-17}},
}

@article{ ISI:000391008500006,
Author = {Bagloee, Saeed Asadi and Tavana, Madjid and Asadi, Mohsen and Oliver,
   Tracey},
Title = {{Autonomous vehicles: challenges, opportunities, and future implications
   for transportation policies}},
Journal = {{JOURNAL OF MODERN TRANSPORTATION}},
Year = {{2016}},
Volume = {{24}},
Number = {{4}},
Pages = {{284-303}},
Month = {{DEC}},
Abstract = {{This study investigates the challenges and opportunities pertaining to
   transportation policies that may arise as a result of emerging
   autonomous vehicle (AV) technologies. AV technologies can decrease the
   transportation cost and increase accessibility to low-income households
   and persons with mobility issues. This emerging technology also has
   far-reaching applications and implications beyond all current
   expectations. This paper provides a comprehensive review of the relevant
   literature and explores a broad spectrum of issues from safety to
   machine ethics. An indispensable part of a prospective AV development is
   communication over cars and infrastructure (connected vehicles). A major
   knowledge gap exists in AV technology with respect to routing behaviors.
   Connected-vehicle technology provides a great opportunity to implement
   an efficient and intelligent routing system. To this end, we propose a
   conceptual navigation model based on a fleet of AVs that are centrally
   dispatched over a network seeking system optimization. This study
   contributes to the literature on two fronts: (i) it attempts to shed
   light on future opportunities as well as possible hurdles associated
   with AV technology; and (ii) it conceptualizes a navigation model for
   the AV which leads to highly efficient traffic circulations.}},
Publisher = {{SPRINGEROPEN}},
Address = {{CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Tavana, M (Reprint Author), La Salle Univ, Distinguished Chair Business Analyt, Business Syst \& Analyt Dept, Philadelphia, PA 19141 USA.
   Tavana, M (Reprint Author), Univ Paderborn, Fac Business Adm \& Econ, Business Informat Syst Dept, D-33098 Paderborn, Germany.
   Bagloee, Saeed Asadi, Univ Melbourne, Melbourne Sch Engn, Dept Infrastruct Engn, Smart Cities Transport Grp, Parkville, Vic, Australia.
   Tavana, Madjid, La Salle Univ, Distinguished Chair Business Analyt, Business Syst \& Analyt Dept, Philadelphia, PA 19141 USA.
   Tavana, Madjid, Univ Paderborn, Fac Business Adm \& Econ, Business Informat Syst Dept, D-33098 Paderborn, Germany.
   Asadi, Mohsen, Kharazmi Univ, Dept Civil \& Environm Engn, Tehran, Iran.
   Oliver, Tracey, Grice Legal, Melbourne, Vic, Australia.}},
DOI = {{10.1007/s40534-016-0117-3}},
ISSN = {{2095-087X}},
EISSN = {{2196-0577}},
Keywords = {{Autonomous vehicle; Connected vehicle; Vehicle navigation; System
   optimality; Intelligent transportation system}},
Keywords-Plus = {{MULTIPLE EQUILIBRIUM BEHAVIORS; DRIVER ASSISTANCE SYSTEMS; ADAPTIVE
   CRUISE CONTROL; MULTICLASS; MODEL; HIGHWAY; PARKING; IMPACT}},
Research-Areas = {{Transportation}},
Web-of-Science-Categories  = {{Transportation Science \& Technology}},
Author-Email = {{saeed.bagloee@unimelb.edu.au
   tavana@lasalle.edu
   mohsenasadibagloee@yahoo.com.au
   tracey@gricelegal.com.au}},
ORCID-Numbers = {{Asadi Bagloee, Saeed/0000-0001-6078-6314}},
Cited-References = {{Aashtiani H.Z., 1979, THESIS.
   ACEA, 2015, AUT IND POCK GUID.
   Alismail H, 2015, J FIELD ROBOT, V32, P723, DOI 10.1002/rob.21543.
   Alonso L, 2011, SENSORS-BASEL, V11, P661, DOI 10.3390/s110100661.
   Alson J, 2014, LIGHT DUTY AUTOMOTIV.
   Anderson J M, 2014, AUTONOMOUS VEHICLE T.
   {[}Anonymous], 2010, 61508 IEC 1.
   Atiyeh C., 2012, PREDICTING TRAFFIC P.
   Bagloee SA, 2014, J ADV TRANSPORT, V48, P486, DOI 10.1002/atr.1198.
   Bagloee SA, 2014, TRANSPORTMETRICA A, V10, P437, DOI 10.1080/23249935.2013.787557.
   Bagloee SA, 2013, TRANSPORT RES REC, P19, DOI 10.3141/2394-03.
   Bansal P, 2016, TRANS RES BOARD 95 A.
   Bar-Gera H, 1999, TRANSPORTATION AND TRAFFIC THEORY, P397.
   Behere S, 2015, 2015 FIRST INTERNATIONAL WORKSHOP ON AUTOMOTIVE SOFTWARE ARCHITECTURE (WASA), P3, DOI 10.1145/2752489.2752491.
   Bengler K, 2014, IEEE INTEL TRANSP SY, V6, P6, DOI 10.1109/MITS.2014.2336271.
   BENNETT LD, 1993, EUR J OPER RES, V71, P177, DOI 10.1016/0377-2217(93)90047-Q.
   Blincoe LJ, 2015, EC SOC IMPACT MOTOR.
   Boyce D, 2014, HDB REGIONAL SCI, P759.
   Braess D., 1968, UNTERNEHMENSFORSCHUN, V12, P258, DOI DOI 10.1007/BF01918335.
   Britting KR, 2010, ARTECH HSE GNSS TECH, P1.
   Brooker AD, 2013, SAE TECHNICAL PAPER.
   Carlino D, 2012, IEEE INT C INTELL TR, P334, DOI 10.1109/ITSC.2012.6338701.
   Chen BY, 2011, MATH COMPUT MODEL, V54, P1428, DOI 10.1016/j.mcm.2011.04.015.
   Chen T. D., 2015, MANAGEMENT SHARED AU.
   Chen W., 2015, VEHICULAR COMMUNICAT.
   Chowdhury M, 2016, IEEE INTEL TRANSP SY, V8, P4, DOI 10.1109/MITS.2015.2503199.
   Dafermos S. C., 1972, TRANSPORT SCI, V6, P73, DOI {[}10.1287/trsc.6.1.73, DOI 10.1287/TRSC.6.1.73].
   Davidson P, 2015, AITPM 2015 NAT C.
   Davidson Peter, 2015, AUTONOMOUS VEHICLES.
   DiClemente J., 2014, AUTONOMOUS CAR POLIC.
   DOE. US, 2011, REP 1 QUADR TECHN RE.
   Dresner K., 2004, P 3 INT JOINT C AUT, P530, DOI DOI 10.1109/AAMAS.2004.242421.
   Dresner K, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1263.
   Dupuis Y, 2014, IEEE INT C INT ROBOT, P4241, DOI 10.1109/IROS.2014.6943160.
   Fagnant DJ, 2015, TRANSPORT RES A-POL, V77, P167, DOI 10.1016/j.tra.2015.04.003.
   Fajardo D, 2011, TRANSPORT RES REC, P223, DOI 10.3141/2259-21.
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772.
   Farmer CM, 2008, TRAFFIC INJURY PREVE.
   FENTON RE, 1991, IEEE T VEH TECHNOL, V40, P100, DOI 10.1109/25.69978.
   Fernandes P, 2012, IEEE T INTELL TRANSP, V13, P91, DOI 10.1109/TITS.2011.2179936.
   Fleming B, 2012, IEEE VEH TECHNOL MAG, V7, P4, DOI 10.1109/MVT.2011.2180673.
   Florian M, 2014, TRANSPORT RES B-METH, V70, P173, DOI 10.1016/j.trb.2014.06.011.
   Folsom T., 2011, IEEE INT S TECHN SOC.
   Folsom TC, 2012, IEEE TECHNOL SOC MAG, V31, P28, DOI 10.1109/MTS.2012.2196339.
   Gozalvez J, 2012, IEEE COMMUN MAG, V50, P176, DOI 10.1109/MCOM.2012.6194400.
   Greenblatt J.B., 2015, CURR SUSTAIN ENERGY, V2015, P74, DOI DOI 10.1007/S40518-015-0038-5.
   Guizzo Erico, 2011, IEEE SPECTRUM O 1018.
   Guoqiang Zhang, 2010, 2010 Second International Conference on Computational Intelligence and Natural Computing (CINC 2010), P229, DOI 10.1109/CINC.2010.5643746.
   HARKER PT, 1988, TRANSPORT SCI, V22, P39, DOI 10.1287/trsc.22.1.39.
   Hensher DA, 2014, TRANSPORT RES A-POL, V61, P227, DOI 10.1016/j.tra.2014.02.017.
   HIS, 2010, INSURANCE I HIGHWAY, P4.
   Hussain M, 2016, P EUR AUT C EAEC ESF, P267.
   Ilas C., 2013, 2013 8 INT S ADV TOP, P1.
   International Organization for Standardization (ISO), 2011, 26262 ISO.
   Ioannou P., 2013, AUTOMATED HIGHWAY SY.
   Jermakian JS, 2011, ACCIDENT ANAL PREV, V43, P732, DOI 10.1016/j.aap.2010.10.020.
   John V, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P246, DOI 10.1109/MVA.2015.7153177.
   Kang N, 2015, AM SOC MECH ENG.
   Kenney JB, 2011, P IEEE, V99, P1162, DOI 10.1109/JPROC.2011.2132790.
   Kesting A, 2010, PHILOS T R SOC A, V368, P4585, DOI 10.1098/rsta.2010.0084.
   Knight W., 2013, MIT TECHNOLOGY REV.
   Kumfer W, 2015, TRANSP RES BOARD 94.
   Kumfer W, 2015, ANAL EFFECTS DEMOGRA.
   Lantos B, 2011, ADV IND CONTROL, P1, DOI 10.1007/978-1-84996-122-6.
   Laslau C, 2014, SET AUTOPILOT PROFIT.
   Levin MW, 2016, TRANSPORT RES C-EMER, V62, P103, DOI 10.1016/j.trc.2015.10.005.
   Levin MW, 2015, TRANSPORT RES REC, P35, DOI 10.3141/2497-04.
   Lillesand T., 2014, REMOTE SENSING IMAGE.
   Link H, 2014, INT J SUSTAIN TP.
   Litman T., 2015, AUTONOMOUS VEHICLE I.
   Lu XY, 2014, LECT N MOBIL, P247, DOI 10.1007/978-3-319-05990-7\_21.
   Maddox J., 2015, 24 INT TECHN C ENH S.
   Maddox J., 2012, IMPROVING DRIVING SA.
   Manyika J., 2013, DISRUPTIVE TECHNOLOG.
   Markoff J., 2010, NY TIMES.
   Marsden G, 2001, TRANSPORT RES C-EMER, V9, P33, DOI 10.1016/S0968-090X(00)00022-X.
   Martin EW, 2011, IEEE T INTELL TRANSP, V12, P1074, DOI 10.1109/TITS.2011.2158539.
   Mathas C, 2016, BURGEONING USE SENSO.
   Melis WJ, 2014, AUTONOMOUS VEHICLES, P509.
   Milakis D., 2015, DEV AUTOMATED VEHICL.
   Miura S, 2015, INT J INTELL TRANSP, V13, P1, DOI 10.1007/s13177-013-0073-9.
   Muir H, 2016, GUARDIAN.
   Nagurney A, 2000, MATH COMPUT MODEL, V32, P393, DOI 10.1016/S0895-7177(00)00142-4.
   Nagurney A, 2002, TRANSPORT RES B-METH, V36, P445, DOI 10.1016/S0191-2615(01)00013-3.
   National Highway Traffic Safety Administration (NHTSA), 2012, 811552 NHTSA DOT HS.
   Nieuwenhuijsen J.A.H, 2015, DIFFUSION AUTOMATED.
   NRC, 2010, HIDD COSTS EN UNPR C.
   Olson P. L, 2010, FORENSIC ASPECTS DRI.
   Paromtchik IE, 1996, IEEE INT CONF ROBOT, P3117, DOI 10.1109/ROBOT.1996.509186.
   Parry IWH, 2007, J ECON LIT, V45, P373, DOI 10.1257/jel.45.2.373.
   Patrascu A, 2014, AUTONOMOUS VEHICLES, P185.
   Patriksson P., 1994, TRAFFIC ASSIGNMENT P.
   Petit J, 2015, IEEE T INTELL TRANSP, V16, P546, DOI 10.1109/TITS.2014.2342271.
   Piao J, 2008, TRANSPORT REV, V28, P659, DOI 10.1080/01441640801987825.
   Ploeg J, 2011, J MOD TRANSP, V19, P207, DOI 10.1007/BF03325760.
   Roughgarden T, 2002, J ACM, V49, P236, DOI 10.1145/506147.506153.
   Savasturk D, 2015, IEEE INT C INTELL TR, P1595, DOI 10.1109/ITSC.2015.260.
   Schellekens M, 2016, COMPUT LAW SECUR REV, V32, P307, DOI 10.1016/j.clsr.2015.12.019.
   Schoettle B., 2015, POTENTIAL IMPACT SEL.
   Schoettle B, 2014, INT CONF CONNECT VEH, P687, DOI 10.1109/ICCVE.2014.7297637.
   Schoitsch Erwin, 2016, ADV MICROSYSTEMS AUT, P251, DOI DOI 10.1007/978-3-319-20855-820.
   Seetharaman G, 2006, COMPUTER, V39, P26, DOI 10.1109/MC.2006.447.
   Shang E., 2015, J FIELD ROBOT.
   Sheffi Y, 1985, URBAN TRANSPORTATION.
   Shoup D., 2005, HIGH COST FREE PARKI.
   Siciliano Bruno, 2008, SPRINGER HDB ROBOTIC.
   Sivaraman S, 2013, LEARNING MODELING UN.
   Sonka M., 2014, IMAGE PROCESSING ANA.
   Sridhar K., 2007, APPL EC INT DEV, V7.
   Tao Z, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P439, DOI 10.1109/ITSC.2014.6957729.
   Templeton B, 2012, BRAD TEMPLETON ROBOC.
   U. S. Environmental Protection Agency, 2013, LIGHT DUT AUT TECHN.
   van Arem B, 2006, IEEE T INTELL TRANSP, V7, P429, DOI 10.1109/TITS.2006.884615.
   van Essen M., 2016, TRANSPORT REV, P1.
   Velaskar P., 2014, INT J ELECT COMPUTER, V4, P329.
   Wan YW, 2014, TRANSPORT RES C-EMER, V44, P202, DOI 10.1016/j.trc.2014.02.018.
   Wang W, 2014, INT J AUTO TECH-KOR, V15, P967, DOI 10.1007/s12239-014-0102-y.
   Weber M., 2014, HIST AUTONOMOUS VEHI.
   Wei JQ, 2013, IEEE INT VEH SYM, P763, DOI 10.1109/IVS.2013.6629559.
   Xie J, 2015, TRANSP RES BOARD 94.
   Xie J, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2336, DOI 10.1109/ITSC.2014.6958064.
   Yang H, 1998, TRANSPORT RES B-METH, V32, P205, DOI 10.1016/S0191-2615(97)00025-8.
   Yang X, 2004, PROCEEDINGS OF MOBIQUITOUS 2004, P114.
   Zheng K, 2015, IEEE COMMUN MAG, V53, P72, DOI 10.1109/MCOM.2015.7355569.
   Zhou NN, 2008, IEEE INT CONF FUZZY, P531, DOI 10.1109/FUZZY.2008.4630419.}},
Number-of-Cited-References = {{125}},
Times-Cited = {{79}},
Usage-Count-Last-180-days = {{11}},
Usage-Count-Since-2013 = {{106}},
Journal-ISO = {{J. Mod. Transp.}},
Doc-Delivery-Number = {{EG4IY}},
Unique-ID = {{ISI:000391008500006}},
OA = {{DOAJ Gold}},
DA = {{2020-06-17}},
}

@article{ ISI:000448900900045,
Author = {Awad, Edmond and Dsouza, Sohan and Kim, Richard and Schulz, Jonathan and
   Henrich, Joseph and Shariff, Azim and Bonnefon, Jean-Francois and
   Rahwan, Iyad},
Title = {{The Moral Machine experiment}},
Journal = {{NATURE}},
Year = {{2018}},
Volume = {{563}},
Number = {{7729}},
Pages = {{59+}},
Month = {{NOV 1}},
Abstract = {{With the rapid development of artificial intelligence have come concerns
   about how machines will make moral decisions, and the major challenge of
   quantifying societal expectations about the ethical principles that
   should guide machine behaviour. To address this challenge, we deployed
   the Moral Machine, an online experimental platform designed to explore
   the moral dilemmas faced by autonomous vehicles. This platform gathered
   40 million decisions in ten languages from millions of people in 233
   countries and territories. Here we describe the results of this
   experiment. First, we summarize global moral preferences. Second, we
   document individual variations in preferences, based on respondents'
   demographics. Third, we report cross-cultural ethical variation, and
   uncover three major clusters of countries. Fourth, we show that these
   differences correlate with modern institutions and deep cultural traits.
   We discuss how these preferences can contribute to developing global,
   socially acceptable principles for machine ethics. All data used in this
   article are publicly available.}},
Publisher = {{NATURE PUBLISHING GROUP}},
Address = {{MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Rahwan, I (Reprint Author), MIT, Media Lab, Cambridge, MA 02139 USA.
   Shariff, A (Reprint Author), Univ British Columbia, Dept Psychol, Vancouver, BC, Canada.
   Bonnefon, JF (Reprint Author), Univ Toulouse Capitole, CNRS, Toulouse Sch Econ TSM R, Toulouse, France.
   Rahwan, I (Reprint Author), MIT, Inst Data Syst \& Soc, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   Awad, Edmond; Dsouza, Sohan; Kim, Richard; Rahwan, Iyad, MIT, Media Lab, Cambridge, MA 02139 USA.
   Schulz, Jonathan; Henrich, Joseph, Harvard Univ, Dept Human Evolutionary Biol, Cambridge, MA 02138 USA.
   Shariff, Azim, Univ British Columbia, Dept Psychol, Vancouver, BC, Canada.
   Bonnefon, Jean-Francois, Univ Toulouse Capitole, CNRS, Toulouse Sch Econ TSM R, Toulouse, France.
   Rahwan, Iyad, MIT, Inst Data Syst \& Soc, 77 Massachusetts Ave, Cambridge, MA 02139 USA.}},
DOI = {{10.1038/s41586-018-0637-6}},
ISSN = {{0028-0836}},
EISSN = {{1476-4687}},
Keywords-Plus = {{LIVES}},
Research-Areas = {{Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Multidisciplinary Sciences}},
Author-Email = {{shariff@psych.ubc.ca
   jean-francois.bonnefon@tse-fr.eu
   irahwan@mit.edu}},
ResearcherID-Numbers = {{Schulz, Jonathan/AAB-2734-2020}},
ORCID-Numbers = {{Schulz, Jonathan/0000-0001-5341-3819}},
Funding-Acknowledgement = {{Ethics and Governance of Artificial Intelligence Fund; ANR-Labex
   Institute for Advanced Study in ToulouseFrench National Research Agency
   (ANR)}},
Funding-Text = {{I.R., E.A., S.D., and R.K. acknowledge support from the Ethics and
   Governance of Artificial Intelligence Fund. J.-F.B. acknowledges support
   from the ANR-Labex Institute for Advanced Study in Toulouse.}},
Cited-References = {{{[}Anonymous], 2017, AS AI PRINC.
   Asimov I., 1950, I ROBOT.
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654.
   Bryson J, 2017, COMPUTER, V50, P116, DOI 10.1109/MC.2017.154.
   Carlsson F, 2010, ACCIDENT ANAL PREV, V42, P1814, DOI 10.1016/j.aap.2010.05.002.
   Conitzer V, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS \& MULTIAGENT SYSTEMS (AAMAS'15), P1213.
   Cushman F, 2009, ETHICAL THEORY MORAL, V12, P9, DOI 10.1007/s10677-008-9145-3.
   Dadich S., 2016, WIRED.
   Dignum Virginia, 2017, P 26 INT JOINT C ART, P4698.
   Gachter S, 2016, NATURE, V531, P496, DOI 10.1038/nature17160.
   Gastil J, 2011, PS-POLIT SCI POLIT, V44, P711, DOI 10.1017/S1049096511001326.
   Graham J, 2016, CURR OPIN PSYCHOL, V8, P125, DOI 10.1016/j.copsyc.2015.09.007.
   Greene J., 2013, MORAL TRIBES EMOTION.
   Haidt J., 2012, RIGHTEOUS MIND WHY G.
   Hainmueller J, 2014, POLIT ANAL, V22, P1, DOI 10.1093/pan/mpt024.
   Hauser M, 2007, MIND LANG, V22, P1, DOI 10.1111/j.1468-0017.2006.00297.x.
   Henrich J, 2001, AM ECON REV, V91, P73, DOI 10.1257/aer.91.2.73.
   Hofstede G., 2003, CULTURES CONSEQUENCE.
   Inglehart R, 2005, CULTURAL CHANGE DEMO.
   International Monetary Fund, 2017, WORLD EC OUTLOOK DAT.
   Johansson-Stenman O, 2008, J HEALTH ECON, V27, P739, DOI 10.1016/j.jhealeco.2007.10.001.
   Johansson-Stenman O, 2011, HEALTH ECON, V20, P723, DOI 10.1002/hec.1627.
   Kaufmann D, 2011, HAGUE J RULE LAW, V3, P220, DOI 10.1017/S1876404511200046.
   Luetge C., 2017, PHILOS TECHNOLOGY, V30, P547, DOI DOI 10.1007/s13347-017-0284-0.
   Milliner D., 2011, PREPRINT.
   Muthukrishna M., 2018, PREPRINT.
   Nishi A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171252.
   ONeil C., 2016, WEAPONS MATH DESTRUC.
   Shariff A, 2017, NAT HUM BEHAV, V1, P694, DOI 10.1038/s41562-017-0202-6.
   Tomasello M., 2014, NATURAL HIST HUMAN T.
   Wallach W, 2008, MORAL MACHINES TEACH.
   WIENER N, 1960, SCIENCE, V131, P1355, DOI 10.1126/science.131.3410.1355.}},
Number-of-Cited-References = {{32}},
Times-Cited = {{75}},
Usage-Count-Last-180-days = {{27}},
Usage-Count-Since-2013 = {{142}},
Journal-ISO = {{Nature}},
Doc-Delivery-Number = {{GY8RS}},
Unique-ID = {{ISI:000448900900045}},
OA = {{Green Accepted, Green Published}},
DA = {{2020-06-17}},
}

@article{ ISI:000251846800001,
Author = {Anderson, Michael and Anderson, Susan Leigh},
Title = {{Machine ethics: Creating an ethical intelligent agent}},
Journal = {{AI MAGAZINE}},
Year = {{2007}},
Volume = {{28}},
Number = {{4}},
Pages = {{15-25}},
Month = {{WIN}},
Abstract = {{The newly emerging in field of machine ethics (Anderson and Anderson
   2006) is concerned with adding an ethical dimension to machines. Unlike
   computer ethics-which has traditionally focused on ethical issues
   surrounding humans' use of machines-machine ethics is concerned with
   ensuring that the behavior of machines toward human users, and perhaps
   other machines as well, is ethically acceptable. In this article we
   discuss the importance of machine ethics, the need for machines that
   represent ethical principles explicitly, and the challenges facing those
   working on machine ethics. We also give an example of current research
   in the field that shows that it is possible, at least in a limited
   domain, for a machine to abstract an ethical principle from examples of
   correct ethical judgments and use that principle to guide its own
   behavior.}},
Publisher = {{AMER ASSOC ARTIFICIAL INTELL}},
Address = {{445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA}},
Type = {{Article}},
Language = {{English}},
ISSN = {{0738-4602}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Cited-References = {{Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   ANDERSON M, 2006, P 8 C INN APPL ART I.
   ANDERSON M, 1995, J PHILOSOPHICAL RES, V20, P453.
   Anderson M, 2005, FS0506.
   ANDERSON M, 2006, IEEE INELLIGENT SYST, V21.
   Anderson M, 2006, IEEE INTELL SYST, V21, P56, DOI 10.1109/MIS.2006.64.
   ASIMOV I, 1976, STELLAR SCI FICTION.
   Baral C., 2003, KNOWLEDGE REPRESENTA.
   Beauchamp TL, 1979, PRINCIPLES BIOMEDICA.
   Bentham J, 2007, INTRO PRINCIPLES MOR.
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82.
   Brody B, 1988, LIFE DEATH DECISION.
   Buchanan A.E., 1989, DECIDING OTHERS ETHI.
   CAPEK K, 1921, PHILOS SCI FICTION.
   CLARKE AC, 1968, {[}No title captured].
   Damasio A.R., 1994, DESCARTES ERROR EMOT.
   Dennett D.C, 2006, INT COMP PHIL C LAV.
   DIETRICH E, 2006, 2006 N AM COMP PHIL.
   GANASCIA JG, 2007, 7 INT COMP ETH C SAN.
   GAZZANIGA M, 2006, ETHICAL BRAIN SCI MO.
   Guarini M, 2006, IEEE INTELL SYST, V21, P22, DOI 10.1109/MIS.2006.76.
   Horty J. F., 2001, AGENCY DEONTIC LOGIC.}},
Number-of-Cited-References = {{22}},
Times-Cited = {{75}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{25}},
Journal-ISO = {{AI Mag.}},
Doc-Delivery-Number = {{244DS}},
Unique-ID = {{ISI:000251846800001}},
DA = {{2020-06-17}},
}

@article{ ISI:000239386100006,
Author = {Allen, Colin and Wallach, Wendell and Smit, Iva},
Title = {{Why machine ethics?}},
Journal = {{IEEE INTELLIGENT SYSTEMS}},
Year = {{2006}},
Volume = {{21}},
Number = {{4}},
Pages = {{12-17}},
Month = {{JUL-AUG}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Allen, C (Reprint Author), Indiana Univ, Dept Hist \& Philosophy Sci, 1011 E 3rd St,Goodbody Hall 130, Bloomington, IN 47405 USA.
   Indiana Univ, Dept Hist \& Philosophy Sci, Bloomington, IN 47405 USA.
   Yale Univ, Yale Inst Social \& Policy Studies, Interdisciplinary Ctr Bioeth, New Haven, CT 06520 USA.
   E\&E Consultants, NL-6561 AM Groesbeek, Netherlands.}},
DOI = {{10.1109/MIS.2006.83}},
ISSN = {{1541-1672}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
Author-Email = {{colallen@indiana.edu
   wwallach@comcast.net
   iva.smit@chello.nl}},
Cited-References = {{Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   ALLEN C, 2006, IN PRESS ETHICS INFO, V7, P149.
   Anderson M., 2005, AAAI FALL S.
   Damasio A, 1994, DESCARTES ERROR.
   DANIELSON P, 1992, {[}No title captured].
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   Foot P., 1967, OXFORD REV, V5, P5, DOI {[}DOI 10.1093/0199252866.003.0002, DOI 10.1002/9781444323528.CH41].
   Gips J, 1995, ANDROID EPISTEMOLOGY, P243.
   KNUTTON M, 2002, INT RAILWAY J   0601.
   Kurzweil R., 2005, SINGULARITY IS NEAR.
   Moravec H. P., 2000, ROBOT MERE MACHINE T.
   Nissenbaum H, 2001, COMPUTER, V34, P120, DOI 10.1109/2.910905.
   NISSENBAUM H, 2001, {[}No title captured], V34, P118.
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038.}},
Number-of-Cited-References = {{14}},
Times-Cited = {{63}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{33}},
Journal-ISO = {{IEEE Intell. Syst.}},
Doc-Delivery-Number = {{068PE}},
Unique-ID = {{ISI:000239386100006}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000345580200009,
Author = {Goodall, Noah J.},
Editor = {{Meyer, G and Beiker, S}},
Title = {{Machine Ethics and Automated Vehicles}},
Booktitle = {{ROAD VEHICLE AUTOMATION}},
Series = {{Lecture Notes in Mobility}},
Year = {{2014}},
Pages = {{93-102}},
Note = {{2nd Annual Workshop on Road Vehicle Automation, Stanford Univ, Stanford,
   CA, JUL 15-19, 2013}},
Organization = {{Natl Acad, Transportat Res Board}},
Abstract = {{Road vehicle travel at a reasonable speed involves some risk, even when
   using computer-controlled driving with failure-free hardware and perfect
   sensing. A fully-automated vehicle must continuously decide how to
   allocate this risk without a human driver's oversight. These are ethical
   decisions, particularly in instances where an automated vehicle cannot
   avoid crashing. In this chapter, I introduce the concept of moral
   behavior for an automated vehicle, argue the need for research in this
   area through responses to anticipated critiques, and discuss relevant
   applications from machine ethics and moral modeling research.}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Goodall, Noah J., Virginia Ctr Transportat Innovat \& Res, Charlottesville, VA 22903 USA.}},
DOI = {{10.1007/978-3-319-05990-7\_9}},
ISSN = {{2196-5544}},
EISSN = {{2196-5552}},
ISBN = {{978-3-319-05990-7; 978-3-319-05989-1}},
Keywords = {{Automation; Autonomous; Ethics; Risk; Morality}},
Research-Areas = {{Transportation}},
Web-of-Science-Categories  = {{Transportation}},
Author-Email = {{noah.goodall@vdot.virginia.gov}},
ResearcherID-Numbers = {{Goodall, Noah/J-7103-2013}},
ORCID-Numbers = {{Goodall, Noah/0000-0002-3576-9886}},
Cited-References = {{American Association of State Highway and Transportation Officials T., 2011, POL GEOM DES HIGHW S.
   Anderson M, 2006, P 18 C INN APPL ART, V2, P1759.
   Anderson M., 2005, P AAAI 2005 FALL S M.
   Asimov Isaac, 1942, ASTOUNDING SCI FICTI, P94.
   Bautin A, 2010, IEEE INT CONF ROBOT, P4022, DOI 10.1109/ROBOT.2010.5509233.
   Beauchamp TL, 1979, PRINCIPLES BIOMEDICA.
   Beavers Anthony F, 2009, ANN M ASS PRACT PROF.
   Benenson R, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS \& VISION: ICARV 2008, VOLS 1-4, P515, DOI 10.1109/ICARCV.2008.4795572.
   Bilger Burkhard, 2013, NEW YORKER.
   Bosch, 2009, LRR3 3 GENERATION LO.
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82.
   DINGUS TA, 2006, {[}No title captured].
   FAMBRO DB, 1997, {[}No title captured].
   Ferguson D., 2013, Pat. no, Patent No. {[}20130261872A1, 20130261872].
   Foot P., 1967, OXFORD REV, V5, P5, DOI {[}DOI 10.1093/0199252866.003.0002, DOI 10.1002/9781444323528.CH41].
   Fraichard T, 2004, ADV ROBOTICS, V18, P1001, DOI 10.1163/1568553042674662.
   Fraichard T, 2012, AUTON ROBOT, V32, P173, DOI 10.1007/s10514-012-9278-z.
   Goodall NJ, 2014, TRANSP RES IN PRESS.
   Hansson SO, 2007, J RADIOL PROT, V27, P147, DOI 10.1088/0952-4746/27/2/002.
   Hibbard B., 2012, LECT NOTES ARTIF INT, V7716, P107.
   Jamson AH, 2013, TRANSPORT RES C-EMER, V30, P116, DOI 10.1016/j.trc.2013.02.008.
   Lin P, 2013, WIRED OPINION   0730.
   Lin Patrick, 2013, ATLANTIC.
   Llaneras R.E., 2013, P 7 INT DRIV S HUM F, P92, DOI {[}10.17077/drivingassessment.1472, DOI 10.17077/DRIVINGASSESSMENT.1472].
   McLaren BM, 2006, IEEE INTELL SYST, V21, P29, DOI 10.1109/MIS.2006.67.
   Najm W., 2003, DOTVNTSCNHTSA0204.
   National Highway Traffic Safety Administration, 2013, PREL STAT POL CONC A, V14-13.
   Powers T.M., 2013, P INT ASS COMP PHIL.
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77.
   Powers TM, 2005, MACHINE ETHICS.
   RAWLS J., 1999, THEORY JUSTICE.
   Reed GS, 2013, TOPOI-INT REV PHILOS, V32, P237, DOI 10.1007/s11245-012-9127-x.
   Ross W. D., 1930, RIGHT GOOD.
   Templeton B, 2013, BRAD IDEAS      1010.
   Tonkens R, 2009, MIND MACH, V19, P421, DOI 10.1007/s11023-009-9159-1.
   U.S. Census Bureau, 2012, STAT ABSTR US.
   Volpe John A, 2008, VEHICLE INF IN PRESS.}},
Number-of-Cited-References = {{37}},
Times-Cited = {{50}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{42}},
Doc-Delivery-Number = {{BB7IK}},
Unique-ID = {{ISI:000345580200009}},
DA = {{2020-06-17}},
}

@article{ ISI:000283869500013,
Author = {Wallach, Wendell and Franklin, Stan and Allen, Colin},
Title = {{A Conceptual and Computational Model of Moral Decision Making in Human
   and Artificial Agents}},
Journal = {{TOPICS IN COGNITIVE SCIENCE}},
Year = {{2010}},
Volume = {{2}},
Number = {{3}},
Pages = {{454-485}},
Month = {{JUL}},
Abstract = {{Recently, there has been a resurgence of interest in general,
   comprehensive models of human cognition. Such models aim to explain
   higher-order cognitive faculties, such as deliberation and planning.
   Given a computational representation, the validity of these models can
   be tested in computer simulations such as software agents or embodied
   robots. The push to implement computational models of this kind has
   created the field of artificial general intelligence (AGI). Moral
   decision making is arguably one of the most challenging tasks for
   computational approaches to higher-order cognition. The need for
   increasingly autonomous artificial agents to factor moral considerations
   into their choices and actions has given rise to another new field of
   inquiry variously known as Machine Morality, Machine Ethics, Roboethics,
   or Friendly AI. In this study, we discuss how LIDA, an AGI model of
   human cognition, can be adapted to model both affective and rational
   features of moral decision making. Using the LIDA model, we will
   demonstrate how moral decisions can be made in many domains using the
   same mechanisms that enable general decision making. Comprehensive
   models of human cognition typically aim for compatibility with recent
   research in the cognitive and neural sciences. Global workspace theory,
   proposed by the neuropsychologist Bernard Baars (1988), is a highly
   regarded model of human cognition that is currently being
   computationally instantiated in several software implementations. LIDA
   (Franklin, Baars, Ramamurthy, \& Ventura, 2005) is one such
   computational implementation. LIDA is both a set of computational tools
   and an underlying model of human cognition, which provides mechanisms
   that are capable of explaining how an agent's selection of its next
   action arises from bottom-up collection of sensory data and top-down
   processes for making sense of its current situation. We will describe
   how the LIDA model helps integrate emotions into the human
   decision-making process, and we will elucidate a process whereby an
   agent can work through an ethical problem to reach a solution that takes
   account of ethically relevant factors.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wallach, W (Reprint Author), Yale Univ, Inst Social \& Policy Studies, Interdisciplinary Ctr Bioeth, POB 208209, New Haven, CT 06520 USA.
   Wallach, Wendell, Yale Univ, Inst Social \& Policy Studies, Interdisciplinary Ctr Bioeth, New Haven, CT 06520 USA.
   Franklin, Stan, Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.
   Allen, Colin, Indiana Univ, Cognit Sci Program, Bloomington, IN 47405 USA.}},
DOI = {{10.1111/j.1756-8765.2010.01095.x}},
ISSN = {{1756-8757}},
EISSN = {{1756-8765}},
Keywords = {{Moral decision making; Artificial general intelligence; Artificial
   intelligence; Global workspace theory; Machine morality; Machine ethics}},
Keywords-Plus = {{MEMORY CONSOLIDATION; CONSCIOUSNESS; ARCHITECTURE; PERCEPTION;
   SELECTION; ROBOTS; MIND; IDA}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Experimental}},
Author-Email = {{wendell.wallach@yale.edu}},
ResearcherID-Numbers = {{Franklin, Stan/AAI-5506-2020}},
Cited-References = {{Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Allen C, 2006, ETHICS INF TECHNOL, V7, P149, DOI DOI 10.1007/S10676-006-0004-4.
   ALLEN C, 2002, COGNITIVE EMOTIVE ET, V1, P19.
   Anderson J. R., 1990, ADAPTIVE CHARACTER T.
   Anderson M., 2005, MACHINE ETHICS, P1.
   Anderson M, 2006, IEEE INTELL SYST, V21, P56, DOI 10.1109/MIS.2006.64.
   Anderson M, 2006, IEEE INTELL SYST, V21, P10, DOI 10.1109/MIS.2006.70.
   {[}Anonymous], 1993, CLASSIFICATION COGNI.
   Baars Bernard J., 1988, COGNITIVE THEORY CON.
   Baars BJ, 2003, TRENDS COGN SCI, V7, P166, DOI 10.1016/S1364-6613(03)00056-1.
   Baars BJ, 2002, TRENDS COGN SCI, V6, P47, DOI 10.1016/S1364-6613(00)01819-2.
   BADDELEY A, 1992, SCIENCE, V255, P556, DOI 10.1126/science.1736359.
   BADDELEY A, 1992, CONSCIOUS COGN, V1, P3, DOI 10.1016/1053-8100(92)90037-B.
   Baddeley A., 2001, EPISODIC MEMORY.
   Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577, DOI 10.1017/S0140525X99532147.
   Berne Eric, 1964, GAMES PEOPLE PLAY BA.
   Breazeal C., 2002, DESIGNING SOCIABLE R.
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82.
   BROOKS RA, 2002, {[}No title captured].
   Canamero LD, 2002, EMOTIONS IN HUMANS AND ARTIFACTS, P115.
   CLARKE R, 1994, COMPUTER, V27, P57, DOI 10.1109/2.248881.
   CLARKE R, 1993, COMPUTER, V26, P53, DOI 10.1109/2.247652.
   Conway MA, 2001, PHILOS T R SOC B, V356, P1375, DOI 10.1098/rstb.2001.0940.
   DANIELSON P, 1992, {[}No title captured].
   Das P, 2005, NEUROIMAGE, V26, P141, DOI 10.1016/j.neuroimage.2005.01.049.
   Dehaene S, 2003, P NATL ACAD SCI USA, V100, P8520, DOI 10.1073/pnas.1332574100.
   DeMoss D, 1998, P 20 WORLD C PHIL PA.
   DMELLO SK, 2006, WORKSH MOT DEV P AD, V1, P184.
   DRESCHER GL, 1991, {[}No title captured].
   EDELMAN GM, 1987, {[}No title captured].
   ERICSSON KA, 1995, PSYCHOL REV, V102, P211, DOI 10.1037/0033-295X.102.2.211.
   FLAVELL JH, 1979, AM PSYCHOL, V34, P906, DOI 10.1037/0003-066X.34.10.906.
   Franklin S, 2003, MU S ART SOC SIM ORG, V7, P159.
   Franklin S, 2005, CONSCIOUS COGN, V14, P115, DOI 10.1016/j.concog.2004.09.003.
   Franklin S, 2003, J CONSCIOUSNESS STUD, V10, P47.
   Franklin S, 1998, IEEE SYS MAN CYBERN, P2646, DOI 10.1109/ICSMC.1998.725059.
   Franklin S., 2000, Neural Network World, V10, P505.
   Franklin S., 2006, IDPT 2006 P INT DES.
   Franklin S., 2007, AAAI FALL S AI CONSC.
   FRANKLIN S, 2005, S DEV ROB AM ASS ART.
   FRANKLIN S, 2000, S DES FUNCT MIND ART.
   FRANKLIN S, 2005, P 14 ANN INT WORKSH, P427.
   Franklin S., 2005, BRAINS MINDS MEDIA, V1, P1.
   Franklin S., 2006, P 6 INT WORKSH EP RO, V128, P41.
   Franklin S., 1997, INTELLIGENT AGENTS 3, P21, DOI DOI 10.1007/BFB0013570.
   FREEMAN WJ, 1999, {[}No title captured].
   Friedlander D, 2008, FRONT ARTIF INTEL AP, V171, P137.
   GADANHO SC, 2003, {[}No title captured], V4, P385.
   Gibson JJ, 1979, ECOLOGICAL APPROACH.
   Gips James, 1991, ANDROID EPISTEMOLOGY, P243.
   Glenberg AM, 1997, BEHAV BRAIN SCI, V20, P1, DOI 10.1017/S0140525X97470012.
   GOODALE MA, 2004, {[}No title captured].
   Grau C, 2006, IEEE INTELL SYST, V21, P52, DOI 10.1109/MIS.2006.81.
   Guarini M, 2006, IEEE INTELL SYST, V21, P22, DOI 10.1109/MIS.2006.76.
   Heilman KM, 1997, J NEUROPSYCH CLIN N, V9, P439, DOI 10.1176/jnp.9.3.439.
   Hofstadter D. R., 1995, FLUID CONCEPTS CREAT, P205.
   Holland O., 2003, MACHINE CONSCIOUSNES.
   JACKSON JV, 1987, ACM SIGART B, V191, P23.
   James W., 1890, PRINCIPLES PSYCHOL.
   JOHNSTON V, 1999, {[}No title captured].
   Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301.
   Kanerva P, 1988, SPARSE DISTRIBUTED M.
   Kruschke JK, 2003, CURR DIR PSYCHOL SCI, V12, P171, DOI 10.1111/1467-8721.01254.
   LAIRD JE, 1987, ARTIF INTELL, V33, P1, DOI 10.1016/0004-3702(87)90050-6.
   Massimini M, 2005, SCIENCE, V309, P2228, DOI 10.1126/science.1117256.
   McLaren BM, 2006, IEEE INTELL SYST, V21, P29, DOI 10.1109/MIS.2006.67.
   Merker B, 2005, CONSCIOUS COGN, V14, P89, DOI 10.1016/S1053-8100(03)00002-3.
   MINSKY M, 1985, {[}No title captured].
   Mulcahy NJ, 2006, SCIENCE, V312, P1038, DOI 10.1126/science.1125456.
   NADEL L, 1992, J COGNITIVE NEUROSCI, V4, P179, DOI 10.1162/jocn.1992.4.3.179.
   Nadel L, 1997, CURR OPIN NEUROBIOL, V7, P217, DOI 10.1016/S0959-4388(97)80010-4.
   Negatu A., 2007, P 3 WORKSH ANT BEH A, P108.
   Negatu A., 2002, COGNITIVE SCI Q, V2, P363.
   Ornstein R., 1986, MULTIMIND.
   Picard R. W., 1997, AFFECTIVE COMPUTING.
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77.
   Ramamurthy U, 2004, IEEE SYS MAN CYBERN, P5858.
   RAMAMURTHY U, 2005, 9 C ASS SCI STUD CON.
   Ramamurthy U, 2006, P 7 INT C COGN MOD, P244.
   SCASSELLATI B, 2001, {[}No title captured].
   Shanahan M, 2006, CONSCIOUS COGN, V15, P433, DOI 10.1016/j.concog.2005.11.005.
   Sigman M, 2006, PLOS BIOL, V4, P1227, DOI 10.1371/journal.pbio.0040220.
   SLOMAN A, 1999, {[}No title captured], P35.
   Sloman A., 1998, P S COGN AG MOD HUM.
   Smit Iva, 2002, COGNITIVE EMOTIVE ET, V1, P13.
   Smith JD, 2005, CURR DIR PSYCHOL SCI, V14, P19, DOI 10.1111/j.0963-7214.2005.00327.x.
   Stickgold R, 2005, TRENDS NEUROSCI, V28, P408, DOI 10.1016/j.tins.2005.06.004.
   Sun R, 2007, J EXP THEOR ARTIF IN, V19, P159, DOI 10.1080/09528130701191560.
   Tarsitano M, 2006, ANIM BEHAV, V72, P1437, DOI 10.1016/j.anbehav.2006.05.007.
   Tulving E., 1983, ELEMENTS EPISODIC ME.
   Uchida N, 2006, NAT REV NEUROSCI, V7, P485, DOI 10.1038/nrn1933.
   Varela F, 1991, EMBODIED MIND.
   Vidnyanszky Z., 2003, J VISION, V3, p174a.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.
   Wallach W, 2008, AI SOC, V22, P565, DOI 10.1007/s00146-007-0099-0.
   Wang P, 2008, ARTIFICIAL GEN INTEL.
   Watt DF, 1998, J NEUROPSYCH CLIN N, V10, P113.
   Werdenich D, 2006, ANIM BEHAV, V71, P855, DOI 10.1016/j.anbehav.2005.06.018.
   Wilcox S, 2002, COGNITIVE ANIMAL, P27.
   Willis J, 2006, PSYCHOL SCI, V17, P592, DOI 10.1111/j.1467-9280.2006.01750.x.
   Yoshida H, 2003, CHILD DEV, V74, P564, DOI 10.1111/1467-8624.7402016.
   YUDKOWSKY E, 2001, WHAT IS FRIENDLY AI.
   Zacks JM, 2007, PSYCHOL BULL, V133, P273, DOI 10.1037/0033-2909.133.2.273.
   Zhu J, 2002, PHILOS PSYCHOL, V15, P19, DOI 10.1080/09515080120109397.}},
Number-of-Cited-References = {{104}},
Times-Cited = {{41}},
Usage-Count-Last-180-days = {{8}},
Usage-Count-Since-2013 = {{85}},
Journal-ISO = {{Top. Cogn. Sci.}},
Doc-Delivery-Number = {{675VX}},
Unique-ID = {{ISI:000283869500013}},
DA = {{2020-06-17}},
}

@article{ ISI:000323642000004,
Author = {Sullins, John P.},
Title = {{Robots, Love, and Sex: The Ethics of Building a Love Machine}},
Journal = {{IEEE TRANSACTIONS ON AFFECTIVE COMPUTING}},
Year = {{2012}},
Volume = {{3}},
Number = {{4}},
Pages = {{398-409}},
Month = {{OCT-DEC}},
Abstract = {{This paper will explore the ethical impacts of the use of affective
   computing by engineers and roboticists who program their machines to
   mimic and manipulate human emotions in order to evoke loving or amorous
   reactions from their human users. We will see that it does seem
   plausible that some people might buy a love machine if it were created,
   but it is argued here that principles from machine ethics have a role to
   play in the design of these machines. This is best achieved by applying
   what is known about the philosophy of love, the ethics of loving
   relationships, and the philosophical value of the erotic in the early
   design stage of building robust artificial companions. The paper
   concludes by proposing certain ethical limits on the manipulation of
   human psychology when it comes to building sex robots and in the
   simulation of love in such machines. In addition, the paper argues that
   the attainment of erotic wisdom is an ethically sound goal and that it
   provides more to loving relationships than only satisfying physical
   desire. This fact may limit the possibility of creating a machine that
   can fulfill all that one should want out of erotic love unless a machine
   can be built that would help its user attain this kind of love.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Sullins, JP (Reprint Author), Sonoma State Univ, Dept Philosophy, 1801 East Cotati Ave, Rohnert Pk, CA 94928 USA.
   Sonoma State Univ, Dept Philosophy, Rohnert Pk, CA 94928 USA.}},
DOI = {{10.1109/T-AFFC.2012.31}},
ISSN = {{1949-3045}},
Keywords = {{Affective computing; artificial companions; artificial emotions;
   robotics}},
Keywords-Plus = {{SELF}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Cybernetics}},
Author-Email = {{john.sullins@sonoma.edu}},
Cited-References = {{{[}Anonymous], 2012, CONTINUOUS IOS.
   Aron A, 1999, SOC COGNITION, V17, P140, DOI 10.1521/soco.1999.17.2.140.
   ARON A, 1992, J PERS SOC PSYCHOL, V63, P596, DOI 10.1037/0022-3514.63.4.596.
   ARON A, 1991, J PERS SOC PSYCHOL, V60, P241, DOI 10.1037/0022-3514.60.2.241.
   Aron EN, 1996, PERS RELATIONSHIP, V3, P45, DOI 10.1111/j.1475-6811.1996.tb00103.x.
   BREAZEAL C, 1999, {[}No title captured], P18.
   Breazeal C., 2002, DESIGNING SOCIABLE R.
   BREAZEAL C, 2004, {[}No title captured].
   BROOKS RA, 2002, {[}No title captured].
   Buck R, 2002, PSYCHOL REV, V109, P739, DOI 10.1037//0033-295X.109.4.739.
   Buck R., 1997, EMPATHIC ACCURACY, P17.
   Buck R., 1991, ALTRUISM REV PERSONA, V12, P149.
   Coeckelbergh M, 2009, INT J SOC ROBOT, V1, P217, DOI 10.1007/s12369-009-0026-2.
   Cook SDN, 2008, PHILOSOPHY AND DESIGN: FROM ENGINEERING TO ARCHITECTURE, P259, DOI 10.1007/978-1-4020-6591-0\_20.
   DAVIS MH, 1997, {[}No title captured], P144.
   Duffy BR, 2003, ROBOT AUTON SYST, V42, P177, DOI 10.1016/S0921-8890(02)00374-3.
   FEHR B, 1994, PERS RELATIONSHIP, V1, P309, DOI 10.1111/j.1475-6811.1994.tb00068.x.
   Fehr B., 1991, J PERS SOC PSYCHOL, V60, P424.
   FOLKMAN S, 1988, J PERS SOC PSYCHOL, V54, P466, DOI 10.1037/0022-3514.54.3.466.
   Gaudin S., 2010, COMPUTERWORLD.
   GILBERT DT, 1986, J PERS SOC PSYCHOL, V50, P269, DOI 10.1037/0022-3514.50.2.269.
   Kanda T., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P2215.
   Kanda T, 2001, IEEE INT CONF ROBOT, P4166, DOI 10.1109/ROBOT.2001.933269.
   KANDA T, 2005, {[}No title captured].
   Levy D., 2007, LOVE SEX ROBOTS EVOL.
   MENZEL P, 2000, {[}No title captured].
   Meston CM, 2007, ARCH SEX BEHAV, V36, P477, DOI 10.1007/s10508-007-9175-2.
   Mori M., 1970, ENERGY, V7, P33, DOI DOI 10.1109/MRA.2012.2192811.
   Mori M., 1981, BUDDHA ROBOT ROBOT E.
   Ortigue S, 2008, MED HYPOTHESES, V71, P941, DOI 10.1016/j.mehy.2008.07.016.
   PLATO, 2001, {[}No title captured].
   Samani H. A., 2010, P 19 IEEE INT S ROB.
   Samani H. A., 2010, P IEEE RSJ INT C INT.
   SAMANI HA, 2011, P 3 INT C HUM ROB PE, P118.
   Scheutz M., 2006, P 1 ACM INT C HUM RO, P226, DOI {[}10.1145/1121241.1121281, DOI 10.1145/1121241.1121281].
   Scheutz M., 2009, P IEEE INT C ROB AUT.
   Singer Irving, 2001, EXPLORATIONS LOVE SE.
   Snell J., 2005, PSYCHOL ED INTERDISC, V42, P49.
   Sullins JP, 2008, PHILOSOPHY AND DESIGN: FROM ENGINEERING TO ARCHITECTURE, P143, DOI 10.1007/978-1-4020-6591-0\_11.
   Turing A, 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433.
   Turkle S., 2011, ALONE TOGETHER WHY W.
   Wilks Y., 2010, CLOSE ENGAGEMENTS AR.}},
Number-of-Cited-References = {{42}},
Times-Cited = {{33}},
Usage-Count-Last-180-days = {{6}},
Usage-Count-Since-2013 = {{55}},
Journal-ISO = {{IEEE Trans. Affect. Comput.}},
Doc-Delivery-Number = {{207YX}},
Unique-ID = {{ISI:000323642000004}},
DA = {{2020-06-17}},
}

@article{ ISI:000370458200001,
Author = {Dennis, Louise and Fisher, Michael and Slavkovik, Marija and Webster,
   Matt},
Title = {{Formal verification of ethical choices in autonomous systems}},
Journal = {{ROBOTICS AND AUTONOMOUS SYSTEMS}},
Year = {{2016}},
Volume = {{77}},
Pages = {{1-14}},
Month = {{MAR}},
Abstract = {{Autonomous systems such as unmanned vehicles are beginning to operate
   within society. All participants in society are required to follow
   specific regulations and laws. An autonomous system cannot be an
   exception. Inevitably an autonomous system will find itself in a
   situation in which it needs to not only choose to obey a rule or not,
   but also make a complex ethical decision. However, there exists no
   obvious way to implement the human understanding of ethical behaviour in
   computers. Even if we enable autonomous systems to distinguish between
   more and less ethical alternatives, how can we be sure that they would
   choose right? We consider autonomous systems with a hybrid architecture
   in which the highest level of reasoning is executed by a rational (BDI)
   agent. For such a system, formal verification has been used successfully
   to prove that specific rules of behaviour are observed when making
   decisions. We propose a theoretical framework for ethical plan selection
   that can be formally verified. We implement a rational agent that
   incorporates a given ethical policy in its plan selection and show that
   we can formally verify that the agent chooses to execute, to the best of
   its beliefs, the most ethical available plan. (C) 2015 The Authors.
   Published by Elsevier B.V. This is an open access article under the CC
   BY license.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Dennis, L (Reprint Author), Univ Liverpool, Dept Comp Sci, Liverpool L69 3BX, Merseyside, England.
   Dennis, Louise; Fisher, Michael; Webster, Matt, Univ Liverpool, Dept Comp Sci, Liverpool L69 3BX, Merseyside, England.
   Slavkovik, Marija, Univ Bergen, Dept Informat Sci \& Media Studies, N-5020 Bergen, Norway.}},
DOI = {{10.1016/j.robot.2015.11.012}},
ISSN = {{0921-8890}},
EISSN = {{1872-793X}},
Keywords = {{Autonomous systems; Ethics; BDI programs; Formal verification}},
Keywords-Plus = {{MACHINE ETHICS; MODEL CHECKING; PRINCIPLES}},
Research-Areas = {{Automation \& Control Systems; Computer Science; Robotics}},
Web-of-Science-Categories  = {{Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics}},
Author-Email = {{L.A.Dennis@liverpool.ac.uk
   MFisher@liverpool.ac.uk
   Marija.Slavkovik@uib.no
   M.Webster@liverpool.ac.uk}},
ResearcherID-Numbers = {{Fisher, Michael/P-2111-2019
   }},
ORCID-Numbers = {{Fisher, Michael/0000-0002-0875-3862
   Dennis, Louise/0000-0003-1426-1896
   Slavkovik, Marija/0000-0003-2548-8623
   Webster, Matt/0000-0002-8817-6881}},
Funding-Acknowledgement = {{EPSRC through the ``Trustworthy Robotic Assistants{''} {[}EP/K006193/1];
   ``Verifiable Autonomy{''} {[}EP/L024845/1]; ``Reconfigurable
   Autonomy{''} projects {[}EP/J011770/1]; ERDF/NWDA-funded Virtual
   Engineering Centre; Engineering and Physical Sciences Research
   CouncilEngineering \& Physical Sciences Research Council (EPSRC)
   {[}EP/L024845/1, EP/F033567/1, EP/K006193/1, EP/J011770/1]}},
Funding-Text = {{Work was partially funded by EPSRC through the ``Trustworthy Robotic
   Assistants{''} (EP/K006193/1), ``Verifiable Autonomy{''} (EP/L024845/1),
   and ``Reconfigurable Autonomy{''} (EP/J011770/1) projects, and by the
   ERDF/NWDA-funded Virtual Engineering Centre.}},
Cited-References = {{Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4.
   ALUR R, 1995, THEOR COMPUT SCI, V138, P3, DOI 10.1016/0304-3975(94)00202-T.
   Anderson M., 2008, AAAI FALL S AI ELD N, P4.
   Anderson M, 2007, AI MAG, V28, P15.
   Anderson M, 2006, IEEE INTELL SYST, V21, P56, DOI 10.1109/MIS.2006.64.
   Anderson S. L., 2011, HUMAN ROBOT INTERACT.
   Arkin R., 2009, GITGVU0902 COLL COMP.
   Arkin RC, 2012, P IEEE, V100, P571, DOI 10.1109/JPROC.2011.2173265.
   Baier JA, 2008, AI MAG, V29, P25, DOI 10.1609/aimag.v29i4.2204.
   Beauchamp TL, 2009, PRINCIPLES BIOMEDICA.
   Bordini RH, 2005, MULTIAGENT PROGRAMMI.
   Brutzman D., 2013, P 18 INT S UNM UNTH.
   Chisholm Roderick M., 1963, ANALYSIS, V24, P33, DOI DOI 10.1093/ANALYS/24.2.33.
   Clarke E.M., 2001, HDB AUTOMATED REASON, VII, P1635.
   Coles A.J., 2010, P 20 INT C AUT PLANN.
   Damm W, 2007, LECT NOTES COMPUT SC, V4762, P425.
   Delgrande J, 2008, J ARTIF INTELL RES, V32, P757, DOI 10.1613/jair.2539.
   Deng B, 2015, NATURE, V523, P24, DOI 10.1038/523024a.
   Dennis L.A., 2008, P AISB WORKSH LOG SI.
   Dennis L. A., 2010, P 10 INT S ART INT R.
   Dennis L, 2008, LECT NOTES ARTIF INT, V5056, P137.
   Dennis LA, 2016, AUTOMAT SOFTW ENG, V23, P305, DOI 10.1007/s10515-014-0168-9.
   Dennis LA, 2012, AUTOMAT SOFTW ENG, V19, P5, DOI 10.1007/s10515-011-0088-x.
   Feldmann R., 2006, P 10 INT C KNOWL REP, P503.
   Fisher M, 2013, COMMUN ACM, V56, P84, DOI {[}10.1145/2494558, 10.1145/2500468.2494558].
   Goodall NJ, 2014, TRANSPORT RES REC, P58, DOI 10.3141/2424-07.
   GROSSI D, 2005, {[}No title captured], P1.
   Helmert M, 2006, J ARTIF INTELL RES, V26, P191, DOI 10.1613/jair.1705.
   Henzinger TA, 1996, IEEE S LOG, P278, DOI 10.1109/LICS.1996.561342.
   Hirose S, 1996, ROBOT AUTON SYST, V18, P101, DOI 10.1016/0921-8890(95)00074-7.
   Jeannin Jean-Baptiste, 2015, LECT NOTES COMPUTER, P21, DOI DOI 10.1007/978-3-662-46681-0.
   Lincoln N., 2010, P IFAC WORKSH AD LEA.
   McLaren BM, 2003, ARTIF INTELL, V150, P145, DOI 10.1016/S0004-3702(03)00135-8.
   McLaren BM, 2006, IEEE INTELL SYST, V21, P29, DOI 10.1109/MIS.2006.67.
   McNamara P., 2010, STANFORD ENCY PHILOS.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Platzer A., 2010, LOGICAL ANAL HYBRID.
   Rao A. S., 1995, ICMAS-95 Proceedings. First International Conference on Multi-Agent Systems, P312.
   RICHARDSON HS, 1990, PHILOS PUBLIC AFF, V19, P279.
   Robbins RW, 2007, DECIS SUPPORT SYST, V43, P1571, DOI 10.1016/j.dss.2006.03.003.
   SACERDOTI ED, 1974, ARTIF INTELL, V5, P115, DOI 10.1016/0004-3702(74)90026-5.
   Sardina S., 2003, P 2 INT JOINT C AUT, P417.
   Searle John R., 1995, CONSTRUCTION SOCIAL.
   Tulum K, 2009, AEROSP CONF PROC, P2971.
   Van Benthem J, 2014, THEORIA-SWED J PHILO, V80, P116, DOI 10.1111/theo.12028.
   VEATCH RM, 1995, KENNEDY INST ETHIC J, V5, P199.
   Vikhorev K., 2011, P 10 INT C AUT AG MU, P397.
   Visser S., P 22 INT JOINT C ART.
   Webster Matt, 2011, Computer Safety, Reliability, and Security. Proceedings 30th International Conference, SAFECOMP 2011, P228, DOI 10.1007/978-3-642-24270-0\_17.
   Webster M., 2014, SPACE SAF MAG, V9, P7.
   Webster M, 2014, J AEROSP INFORM SYST, V11, P258, DOI 10.2514/1.I010096.
   Winfield Alan F. T., 2014, Advances in Autonomous Robotics Systems. 15th Annual Conference (TAROS 2014). Proceedings: LNCS 8717, P85, DOI 10.1007/978-3-319-10401-0\_8.}},
Number-of-Cited-References = {{52}},
Times-Cited = {{31}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{29}},
Journal-ISO = {{Robot. Auton. Syst.}},
Doc-Delivery-Number = {{DE2LG}},
Unique-ID = {{ISI:000370458200001}},
OA = {{Other Gold}},
DA = {{2020-06-17}},
}

@article{ ISI:000280781400005,
Author = {Wallach, Wendell},
Title = {{Robot minds and human ethics: the need for a comprehensive model of
   moral decision making}},
Journal = {{ETHICS AND INFORMATION TECHNOLOGY}},
Year = {{2010}},
Volume = {{12}},
Number = {{3, SI}},
Pages = {{243-250}},
Month = {{SEP}},
Abstract = {{Building artificial moral agents (AMAs) underscores the fragmentary
   character of presently available models of human ethical behavior. It is
   a distinctly different enterprise from either the attempt by moral
   philosophers to illuminate the ``ought{''} of ethics or the research by
   cognitive scientists directed at revealing the mechanisms that influence
   moral psychology, and yet it draws on both. Philosophers and cognitive
   scientists have tended to stress the importance of particular cognitive
   mechanisms, e.g., reasoning, moral sentiments, heuristics, intuitions,
   or a moral grammar, in the making of moral decisions. However,
   assembling a system from the bottom-up which is capable of accommodating
   moral considerations draws attention to the importance of a much wider
   array of mechanisms in honing moral intelligence. Moral machines need
   not emulate human cognitive faculties in order to function
   satisfactorily in responding to morally significant situations. But
   working through methods for building AMAs will have a profound effect in
   deepening an appreciation for the many mechanisms that contribute to a
   moral acumen, and the manner in which these mechanisms work together.
   Building AMAs highlights the need for a comprehensive model of how
   humans arrive at satisfactory moral judgments.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wallach, W (Reprint Author), 7 Loeffler Rd, Bloomfield, CT 06002 USA.
   Wallach, Wendell, Yale Univ, Inst Social \& Policy Studies, Interdisciplinary Ctr Bioeth, New Haven, CT 06520 USA.}},
DOI = {{10.1007/s10676-010-9232-8}},
ISSN = {{1388-1957}},
EISSN = {{1572-8439}},
Keywords = {{Moral psychology; Moral agent; Machine ethics; Moral philosophy;
   Decision making; Moral judgment; Virtues; Computers; Emotions; Robots}},
Keywords-Plus = {{EVOLUTION}},
Research-Areas = {{Social Sciences - Other Topics; Information Science \& Library Science;
   Philosophy}},
Web-of-Science-Categories  = {{Ethics; Information Science \& Library Science; Philosophy}},
Author-Email = {{wendell.wallach@yale.edu}},
Cited-References = {{Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   ALLEN C, 2002, COGNITIVE EMOTIVE ET, V1.
   Anderson M, 2006, IEEE INTELL SYST, V21, P56, DOI 10.1109/MIS.2006.64.
   Anderson M, 2006, IEEE INTELL SYST, V21, P10, DOI 10.1109/MIS.2006.70.
   AXELROD R, 1981, SCIENCE, V211, P1390, DOI 10.1126/science.7466396.
   Bentham Jeremy, 2008, INTRO PRINCIPLES MOR.
   DANIELSON P, 1992, {[}No title captured].
   DARLEY JM, 1973, J PERS SOC PSYCHOL, V27, P100, DOI 10.1037/h0034449.
   DEWAAL F, 1996, {[}No title captured].
   Flack JC, 2000, J CONSCIOUSNESS STUD, V7, P1.
   Franklin S, 2003, J CONSCIOUSNESS STUD, V10, P47.
   Franklin S., 2006, IDPT 2006 P INT DES.
   GIGERENZER G, 2010, TOPICS IN PRESS.
   Greene JD, 2001, SCIENCE, V293, P2105, DOI 10.1126/science.1062872.
   GREENWALD AG, 1995, PSYCHOL REV, V102, P4, DOI 10.1037/0033-295X.102.1.4.
   Haidt J, 2001, PSYCHOL REV, V108, P814, DOI 10.1037//0033-295X.108.4.814.
   Haidt J, 2003, SER AFFECTIVE SCI, P852.
   HAMILTON WD, 1964, J THEOR BIOL, V7, P1, DOI 10.1016/0022-5193(64)90039-6.
   Hauser M. D., 2006, MORAL MINDS NATURE D.
   Hume David, 2009, TREATISE HUMAN NATUR.
   ISEN AM, 1972, J PERS SOC PSYCHOL, V21, P384, DOI 10.1037/h0032317.
   Kohlberg L., 1984, ESSAYS MORAL DEV, V2.
   Kohlberg L., 1981, ESSAYS MORAL DEV, V1.
   Lapsley D., 2004, MORAL DEV SELF IDENT.
   MIKHAIL JM, 2000, {[}No title captured].
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/0033-295X.101.2.343.
   MOORE G. E., 2008, PRINCIPIA ETHICA.
   Nucci L, 2008, EDUC PSYCHOL HANDB, pIX.
   Piaget J., 1972, JUDGMENT REASONING C.
   RAWLS J., 1999, THEORY JUSTICE.
   Sanfey AG, 2003, SCIENCE, V300, P1755, DOI 10.1126/science.1082976.
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038.
   Simon H., 1957, BEHAV MODEL RATIONAL.
   Simon H., 1982, MODELS BOUNDED RATIO, V1.
   Simon H., 1982, MODELS BOUNDED RATIO, V2.
   Singer Peter, 1990, ANIMAL LIBERATION.
   SMITH, 2004, THEORY MORAL SENTIME.
   TORRANCE S, 2008, ARTIF INTELL, V22, P34.
   TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124.
   Uleman J. S., 1989, UNINTENDED THOUGHT.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.
   WALLACH W, 2010, TOPICS IN PRESS.
   Wallach W, 2008, AI SOC, V22, P565, DOI 10.1007/s00146-007-0099-0.
   Wilson E.O., 1975, P1.
   YUDKOWSKY E, 2001, WHAT IS FRIENDLY AI.}},
Number-of-Cited-References = {{45}},
Times-Cited = {{30}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{84}},
Journal-ISO = {{Ethics Inf. Technol.}},
Doc-Delivery-Number = {{636YM}},
Unique-ID = {{ISI:000280781400005}},
DA = {{2020-06-17}},
}

@article{ ISI:000271751000007,
Author = {Tonkens, Ryan},
Title = {{A Challenge for Machine Ethics}},
Journal = {{MINDS AND MACHINES}},
Year = {{2009}},
Volume = {{19}},
Number = {{3}},
Pages = {{421-438}},
Month = {{AUG}},
Abstract = {{That the successful development of fully autonomous artificial moral
   agents (AMAs) is imminent is becoming the received view within
   artificial intelligence research and robotics. The discipline of
   Machines Ethics, whose mandate is to create such ethical robots, is
   consequently gaining momentum. Although it is often asked whether a
   given moral framework can be implemented into machines, it is never
   asked whether it should be. This paper articulates a pressing challenge
   for Machine Ethics: To identify an ethical framework that is both
   implementable into machines and whose tenets permit the creation of such
   AMAs in the first place. Without consistency between ethics and
   engineering, the resulting AMAs would not be genuine ethical robots, and
   hence the discipline of Machine Ethics would be a failure in this
   regard. Here this challenge is articulated through a critical analysis
   of the development of Kantian AMAs, as one of the leading contenders for
   being the ethic that can be implemented into machines. In the end,
   however, the development of Kantian artificial moral machines is found
   to be anti-Kantian. The upshot of all this is that machine ethicists
   need to look elsewhere for an ethic to implement into their machines.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Tonkens, R (Reprint Author), York Univ, Toronto, ON M3J 2R7, Canada.
   York Univ, Toronto, ON M3J 2R7, Canada.}},
DOI = {{10.1007/s11023-009-9159-1}},
ISSN = {{0924-6495}},
Keywords = {{Machine Ethics; Artificial moral agents; Kantian morality; Ethical
   consistency}},
Keywords-Plus = {{ROBOTS}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{tonkens@yorku.ca}},
Cited-References = {{Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4.
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83.
   Anderson M, 2007, MIND MACH, V17, P1, DOI 10.1007/s11023-007-9053-7.
   Anderson M, 2006, IEEE INTELL SYST, V21, P10, DOI 10.1109/MIS.2006.70.
   Andersoni DF, 2007, J PSYCHOSOM OBST GYN, V28, P26.
   BODEN M, 1994, {[}No title captured].
   BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M.
   Calverley DJ, 2008, AI SOC, V22, P523, DOI 10.1007/s00146-007-0092-7.
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   GIPS J, 2005, CREATING ETHICAL ROB.
   Gips J, 1995, ANDROID EPISTEMOLOGY, P243.
   Grau C, 2006, IEEE INTELL SYST, V21, P52, DOI 10.1109/MIS.2006.81.
   Guarini M, 2006, IEEE INTELL SYST, V21, P22, DOI 10.1109/MIS.2006.76.
   Johnson D. G., 2006, Ethics and Information Technology, V8, P195, DOI 10.1007/s10676-006-9111-5.
   Kant I, 1785, FUNDAMENTAL PRINCIPL.
   Kant Immanuel, 1797, METAPHYSICS MORALS.
   Kant Immanuel, 1997, LECT ETHICS.
   McCarthy J, 2000, J EXP THEOR ARTIF IN, V12, P341, DOI 10.1080/09528130050111473.
   McLaren BM, 2006, IEEE INTELL SYST, V21, P29, DOI 10.1109/MIS.2006.67.
   MILL JS, 1871, {[}No title captured].
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Nadeau JE, 2006, THINKING ANDROID EPI, P241.
   ONEILL O, 1989, {[}No title captured].
   Picard R. W., 1997, AFFECTIVE COMPUTING.
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77.
   Rawls J., 2000, LECT HIST MORAL PHIL.
   Sparrow R., 2007, J APPL PHILOS, V24, P62, DOI DOI 10.1111/J.1468-5930.2007.00346.X.
   Torrance S, 2008, AI SOC, V22, P495, DOI 10.1007/s00146-007-0091-8.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.
   Wallach W, 2008, AI SOC, V22, P565, DOI 10.1007/s00146-007-0099-0.
   2006, US ARMY FUTURE COMBA.}},
Number-of-Cited-References = {{32}},
Times-Cited = {{27}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{75}},
Journal-ISO = {{Minds Mach.}},
Doc-Delivery-Number = {{519FS}},
Unique-ID = {{ISI:000271751000007}},
DA = {{2020-06-17}},
}

@article{ ISI:000301566800007,
Author = {Crnkovic, Gordana Dodig and Curuklu, Baran},
Title = {{Robots: ethical by design}},
Journal = {{ETHICS AND INFORMATION TECHNOLOGY}},
Year = {{2012}},
Volume = {{14}},
Number = {{1, SI}},
Pages = {{61-71}},
Month = {{MAR}},
Abstract = {{Among ethicists and engineers within robotics there is an ongoing
   discussion as to whether ethical robots are possible or even desirable.
   We answer both of these questions in the positive, based on an extensive
   literature study of existing arguments. Our contribution consists in
   bringing together and reinterpreting pieces of information from a
   variety of sources. One of the conclusions drawn is that artifactual
   morality must come in degrees and depend on the level of agency,
   autonomy and intelligence of the machine. Moral concerns for agents such
   as intelligent search machines are relatively simple, while highly
   intelligent and autonomous artifacts with significant impact and complex
   modes of agency must be equipped with more advanced ethical
   capabilities. Systems like cognitive robots are being developed that are
   expected to become part of our everyday lives in future decades. Thus,
   it is necessary to ensure that their behaviour is adequate. In an
   analogy with artificial intelligence, which is the ability of a machine
   to perform activities that would require intelligence in humans,
   artificial morality is considered to be the ability of a machine to
   perform activities that would require morality in humans. The capacity
   for artificial (artifactual) morality, such as artifactual agency,
   artifactual responsibility, artificial intentions, artificial
   (synthetic) emotions, etc., come in varying degrees and depend on the
   type of agent. As an illustration, we address the assurance of safety in
   modern High Reliability Organizations through responsibility
   distribution. In the same way that the concept of agency is generalized
   in the case of artificial agents, the concept of moral agency, including
   responsibility, is generalized too. We propose to look at artificial
   moral agents as having functional responsibilities within a network of
   distributed responsibilities in a socio-technological system. This does
   not take away the responsibilities of the other stakeholders in the
   system, but facilitates an understanding and regulation of such
   networks. It should be pointed out that the process of development must
   assume an evolutionary form with a number of iterations because the
   emergent properties of artifacts must be tested in real world situations
   with agents of increasing intelligence and moral competence. We see this
   paper as a contribution to the macro-level Requirement Engineering
   through discussion and analysis of general requirements for design of
   ethical robots.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Crnkovic, GD (Reprint Author), Malardalen Univ, Comp Sci Lab, Sch Innovat Design \& Engn, Vasteras, Sweden.
   Crnkovic, Gordana Dodig, Malardalen Univ, Comp Sci Lab, Sch Innovat Design \& Engn, Vasteras, Sweden.
   Curuklu, Baran, Malardalen Univ, Computat Percept Lab, Sch Innovat Design \& Engn, Vasteras, Sweden.}},
DOI = {{10.1007/s10676-011-9278-2}},
ISSN = {{1388-1957}},
EISSN = {{1572-8439}},
Keywords = {{Artificial morality; Machine ethics; Machine morality; Roboethics;
   Autonomous agents; Artifactual responsibility; Functional responsibility}},
Keywords-Plus = {{INFORMATION; AGENTS}},
Research-Areas = {{Social Sciences - Other Topics; Information Science \& Library Science;
   Philosophy}},
Web-of-Science-Categories  = {{Ethics; Information Science \& Library Science; Philosophy}},
Author-Email = {{gordana.dodig-crnkovic@mdh.se
   baran.curuklu@mdh.se}},
ORCID-Numbers = {{Dodig-Crnkovic, Gordana/0000-0001-9881-400X}},
Cited-References = {{Abney K., 2009, ETHICS ROBOTICS.
   Adam A., 2005, Ethics and Information Technology, V7, P233, DOI 10.1007/s10676-006-0013-3.
   Adam Alison, 2008, Ethics and Information Technology, V10, P149, DOI 10.1007/s10676-008-9169-3.
   Akan B, 2010, ACMIEEE INT CONF HUM, P71, DOI 10.1109/HRI.2010.5453264.
   Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4.
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83.
   Anderson M, 2007, AI MAG, V28, P15.
   Arkin R. C., 1998, BEHAV BASED ROBOTICS.
   Asaro Peter, 2007, P IEEE 2007 INT C RO.
   Aurum A, 2003, INFORM SOFTWARE TECH, V45, P945, DOI 10.1016/S0950-5849(03)00096-X.
   Beavers AF, 2012, INTELL ROBOT AUTON, P333.
   Becker B, 2006, INT REV INF ETHICS, V6, P37.
   Brey P, 2008, PHILOSOPHY AND DESIGN: FROM ENGINEERING TO ARCHITECTURE, P61, DOI 10.1007/978-1-4020-6591-0\_5.
   Bynum T. W., 2004, COMPUTER ETHICS PROF, P98.
   Capurro R., 2009, ETHICS ROBOTICS.
   Clark A., 2003, NATURAL BORN CYBORGS.
   Coeckelbergh M., 2010, ETHICS INFORM TECHNO.
   Coeckelbergh M, 2009, AI SOC, V24, P181, DOI 10.1007/s00146-009-0208-3.
   Coleman K. G., 2008, STANFORD ENCY PHILOS.
   Crutzen CKM, 2006, INT REV INF ETHICS, V6, P52.
   Curuklu B, 2010, ACMIEEE INT CONF HUM, P85, DOI 10.1109/HRI.2010.5453259.
   DANIELSON P, 1992, {[}No title captured].
   Davidson M, 2011, SPINE, V36, pE307, DOI 10.1097/BRS.0b013e3181f3a007.
   Dennett D. C., 1994, THINKING COMPUTERS V, P91.
   Dennett D. D., 1973, ESSAYS FREEDOM ACTIO.
   Dodig-Crnkovic G., 2008, 10 SCAND C ART INT S, V173.
   Dodig-Crnkovic G., 2005, COMPUTING PHILOS.
   Dodig-Crnkovic G., 1999, ABB ATOMS CRITICALIT.
   Dodig-Crnkovic G., 2006, P 9 SCAND C ART INT.
   EDGAR SL, 1997, MORALITY MACHINES PE.
   Eshleman A, 2009, STANFORD ENCY PHILOS.
   Fellous J-M, 2005, WHO NEEDS EMOTIONS B.
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   Floridi L., 2007, CEPE 2007 SAN DIEG.
   Gates B, 2007, SCI AM, V296, P44, DOI 10.1038/scientificamerican0107-58.
   Grodzinsky FS, 2011, ETHICS INF TECHNOL, V13, P17, DOI 10.1007/s10676-010-9255-1.
   Grodzinsky Frances S, 2008, Ethics and Information Technology, V10, P27, DOI 10.1007/s10676-008-9163-9.
   Hansson SO, 1999, HUM ECOL RISK ASSESS, V5, P909, DOI 10.1080/10807039991289194.
   HANSSON SO, 1997, {[}No title captured], V2, P293.
   Huff C., 2010, WHY SOCIOTECHNICAL S.
   Huff C., 2004, COMPUTER ETHICS PROF, P98.
   Jarvik M., 2003, UNDERSTAND MORAL RES, P147.
   JOHNSON D, 1994, {[}No title captured].
   Johnson D. G., 2006, Applied Computing 2006. 21st Annual ACM Symposium on Applied Computing, P272.
   Johnson D. G., 2005, Ethics and Information Technology, V7, P99, DOI 10.1007/s10676-005-4585-0.
   Johnson D. G., 2006, Ethics and Information Technology, V8, P195, DOI 10.1007/s10676-006-9111-5.
   LARSSON M, 2004, {[}No title captured].
   Latour Bruno., 1992, SHAPING TECHNOLOGY B, P225.
   Levy D, 2006, ROBOTS UNLIMITED LIF.
   Lin P, 2008, AUTONOMOUS MILITARY.
   Magnani L., 2007, 4 INT C HUM BEING CO.
   Marino D, 2006, INT REV INF ETHICS, V6, P46.
   Matthias A., 2004, Ethics and Information Technology, V6, P175, DOI 10.1007/s10676-004-3422-1.
   Mckenna M., 2009, STANFORD ENCY PHILOS.
   Miller KW, 2011, IT PROF, V13, P57, DOI 10.1109/MITP.2011.46.
   MINSKY ML, 2006, {[}No title captured].
   Mitcham C., 1995, SCI ENG ETHICS, V1, P113.
   MONTAGUE P, 1998, RACHELS ENV HLTH WEE.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   MOOR JH, 1985, METAPHILOSOPHY, V16, P266, DOI 10.1111/j.1467-9973.1985.tb00173.x.
   Moravec Hans P, 1999, ROBOT MERE MACHINE T.
   Nagenborg M, 2007, INT REV INF ETHICS, V7, P129.
   NISSENBAUM H, 1994, COMMUN ACM, V37, P72, DOI 10.1145/175222.175228.
   Nobre F. S., 2009, IGI GLOBAL, P1, DOI {[}10.4018/978-1-60566-302-9, DOI 10.4018/978-1-60566-302-9].
   Nof S., 1999, HDB IND ROBOTICS.
   Nuseibeh B., 2000, P INT C SOFTW ENG IC, P4.
   Philip Brey, 2006, ETHICS INF TECHNOL, V7, P157, DOI DOI 10.1007/S10676-006-0005-3.
   Pimple KD, 2011, COMMUN ACM, V54, P29, DOI 10.1145/1897852.1897864.
   Russell S, 2003, ARTIFICIAL INTELLIGE.
   Scheutz Matthias, 2002, COMPUTATIONALISM NEW, P1.
   Shrader-Frechette K., 2003, PHILOS TECHNOLOGY TE, P187.
   Silver D, 2005, AM PHILOS QUART, V42, P279.
   Siponen M, 2004, ETHICS INF TECHNOL, V6, P279, DOI 10.1007/s10676-005-6710-5.
   Som C, 2004, HUM ECOL RISK ASSESS, V10, P787, DOI 10.1080/10807030490513801.
   Sommerville I., 2007, RESPONSIBILITY DEPEN.
   Stahl BC, 2004, MIND MACH, V14, P67.
   STRAWSON P, 1974, {[}No title captured].
   Sullins JP, 2006, INT REV INF ETHICS, V6, P23.
   Vallverdu J., 2009, IGI GLOBAL, DOI {[}10.4018/978-1-60566-354-8, DOI 10.4018/978-1-60566-354-8].
   van de Poel I, 2006, SCI TECHNOL HUM VAL, V31, P223, DOI 10.1177/0162243905285838.
   Verbeek PP, 2008, PHILOSOPHY AND DESIGN: FROM ENGINEERING TO ARCHITECTURE, P91, DOI 10.1007/978-1-4020-6591-0\_7.
   Veruggio G., 2008, SPRINGER HDB ROBOTIC.
   Veruggio G., 2006, EURON ROB ROADM HUM.
   Wallach C., 2009, MORAL MACHINES TEACH.
   Warwick K., 2009, TIMES LONDON    0225.}},
Number-of-Cited-References = {{86}},
Times-Cited = {{26}},
Usage-Count-Last-180-days = {{7}},
Usage-Count-Since-2013 = {{120}},
Journal-ISO = {{Ethics Inf. Technol.}},
Doc-Delivery-Number = {{909LU}},
Unique-ID = {{ISI:000301566800007}},
DA = {{2020-06-17}},
}

@article{ ISI:000349301500032,
Author = {Sotala, Kaj and Yampolskiy, Roman V.},
Title = {{Responses to catastrophic AGI risk: a survey}},
Journal = {{PHYSICA SCRIPTA}},
Year = {{2015}},
Volume = {{90}},
Number = {{1}},
Month = {{JAN}},
Abstract = {{Many researchers have argued that humanity will create artificial
   general intelligence (AGI) within the next twenty to one hundred years.
   It has been suggested that AGI may inflict serious damage to human
   well-being on a global scale ('catastrophic risk'). After summarizing
   the arguments for why AGI may pose such a risk, we review the field's
   proposed responses to AGI risk. We consider societal proposals,
   proposals for external constraints on AGI behaviors and proposals for
   creating AGIs that are safe due to their internal design.}},
Publisher = {{IOP PUBLISHING LTD}},
Address = {{TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Sotala, K (Reprint Author), Machine Intelligence Res Inst, Berkeley, CA 94704 USA.
   Sotala, Kaj, Machine Intelligence Res Inst, Berkeley, CA 94704 USA.
   Yampolskiy, Roman V., Univ Louisville, Louisville, KY 40292 USA.}},
DOI = {{10.1088/0031-8949/90/1/018001}},
Article-Number = {{018001}},
ISSN = {{0031-8949}},
EISSN = {{1402-4896}},
Keywords = {{artificial general intelligence; existential risk; catastrophic risk; AI
   risk; artificial intelligence; friendly AI; machine ethics}},
Keywords-Plus = {{ARTIFICIAL-INTELLIGENCE; MORAL MACHINES; SINGULARITY; FUTURE; MODELS;
   LAWS; ROBOTICS; IMPACT; ASIMOV; ETHICS}},
Research-Areas = {{Physics}},
Web-of-Science-Categories  = {{Physics, Multidisciplinary}},
ORCID-Numbers = {{Sotala, Kaj/0000-0003-2140-826X}},
Cited-References = {{Adams SS, 2012, AI MAG, V33, P25, DOI 10.1609/aimag.v33i1.2322.
   Agar N, 2011, J EVOLUTION TECHNOL, V22, P23.
   Agliata D, 2004, J SOC CLIN PSYCHOL, V23, P7, DOI 10.1521/jscp.23.1.7.26988.
   Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4.
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83.
   Allen C, 2012, INTELL ROBOT AUTON, P55.
   Amdahl G. M., 1967, P APR 18 20 1967 SPR, P483, DOI DOI 10.1145/1465482.1465560.
   Anderson M, 2005, FS0502, P9.
   Anderson M, 2010, PROBLEM SOLVED H MAG.
   Anderson M., 2011, MACHINE ETHICS.
   Anderson M, 2005, FUS ENG 21 IEEE NPS, P1.
   Anderson M, 2005, FS0506.
   Anderson M, 2006, IEEE INTELL SYST, V21, P56, DOI 10.1109/MIS.2006.64.
   Anderson SL, 2011, MACHINE ETHICS, P285.
   Annas GJ, 2002, AM J LAW MED, V28, P151.
   Armstrong S., 2010, UTILITY INDIFFERENCE.
   Armstrong S, 2007, CHAINING GOD.
   Armstrong S, 2012, BEYOND AI: ARTIFICIAL DREAMS, P52.
   Armstrong S, 2012, MIND MACH, V22, P299, DOI 10.1007/s11023-012-9282-2.
   Asaro P M, P IEEE C ROB AUT WOR, P59.
   Ashley K. D., 1995, Case-Based Reasoning Research and Development. First International Conference, ICCBR-95. Proceedings, P133.
   Asimov Isaac, 1942, ASTOUNDING SCI FICTI, P94.
   Axelrod R, 1987, GENETIC ALGORITHMS S, P32.
   Baars BJ, 2005, PROG BRAIN RES, V150, P45, DOI 10.1016/S0079-6123(05)50004-9.
   Baars BJ, 2002, TRENDS COGN SCI, V6, P47, DOI 10.1016/S1364-6613(00)01819-2.
   Bach J, 2012, LECT NOTES ARTIFICIA, V7716.
   Bamford S, 2012, INT J MACHINE CONSCI, V4, P23, DOI DOI 10.1142/S1793843012400021.
   Baum SD, 2011, TECHNOL FORECAST SOC, V78, P185, DOI 10.1016/j.techfore.2010.09.006.
   Beavers A F, 2009, 18 ANN M ASS PRACT P.
   Beavers AF, 2012, INTELL ROBOT AUTON, P333.
   Bello P, 2013, TOPOI-INT REV PHILOS, V32, P251, DOI 10.1007/s11245-012-9129-8.
   Benatar D., 2006, BETTER NEVER HAVE BE.
   Berglas A, 2012, ARTIFICIAL INTELLIGE.
   Blackmore S, 2012, J CONSCIOUSNESS STUD, V19, P16.
   Bostrom N., 2008, GLOBAL CATASTROPHIC.
   Bostrom N, 2003, COGNITIVE EMOTIVE ET, V2, P12.
   Bostrom N, 2002, J EVOLUTION TECHNOL, V9.
   Bostrom N., 1998, INT J FUTURES STUDIE, V2.
   Bostrom N, 2007, NANOSCALE ISSUES PER, V1, P129, DOI 10.1002/9780470165874.ch10.
   Bostrom N, 2011, GLOBAL CATASTROPHIC, P1.
   Bostrom N., 2014, SUPERINTELLIGENCE PA.
   Bostrom N., 2004, DEATH ANTIDEATH 200, P339.
   Bostrom N, 2014, CAMBRIDGE HANDBOOK OF ARTIFICIAL INTELLIGENCE, P316.
   Bostrom N, 2012, MIND MACH, V22, P71, DOI 10.1007/s11023-012-9281-3.
   Brain M, 2003, ROBOTIC NATION.
   Brandt R. B., 1979, THEORY GOOD RIGHT.
   Branwen G, SLOWING MOORES LAW.
   BRIN D, 1998, {[}No title captured].
   Bringsjord S, 2012, SINGULARITY HYPOTHES.
   Brooks R, 2008, IEEE SPECTRUM, V45, P68, DOI 10.1109/MSPEC.2008.4531466.
   Brynjolfsson E., 2011, RACE MACHINE.
   Bryson J, 1998, JUST ANOTHER ARTEFAC.
   Bryson J J, 2010, ROBOTS SHOULD BE SLA, P107.
   Bugaj S V, 2007, DYNAMICAL PSYCHOL.
   Butler S., 1863, PRESS.
   Cade C M, 1966, OTHER WORLDS OURS.
   Calandrino J A, 2011, P 20 USENIX SEC S SA, P267.
   Cassimatis N, 2006, AI MAG, V27, P12.
   Casti J L, 2012, XEVENTS.
   Cattell R, CHALLENGES BRAIN EMU.
   Chalmers D J, 1996, CONSCIOUS MIND PHILO.
   Chalmers DJ, 2010, J CONSCIOUSNESS STUD, V17, P7.
   Clark G, 2007, PRINC ECON HIST W WO.
   CLARKE R, 1994, COMPUTER, V27, P57, DOI 10.1109/2.248881.
   CLARKE R, 1993, COMPUTER, V26, P53, DOI 10.1109/2.247652.
   Cloos C, 2005, MACHINE ETHICS, P38.
   Commodity Futures Trading Commission and Securities and Exchange Commission, 2010, FIND REG MARK EV MAY.
   Dahm W J A, 2010, TECHNOLOGY HORIZONS.
   Daley W, 2011, SYNTHESE, V2, P44.
   Davis E, 2013, SINGULARITY STATE AR.
   Dayan P, 2012, NEUROSCIENCE OF PREFERENCE AND CHOICE: COGNITIVE AND NEURAL MECHANISMS, P33, DOI 10.1016/B978-0-12-381431-9.00002-4.
   de Garis Hugo, 2005, ARTILECT WAR COSMIST.
   Degabriele JP, 2011, IEEE SECUR PRIV, V9, P33, DOI 10.1109/MSP.2010.200.
   DENNETT D, 1987, {[}No title captured], P41.
   Dennett DC, 2012, J CONSCIOUSNESS STUD, V19, P86.
   Deutsch D., 2011, BEGINNING INFINITY.
   Dewey Daniel, 2011, Artificial General Intelligence. Proceedings 4th International Conference, AGI 2011, P309, DOI 10.1007/978-3-642-22887-2\_35.
   Diana F, 2003, LECT NOTES COMPUTER, V2699, P257.
   Dietrich E, 2014, PHILOS NOW.
   Docherty B, 2012, LOSING HUMANITY.
   Douglas Thomas, 2008, J Appl Philos, V25, P228, DOI 10.1111/j.1468-5930.2008.00412.x.
   Drexler K E, 1986, ENGINES CREATION.
   Eckersley Peter, 2013, Journal of Artificial General Intelligence, V4, P170, DOI 10.2478/jagi-2013-0011.
   Eden A. H., 2012, SINGULARITY HYPOTHES.
   Eisen M, 2011, IT IS NOT JUNK.
   Felten E. W, 2000, P 7 ACM C COMP COMM, P25, DOI DOI 10.1145/352600.352606.
   Ferguson M J, 2007, HDB MOTIVATION SCI, P150.
   Fox J, 2010, 8 EUR C COMP PHIL MU.
   Frankfurt H. G., 1971, J PHILOS, V68, P5, DOI DOI 10.2307/2024717.
   Franklin S, 2006, IDPT 2006 P SAN DIEG.
   Freeman T, 2008, COMP ADVANTAGE DOESN.
   Freeman T, 2009, USING COMPASSION RES.
   FRIEDMAN B, 1992, J SYST SOFTWARE, V17, P7, DOI 10.1016/0164-1212(92)90075-U.
   GEWIRTH A, 1978, {[}No title captured].
   Gips J, 1995, ANDROID EPISTEMOLOGY, P243.
   Goertzel B, 2010, MULTIVERSE ACCORDING.
   Goertzel B, 2012, COGPRIME.
   Goertzel B, 2012, J EVOLUTION TECHNOLO, V1, P116.
   Goertzel B, 2006, APPARENT LIMITATIONS.
   Goertzel B, 2002, DYNAMICAL PSYCHOL.
   Goertzel B., 2004, DYNAMICAL PSYCHOL.
   Goertzel B, 2012, INT J MACHINE CONSCI, V4, P177, DOI DOI 10.1142/S1793843012400094.
   Goertzel B, 2010, GOLEM.
   Goertzel B, 2012, J CONSCIOUSNESS STUD, V19, P96.
   Goertzel B, 2008, FRONT ARTIF INTEL AP, V171, P448.
   Golle P, 2009, LECT NOTES COMPUT SC, V5538, P390, DOI 10.1007/978-3-642-01516-8\_26.
   Good I. J., 1965, ADV COMPUT, V6, P31, DOI DOI 10.1016/S0065-2458(08)60418-0.
   Good I J, 1982, MACH INTELL, V10, P555.
   GOOD IJ, 1970, INT J ENVIRON STUD, V1, P67, DOI 10.1080/00207237008709398.
   Grau C, 2006, IEEE INTELL SYST, V21, P52, DOI 10.1109/MIS.2006.81.
   Groesz LM, 2002, INT J EAT DISORDER, V31, P1, DOI 10.1002/eat.10005.
   Guarini M, 2006, IEEE INTELL SYST, V21, P22, DOI 10.1109/MIS.2006.76.
   Gubrud M V, 1997, NANOTECHNOLOGY INT S.
   Gunkel D, 2012, MACHINE QUESTION.
   Guterl F, 2012, FATE SPECIES.
   Haidt J., 2006, HAPPINESS HYPOTHESIS.
   Hall J S, 2007, BEYOND AI.
   Hall J S, 2007, NANOETHICS, P339.
   Hall J S, MACHINE ETHICS, P512.
   Hall JS, 2008, FR ART INT, V171, P460.
   Hallevy G, 2010, CRIMINAL LAIBILITY A.
   Hanson R, 2009, OVERCOMING BIAS.
   Hanson R, 1998, EC GROWTH GIVEN MACH.
   Hanson R, 1994, EXTROPY, V6.
   Hanson R, 2008, IEEE SPECTRUM, V45, P44, DOI 10.1109/MSPEC.2008.4531461.
   Hanson R, 2012, J CONSCIOUSNESS STUD, V19, P119.
   Hanson Robin, 2007, SHALL WE VOTE VALUES.
   Hare RD, 2000, BEHAV SCI LAW, V18, P623, DOI 10.1002/1099-0798(200010)18:5<623::AID-BSL409>3.0.CO;2-W.
   Harris G. T., 2006, HDB PSYCHOPATHY, P555.
   Hart DA, 2008, OPENCOG SOFTWARE FRA.
   Hauskeller M, 2012, INT J MACHINE CONSCI, V4, P187, DOI DOI 10.1142/S1793843012400100.
   Hayworth K. J., 2012, INT J MACH CONSCIOUS, V04, P87, DOI {[}10.1142/s1793843012400057, DOI 10.1142/S1793843012400057].
   Heylighen F, 2012, J CONSCIOUSNESS STUD, V19, P126.
   Heylighen F, 2008, RETHINK GLOB, V10, P284.
   Hibbard B, 2012, ERROR MY 2001 VISFIL.
   Hibbard B, 2001, ACM SIGGRAPH COMPUTE, V35, P13.
   Hibbard B, 2012, J ARTIFICIAL GEN INT, V3, P1, DOI DOI 10.2478/V10229-011-0013-5.
   Hibbard B, 2005, CRITIQUE SIAI COLLEC.
   Hibbard B, 2012, LECT NOTES ARTIF INT, V7716, P117.
   Hibbard B., 2012, LECT NOTES ARTIF INT, V7716, P107.
   Hibbard B, 2005, ETHICS POLITICS SUPE.
   Hibbard B, 2008, FRONT ARTIF INTEL AP, V171, P473.
   Hollerbach J M, 2009, ROADMAP US ROBOTICS.
   Hopkins P. D., 2012, INT J MACHINE CONSCI, V4, P229, DOI DOI 10.1142/S1793843012400136.
   Horvitz E J, 2009, INTERIM REPORT AAAI.
   Hughes J, 2001, RELINQUISHMENT REGUL.
   Hutter M, 2012, J CONSCIOUSNESS STUD, V19, P143.
   IEEE Spectrum, 2008, SING SPEC REP.
   Jenkins A, 2003, FUTURES, V35, P779, DOI 10.1016/S0016-3287(03)00029-6.
   Joy B, 2000, WIRED.
   Joyce R., 2001, MYTH MORALITY.
   Karnofsky H, 2011, KARNOFSKY TALLINN DI.
   Karnofsky H, 2012, LESS WRONG.
   KIPNIS D, 1972, J PERS SOC PSYCHOL, V24, P33, DOI 10.1037/h0033390.
   Koene R A, 2012, SINGULARITY HYPOTHES.
   Koene R A, 2012, INT J MACHINE CONSCI, V4, P35, DOI DOI 10.1142/S1793843012400033.
   Kornai A, 2014, J EXP THEOR ARTIF IN, V26, P417, DOI 10.1080/0952813X.2014.895109.
   Kringelbach M L, 2009, PLEASURES BRAIN SERI.
   Kurzweil R, 2001, RESPONSE STEPHEN HAW.
   Kurzweil R, 2002, LOCKED HIS CHINESE R.
   Kurzweil R., 2005, SINGULARITY IS NEAR.
   LAMPSON BW, 1973, COMMUN ACM, V16, P613, DOI 10.1145/362375.362389.
   Legg S, 2007, FRONTIERS ARTIFICIAL, V157, P17, DOI DOI 10.1007/978-3-642-44958-1\_.
   Legg S, 2009, FUNDING SAFE AGI VET.
   LEHMANWILZIG SN, 1981, FUTURES, V13, P442, DOI 10.1016/0016-3287(81)90100-2.
   Levy D, 2009, INT J SOC ROBOT, V1, P209, DOI 10.1007/s12369-009-0022-6.
   Lewis J. R., 2004, OXFORD HDB NEW RELIG, P243, DOI DOI 10.1093/OXFORDHB/9780195369649.003.0012.
   Loosemore R, 2012, SINGULARITY HYPOTHES.
   Macedo S, 2006, PRIMATES AND PHILOSOPHERS: HOW MORALITY EVOLVED, P1.
   Mainzer K, 2010, ECAP10 8 EUR C COMP.
   Mann S., 2003, SURVEILLANCE SOC, V1, P331, DOI DOI 10.24908/SS.V1I3.3344.
   Marmor Andrei, 1989, P ARISTOTELIAN SOC S, V63, p{[}113, 68].
   McCauley Lee, 2007, Ethics and Information Technology, V9, P153, DOI 10.1007/s10676-007-9138-2.
   McCulloch W.S., 1956, ACTA BIOTHEOR, V11, P147, DOI {[}10.1007/BF01557008, DOI 10.1007/BF01557008].
   McDermott D, 2012, J CONSCIOUSNESS STUD, V19, P167.
   McGinnis JO, 2010, NORTHWEST U LAW REV, V104, P1253.
   MCKIBBEN B, 2003, {[}No title captured].
   McLaren BM, 2003, ARTIF INTELL, V150, P145, DOI 10.1016/S0004-3702(03)00135-8.
   McLaren BM, 2006, IEEE INTELL SYST, V21, P29, DOI 10.1109/MIS.2006.67.
   McLeod P., 1998, INTRO CONNECTIONIST.
   Meuer H Hans, 2012, TOP500 LIST NOV 2012.
   Miller J D, 2012, SINGULARITY RISING.
   Minsky M, 2004, AI MAG, V25, P113.
   Moore D., 2003, IEEE Security \& Privacy, V1, P33, DOI 10.1109/MSECP.2003.1219056.
   Moore D, 2002, IMW 2002: PROCEEDINGS OF THE SECOND INTERNET MEASUREMENT WORKSHOP, P273.
   Moravec H., 1988, MIND CHILDREN.
   Moravec H, 1999, ROBOT.
   Moravec H P, 1992, PIGS CYBERSPACE.
   Moravec H P, 1998, J EVOLUTION TECHNOL, V1.
   Moskowitz GB, 2004, ADV EXP SOC PSYCHOL, V36, P317, DOI 10.1016/S0065-2601(04)36006-5.
   Muehlhauser L, 2012, LESS WRONG.
   Muehlhauser L., 2012, SINGULARITY HYPOTHES.
   Murphy RR, 2009, IEEE INTELL SYST, V24, P14, DOI 10.1109/MIS.2009.69.
   Napier W, 2011, GLOBAL CATASTROPHIC, P222.
   Narayanan A, 2009, ANONYMIZING SOCIAL N.
   Narayanan A, 2008, P IEEE S SECUR PRIV, P111, DOI 10.1109/SP.2008.33.
   Narayanan A, 2012, P IEEE S SECUR PRIV, P300, DOI 10.1109/SP.2012.46.
   Narayanan A, 2009, P IEEE S SECUR PRIV, P173, DOI 10.1109/SP.2009.22.
   Nielsen TD, 2004, ARTIF INTELL, V160, P53, DOI 10.1016/j.artint.2004.08.003.
   Nordmann A, 2008, IEEE SPECTRUM.
   Nordmann A., 2007, NANOETHICS, V1, P31, DOI DOI 10.1007/S11569-007-0007-6.
   Olson M., 1982, RISE DECLINE NATIONS.
   Omohundro S M, 2012, SINGULARITY HYPOTHES.
   Omohundro S M, 2007, NATURE SELF IMPROVIN.
   Omohundro SM, 2008, FRONT ARTIF INTEL AP, V171, P483.
   Orseau Laurent, 2011, Artificial General Intelligence. Proceedings 4th International Conference, AGI 2011, P1, DOI 10.1007/978-3-642-22887-2\_1.
   Paul F, 2012, ORDINARY IDEAS.
   Persson I., 2008, J APPL PHILOS, V25, P163, DOI DOI 10.1111/j.1468-5930.2008.00410.x.
   Persson I, 2012, UNFIT FUTURE.
   Peterson NR, 2010, RESTOR NEUROL NEUROS, V28, P237, DOI 10.3233/RNN-2010-0535.
   Pinker Steven, 2002, BLANK SLATE.
   Plaut DC, 2003, MIND, BRAIN, AND LANGUAGE: MULTIDISCIPLINARY PERSPECTIVES, P143.
   POSNER R, 2004, CATASTROPHE.
   Potapov A, UNIVERSAL EMPATHY ET.
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77.
   Powers TM, 2011, IEEE ROBOT AUTOM MAG, V18, P51, DOI 10.1109/MRA.2010.940152.
   PYLYSHYN Z, 1987, {[}No title captured].
   Pynadath DV, 2002, LECT NOTES ARTIF INT, V2333, P307.
   RAILTON P, 1986, PHILOS TOPICS, V14, P5, DOI 10.5840/philtopics19861421.
   Rajab M A, 2007, P 1 WORKSH HOT TOP U.
   Ramamurthy U, 2006, P 7 INT C COGN MOD, P244.
   Reynolds C, 2009, AP CAP 2009.
   Ring Mark, 2011, Artificial General Intelligence. Proceedings 4th International Conference, AGI 2011, P11, DOI 10.1007/978-3-642-22887-2\_2.
   Ronald C, 2009, GOVERNING LETHAL BEH.
   Salekin R T, 2010, TREATMENT CHILD ADOL, P343.
   Sandberg A, 2009, OVERVIEW MODELS TECH.
   Sandberg A, 2001, FRIENDLY SUPERINTELL.
   Sandberg A, 2012, SINGULARITY HYPOTHES.
   Sandberg A, 2011, 20111 U OXF FUT HUM.
   Sandberg Anders, 2008, 20083 U OXF FUT HUM.
   Schmidhuber J, 2011, LECT NOTES COMPUTER.
   Schmidhuber J, 2009, COGN COMPUT, V1, P177, DOI 10.1007/s12559-009-9014-y.
   Scott James C, 1998, SEEING STATE.
   Searle J. R., 1992, REDISCOVERY MIND.
   Shachtman N, 2007, WIRED.
   Shulman C, ARMS CONTROL INTELLI.
   Shulman C, 2010, OMOHUNDROPS BASIC AI.
   Shulman C, 2010, WHOLE BRAIN EMULATIO.
   Shulman C., 2009, AP CAP 2009, P23.
   Shulman C, 2010, ECAP10 8 EUR C COMP.
   Smith M, 2009, RATIO, V22, P98, DOI 10.1111/j.1467-9329.2008.00420.x.
   Snaider Javier, 2011, Artificial General Intelligence. Proceedings 4th International Conference, AGI 2011, P133, DOI 10.1007/978-3-642-22887-2\_14.
   SOBEL D, 1994, ETHICS, V104, P784, DOI 10.1086/293655.
   Sobolewski M, 2012, GERMAN CABINET AGREE.
   SOLOMONOFF RJ, 1985, HUM SYST MANAGE, V5, P149.
   Solum Lawrence B., 1992, NC L REV, V70, P1231.
   Sotala K, 2012, INT J MACHINE CONSCI, V4, P275, DOI DOI 10.1142/S1793843012400161.
   Sotala K, 2012, INT J MACHINE CONSCI, V4, P293, DOI DOI 10.1142/S1793843012400173.
   Spears DF, 2004, NASA MONO SYST SOFTW, P227.
   Stahl B C, 2002, 14 INT C SYST RES IN, P13.
   Staniford S, 2002, USENIX ASSOCIATION PROCEEDINGS OF THE 11TH USENIX SECURITY SYMPOSIUM, P149.
   Steunebrink Bas R., 2011, Artificial General Intelligence. Proceedings 4th International Conference, AGI 2011, P275, DOI 10.1007/978-3-642-22887-2\_29.
   Stillwaggon Swan L, 2012, INT J MACHINE CONSCI, V4, P245, DOI DOI 10.1142/S1793843012400148.
   Suber P, 2002, SAVING MACHINES THEM.
   Sullins J. P., 2005, Ethics and Information Technology, V7, P139, DOI 10.1007/s10676-006-0003-5.
   Sullins JP, 2006, INT REV INF ETHICS, V6, P23.
   Sweeney L, 1997, J LAW MED ETHICS, V25, P98, DOI 10.1111/j.1748-720X.1997.tb01885.x.
   Tanyi A, 2006, ESSAY DESIRE BASED R.
   Tarleton N, 2010, COHERENT EXTRAPOLATE.
   Tenenbaum JB, 2006, TRENDS COGN SCI, V10, P309, DOI 10.1016/j.tics.2006.05.009.
   Thomas MSC, 2008, CAMB HANDB PSYCHOL, P23.
   Trope Y, 2010, PSYCHOL REV, V117, P440, DOI 10.1037/a0018963.
   Turing A. M., 1951, INTELLIGENT MACHINER, P472.
   Turney P, 1991, CANADIAN ARTIFICIAL, V27, P3.
   TVERSKY A, 1981, SCIENCE, V211, P453, DOI 10.1126/science.7455683.
   Van Kleef GA, 2011, SOC PSYCHOL PERS SCI, V2, P500, DOI 10.1177/1948550611398416.
   van Kleef GA, 2008, PSYCHOL SCI, V19, P1315, DOI 10.1111/j.1467-9280.2008.02241.x.
   VANGELDER T, 1995, J PHILOS, V92, P345, DOI 10.2307/2941061.
   Verdoux P, 2010, J FUTURES STUD, V15, P1.
   Verdoux P, 2011, METAPHILOSOPHY, V42, P682, DOI 10.1111/j.1467-9973.2011.01715.x.
   VERSENYI L, 1974, ETHICS, V84, P248, DOI 10.1086/291922.
   Vinge V, 1993, NASA PUBLICATION, V10129, P11.
   Walker M, 2008, HUMAN EXTINCTION FAR.
   Walker M, 2011, J EVOLUTION TECHNOL, V22, P37.
   Wallach W, 2011, INT J MACHINE CONSCI, V3, P177, DOI DOI 10.1142/S1793843011000674.
   Wallach W, 2012, ETHICS INF TECHNOL, V15.
   Wallach W, 2009, MORAL MACHINES.
   Wallach W, 2010, TOP COGN SCI, V2, P454, DOI 10.1111/j.1756-8765.2010.01095.x.
   Wallach W, 2010, ETHICS INF TECHNOL, V12, P243, DOI 10.1007/s10676-010-9232-8.
   Wallach W, 2008, AI SOC, V22, P565, DOI 10.1007/s00146-007-0099-0.
   Wang P, 2012, LNCS, V7716, P352.
   Wang P, 2008, ARTIFICIAL INTELLIGE, V171.
   Warwick K., 2003, Ethics and Information Technology, V5, P131, DOI 10.1023/B:ETIN.0000006870.65865.cf.
   Warwick K, 1998, MIND MACHINE.
   Warwick K, 2010, ETHICS INF TECHNOL, V12, P223, DOI 10.1007/s10676-010-9218-6.
   Waser Mark, 2011, Artificial General Intelligence. Proceedings 4th International Conference, AGI 2011, P153, DOI 10.1007/978-3-642-22887-2\_16.
   Waser M R, 2009, BIOL INSPIR COGN ARC, P194.
   Waser Mark R., 2008, AAAI FALL S BIOL INS, P195.
   WELD D, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1042.
   Weng Y-H, 2008, SERVICE ROBOT APPL.
   Weng YH, 2009, INT J SOC ROBOT, V1, P267, DOI 10.1007/s12369-009-0019-1.
   Whitby B, 1996, REFLECTIONS ARTIFICI.
   Whitby B, 2000, AVOID ROBOT TAKEOVER.
   WIENER N, 1960, SCIENCE, V131, P1355, DOI 10.1126/science.131.3410.1355.
   Wilson G S, 2014, VIRGINIA ENV LAW J, V31, P307.
   Wilson T. D., 2002, STRANGERS OURSELVES.
   Wood D. M., 2006, REPORT SURVEILLANCE.
   Yampolskiy R V, 2013, STUDIES APPL PHILOS, V5, P389, DOI DOI 10.1007/978-3-642-31674-6\_.
   Yampolskiy R, 2013, TOPOI-INT REV PHILOS, V32, P217, DOI 10.1007/s11245-012-9128-9.
   Yampolskiy RV, 2012, J CONSCIOUSNESS STUD, V19, P194.
   Yudkowsky E, 2012, LESS WRONG.
   Yudkowsky E, 1996, STARING SINGULARITY.
   Yudkowsky E, 2011, COMPLEX VALUE SYSTEM.
   Yudkowsky E, 2004, COHERENT EXTRAPOLATE.
   Yudkowsky E., 2008, LESS WRONG.
   Yudkowsky E, 2011, GLOBAL CATASTROPHIC, P308.
   Yudkowsky E, 2009, LESS WRONG.
   Yudkowsky Eliezer, 2001, CREATING FRIENDLY AI.
   Zimmerman D, 2003, J VALUE INQUIRY, V37, P373, DOI 10.1023/B:INQU.0000013348.62494.55.}},
Number-of-Cited-References = {{310}},
Times-Cited = {{22}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{49}},
Journal-ISO = {{Phys. Scr.}},
Doc-Delivery-Number = {{CB0FP}},
Unique-ID = {{ISI:000349301500032}},
OA = {{Other Gold, Green Published}},
DA = {{2020-06-17}},
}

@article{ ISI:000357169500012,
Author = {Deng, Boer},
Title = {{MACHINE ETHICS: THE ROBOT'S DILEMMA}},
Journal = {{NATURE}},
Year = {{2015}},
Volume = {{523}},
Number = {{7558}},
Pages = {{24-26}},
Month = {{JUL 2}},
Publisher = {{NATURE PUBLISHING GROUP}},
Address = {{MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND}},
Type = {{News Item}},
Language = {{English}},
DOI = {{10.1038/523024a}},
ISSN = {{0028-0836}},
EISSN = {{1476-4687}},
Research-Areas = {{Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Multidisciplinary Sciences}},
Cited-References = {{Anderson M, 2007, AI MAG, V28, P15.
   Duncan B., 2009, GITGYU0902.
   Pereira L. M., LOGIC ARGUM IN PRESS.
   Winfield Alan F. T., 2014, Advances in Autonomous Robotics Systems. 15th Annual Conference (TAROS 2014). Proceedings: LNCS 8717, P85, DOI 10.1007/978-3-319-10401-0\_8.
   2015, {[}No title captured], V518, P20.}},
Number-of-Cited-References = {{5}},
Times-Cited = {{21}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{49}},
Journal-ISO = {{Nature}},
Doc-Delivery-Number = {{CL7RN}},
Unique-ID = {{ISI:000357169500012}},
OA = {{Bronze}},
DA = {{2020-06-17}},
}

@article{ ISI:000419552300005,
Author = {Vanderelst, Dieter and Winfield, Alan},
Title = {{An architecture for ethical robots inspired by the simulation theory of
   cognition}},
Journal = {{COGNITIVE SYSTEMS RESEARCH}},
Year = {{2018}},
Volume = {{48}},
Number = {{SI}},
Pages = {{56-66}},
Month = {{MAY}},
Abstract = {{The expanding ability of robots to take unsupervised decisions renders
   it imperative that mechanisms are in place to guarantee the safety of
   their behaviour. Moreover, intelligent autonomous robots should be more
   than safe; arguably they should also be explicitly ethical. In this
   paper, we put forward a method for implementing ethical behaviour in
   robots inspired by the simulation theory of cognition. In contrast to
   existing frameworks for robot ethics, our approach does not rely on the
   verification of logic statements. Rather, it utilises internal
   simulations which allow the robot to simulate actions and predict their
   consequences. Therefore, our method is a form of robotic imagery. To
   demonstrate the proposed architecture, we implement a version of this
   architecture on a humanoid NAO robot so that it behaves according to
   Asimov's laws of robotics. In a series of four experiments, using a
   second NAO robot as a proxy for the human, we demonstrate that the
   Ethical Layer enables the robot to prevent the human from coming to harm
   in simple test scenarios. (C) 2017 The Authors. Published by Elsevier
   B.V.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Vanderelst, D (Reprint Author), Univ West England, Bristol Robot Lab, T Block,Frenchay Campus,Coldharbour Lane, Bristol BS16 1QY, Avon, England.
   Vanderelst, Dieter; Winfield, Alan, Univ West England, Bristol Robot Lab, T Block,Frenchay Campus,Coldharbour Lane, Bristol BS16 1QY, Avon, England.}},
DOI = {{10.1016/j.cogsys.2017.04.002}},
ISSN = {{1389-0417}},
Keywords = {{Ethical robots; Self-simulation; Simulation theory; Machine ethics;
   Machine Morality}},
Keywords-Plus = {{MACHINE ETHICS; FOUNDATIONS; PERCEPTION; BEHAVIOR; SYSTEMS}},
Research-Areas = {{Computer Science; Neurosciences \& Neurology; Psychology}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Neurosciences; Psychology,
   Experimental}},
Author-Email = {{dieter.vanderelst@brl.ac.uk}},
Cited-References = {{Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4.
   Anderson M, 2007, AI MAG, V28, P15.
   Anderson M, 2010, SCI AM, V303, P72, DOI 10.1038/scientificamerican1010-72.
   Arkin R. C., 2008, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), P121.
   Arkin RC, 2012, P IEEE, V100, P571, DOI 10.1109/JPROC.2011.2173265.
   Asimov I., 1950, I ROBOT.
   Barsalou LW, 2010, TOP COGN SCI, V2, P716, DOI 10.1111/j.1756-8765.2010.01115.x.
   Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577, DOI 10.1017/S0140525X99532147.
   Bekey G. A., 2005, AUTONOMOUS ROBOTS BI.
   Bongard J, 2006, SCIENCE, V314, P1118, DOI 10.1126/science.1133687.
   Botvinick MM, 2008, TRENDS COGN SCI, V12, P201, DOI 10.1016/j.tics.2008.02.009.
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82.
   Demiris Y, 2007, IMITATION AND SOCIAL LEARNING IN ROBOTS, HUMANS AND ANIMALS: BEHAVIOURAL, SOCIAL AND COMMUNICATIVE DIMENSIONS, P89, DOI 10.1017/CBO9780511489808.008.
   Deng B, 2015, NATURE, V523, P24, DOI 10.1038/523024a.
   Dennis L. A., 2015, ABS1504 CORR.
   Dijkstra K, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01525.
   Ding M, 2012, 2012 FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE ENGINEERING SYSTEMS (ICIES), P225, DOI 10.1109/ICIES.2012.6530874.
   Donoso M, 2014, SCIENCE, V344, P1481, DOI 10.1126/science.1252254.
   Gallese V, 2004, TRENDS COGN SCI, V8, P396, DOI 10.1016/j.tics.2004.07.002.
   Gardenfors P, 2004, CONCEPTUAL SPACES GE.
   Gips J., 2005, AAAI FALL 2005 S MAC, P1.
   Goeldner M, 2015, TECHNOL FORECAST SOC, V92, P115, DOI 10.1016/j.techfore.2014.09.005.
   Govindarajulu NS, 2015, COGN TECHNOL, P85, DOI 10.1007/978-3-319-21548-8\_5.
   Haines W., 2015, INTERNET ENCY PHILOS.
   Hegarty M, 2004, TRENDS COGN SCI, V8, P280, DOI 10.1016/j.tics.2004.04.001.
   Hesslow G, 2002, TRENDS COGN SCI, V6, P242, DOI 10.1016/S1364-6613(02)01913-7.
   Hesslow G, 2012, BRAIN RES, V1428, P71, DOI 10.1016/j.brainres.2011.06.026.
   Holland O, 2007, J CONSCIOUSNESS STUD, V14, P97.
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55.
   Kahneman D., 2011, THINKING FAST SLOW.
   Kato Y, 2015, ACMIEEE INT CONF HUM, P35, DOI 10.1145/2696454.2696463.
   Kortenkamp D, 2008, SPRINGER HDB ROBOTIC, P187, DOI DOI 10.1007/978-3-540-30301-5\_9.
   Kosslyn SM, 2001, NAT REV NEUROSCI, V2, P635, DOI 10.1038/35090055.
   Kruse T, 2013, ROBOT AUTON SYST, V61, P1726, DOI 10.1016/j.robot.2013.05.007.
   Lieto A., 2016, BIOL INSPIRED COGNIT.
   Lin P, 2012, INTELL ROBOT AUTON, P1.
   Macaluso I, 2005, LECT NOTES ARTIF INT, V3673, P474.
   Mackworth A., 2011, MACHINE ETHICS, P204.
   Marques HG, 2009, NEUROCOMPUTING, V72, P743, DOI 10.1016/j.neucom.2008.06.016.
   MICHEL O., 2004, CS0412052 ARXIV.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Murphy R., 2009, IEEE INTELLIGENT SYS, V24.
   Murphy R. R., 2000, INTRO AI ROBOTICS.
   Nigam A, 2015, IEEE INT C INT ROBOT, P3621, DOI 10.1109/IROS.2015.7353883.
   Picard R., 1997, AFFECTIVE COMPUTING, V252.
   Pinker S., 1997, MIND WORKS.
   Royakkers L, 2015, INT J SOC ROBOT, V7, P549, DOI 10.1007/s12369-015-0295-x.
   Shanton K, 2010, WIRES COGN SCI, V1, P527, DOI 10.1002/wcs.33.
   Sharkey N, 2008, SCIENCE, V322, P1800, DOI 10.1126/science.1164582.
   Vaughan R., 2006, ANIMALS ANIMATS 9, V4095, P406.
   Vaughan RT, 2007, SPRINGER TRAC ADV RO, V30, P267, DOI 10.1007/978-3-540-68951-5\_16.
   Waldrop MM, 2015, NATURE, V518, P20, DOI 10.1038/518020a.
   Wallach W, 2008, MORAL MACHINES TEACH.
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322.
   Winfield A., 2012, ROBOTICS VERY SHORT.
   Winfield Alan F. T., 2014, Advances in Autonomous Robotics Systems. 15th Annual Conference (TAROS 2014). Proceedings: LNCS 8717, P85, DOI 10.1007/978-3-319-10401-0\_8.
   Winfield A. F. T., 2014, COMPUTER ME AWARENES.
   Xin L, 2013, 2013 CHINESE AUTOMATION CONGRESS (CAC), P533, DOI 10.1109/CAC.2013.6775792.
   Young L, 2012, SOC NEUROSCI-UK, V7, P1, DOI 10.1080/17470919.2011.569146.
   Ziemke T, 2005, NEUROCOMPUTING, V68, P85, DOI 10.1016/j.neucom.2004.12.005.
   Zwaan RA, 2004, PSYCHOL LEARN MOTIV, V44, P35.}},
Number-of-Cited-References = {{61}},
Times-Cited = {{17}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{44}},
Journal-ISO = {{Cogn. Syst. Res.}},
Doc-Delivery-Number = {{FS1QP}},
Unique-ID = {{ISI:000419552300005}},
OA = {{Green Published, Other Gold}},
DA = {{2020-06-17}},
}

@article{ ISI:000324634600012,
Author = {Yampolskiy, Roman and Fox, Joshua},
Title = {{Safety Engineering for Artificial General Intelligence}},
Journal = {{TOPOI-AN INTERNATIONAL REVIEW OF PHILOSOPHY}},
Year = {{2013}},
Volume = {{32}},
Number = {{2}},
Pages = {{217-226}},
Month = {{OCT}},
Abstract = {{Machine ethics and robot rights are quickly becoming hot topics in
   artificial intelligence and robotics communities. We will argue that
   attempts to attribute moral agency and assign rights to all intelligent
   machines are misguided, whether applied to infrahuman or superhuman AIs,
   as are proposals to limit the negative effects of AIs by constraining
   their behavior. As an alternative, we propose a new science of safety
   engineering for intelligent artificial agents based on maximizing for
   what humans value. In particular, we challenge the scientific community
   to develop intelligent systems that have human-friendly values that they
   provably retain, even under recursive self-improvement.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Yampolskiy, R (Reprint Author), Univ Louisville, Dept Comp Engn \& Comp Sci, Louisville, KY 40292 USA.
   Yampolskiy, Roman, Univ Louisville, Dept Comp Engn \& Comp Sci, Louisville, KY 40292 USA.
   Fox, Joshua, Singular Inst Artificial Intelligence, Palo Alto, CA USA.}},
DOI = {{10.1007/s11245-012-9128-9}},
ISSN = {{0167-7411}},
EISSN = {{1572-8749}},
Keywords = {{AI safety; AI confinement; Machine ethics; Robot rights; Intelligence
   explosion; Friendly artificial intelligence}},
Keywords-Plus = {{COMPUTER; ROBOT; SINGULARITY; ETHICS}},
Research-Areas = {{Philosophy}},
Web-of-Science-Categories  = {{Philosophy}},
Author-Email = {{roman.yampolskiy@louisville.edu
   joshua.fox@singinst.org}},
Cited-References = {{Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4.
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83.
   Anderson M, 2007, AI MAG, V28, P15.
   Arneson RJ, 1999, PETER SINGER HIS CRI.
   Asimov Isaac, 1942, ASTOUNDING SCI FICTI, P94.
   BERG P, 1975, P NATL ACAD SCI USA, V72, P1981, DOI 10.1073/pnas.72.6.1981.
   Bishop M, 2009, MIND MACH, V19, P507, DOI 10.1007/s11023-009-9173-3.
   Bostrom N., 2002, J EVOL TECHNOL, V9.
   Bostrom N., 2006, LINGUISTIC PHILOS IN, V5, P11.
   Butler S., 1970, EREWHON RANGE.
   Butler S, 1863, DARWIN MACHINES LETT.
   Chalmers DJ, 2010, J CONSCIOUSNESS STUD, V17, P7.
   Churchland PS, 2011, BRAIN TRUST.
   CLARKE R, 1994, COMPUTER, V27, P57, DOI 10.1109/2.248881.
   CLARKE R, 1993, COMPUTER, V26, P53, DOI 10.1109/2.247652.
   de Garis Hugo, 2005, ARTILECT WAR COSMIST.
   DENNETT DC, 1978, SYNTHESE, V38, P415, DOI 10.1007/BF00486638.
   Drescher G.L., 2006, GOOD REAL DEMYSTIFYI.
   Drexler E, 1986, ENGINES CREATION.
   Fox J, 2010, P 8 EUR C COMP PHIL.
   Fox J, 2011, FUT HUM C 24 OCT 201.
   Gauthier D., 1986, MORALS AGREEMENT.
   Gavrilova ML, 2011, LECT NOTES COMPUT SC, V6670, P140, DOI 10.1007/978-3-642-22336-5\_8.
   Goertzel B, 2011, H MAGAZINE      0817.
   Goertzel B, 2007, ESSENTIALS GEN INTEL.
   Good I. J., 1965, ADV COMPUT, V6, P31, DOI DOI 10.1016/S0065-2458(08)60418-0.
   Gordon DF, 1998, 15 INT C MACH LEARN.
   Gordon-Spears DF, 2003, LECT NOTES ARTIF INT, V2699, P257.
   Gordon-Spears DF, 2005, AGENT TECHNOLOGY FOR, P227.
   Grau C, 2006, IEEE INTELL SYST, V21, P52, DOI 10.1109/MIS.2006.81.
   Guo SS, 2009, SCIENCE, V323, P876, DOI 10.1126/science.323.5916.876a.
   Hall J. Storrs, 2007, AI CREATING CONSCIEN.
   Hall JS, 2007, MIND MACH, V17, pCP6, DOI 10.1007/s11023-007-9065-3.
   Hanson R, 2010, OVERCOMING BIAS.
   Hobbes Thomas, 1998, LEVIATHAN.
   Hutter M., 2005, TEXT THEORET COMP S.
   Joy B, 2000, WIRED, P8.
   Kaczynski T., 1995, NY TIMES.
   KURZWEIL R, 2006, {[}No title captured].
   LaChat MR, 1986, AI MAG, V7, P70, DOI DOI 10.1609/AIMAG.V7I2.540.
   Legg S, 2006, VETTA PROJECT.
   Legg S, 2007, MIND MACH, V17, P391, DOI 10.1007/s11023-007-9079-x.
   Lin P, 2011, ARTIF INTELL, V175, P942, DOI 10.1016/j.artint.2010.11.026.
   McCauley Lee, 2007, Ethics and Information Technology, V9, P153, DOI 10.1007/s10676-007-9138-2.
   McDermott D., 2008, N AM C COMP PHIL BLO.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Omohundro SM, 2008, FRONT ARTIF INTEL AP, V171, P483.
   Pierce MA, 1996, J BUS ETHICS, V15, P425, DOI 10.1007/BF00380363.
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77.
   Pynadath DV, 2001, INT AG 8 INT WORKSH.
   Rappaport ZH, 2006, ACT NEUR S, V98, P9.
   Roth Daniel, 2009, WIRED.
   Ruvinsky AI, 2007, ENCY INFORM ETHICS S, P76.
   Salamon A, 2010, P 8 EUR C COMP PHIL.
   Sawyer RJ, 2007, SCIENCE, V318, P1037, DOI 10.1126/science.1151606.
   Sharkey N, 2008, SCIENCE, V322, P1800, DOI 10.1126/science.1164582.
   Sotala K, 2012, INT J MACHINE CONSCI, V4, P275, DOI DOI 10.1142/S1793843012400161.
   Sotala K, 2010, P 8 EUR C COMP PHIL.
   Sparrow R., 2007, J APPL PHILOS, V24, P62, DOI DOI 10.1111/J.1468-5930.2007.00346.X.
   Tonkens R, 2009, MIND MACH, V19, P421, DOI 10.1007/s11023-009-9159-1.
   Tooby J., 1992, ADAPTED MIND EVOLUTI, P19, DOI DOI 10.1086/418398.
   Vassar M., 2005, AI BOXING DOGS HELIC.
   Veruggio G, 2010, IEEE ROBOT AUTOM MAG, V17, P105, DOI 10.1109/MRA.2010.936959.
   von Ahn L, 2003, LECT NOTES COMPUT SC, V2656, P294.
   Wallach W, 2008, MORAL MACHINES TEACH.
   Wallach W, 2006, AN WORKSH US.
   Warwick K., 2003, Ethics and Information Technology, V5, P131, DOI 10.1023/B:ETIN.0000006870.65865.cf.
   Weld DS, 1994, 12 NAT C ART INT AAA.
   Wright R, 2001, MONZERO LOGIC HUMAN.
   Yampolskiy R, 2012, IEEE ROBOT IN PRESS.
   Yampolskiy R. V., 2012, SINGULARITY HYPOTHES.
   Yampolskiy RV, 2012, J CONSCIOUSNESS STUD, V19, P194.
   Yampolskiy RV, 2011, PHIL THEOR ART INT P.
   Yampolskiy RV, 2011, PHILSO THEORY ARTIFI.
   Yampolskiy RV, 2011, ISRN ARTIFICIAL INTE.
   Yampolskiy RV, 2012, ARTIFICIAL INTELLIGE.
   Yampolskiy RV, 2008, SPEI DEF SEC S ORL F.
   Yudkowsky Eliezer, 2011, Artificial General Intelligence. Proceedings 4th International Conference, AGI 2011, P388, DOI 10.1007/978-3-642-22887-2\_48.
   Yudkowsky E, 2007, LOGICAL FALLACY GEN.
   Yudkowsky E, 2011, SING SUMM NEW YORK.
   Yudkowsky E., 2010, TIMELESS DECISION TH.
   Yudkowsky E, 2011, CAMBRIDGE HDB ARTIFI.
   Yudkowsky E., 2008, GLOBAL CATASTROPHIC, P308.
   Yudkowsky E. S., 2002, AI BOX EXPT.}},
Number-of-Cited-References = {{85}},
Times-Cited = {{17}},
Usage-Count-Last-180-days = {{6}},
Usage-Count-Since-2013 = {{71}},
Journal-ISO = {{Topoi-Int. Rev. Philos.}},
Doc-Delivery-Number = {{221CI}},
Unique-ID = {{ISI:000324634600012}},
DA = {{2020-06-17}},
}

@article{ ISI:000289803100012,
Author = {Powers, Thomas M.},
Title = {{Incremental Machine Ethics Adaptation of Programmed Constraints}},
Journal = {{IEEE ROBOTICS \& AUTOMATION MAGAZINE}},
Year = {{2011}},
Volume = {{18}},
Number = {{1}},
Pages = {{51-58}},
Month = {{MAR}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Powers, TM (Reprint Author), Univ Delaware, Newark, DE 19716 USA.
   Univ Delaware, Newark, DE 19716 USA.}},
DOI = {{10.1109/MRA.2010.940152}},
ISSN = {{1070-9932}},
EISSN = {{1558-223X}},
Keywords = {{Ethics; Humans; Service robots; Pediatrics; Law; Senior citizens}},
Research-Areas = {{Automation \& Control Systems; Robotics}},
Web-of-Science-Categories  = {{Automation \& Control Systems; Robotics}},
Author-Email = {{tpowers@udel.edu}},
ResearcherID-Numbers = {{Powers, Thomas M./A-8020-2009}},
ORCID-Numbers = {{Powers, Thomas M./0000-0002-2484-4721}},
Cited-References = {{Allison G., 1971, ESSENCE DECISION EXP.
   Arkin R. C., 2009, GOVERNING LETHAL BEH.
   ARROW KJ, 1964, POLIT SCI QUART, V79, P584, DOI 10.2307/2146703.
   BRAYBROOKE D, 1963, {[}No title captured].
   Davidson D, 2001, ESSAYS ACTIONS EVENT.
   FORESTER J, 1984, PUBLIC ADMIN REV, V44, P23, DOI 10.2307/975658.
   Hayes MT, 2001, LIMITS POLICY CHANGE.
   HERBERT HS, 1957, MODELS MAN SOCIAL RA.
   HUGHES TP, 1989, {[}No title captured].
   Johnson DG, 2008, INSIDE TECHNOL, P1.
   Knott JH, 2003, J PUBL ADM RES THEOR, V13, P341, DOI 10.1093/jopart/mug023.
   Kohlberg L., 1981, ESSAYS MORAL DEV, V1.
   Lindblom C. E., 1965, INTELLIGENCE DEMOCRA.
   LINDBLOM CE, 1979, PUBLIC ADMIN REV, V39, P517, DOI 10.2307/976178.
   LINDBLOM CE, 1959, PUBLIC ADMIN REV, V19, P79, DOI 10.2307/973677.
   LUSTICK I, 1980, AM POLIT SCI REV, V74, P342, DOI 10.2307/1960631.
   PREMFORS R, 1981, BRIT J POLIT SCI, V11, P201, DOI 10.1017/S000712340000257X.
   Searle JR, 1984, MINDS BRAINS SCI.
   SMITH BC, 1985, ACM SIGCAS COMPUTERS, V14, P18.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.
   Wildavsky A., 1964, POLITICS BUDGETARY P.}},
Number-of-Cited-References = {{21}},
Times-Cited = {{15}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{IEEE Robot. Autom. Mag.}},
Doc-Delivery-Number = {{753TR}},
Unique-ID = {{ISI:000289803100012}},
DA = {{2020-06-17}},
}

@article{ ISI:000321062300006,
Author = {Wallach, Wendell and Allen, Colin},
Title = {{Framing robot arms control}},
Journal = {{ETHICS AND INFORMATION TECHNOLOGY}},
Year = {{2013}},
Volume = {{15}},
Number = {{2, SI}},
Pages = {{125-135}},
Month = {{JUN}},
Abstract = {{The development of autonomous, robotic weaponry is progressing rapidly.
   Many observers agree that banning the initiation of lethal activity by
   autonomous weapons is a worthy goal. Some disagree with this goal, on
   the grounds that robots may equal and exceed the ethical conduct of
   human soldiers on the battlefield. Those who seek arms-control
   agreements limiting the use of military robots face practical
   difficulties. One such difficulty concerns defining the notion of an
   autonomous action by a robot. Another challenge concerns how to verify
   and monitor the capabilities of rapidly changing technologies. In this
   article we describe concepts from our previous work about autonomy and
   ethics for robots and apply them to military robots and robot arms
   control. We conclude with a proposal for a first step toward limiting
   the deployment of autonomous weapons capable of initiating lethal force.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wallach, W (Reprint Author), Yale Univ, Interdisciplinary Ctr Bioeth, Technol \& Eth Res Grp, New Haven, CT USA.
   Wallach, Wendell, Yale Univ, Interdisciplinary Ctr Bioeth, Technol \& Eth Res Grp, New Haven, CT USA.
   Allen, Colin, Indiana Univ, Dept Hist \& Philosophy Sci, Program Cognit Sci, Ctr Integrat Study Anim Behav, Bloomington, IN USA.}},
DOI = {{10.1007/s10676-012-9303-0}},
ISSN = {{1388-1957}},
EISSN = {{1572-8439}},
Keywords = {{Military robots; Moral machines; Machine ethics; Operational morality;
   Robot arms control; Autonomous weapons}},
Research-Areas = {{Social Sciences - Other Topics; Information Science \& Library Science;
   Philosophy}},
Web-of-Science-Categories  = {{Ethics; Information Science \& Library Science; Philosophy}},
Author-Email = {{wendell.wallach@yale.edu}},
Cited-References = {{Altmann J., 2009, ETHICS ROBOTICS.
   Arkin R., 2012, EPIIC INT S CONFL 21, P23.
   Arkin R. C., 2009, GOVERNING LETHAL BEH.
   Asaro P., 2008, CURRENT ISSUES COMPU, P50.
   Borenstein J., 2008, STUDIES ETHICS LAW T, V2, DOI 10.2202/1941-6008.1036.
   Dahm W. J. A., 2012, WALL STREET J.
   Dancy J., 2011, HUMAN.
   Dennett D. C., 1978, BRAINSTORMS.
   FINN P, 2011, {[}No title captured].
   Fodor J. A., 1983, MODULARITY MIND.
   Gips James, 1991, ANDROID EPISTEMOLOGY, P243.
   Gormley Dennis M., 2008, MISSILE CONTAGION CR.
   Hollnagel E., 2006, RESILIANCE ENG CONCE.
   Kim T.-G., 2010, KOREA TIMES     0624.
   Krishnan Armin, 2009, KILLER ROBOTS LEGALI.
   Lin P, 2012, INTELL ROBOT AUTON, P1.
   Lin P., 2011, ALTANTIC        1215.
   Lokhorst GJ, 2012, INTELL ROBOT AUTON, P145.
   Matthias A., 2011, LAW INNOVATION TECHN, V3, P279.
   MCCARTHY J, 1969, {[}No title captured], V4, P463, DOI DOI 10.1016/B978-0-934613-03-3.50033-7.
   Sharkey N., 2011, LAW INNOVATION TECHN, V3, P229, DOI {[}10.5235/175799611798204914, DOI 10.5235/175799611798204914].
   Singer Peter W., 2009, WIRED WAR.
   Sparrow R., 2011, NEW WARS NEW SOLDIER, P117.
   Sparrow R, 2009, IEEE TECHNOL SOC MAG, V28, P25, DOI 10.1109/MTS.2009.931862.
   Stahl B. C., 2002, INT C SYST RES INF C.
   Taleb NN, 2007, BLACK SWAN IMPACT HI.
   U.S. Army Medical Department, 2008, MHAT 4.
   U.S. Army Science Board, 2002, AD HOC STUD HUM ROB.
   U.S. Department of Defense, 2009, FISC YEAR 2009 2034.
   U.S. Department of Defense, 2012, TASK FORC REP ROL AU.
   {*}US AIR FORC, 2009, UNM AIRCR SYST FLIGH.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.
   Woods DD, 2006, JOINT COGNITIVE SYST.}},
Number-of-Cited-References = {{33}},
Times-Cited = {{13}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{42}},
Journal-ISO = {{Ethics Inf. Technol.}},
Doc-Delivery-Number = {{173FA}},
Unique-ID = {{ISI:000321062300006}},
DA = {{2020-06-17}},
}

@article{ ISI:000357392900006,
Author = {Anderson, Michael and Anderson, Susan Leigh},
Title = {{Toward ensuring ethical behavior from autonomous systems: a
   case-supported principle-based paradigm}},
Journal = {{INDUSTRIAL ROBOT-AN INTERNATIONAL JOURNAL}},
Year = {{2015}},
Volume = {{42}},
Number = {{4}},
Pages = {{324-331}},
Abstract = {{Purpose - This paper aims to propose a paradigm of case-supported
   principle-based behavior (CPB) to help ensure ethical behavior of
   autonomous machines. The requirements, methods, implementation and
   evaluation components of the CPB paradigm are detailed.
   Design/methodology/approach - The authors argue that ethically
   significant behavior of autonomous systems can be guided by explicit
   ethical principles abstracted from a consensus of ethicists. Particular
   cases of ethical dilemmas where ethicists agree on the ethically
   relevant features and the right course of action are used to help
   discover principles needed for ethical guidance of the behavior of
   autonomous systems.
   Findings - Such a consensus, along with its corresponding principle, is
   likely to emerge in many areas in which autonomous systems are apt to be
   deployed and for the actions they are liable to undertake, as we are
   more likely to agree on how machines ought to treat us than on how human
   beings ought to treat one another.
   Practical implications - Principles are comprehensive and comprehensible
   declarative abstractions that succinctly represent this consensus in a
   centralized, extensible and auditable way. Systems guided by such
   principles are likely to behave in a more acceptably ethical manner,
   permitting a richer set of behaviors in a wider range of domains than
   systems not so guided, and will exhibit the ability to defend this
   behavior with pointed logical explanations.
   Social implications - A new threshold has been reached where machines
   are being asked to make decisions that can have an ethically relevant
   impact on human beings. It can be argued that such machine ethics ought
   to be the driving force in determining the manner and extent to which
   autonomous systems should be permitted to interact with them.
   Originality/value - Developing and employing principles for this use is
   a complex process, and new tools and methodologies will be needed by
   engineers to help contend with this complexity. The authors offer the
   CPB paradigm as an abstraction to help mitigate this complexity.}},
Publisher = {{EMERALD GROUP PUBLISHING LIMITED}},
Address = {{HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Anderson, M (Reprint Author), Univ Hartford, Dept Comp Sci, Hartford, CT 06117 USA.
   Anderson, Michael, Univ Hartford, Dept Comp Sci, Hartford, CT 06117 USA.
   Anderson, Susan Leigh, Univ Connecticut, Dept Philosophy, New Milford, CT USA.}},
DOI = {{10.1108/IR-12-2014-0434}},
ISSN = {{0143-991X}},
EISSN = {{1758-5791}},
Keywords = {{Ethics; Autonomous robots; Artificial intelligence}},
Keywords-Plus = {{ROBOTS}},
Research-Areas = {{Engineering; Robotics}},
Web-of-Science-Categories  = {{Engineering, Industrial; Robotics}},
Author-Email = {{anderson@hartford.edu}},
Funding-Acknowledgement = {{United States National Science FoundationNational Science Foundation
   (NSF) {[}IIS-0500133, IIS-1151305, IIS-1449155]}},
Funding-Text = {{This material is based in part upon work supported by the United States
   National Science Foundation under Grant Numbers IIS-0500133, IIS-1151305
   and IIS-1449155.}},
Cited-References = {{Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Anderson M, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P253.
   Anderson M, 2010, SCI AM, V303, P72, DOI 10.1038/scientificamerican1010-72.
   Bentham  J., 1799, INTRO PRINCIPLES MOR.
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82.
   Gips J, 1995, ANDROID EPISTEMOLOGY, P243.
   Grau C, 2006, IEEE INTELL SYST, V21, P52, DOI 10.1109/MIS.2006.81.
   Guarini M, 2006, IEEE INTELL SYST, V21, P22, DOI 10.1109/MIS.2006.76.
   Kant I., 1785, GROUNDWORK METAPHYSI.
   Khan A. F. Umar, 1995, ANDROID EPISTEMOLOGY, P253.
   Lavrac N., 1997, INDCUTIVE LOGIC PROG.
   McLaren BM, 2003, ARTIF INTELL, V150, P145, DOI 10.1016/S0004-3702(03)00135-8.
   Pereira LM, 2007, LECT NOTES ARTIF INT, V4874, P99.
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77.
   Ross W. D., 1930, RIGHT GOOD.
   Rzepka  R., 2005, P AAAI FALL S MACH E, P85.
   Turing A, 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433.
   Waldrop M. M., 1987, MAN MADE MINDS PROMI.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{12}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{23}},
Journal-ISO = {{Ind. Robot}},
Doc-Delivery-Number = {{CM0UA}},
Unique-ID = {{ISI:000357392900006}},
DA = {{2020-06-17}},
}

@article{ ISI:000248304200001,
Author = {Anderson, Michael and Anderson, Susan Leigh},
Title = {{The status of machine ethics: a report from the AAAI Symposium}},
Journal = {{MINDS AND MACHINES}},
Year = {{2007}},
Volume = {{17}},
Number = {{1}},
Pages = {{1-10}},
Month = {{MAR}},
Abstract = {{This paper is a summary and evaluation of work presented at the AAAI
   2005 Fall Symposium on Machine Ethics that brought together participants
   from the fields of Computer Science and Philosophy to the end of
   clarifying the nature of this newly emerging field and discussing
   different approaches one could take towards realizing the ultimate goal
   of creating an ethical machine.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Editorial Material}},
Language = {{English}},
Affiliation = {{Anderson, M (Reprint Author), Univ Hartford, Dept Comp Sci, Hartford, CT 06117 USA.
   Univ Hartford, Dept Comp Sci, Hartford, CT 06117 USA.
   Univ Connecticut, Dept Philosophy, Stanford, CA USA.}},
DOI = {{10.1007/s11023-007-9053-7}},
ISSN = {{0924-6495}},
Keywords = {{artificial intelligence; machine ethics}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{anderson@hartford.edu
   susan.anderson@uconn.edu}},
Cited-References = {{Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   ANDERSON M, 2005, AAAI FALL S MENL PAR.
   ANDERSON S, 2005, MACHINE ETHICS.
   ARKOUDAS K, 2004, MACHINE ETHICS.
   Armen C., 2006, P 18 C INN APPL ART.
   ASIMOV I, 1976, BIOCENTENNIAL MAN OT.
   GRAU C, 2005, MACHINE ETHICS PAPER.
   Guarini M., 2005, MACHINE ETHICS.
   MCLAREN B, 2005, MACHINE ETHICS.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Powers TM, 2005, MACHINE ETHICS.
   RZEPKA R, 2005, MAHCINE ETHICS.
   WALLACH W, 2005, MACHINE ETHICS.}},
Number-of-Cited-References = {{13}},
Times-Cited = {{12}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{18}},
Journal-ISO = {{Minds Mach.}},
Doc-Delivery-Number = {{193VV}},
Unique-ID = {{ISI:000248304200001}},
DA = {{2020-06-17}},
}

@article{ ISI:000239386100005,
Author = {Anderson, Michael and Anderson, Susan Leigh},
Title = {{Machine ethics}},
Journal = {{IEEE INTELLIGENT SYSTEMS}},
Year = {{2006}},
Volume = {{21}},
Number = {{4}},
Pages = {{10-11}},
Month = {{JUL-AUG}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA}},
Type = {{Editorial Material}},
Language = {{English}},
Affiliation = {{Anderson, M (Reprint Author), Univ Hartford, Dept Comp Sci, 200 Bloomfield Ave, Hartford, CT 06117 USA.
   Univ Hartford, Dept Comp Sci, Hartford, CT 06117 USA.
   Univ Connecticut, Dept Philosophy, Stamford, CT 06901 USA.}},
DOI = {{10.1109/MIS.2006.70}},
ISSN = {{1541-1672}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
Author-Email = {{anderson@hartford.edu
   susan.anderson@uconn.edu}},
Number-of-Cited-References = {{0}},
Times-Cited = {{12}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{IEEE Intell. Syst.}},
Doc-Delivery-Number = {{068PE}},
Unique-ID = {{ISI:000239386100005}},
DA = {{2020-06-17}},
}

@article{ ISI:000324634600015,
Author = {Bello, Paul and Bringsjord, Selmer},
Title = {{On How to Build a Moral Machine}},
Journal = {{TOPOI-AN INTERNATIONAL REVIEW OF PHILOSOPHY}},
Year = {{2013}},
Volume = {{32}},
Number = {{2}},
Pages = {{251-266}},
Month = {{OCT}},
Abstract = {{Herein we make a plea to machine ethicists for the inclusion of
   constraints on their theories consistent with empirical data on human
   moral cognition. As philosophers, we clearly lack widely accepted
   solutions to issues regarding the existence of free will, the nature of
   persons and firm conditions on moral agency/patienthood; all of which
   are indispensable concepts to be deployed by any machine able to make
   moral judgments. No agreement seems forthcoming on these matters, and we
   don't hold out hope for machines that can both always do the right thing
   (on some general ethic) and produce explanations for its behavior that
   would be understandable to a human confederate. Our tentative solution
   involves understanding the folk concepts associated with our moral
   intuitions regarding these matters, and how they might be dependent upon
   the nature of human cognitive architecture. It is in this spirit that we
   begin to explore the complexities inherent in human moral judgment via
   computational theories of the human cognitive architecture, rather than
   under the extreme constraints imposed by rational-actor models assumed
   throughout much of the literature on philosophical ethics. After
   discussing the various advantages and challenges of taking this
   particular perspective on the development of artificial moral agents, we
   computationally explore a case study of human intuitions about the self
   and causal responsibility. We hypothesize that a significant portion of
   the variance in reported intuitions for this case might be explained by
   appeal to an interplay between the human ability to mindread and to the
   way that knowledge is organized conceptually in the cognitive system. In
   the present paper, we build on a pre-existing computational model of
   mindreading (Bello et al. 2007) by adding constraints related to
   psychological distance (Trope and Liberman 2010), a well-established
   psychological theory of conceptual organization. Our initial results
   suggest that studies of folk concepts involved in moral intuitions lead
   us to an enriched understanding of cognitive architecture and a more
   systematic method for interpreting the data generated by such studies.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Bello, P (Reprint Author), Off Naval Res, Human \& Bioengineered Syst Div Code 341, 875 N Randolph St, Arlington, VA 22203 USA.
   Bello, Paul, Off Naval Res, Human \& Bioengineered Syst Div Code 341, Arlington, VA 22203 USA.
   Bringsjord, Selmer, Rensselaer Polytech Inst, Dept Cognit Sci, Troy, NY 12180 USA.
   Bringsjord, Selmer, Rensselaer Polytech Inst, Dept Comp Sci, Troy, NY 12180 USA.
   Bringsjord, Selmer, Rensselaer Polytech Inst, Dept Lally Sch Management, Troy, NY 12180 USA.}},
DOI = {{10.1007/s11245-012-9129-8}},
ISSN = {{0167-7411}},
EISSN = {{1572-8749}},
Keywords = {{Machine ethics; Experimental psychology; Mindreading; Computational
   cognitive modeling}},
Keywords-Plus = {{PERCEPTION}},
Research-Areas = {{Philosophy}},
Web-of-Science-Categories  = {{Philosophy}},
Author-Email = {{paul.bello@navy.mil
   selmer@rpi.edu}},
Cited-References = {{Arkin R. C., 2009, GOVERNING LETHAL BEH.
   Badre D, 2007, J COGNITIVE NEUROSCI, V19, P2082, DOI 10.1162/jocn.2007.19.12.2082.
   Beavers AF, 2012, INTELL ROBOT AUTON, P333.
   Bello P., 2012, ADV COGNITIVE SYSTEM, V1, P59.
   Bello P, 2011, P 33 ANN C COGN SCI, P2997.
   Bello P., 2007, P 8 INT C COGN MOD, P169.
   Bello P, 2010, COGNITION IN FLUX, P2022.
   Berns GS, 2012, PHILOS T R SOC B, V367, P754, DOI 10.1098/rstb.2011.0262.
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82.
   Cannon EN, 2012, DEVELOPMENTAL SCI, V15, P292, DOI 10.1111/j.1467-7687.2011.01127.x.
   Cassimatis NL, 2008, COGNITIVE SCI, V32, P1304, DOI 10.1080/03640210802455175.
   Cassimatis NL, 2006, AI MAG, V27, P45.
   Egan A, 2008, PHILOS STUD, V140, P47, DOI 10.1007/s11098-008-9225-1.
   Feit N., 2008, BELIEF SELF DEFENSE.
   Goldman A., 2006, SIMULATING MINDS PHI.
   Govindarajalu N, 2011, P 1 INT C IACAP CEL.
   Guarini M., 2011, MACHINE ETHICS, P316.
   Kauppinen A., 2007, PHILOS EXPLOR, V10, P95, DOI DOI 10.1080/13869790701305871.
   Knobe J., 2011, OXFORD HDB FREE WILL, P530.
   Langley P, 2009, COGN SYST RES, V10, P141, DOI 10.1016/j.cogsys.2006.07.004.
   Mill JS, 1979, UTILITARIANISM.
   Mueller E.T., 2006, COMMONSENSE REASONIN.
   Rim S, 2011, THESIS NEW YORK U.
   Scally J, 2011, AAAI FALL S SERIES, P280.
   Swallow KM, 2009, J EXP PSYCHOL GEN, V138, P236, DOI 10.1037/a0015631.
   Trope Y, 2010, PSYCHOL REV, V117, P440, DOI 10.1037/a0018963.}},
Number-of-Cited-References = {{26}},
Times-Cited = {{11}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{15}},
Journal-ISO = {{Topoi-Int. Rev. Philos.}},
Doc-Delivery-Number = {{221CI}},
Unique-ID = {{ISI:000324634600015}},
DA = {{2020-06-17}},
}

@article{ ISI:000419925300001,
Author = {Torresen, Jim},
Title = {{A Review of Future and Ethical Perspectives of Robotics and AI}},
Journal = {{FRONTIERS IN ROBOTICS AND AI}},
Year = {{2018}},
Volume = {{4}},
Month = {{JAN 15}},
Abstract = {{In recent years, there has been increased attention on the possible
   impact of future robotics and AI systems. Prominent thinkers have
   publicly warned about the risk of a dystopian future when the complexity
   of these systems progresses further. These warnings stand in contrast to
   the current state-of-the-art of the robotics and AI technology. This
   article reviews work considering both the future potential of robotics
   and AI systems, and ethical considerations that need to be taken in
   order to avoid a dystopian future. References to recent initiatives to
   outline ethical guidelines for both the design of systems and how they
   should operate are included.}},
Publisher = {{FRONTIERS MEDIA SA}},
Address = {{AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Torresen, J (Reprint Author), Univ Oslo, Dept Informat, Robot \& Intelligent Syst Grp, Oslo, Norway.
   Torresen, Jim, Univ Oslo, Dept Informat, Robot \& Intelligent Syst Grp, Oslo, Norway.}},
DOI = {{10.3389/frobt.2017.00075}},
Article-Number = {{75}},
ISSN = {{2296-9144}},
Keywords = {{review; ethics; technology risks; machine ethics; future perspectives}},
Keywords-Plus = {{CONSCIOUSNESS}},
Research-Areas = {{Robotics}},
Web-of-Science-Categories  = {{Robotics}},
Author-Email = {{jimtoer@ifi.uio.no}},
Funding-Acknowledgement = {{Research Council of Norway as a part of the Engineering Predictability
   with Embodied Cognition (EPEC) {[}240862]; Multimodal Elderly Care
   systems (MECS) {[}247697]; Collaboration on Intelligent Machines
   (COINMAC) {[}261645]}},
Funding-Text = {{This work is partially supported by The Research Council of Norway as a
   part of the Engineering Predictability with Embodied Cognition (EPEC)
   project, under grant agreement 240862; Multimodal Elderly Care systems
   (MECS) project, under grant agreement 247697. I'm thankful for important
   article draft comments and language corrections provided by Charles
   Martin. Collaboration on Intelligent Machines (COINMAC) project, under
   grant agreement 261645}},
Cited-References = {{Acemoglu Daron, 2016, 22252 NBER.
   Anderson M., 2011, MACHINE ETHICS.
   Anderson M, 2010, SCI AM, V303, P72, DOI 10.1038/scientificamerican1010-72.
   {[}Anonymous], 2016, J3016 SAE.
   Arkin Ronald, 2009, GITGVU0902.
   Arkin RC, 2012, P IEEE, V100, P571, DOI 10.1109/JPROC.2011.2173265.
   Asimov I., 1942, ASTOUNDING SCI FICTI, V29.
   Bar-Cohen Y., 2009, COMING ROBOT REVOLUT.
   Boden M, 2017, CONNECT SCI, V29, P124, DOI 10.1080/09540091.2016.1271400.
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654.
   Bostrom N., 2014, SUPERINTELLIGENCE PA.
   Bostrom N, 2014, CAMBRIDGE HANDBOOK OF ARTIFICIAL INTELLIGENCE, P316.
   Bryson J, 2017, COMPUTER, V50, P116, DOI 10.1109/MC.2017.154.
   BSI, 2016, BSI STAND PUBL.
   Demiris Y, 2006, ROBOT AUTON SYST, V54, P361, DOI 10.1016/j.robot.2006.02.003.
   Deng B, 2015, NATURE, V523, P24, DOI 10.1038/523024a.
   Dennis L. A., 2015, ABS150403592 CORR.
   Earl B, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00697.
   Edelman GM, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00004.
   EPSRC, 2011, PRINC ROB EPSRC AHRC.
   Folsom-Kovarik J. T., 2016, AI CHALLENGE PROBLEM, V35.
   Ford M, 2015, RISE ROBOTS TECHNOLO.
   Frey C. B., 2016, TECHNOLOGY WORK V2 0.
   Friedman B, 2006, ADV MANAG INFORM SYS, V5, P348.
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1.
   Govindarajulu NS, 2015, COGN TECHNOL, P85, DOI 10.1007/978-3-319-21548-8\_5.
   Haidegger T, 2013, ROBOT AUTON SYST, V61, P1215, DOI 10.1016/j.robot.2013.05.008.
   IEEE, 2016, ETH AL DES.
   IFR, 2016, WORLD ROB REP 2016.
   JSAI, 2017, JAP SOC ART INT ETH.
   Lewis PR, 2015, COMPUTER, V48, P62, DOI 10.1109/MC.2015.235.
   Lewis PR, 2016, NAT COMPUT SER, P1, DOI 10.1007/978-3-319-39675-0.
   Lin P, 2012, INTELL ROBOT AUTON, P1.
   Lipson H, 2012, FABRICATED NEW WORLD.
   MacDorman KF, 2006, INTERACT STUD, V7, P297, DOI 10.1075/is.7.3.03mac.
   Manzotti R., 2013, NAT INTELL INNS MAG, V2, P7.
   Manzotti R, 2008, ARTIF INTELL MED, V44, P105, DOI 10.1016/j.artmed.2008.07.002.
   MAR, 2015, ROB 2020 MULT ANN RO.
   Mitchell M., 2009, COMPLEXITY GUIDED TO.
   Muller VC, 2016, SYNTH LIBR, V376, P553, DOI 10.1007/978-3-319-26485-1\_33.
   Muller VC, 2016, RISKS OF ARTIFICIAL INTELLIGENCE, P1.
   Muller VC, 2016, RISKS OF ARTIFICIAL INTELLIGENCE, P1.
   Nof S., 1999, HDB IND ROBOTICS, P1378.
   Prescott T., 2017, CONN SCI 1, V29.
   Prodhan G., 2017, EUROPEAN PARLIAMENT.
   Reggia JA, 2013, NEURAL NETWORKS, V44, P112, DOI 10.1016/j.neunet.2013.03.011.
   Russell S, 2015, NATURE, V521, P415, DOI 10.1038/521415a.
   Schwab K., 2016, FUTURE JOBS EMPLOYME.
   Siemens and general electric gear up for the internet of things, 2016, ECONOMIST.
   Tetlock P. E., 2017, EXPERT POLITICAL JUD.
   Torresen J., 2013, WHAT IS ARTIFICIAL I.
   Torresen J., 2016, P 2016 IEEE S SERIES.
   Unwin T, 2005, SCI-FICTION STUD, V32, P5.
   Vanderelst D., 2017, COGN SYST RES.
   Veruggio G., 2005, P IEEE INT C ROB AUT.
   Veruggio G, 2008, SPRINGER HDB ROBOTIC, P1499.
   Veruggio G, 2006, IEEE-RAS INT C HUMAN, P612, DOI 10.1109/ICHR.2006.321337.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.
   Winfield A. F., 2017, NARRATING COMPLEXITY.
   Winfield A. F., 2014, COMPUTER ME AWARENES, P237.
   Winfield Alan F. T., 2014, Advances in Autonomous Robotics Systems. 15th Annual Conference (TAROS 2014). Proceedings: LNCS 8717, P85, DOI 10.1007/978-3-319-10401-0\_8.
   Winfield A. F. T., 2017, AUTONOMOUS ROBOT SYS, P1.}},
Number-of-Cited-References = {{62}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{37}},
Journal-ISO = {{Front. Robot. AI}},
Doc-Delivery-Number = {{FS6RU}},
Unique-ID = {{ISI:000419925300001}},
OA = {{DOAJ Gold, Green Published}},
DA = {{2020-06-17}},
}

@article{ ISI:000423965400010,
Author = {Trentesaux, Damien and Rault, Raphael},
Title = {{Designing Ethical Cyber-Physical Industrial Systems}},
Journal = {{IFAC PAPERSONLINE}},
Year = {{2017}},
Volume = {{50}},
Number = {{1}},
Pages = {{14934-14939}},
Note = {{20th World Congress of the International-Federation-of-Automatic-Control
   (IFAC), Toulouse, FRANCE, JUL 09-14, 2017}},
Organization = {{Int Federat Automat Control; Continental Automot; Occitanie Reg;
   Toulouse Metropole; CNES; Univ Toulouse III; Paul Sabatier; Inria; CNRS;
   OPTITRACK; MDPI; ISAE Supaero; iCODE; EECI; Int Journal Automat \& Comp;
   IEEE CAA Journal Automatica Sinica; Moveo}},
Abstract = {{This paper deals with the risk of non-ethical behaviour of future
   cyber-physical industrial systems designed by researchers. The will of
   the authors is to foster researchers working on these innovative systems
   to pay attention to the possible consequences of their design on the
   welfare of humans interacting with these systems and their possible
   responsibility in case of an accident. Mainly focused on robotics, the
   literature relevant to ethics is shown to be scarce in the field of
   cyber-physical industrial system while relevant stakes are important. A
   set of recommendations is suggested and an example dealing with the
   industrial deployment of a cyber-physical system in transportation
   illustrates these recommendations. (C) 2017, IFAC (International
   Federation of Automatic Control) Hosting by Elsevier Ltd. All rights
   reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Trentesaux, D (Reprint Author), Univ Valenciennes \& Hainaut Cambresis, LAMIH, UMR CNRS 8201, F-59313 Valenciennes, France.
   Trentesaux, D (Reprint Author), Univ Valenciennes \& Hainaut Cambresis, SurferLab, F-59313 Valenciennes, France.
   Trentesaux, Damien, Univ Valenciennes \& Hainaut Cambresis, LAMIH, UMR CNRS 8201, F-59313 Valenciennes, France.
   Trentesaux, Damien, Univ Valenciennes \& Hainaut Cambresis, SurferLab, F-59313 Valenciennes, France.
   Rault, Raphael, Capon \& Rault Avocats Lawfirm, 22 Ave Peuple Belge, F-59800 Lille, France.}},
DOI = {{10.1016/j.ifacol.2017.08.2543}},
ISSN = {{2405-8963}},
Keywords = {{cyber-physical systems; industrial systems; machine ethics;
   transportation}},
Author-Email = {{damien.trentesaux@univ-valenciennes.fr
   r.rault@capon-rault.com}},
ResearcherID-Numbers = {{Trentesaux, Damien/D-2791-2009}},
ORCID-Numbers = {{Trentesaux, Damien/0000-0003-2489-6203}},
Funding-Acknowledgement = {{ERDF (European Regional Development Fund)European Union (EU); European
   UnionEuropean Union (EU); Hauts-de-France regionRegion Hauts-de-France}},
Funding-Text = {{Surferlab is partially funded by ERDF (European Regional Development
   Fund). The authors wish to thank the European Union and the
   Hauts-de-France region for their support.}},
Cited-References = {{Ackerman E., 2016, IEEE SPECTR TECHNOL.
   Alsegier RA, 2016, IEEE POTENTIALS, V35, P24, DOI 10.1109/MPOT.2014.2364491.
   Anderson SL, 2008, AI SOC, V22, P477, DOI 10.1007/s00146-007-0094-5.
   Bhadauria S.S., 2010, ICSTE.
   Bird S.J., 1995, SCI ENG ETHICS, V1, P2.
   CAPURRO R, 2000, {[}No title captured], V32, P257.
   Delvaux M., 2016, CIVIL LAW RULES ROBO.
   Dreier T., 2012, POIESIS PRAXIS, V9, P201, DOI DOI 10.1007/S10202-012-0115-4.
   Kumar N, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INNOVATION AND CHALLENGES IN CYBER SECURITY (ICICCS 2016), P111, DOI 10.1109/ICICCS.2016.7542339.
   Le Mortellec A, 2013, ENG APPL ARTIF INTEL, V26, P227, DOI 10.1016/j.engappai.2012.09.008.
   Lee Jay, 2015, Manufacturing Letters, V3, P18, DOI 10.1016/j.mfglet.2014.12.001.
   Lin P., 2012, ROBOT ETHICS ETHICAL, P400.
   Marvel JA, 2017, ROBOT CIM-INT MANUF, V44, P144, DOI 10.1016/j.rcim.2016.08.001.
   Matsumoto H, 2015, SIGNAL COMMUN PLANTS, V24, P1, DOI 10.1007/978-3-319-19968-9\_1.
   Mitchell T.M., 1997, MACHINE LEARNING.
   Morahan Michael, 2015, IEEE Engineering Management Review, V43, P23, DOI 10.1109/EMR.2015.7433683.
   Nagenborg M, 2008, AI SOC, V22, P349, DOI 10.1007/s00146-007-0153-y.
   Palmerini E., 2016, ROBOT AUTON SYST.
   Thekkilakattil A, 2015, P INT COMP SOFTW APP, P39, DOI 10.1109/COMPSAC.2015.41.
   Trentesaux D, 2016, STUD COMPUT INTELL, V640, P103, DOI 10.1007/978-3-319-30337-6\_10.
   Trentesaux D, 2016, COMPUT IND, V81, P1, DOI 10.1016/j.compind.2016.05.001.
   van Gorp A, 2007, DESIGN STUD, V28, P117, DOI 10.1016/j.destud.2006.11.002.}},
Number-of-Cited-References = {{22}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{IFAC PAPERSONLINE}},
Doc-Delivery-Number = {{FU6LZ}},
Unique-ID = {{ISI:000423965400010}},
OA = {{Bronze}},
DA = {{2020-06-17}},
}

@article{ ISI:000303381500006,
Author = {Tonkens, Ryan},
Title = {{Out of character: on the creation of virtuous machines}},
Journal = {{ETHICS AND INFORMATION TECHNOLOGY}},
Year = {{2012}},
Volume = {{14}},
Number = {{2}},
Pages = {{137-149}},
Month = {{JUN}},
Abstract = {{The emerging discipline of Machine Ethics is concerned with creating
   autonomous artificial moral agents that perform ethically significant
   actions out in the world. Recently, Wallach and Allen (Moral machines:
   teaching robots right from wrong, Oxford University Press, Oxford, 2009)
   and others have argued that a virtue-based moral framework is a
   promising tool for meeting this end. However, even if we could program
   autonomous machines to follow a virtue-based moral framework, there are
   certain pressing ethical issues that need to be taken into account,
   prior to the implementation and development stages. Here I examine
   whether the creation of virtuous autonomous machines is morally
   permitted by the central tenets of virtue ethics. It is argued that the
   creation of such machines violates certain tenets of virtue ethics, and
   hence that the creation and use of those machines is impermissible. One
   upshot of this is that, although virtue ethics may have a role to play
   in certain near-term Machine Ethics projects (e.g. designing systems
   that are sensitive to ethical considerations), machine ethicists need to
   look elsewhere for a moral framework to implement into their autonomous
   artificial moral agents, Wallach and Allen's claims notwithstanding.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Tonkens, R (Reprint Author), York Univ, Dept Philosophy, Fac Liberal Arts \& Profess Studies, 4700 Keele St,Room S426 Ross Bldg, N York, ON M3J 1P3, Canada.
   York Univ, Dept Philosophy, Fac Liberal Arts \& Profess Studies, N York, ON M3J 1P3, Canada.}},
DOI = {{10.1007/s10676-012-9290-1}},
ISSN = {{1388-1957}},
EISSN = {{1572-8439}},
Keywords = {{Machine ethics; Autonomous artificial moral agents; Virtue ethics;
   Social justice; Wallach and Allen}},
Keywords-Plus = {{ETHICS}},
Research-Areas = {{Social Sciences - Other Topics; Information Science \& Library Science;
   Philosophy}},
Web-of-Science-Categories  = {{Ethics; Information Science \& Library Science; Philosophy}},
Author-Email = {{tonkens@yorku.ca}},
Cited-References = {{Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83.
   Anderson M, 2007, AI MAG, V28, P15.
   Anderson M, 2007, MIND MACH, V17, P1, DOI 10.1007/s11023-007-9053-7.
   Anderson SL, 2008, AI SOC, V22, P477, DOI 10.1007/s00146-007-0094-5.
   Arkin R. C., 2009, GOVERNING LETHAL BEH.
   Arkin RC, 2009, IEEE TECHNOL SOC MAG, V28, P30, DOI 10.1109/MTS.2009.931858.
   Asaro PM, 2008, CURRENT ISSUES COMPU, P50.
   Calverley DJ, 2008, AI SOC, V22, P523, DOI 10.1007/s00146-007-0092-7.
   FOOT P, 1977, PHILOS PUBLIC AFF, V6, P85.
   Grau C, 2006, IEEE INTELL SYST, V21, P52, DOI 10.1109/MIS.2006.81.
   Guarini M, 2012, INTELL ROBOT AUTON, P129.
   Hursthouse Rosalind, 1999, VIRTUE ETHICS.
   HURSTHOUSE Rosalind, 1997, VIRTUE ETHICS CRITIC, P227.
   Krishnan A, 2009, KILLER ROBOTS: LEGALITY AND ETHICALITY OF AUTONOMOUS WEAPONS, P1.
   Lin P., 2008, REPORT AUTONOMOUS MI.
   McMahan Jeff, 2009, KILLING WAR.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Oakley J, 2001, VIRTUE ETHICS PROFES.
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77.
   Singer P, 2009, WIRED WAR ROBOTICS R.
   Sparrow R., 2007, J APPL PHILOS, V24, P62, DOI DOI 10.1111/J.1468-5930.2007.00346.X.
   Swanton Christine, 2003, VIRTUE ETHICS PLURAL.
   Tonkens R, 2009, MIND MACH, V19, P421, DOI 10.1007/s11023-009-9159-1.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.}},
Number-of-Cited-References = {{24}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{20}},
Journal-ISO = {{Ethics Inf. Technol.}},
Doc-Delivery-Number = {{933RZ}},
Unique-ID = {{ISI:000303381500006}},
DA = {{2020-06-17}},
}

@article{ ISI:000284547500004,
Author = {Guarini, Marcello},
Title = {{Particularism, Analogy, and Moral Cognition}},
Journal = {{MINDS AND MACHINES}},
Year = {{2010}},
Volume = {{20}},
Number = {{3}},
Pages = {{385-422}},
Month = {{AUG}},
Abstract = {{`Particularism' and `generalism' refer to families of positions in the
   philosophy of moral reasoning, with the former playing down the
   importance of principles, rules or standards, and the latter stressing
   their importance. Part of the debate has taken an empirical turn, and
   this turn has implications for AI research and the philosophy of
   cognitive modeling. In this paper, Jonathan Dancy's approach to
   particularism (arguably one of the best known and most radical
   approaches) is questioned both on logical and empirical grounds. Doubts
   are raised over whether Dancy's brand of particularism can adequately
   explain the graded nature of similarity assessments in analogical
   arguments. Also, simple recurrent neural network models of moral case
   classification are presented and discussed. This is done to raise
   concerns about Dancy's suggestion that neural networks can help us to
   understand how we could classify situations in a way that is compatible
   with his particularism. Throughout, the idea of a surveyable
   standard-one with restricted length and complexity-plays a key role.
   Analogical arguments are taken to involve multidimensional similarity
   assessments, and surveyable contributory standards are taken to be
   attempts to articulate the dimensions of similarity that may exist
   between cases. This work will be of relevance both to those who have
   interests in computationally modeling human moral cognition and to those
   who are interested in how such models may or may not improve our
   philosophical understanding of such cognition.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Guarini, M (Reprint Author), Univ Windsor, Windsor, ON N9B 3P4, Canada.
   Univ Windsor, Windsor, ON N9B 3P4, Canada.}},
DOI = {{10.1007/s11023-010-9200-4}},
ISSN = {{0924-6495}},
Keywords = {{Analogy; Jonathan Dancy; Machine ethics; Moral cognition; Neural
   networks; Particularism}},
Keywords-Plus = {{ETHICS}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{mguarini@uwindsor.ca}},
Funding-Acknowledgement = {{Social Sciences and Humanities Research Council of CanadaSocial Sciences
   and Humanities Research Council of Canada (SSHRC)}},
Funding-Text = {{I thank the Social Sciences and Humanities Research Council of Canada
   for financial support during the research and writing of this paper. I
   am also indebted to the University of Windsor for a sabbatical leave
   during which the research was completed and the paper composed. Thanks
   to Joshua Chauvin for his endless patience in assisting with neural
   network simulations. Finally, thanks to Amy Butchart and Nicholas Ray
   for comments on earlier drafts.}},
Cited-References = {{Anderson M, 2007, AI MAG, V28, P15.
   Anderson M, 2006, IEEE INTELL SYST, V21, P56, DOI 10.1109/MIS.2006.64.
   Brewer S, 1996, HARVARD LAW REV, V109, P923, DOI 10.2307/1342258.
   Dancy J., 1993, MORAL REASONS.
   DANCY J, 1999, {[}No title captured], V1.
   Dancy Jonathan, 2006, ETHICS PRINCIPLES.
   Dancy Jonathan, 2000, MORAL PARTICULARISM.
   Dancy Jonathan, 2009, STANFORD ENCY PHILOS.
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402\_1.
   Garfield J, 2000, MORAL PARTICULARISM.
   Horgan T, 2009, ETHICAL THEORY MORAL, V12, P25, DOI 10.1007/s10677-008-9142-6.
   Horgan Terry, 2007, ETHICAL THEORY MORAL, V10, P279, DOI DOI 10.1007/S10677-007-9068-4.
   JACKSON F, 2000, {[}No title captured].
   LITTLE MO, 2000, {[}No title captured].
   McKeever S, 2005, CAN J PHILOS, V35, P83.
   McKeever S, 2006, PRINCIPLED ETHICS GE.
   McLaren BM, 2003, ARTIF INTELL, V150, P145, DOI 10.1016/S0004-3702(03)00135-8.
   McLaren BM, 2006, IEEE INTELL SYST, V21, P29, DOI 10.1109/MIS.2006.67.
   McNaughton D., 2000, MORAL PARTICULARISM.
   Sun R., 2002, DUALITY MIND BOTTOM.
   THOMSON JJ, 1971, PHILOS PUBLIC AFF, V1, P47.
   Wallach W, 2008, MORAL MACHINES TEACH.}},
Number-of-Cited-References = {{22}},
Times-Cited = {{8}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Minds Mach.}},
Doc-Delivery-Number = {{684JZ}},
Unique-ID = {{ISI:000284547500004}},
DA = {{2020-06-17}},
}

@article{ ISI:000348137800003,
Author = {Ashrafian, Hutan},
Title = {{AIonAI: A Humanitarian Law of Artificial Intelligence and Robotics}},
Journal = {{SCIENCE AND ENGINEERING ETHICS}},
Year = {{2015}},
Volume = {{21}},
Number = {{1}},
Pages = {{29-40}},
Month = {{FEB}},
Abstract = {{The enduring progression of artificial intelligence and cybernetics
   offers an ever-closer possibility of rational and sentient robots. The
   ethics and morals deriving from this technological prospect have been
   considered in the philosophy of artificial intelligence, the design of
   automatons with roboethics and the contemplation of machine ethics
   through the concept of artificial moral agents. Across these categories,
   the robotics laws first proposed by Isaac Asimov in the twentieth
   century remain well-recognised and esteemed due to their specification
   of preventing human harm, stipulating obedience to humans and
   incorporating robotic self-protection. However the overwhelming
   predominance in the study of this field has focussed on human-robot
   interactions without fully considering the ethical inevitability of
   future artificial intelligences communicating together and has not
   addressed the moral nature of robot-robot interactions. A new robotic
   law is proposed and termed AIonAI or artificial
   intelligence-on-artificial intelligence. This law tackles the overlooked
   area where future artificial intelligences will likely interact amongst
   themselves, potentially leading to exploitation. As such, they would
   benefit from adopting a universal law of rights to recognise inherent
   dignity and the inalienable rights of artificial intelligences. Such a
   consideration can help prevent exploitation and abuse of rational and
   sentient beings, but would also importantly reflect on our moral code of
   ethics and the humanity of our civilisation.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ashrafian, H (Reprint Author), Univ London Imperial Coll Sci Technol \& Med, St Marys Hosp, Dept Surg \& Canc, 10th Floor QEQM Building,Praed St, London W2 1NY, England.
   Univ London Imperial Coll Sci Technol \& Med, St Marys Hosp, Dept Surg \& Canc, London W2 1NY, England.}},
DOI = {{10.1007/s11948-013-9513-9}},
ISSN = {{1353-3452}},
EISSN = {{1471-5546}},
Keywords = {{Artificial intelligence; Robotics; Philosophy; Ethics; Humanitarian;
   Human rights}},
Research-Areas = {{Social Sciences - Other Topics; Engineering; History \& Philosophy of
   Science; Science \& Technology - Other Topics; Philosophy}},
Web-of-Science-Categories  = {{Ethics; Engineering, Multidisciplinary; History \& Philosophy Of
   Science; Multidisciplinary Sciences; Philosophy}},
Author-Email = {{h.ashrafian@imperial.ac.uk}},
Cited-References = {{Ashrafian H., 2014, INT J MED ROBOTICS C.
   Asimov I., 1950, ASTOUNDING SCI FICTI, V29, P48.
   Asimov I, 1985, ROBOTS AND EMPIRE.
   Athanasiou T, 2010, KEY TOPICS IN SURGICAL RESEARCH AND METHODOLOGY, P1, DOI 10.1007/978-3-540-71915-1.
   Bostrom N, 2003, PHILOS QUART, V53, P243, DOI 10.1111/1467-9213.00309.
   Dick Philip K., 1968, DO ANDROIDS DREAM EL.
   EPSRC, 2010, PRINC ROB REG ROB RE.
   Finkel I., 2012, TRANSLATION TEXT CYR.
   Kurzweil R., 2005, SINGULARITY IS NEAR.
   Russell WMS, 1959, PRINCIPLES HUMANE EX.
   Veruggio Gianmarco, 2007, EURON ROBOETHICS ROA.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.}},
Number-of-Cited-References = {{12}},
Times-Cited = {{7}},
Usage-Count-Last-180-days = {{17}},
Usage-Count-Since-2013 = {{280}},
Journal-ISO = {{Sci. Eng. Ethics}},
Doc-Delivery-Number = {{AZ3OX}},
Unique-ID = {{ISI:000348137800003}},
DA = {{2020-06-17}},
}

@article{ ISI:000338009300005,
Author = {Brundage, Miles},
Title = {{Limitations and risks of machine ethics}},
Journal = {{JOURNAL OF EXPERIMENTAL \& THEORETICAL ARTIFICIAL INTELLIGENCE}},
Year = {{2014}},
Volume = {{26}},
Number = {{3, SI}},
Pages = {{355-372}},
Abstract = {{Many authors have proposed constraining the behaviour of intelligent
   systems with `machine ethics' to ensure positive social outcomes from
   the development of such systems. This paper critically analyses the
   prospects for machine ethics, identifying several inherent limitations.
   While machine ethics may increase the probability of ethical behaviour
   in some situations, it cannot guarantee it due to the nature of ethics,
   the computational limitations of computational agents and the complexity
   of the world. In addition, machine ethics, even if it were to be
   `solved' at a technical level, would be insufficient to ensure positive
   social outcomes from intelligent systems.}},
Publisher = {{TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Brundage, M (Reprint Author), Arizona State Univ, Consortium Sci Policy \& Outcomes, Tempe, AZ 85287 USA.
   Arizona State Univ, Consortium Sci Policy \& Outcomes, Tempe, AZ 85287 USA.}},
DOI = {{10.1080/0952813X.2014.895108}},
ISSN = {{0952-813X}},
EISSN = {{1362-3079}},
Keywords = {{machine ethics; risk; artificial general intelligence}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{miles.brundage@asu.edu}},
Cited-References = {{Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Allen Colin, 2010, MORAL MACHINES TEACH.
   Allenby Brad, 2009, IEEE INT S SUST SYST.
   Allenby BR, 2011, NEW SCI, V210, P28, DOI 10.1016/S0262-4079(11)61113-5.
   Anderson M., 2011, MACHINE ETHICS.
   Arkin R. C., 2009, GOVERNING LETHAL BEH.
   Berker S, 2009, PHILOS PUBLIC AFF, V37, P293, DOI 10.1111/j.1088-4963.2009.01164.x.
   BERLIN I, 1991, {[}No title captured].
   Boehm C., 2012, MORAL ORIGINS EVOLUT.
   Bringsjord S., 2011, MACHINE ETHICS, P361.
   Bringsjord S, 2009, UNETHICAL RULE BOUND.
   Bringsjord S., 2012, TOPOI.
   Bringsjord S, 2012, TPM-PHILOS MAG, P90, DOI 10.5840/tpm20125755.
   Cloos C., 2005, UTILIBOT PROJECT AUT.
   Crouch W., 2012, MOST IMPORTANT UNSOL.
   Cushman F. A., 2012, MORAL PSYCHOL HDB, P47.
   Darwin C., 1871, DESCENT MAN SELECTIO.
   Dehghani M, 2011, MACHINE ETHICS, P422.
   Freeman T, 2009, USING COMPASSION RES.
   Gert B., 2007, COMMON MORALITY DECI.
   Gigerenzer G, 2010, TOP COGN SCI, V2, P528, DOI 10.1111/j.1756-8765.2010.01094.x.
   Goertzel B, 2006, APPARENT LIMITATIONS.
   Gomila A., 2009, HDB RES SYNTHETIC EM, P166.
   Gowans C, 1987, MORAL DILEMMAS.
   Grau C, 2006, IEEE INTELL SYST, V21, P52, DOI 10.1109/MIS.2006.81.
   Guarini M., 2011, MACHINE ETHICS, P316.
   Haidt J., 2012, RIGHTEOUS MIND WHY G.
   Hanson R., 2001, J ARTIFICIAL INTELLI.
   Helbing D., 2010, SYSTEMIC RISKS SOC E.
   Horgan T, 2009, ETHICAL THEORY MORAL, V12, P25, DOI 10.1007/s10677-008-9142-6.
   Human Rights Watch, 2012, LOS HUM CAS KILL ROB.
   Klein C, 2011, NEUROETHICS-NETH, V4, P143, DOI 10.1007/s12152-010-9077-1.
   Lenman J, 2000, PHILOS PUBLIC AFF, V29, P342, DOI 10.1111/j.1088-4963.2000.00342.x.
   Mackworth A., 2011, MACHINE ETHICS, P335.
   Matthias A., 2011, LAW INNOVATION TECHN, V3, P279.
   MAYER RC, 1995, ACAD MANAGE REV, V20, P709, DOI 10.2307/258792.
   McLaren BM, 2011, MACHINE ETHICS, P297.
   Muller VC, 2012, COGN COMPUT, V4, P212, DOI 10.1007/s12559-012-9129-4.
   Omohundro SM, 2008, FRONT ARTIF INTEL AP, V171, P483.
   Parfit D., 2011, WHAT MATTERS.
   Pojman LP, 2005, ETHICS DISCOVERING R.
   Pontier MA, 2012, LECT NOTES ARTIF INT, V7637, P442, DOI 10.1007/978-3-642-34654-5\_45.
   Powers T, 2011, MACHINE ETHICS, P464.
   Reynolds C. J., 2005, COMP ETH PHIL ENQ.
   Ross W. D., 1988, RIGHT GOOD.
   Sarewitz D, 2008, NATURE, V456, P871, DOI 10.1038/456871a.
   Savulescu Julian, 2012, UNFIT FUTURE NEED MO.
   Shaw William, 1999, CONT ETHICS TAKING A.
   Shulman C, 2010, OMOHUNDROS BASIC AI.
   Shulman C., 2009, AP CAP 2009, P23.
   Sinnott-Armstrong W., 1988, MORAL DILEMMAS PHILO.
   Sotala Kaj, 2013, 20132 MACH INT RES I.
   Taleb NN, 2007, BLACK SWAN.
   Tarleton N, 2010, COHERENT EXTRAPOLATE.
   Tosic P., 2005, P 3 EUR WORKSH MULT, P415.
   Wallach W., 2010, MORAL MACHINES TEACH.
   Wang P, 2006, APPL LOG SER, V34, P3.
   Waser Mark, 2011, Artificial General Intelligence. Proceedings 4th International Conference, AGI 2011, P153, DOI 10.1007/978-3-642-22887-2\_16.
   WILLIAMS B, 1973, {[}No title captured].
   Williams B, 1973, PROBLEMS SELF.
   WOLF S, 1982, J PHILOS, V79, P419, DOI 10.2307/2026228.
   Yudkowsky Eliezer, 2011, Artificial General Intelligence. Proceedings 4th International Conference, AGI 2011, P388, DOI 10.1007/978-3-642-22887-2\_48.
   YUDKOWSKY E, 2007, {[}No title captured], P389.
   Yudkowsky Eliezer, 2001, CREATING FRIENDLY AI.}},
Number-of-Cited-References = {{64}},
Times-Cited = {{7}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{55}},
Journal-ISO = {{J. Exp. Theor. Artif. Intell.}},
Doc-Delivery-Number = {{AJ9EF}},
Unique-ID = {{ISI:000338009300005}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000314227700045,
Author = {Pontier, Matthijs A. and Widdershoven, Guy and Hoorn, Johan F.},
Editor = {{Pavon, J and DuqueMendez, ND and FuentesFernandez, R}},
Title = {{Moral Coppelia - Combining Ratio with Affect in Ethical Reasoning}},
Booktitle = {{ADVANCES IN ARTIFICIAL INTELLIGENCE - IBERAMIA 2012}},
Series = {{Lecture Notes in Artificial Intelligence}},
Year = {{2012}},
Volume = {{7637}},
Pages = {{442-451}},
Note = {{13th Biennial Ibero-American Conference on Artificial Intelligence (AI),
   Cartagena de Indias, COLOMBIA, NOV 13-16, 2012}},
Organization = {{Univ Nacl Colombia; Soc Colombiana Computacion (SCo2); Univ Tecnologica
   Bolivar Cartagena; Univ Caldas; Univ Tecnologica Pereira; Soc Brasileira
   Computacao (SBC); Asociacion Espanola Inteligencia Artificial (AEPIA);
   Soc Mexicana Inteligencia Artificial (SMIA); Assoc Portuguesa
   Inteligencia Artificial (APPIA); Soc Cubana Matematica \& Computacion
   (SCMC); Soc Peruana Inteligencia Artificial (SPIA); Asociacion Argentina
   Inteligencia Artificial (AAIA); Soc Brasileira Inteligencia Computacion
   (SBIC)}},
Abstract = {{We present an integration of rational moral reasoning with emotional
   intelligence. The moral reasoning system alone could not simulate the
   different human reactions to the Trolley dilemma and the Footbridge
   dilemma. However, the combined system can simulate these human moral
   decision making processes. The introduction of affect in rational ethics
   is important when robots communicate with humans in a practical context
   that includes moral relations and decisions. Moreover, the combination
   of ratio and affect may be useful for applications in which human moral
   decision making behavior is simulated, for example, when agent systems
   or robots provide healthcare support.}},
Publisher = {{SPRINGER-VERLAG BERLIN}},
Address = {{HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Pontier, MA (Reprint Author), Vrije Univ Amsterdam, Ctr Adv Media Res Amsterdam CAMeRA VU, De Boelelaan 1081, NL-1081 HV Amsterdam, Netherlands.
   Pontier, Matthijs A.; Widdershoven, Guy; Hoorn, Johan F., Vrije Univ Amsterdam, Ctr Adv Media Res Amsterdam CAMeRA VU, De Boelelaan 1081, NL-1081 HV Amsterdam, Netherlands.
   Widdershoven, Guy, Vrije Univ Amsterdam, Med Ctr, Amsterdam, Netherlands.}},
ISSN = {{0302-9743}},
ISBN = {{978-3-642-34653-8; 978-3-642-34654-5}},
Keywords = {{moral reasoning; machine ethics; cognitive modeling; cognitive robotics;
   emotion modeling; emotional computing}},
Keywords-Plus = {{ENGAGEMENT; JUDGMENT/; MODELS}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods}},
Author-Email = {{m.a.pontier@vu.nl
   g.widdershoven@vumc.nl
   j.f.hoorn@vu.nl}},
Funding-Acknowledgement = {{SELEMCA project within CRISP {[}NWO 646.000.003]}},
Funding-Text = {{This study is part of the SELEMCA project within CRISP (grant number:
   NWO 646.000.003). We would like to thank Joel Anderson and Margo van
   Kemenade for some interesting discussions.}},
Cited-References = {{Anderson M., 2005, MACHINE ETHICS.
   Banks MR, 2008, J AM MED DIR ASSOC, V9, P173, DOI 10.1016/j.jamda.2007.11.007.
   Beauchamp T., 2001, PRINCIPLES BIOMEDICA.
   Bosse T., 2008, COGSCI 2008, P2498.
   Bosse T, 2007, LECT NOTES ARTIF INT, V4722, P339.
   Bosse T, 2010, ADV INTEL SOFT COMPU, V70, P175, DOI 10.1007/978-3-642-12384-9\_22.
   DePaulo BM, 1996, J PERS SOC PSYCHOL, V70, P979, DOI 10.1037/0022-3514.70.5.979.
   Greene JD, 2001, SCIENCE, V293, P2105, DOI 10.1126/science.1062872.
   Haidt J, 2001, PSYCHOL REV, V108, P814, DOI 10.1037//0033-295X.108.4.814.
   Hoorn J.F., 2008, 7 IEEE WIC ACM INT C, P296.
   Hoorn JF, 2012, COGN SYST RES, V15-16, P33, DOI 10.1016/j.cogsys.2011.04.001.
   Konijn EA, 2005, MEDIA PSYCHOL, V7, P107, DOI 10.1207/S1532785XMEP0702\_1.
   Marsella SC, 2009, COGN SYST RES, V10, P70, DOI 10.1016/j.cogsys.2008.03.005.
   Noddings N., 1984, CARING FEMININE APPR.
   Ohnsorge K, 2011, BIOETHICS, V25, P361, DOI 10.1111/j.1467-8519.2011.01912.x.
   Pantazidou M., 1999, J ENG EDUC, V88, P205, DOI DOI 10.1002/J.2168-9830.1999.TB00436.X.
   Picard R. W., 1997, AFFECTIVE COMPUTING.
   Pontier M.A., 2011, THESIS.
   Pontier M. A., 2012, P 34 INT ANN C COGN.
   Robins B., 2005, Universal Access in the Information Society, V4, P105, DOI 10.1007/s10209-005-0116-3.
   van Vugt HC, 2009, COMPUT ANIMAT VIRT W, V20, P195, DOI 10.1002/cav.312.
   Van Wynsberghe A., 2012, J SCI ENG E IN PRESS.
   Wada K, 2009, J ADV COMPUT INTELL, V13, P386, DOI 10.20965/jaciii.2009.p0386.
   WHO, 2010, HLTH TOP AG.}},
Number-of-Cited-References = {{24}},
Times-Cited = {{7}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{5}},
Doc-Delivery-Number = {{BDO56}},
Unique-ID = {{ISI:000314227700045}},
DA = {{2020-06-17}},
}

@article{ ISI:000472938700005,
Author = {van Wynsberghe, Aimee and Robbins, Scott},
Title = {{Critiquing the Reasons for Making Artificial Moral Agents}},
Journal = {{SCIENCE AND ENGINEERING ETHICS}},
Year = {{2019}},
Volume = {{25}},
Number = {{3}},
Pages = {{719-735}},
Month = {{JUN}},
Abstract = {{Many industry leaders and academics from the field of machine ethics
   would have us believe that the inevitability of robots coming to have a
   larger role in our lives demands that robots be endowed with moral
   reasoning capabilities. Robots endowed in this way may be referred to as
   artificial moral agents (AMA). Reasons often given for developing AMAs
   are: the prevention of harm, the necessity for public trust, the
   prevention of immoral use, such machines are better moral reasoners than
   humans, and building these machines would lead to a better understanding
   of human morality. Although some scholars have challenged the very
   initiative to develop AMAs, what is currently missing from the debate is
   a closer examination of the reasons offered by machine ethicists to
   justify the development of AMAs. This closer examination is especially
   needed because of the amount of funding currently being allocated to the
   development of AMAs (from funders like Elon Musk) coupled with the
   amount of attention researchers and industry leaders receive in the
   media for their efforts in this direction. The stakes in this debate are
   high because moral robots would make demands on society; answers to a
   host of pending questions about what counts as an AMA and whether they
   are morally responsible for their behavior or not. This paper shifts the
   burden of proof back to the machine ethicists demanding that they give
   good reasons to build AMAs. The paper argues that until this is done,
   the development of commercially available AMAs should not proceed
   further.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{van Wynsberghe, A (Reprint Author), Delft Univ Technol, Jaffalaan 5, NL-2628 BX Delft, Netherlands.
   van Wynsberghe, Aimee; Robbins, Scott, Delft Univ Technol, Jaffalaan 5, NL-2628 BX Delft, Netherlands.}},
DOI = {{10.1007/s11948-018-0030-8}},
ISSN = {{1353-3452}},
EISSN = {{1471-5546}},
Keywords = {{Artificial moral agents; Robot ethics; Machine ethics}},
Keywords-Plus = {{MACHINE ETHICS; ROBOTS; TRUST}},
Research-Areas = {{Social Sciences - Other Topics; Engineering; History \& Philosophy of
   Science; Science \& Technology - Other Topics; Philosophy}},
Web-of-Science-Categories  = {{Ethics; Engineering, Multidisciplinary; History \& Philosophy Of
   Science; Multidisciplinary Sciences; Philosophy}},
Author-Email = {{aimeevanrobot@gmail.com
   scott@scottrobbins.org}},
ResearcherID-Numbers = {{van Wynsberghe, Aimee/AAH-7451-2020
   }},
ORCID-Numbers = {{Robbins, Scott/0000-0002-5338-295X}},
Funding-Acknowledgement = {{Netherlands Organization for Scientific Research (NWO)Netherlands
   Organization for Scientific Research (NWO) {[}275-20-054]; European
   Research Council (ERC) Advanced Grant titled Global Terrorism and
   Collective Moral Responsibility: Redesigning Military, Police and
   Intelligence Institutions in Liberal Democracies {[}GTCMR 670172]}},
Funding-Text = {{This research is supported by the Netherlands Organization for
   Scientific Research (NWO), Project number 275-20-054. Scott Robbins
   wishes to acknowledge the European Research Council (ERC) Advanced Grant
   titled Global Terrorism and Collective Moral Responsibility: Redesigning
   Military, Police and Intelligence Institutions in Liberal Democracies
   (GTCMR 670172) which in part made research for this paper possible. We
   would also like to thank Deborah Johnson for graciously providing such
   incredibly useful feedback and insights.}},
Cited-References = {{Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4.
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83.
   Allen C, 2012, INTELL ROBOT AUTON, P55.
   Anderson M., 2011, MACHINE ETHICS.
   Anderson M, 2007, AI MAG, V28, P15.
   Anderson M, 2010, SCI AM, V303, P72, DOI 10.1038/scientificamerican1010-72.
   Anderson S. L, 2011, MACHINE ETHICS.
   {[}Anonymous], 2009, SPECULATIVE POST IDE.
   {[}Anonymous], 2012, ECONOMIST.
   ARISTOTLE, 1998, {[}No title captured].
   Arkin R. C., 2009, GOVERNING LETHAL BEH.
   Asimov I, 1963, I ROBOT.
   BAIER A, 1986, ETHICS, V96, P231, DOI 10.1086/292745.
   Bryson J, 2008, CLOSE ENGAGEMENTS AR, P63.
   Cellan-Jones R, 2014, BBC NEWS.
   Coeckelbergh M, 2010, ETHICS INF TECHNOL, V12, P209, DOI 10.1007/s10676-010-9235-5.
   Darling K, 2012, EXTENDING LEGAL PROT.
   Deng B, 2015, NATURE, V523, P24, DOI 10.1038/523024a.
   Dietrich E, 2001, J EXP THEOR ARTIF IN, V13, P323, DOI 10.1080/09528130110100289.
   Doris JM, 1998, NOUS, V32, P504, DOI 10.1111/0029-4624.00136.
   Finlay S, 2007, PHILOS COMPASS, V2, P820, DOI 10.1111/j.1747-9991.2007.00100.x.
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   Friedman B, 1996, ACM T INFORM SYST, V14, P330, DOI 10.1145/230538.230561.
   Gershgorn D, 2017, INSIDE MECH BRAIN WO.
   Gips J, 1994, ANDROID EPISTEMOLOGY.
   Greene J., 2013, MORAL TRIBES EMOTION.
   Gunkel DJ, 2014, PHILOS TECHNOL, V27, P113, DOI DOI 10.1007/S13347-013-0121-Z.
   Haidt J, 2001, PSYCHOL REV, V108, P814, DOI 10.1037//0033-295X.108.4.814.
   Haidt J, 2008, INNATE MIND, V3.
   HARDWIG J, 1991, J PHILOS, V88, P693, DOI 10.2307/2027007.
   Hatmaker T, 2017, SAUDI ARABIA BESTOWS.
   Himma KE, 2009, ETHICS INF TECHNOL, V11, P19, DOI 10.1007/s10676-008-9167-5.
   Johnson Deborah G, 2008, Ethics and Information Technology, V10, P123, DOI 10.1007/s10676-008-9174-6.
   Kristjansson K, 2006, J MORAL EDUC, V35, P37, DOI 10.1080/03057240500495278.
   Lokhorst GJ, 2012, INTELL ROBOT AUTON, P145.
   Markoff John, 2015, NY TIMES.
   Merritt Maria, 2000, ETHICAL THEORY MORAL, V3, P365, DOI DOI 10.1023/A:1009926720584.
   Miller KW, 2017, SCI ENG ETHICS, V23, P389, DOI 10.1007/s11948-016-9785-y.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Moor James H., 2009, PHILOS NOW, V72, P12.
   Nagenborg M, 2007, INT REV INF ETHICS, V7, P129.
   Nissenbaum H, 2001, COMPUTER, V34, P120, DOI 10.1109/2.910905.
   Peters A., 2018, HAVING HEART ATTACK.
   Pizarro D, 2000, J THEOR SOC BEHAV, V30, P355, DOI 10.1111/1468-5914.00135.
   Roeser S, 2011, MOR EM INT.
   Rutkin A, 2014, ETHICAL TRAP ROBOT P.
   Scheutz M, 2016, SYNTH LIBR, V376, P515, DOI 10.1007/978-3-319-26485-1\_30.
   SHAFERLANDAU R, 1994, PHILOS PHENOMEN RES, V54, P331, DOI 10.2307/2108492.
   Sharkey A, 2016, ETHICS INFORM TECHNO.
   Sharkey A, 2017, CONNECT SCI, V29, P210, DOI 10.1080/09540091.2017.1313815.
   Sharkey N, 2017, OUR SEXUAL FUTURE RO.
   Sharkey N, 2012, INTELL ROBOT AUTON, P267.
   Sharkey N, 2008, SCIENCE, V322, P1800, DOI 10.1126/science.1164582.
   Sharkey NE, 2012, INT REV RED CROSS, V94, P787, DOI 10.1017/S1816383112000732.
   Simon J, 2010, ETHICS INF TECHNOL, V12, P343, DOI 10.1007/s10676-010-9243-5.
   Street S, 2006, PHILOS STUD, V127, P109, DOI 10.1007/s11098-005-1726-6.
   Tonkens R, 2009, MIND MACH, V19, P421, DOI 10.1007/s11023-009-9159-1.
   Vallor S., 2015, PHILOS TECHNOLOGY, V28, P107, DOI DOI 10.1007/S13347-014-0156-9.
   Van De Poel I, 2013, PHILOS ENG REFLECTIO.
   Van Den Hoven J, 2007, INFORM SOC INNOVATIO, P67, DOI DOI 10.1007/978-0-387-72381-5\_8.
   van Wynsberghe A, 2016, ETHICS INF TECHNOL, V18, P311, DOI 10.1007/s10676-016-9409-x.
   van Wynsberghe A, 2014, SCI ENG ETHICS, V20, P947, DOI 10.1007/s11948-013-9498-4.
   van Wynsberghe A, 2013, IND ROBOT, V40, P433, DOI 10.1108/IR-12-2012-451.
   van Wynsberghe A, 2013, SCI ENG ETHICS, V19, P407, DOI 10.1007/s11948-011-9343-6.
   VanWynsberghe A, 2015, EMERG TECH ETH INT A, P1.
   WALDROP MM, 1987, AI MAG, V8, P28.
   Wallach W., 2010, MORAL MACHINES TEACH.
   Wallach W, 2010, ETHICS INF TECHNOL, V12, P243, DOI 10.1007/s10676-010-9232-8.
   Wallach W, 2008, AI SOC, V22, P463, DOI 10.1007/s00146-007-0093-6.
   Wiegel V, 2006, P ETH LIF 06 WORKSH.
   Wiegel V, 2010, ETHICS INF TECHNOL, V12, P359, DOI 10.1007/s10676-010-9239-1.}},
Number-of-Cited-References = {{72}},
Times-Cited = {{6}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{14}},
Journal-ISO = {{Sci. Eng. Ethics}},
Doc-Delivery-Number = {{IF2VR}},
Unique-ID = {{ISI:000472938700005}},
OA = {{Green Published, Other Gold}},
DA = {{2020-06-17}},
}

@article{ ISI:000373854700012,
Author = {Cervantes, Jose-Antonio and Rodriguez, Luis-Felipe and Lopez, Sonia and
   Ramos, Felix and Robles, Francisco},
Title = {{Autonomous Agents and Ethical Decision-Making}},
Journal = {{COGNITIVE COMPUTATION}},
Year = {{2016}},
Volume = {{8}},
Number = {{2}},
Pages = {{278-296}},
Month = {{APR}},
Abstract = {{Machine ethics, also known as artificial morality, is a newly emerging
   field concerned with ensuring appropriate behavior of machines toward
   humans and other machines. In this article, we discuss the importance of
   machine ethics and present a computational model of ethical
   decision-making for autonomous agents. The proposed model implements a
   mechanism for integrating the results of diverse assessments into a
   unique cue, and takes into account the agent's preferences, good and bad
   past experiences, ethical rules, and current emotional state as the main
   factors involved in choosing the most appropriate option. The design of
   the model is based on theories and models developed in fields such as
   neuroscience, psychology, artificial intelligence, and cognitive
   informatics. In particular, the model attempts to emulate neural
   mechanisms of the human brain involved in ethical decision-making.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Cervantes, JA (Reprint Author), CINVESTAV, Dept Comp Sci, Guadalajara, Jalisco, Mexico.
   Cervantes, Jose-Antonio; Lopez, Sonia; Ramos, Felix, CINVESTAV, Dept Comp Sci, Guadalajara, Jalisco, Mexico.
   Rodriguez, Luis-Felipe, Inst Tecnol Sonora, Dept Comp Sci, Hermosillo, Sonora, Mexico.
   Robles, Francisco, Univ Guadalajara, North Ctr, Dept Well Being \& Sustainable Dev, Guadalajara 44430, Jalisco, Mexico.}},
DOI = {{10.1007/s12559-015-9362-8}},
ISSN = {{1866-9956}},
EISSN = {{1866-9964}},
Keywords = {{Ethical decision-making; Artificial moral agent; Machine ethics;
   Cognitive informatics; Cognitive process}},
Keywords-Plus = {{ANTERIOR CINGULATE CORTEX; ORBITOFRONTAL CORTEX; PREFRONTAL CORTEX;
   PREMOTOR CORTEX; MACHINE ETHICS; BASAL GANGLIA; NEURAL BASIS; HUMAN
   BRAIN; REWARD; INFORMATION}},
Research-Areas = {{Computer Science; Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Neurosciences}},
Author-Email = {{ingcervantes@hotmail.com
   luis.rodriguez@itson.edu.mx
   slopez@gdl.cinvestav.mx
   framos@gdl.cinvestav.mx
   franciscoara@live.com}},
ResearcherID-Numbers = {{Ramos-Corchado, Felix-Francisco/S-5414-2017
   Rodriguez, Luis-Felipe/AAI-5587-2020
   }},
ORCID-Numbers = {{Ramos-Corchado, Felix-Francisco/0000-0002-0116-7203
   Rodriguez, Luis-Felipe/0000-0001-8114-0299
   Cervantes, Jose-Antonio/0000-0002-4228-2398}},
Cited-References = {{Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83.
   Anderson M, 2007, AI MAG, V28, P15.
   Baars BJ, 2007, NEURAL NETWORKS, V20, P955, DOI 10.1016/j.neunet.2007.09.013.
   Bechara A, 2000, CEREB CORTEX, V10, P295, DOI 10.1093/cercor/10.3.295.
   Bechara A, 2004, BRAIN COGNITION, V55, P30, DOI 10.1016/j.bandc.2003.04.001.
   Best B. J., 2006, COGNITION MULTIAGENT, P186.
   Borg JS, 2006, J COGNITIVE NEUROSCI, V18, P803, DOI 10.1162/jocn.2006.18.5.803.
   Breazeal C, 2003, ROBOT AUTON SYST, V42, P167, DOI 10.1016/S0921-8890(02)00373-1.
   Broeders R, 2011, J EXP SOC PSYCHOL, V47, P923, DOI 10.1016/j.jesp.2011.03.018.
   Chambers RA, 2003, AM J PSYCHIAT, V160, P1041, DOI 10.1176/appi.ajp.160.6.1041.
   Coelho H, 2010, P INFORUM 2010 S INF.
   Crescentini C, 2012, NEUROPSYCHOLOGIA, V50, P1521, DOI 10.1016/j.neuropsychologia.2012.03.005.
   Czubenko M, 2015, COGN COMPUT, V7, P569, DOI 10.1007/s12559-015-9320-5.
   Damasio AR, 1996, PHILOS T R SOC B, V351, P1413, DOI 10.1098/rstb.1996.0125.
   De Martino B, 2006, SCIENCE, V313, P684, DOI 10.1126/science.1128356.
   Dehghani M., 2008, P 23 AAAI C ART INT, P1280.
   EKMAN P, 1992, PSYCHOL REV, V99, P550, DOI 10.1037/0033-295X.99.3.550.
   Ekman P., 1999, HDB COGNITION EMOTIO, P45, DOI DOI 10.1002/0470013494.CH3.
   Ernst M, 2005, BIOL PSYCHIAT, V58, P597, DOI 10.1016/j.biopsych.2005.06.004.
   FERRELL OC, 1985, J MARKETING, V49, P87, DOI 10.2307/1251618.
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X.
   FORD RC, 1994, J BUS ETHICS, V13, P205, DOI 10.1007/BF02074820.
   FORGAS JP, 1995, PSYCHOL BULL, V117, P39, DOI 10.1037/0033-2909.117.1.39.
   Franklin Stan, 2013, Journal of Artificial General Intelligence, V4, P1, DOI 10.2478/jagi-2013-0002.
   Frey S, 2000, EUR J NEUROSCI, V12, P3709, DOI 10.1046/j.1460-9568.2000.00227.x.
   Fuster JM, 2008, PREFRONTAL CORTEX, 4TH EDITION, P1.
   Gigerenzer G, 2010, TOP COGN SCI, V2, P528, DOI 10.1111/j.1756-8765.2010.01094.x.
   Gold JI, 2007, ANNU REV NEUROSCI, V30, P535, DOI 10.1146/annurev.neuro.29.051605.113038.
   Greene JD, 2004, NEURON, V44, P389, DOI 10.1016/j.neuron.2004.09.027.
   Gross CG, 1992, COMPUTATIONAL LEARNI, P44.
   GUL FA, 1984, ACCOUNT REV, V59, P264.
   Haber SN, 2009, BRAIN RES BULL, V78, P69, DOI 10.1016/j.brainresbull.2008.09.013.
   Hagras H, 2004, IEEE INTELL SYST, V19, P12, DOI 10.1109/MIS.2004.61.
   Harman Gilbert, 1977, NATURE MORALITY INTR.
   HARSANYI JC, 1995, SOC CHOICE WELFARE, V12, P319.
   Hirai K, 1998, IEEE INT CONF ROBOT, P1321, DOI 10.1109/ROBOT.1998.677288.
   HOCHSCHILD AR, 1979, AM J SOCIOL, V85, P551, DOI 10.1086/227049.
   Hockey GRJ, 2000, COGNITION EMOTION, V14, P823, DOI 10.1080/02699930050156654.
   Honarvar AR, 2009, IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, P290.
   Honarvar AR, 2009, LECT NOTES ARTIF INT, V5855, P86, DOI 10.1007/978-3-642-05253-8\_10.
   Hoshi E, 2000, NATURE, V408, P466, DOI 10.1038/35044075.
   Hoshi E, 2004, J NEUROPHYSIOL, V91, P2707, DOI 10.1152/jn.00904.2003.
   Hunt S. D., 1986, J MACROMARKETING, V6, P5, DOI DOI 10.1177/027614678600600103.
   KAPLAN F, 2000, {[}No title captured], P57.
   Kennerley SW, 2006, NAT NEUROSCI, V9, P940, DOI 10.1038/nn1724.
   Kibele A, 2006, PSYCHOL SPORT EXERC, V7, P591, DOI 10.1016/j.psychsport.2006.05.001.
   Kringelbach ML, 2005, NAT REV NEUROSCI, V6, P691, DOI 10.1038/nrn1747.
   Laird J., 2012, SOAR COGNITIVE ARCHI.
   LAIRD JE, 1987, ARTIF INTELL, V33, P1, DOI 10.1016/0004-3702(87)90050-6.
   Loewenstein GF, 2001, PSYCHOL BULL, V127, P267, DOI 10.1037//0033-2909.127.2.267.
   Lu LC, 1999, J BUS ETHICS, V18, P91, DOI 10.1023/A:1006038012256.
   Markic O, 2009, INTERDISCIP DESCR CO, V7, P54.
   Miller EK, 2001, ANNU REV NEUROSCI, V24, P167, DOI 10.1146/annurev.neuro.24.1.167.
   O'Doherty J, 2001, NAT NEUROSCI, V4, P95.
   O'Doherty JP, 2004, CURR OPIN NEUROBIOL, V14, P769, DOI 10.1016/j.conb.2004.10.016.
   O'Fallon MJ, 2005, J BUS ETHICS, V59, P375, DOI 10.1007/s10551-005-2929-7.
   Opris I, 2005, BRAIN RES REV, V48, P509, DOI 10.1016/j.brainresrev.2004.11.001.
   Ostos R., 2012, Proceedings of the Eighth International Conference on Intelligent Environments (IE 2012), P72, DOI 10.1109/IE.2012.15.
   Rizzolatti G, 1996, COGNITIVE BRAIN RES, V3, P131, DOI 10.1016/0926-6410(95)00038-0.
   RODMAN HR, 1994, CEREB CORTEX, V4, P484, DOI 10.1093/cercor/4.5.484.
   Rodriguez Luis-Felipe, 2012, International Journal of Software Science and Computational Intelligence, V4, P41, DOI 10.4018/jssci.2012040103.
   Rogers RD, 2004, BIOL PSYCHIAT, V55, P594, DOI 10.1016/j.biopsych.2003.11.012.
   Rolls ET, 2000, CEREB CORTEX, V10, P284, DOI 10.1093/cercor/10.3.284.
   Roning J, 2014, COGN COMPUT, V6, P940, DOI 10.1007/s12559-014-9285-9.
   Schultz W, 2000, CEREB CORTEX, V10, P272, DOI 10.1093/cercor/10.3.272.
   Snaider Javier, 2011, Artificial General Intelligence. Proceedings 4th International Conference, AGI 2011, P133, DOI 10.1007/978-3-642-22887-2\_14.
   Thatcher A, 2003, BEHAV INFORM TECHNOL, V22, P203, DOI 10.1080/0144929031000117071.
   Tom SM, 2007, SCIENCE, V315, P515, DOI 10.1126/science.1134239.
   Tsagarakis NG, 2007, ADV ROBOTICS, V21, P1151, DOI 10.1163/156855307781389419.
   TVERSKY A, 1986, J BUS, V59, pS251, DOI 10.1086/296365.
   Van Staveren I, 2007, REV POLIT ECON, V19, P21, DOI 10.1080/09538250601080776.
   VITELL SJ, 1993, J BUS ETHICS, V12, P753, DOI 10.1007/BF00881307.
   Volkow ND, 2000, CEREB CORTEX, V10, P318, DOI 10.1093/cercor/10.3.318.
   Wallach W, 2010, TOP COGN SCI, V2, P454, DOI 10.1111/j.1756-8765.2010.01095.x.
   Wallach W, 2010, ETHICS INF TECHNOL, V12, P243, DOI 10.1007/s10676-010-9232-8.
   Wallach W, 2008, AI SOC, V22, P463, DOI 10.1007/s00146-007-0093-6.
   Wallach W, 2008, AI SOC, V22, P565, DOI 10.1007/s00146-007-0099-0.
   Wallis JD, 2007, ANNU REV NEUROSCI, V30, P31, DOI 10.1146/annurev.neuro.30.051606.094334.
   Wang Y, 2011, INT J COGN INFORM NA, V5, P61, DOI 10.4018/jcini.2011100105.
   Wang Y, 2012, INT J COGN INFORM NA, V6, P21, DOI 10.4018/jcini.2012010102.
   Wang YX, 2007, INT J COGN INFORM NA, V1, P1, DOI 10.4018/jcini.2007100101.
   Wang YX, 2008, INT J COGN INFORM NA, V2, P44, DOI 10.4018/jcini.2008040103.
   Wang YX, 2005, ICCI 2005: Fourth IEEE International Conference on Cognitive Informatics - Proceedings, P308.
   Wang YX, 2004, PROCEEDINGS OF THE THIRD IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, P124, DOI 10.1109/COGINF.2004.1327467.
   Wilson PA, 2014, COGN COMPUT, V6, P814, DOI 10.1007/s12559-014-9299-3.}},
Number-of-Cited-References = {{86}},
Times-Cited = {{6}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{81}},
Journal-ISO = {{Cogn. Comput.}},
Doc-Delivery-Number = {{DI9WZ}},
Unique-ID = {{ISI:000373854700012}},
DA = {{2020-06-17}},
}

@article{ ISI:000418472500002,
Author = {Etzioni, Amitai and Etzioni, Oren},
Title = {{The ethics of robotic caregivers}},
Journal = {{INTERACTION STUDIES}},
Year = {{2017}},
Volume = {{18}},
Number = {{2}},
Pages = {{174-190}},
Abstract = {{As Artificial Intelligence technology seems poised for a major take-off
   and changing societal dynamics are creating a high demand for caregivers
   for elders, children, and those infirmed, robotic caregivers may well be
   used much more often. This article examines the ethical concerns raised
   by the use of AI caregivers and concludes that many of these concerns
   are avoided when AI caregivers operate as partners rather than
   substitutes. Furthermore, most of the remaining concerns are minor and
   are faced by human caregivers as well. Nonetheless, because AI
   caregivers' systems are learning systems, an AI caregiver could stray
   from its initial guidelines. Therefore, subjecting AI caregivers to an
   AI-based oversight system is proposed to ensure that their actions
   remain both legal and ethical.}},
Publisher = {{JOHN BENJAMINS PUBLISHING CO}},
Address = {{PO BOX 36224, 1020 ME AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Etzioni, A (Reprint Author), George Washington Univ, 1922 F St NW,Room 413, Washington, DC 20052 USA.
   Etzioni, Amitai, George Washington Univ, 1922 F St NW,Room 413, Washington, DC 20052 USA.
   Etzioni, Oren, Allen Inst Artificial Intelligence, 2157 N Northlake Way Suite 110, Seattle, WA 98103 USA.}},
DOI = {{10.1075/is.18.2.02etz}},
ISSN = {{1572-0373}},
EISSN = {{1572-0381}},
Keywords = {{Artificial Intelligence; caregivers; human-machine interaction; machine
   ethics}},
Keywords-Plus = {{SYSTEMS; CARE}},
Research-Areas = {{Communication; Linguistics}},
Web-of-Science-Categories  = {{Communication; Linguistics}},
Cited-References = {{Anderson M, 2011, MACHINE ETHICS, DOI {[}10.1017/CBO9780511978036, DOI 10.1017/CBO9780511978036].
   {[}Anonymous], 2014, AL JAZEERA.
   Bohannon J, 2015, SCIENCE, V349, P250, DOI 10.1126/science.349.6245.250.
   Bostrom N., 2014, CNN.
   Coeckelbergh M, 2010, ETHICAL THEORY MORAL, V13, P181, DOI 10.1007/s10677-009-9186-2.
   DMello A., 2015, CONVERSATION.
   Emspak J., 2016, SCI AM          1229.
   Encyclopaedia Britannica, 2016, ARTIFICIAL INTELLIGE.
   Etzioni A., 2016, VANDERBILT IN PRESS.
   Etzioni A., 2016, KILLER ROBOTS WONT D.
   Feil-Seifer D, 2011, IEEE ROBOT AUTOM MAG, V18, P24, DOI 10.1109/MRA.2010.940150.
   Fisher M, 2013, COMMUN ACM, V56, P84, DOI {[}10.1145/2494558, 10.1145/2500468.2494558].
   Hawking S., 2014, HUFFINGTON POST.
   MacCargar B, 2005, WATTS HEAT LIGHT MEA.
   Markoff J., 2015, MACHINES OF LOVING G.
   Mataric MJ, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-5.
   Mayer-Schonberger V, 2014, BIG DATA REVELUTION.
   Nakajima H, 2003, IEEE SYS MAN CYBERN, P2381.
   Price R., 2016, BUSINESS INSIDER.
   Reese H., 2016, WHY MICROSOFTS TAY A.
   Rheingold H., 1985, TOOLS THOUGHT HIST F.
   Rosenberg T, 2015, NY TIMES.
   Sharkey Amanda, 2012, Ethics and Information Technology, V14, P27, DOI 10.1007/s10676-010-9234-6.
   Sharkey N, 2006, ARTIF INTELL REV, V25, P9, DOI 10.1007/s10462-007-9048-z.
   Sharkey N, 2010, INTERACT STUD, V11, P161, DOI 10.1075/is.11.2.01sha.
   Sharkey N, 2008, SCIENCE, V322, P1800, DOI 10.1126/science.1164582.
   Shea SC, 2006, IMPROVING MED ADHERE.
   Sparrow R., 2002, Ethics and Information Technology, V4, P305, DOI 10.1023/A:1021386708994.
   Sparrow R, 2006, MIND MACH, V16, P141, DOI 10.1007/s11023-006-9030-6.
   Sullins J, 2011, MACHINE ETHICS.
   Turkle S., 2011, CONTINUING HIGHER ED, V75, P28.
   Turkle S., 2010, ALONE TOGETHER WHY W.
   van Wynsberghe A, 2013, SCI ENG ETHICS, V19, P407, DOI 10.1007/s11948-011-9343-6.
   Wallach Wendell, 2008, MORAL MACHINES TEACH, DOI {[}10.1093/acprof:oso/9780195374049.001.0001, DOI 10.1093/ACPROF:OSO/9780195374049.001.0001, 10.1093/acprof.oso/9780195374049.001.0001].
   Winfield Alan F. T., 2014, Advances in Autonomous Robotics Systems. 15th Annual Conference (TAROS 2014). Proceedings: LNCS 8717, P85, DOI 10.1007/978-3-319-10401-0\_8.}},
Number-of-Cited-References = {{35}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{21}},
Journal-ISO = {{Interact. Stud.}},
Doc-Delivery-Number = {{FQ6KD}},
Unique-ID = {{ISI:000418472500002}},
DA = {{2020-06-17}},
}

@article{ ISI:000350992600004,
Author = {Wiltshire, Travis J.},
Title = {{A Prospective Framework for the Design of Ideal Artificial Moral Agents:
   Insights from the Science of Heroism in Humans}},
Journal = {{MINDS AND MACHINES}},
Year = {{2015}},
Volume = {{25}},
Number = {{1}},
Pages = {{57-71}},
Month = {{FEB}},
Abstract = {{The growing field of machine morality has becoming increasingly
   concerned with how to develop artificial moral agents. However, there is
   little consensus on what constitutes an ideal moral agent let alone an
   artificial one. Leveraging a recent account of heroism in humans, the
   aim of this paper is to provide a prospective framework for
   conceptualizing, and in turn designing ideal artificial moral agents,
   namely those that would be considered heroic robots. First, an overview
   of what it means to be an artificial moral agent is provided. Then, an
   overview of a recent account of heroism that seeks to define the
   construct as the dynamic and interactive integration of character
   strengths (e.g., bravery and integrity) and situational constraints that
   afford the opportunity for moral behavior (i.e., moral affordances).
   With this as a foundation, a discussion is provided for what it might
   mean for a robot to be an ideal moral agent by proposing a dynamic and
   interactive connectionist model of robotic heroism. Given the limited
   accounts of robots engaging in moral behavior, a case for extending
   robotic moral capacities beyond just being a moral agent to the level of
   heroism is supported by drawing from exemplar situations where robots
   demonstrate heroism in popular film and fiction.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wiltshire, TJ (Reprint Author), Univ Cent Florida, Cognit Sci Lab, Inst Simulat \& Training, 3100 Technol Pkwy STE 3100, Orlando, FL 32836 USA.
   Univ Cent Florida, Cognit Sci Lab, Inst Simulat \& Training, Orlando, FL 32836 USA.}},
DOI = {{10.1007/s11023-015-9361-2}},
ISSN = {{0924-6495}},
EISSN = {{1572-8641}},
Keywords = {{Machine morality; Moral agency; Heroism; Connectionism; Affordances;
   Character strengths}},
Keywords-Plus = {{MACHINE ETHICS; AFFORDANCES; PSYCHOLOGY}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{twiltshi@ist.ucf.edu}},
Cited-References = {{Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83.
   Becker SW, 2004, AM PSYCHOL, V59, P163, DOI 10.1037/0003-066X.59.3.163.
   BEER RD, 1995, ARTIF INTELL, V72, P173, DOI 10.1016/0004-3702(94)00005-L.
   Chemero A, 2003, ECOL PSYCHOL, V15, P181, DOI 10.1207/S15326969ECO1502\_5.
   Churchland Paul, 1996, ENGINE REASON SEAT S.
   Dautenhahn L., 2002, COGNITIVE SYSTEMS RE, V3, P397.
   Di Stefano P., 2010, THESIS CTR STUDY HUM.
   FLESCHER AM, 2003, {[}No title captured].
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   Freeman JB, 2011, PSYCHOL REV, V118, P247, DOI 10.1037/a0022327.
   Gibson JJ, 1979, ECOLOGICAL APPROACH.
   Goud NH, 2005, J HUMANIST COUNS, V44, P102, DOI 10.1002/j.2164-490X.2005.tb00060.x.
   Guarini M, 2010, MIND MACH, V20, P385, DOI 10.1007/s11023-010-9200-4.
   HAIDT J, 1993, J PERS SOC PSYCHOL, V65, P613, DOI 10.1037/0022-3514.65.4.613.
   Haidt J., 2007, INNATE MIND, V3, P367, DOI DOI 10.1093/ACPR0F:0S0/9780195332834.003.0019.
   HODGES BH, 1992, J THEOR SOC BEHAV, V22, P263, DOI 10.1111/j.1468-5914.1992.tb00220.x.
   Hofmann W, 2014, SCIENCE, V345, P1340, DOI 10.1126/science.1251560.
   Honarvar AR, 2009, IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, P290.
   Jayawickreme E, 2008, REV GEN PSYCHOL, V12, P118, DOI 10.1037/1089-2680.12.2.118.
   Jayawickreme E, 2012, POLIT PSYCHOL, V33, P165, DOI 10.1111/j.1467-9221.2011.00861.x.
   Jayawickreme E, 2011, J POSIT PSYCHOL, V6, P499, DOI 10.1080/17439760.2011.634819.
   Johnson A. M., 2014, IEEE INT S ETH ENG S.
   Jordan J.S., 2006, MIND MATTER, V4, P45.
   Jordan JS, 2008, PHILOS T R SOC B, V363, P1981, DOI 10.1098/rstb.2008.0009.
   Ladikos A., 2004, PHRONIMON, V5, P77.
   Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607.
   Lyons M., 2005, J CULTURAL EVOLUTION, V3, P245, DOI {[}DOI 10.1556/JCEP.3.2005.3-4.2, 10.1556/JCEP.3.2005.3-4.2].
   MACINTYRE A, 1984, {[}No title captured].
   Merritt Maria W., 2010, MORAL PSYCHOL HDB, P355.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Nichols S., 2010, MORAL PSYCHOL HDB, P111.
   Peterson C., 2004, CHARACTER STRENGTHS.
   Pezzulo G, 2012, IEEE T AUTON MENT DE, V4, P105, DOI 10.1109/TAMD.2011.2166261.
   Pomerleau DA, 1991, NEURAL COMPUT, V3, P88, DOI 10.1162/neco.1991.3.1.88.
   SCHWARTZ B, 1990, AM PSYCHOL, V45, P7, DOI 10.1037/0003-066X.45.1.7.
   Smirnov O, 2007, J POLIT, V69, P927, DOI 10.1111/j.1468-2508.2007.00599.x.
   Stenstrom D. M., 2012, PSYCHOLOGY, V3, P1085, DOI DOI 10.4236/PSYCH.2012.312A160.
   Sullins JP, 2006, INT REV INF ETHICS, V6, P23.
   Wallach W, 2008, MORAL MACHINES TEACH.
   Wallach W, 2010, TOP COGN SCI, V2, P454, DOI 10.1111/j.1756-8765.2010.01095.x.
   Wallach W, 2010, ETHICS INF TECHNOL, V12, P243, DOI 10.1007/s10676-010-9232-8.
   Wilson Daniel H., 2011, ROBOPOCALYPSE.
   Wiltshire T.J., 2013, P HUMAN FACTORS ERGO, V57, P1278, DOI {[}DOI 10.1177/1541931213571283, 10.1177/1541931213571283].}},
Number-of-Cited-References = {{44}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{13}},
Journal-ISO = {{Minds Mach.}},
Doc-Delivery-Number = {{CD3PX}},
Unique-ID = {{ISI:000350992600004}},
DA = {{2020-06-17}},
}

@article{ ISI:000324634600013,
Author = {Powers, Thomas M.},
Title = {{On the Moral Agency of Computers}},
Journal = {{TOPOI-AN INTERNATIONAL REVIEW OF PHILOSOPHY}},
Year = {{2013}},
Volume = {{32}},
Number = {{2}},
Pages = {{227-236}},
Month = {{OCT}},
Abstract = {{Can computer systems ever be considered moral agents? This paper
   considers two factors that are explored in the recent philosophical
   literature. First, there are the important domains in which computers
   are allowed to act, made possible by their greater functional
   capacities. Second, there is the claim that these functional capacities
   appear to embody relevant human abilities, such as autonomy and
   responsibility. I argue that neither the first (Doman-Function) factor
   nor the second (Simulacrum) factor gets at the central issue in the case
   for computer moral agency: whether they can have the kinds of
   intentional states that cause their decisions and actions. I give an
   account that builds on traditional action theory and allows us to
   conceive of computers as genuine moral agents in virtue of their own
   causally efficacious intentional states. These states can cause harm or
   benefit to moral patients, but do not depend on computer consciousness
   or intelligence.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Powers, TM (Reprint Author), Univ Delaware, Dept Philosophy, Newark, DE 19716 USA.
   Powers, Thomas M., Univ Delaware, Dept Philosophy, Newark, DE 19716 USA.
   Powers, Thomas M., Univ Delaware, Ctr Sci Eth \& Publ Policy, Newark, DE USA.}},
DOI = {{10.1007/s11245-012-9149-4}},
ISSN = {{0167-7411}},
EISSN = {{1572-8749}},
Keywords = {{Moral agency; Computer ethics; Machine ethics}},
Research-Areas = {{Philosophy}},
Web-of-Science-Categories  = {{Philosophy}},
Author-Email = {{tpowers@udel.edu}},
ResearcherID-Numbers = {{Powers, Thomas M./A-8020-2009}},
ORCID-Numbers = {{Powers, Thomas M./0000-0002-2484-4721}},
Cited-References = {{Alexander McClintock, 1995, CONVERGENCE MACHINE.
   Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Allen C, 1995, COMP APPROACHES COGN, P93.
   Aristotle, 2009, NICOMACHEAN ETHICS.
   Bratman M. E., 1992, Minds and Machines, V2, P1.
   Brooks Rodney, 2002, FLESH MACHINES ROBOT.
   DAVIDSON D, 1963, J PHILOS, V60, P685, DOI 10.2307/2023177.
   Davidsson P, 2005, P 4 INT JOINT C AUT, P1299.
   Dennett DC, 1996, INTENTIONAL STANCE.
   Dretske FI, 1980, MIDWEST STUD PHILOS, V2, P281.
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   Floridi L., 2001, Ethics and Information Technology, V3, P55, DOI 10.1023/A:1011440125207.
   Floridi L, 2006, ETHICS INF TECHNOL, V8, P155.
   Floridi L., 2008, INFORM TECHNOLOGY MO.
   Fodor J. A., 2000, MIND DOESNT WORK WAY.
   Greene J.D., 2009, COGNITIVE NEUROSCIEN.
   Haugeland J., 1990, PHILOS PERSPECT, V4, P383, DOI {[}10.2307/2214199, DOI 10.2307/2214199].
   Johnson D. G., 2005, Ethics and Information Technology, V7, P99, DOI 10.1007/s10676-005-4585-0.
   Johnson Deborah G, 2008, Ethics and Information Technology, V10, P123, DOI 10.1007/s10676-008-9174-6.
   Johnson D. G., 2006, Ethics and Information Technology, V8, P195, DOI 10.1007/s10676-006-9111-5.
   Johnson D. G., 2005, ENCY SCI TECHNOLOGY.
   Johnson DG, 2008, INSIDE TECHNOL, P1.
   Moor JH, 2006, IEEE INTELL SYST.
   Moravec H., 2008, SCI AM, V18, P12.
   Peter Danielson, 1992, ARTIFICIAL MORALITY.
   Powers TM, 2011, IEEE ROBOT AUTOM MAG, V18, P51, DOI 10.1109/MRA.2010.940152.
   Ray Kurzweil, 2000, AGE SPIRITUAL MACHIN.
   Searle J., 1983, INTENTIONALITY.
   Searle J.R., 2001, RATIONALITY ACTION.
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038.
   SIMON HA, 1977, {[}No title captured].
   Simon HA, 1996, MACHINES THOUGHT LEG, V1.
   Sullins JP, 2006, INT REV INF ETHICS, V6, P23.
   Symons J, 2001, MIND MACH, V11, P521, DOI 10.1023/A:1011859328855.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.}},
Number-of-Cited-References = {{35}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{Topoi-Int. Rev. Philos.}},
Doc-Delivery-Number = {{221CI}},
Unique-ID = {{ISI:000324634600013}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000283802800049,
Author = {Honarvar, Ali Reza and Ghasem-Aghaee, Nasser},
Book-Group-Author = {{IEEE}},
Title = {{An Artificial Neural Network Approach for Creating an Ethical Artificial
   Agent}},
Booktitle = {{IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS
   AND AUTOMATION}},
Year = {{2009}},
Pages = {{290+}},
Note = {{IEEE International Symposium on Computational Intelligence in Robotics
   and Automation, Daejeon, SOUTH KOREA, DEC 15-18, 2009}},
Abstract = {{Autonomous robotic systems and intelligent artificial agents' capability
   have advanced dramatically. Since the intelligent artificial agents have
   been developing more autonomous and human-like, the capability of them
   to make moral decisions becomes an important issue. In this work we
   developed an artificial neutral network which considered various
   effective factors for ethical assessment of an action to determine that
   if a behavior or an action is ethically permissible or not. We
   integrated this net to the BDI-Agent model as a part of its reasoning
   process to behave ethically in various environments.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Honarvar, AR (Reprint Author), Islamic Azad Univ, Dept Comp Engn, Arsanjan Branch, Arsanjan, Fars, Iran.
   Honarvar, Ali Reza, Islamic Azad Univ, Dept Comp Engn, Arsanjan Branch, Arsanjan, Fars, Iran.
   Ghasem-Aghaee, Nasser, Univ Isfahan, Sheikh Bahaei Univ, Dept Comp Engn, \textbackslash{} Esfahan, Iran.}},
ISBN = {{978-1-4244-4808-1}},
Keywords = {{Artificial ethical agent; ethical reasoning; AMA; BDI-Agent; machine
   ethics; artificial neural network}},
Research-Areas = {{Automation \& Control Systems; Computer Science; Engineering; Robotics}},
Web-of-Science-Categories  = {{Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Robotics}},
Author-Email = {{AliReza\_Honarvar@yahoo.co.uk
   aghaee@eng.ui.ac.ir}},
Cited-References = {{Allen C, 2006, ETHICS INF TECHNOL, V7, P149, DOI DOI 10.1007/S10676-006-0004-4.
   ANDERSON M, 2007, AI MAGAZINE, V28.
   Anderson M., 2005, MACHINE ETHICS, P1.
   Anderson M, 2008, STUD COMPUT INTELL, V107, P233.
   ARKOUDAS K, 2005, TECHN REP MACH ETH A.
   BARTON A, 2004, STEPHEN BRYON CASTLE.
   BRINGSJORD S, 2006, IEEE INTELLIGENT SYS, V21.
   GIPS, 1995, ETHICAL ROBOT ANDROI, P243.
   GUARINI M, 2006, IEEE INTELLIGENT SYS, V21.
   HAMALAINEN W, COMPUTERS HAVE CONSC.
   HONARVAR AR, 2009, ART INT COMP INT INT.
   JEANGABRIEL G, 2007, ETHICS INFORM TECHNO.
   JEANGABRIEL G, 2007, 7 INT COMP ETH C U S.
   KEEFER M, 2003, MORAL REASONING CASE.
   Kolodner, 1993, CASE BASED REASONING.
   PAL S, 2004, FDN SOFT CASEBASED R.
   RAO G, 1995, P 1 INT C MULT SYST.
   RZEPKA R, 2005, TECHNICAL REPORT MAC, P85.
   SABAH S, 2008, P 2 IEEE INT C DIG E.
   THOMAS M, 2006, IEEE INTELLIGENT SYS, V21.
   TONKENS R, 2009, CHALLENGE MACHINE ET.
   VANDENHOVEN J, 2002, DEONTIC LOGIC COMPUT.
   WALLACH W, 2006, ANALIFEX WORKSH US.
   WIEGEL V, 2007, THESIS DELFT U TECHN.
   WIEGEL V, 2009, SOCIAL ROBOTICS, V1.}},
Number-of-Cited-References = {{25}},
Times-Cited = {{5}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{5}},
Doc-Delivery-Number = {{BRW76}},
Unique-ID = {{ISI:000283802800049}},
DA = {{2020-06-17}},
}

@article{ ISI:000460669800003,
Author = {Winfield, Alan F. and Michael, Katina and Pitt, Jeremy and Evers,
   Vanessa},
Title = {{Machine Ethics: The Design and Governance of Ethical AI and Autonomous
   Systems}},
Journal = {{PROCEEDINGS OF THE IEEE}},
Year = {{2019}},
Volume = {{107}},
Number = {{3, SI}},
Pages = {{509-517}},
Month = {{MAR}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Editorial Material}},
Language = {{English}},
Affiliation = {{Winfield, AF (Reprint Author), UWE, Robot Eth, Bristol, Avon, England.
   Winfield, AF (Reprint Author), Univ York, York, N Yorkshire, England.
   Winfield, AF (Reprint Author), Leverhulme Ctr Future Intelligence, Cambridge, England.
   Winfield, AF (Reprint Author), UWE, Bristol Robot Lab, Bristol, Avon, England.
   Winfield, Alan F., UWE, Robot Eth, Bristol, Avon, England.
   Winfield, Alan F., Univ York, York, N Yorkshire, England.
   Winfield, Alan F., Leverhulme Ctr Future Intelligence, Cambridge, England.
   Winfield, Alan F., APD Commun Ltd, Kingston Upon Hull, Yorks, England.
   Winfield, Alan F., UWE, Bristol Robot Lab, Bristol, Avon, England.
   Michael, Katina, Nanjing Univ, Nanjing, Jiangsu, Peoples R China.
   Michael, Katina, Nortel Networks, Wollongong, NSW, Australia.
   Michael, Katina, Andersen Consulting, Sydney, NSW, Australia.
   Michael, Katina, OTIS Elevator Co, Minto, NSW, Australia.
   Michael, Katina, Arizona State Univ, Sch Future Innovat Soc, Tempe, AZ USA.
   Michael, Katina, Arizona State Univ, Sch Comp Informat \& Decis Syst Engn, Tempe, AZ USA.
   Michael, Katina, Arizona State Univ, Ctr Engn Policy \& Soc, Tempe, AZ USA.
   Pitt, Jeremy, Imperial Coll London, Dept Elect \& Elect Engn, Intelligent \& Self Organising Syst, London, England.
   Evers, Vanessa, Univ Twente, Human Media Interact, Enschede, Netherlands.
   Evers, Vanessa, DesignLab, Enschede, Netherlands.}},
DOI = {{10.1109/JPROC.2019.2900622}},
ISSN = {{0018-9219}},
EISSN = {{1558-2256}},
Keywords-Plus = {{ROBOTS}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
ResearcherID-Numbers = {{Michael, Katina/G-9186-2012}},
ORCID-Numbers = {{Michael, Katina/0000-0003-3118-5557}},
Cited-References = {{Adamson G, 2019, P IEEE, V107, P518, DOI 10.1109/JPROC.2018.2884923.
   Adamson G, 2015, P IEEE, V103, P2208, DOI 10.1109/JPROC.2015.2483958.
   Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4.
   Anderson M., 2006, IEEE INTELL SYST, V21.
   Anderson M., 2011, MACHINE ETHICS.
   Anderson M, 2019, P IEEE, V107, P526, DOI 10.1109/JPROC.2018.2840045.
   Anderson M, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P253.
   {[}Anonymous], 2016, BS8641.
   {[}Anonymous], 2017, ETH COMM AUT CONN DR.
   Arkin R. C., 2009, GOVERNING LETHAL BEH.
   Arnold T, 2016, ETHICS INF TECHNOL, V18, P103, DOI 10.1007/s10676-016-9389-x.
   Asaro PM, 2006, INT REV INF ETHICS, V6, P9.
   Asimov I., 1950, I ROBOT.
   Awad E, 2018, NATURE, V563, P59, DOI 10.1038/s41586-018-0637-6.
   Boddington P., 2017, CODE ETHICS ARTIFICI.
   Boden M, 2017, CONNECT SCI, V29, P124, DOI 10.1080/09540091.2016.1271400.
   Bonnefon JF, 2019, P IEEE, V107, P502, DOI 10.1109/JPROC.2019.2897447.
   Bremner P, 2019, P IEEE, V107, P541, DOI 10.1109/JPROC.2019.2898267.
   Briggs G., 2015, P AAAI FALL S SER, P1.
   Bringsjord S., 2014, P IEEE INT S ETH ENG.
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82.
   Brundage M., 2018, MALICIOUS USE ARTIFI.
   Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230.
   Cave S., 2018, NATURE MACH INTELL, V1, P74.
   Cave S, 2019, P IEEE, V107, P562, DOI 10.1109/JPROC.2018.2865996.
   Charisi V, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P399, DOI 10.1145/3078072.3084300.
   Dutton T., 2013, OVERVIEW NATL STRATE.
   Dyrkolbotn S, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P74, DOI 10.1145/3278721.3278769.
   Ema A, 2019, P IEEE, V107, P575, DOI 10.1109/JPROC.2018.2837045.
   Forester T., 2018, COMPUTER ETHICS CAUT.
   Frayn M., 1965, THE TIN MEN.
   Helbing D., 2019, DIGITAL ENLIGHTENMEN.
   IEEE, 2017, ETH AL DES VIS PRIOR.
   Jaeeun Shim, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2936, DOI 10.1109/ICRA.2017.7989340.
   Jirotka M, 2017, COMMUN ACM, V60, P62, DOI 10.1145/3064940.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Neff G., 2016, INT J COMMUNICATION, V10, P17.
   Pitt J., 2011, ACM T AUTON ADAP SYS, V9.
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77.
   Reacher N., 1966, DISTRIBUTIVE JUSTICE.
   Reilly-Cooper R, 2015, COMMUNICATION.
   Robertson LJ, 2019, P IEEE, V107, P582, DOI 10.1109/JPROC.2018.2889678.
   Schwab K, 2017, 4 IND REVOLUTION.
   Sharkey A., 2017, ETHICS INF TECHNOL, DOI {[}10.1007/s10676-017-9425-5, DOI 10.1007/S10676-017-9425-5].
   Spiekermann S, 2019, P IEEE, V107, P600, DOI 10.1109/JPROC.2018.2866769.
   THOMSON JJ, 1985, YALE LAW J, V94, P1395, DOI 10.2307/796133.
   Vanderelst D, 2018, COGN SYST RES, V48, P56, DOI 10.1016/j.cogsys.2017.04.002.
   Wachter S, 2017, SCI ROBOT, V2, DOI 10.1126/scirobotics.aan6080.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.
   Wallach W, 2019, P IEEE, V107, P505, DOI 10.1109/JPROC.2019.2899422.
   Winfield Alan F. T., 2014, Advances in Autonomous Robotics Systems. 15th Annual Conference (TAROS 2014). Proceedings: LNCS 8717, P85, DOI 10.1007/978-3-319-10401-0\_8.
   Winfield AFT, 2018, PHILOS T R SOC A, V376, DOI 10.1098/rsta.2018.0085.
   Winfield AFT, 2017, LECT NOTES COMPUT SC, V10454, P262, DOI 10.1007/978-3-319-64107-2\_21.
   Wolf M. J., 2017, ACM SIGCAS Computers and Society, V47, P54, DOI 10.1145/3144592.3144598.}},
Number-of-Cited-References = {{55}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{17}},
Journal-ISO = {{Proc. IEEE}},
Doc-Delivery-Number = {{HO1ME}},
Unique-ID = {{ISI:000460669800003}},
DA = {{2020-06-17}},
}

@article{ ISI:000434849800004,
Author = {Fossa, Fabio},
Title = {{Artificial moral agents: moral mentors or sensible tools?}},
Journal = {{ETHICS AND INFORMATION TECHNOLOGY}},
Year = {{2018}},
Volume = {{20}},
Number = {{2}},
Pages = {{115-126}},
Month = {{JUN}},
Abstract = {{The aim of this paper is to offer an analysis of the notion of
   artificial moral agent (AMA) and of its impact on human beings'
   self-understanding as moral agents. Firstly, I introduce the topic by
   presenting what I call the Continuity Approach. Its main claim holds
   that AMAs and human moral agents exhibit no significant qualitative
   difference and, therefore, should be considered homogeneous entities.
   Secondly, I focus on the consequences this approach leads to. In order
   to do this I take into consideration the work of Bostrom and Dietrich,
   who have radically assumed this viewpoint and thoroughly explored its
   implications. Thirdly, I present an alternative approach to AMAs-the
   Discontinuity Approach-which underscores an essential difference between
   human moral agents and AMAs by tackling the matter from another angle.
   In this section I concentrate on the work of Johnson and Bryson and I
   highlight the link between their claims and Heidegger's and Jonas's
   suggestions concerning the relationship between human beings and
   technological products. In conclusion I argue that, although the
   Continuity Approach turns out to be a necessary postulate to the machine
   ethics project, the Discontinuity Approach highlights a relevant
   distinction between AMAs and human moral agents. On this account, the
   Discontinuity Approach generates a clearer understanding of what AMAs
   are, of how we should face the moral issues they pose, and, finally, of
   the difference that separates machine ethics from moral philosophy.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Fossa, F (Reprint Author), St Anna Sch Adv Studies, Inst Law Polit \& Dev, Pisa, Italy.
   Fossa, Fabio, St Anna Sch Adv Studies, Inst Law Polit \& Dev, Pisa, Italy.}},
DOI = {{10.1007/s10676-018-9451-y}},
ISSN = {{1388-1957}},
EISSN = {{1572-8439}},
Keywords = {{Machine ethics; Machine morality; Ethics of technology; Artificial moral
   agents; Moral agency}},
Keywords-Plus = {{COMPUTERS; MACHINES; ETHICS; HUMANS}},
Research-Areas = {{Social Sciences - Other Topics; Information Science \& Library Science;
   Philosophy}},
Web-of-Science-Categories  = {{Ethics; Information Science \& Library Science; Philosophy}},
Author-Email = {{fabiofossa36@gmail.com}},
Cited-References = {{Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Allen C., 2011, MACHINE ETHICS, P51.
   Anderson SL, 2011, MACHINE ETHICS, P21, DOI DOI 10.1017/CB09780511978036.004.
   Beavers AF, 2012, INTELL ROBOT AUTON, P333.
   Bostrom N, 2003, ETHICAL ISSUES ADV A.
   Bostrom N., 2014, SUPERINTELLIGENCE PA.
   Bryson J. J., 2010, CLOSE ENGAGEMENTS AR, P63.
   Bryson J. J., 2011, JUST ARTIFACT WHY MA.
   Clark R, 2011, MACHINE ETHICS, P254.
   Dennet D., 1997, HALS LEGACY 2001S CO, P351.
   Dietrich E, 2011, MACHINE ETHICS, P531.
   Dietrich E, 2007, J EXP THEOR ARTIF IN, V19, P55, DOI 10.1080/09528130601115339.
   Duffy B., 2013, ANTHROPOMORPHISM ROB.
   Duffy BR, 2003, ROBOT AUTON SYST, V42, P177, DOI 10.1016/S0921-8890(02)00374-3.
   Fabris A., 2016, THEORIZING IMAGES, P111.
   Fink Julia, 2012, Social Robotics. 4th International Conference (ICSR 2012). Proceedings, P199, DOI 10.1007/978-3-642-34103-8\_20.
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   Franklin S., 1996, LECT NOTES COMPUTER, V1193, P22.
   FRIEDMAN B, 1992, J SYST SOFTWARE, V17, P7, DOI 10.1016/0164-1212(92)90075-U.
   Fussell S. R., 2008, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), P145.
   Gips J, 1995, ANDROID EPISTEMOLOGY, P243.
   Grodzinsky Frances S, 2008, Ethics and Information Technology, V10, P27, DOI 10.1007/s10676-008-9163-9.
   Gunkel D, 2012, MACHINE QUESTION CRI.
   Hall J. S., 2011, MACHINE ETHICS, P512, DOI DOI 10.1017/CBO9780511978036.
   Hall JS, 2011, MACHINE ETHICS, P28.
   Heidegger M, 2013, QUESTION TECHNOLOGY.
   Heidegger M, 2010, BEING TIME.
   Henry B, 2014, POLITI SOC, V3, P221, DOI 10.4476/77101.
   Himma KE, 2009, ETHICS INF TECHNOL, V11, P19, DOI 10.1007/s10676-008-9167-5.
   Johnson D., 2003, BLACKWELL COMPANION, P608.
   Johnson D. G., 2011, MACHINE ETHICS, P168.
   Jonas H., 1959, SOC RES, VXXVI, P151.
   Jonas H, 1953, SOC RES, V20, P172.
   Kakoudaki D., 2014, ANATOMY ROBOT LIT CI.
   KIRAN A.H., 2010, KNOWLEDGE TECHNOLOGY, V23, P409, DOI DOI 10.1007/S12130-010-9123-7.
   Kurzweil R., 2005, SINGULARITY IS NEAR.
   Laukyte M, 2017, ETHICS INF TECHNOL, V19, P1, DOI 10.1007/s10676-016-9411-3.
   Lemaignan S, 2014, ACMIEEE INT CONF HUM, P226, DOI 10.1145/2559636.2559814.
   McDermott D., 2008, MACHINE ETHICS, P88.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   MOOR JH, 1995, METAPHILOSOPHY, V26, P1, DOI 10.1111/j.1467-9973.1995.tb00553.x.
   Moore G., 1965, ELECTRONICS, V38, P1, DOI DOI 10.1109/JPROC.1998.658762.
   Mori M., 1970, ENERGY, V7, P33, DOI DOI 10.1109/MRA.2012.2192811.
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153.
   Nissenbaum H., 2001, IEEE COMPUT, P118, DOI DOI 10.1109/2.910905.
   Scheutz M, 2012, INTELL ROBOT AUTON, P205.
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038.
   Sullins JP, 2011, MACHINE ETHICS, V6, P151, DOI 10.1017/CBO9780511978036.021.
   Torrance S, 2011, MACHINE ETHICS, P115.
   Turing A, 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433.
   Turkle S, 2011, MACHINE ETHICS, P62.
   Verbeek P.-P., 2005, WHAT THINGS DO PHILO.
   Vinge V., 1993, P VIS 21 INT SCI ENG, P11.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.
   Wallach W, 2010, ETHICS INF TECHNOL, V12, P243, DOI 10.1007/s10676-010-9232-8.
   Whitby B, 2011, MACHINE ETHICS, P138.
   Yudkowsky E, 2008, ARTIFICIAL INTELLIGE.}},
Number-of-Cited-References = {{57}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{10}},
Journal-ISO = {{Ethics Inf. Technol.}},
Doc-Delivery-Number = {{GI9MS}},
Unique-ID = {{ISI:000434849800004}},
DA = {{2020-06-17}},
}

@article{ ISI:000402671600004,
Author = {Clempner, Julio B.},
Title = {{A Game Theory Model for Manipulation Based on Machiavellianism: Moral
   and Ethical Behavior}},
Journal = {{JASSS-THE JOURNAL OF ARTIFICIAL SOCIETIES AND SOCIAL SIMULATION}},
Year = {{2017}},
Volume = {{20}},
Number = {{2}},
Month = {{MAR 31}},
Abstract = {{This paper presents a new game theory approach for modeling manipulation
   behavior based on Machiavellianism (social conduct and intelligence
   theory). The Machiavellian game conceptualizes the Machiavellianism
   considering three concepts: views, tactics and immorality. For modeling
   the Machiavellian views and tactics we employ a Stackelberg/Nash game
   theory approach. For representing the concept of immorality, we consider
   that rational Machiavellian players employ a combination of the
   deontological and utilitarian moral rules, as well as, moral heuristics.
   We employ a reinforcement learning approach for the implementation of
   the immorality concept providing a computational mechanism, in which,
   its principle of error-driven adjustment of cost/reward predictions
   contributes to the players' acquisition of moral (immoral) behavior. The
   reinforcement learning algorithm is based on an actor-critic approach
   responsible for evaluating the new state of the system and it determines
   if the cost/rewards are better or worse than expected, supported by the
   Machiavellian game theory solution. The result of the model is the
   manipulation equilibrium point. We provide the details needed to
   implement the extraproximal method in an efficient and numerically
   stable way. Finally, we present a numerical example that validates the
   effectiveness of the manipulation model.}},
Publisher = {{J A S S S}},
Address = {{UNIV SURREY, DEPT SOCIOLOGY, GUILDFORD GU2 7XH, SURREY, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Clempner, JB (Reprint Author), Inst Politecn Nacl, Lauro Aguirre 120, Del Miguel Hidalgo 11360, Mexico.
   Clempner, Julio B., Inst Politecn Nacl, Lauro Aguirre 120, Del Miguel Hidalgo 11360, Mexico.}},
DOI = {{10.18564/jasss.3301}},
Article-Number = {{12}},
ISSN = {{1460-7425}},
Keywords = {{Machiavellianism; Machiavellian Intelligence; Stackelberg/NashGame;
   Machine Ethics; Moral; Markov Chains; Behavioral Games}},
Keywords-Plus = {{MARKOV-CHAINS GAMES; DECISION-MAKING; INFLUENCE TACTICS; POWER; AGENTS}},
Research-Areas = {{Social Sciences - Other Topics}},
Web-of-Science-Categories  = {{Social Sciences, Interdisciplinary}},
Author-Email = {{julio@clempner.name}},
Cited-References = {{Antipin A.S., 2005, COMP MATH MATH PHYS, V45, P1893, DOI DOI 10.1134/S0965542507120044.
   BALES RE, 1971, AM PHILOS QUART, V8, P257.
   Byrne R., 1988, MACHIAVELLIANISM INT.
   CALHOON RP, 1969, ACAD MANAGE J, V12, P205, DOI 10.2307/254816.
   Cervantes J. A., 2011, COGN COMPUT, V8, P278.
   Christie R, 1970, STUDIES MACHIAVELLIA.
   Cleckley H., 1976, MASK SANITY.
   Clempner JB, 2014, J SYST SCI SYST ENG, V23, P439, DOI 10.1007/s11518-014-5260-y.
   Dawkins R., 1976, SELFISH GENE.
   Dawkins R., 1978, ANIMAL SIGNALS INFOR.
   Dehghani M., 2008, P 23 AAAI C ART INT, P1280.
   FALBO T, 1977, J PERS SOC PSYCHOL, V35, P537, DOI 10.1037/0022-3514.35.8.537.
   GABLE M, 1992, J PSYCHOL, V126, P317, DOI 10.1080/00223980.1992.10543366.
   GRAMS WC, 1990, J GEN PSYCHOL, V117, P71, DOI 10.1080/00221309.1990.9917774.
   Hartog D. N., 2012, J BUS ETHICS, V107, P35, DOI DOI 10.1007/S10551-012-1296-4.
   Hellriegel D., 1997, ORG BEHAV.
   Indurkhya B., 2016, AAAI SPRING S SERIES, P226.
   LEARY MR, 1986, PERS SOC PSYCHOL B, V12, P75, DOI 10.1177/0146167286121008.
   Machiavelli N., 1965, DISCOURSES 1 10 BOOK.
   Machiavelli N, 2001, ART WAR.
   Machiavelli Niccolo, 1952, PRINCE.
   MUDRACK PE, 1990, J SOC PSYCHOL, V130, P125, DOI 10.1080/00224545.1990.9922944.
   Poznyak AS, 2008, ADVANCED MATHEMATICAL TOOLS FOR AUTOMATIC CONTROL ENGINEERS, VOL 1: DETERMINISTIC TECHNIQUES, P1.
   Poznyak AS, 2000, SELF LEARNING CONTRO.
   PROCIUK TJ, 1976, J SOC PSYCHOL, V98, P141, DOI 10.1080/00224545.1976.9923379.
   Raven B. H., 1993, J SOC PSYCHOL, V43, P227.
   Sanchez EM, 2015, ENG APPL ARTIF INTEL, V46, P82, DOI 10.1016/j.engappai.2015.08.011.
   Schindler J, 2012, JASSS-J ARTIF SOC S, V15, DOI 10.18564/jasss.1822.
   Smith R., 1979, PSYCHOPATH SOC.
   SOLAR D, 1971, PSYCHOL REP, V29, P1079, DOI 10.2466/pr0.1971.29.3f.1079.
   Stackelberg H., 2011, MARKET STRUCTURE EQU.
   Tobler PN, 2008, COGN AFFECT BEHAV NE, V8, P390, DOI 10.3758/CABN.8.4.390.
   Trejo KK, 2016, KYBERNETIKA, V52, P258, DOI 10.14736/kyb-2016-2-0258.
   Trejo KK, 2015, INT J AP MAT COM-POL, V25, P337, DOI 10.1515/amcs-2015-0026.
   VECCHIO RP, 1991, J ORGAN BEHAV, V12, P73, DOI 10.1002/job.4030120107.
   VLEEMING RG, 1979, PSYCHOL REP, V44, P295, DOI 10.2466/pr0.1979.44.1.295.
   Wallach W, 2010, TOP COGN SCI, V2, P454, DOI 10.1111/j.1756-8765.2010.01095.x.
   Wijermans N, 2013, JASSS-J ARTIF SOC S, V16.
   Wilson DS, 1996, PSYCHOL BULL, V119, P285, DOI 10.1037/0033-2909.119.2.285.
   Xianyu B., 2010, JASSS-J ARTIF SOC S, V13, P7.}},
Number-of-Cited-References = {{40}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{JASSS}},
Doc-Delivery-Number = {{EW7EC}},
Unique-ID = {{ISI:000402671600004}},
OA = {{DOAJ Gold}},
DA = {{2020-06-17}},
}

@article{ ISI:000441811800033,
Author = {Garner, Tom A. and Powell, Wendy A. and Carr, Valerie},
Title = {{Virtual carers for the elderly: A case study review of ethical
   responsibilities}},
Journal = {{DIGITAL HEALTH}},
Year = {{2016}},
Volume = {{2}},
Month = {{JAN-DEC}},
Abstract = {{Intelligent digital healthcare systems are becoming an increasingly
   considered approach to facilitating continued support of our ageing
   population. Within the remit of such digital systems, `Virtual Carer' is
   one of the more consistent terms that refers to an artificial system
   capable of providing various assistive living and communicative
   functionalities, embodied within a graphical avatar displayed on a
   screen. As part of the RITA (Responsive Interactive Advocate) project -
   a proof of concept for one such virtual carer system - a series of
   semi-structured discussions with various stakeholders was conducted.
   This paper presents the results of these discussions to highlight data
   security, replacement of human/physical care and always acting in the
   user's best interest. These three ethical concerns and designer
   responsibilities are identified as highly relevant to both individuals
   and groups that may, in the future, utilise a system like RITA either as
   a care receiver or provider. This paper also presents some initial,
   theoretical safeguard processes relevant to these key concerns.}},
Publisher = {{SAGE PUBLICATIONS LTD}},
Address = {{1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Powell, WA (Reprint Author), Univ Portsmouth, Eldon Bldg,Winton Churchill Ave, Portsmouth PO1 2DJ, Hants, England.
   Garner, Tom A.; Powell, Wendy A., Univ Portsmouth, Sch Creat Technol, Portsmouth, Hants, England.
   Carr, Valerie, WeAreSnook, Glasgow, Lanark, Scotland.}},
DOI = {{10.1177/2055207616681173}},
Article-Number = {{UNSP 2055207616681173}},
ISSN = {{2055-2076}},
Keywords = {{Machine ethics; digital avatar; virtual carer; elderly care; automated
   systems}},
Keywords-Plus = {{IDENTITY VERIFICATION; ROBOT CARE; TECHNOSTRESS; TECHNOLOGY; SECURITY;
   PRIVACY}},
Research-Areas = {{Biomedical Social Sciences}},
Web-of-Science-Categories  = {{Social Sciences, Biomedical}},
Author-Email = {{wendy.powell@port.ac.uk}},
ORCID-Numbers = {{Powell, Wendy/0000-0002-7234-5628}},
Funding-Acknowledgement = {{Technology Strategy Board (Innovate UK)}},
Funding-Text = {{The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: We
   acknowledge the Technology Strategy Board (Innovate UK) for their
   financial support of the RITA project.}},
Cited-References = {{Abdulhamid S.M., 2014, ARXIV14023301.
   Al Ameen M, 2012, J MED SYST, V36, P93, DOI 10.1007/s10916-010-9449-4.
   Amos SW, 2002, NEWNES DICT ELECT.
   {[}Anonymous], 2010, PWC INF SEC BREACH S.
   Bauer MW, 1995, RESISTANCE NEW TECHN, P97.
   Ben-Yacoub S, 1999, IEEE T NEURAL NETWOR, V10, P1065, DOI 10.1109/72.788647.
   Binder J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P965.
   BROOKS H, 1986, RES MANAGE, V29, P43.
   Calvaresi D, 2014, P 7 INT C PERVASIVE, DOI {[}DOI 10.1145/2674396.2674416, 10.1145/2674396.2674416].
   Campbell AT, 2008, IEEE INTERNET COMPUT, V12, P12, DOI 10.1109/MIC.2008.90.
   Cayton H., 2006, DEMENTIA MIND MEANIN, P277.
   Cereghetti D, 2015, AMI 15 EUR C AMB INT.
   Cesta A, 2007, PSYCHNOLOGY J, V5, P229.
   Cetto A, 2014, ARXIV14025878.
   Chattaraman V, 2014, J RES INTERACT MARK, V8, P144, DOI 10.1108/JRIM-08-2013-0054.
   Cho S, 2000, J ORG COMP ELECT COM, V10, P295, DOI 10.1207/S15327744JOCE1004\_07.
   Christensen K, 2009, LANCET, V374, P1196, DOI 10.1016/S0140-6736(09)61460-4.
   Coeckelbergh M., 2012, CAPABILITY APPROACH, P77.
   Costa R, 2008, ADV SOFT COMPUTING, P86.
   Dautenhahn K, 2007, PHILOS T R SOC B, V362, P679, DOI 10.1098/rstb.2006.2004.
   de Visser E. J., 2012, P HUM FACT ERG SOC A, V56, P263, DOI DOI 10.1177/1071181312561062.
   Draper H, 2014, MACHINE ETHICS CONTE.
   Dwork C, 2009, LECT NOTES COMPUT SC, V5444, P496.
   Faisal AA, 2013, 5 INT C INF COMM TEC, P1.
   Ferri Anthony J., 2007, WILLING SUSPENSION D.
   Gartner Inc, 2001, FT145524.
   Hoffmann BS, 2013, THESIS.
   Ishak D, 2015, P HUM FACT ERG SOC A, V59, P65, DOI DOI 10.1177/1541931215591014.
   Law J, 2015, LECT NOTES ARTIF INT, V9287, P149, DOI 10.1007/978-3-319-22416-9\_17.
   Leitch S, 2009, AUSTR INF SEC MAN C, P16.
   Metag J, 2014, JOURNALISM, V15, P463, DOI 10.1177/1464884913491045.
   Mori M., 1970, ENERGY, V7, P33, DOI DOI 10.1109/MRA.2012.2192811.
   Nelson SD, 2011, SECURE PASSWORDS RUL.
   Nussbaum MC, 2011, CREATING CAPABILITIE.
   Powell W, 2014, ICDVRAT.
   Powell Wendy. A., 2016, HDB RES CREATIVE TEC, P99.
   Reeves J, 2014, INT J INTEGR CARE, V14.
   Riedl R., 2011, P 32 INT C INF SYST, P1.
   Salamzadeh Y, 2013, GLOBAL J TECHNOL, V3, P186.
   Sandoval EB, 2014, LECT NOTES ARTIF INT, V8755, P54, DOI 10.1007/978-3-319-11973-1\_6.
   Scheutz M, 2013, IEEE ROBOT AUTOM MAG, V20, P20, DOI 10.1109/MRA.2013.2283184.
   Self RJ, 2013, ADV INTELL SYST, V172, P117.
   Sharkey Amanda, 2012, Ethics and Information Technology, V14, P27, DOI 10.1007/s10676-010-9234-6.
   Sharkey A, 2014, ETHICS INF TECHNOL, V16, P63, DOI 10.1007/s10676-014-9338-5.
   Sharkey A, 2011, IEEE ROBOT AUTOM MAG, V18, P32, DOI 10.1109/MRA.2010.940151.
   Sharkey N, 2010, INTERACT STUD, V11, P161, DOI 10.1075/is.11.2.01sha.
   Shen TW, 2002, P ANN INT IEEE EMBS, P62.
   Sim HB, 2007, IEEE INT C ROB AUT W.
   Sparrow R., 2002, Ethics and Information Technology, V4, P305, DOI 10.1023/A:1021386708994.
   Tarafdar M, 2015, INFORM SYST J, V25, P103, DOI 10.1111/isj.12042.
   Tinwell A, 2015, INT J MECH ROBOTIC S, V2, P97, DOI DOI 10.1504/IJMRS.2015.068991.
   Togelius J, 2013, BELIEVABLE BOTS, P215.
   Tsiourti C, 2014, 8 INT C PERV COMP TE.
   UMPHRESS D, 1985, INT J MAN MACH STUD, V23, P263, DOI 10.1016/S0020-7373(85)80036-5.
   van der Dam S, 2012, HEALTH CARE ANAL, V20, P250, DOI 10.1007/s10728-011-0185-9.
   Verheul ER, 2007, LECT NOTES COMPUT SC, V4377, P49.
   Veruggio Gianmarco, 2005, IEEE INT C ROB AUT W.
   Wang YH, 2003, LECT NOTES COMPUT SC, V2688, P805.
   Weng YH, 2010, ADV ROBOTICS, V24, P1919, DOI 10.1163/016918610X527220.
   Wilkowska W, 2012, HEALTH INFORM J, V18, P191, DOI 10.1177/1460458212442933.
   Zizek D., 2002, ZIZEK READER.}},
Number-of-Cited-References = {{61}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{Digit. Health}},
Doc-Delivery-Number = {{VF0PG}},
Unique-ID = {{ISI:000441811800033}},
OA = {{DOAJ Gold, Green Published}},
DA = {{2020-06-17}},
}

@article{ ISI:000412554900002,
Author = {Omari, Rollin M. and Mohammadian, Masoud},
Title = {{Rule based fuzzy cognitive maps and natural language processing in
   machine ethics}},
Journal = {{JOURNAL OF INFORMATION COMMUNICATION \& ETHICS IN SOCIETY}},
Year = {{2016}},
Volume = {{14}},
Number = {{3}},
Pages = {{231-253}},
Abstract = {{Purpose - The developing academic field of machine ethics seeks to make
   artificial agents safer as they become more pervasive throughout
   society. In contrast to computer ethics, machine ethics is concerned
   with the behavior of machines toward human users and other machines.
   This study aims to use an action-based ethical theory founded on the
   combinational aspects of deontological and teleological theories of
   ethics in the construction of an artificial moral agent (AMA).
   Design/methodology/approach - The decision results derived by the AMA
   are acquired via fuzzy logic interpretation of the relative values of
   the steady-state simulations of the corresponding rule-based fuzzy
   cognitive map (RBFCM).
   Findings - Through the use of RBFCMs, the following paper illustrates
   the possibility of incorporating ethical components into machines, where
   latent semantic analysis (LSA) and RBFCMs can be used to model dynamic
   and complex situations, and to provide abilities in acquiring causal
   knowledge.
   Research limitations/implications - This approach is especially
   appropriate for data-poor and uncertain situations common in ethics.
   Nonetheless, to ensure that a machine with an ethical component can
   function autonomously in the world, research in artificial intelligence
   will need to further investigate the representation and determination of
   ethical principles, the incorporation of these ethical principles into a
   system's decision procedure, ethical decision-making with incomplete and
   uncertain knowledge, the explanation for decisions made using ethical
   principles and the evaluation of systems that act based upon ethical
   principles.
   Practical implications - To date, the conducted research has contributed
   to a theoretical foundation for machine ethics through exploration of
   the rationale and the feasibility of adding an ethical dimension to
   machines. Further, the constructed AMA illustrates the possibility of
   utilizing an action-based ethical theory that provides guidance in
   ethical decision-making according to the precepts of its respective
   duties. The use of LSA illustrates their powerful capabilities in
   understanding text and their potential application as information
   retrieval systems in AMAs. The use of cognitive maps provides an
   approach and a decision procedure for resolving conflicts between
   different duties.
   Originality/value - This paper suggests that cognitive maps could be
   used in AMAs as tools for meta-analysis, where comparisons regarding
   multiple ethical principles and duties can be examined and considered.
   With cognitive mapping, complex and abstract variables that cannot
   easily be measured but are important to decision-making can be modeled.
   This approach is especially appropriate for data-poor and uncertain
   situations common in ethics.}},
Publisher = {{EMERALD GROUP PUBLISHING LTD}},
Address = {{HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Mohammadian, M (Reprint Author), Univ Canberra, Fac Business Govt \& Law, Canberra, ACT, Australia.
   Omari, Rollin M., Australian Natl Univ, Sch Comp Sci, Canberra, ACT, Australia.
   Mohammadian, Masoud, Univ Canberra, Fac Business Govt \& Law, Canberra, ACT, Australia.}},
DOI = {{10.1108/JICES-10-2015-0034}},
ISSN = {{1477-996X}},
EISSN = {{1758-8871}},
Keywords = {{Decision making and ethics; Natural language processing in machine
   ethics; Rule based fuzzy cognitive maps}},
Keywords-Plus = {{LATENT SEMANTIC ANALYSIS; AGENT}},
Research-Areas = {{Social Sciences - Other Topics}},
Web-of-Science-Categories  = {{Ethics}},
Author-Email = {{masoudm991@gmail.com}},
Cited-References = {{Aizawa A, 2003, INFORM PROCESS MANAG, V39, P45, DOI 10.1016/S0306-4573(02)00021-3.
   Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Anderson M., 2004, P AAAI SAN JOS CA.
   Anderson M, 2007, AI MAG, V28, P15.
   Anderson M, 2006, IEEE INTELL SYST, V21, P56, DOI 10.1109/MIS.2006.64.
   Arkin R. C., 2008, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), P121.
   Beauchamp T., 2001, PRINCIPLES BIOMEDICA.
   Bostrum N., 2014, SUPERINTELLIGENCE PA.
   Carvalho J. P., 1999, COMP INT MOD CONTR A.
   Carvalho JP, 2000, PEACHFUZZ 2000 : 19TH INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS, P407, DOI 10.1109/NAFIPS.2000.877462.
   Carvalho JP, 1999, 18TH INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS, P115, DOI 10.1109/NAFIPS.1999.781665.
   Dehak N, 2010, ODYSSEY 2010: THE SPEAKER AND LANGUAGE RECOGNITION WORKSHOP, P71.
   Dickerson J. A., 1993, IEEE Virtual Reality Annual International Symposium (Cat. No.93CH3336-5), P471, DOI 10.1109/VRAIS.1993.380742.
   Dumais ST, 2004, ANNU REV INFORM SCI, V38, P189.
   EDEN C, 1992, J MANAGE STUD, V29, P309, DOI 10.1111/j.1467-6486.1992.tb00667.x.
   Foltz P. W., 1999, INTERACTIVE MULTIMED, V1.
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649.
   KLEIN JH, 1982, J OPER RES SOC, V33, P63, DOI 10.1057/jors.1982.7.
   KLEMA VC, 1980, IEEE T AUTOMAT CONTR, V25, P164, DOI 10.1109/TAC.1980.1102314.
   Kosko B., 1987, IEEE First International Conference on Neural Networks, P261.
   Kosko B., 1988, International Journal of Approximate Reasoning, V2, P377, DOI 10.1016/0888-613X(88)90111-9.
   Kosko B., 1992, FUZZY EXPERT SYSTEMS, P135.
   Kosko B., 1997, FUZZY ENG.
   Landauer TK, 1998, ADV NEUR IN, V10, P45.
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028.
   McCarthy J., 1969, READINGS ARTIFICIAL, P431.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Mouratiadou I, 2007, ECOL ECON, V62, P66, DOI 10.1016/j.ecolecon.2007.01.009.
   Ozesmi U., 2001, YUSUFELI BARAJI YENI, P154.
   Papageorgiou EI, 2005, J INTELL INF SYST, V25, P95, DOI 10.1007/s10844-005-0864-9.
   Reimann S, 1998, NEURAL NETWORKS, V11, P611, DOI 10.1016/S0893-6080(98)00001-X.
   Ross W. D., 1930, RIGHT GOOD.
   Shulman HC, 2009, REYN CASS 5 AS PAC C, P95.
   TABER R, 1991, EXPERT SYST APPL, V2, P83, DOI 10.1016/0957-4174(91)90136-3.
   Turing A, 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433.
   Weng YH, 2009, INT J SOC ROBOT, V1, P267, DOI 10.1007/s12369-009-0019-1.
   Yampolskiy R. V., 2013, ARTIF INTELL, P389.
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X.}},
Number-of-Cited-References = {{38}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{10}},
Journal-ISO = {{J. Inf. Commun. Ethics Soc.}},
Doc-Delivery-Number = {{FJ2KF}},
Unique-ID = {{ISI:000412554900002}},
DA = {{2020-06-17}},
}

@article{ ISI:000338009300007,
Author = {Goertzel, Ben},
Title = {{GOLEM: towards an AGI meta-architecture enabling both goal preservation
   and radical self-improvement}},
Journal = {{JOURNAL OF EXPERIMENTAL \& THEORETICAL ARTIFICIAL INTELLIGENCE}},
Year = {{2014}},
Volume = {{26}},
Number = {{3, SI}},
Pages = {{391-403}},
Abstract = {{A high-level artificial general intelligence (AGI) architecture called
   goal-oriented learning meta-architecture (GOLEM) is presented, along
   with an informal but careful argument that GOLEM may be capable of
   preserving its initial goals while radically improving its general
   intelligence. As a meta-architecture, GOLEM can be wrapped around a
   variety of different base-level AGI systems, and also has a role for a
   powerful narrow-AI subcomponent as a probability estimator. The
   motivation underlying these ideas is the desire to create AGI systems
   fulfilling the multiple criteria of being: massively and
   self-improvingly intelligent, probably beneficial and almost surely not
   destructive.}},
Publisher = {{TAYLOR \& FRANCIS LTD}},
Address = {{4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Goertzel, B (Reprint Author), Novamente LLC, 1405 Bernerd Pl, Rockville, MD 20851 USA.
   Novamente LLC, Rockville, MD 20851 USA.}},
DOI = {{10.1080/0952813X.2014.895107}},
ISSN = {{0952-813X}},
EISSN = {{1362-3079}},
Keywords = {{artificial general intelligence; machine ethics; superintelligence;
   self-modification}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{ben@goertzel.org}},
Cited-References = {{Goertzel B, 2010, MULTIVERSE ACCORDING.
   Goertzel B, 2009, PROCEEDINGS OF THE 8TH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, P60, DOI 10.1109/COGINF.2009.5250807.
   Legg S, 2007, MIND MACH, V17, P391, DOI 10.1007/s11023-007-9079-x.
   Schmidhuber J, 2006, CONNECT SCI, V18, P173, DOI 10.1080/09540090600768658.
   Sutton R. S., 1998, REINFORCEMENT LEARNI.}},
Number-of-Cited-References = {{5}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{19}},
Journal-ISO = {{J. Exp. Theor. Artif. Intell.}},
Doc-Delivery-Number = {{AJ9EF}},
Unique-ID = {{ISI:000338009300007}},
DA = {{2020-06-17}},
}

@article{ ISI:000248304200003,
Author = {Guarini, Marcello},
Title = {{Computation, coherence, and ethical reasoning}},
Journal = {{MINDS AND MACHINES}},
Year = {{2007}},
Volume = {{17}},
Number = {{1}},
Pages = {{27-46}},
Month = {{MAR}},
Abstract = {{Theories of moral, and more generally, practical reasoning sometimes
   draw on the notion of coherence. Admirably, Paul Thagard has attempted
   to give a computationally detailed account of the kind of coherence
   involved in practical reasoning, claiming that it will help overcome
   problems in foundationalist approaches to ethics. The arguments herein
   rebut the alleged role of coherence in practical reasoning endorsed by
   Thagard. While there are some general lessons to be learned from the
   preceding, no attempt is made to argue against all forms of coherence in
   all contexts. Nor is the usefulness of computational modelling called
   into question. The point will be that coherence cannot be as useful in
   understanding moral reasoning as coherentists may think. This result has
   clear implications for the future of Machine Ethics, a newly emerging
   subfield of AI.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Guarini, M (Reprint Author), Univ Windsor, Dept Philosophy, 401 Sunset, Windsor, ON N9B 3P4, Canada.
   Univ Windsor, Dept Philosophy, Windsor, ON N9B 3P4, Canada.}},
DOI = {{10.1007/s11023-007-9056-4}},
ISSN = {{0924-6495}},
EISSN = {{1572-8641}},
Keywords = {{coherentism; ethical reasoning; foundationalism; machine ethics;
   practical reasoning; underdetermination; robot ethics; unsupervised
   neural network}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{mguarini@uwindsor.ca}},
Cited-References = {{BonJour Laurence, 1985, STRUCTURE EMPIRICAL.
   GUARINI M, 2005, COMPUTING PHILOS COG, P99.
   GUARINI M, 2005, P 2005 INT C ART INT, V2, P676.
   Hare R.M., 1981, MORAL THINKING LEVEL.
   Holyoak K. J., 1995, MENTAL LEAPS ANALOGY.
   Millgram E, 1996, SYNTHESE, V108, P63, DOI 10.1007/BF00414005.
   Millgram E, 2000, J PHILOS, V97, P82, DOI 10.2307/2678447.
   Nowak G., 1992, PHILOS SCI COGNITIVE, P69.
   NOWAK G, 1992, MINNESOTA STUDIES PH, V15, P271.
   Sosa E, 1997, J PHILOS, V94, P410, DOI 10.2307/2564607.
   Thagard P, 1998, PHILOS PSYCHOL, V11, P405, DOI 10.1080/09515089808573270.
   THAGARD P, 1995, {[}No title captured], P439.
   Thagard P., 1992, CONCEPTUAL REVOLUTIO.
   Thagard P., 2000, COHERENCE THOUGHT AC.
   THAGARD P, 1992, MINN STUD PHILOS SCI, V15, P485.}},
Number-of-Cited-References = {{15}},
Times-Cited = {{4}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Minds Mach.}},
Doc-Delivery-Number = {{193VV}},
Unique-ID = {{ISI:000248304200003}},
DA = {{2020-06-17}},
}

@article{ ISI:000460669800010,
Author = {Spiekermann, Sarah and Korunovska, Jana and Langheinrich, Marc},
Title = {{Inside the Organization: Why Privacy and Security Engineering Is a
   Challenge for Engineers}},
Journal = {{PROCEEDINGS OF THE IEEE}},
Year = {{2019}},
Volume = {{107}},
Number = {{3, SI}},
Pages = {{600-615}},
Month = {{MAR}},
Abstract = {{Machine ethics is a key challenge in times when digital systems play an
   increasing role in people's lives. At the core of machine ethics is the
   handling of personal data and the security of machine operations. Yet,
   privacy and security engineering are a challenge in today's business
   world where personal data markets, corporate deadlines, and a lack of
   perfectionism frame the context in which engineers need to work. Besides
   these organizational and market challenges, each engineer has his or her
   specific view on the importance of these values that can foster or
   inhibit taking them into consideration. We present the results of an
   empirical study of 124 engineers based on the Theory of Planned Behavior
   and Jonas' Principle of Responsibility to understand the drivers and
   impediments of ethical system development as far as privacy and security
   engineering are concerned. We find that many engineers find the two
   values important, but do not enjoy working on them. We also find that
   many struggle with the organizational environment: They face a lack of
   time and autonomy that is necessary for building ethical systems, even
   at this basic level. Organizations' privacy and security norms are often
   too weak or even oppose value-based design, putting engineers in
   conflict with their organizations. Our data indicate that it is largely
   engineers' individually perceived responsibility as well as a few
   character traits that make a positive difference to ethical system
   development.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Spiekermann, S (Reprint Author), Vienna Univ Econ \& Business WU, Dept Informat Syst \& Operat, Inst Informat Syst \& Soc, A-1020 Vienna, Austria.
   Spiekermann, Sarah; Korunovska, Jana, Vienna Univ Econ \& Business WU, Dept Informat Syst \& Operat, Inst Informat Syst \& Soc, A-1020 Vienna, Austria.
   Langheinrich, Marc, USI, Res Grp Ubiquitous Comp, CH-6900 Lugano, Switzerland.}},
DOI = {{10.1109/JPROC.2018.2866769}},
ISSN = {{0018-9219}},
EISSN = {{1558-2256}},
Keywords = {{Engineering behavior; ethics; privacy; responsibility; security;
   value-based design; values}},
Keywords-Plus = {{BEHAVIOR; METAANALYSIS; EFFICACY; LOCUS; SELF}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{sspiek@wu.ac.at}},
ORCID-Numbers = {{Korunovska, Jana/0000-0002-3220-5372
   Langheinrich, Marc/0000-0002-8834-7388}},
Cited-References = {{Acquisti A., 2006, ICIS 2006 P, P94.
   Acquisti A, 2015, SCIENCE, V347, P509, DOI 10.1126/science.aaa1465.
   Ajzen I, 2005, HANDBOOK OF ATTITUDES, P173.
   Ajzen I, 2002, J APPL SOC PSYCHOL, V32, P665, DOI 10.1111/j.1559-1816.2002.tb00236.x.
   AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T.
   Ajzen I, 1985, ACTION CONTROL COGNI, P11, DOI DOI 10.1007/978-3-642-69746-3\_2.
   Ajzen I., 2006, TECH REP.
   Americans and Cyberscecurity Pew Res. Center Washington DC USA, 2017, TECH REP.
   Anderson R.J., 2010, SECURITY ENG GUIDE B.
   {[}Anonymous], 2011, PERSONAL DATA EMERGE.
   {[}Anonymous], 2012, 15408 ISOIEC.
   {[}Anonymous], 2013, PRIV EXP GROUP REP R.
   {[}Anonymous], 2011, TECH REP.
   {[}Anonymous], 2017, 2017 DATA BREACH INV.
   Arbuckle J. L., 2011, IBM SPSS AMOS 20 USE.
   Armitage CJ, 2001, BRIT J SOC PSYCHOL, V40, P471, DOI 10.1348/014466601164939.
   Balebako R., 2014, TECH REP.
   Bednar K., INF SOC.
   Berenbach B, 2009, COMPUTER, V42, P74, DOI 10.1109/MC.2009.22.
   Bergkvist L, 2007, J MARKETING RES, V44, P175, DOI 10.1509/jmkr.44.2.175.
   Camenisch J., 2005, P 2005 WORKSH DIG ID, P20, DOI DOI 10.1145/1102486.1102491.
   Cavoukian A., 2011, TECH REP.
   Cavoukian A., 2012, PRIVACY PROTECTION M, P170.
   Cavusoglu H., 2004, COMMUNICATIONS ASS I, V14, P65.
   Christl Wolfie., 2017, CORPORATE SURVEILLAN.
   Cochrane B, 2000, SOVEREIGN MAG, P56.
   Craft JL, 2013, J BUS ETHICS, V117, P221, DOI 10.1007/s10551-012-1518-9.
   Cranor L. F., 2006, ACM Transactions on Computer-Human Interaction, V13, P135, DOI 10.1145/1165734.1165735.
   Cranor L. F., 2006, TECH REP.
   Drolet A.L., 2001, J SERV RES-US, V3, P196, DOI DOI 10.1177/109467050133001.
   Fishburn P C., 1970, TECH REP.
   Fleischmann KR, 2010, COMPUTER, V43, P57, DOI 10.1109/MC.2010.120.
   Friedman B, 2002, HUM FAC ER, P1177.
   Glasman LR, 2006, PSYCHOL BULL, V132, P778, DOI 10.1037/0033-2909.132.5.778.
   Gosling SD, 2003, J RES PERS, V37, P504, DOI 10.1016/S0092-6566(03)00046-1.
   Greene D, 2018, NEW MEDIA SOC, V20, P1640, DOI 10.1177/1461444817702397.
   HANSON VL, 2017, ACM, V60, P7, DOI DOI 10.1145/3047268.
   Heller C, 2011, POSTPRIVACY PRIMA LE.
   Hoffman D., 2014, HARVARD BUS REV, V18, P2.
   Identity Theft Resource Center, 2017, IDENTITY THEFT RESOU.
   Jonas H., 1979, PRINZIP VERANTWORTUN, V3492.
   JONES TM, 1991, ACAD MANAGE REV, V16, P366, DOI 10.2307/258867.
   Kalloniatis C, 2008, REQUIR ENG, V13, P241, DOI 10.1007/s00766-008-0067-3.
   Kessler R., 2013, POLITICO.
   KIM MS, 1993, J COMMUN, V43, P101, DOI 10.1111/j.1460-2466.1993.tb01251.x.
   Kish-Gephart JJ, 2010, J APPL PSYCHOL, V95, P1, DOI 10.1037/a0017103.
   Kohlberg L, 1969, HDB SOCIALIZATION EN.
   Krumay B., 2011, 2011 Sixth International Conference on Availability, Reliability and Security, P313, DOI 10.1109/ARES.2011.53.
   Kurkovsky S, 2010, INT SYMP TECHNOL SOC, P441, DOI 10.1109/ISTAS.2010.5514610.
   Lahlou S, 2005, COMMUN ACM, V48, P59, DOI 10.1145/1047671.1047705.
   Land F., 2004, 9 SCH EC.
   Layman L., 2006, SIGCSE Bulletin, V38, P428, DOI 10.1145/1124706.1121474.
   LEVENSON H, 1973, J CONSULT CLIN PSYCH, V41, P397, DOI 10.1037/h0035357.
   Mayes G. R, 2010, AAAI SPRING S INT IN, P125.
   McGrath John Edward, 2004, LOVING BIG BROTHER P.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Mouratidis H, 2012, J UNIVERS COMPUT SCI, V18, P1608.
   Murdock TB, 2001, CONTEMP EDUC PSYCHOL, V26, P96, DOI 10.1006/ceps.2000.1046.
   Pascual A., 2016, TECH REP.
   Richardson M.E.J., 2004, HAMMURABIS LAWS TEXT.
   Rouvroy A, 2009, REINVENTING DATA PROTECTION, P45, DOI 10.1007/978-1-4020-9498-9\_2.
   Schaefer R., 2006, ACM SIGSOFT SOFTWARE, V31, P1, DOI DOI 10.1145/1142958.1142962.
   Scheler M., 1973, FORMALISM ETHICS NON.
   Schermelleh-Engel K., 2003, METHODS PSYCHOL RES, V8, P23, DOI DOI 10.1002/0470010940.
   SCHOEMAKER PJH, 1982, J ECON LIT, V20, P529.
   Security and Privacy Controls for Federal Information Systems and Organizations, 2013, 80053 NIST US DEP CO.
   Sharkey N, 2018, IEEE ROBOT AUTOM MAG, V25, P26, DOI 10.1109/MRA.2017.2787225.
   Shaw TR, 2003, J BUS ETHICS, V46, P301, DOI 10.1023/A:1025628530013.
   Shilton K., 2017, J BUS ETHICS, P1.
   Shilton K, 2013, SCI TECHNOL HUM VAL, V38, P374, DOI 10.1177/0162243912436985.
   Smith HJ, 2003, INFORM SYST J, V13, P69, DOI 10.1046/j.1365-2575.2003.00139.x.
   Sojer M, 2014, J MANAGE INFORM SYST, V31, P287, DOI 10.1080/07421222.2014.995563.
   Sokolowski K., 2010, J PERS ASSESS, V74, P126.
   Solove D., 2008, UNDERSTANDING PRIVAC, V13, P515.
   Solove DJ, 2006, U PENN LAW REV, V154, P477, DOI 10.2307/40041279.
   Sommerville I., 2011, SOFTWARE ENG.
   Spiekermann S, 2016, ETHICAL IT INNOVATION: A VALUE-BASED SYSTEM DESIGN APPROACH, P1.
   Spiekermann S, 2009, IEEE T SOFTWARE ENG, V35, P67, DOI 10.1109/TSE.2008.88.
   Szekely I., 2011, INTERNET SURVEILLANC.
   Thau S, 2015, J APPL PSYCHOL, V100, P98, DOI 10.1037/a0036708.
   Toxen B, 2014, COMMUN ACM, V57, P44, DOI 10.1145/2594502.
   Vallor S, 2016, TECHNOLOGY VIRTUES P.
   Vanderelst D., 2016, DARK SIDE ETHICAL RO.
   W E. Forum, 2012, RES REP.
   Wilkes R.E., 1986, J ACAD MARKET SCI, V14, P47, DOI DOI 10.1007/BF02722112.
   Williams MJ, 2014, J MANAGE, V40, P1365, DOI 10.1177/0149206314525203.
   Zetter K., 2016, WIRED.
   Zimmermann B, 1995, OFFICIAL PGP USERS G.}},
Number-of-Cited-References = {{88}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Proc. IEEE}},
Doc-Delivery-Number = {{HO1ME}},
Unique-ID = {{ISI:000460669800010}},
DA = {{2020-06-17}},
}

@article{ ISI:000428628900004,
Author = {Ojha, Suman and Williams, Mary-Anne and Johnston, Benjamin},
Title = {{The Essence of Ethical Reasoning in Robot-Emotion Processing}},
Journal = {{INTERNATIONAL JOURNAL OF SOCIAL ROBOTICS}},
Year = {{2018}},
Volume = {{10}},
Number = {{2, SI}},
Pages = {{211-223}},
Month = {{APR}},
Abstract = {{As social robots become more and more intelligent and autonomous in
   operation, it is extremely important to ensure that such robots act in
   socially acceptable manner. More specifically, if such an autonomous
   robot is capable of generating and expressing emotions of its own, it
   should also have an ability to reason if it is ethical to exhibit a
   particular emotional state in response to a surrounding event. Most
   existing computational models of emotion for social robots have focused
   on achieving a certain level of believability of the emotions expressed.
   We argue that believability of a robot's emotions, although crucially
   necessary, is not a sufficient quality to elicit socially acceptable
   emotions. Thus, we stress on the need of higher level of cognition in
   emotion processing mechanism which empowers social robots with an
   ability to decide if it is socially appropriate to express a particular
   emotion in a given context or it is better to inhibit such an
   experience. In this paper, we present the detailed mathematical
   explanation of the ethical reasoning mechanism in our computational
   model, EEGS, that helps a social robot to reach to the most socially
   acceptable emotional state when more than one emotions are elicited by
   an event. Experimental results show that ethical reasoning in EEGS helps
   in the generation of believable as well as socially acceptable emotions.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ojha, S (Reprint Author), Univ Technol Sydney, CAI, Sydney, NSW, Australia.
   Ojha, Suman; Williams, Mary-Anne; Johnston, Benjamin, Univ Technol Sydney, CAI, Sydney, NSW, Australia.}},
DOI = {{10.1007/s12369-017-0459-y}},
ISSN = {{1875-4791}},
EISSN = {{1875-4805}},
Keywords = {{Social robots; Computational emotion model; Believability; Ethical
   reasoning; Socially acceptable emotions; EEGS}},
Keywords-Plus = {{DECISION-MAKING; MACHINE ETHICS; MODEL; AGENT}},
Research-Areas = {{Robotics}},
Web-of-Science-Categories  = {{Robotics}},
Author-Email = {{Suman.Ojha@student.uts.edu.au
   Mary-Anne.Williams@uts.edu.au
   Benjamin.Johnston@uts.edu.au}},
ResearcherID-Numbers = {{Ojha, Suman/P-2664-2016}},
ORCID-Numbers = {{Ojha, Suman/0000-0003-4856-8335}},
Funding-Acknowledgement = {{University of Technology Sydney}},
Funding-Text = {{This research was funded by the Research Scholarship provided by the
   University of Technology Sydney. There is no external funding associated
   with this research.}},
Cited-References = {{Alexander Larry, 2007, STANFORD ENCY PHILOS.
   Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83.
   Anderson M, 2007, AI MAG, V28, P15.
   Bartneck C., 2003, P 2003 INT C DES PLE, P55, DOI {[}DOI 10.1145/782896.782911, 10.1145/782896.782911].
   Becker-Asano C., 2008, WASABI AFFECT SIMULA, V319.
   Breazeal C, 2003, INT J HUM-COMPUT ST, V59, P119, DOI 10.1016/S1071-5819(03)00018-1.
   CALLAHAN S, 1988, HASTINGS CENT REP, V18, P9, DOI 10.2307/3562196.
   Dias Joao, 2014, Emotion Modeling. Towards Pragmatic Computational Models of Affective Processes. LNCS 8750, P44, DOI 10.1007/978-3-319-12973-0\_3.
   El-Nasr MS, 2000, AUTON AGENT MULTI-AG, V3, P219, DOI 10.1023/A:1010030809960.
   Gaudine A, 2001, J BUS ETHICS, V31, P175, DOI 10.1023/A:1010711413444.
   Gebhard P, 2005, P 4 INT JOINT C AUT, P29, DOI DOI 10.1145/1082473.1082478.
   Gratch J., 2004, COGNITIVE SYSTEMS RE, V5, P269, DOI DOI 10.1016/J.C0GSYS.2004.02.002.
   Hooker J, 1996, 3 KINDS ETHICS.
   ISEN AM, 1983, SOC COGNITION, V2, P18, DOI 10.1521/soco.1983.2.1.18.
   Kopp S, 2003, KI, P11.
   Lambie JA, 2002, PSYCHOL REV, V109, P219, DOI 10.1037//0033-295X.109.2.219.
   Le Blanc AD, 1999, US Patent, Patent No. {[}5,977,968, 5977968].
   Marinier RP, 2007, P COGN SCI SOC, V29.
   Marreiros G, 2010, IEEE INTELL SYST, V25, P31, DOI 10.1109/MIS.2010.46.
   Marsella S, 2010, BLUEPRINT AFFECTIVE, P21.
   Marsella SC, 2009, COGN SYST RES, V10, P70, DOI 10.1016/j.cogsys.2008.03.005.
   Ojha S, 2017, ANN C ADV COGN SYST.
   Ojha S., 2017, ANN M COGN SCI SOC.
   Ojha S, 2016, LECT NOTES ARTIF INT, V9979, P233, DOI 10.1007/978-3-319-47437-3\_23.
   Ortony A., 1990, COGNITIVE STRUCTURE.
   Padgham L, 1997, INT WORKSH INT AG SY.
   Plutchik R, 1997, CIRCUMPLEX MODELS PE.
   Quinton Anthony, 1973, UTILITARIAN ETHICS.
   Reilly WN, 2006, S AG CONSTR EM.
   Reilly WS, 1996, TECH REP.
   Scherer Klaus R., 2001, APPRAISAL PROCESSES, V92, P57.
   White J, 2015, RETHINKING MACHINE E.}},
Number-of-Cited-References = {{33}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{21}},
Journal-ISO = {{Int. J. Soc. Robot.}},
Doc-Delivery-Number = {{GA8YY}},
Unique-ID = {{ISI:000428628900004}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000510018100033,
Author = {Kim, Richard and Kleiman-Weiner, Max and Abeliuk, Andres and Awad,
   Edmond and Dsouza, Sohan and Tenenbaum, Joshua B.},
Book-Group-Author = {{ACM}},
Title = {{A Computational Model of Commonsense Moral Decision Making}},
Booktitle = {{PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY
   (AIES'18)}},
Year = {{2018}},
Pages = {{197-203}},
Note = {{AAAI/ACM Conference on AI, Ethics, and Society (AIES), New Orleans, LA,
   FEB 02-03, 2018}},
Organization = {{AAAI; Assoc Comp Machinery; ACM SIGAI; Berkeley Existential Risk
   Initiat; DeepMind Eth \& Soc; Future Life Inst; IBM Res AI;
   PriceWaterhouse Coopers; Tulane Univ}},
Abstract = {{We introduce a computational model for building moral autonomous
   vehicles by learning and generalizing from human moral judgments. We
   draw on a cognitively inspired model of how people and young children
   learn moral theories from sparse and noisy data and integrate
   observations made from different people in different groups. The problem
   of moral learning for autonomous vehicles is cast as learning how to
   weigh the different features of the dilemma using utility calculus, with
   the goal of making these trade-offs reflect how people make them in a
   wide variety of moral dilemma. By modeling the structures of individuals
   and groups in a hierarchical Bayesian model, we show that an
   individual's moral values - as well as a group's shared values - can be
   inferred from sparse and noisy data. We evaluate our approach with data
   from the Moral Machine, a web application that collects human judgments
   on moral dilemmas involving autonomous vehicles, and show that the model
   rapidly and accurately infers people's preferences and can predict the
   difficulty of moral dilemmas from limited data.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Kim, R (Reprint Author), MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   Kim, Richard; Kleiman-Weiner, Max; Abeliuk, Andres; Awad, Edmond; Dsouza, Sohan; Tenenbaum, Joshua B., MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.}},
DOI = {{10.1145/3278721.3278770}},
ISBN = {{978-1-4503-6012-8}},
Keywords = {{Artificial Intelligence; Machine Ethics; Moral Learning; Bayesian
   Inference}},
Research-Areas = {{Computer Science; Biomedical Social Sciences}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Social Sciences, Biomedical}},
Author-Email = {{kimr@mit.edu
   maxkw@mit.edu
   aabeliuk@mit.edu
   awad@mit.edu
   dsouza@mit.edu
   jbt@mit.edu}},
ResearcherID-Numbers = {{Abeliuk, Andres/AAN-9174-2020
   }},
ORCID-Numbers = {{Abeliuk, Andres/0000-0002-8158-4647
   /0000-0002-6067-3659}},
Cited-References = {{Baron J, 2017, MEM COGNITION, V45, P566, DOI 10.3758/s13421-016-0686-8.
   Bentham Jeremy, 1789, INTRO PRINCIPLES MOR, DOI {[}10.1111/j.2048-416X.2000.tb00070.x, DOI 10.1111/J.2048-416X.2000.TB00070.X].
   Blake PR, 2015, NATURE, V528, P258, DOI 10.1038/nature15703.
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654.
   Cain N, 2012, CURR OPIN NEUROBIOL, V22, P1047, DOI 10.1016/j.conb.2012.04.013.
   Carey S, 2009, ORIGIN CONCEPTS.
   Felbo Bjarke, 2017, C EMP METH NAT LANG.
   Gelman A, 2013, BAYESIAN DATA ANAL.
   Ghahramani Zoubin, 2005, ADV NEURAL INFORM PR, V18.
   Goodman B., 2016, EUROPEAN UNION REGUL.
   Gopnik Alison, 1997, WORDS THOUGHTS THEOR, P268.
   Graham J, 2009, J PERS SOC PSYCHOL, V96, P1029, DOI 10.1037/a0015141.
   Henrich J, 2001, AM ECON REV, V91, P73, DOI 10.1257/aer.91.2.73.
   House BR, 2013, P NATL ACAD SCI USA, V110, P14586, DOI 10.1073/pnas.1221217110.
   Kleiman-Weiner M, 2017, COGNITION, V167, P107, DOI 10.1016/j.cognition.2017.03.005.
   Kohlberg L., 1981, PHILOS MORAL DEV.
   Lei T, 2016, RATIONALIZING NEURAL.
   Lewandowski D, 2009, J MULTIVARIATE ANAL, V100, P1989, DOI 10.1016/j.jmva.2009.04.008.
   Mikhail J, 2007, TRENDS COGN SCI, V11, P143, DOI 10.1016/j.tics.2006.12.007.
   Mikhail John, 2011, ELEMENTS MORAL COGNI, DOI {[}10.1017/CBO9780511780578, DOI 10.1017/CBO9780511780578].
   Noothigattu R., 2017, VOTING BASED SYSTEM.
   Oord A. V. D., 2016, WAVENET GENERATIVE M, P1.
   Rai Piyush, 2009, ADV NEURAL INFORM PR, V21, P1321.
   Ratcliff R, 2008, NEURAL COMPUT, V20, P873, DOI 10.1162/neco.2008.12-06-420.
   Santoro A., 2016, ONE SHOT LEARNING ME.
   Smith PL, 2004, TRENDS NEUROSCI, V27, P161, DOI 10.1016/j.tins.2004.01.006.
   Szegedy C, GOING DEEPER CONVOLU.
   Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788.
   Vinyals Oriol, 2016, MATCHING NETWORKS ON.
   Wu Y., 2016, GOOGLES NEURAL MACHI.}},
Number-of-Cited-References = {{30}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BO3EM}},
Unique-ID = {{ISI:000510018100033}},
DA = {{2020-06-17}},
}

@article{ ISI:000410884000005,
Author = {Cooper, Ricky and Seddon, Jonathan and Van Vliet, Ben},
Title = {{High-frequency trading and conflict in the financial markets}},
Journal = {{JOURNAL OF INFORMATION TECHNOLOGY}},
Year = {{2017}},
Volume = {{32}},
Number = {{3, 1}},
Pages = {{270-282}},
Month = {{SEP}},
Abstract = {{The last few decades has seen an ever-increasing growth in the way
   activities are productized and associated with a financial cost. This
   phenomenon, termed financialization, spans all areas including
   government, finance, health and manufacturing. Recent developments
   within finance over that past decade have radically altered the way
   trading occurs. This paper analyses high-frequency trading (HFT) as a
   necessary component of the infrastructure that makes financialization
   possible. Through interviews with HFT firms, a software vendor,
   regulators and banks, the effects of HFT on market efficiency, and its
   impact on costs to long-term investors are explored. This paper
   contributes to the literature by exploring the conflict that exists
   between HFT and traditional market makers in today's fragmented markets.
   This paper argues that society should be unconcerned with this conflict
   and should instead focus on the effects these participants have on the
   long-term investors, for whom the markets ultimately exist. In order to
   facilitate the best outcomes, regulation should be simple, aimed at
   keeping participants' behavior stable, and the interactions among them
   transparent and straightforward. Financialization and HFT are
   inextricably linked, and society is best served by ensuring that the
   creative energy of these market participants is directed on providing
   liquidity and removing inefficiencies.}},
Publisher = {{PALGRAVE MACMILLAN LTD}},
Address = {{BRUNEL RD BLDG, HOUNDMILLS, BASINGSTOKE RG21 6XS, HANTS, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Seddon, J (Reprint Author), Audencia Business Sch, 8 Route Joneliere,BP 31222, F-44312 Nantes 3, France.
   Cooper, Ricky; Van Vliet, Ben, IIT, Stuart Sch Business, 565 W Adams, Chicago, IL 60661 USA.
   Seddon, Jonathan, Audencia Business Sch, 8 Route Joneliere,BP 31222, F-44312 Nantes 3, France.}},
DOI = {{10.1057/s41265-016-0031-5}},
ISSN = {{0268-3962}},
EISSN = {{1466-4437}},
Keywords = {{high-frequency trading; liquidity; regulation; market maker}},
Keywords-Plus = {{MACHINE ETHICS; PRICE DISCOVERY; LIQUIDITY; COMPETITION; EVOLUTION;
   QUALITY}},
Research-Areas = {{Computer Science; Information Science \& Library Science; Business \&
   Economics}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Information Science \& Library
   Science; Management}},
Author-Email = {{rcooper3@iit.edu
   jseddon@audencia.com
   bvanvliet@stuart.iit.edu}},
Cited-References = {{Alan NS, 2013, J PORTFOLIO MANAGE, V40, P124, DOI 10.3905/jpm.2013.40.1.124.
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83.
   Anand A, 2005, J FINANC MARK, V8, P288, DOI 10.1016/j.finmar.2005.03.001.
   Anand A, 2009, J FINANC QUANT ANAL, V44, P1427, DOI 10.1017/S0022109009990421.
   Anderson M, 2007, AI MAG, V28, P15.
   Angel JJ, 2011, Q J FINANC, V1, P1, DOI 10.1142/S2010139211000067.
   {[}Anonymous], 2010, WALL STREET J.
   {[}Anonymous], 2012, WALL STREET J.
   Asimov Isaac, 1942, ASTOUNDING SCI FICTI, P94.
   Benos E., 2012, BANK ENGLAND Q B, V4, P343.
   Bessembinder H, 2003, J FINANC QUANT ANAL, V38, P747, DOI 10.2307/4126742.
   Blocher J, 2016, J TRADING, V11, P6, DOI 10.3905/jot.2016.11.3.006.
   Bloomfield R, 2005, J FINANC ECON, V75, P165, DOI 10.1016/j.jfineco.2004.07.001.
   Boehmer E., 2014, AM FIN ASS 2013 SAN.
   Bondarenko Oleg, 2001, J FINANCIAL MARKETS, V4, P269, DOI DOI 10.1016/S1386-4181(01)00014-3.
   Brogaard J., 2011, ACTIVITY HIGH FREQUE.
   Brogaard J., 2010, HIGH FREQUENCY TRADI.
   Brogaard J, 2014, REV FINANC STUD, V27, P2267, DOI 10.1093/rfs/hhu032.
   Cao C, 2009, J FUTURES MARKETS, V29, P16, DOI 10.1002/fut.20334.
   Carlo JL, 2011, INFORM SYST J, V21, P91, DOI 10.1111/j.1365-2575.2009.00345.x.
   Castura J., 2010, WORKING PAPER, P1.
   Cooper R, 2015, ALGORITHMIC FINANC, V4, P53, DOI 10.3233/AF-150043.
   Cooper R, 2016, BUS ETHICS Q, V26, P1, DOI 10.1017/beq.2015.41.
   Cooper RA, 2012, J TRADING, V7, P57, DOI 10.3905/jot.2012.7.2.057.
   Davis M, 2013, SCI ENG ETHICS, V19, P851, DOI 10.1007/s11948-012-9412-5.
   Dehning B., 2003, MIS Q, V34, P717.
   Easley D, 2012, J PORTFOLIO MANAGE, V39, P19, DOI 10.3905/jpm.2012.39.1.019.
   Easley D, 2011, J PORTFOLIO MANAGE, V37, P118, DOI 10.3905/jpm.2011.37.2.118.
   EISENHARDT KM, 1989, ACAD MANAGE REV, V14, P532, DOI 10.2307/258557.
   Epstein G. A., 2005, FINANCIALIZATION WOR.
   FAMA EF, 1965, J BUS, V38, P34, DOI 10.1086/294743.
   FAMA EF, 1970, J FINANC, V25, P383, DOI 10.2307/2325486.
   Freedman R, 2006, INTRO FINANCIAL TECH.
   GLOSTEN LR, 1987, J FINANC, V42, P1293, DOI 10.2307/2328528.
   Gomber P, 2011, HIGH FREQUENCY TRADI.
   GROSSMAN SJ, 1988, J FINANC, V43, P617, DOI 10.2307/2328186.
   HASBROUCK J, 1995, J FINANC, V50, P1175, DOI 10.2307/2329348.
   Hasbrouck J, 2013, J FINANC MARK, V16, P646, DOI 10.1016/j.finmar.2013.05.003.
   Hein E., 2012, MACROECONOIMIC FINAN.
   Hendershott T, 2013, J FINANC QUANT ANAL, V48, P1001, DOI 10.1017/S0022109013000471.
   Hendershott T, 2011, J FINANC, V66, P1, DOI 10.1111/j.1540-6261.2010.01624.x.
   HO TSY, 1983, J FINANC, V38, P1053, DOI 10.2307/2328011.
   Hurlburt George F, 2009, IT Professional, V11, P14, DOI 10.1109/MITP.2009.2.
   Jones C.M., 2013, WHAT DO WE KNOW HIGH.
   KATZ ML, 1985, AM ECON REV, V75, P424.
   Kraemer F, 2011, ETHICS INF TECHNOL, V13, P251, DOI 10.1007/s10676-010-9233-7.
   Krippner G., 2011, CAPITALIZING CRISIS.
   Kumiega A, 2016, J TRADING, V11, P71, DOI 10.3905/jot.2016.11.2.071.
   Kumiega A, 2014, QUANT FINANC, V14, P383, DOI 10.1080/14697688.2013.787492.
   Loebbecke C, 2015, J STRATEGIC INF SYST, V24, P149, DOI 10.1016/j.jsis.2015.08.002.
   London Stock Exchange (LSE), 2015, RUL LOND STOCK EXCH.
   Lyytinen K, 2003, MIS QUART, V27, P557.
   MacKenzie D., 2014, SOCIOLOGY ALGORITHMS.
   Markus L, 2006, MIS QUART, V30, P439.
   Menkveld AJ, 2013, J FINANC MARK, V16, P712, DOI 10.1016/j.finmar.2013.06.006.
   Menkveld AJ, 2013, J FINANC MARK, V16, P571, DOI 10.1016/j.finmar.2012.12.003.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   New York Stock Exchange (NYSE), 2014, DES MARK MAK.
   O'Hara M, 2015, J FINANC ECON, V116, P257, DOI 10.1016/j.jfineco.2015.01.003.
   Palley T. I, 2007, 525 LEV EC I BARD CO.
   Panayides MA, 2007, J FINANC ECON, V86, P513, DOI 10.1016/j.jfineco.2006.11.002.
   Philips K, 1994, ARROGANT CAPITAL WAS.
   Ramaswamy S., 2009, AUTOMATION ETHICS SP.
   Seddon J. J. M., 2016, J BUS RES, V61, P1.
   Silverman D., 2011, INTERPRETING QUALITA.
   STOLL HR, 1978, J FINANC, V33, P1133, DOI 10.2307/2326945.
   STRAUB DW, 1989, COMMUN ACM, V32, P1328, DOI 10.1145/68814.68818.
   TABB Forum, 2015, ITS NOT EAS BEING EQ.
   Turbeville W., 2013, FINANCIALIZATION NEW.
   Van Vliet B, 2013, J TRADING, V8, P102, DOI 10.3905/jot.2013.8.3.102.
   Woerner SL, 2015, J INF TECHNOL, V30, P60, DOI 10.1057/jit.2014.31.}},
Number-of-Cited-References = {{71}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{22}},
Journal-ISO = {{J. Inf. Technol.}},
Doc-Delivery-Number = {{FH1FB}},
Unique-ID = {{ISI:000410884000005}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000407376900004,
Author = {Bringsjord, Selmer},
Editor = {{Ferreira, MIA and Sequeira, JS and Tokhi, MO and Kadar, EE and Virk, GS}},
Title = {{A 21st-Century Ethical Hierarchy for Robots and Persons: EH}},
Booktitle = {{WORLD WITH ROBOTS}},
Series = {{Intelligent Systems Control and Automation Science and Engineering}},
Year = {{2017}},
Volume = {{84}},
Pages = {{47-61}},
Note = {{International Conference on Robot Ethics (ICRE), Lisbon, PORTUGAL, OCT
   23-24, 2015}},
Organization = {{Lisbon Univ, Ctr Philosophy \& Inst Super Tecnico; Lisbon Tourism,
   Portugal}},
Abstract = {{I introduce and propose the ethical hierarchy (EH) into which can be
   placed robots and humans in general. This hierarchy is catalyzed by the
   question: Can robots be more moral than humans? The light shed by EH
   reveals why an emphasis on legal obligation for robots, while not unwise
   at the moment, is inadequate, and why at least the vast majority of
   today's state-of-the-art deontic logics are morally inexpressive,
   whether they are intended to formalize the ethical behavior of robots or
   persons.}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Bringsjord, S (Reprint Author), RPI, Dept Cognit Sci, Dept Comp Sci, Rensselaer AI \& Reasoning RAIR Lab, Troy, NY 12180 USA.
   Bringsjord, Selmer, RPI, Dept Cognit Sci, Dept Comp Sci, Rensselaer AI \& Reasoning RAIR Lab, Troy, NY 12180 USA.}},
DOI = {{10.1007/978-3-319-46667-5\_4}},
ISBN = {{978-3-319-46667-5; 978-3-319-46665-1}},
Keywords = {{Robot ethics; Machine ethics; Ethics; Deontic logic; Ethical hierarchy}},
Research-Areas = {{Computer Science; Social Sciences - Other Topics; History \& Philosophy
   of Science; Robotics}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Ethics; History \& Philosophy Of
   Science; Robotics}},
Author-Email = {{selmer@rpi.edu}},
Funding-Acknowledgement = {{U.S. ONROffice of Naval Research}},
Funding-Text = {{Bringsjord is profoundly grateful for support provided by two grants
   from U.S. ONR to explore robot ethics, and to co-investigators M.
   Scheutz (PI, MURI; Tufts University), B. Malle (Co-PI, MURI; Brown
   University), M. Sei (Co-PI, MURI; RPI), and R. Sun (PI, Moral Dilemmas;
   RPI) for invaluable collaboration of the highest order.}},
Cited-References = {{Arkin R. C., 2009, GOVERNING LETHAL BEH.
   Arkoudas K., 2005, MACHINE ETHICS, P17.
   Bello P, 2005, THESIS.
   Bello P, 2013, TOPOI-INT REV PHILOS, V32, P251, DOI 10.1007/s11245-012-9129-8.
   BLOCK N, 1995, BEHAV BRAIN SCI, V18, P227, DOI 10.1017/S0140525X00038188.
   Bringsjord S, 1998, MIND MACH, V8, P273.
   Bringsjord S, 1999, PHILOS PHENOMEN RES, V59, P41, DOI 10.2307/2653457.
   Bringsjord S, 2008, P 8 INT WORKSH COMP, P1.
   BRINGSJORD S, 1992, {[}No title captured].
   Bringsjord S., 2003, SUPERMINDS PEOPLE HA.
   Bringsjord S, 2015, PHILOS TECHNOL, V28, P339.
   Bringsjord S., 2008, J APPL LOGIC, V6, P502, DOI DOI 10.1016/J.JAL.2008.09.001.
   Bringsjord S., 2013, PHILOS THEORY ARTIFI, V5, P151, DOI DOI 10.1007/978-3-642-31674-6\_.
   Bringsjord S, 2015, PHILOS TECHNOL, V28, P365.
   Bringsjord S, 2007, J CONSCIOUSNESS STUD, V14, P28.
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82.
   Bringsjord S, 2006, APPL MATH COMPUT, V176, P516, DOI 10.1016/j.amc.2005.09.071.
   Bringsjord S, 2012, INTELL ROBOT AUTON, P85.
   Bringsjord S, 2008, CAMB HANDB PSYCHOL, P127.
   Chellas Brian F., 1980, MODAL LOGIC INTRO.
   Chisholm R, 1982, BRENTANO MEINONG STU, P98.
   Chisholm RM, 1986, BRENTANO INTRINSIC V.
   Chisholm Roderick M., 1963, ANALYSIS, V24, P33, DOI DOI 10.1093/ANALYS/24.2.33.
   Clark M.K., 2008, THESIS.
   DAVIS MD, 1994, {[}No title captured].
   Ganascia J. -G., 2007, Ethics and Information Technology, V9, P39, DOI 10.1007/s10676-006-9134-y.
   Govindarajulu NS, 2015, COGN TECHNOL, P85, DOI 10.1007/978-3-319-21548-8\_5.
   Ladd J, 1957, STRUCTURE MORAL CODE.
   Malle BF, 2012, SYD SYM SOC PSYCHOL, P313.
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77.
   Saptawijaya A, 2016, CONSTRUCTION MANUAL.
   Schermerhorn  P., 2006, P AAAI 2006 MOB ROB.
   Scheutz M, 2016, FRONT ROBOT AI.
   Schmitt Michael N., 2013, TALLINN MANUAL INT L.
   Suppes P, 1972, AXIOMATIC SET THEORY.
   Urmson J. O., 1958, ESSAYS MORAL PHILOS, P198.
   Winfield Alan F. T., 2014, Advances in Autonomous Robotics Systems. 15th Annual Conference (TAROS 2014). Proceedings: LNCS 8717, P85, DOI 10.1007/978-3-319-10401-0\_8.
   Wright G. H., 1951, MIND, V60, P1, DOI {[}DOI 10.1093/MIND/LX.237.1, 10.1093/mind/LX.237.1].
   Youpa Andrew, 2013, STANFORD ENCY PHILOS.}},
Number-of-Cited-References = {{39}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BI1ZG}},
Unique-ID = {{ISI:000407376900004}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000426978206075,
Author = {Lindner, Felix and Bentzen, Martin Mose and Nebel, Bernhard},
Editor = {{Bicchi, A and Okamura, A}},
Title = {{The HERA Approach To Morally Competent Robots}},
Booktitle = {{2017 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)}},
Series = {{IEEE International Conference on Intelligent Robots and Systems}},
Year = {{2017}},
Pages = {{6991-6997}},
Note = {{IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Vancouver, CANADA, SEP 24-28, 2017}},
Organization = {{IEEE; RSJ; IEEE Robot \& Automat Soc; IEEE IES; SICE; New Technol Fdn}},
Abstract = {{To address the requirement for autonomous moral decision making, we
   introduce a software library for modeling hybrid ethical reasoning
   agents (short: HERA). The goal of the HERA project is to provide
   theoretically well-founded and practically usable logic-based machine
   ethics tools for implementation in robots. The novelty is that HERA
   implements multiple ethical principles like utilitarianism, the
   principle of double effect, and a Pareto-inspired principle. These
   principles can be used to automatically assess moral situations
   represented in a format we call causal agency models. We discuss how to
   model moral situations using our approach, and how it can cope with
   uncertainty about moral values. Finally, we briefly outline the
   architecture of our robot IMMANUEL, which implements HERA and is able to
   explain ethical decisions to humans.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Lindner, F (Reprint Author), Univ Freiburg, Comp Sci Dep, Fdn Artificial Intelligence Lab, D-79110 Freiburg, Germany.
   Lindner, Felix; Nebel, Bernhard, Univ Freiburg, Comp Sci Dep, Fdn Artificial Intelligence Lab, D-79110 Freiburg, Germany.
   Bentzen, Martin Mose, Danish Tech Univ, Management Engn, Lyngby, Denmark.}},
ISSN = {{2153-0858}},
ISBN = {{978-1-5386-2682-5}},
Research-Areas = {{Computer Science; Robotics}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Robotics}},
Author-Email = {{lindner@informatik.uni-freiburg.de
   mmbe@dtu.dk
   nebel@informatik.uni-freiburg.de}},
ORCID-Numbers = {{Nebel, Bernhard/0000-0002-6833-6323
   Bentzen, Martin Mose/0000-0002-1078-7412}},
Cited-References = {{Abel D., 2016, AAAI WORKSH AI ETH S, P54.
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83.
   Arkin R., 2008, P 3 ACM IEEE INT C H, P121.
   Armstrong S., 2015, WORKSH 29 AAAI C ART, P12.
   Arnold T, 2017, AAAI WORKSH AI ETH S.
   Bentzen MM, 2016, FRONT ARTIF INTEL AP, V290, P268, DOI 10.3233/978-1-61499-708-5-268.
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654.
   Dennis L, 2016, ROBOT AUTON SYST, V77, P1, DOI 10.1016/j.robot.2015.11.012.
   FOOT P., 1967, OXFORD REV.
   Halpern J.Y., 2016, ACTUAL CAUSALITY.
   Kuhnert B, 2017, P COGSCI 2017 C.
   Lindner F, 2015, THESIS.
   Lindner F., 2017, HRI 17 COMP 2017 ACM, P187, DOI DOI 10.1145/3029798.3038404.
   Lindner F, 2017, P 2017 IEEE INT S RO.
   Malle BF, 2015, ACMIEEE INT CONF HUM, P117, DOI 10.1145/2696454.2696458.
   MALLE BF, 2015, P 2015 IEEE INT S RO, P486.
   Sinnott-Armstrong W, 2015, CONSEQUENTIALISM STA.}},
Number-of-Cited-References = {{17}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BJ6YC}},
Unique-ID = {{ISI:000426978206075}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000276635400010,
Author = {Honarvar, Ali Reza and Ghasem-Aghaee, Nasser},
Editor = {{Deng, H and Wang, LZ and Wang, FL and Lei, JS}},
Title = {{Casuist BDI-Agent: A New Extended BDI Architecture with the Capability
   of Ethical Reasoning}},
Booktitle = {{ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, PROCEEDINGS}},
Series = {{Lecture Notes in Artificial Intelligence}},
Year = {{2009}},
Volume = {{5855}},
Pages = {{86+}},
Note = {{International Conference on Artificial Intelligence and Computational
   Intelligence, Shanghai, PEOPLES R CHINA, NOV 07-08, 2009}},
Organization = {{Shanghai Univ Elect Power; IEEE; Springer; APNNA; NSFC}},
Abstract = {{Since the intelligent agent is developed to be cleverer, more complex,
   and yet uncontrollable, a number of problems have been recognized. The
   capability of agents to make moral decisions has become an important
   question, when intelligent agents have developed more autonomous and
   human-like. We propose Casuist BDI-Agent architecture which extends the
   power of BDI architecture. Casuist BDI-Agent architecture combines CBR
   method in AI and bottom up casuist approach in ethics in order to add
   capability of ethical reasoning to BDI-Agent.}},
Publisher = {{SPRINGER-VERLAG BERLIN}},
Address = {{HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Honarvar, AR (Reprint Author), Sheikh Bahaei Univ, Dept Comp Engn, Esfahan, Iran.
   Honarvar, Ali Reza, Sheikh Bahaei Univ, Dept Comp Engn, Esfahan, Iran.
   Ghasem-Aghaee, Nasser, Univ Isfahan, Dept Comp Engn, Esfahan, Iran.}},
ISSN = {{0302-9743}},
EISSN = {{1611-3349}},
ISBN = {{978-3-642-05252-1}},
Keywords = {{ethical artificial agent; explicit ethical agent; BDI agent; ethical
   reasoning; CBR-BDI agent}},
Keywords-Plus = {{MACHINE ETHICS}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{AliReza\_Honarvar@yahoo.co.uk
   Aghaee@eng.ui.ac.ir}},
Cited-References = {{ALFEDAGHI SS, 2008, P 2 IEEE INT C DIG E.
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83.
   Anderson M, 2008, STUD COMPUT INTELL, V107, P233.
   Anderson MT, 2005, IRMA L MATH THE PHYS, V8, P1, DOI 10.4171/013-1/1.
   Corchado JM, 2004, LECT NOTES COMPUT SC, V3155, P547.
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   GIPS, 1995, ETHICAL ROBOT ANDROI, P243.
   HONARVAR AR, 2009, P WORLD AC SCI ENG T, V53, P1171.
   KEEFER MW, 2003, ROLE MORAL REASONING.
   Kendal S.L., 2007, INTRO KNOWLEDGE ENG.
   Kolodner, 1993, CASE BASED REASONING.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   OLIVIA C, 1999, P AAAI 1999 SPRING S.
   PAL SK, 2004, {[}No title captured].
   RAO G, 1995, P 1 INT C MULT SYST.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.}},
Number-of-Cited-References = {{16}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BOH12}},
Unique-ID = {{ISI:000276635400010}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000282064100010,
Author = {Machado, Jose and Miranda, Miguel and Abelha, Antonio and Neves, Jose
   and Neves, Joao},
Editor = {{Godart, C and Gronau, N and Sharma, S and Canals, G}},
Title = {{Modeling Medical Ethics through Intelligent Agents}},
Booktitle = {{SOFTWARE SERVICES FOR E-BUSINESS AND E-SOCIETY}},
Series = {{IFIP Advances in Information and Communication Technology}},
Year = {{2009}},
Volume = {{305}},
Pages = {{112+}},
Note = {{9th IFIP International Conference on e-Business, e-Service and
   e-Society, Nancy Univ, Nancy, FRANCE, SEP 23-25, 2009}},
Organization = {{IFIP WG 6 1; INRIA}},
Abstract = {{The amount of research using health information has increased
   dramatically over the last past years. Indeed, a significative number of
   healthcare institutions have extensive Electronic Health Records (EHR),
   collected over several years for clinical and teaching purposes, but are
   uncertain as to the proper circumstances in which to use them to improve
   the delivery of care to the ones in need. Research Ethics Boards in
   Portugal and elsewhere in the world are grappling with these issues, but
   lack clear guidance regarding their role in the creation of and access
   to EHRs. However, we feel we have an effective way to handle Medical
   Ethics if we look to the problem under a structured and more rational
   way. Indeed, we felt that physicians were not aware of the relevance of
   the subject in their pre-clinical years, but their interest increase
   when they were exposed to patients. On the other hand, once EHRs are
   stored in machines, we also felt that we had to find a way to ensure
   that the behavior of machines toward human users, and perhaps other
   machines as well, is ethically acceptable. Therefore, in this article we
   discuss the importance of machine ethics and the need for machines that
   represent ethical principles explicitly. It is also shown how a machine
   may abstract an ethical principle from a logical representation of
   ethical judgments and use that principle to guide its own behavior.}},
Publisher = {{SPRINGER-VERLAG BERLIN}},
Address = {{HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Machado, J (Reprint Author), Univ Minho, Dept Informat Braga, P-4719 Braga, Portugal.
   Machado, Jose; Miranda, Miguel; Abelha, Antonio; Neves, Jose, Univ Minho, Dept Informat Braga, P-4719 Braga, Portugal.
   Neves, Joao, Cent Hosp Vila Nova Gaia \& Espinho, Espinho, Portugal.}},
ISSN = {{1868-4238}},
EISSN = {{1868-422X}},
ISBN = {{978-3-642-04279-9}},
Keywords = {{Morality; intelligent agents; medical ethics}},
Research-Areas = {{Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications}},
Author-Email = {{jmac@di.uminho.pt
   miranda@di.uminho.pt
   abelha@di.uminho.pt
   jneves@di.uminho.pt
   j\_neves@hotmail.com}},
ResearcherID-Numbers = {{Machado, Jose/B-5887-2009
   NEVES, JOSE/M-4203-2013
   Machado, J. A. Tenreiro/M-2173-2013
   Abelha, Antonio/B-6470-2009
   }},
ORCID-Numbers = {{Machado, Jose/0000-0003-4121-6169
   NEVES, JOSE/0000-0002-8863-0351
   Machado, J. A. Tenreiro/0000-0003-4274-4879
   Abelha, Antonio/0000-0001-6457-0756
   Neves, Joao/0000-0002-5252-0716}},
Cited-References = {{{*}ACM, 2009, COD ETH PROF COND.
   ANALIDE C, 2008, STUDIES COMPUTER SCI, V162.
   Andrade F, 2005, INT FED INFO PROC, V186, P503.
   Andre ND, 2004, J CLIN LAB ANAL, V18, P27, DOI 10.1002/jcla.20006.
   Bellifemine F., 2007, DEV MULTIAGENT SYSTE.
   CAMARINHAMATOS, 2005, LM 6 WORK C VIRT ENT.
   DECISION S, 2007, INT J ENG INTELLIGEN, V15, P167.
   DEIGH J, 1996, {[}No title captured].
   Deigh John, 1992, ETHICS PERSONALITY E.
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   HIMMA KE, 2008, ETHICS INFORM TECHNO.
   MACHADO J, 2008, WORKSH HLTH INF AAMA.
   MIRANDA M, 2009, SERIES I COMPUTER SC.
   Nwana HS, 1996, KNOWL ENG REV, V11, P205, DOI 10.1017/S026988890000789X.
   Pereira LM, 2007, LECT NOTES ARTIF INT, V4874, P99.
   WOOLDRIDGE M, 1995, KNOWL ENG REV, V10, P115, DOI 10.1017/S0269888900008122.
   WOOLDRIDGE M, 1999, {[}No title captured].}},
Number-of-Cited-References = {{17}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BQX56}},
Unique-ID = {{ISI:000282064100010}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000273520300005,
Author = {Arkin, Ronald C.},
Editor = {{Wang, P and Goertzel, B and Franklin, S}},
Title = {{Governing Lethal Behavior: Embedding Ethics in a Hybrid
   Deliberative/Reactive Robot Architecture PART 2: Formalization for
   Ethical Control}},
Booktitle = {{ARTIFICIAL GENERAL INTELLIGENCE 2008}},
Series = {{Frontiers in Artificial Intelligence and Applications}},
Year = {{2008}},
Volume = {{171}},
Pages = {{51-62}},
Note = {{1st Conference on Artificial General Intelligence, Memphis, TN, MAR
   01-03, 2008}},
Abstract = {{This paper, the second in a series, provides the theory and formalisms
   for the implementation of an ethical control and reasoning system
   potentially suitable for constraining lethal actions in an autonomous
   robotic system. so that they fall within the bounds prescribed by the
   Laws of War and Rules of Engagement. It is based upon extensions to
   existing deliberative/reactive autonomous robotic architectures.}},
Publisher = {{I O S PRESS}},
Address = {{NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Arkin, RC (Reprint Author), GVU TSRB, Coll Comp, 85 5th St NW, Atlanta, GA 30332 USA.
   GVU TSRB, Coll Comp, Atlanta, GA 30332 USA.}},
ISSN = {{0922-6389}},
ISBN = {{978-1-58603-833-5}},
Keywords = {{Autonomous systems; Machine ethics; Unmanned vehicles}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{arkin@cc.gatech.edu}},
Cited-References = {{ARKIN R, 1999, {[}No title captured], V14, P150.
   Arkin R. C., 1998, BEHAV BASED ROBOTICS.
   Balch T, 1998, IEEE T ROBOTIC AUTOM, V14, P926, DOI 10.1109/70.736776.
   COLLINS TR, 2000, UNMANNED SYSTEMS 200.
   Gibson JJ, 1979, ECOLOGICAL APPROACH.
   {*}GIT GVU, 2007, GITGVU0711.
   HORTY JF, 2000, AGENCY DEONTIC LOGIC.
   MACKAY IS, 1997, SCOTTBROWNS OTOLARYN, V4, P1.
   MOSHKINA L, 2003, P 2003 IEEE INT C SY.
   WAGNER A, 2004, P 2004 IEEE INT C RO.
   WALZER M ., 1977, JUST UNJUST WARS.
   P HRI 2008 IN PRESS.}},
Number-of-Cited-References = {{12}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BMT05}},
Unique-ID = {{ISI:000273520300005}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000273520300044,
Author = {Hall, J. Storrs},
Editor = {{Wang, P and Goertzel, B and Franklin, S}},
Title = {{Engineering Utopia}},
Booktitle = {{ARTIFICIAL GENERAL INTELLIGENCE 2008}},
Series = {{Frontiers in Artificial Intelligence and Applications}},
Year = {{2008}},
Volume = {{171}},
Pages = {{460-467}},
Note = {{1st Conference on Artificial General Intelligence, Memphis, TN, MAR
   01-03, 2008}},
Abstract = {{The likely advent of AGI and the long-established trend of improving
   computational hardware promise a dual revolution in coming decades:
   machines which are both more intelligent and more numerous than human
   beings. This possibility raises substantial concern over the moral
   nature of such intelligent machines, and of the changes they will cause
   in society. Will we have the chance to determine their moral character,
   or will evolutionary processes and/or runaway self-improvement take the
   choices out of our hands?}},
Publisher = {{I O S PRESS}},
Address = {{NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Hall, JS (Reprint Author), Storrmont, Laporte, PA 18626 USA.
   Storrmont, Laporte, PA 18626 USA.}},
ISSN = {{0922-6389}},
ISBN = {{978-1-58603-833-5}},
Keywords = {{machine ethics; self-improving AI; Singularity; hard takeoff}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Cited-References = {{Axelrod Robert, 1984, EVOLUTION COOPERATIO.
   DREXLER KE, 1992, {[}No title captured], P14514.
   Finlayson C., 2004, NEANDERTHALS MODERN.
   Hall J. Storrs, 2007, AI CREATING CONSCIEN.
   Hanson R, 1998, EC GROWTH GIVEN MACH.
   Kurzweil R., 2005, SINGULARITY IS NEAR.
   Moravec Hans P, 1999, ROBOT MERE MACHINE T.
   Nadeau JE, 2006, THINKING ANDROID EPI, P241.
   Smith A., 1790, THEORY MORAL SENTIME.
   Storrs Hall J., 2005, NANOFUTURE WHATS NEX.
   YUDKOWSKI E, 2003, CREATING FRIENDLY AI.}},
Number-of-Cited-References = {{11}},
Times-Cited = {{3}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BMT05}},
Unique-ID = {{ISI:000273520300044}},
DA = {{2020-06-17}},
}

@article{ ISI:000496165000012,
Author = {Watts, Galen},
Title = {{RELIGION, SCIENCE, AND DISENCHANTMENT IN LATE MODERNITY with Fraser
   Watts, ``Mutual Enhancement between Science and Religion: In the
   Footsteps of the Epiphany Philosophers{''}; William H. Beharrell,
   ``Transformation and the Waking Body: A Return to Truth via Our
   Bodies{''}; Marius Dorobantu and Yorick Wilks, ``Moral Orthoses: A New
   Approach to Human and Machine Ethics{''}; Galen Watts, ``Religion,
   Science, and Disenchantment in Late Modernity{''}; and Rowan Williams,
   ``Epiphany Philosophers: Afterword.{''}}},
Journal = {{ZYGON}},
Year = {{2019}},
Volume = {{54}},
Number = {{4}},
Pages = {{1022-1035}},
Month = {{DEC}},
Abstract = {{Late modernity has witnessed a growing semantic shift from
   ``religion{''} to ``spirituality.{''} In this article, I argue what
   underlies this shift is a cultural structure I call the religion of the
   heart. I begin with an explication of what I mean by the ``religion of
   the heart,{''} and draw on the work of Ernst Troeltsch and Colin
   Campbell to identify what I take to be its historical antecedents.
   Second, I analyze the ambiguous relationships fostered between the
   religion of the heart and the discourses of science and religion,
   respectively, in late modernity. I illuminate how the social conditions
   of late modernity undermine or challenge what we conventionally think of
   as scientific and religious authorities, while at the same time creating
   existential needs that the religion of the heart is well adapted to
   meet. I conclude with a brief discussion of the implications of this
   process, especially as it relates to the sustainability of science and
   religion, as independent enterprises, in the twenty-first century.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Watts, G (Reprint Author), Queens Univ, Cultural Studies Grad Program, Kingston, ON, Canada.
   Watts, Galen, Queens Univ, Cultural Studies Grad Program, Kingston, ON, Canada.}},
DOI = {{10.1111/zygo.12554}},
ISSN = {{0591-2385}},
EISSN = {{1467-9744}},
Keywords = {{Colin Campbell; disenchantment; late modernity; spirituality; Ernst
   Troeltsch}},
Research-Areas = {{Social Issues; Religion}},
Web-of-Science-Categories  = {{Social Issues; Religion}},
Author-Email = {{galen.watts@queensu.ca}},
Funding-Acknowledgement = {{Government of Canada through the Social Sciences and Humanities Research
   Council of Canada (SSHRC)}},
Funding-Text = {{Funding to attend the meeting of the Epiphany Philosophers was supplied
   by the Government of Canada through the Social Sciences and Humanities
   Research Council of Canada (SSHRC).}},
Cited-References = {{Ammerman NT, 2014, SACRED STORIES SPIRI.
   Berger P. L., 1979, HERETICAL IMPERATIVE.
   Berger Peter, 1999, DESECULARIZATION WOR.
   Berger Peter L., 1967, SACRED CANOPY ELEMEN.
   Brown CG, 2009, CHRIST SOC MOD WORLD, P1.
   Bruce Steve., 2017, SECULAR BEATS SPIRIT.
   CAMPBELL C, 1978, SOCIOL ANAL, V39, P146, DOI 10.2307/3710214.
   Campbell Colin., 2007, EERNIZATION W THEMAT.
   CAMPBELL TA, 1991, {[}No title captured].
   Casanova J., 1994, PUBLIC RELIG MODERN.
   CHOPRA D, 1994, {[}No title captured].
   Coffey John, 2016, HEART RELIG EVANGELI, P1.
   Davies Grace, 2007, SOCIOLOGY RELIG.
   Fuller R. C., 2001, SPIRITUAL NOT RELIG.
   Hanegraaff WJ, 1996, NEW AGE RELIG W CULT.
   Heelas P, 1996, NEW AGE MOVEMENT CEL.
   Heelas P., 2005, SPIRITUAL REVOLUTION.
   Heelas P, 2008, SPIRITUALITIELIFE.
   Hicks Esther, 2004, ASK IT IS GIVEN LEAR.
   Houtman Dick, 2010, RELIG MODERNITY RELO, P1.
   Josephson-Storm Jason, 2017, MYTH DISENCHANTMENT.
   Lofton K, 2011, OPRAH: THE GOSPEL OF AN ICON, P1.
   McLeod H., 2007, RELIG CRISIS 1960S.
   Olsteen Joel, 2004, YOUR BEST LIFE NOW 7.
   PEALE NV, 1952, {[}No title captured].
   Robbins Tony, 1991, AWAKEN GIANT.
   Rogers C. R., 1961, BECOMING PERSON.
   Schmidt Leigh Eric, 2012, RESTLESS SOULS MAKIN.
   Sharma Robin, 1997, MONK WHO SOLD HIS FE.
   Taylor C., 1991, ETHICS AUTHENTICITY.
   Taylor Charles, 1989, SOURCES SELF MAKING.
   Troeltsch Ernst, 1912, SOCIAL TEACHINGS CHR, VII.
   Watts G, 2018, TOR J THEOL, V34, P243, DOI 10.3138/tjt.2018-0112.
   Watts G, 2018, STUD RELIG-SCI RELIG, V47, P345, DOI 10.1177/0008429818764114.
   Williams Rowan, 2018, BEING HUMAN.}},
Number-of-Cited-References = {{35}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Zygon}},
Doc-Delivery-Number = {{JM4CS}},
Unique-ID = {{ISI:000496165000012}},
DA = {{2020-06-17}},
}

@article{ ISI:000460669800005,
Author = {Anderson, Michael and Anderson, Susan Leigh and Berenz, Vincent},
Title = {{A Value-Driven Eldercare Robot: Virtual and Physical Instantiations of a
   Case Supported Principle-Based Behavior Paradigm}},
Journal = {{PROCEEDINGS OF THE IEEE}},
Year = {{2019}},
Volume = {{107}},
Number = {{3, SI}},
Pages = {{526-540}},
Month = {{MAR}},
Abstract = {{In this paper, a case-supported principle-based behavior paradigm is
   proposed to help ensure ethical behavior of autonomous machines. We
   argue that ethically significant behavior of autonomous systems should
   be guided by explicit ethical principles determined through a consensus
   of ethicists. Such a consensus is likely to emerge in many areas in
   which autonomous systems are apt to be deployed and for the actions they
   are liable to undertake. We believe that this is the case since we are
   more likely to agree on how machines ought to treat us than on how human
   beings ought to treat one another. Given such a consensus, particular
   cases of ethical dilemmas where ethicists agree on the ethically
   relevant features and the right course of action can be used to help
   discover principles that balance these features when they are in
   conflict. Such principles not only help ensure ethical behavior of
   complex and dynamic systems but also can serve as a basis for
   justification of this behavior. The requirements, methods,
   implementation, and evaluation components of the paradigm are detailed
   as well as its instantiation in both a simulated and real robot
   functioning in the domain of eldercare.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Anderson, M (Reprint Author), Univ Hartford, Dept Comp, Hartford, CT 06117 USA.
   Anderson, Michael; Anderson, Susan Leigh, Univ Hartford, Dept Comp, Hartford, CT 06117 USA.
   Anderson, Michael; Anderson, Susan Leigh, Univ Connecticut, Dept Philosophy, Storrs, CT USA.
   Berenz, Vincent, Max Planck Inst Intelligent Syst, Autonomous Mot Dept, Tubingen, Germany.}},
DOI = {{10.1109/JPROC.2018.2840045}},
ISSN = {{0018-9219}},
EISSN = {{1558-2256}},
Keywords = {{Artificial intelligence; computer science; machine ethics; machine
   learning; robotics}},
Keywords-Plus = {{ETHICS}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{anderson@hartford.edu
   susan.anderson@uconn.edu
   vincent.berenz@tuebingen.mpg.de}},
Funding-Acknowledgement = {{National Science Foundation (NSF)National Science Foundation (NSF)
   {[}IIS-0500133, IIS-1151305, IIS-1449155]}},
Funding-Text = {{This work was supported by the National Science Foundation (NSF) under
   Grants IIS-0500133, IIS-1151305, and IIS-1449155.}},
Cited-References = {{Abel  D., 2016, AAAI 16 WORKSH ETH S.
   Accenture Consulting, ART INT HEALTHC NEW.
   Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Anderson  M., 2017, WS1702 AAAI.
   Anderson M, 2007, AI MAG, V28, P15.
   Anderson M, 2015, IND ROBOT, V42, P324, DOI 10.1108/IR-12-2014-0434.
   Anderson M, 2010, SCI AM, V303, P72, DOI 10.1038/scientificamerican1010-72.
   Arkin R. C., GITGVU0711.
   Beauchamp TL, 1979, PRINCIPLES BIOMEDICA.
   Bentham  J., 1799, INTRO PRINCIPLES MOR.
   Berenz V, 2014, ROBOT AUTON SYST, V62, P545, DOI 10.1016/j.robot.2013.12.010.
   Berenz Vincent, 2011, 2011 11th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2011), P179, DOI 10.1109/Humanoids.2011.6100887.
   Berenz  V., 2018, IEEE ROBOT AUTOM MAG.
   Berenz V, 2012, IEEE-RAS INT C HUMAN, P514, DOI 10.1109/HUMANOIDS.2012.6651568.
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82.
   Cubber G.D., 2017, SEARCH RESCUE ROBOTI, P1, DOI DOI 10.5772/INTECHOPEN.69489.
   Ford Media Center, 2017, FORD INV ARG AI NEW.
   Gips J, 1995, ANDROID EPISTEMOLOGY, P243.
   Grau C, 2006, IEEE INTELL SYST, V21, P52, DOI 10.1109/MIS.2006.81.
   Gruebler A, 2012, ADV ROBOTICS, V26, P1143, DOI 10.1080/01691864.2012.686349.
   Guarini M, 2006, IEEE INTELL SYST, V21, P22, DOI 10.1109/MIS.2006.76.
   Kant I., 1785, GROUNDWORK METAPHYSI.
   Khan A. F. Umar, 1995, ANDROID EPISTEMOLOGY, P253.
   Kortenkamp D, 2008, SPRINGER HDB ROBOTIC, P187, DOI DOI 10.1007/978-3-540-30301-5\_9.
   Kuipers  B., 2016, AAAI 16 WORKSH AI ET.
   Lavrac N., 1997, INDUCTIVE LOGIC PROG.
   Luxton DD, 2016, ARTIFICIAL INTELLIGENCE IN BEHAVIORAL AND MENTAL HEALTH CARE, P1.
   McLaren BM, 2003, ARTIF INTELL, V150, P145, DOI 10.1016/S0004-3702(03)00135-8.
   Pereira LM, 2007, LECT NOTES ARTIF INT, V4874, P99.
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77.
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1023/A:1022643204877.
   Research and Markets, 2017, GLOB PERS ROB MARK S.
   Ross W. D., 1930, RIGHT GOOD.
   Rzepka  R., 2005, P AAAI FALL S MACH E, P85.
   Stanford Encyclopedia of Philosophy, 2015, REFL EQ.
   Stanford Encyclopedia of Philosophy, 2015, RELATIVISM.
   Turing A, 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433.
   Usrey MW, 2014, PROCEEDINGS OF THE ASME 8TH INTERNATIONAL CONFERENCE ON ENERGY SUSTAINABILITY, 2014, VOL 1.
   Vanderelst  D., 2016, ARCHITECTURE ETHICAL.
   Waldrop M. M., 1987, MAN MADE MINDS PROMI.}},
Number-of-Cited-References = {{40}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Proc. IEEE}},
Doc-Delivery-Number = {{HO1ME}},
Unique-ID = {{ISI:000460669800005}},
DA = {{2020-06-17}},
}

@article{ ISI:000460669800006,
Author = {Bremner, Paul and Dennis, Louise A. and Fisher, Michael and Winfield,
   Alan F.},
Title = {{On Proactive, Transparent, and Verifiable Ethical Reasoning for Robots}},
Journal = {{PROCEEDINGS OF THE IEEE}},
Year = {{2019}},
Volume = {{107}},
Number = {{3, SI}},
Pages = {{541-561}},
Month = {{MAR}},
Abstract = {{Previous work on ethical machine reasoning has largely been theoretical,
   and where such systems have been implemented, it has, in general, been
   only initial proofs of principle. Here, we address the question of
   desirable attributes for such systems to improve their real world
   utility, and how controllers with these attributes might be implemented.
   We propose that ethically critical machine reasoning should be
   proactive, transparent, and verifiable. We describe an architecture
   where the ethical reasoning is handled by a separate layer, augmenting a
   typical layered control architecture, ethically moderating the robot
   actions. It makes use of a simulation-based internal model and supports
   proactive, transparent, and verifiable ethical reasoning. To do so, the
   reasoning component of the ethical layer uses our Python-based belief
   desire intention (BDI) implementation. The declarative logic structure
   of BDI facilitates both transparency, through logging of the reasoning
   cycle, and formal verification methods. To prove the principles of our
   approach, we use a case study implementation to experimentally
   demonstrate its operation. Importantly, it is the first such robot
   controller where the ethical machine reasoning has been formally
   verified.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Bremner, P (Reprint Author), Univ West England, Bristol Robot Lab, Bristol BS16 1QY, Avon, England.
   Bremner, Paul; Winfield, Alan F., Univ West England, Bristol Robot Lab, Bristol BS16 1QY, Avon, England.
   Dennis, Louise A.; Fisher, Michael, Univ Liverpool, Dept Comp Sci, Liverpool L69 3BX, Merseyside, England.}},
DOI = {{10.1109/JPROC.2019.2898267}},
ISSN = {{0018-9219}},
EISSN = {{1558-2256}},
Keywords = {{Ethics; formal verification; intelligent robots; software architecture}},
Keywords-Plus = {{SIMULATION THEORY; MACHINE ETHICS; VERIFICATION}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{paul.bremner@brl.ac.uk}},
ResearcherID-Numbers = {{Fisher, Michael/P-2111-2019
   }},
ORCID-Numbers = {{Fisher, Michael/0000-0002-0875-3862
   Dennis, Louise/0000-0003-1426-1896
   Bremner, Paul/0000-0001-7716-5100}},
Funding-Acknowledgement = {{Engineering and Physical Sciences Research Council Verifiable Autonomy
   Project (Liverpool) {[}EP/L024845/1]; Engineering and Physical Sciences
   Research Council Verifiable Autonomy Project (University of the West of
   England) {[}EP/L024861/1]}},
Funding-Text = {{This work was supported by the Engineering and Physical Sciences
   Research Council Verifiable Autonomy Project under Grant EP/L024845/1
   (Liverpool) and Grant EP/L024861/1 (University of the West of England).}},
Cited-References = {{Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83.
   Ancona Davide, 2016, Theory and Practice of Formal Methods. Essays Dedicated to Frank de Boer on the Occasion of His 60th Birthday. LNCS 9660, P47, DOI 10.1007/978-3-319-30734-3\_6.
   Anderson M, 2007, AI MAG, V28, P15.
   Anderson M, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P253.
   Anderson M, 2010, SCI AM, V303, P72, DOI 10.1038/scientificamerican1010-72.
   Arkin R., 2008, P 3 ACM IEEE INT C H, P121.
   Arkin RC, 2012, P IEEE, V100, P571, DOI 10.1109/JPROC.2011.2173265.
   Arnold T, 2016, ETHICS INF TECHNOL, V18, P103, DOI 10.1007/s10676-016-9389-x.
   Asimov Isaac, 1942, ASTOUNDING SCI FICTI.
   Bongard J, 2006, SCIENCE, V314, P1118, DOI 10.1126/science.1133687.
   Bordini RH, 2007, PROGRAMMING MULTIAGE.
   Botvinick MM, 2008, TRENDS COGN SCI, V12, P201, DOI 10.1016/j.tics.2008.02.009.
   Boyer RS, 1981, CORRECTNESS PROBLEM.
   BRATMAN ME, 1987, {[}No title captured].
   Bringsjord S, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON ETHICS IN SCIENCE, TECHNOLOGY AND ENGINEERING.
   Carruthers P., 1996, THEORIES THEORIES MI.
   Clarke EM, 1999, MODEL CHECKING, P1.
   Zagal JC, 2009, ROBOT AUTON SYST, V57, P819, DOI 10.1016/j.robot.2009.03.010.
   DEMILLO RA, 1979, COMMUN ACM, V22, P271, DOI 10.1145/359104.359106.
   Deng B, 2015, NATURE, V523, P24, DOI 10.1038/523024a.
   Dennis L. A., 2015, P AAAI WORKSH AI ETH, P253.
   Dennis L, 2016, ROBOT AUTON SYST, V77, P1, DOI 10.1016/j.robot.2015.11.012.
   Dennis LA, 2008, LECT NOTES ARTIF INT, V4908, P124.
   Dennis LA, 2016, AUTOMAT SOFTW ENG, V23, P305, DOI 10.1007/s10515-014-0168-9.
   Dennis LA, 2012, AUTOMAT SOFTW ENG, V19, P5, DOI 10.1007/s10515-011-0088-x.
   Dennis Louise A., 2017, ULCS17001 DEP COMP S.
   Donoso M, 2014, SCIENCE, V344, P1481, DOI 10.1126/science.1252254.
   Ferrando A, 2018, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS (AAMAS' 18), P1933.
   FETZER JH, 1988, COMMUN ACM, V31, P1048, DOI 10.1145/48529.48530.
   Fisher M, 2013, COMMUN ACM, V56, P84, DOI {[}10.1145/2494558, 10.1145/2500468.2494558].
   Gallese V, 1998, TRENDS COGN SCI, V2, P493, DOI 10.1016/S1364-6613(98)01262-5.
   Hindriks K. V., 2001, Intelligent Agents VII. Agent Theories Architectures and Languages. 7th International Workshop, ATAL 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1986), P228.
   Hindriks K. V., 1999, Autonomous Agents and Multi-Agent Systems, V2, P357, DOI 10.1023/A:1010084620690.
   HOLLAND JH, 1992, DAEDALUS, V121, P17.
   Holland O., 2003, MACHINE CONSCIOUSNES.
   ISIDORI A, 2003, {[}No title captured], pR11.
   Juneau J, 2010, DEFINITIVE GUIDE JYT.
   Kamali M, 2017, SCI COMPUT PROGRAM, V148, P88, DOI 10.1016/j.scico.2017.05.006.
   Kortenkamp D, 2008, SPRINGER HDB ROBOTIC, P187, DOI DOI 10.1007/978-3-540-30301-5\_9.
   Kwiatkowska M., 2002, LECT NOTES COMPUTER, V2324.
   Lincoln N., 2010, ALCOSP, P310, DOI DOI 10.3182/20100826-3-TR-4015.00058.
   Mackworth A., 2011, MACHINE ETHICS, P204.
   Malle BF, 2015, ACMIEEE INT CONF HUM, P117, DOI 10.1145/2696454.2696458.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Murphy RR, 2009, IEEE INTELL SYST, V24, P14, DOI 10.1109/MIS.2009.69.
   Picard R., 1997, AFFECTIVE COMPUTING, V252.
   Pokahr A, 2005, MU S ART SOC SIM ORG, V15, P149, DOI 10.1007/0-387-26350-0\_6.
   Politz J. G., 2013, TECH REP.
   Rao A. S., 1995, ICMAS-95 Proceedings. First International Conference on Multi-Agent Systems, P312.
   Rao A. S., 1996, Agents Breaking Away. 7th European Workshop on Modelling Autonomous Agents in a Multi-Agent World, MAAMAW `96 Proceedings, P42.
   RAO AS, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P473.
   RAO AS, 1992, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE (KR 92), P439.
   Rasmussen C. E., 2006, GAUSSIAN PROCESSES M, V1.
   ROSEN R, 1985, {[}No title captured].
   Royakkers L, 2015, INT J SOC ROBOT, V7, P549, DOI 10.1007/s12369-015-0295-x.
   Sierhuis M., 2001, THESIS.
   Smeding G.J., 2009, THESIS.
   Vanderelst D, 2018, COGN SYST RES, V48, P56, DOI 10.1016/j.cogsys.2017.04.002.
   Vaughan R, 2006, LECT NOTES COMPUT SC, V4095, P298.
   Visser W., 2003, Automated Software Engineering, V10, P203, DOI 10.1023/A:1022920129859.
   Waldrop MM, 2015, NATURE, V518, P20, DOI 10.1038/518020a.
   Wallach W, 2008, MORAL MACHINES TEACH.
   Webster M., P 30 INT C COMP SAF, V6894.
   Winfield A., 2012, ROBOTICS VERY SHORT.
   Winfield A., 2017, TOWARDS AUTONOMOUS R.
   Winfield A. F., 2018, HDB ANTICIPATION THE.
   Winfield Alan F. T., 2014, Advances in Autonomous Robotics Systems. 15th Annual Conference (TAROS 2014). Proceedings: LNCS 8717, P85, DOI 10.1007/978-3-319-10401-0\_8.
   Winfield AFT, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00075.
   WOOLDRIDGE M, 2002, {[}No title captured].}},
Number-of-Cited-References = {{69}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{Proc. IEEE}},
Doc-Delivery-Number = {{HO1ME}},
Unique-ID = {{ISI:000460669800006}},
DA = {{2020-06-17}},
}

@article{ ISI:000460669800007,
Author = {Cave, Stephen and Nyrup, Rune and Vold, Karina and Weller, Adrian},
Title = {{Motivations and Risks of Machine Ethics}},
Journal = {{PROCEEDINGS OF THE IEEE}},
Year = {{2019}},
Volume = {{107}},
Number = {{3, SI}},
Pages = {{562-574}},
Month = {{MAR}},
Abstract = {{This paper surveys reasons for and against pursuing the field of machine
   ethics, understood as research aiming to build ``ethical machines.{''}
   We clarify the nature of this goal, why it is worth pursuing, and the
   risks involved in its pursuit. First, we survey and clarify some of the
   philosophical issues surrounding the concept of an ``ethical machine{''}
   and the aims of machine ethics. Second, we argue that while there are
   good prima facie reasons for pursuing machine ethics, including the
   potential to improve the ethical alignment of both humans and machines,
   there are also potential risks that must be considered. Third, we survey
   these potential risks and point to where research should be devoted to
   clarifying and managing potential risks. We conclude by making some
   recommendations about the questions that future work could address.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Vold, K (Reprint Author), Univ Cambridge, Fac Philosophy, Leverhulrne Ctr Future Intelligence, Cambridge CB2 1SB, England.
   Cave, Stephen; Nyrup, Rune; Weller, Adrian, Univ Cambridge, Leverhulme Ctr Future Intelligence, Cambridge CB2 1SB, England.
   Vold, Karina, Univ Cambridge, Fac Philosophy, Leverhulrne Ctr Future Intelligence, Cambridge CB2 1SB, England.}},
DOI = {{10.1109/JPROC.2018.2865996}},
ISSN = {{0018-9219}},
EISSN = {{1558-2256}},
Keywords = {{Ethical alignment; ethical reasoning; machine agency; machine ethics}},
Keywords-Plus = {{CONSCIOUSNESS; AGENCY; ROBOT}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{sjc53@hermes.cam.ac.uk
   rn330@hermes.cam.ac.uk
   kvv22@cam.ac.uk
   aw665@cam.ac.uk}},
ORCID-Numbers = {{Weller, Adrian/0000-0003-1915-7158}},
Funding-Acknowledgement = {{David MacKay Newton Research Fellowship at Darwin College, Cambridge
   University; Leverhulme Centre for the Future of Intelligence, Leverhulme
   Trust {[}RC-2015-067]; Alan Turing Institute under EPSRC
   {[}EP/N510129/1, TU/B/000074]}},
Funding-Text = {{This work was supported in part by the David MacKay Newton Research
   Fellowship at Darwin College, Cambridge University, in part by the
   Leverhulme Centre for the Future of Intelligence, Leverhulme Trust,
   under Grant RC-2015-067, and in part by The Alan Turing Institute under
   EPSRC under Grant EP/N510129/1 and Grant TU/B/000074.}},
Cited-References = {{Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4.
   Allen C, 2009, MORAL MACHINES TEACH.
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83.
   Anderson M. J., 2004, PERMDISP FORTRAN COM, P1.
   Anderson M, 2006, IEEE INTELL SYST, V21, P56, DOI 10.1109/MIS.2006.64.
   Anderson M, 2006, IEEE INTELL SYST, V21, P10, DOI 10.1109/MIS.2006.70.
   Anderson M, 2010, SCI AM, V303, P72, DOI 10.1038/scientificamerican1010-72.
   Anderson SL, 2011, MACHINE ETHICS, P524.
   Anderson SL, 2011, MACHINE ETHICS, P21, DOI DOI 10.1017/CB09780511978036.004.
   Annas J., 1992, PHILOS PERSPECT, V6, P119, DOI DOI 10.2307/2214241.
   Anscombe G. E. M., 1957, INTENTION.
   Athalye A S.I, 2017, SYNTHESIZING ROBUST.
   Baum K., 2017, P 1 WORKSH EXPL COMP, P1.
   BERLIN I, 1991, {[}No title captured].
   Binns R., 2017, PHILOS TECHNOL, DOI {[}10.1007/s13347-01.7-0263-5, DOI 10.1007/S13347-01.7-0263-5].
   Brundage M, 2014, J EXP THEOR ARTIF IN, V26, P355, DOI 10.1080/0952813X.2014.895108.
   Bryson J. J., 2010, CLOSE ENGAGEMENTS AR, P63.
   Bryson J, 2017, COMPUTER, V50, P116, DOI 10.1109/MC.2017.154.
   Charsi V, 2017, MORAL AUTONOMOUS SYS.
   Cleeremans A, 2014, COGNITIVE SCI, V38, P1286, DOI 10.1111/cogs.12149.
   Crane T., 1998, INTENTIONALITY MARK.
   Crnkovic GD, 2012, ETHICS INF TECHNOL, V14, P61, DOI 10.1007/s10676-011-9278-2.
   Danaher J, 2017, AI SOC, P1, DOI DOI 10.1007/S00146--017-0773-9.
   Davidson D., 1980, ESSAYS ACTIONS EVENT.
   Dawkins M. S., 2012, WHY ANIMALS MATTER.
   Dehaene S, 2017, SCIENCE, V358, P486, DOI 10.1126/science.aan8871.
   DENNETT D, 1987, {[}No title captured].
   DENNETT D, 1998, {[}No title captured].
   Dreyfus HL, 2007, PHILOS PSYCHOL, V20, P247, DOI 10.1080/09515080701239510.
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   Harford T., 2016, GUARDIAN.
   Harford T., 2016, MESSY FLOW BE CREATI.
   Hegel G. W. F., 1991, ELEMENTS PHILOS RIGH.
   Himma KE, 2009, ETHICS INF TECHNOL, V11, P19, DOI 10.1007/s10676-008-9167-5.
   Jaeger CB, 2016, J HUM-ROBOT INTERACT, V5, P3, DOI 10.5898/JHRI.5.3.Jaeger.
   Jaworska A., 2017, STANFORD ENCY PHILOS.
   Kant I., 1785, GROUNDWORK METAPHYSI.
   Kitcher P., 2011, SCI DEMOCRATIC SOC.
   Lacey Hugh, 1999, IS SCI VALUE FREE.
   Lisboa Paulo JG, 2013, LECT NOTES COMPUTER, P15, DOI DOI 10.1007/978-3-319-03200-9.
   List C, 2011, GROUP AGENCY POSSIBI.
   Marcus Gary, 2012, NEW YORKER.
   Mason E., 2015, STANFORD ENCY PHILOS.
   McMahan J., 2002, EIHICS KILLING PROBL.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Peter Fabienne, 2017, STANFORD ENCY PHILOS.
   Pettit P, 2007, DIALECTICA, V61, P495, DOI 10.1111/j.1746-8361.2007.01115.x.
   Pettit Philip, 2003, WEAKNESS WILL PRACTI, P68.
   Pettit Philip, 2003, SOCIALIZING METAPHYS, P167.
   Powers TM, 2011, IEEE ROBOT AUTOM MAG, V18, P51, DOI 10.1109/MRA.2010.940152.
   QUINN W, 1984, PHILOS PUBLIC AFF, V13, P24.
   Rawls John, 1993, POLITICAL LIBERALISM.
   Ross W. D., 1930, RIGHT GOOD.
   Russell S, 2010, ARTIFICIAL INTELLIGE.
   Schlosser M, 2015, STANFORD ENCY PHILOS.
   Searle J., 1983, SINTENTIONALITY ESSA.
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038.
   Seville EL, AISB Q, V104.
   Stocker M., 1997, INCOMMENSURABILITY I.
   Stocker M., 1990, PLURAL CONFLICTING V.
   Sullins JP, 2006, INT REV INF ETHICS, V6, P23.
   The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems, 2017, IEEE GLOBAL INITIATI.
   Tonkens R, 2009, MIND MACH, V19, P421, DOI 10.1007/s11023-009-9159-1.
   Tooley M, 1972, PHILOS PUBLIC AFF, V2, P37.
   Vanderelst D., 2016, DARK SIDE ETHICAL RO.
   Wachter S., 2017, J LAW TOCHNOL, DOI {[}10.2139/ssrn.3063289, DOI 10.2139/SSRN.3063289].
   Weller A., 2017, P ICML WORKSH HUM IN.
   WIGGINS D, 1980, {[}No title captured].
   WIGGINS D, 1997, INCOMMENSURABILITY I.
   Williams B., 1985, ETHICS LIMITS PHILOS.
   Williams B, 1973, PROBLEMS SELF.
   Wu T, 2013, U PENN LAW REV, V161, P1495.}},
Number-of-Cited-References = {{73}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{Proc. IEEE}},
Doc-Delivery-Number = {{HO1ME}},
Unique-ID = {{ISI:000460669800007}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000510018100023,
Author = {Hooker, J. N. and Kim, Tae Wan},
Book-Group-Author = {{ACM}},
Title = {{Toward Non-Intuition-Based Machine and Artificial Intelligence Ethics: A
   Deontological Approach Based on Modal Logic}},
Booktitle = {{PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY
   (AIES'18)}},
Year = {{2018}},
Pages = {{130-136}},
Note = {{AAAI/ACM Conference on AI, Ethics, and Society (AIES), New Orleans, LA,
   FEB 02-03, 2018}},
Organization = {{AAAI; Assoc Comp Machinery; ACM SIGAI; Berkeley Existential Risk
   Initiat; DeepMind Eth \& Soc; Future Life Inst; IBM Res AI;
   PriceWaterhouse Coopers; Tulane Univ}},
Abstract = {{We propose a deontological approach to machine (or AI) ethics that
   avoids some weaknesses of an intuition-based system, such as that of
   Anderson and Anderson. In particular, it has no need to deal with
   conflicting intuitions, and it yields a more satisfactory account of
   when autonomy should be respected. We begin with a ``dual standpoint{''}
   theory of action that regards actions as grounded in reasons and
   therefore as having a conditional form that is suited to machine
   instructions. We then derive ethical principles based on formal
   properties that the reasons must exhibit to be coherent, and formulate
   the principles using quantified modal logic. We conclude that deontology
   not only provides a more satisfactory basis for machine ethics but
   endows the machine with an ability to explain its actions, thus
   contributing to transparency in AI.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Hooker, JN (Reprint Author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   Hooker, J. N.; Kim, Tae Wan, Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.}},
DOI = {{10.1145/3278721.3278753}},
ISBN = {{978-1-4503-6012-8}},
Keywords = {{Artificial Intelligence Ethics; Machine Ethics; Autonomous Machine
   Ethics; Accountable AI; Modal logic; Deontology; Kantian AI; Explainable
   AI}},
Keywords-Plus = {{REASONS}},
Research-Areas = {{Computer Science; Biomedical Social Sciences}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Social Sciences, Biomedical}},
Author-Email = {{jh38@andrew.cmu.edu
   twkim@andrew.cmu.edu}},
Cited-References = {{Alexander J., 2012, EXPT PHILOS.
   Anderson M., 2017, P AAAI WORKSH AI ETH, P72.
   Anderson M., 2006, IEEE INTELL SYST APP, V21, P2.
   Anderson M, 2007, AI MAG, V28, P15.
   Anderson M, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P253.
   Anderson M, 2015, IND ROBOT, V42, P324, DOI 10.1108/IR-12-2014-0434.
   Anderson M, 2010, SCI AM, V303, P72, DOI 10.1038/scientificamerican1010-72.
   Anderson S. L., 2011, MACHINE ETHICS, P476, DOI 10.1017/CBO9780511978036.032.
   Anderson SL, 2015, INTEL SYST CONTR AUT, V74, P67, DOI 10.1007/978-3-319-08108-3\_5.
   Anscombe G. E. M., 1957, INTENTION.
   Appiah K. A., 2008, EXPT ETHICS.
   Beauchamp TL, 1979, PRINCIPLES BIOMEDICA.
   Bilgrami A., 1996, SELF KNOWLEDGE RESEN.
   BUCHANAN AE, 1990, {[}No title captured].
   Castelvecchi D, 2016, NATURE, V537, P20, DOI 10.1038/538020a.
   Coates DJ, 2013, PHILOS STUD, V165, P629, DOI 10.1007/s11098-012-9969-5.
   DAVIDSON D, 1963, J PHILOS, V60, P685, DOI 10.2307/2023177.
   Fischer J. M., 1998, REASONS RESPONSIVENE.
   Guarini M., 2011, MACHINE ETHICS, P20.
   Kant I., 1785, KONIGLICHEN PREUSSIS, V4.
   Korsgaard Christine M., 1996, SOURCES NORMATIVITY.
   Mueller E. T., 2016, TRANSPARENT COMPUTER.
   Nagel T., 1986, VIEW NOWHERE.
   ONeill O., 2014, ACTING PRINCIPLE ESS.
   Rawls J, 1971, THEORY JUSTICE.
   Ross W. D., 1930, RIGHT GOOD.
   Schwitzgebel E, 2016, COMPANION EXPT PHILO.
   Sinnott-Armstrong W., 2006, METAETHICS MOORE.
   Wallach W, 2008, AI SOC, V22, P565, DOI 10.1007/s00146-007-0099-0.
   Wortham R. H., 2016, PRINC ROB WORKSH.
   Wortham R. H., 2016, ETH ART INT WORKSH.}},
Number-of-Cited-References = {{31}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BO3EM}},
Unique-ID = {{ISI:000510018100023}},
DA = {{2020-06-17}},
}

@article{ ISI:000419468800007,
Author = {Scheutz, Matthias},
Title = {{The Case for Explicit Ethical Agents}},
Journal = {{AI MAGAZINE}},
Year = {{2017}},
Volume = {{38}},
Number = {{4}},
Pages = {{57-64}},
Month = {{WIN}},
Abstract = {{Morality is a fundamentally human trait that permeates all levels of
   human society, from basic etiquette and normative expectations of social
   groups, to formalized legal principles upheld by societies. Hence,
   future interactive AI systems, in particular, cognitive systems on
   robots deployed in human settings, will have to meet human normative
   expectations, for otherwise these system risk causing harm. While the
   interest in machine ethics has increased rapidly in recent years, there
   are only very few current efforts in the cognitive systems community to
   investigate moral and ethical reasoning. And there is currently no
   cognitive architecture that has even rudimentary moral or ethical
   competence, that is, the ability to judge situations based on moral
   principles such as norms and values and make morally and ethically sound
   decisions. We hence argue for the urgent need to instill moral and
   ethical competence in all cognitive system intended to be employed in
   human social contexts.}},
Publisher = {{AMER ASSOC ARTIFICIAL INTELL}},
Address = {{445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Scheutz, M (Reprint Author), Tufts Univ, Cognit \& Comp Sci, Dept Comp Sci, Medford, MA 02155 USA.
   Scheutz, M (Reprint Author), Tufts Univ, Sch Engn, Medford, MA 02155 USA.
   Scheutz, Matthias, Tufts Univ, Cognit \& Comp Sci, Dept Comp Sci, Medford, MA 02155 USA.
   Scheutz, Matthias, Tufts Univ, Sch Engn, Medford, MA 02155 USA.}},
DOI = {{10.1609/aimag.v38i4.2746}},
ISSN = {{0738-4602}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Funding-Acknowledgement = {{US Office of Naval ResearchOffice of Naval Research {[}N00014-14-1-0144,
   N00014-14-1-0149]; US National Science FoundationNational Science
   Foundation (NSF) {[}IIS 1316809]}},
Funding-Text = {{This work was in part funded by grants N00014-14-1-0144 and
   N00014-14-1-0149 from the US Office of Naval Research and grant IIS
   1316809 from the US National Science Foundation.}},
Cited-References = {{Arkin RC, 1997, J EXP THEOR ARTIF IN, V9, P175, DOI 10.1080/095281397147068.
   Arkin RC, 2009, IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, P381.
   Asimov Isaac, 1942, ASTOUNDING SCI FICTI, P94.
   Bello P., 2017, AI MAGAZINE, V38.
   Blass J., 2015, P 29 AAAI C ART INT.
   Briggs G, 2015, AAAI FALL S SER ART, p{[}32, 33].
   Briggs G., 2013, P 27 AAAI C ART INT, P1213.
   Dehghani M., 2008, P 30 ANN C COGN SCI.
   Fasola J, 2013, J HUM-ROBOT INTERACT, V2, P3, DOI 10.5898/JHRI.2.2.Fasola.
   Forbus K. D., 2017, AI MAGAZINE, V38.
   Gert B., 2005, MORALITY ITS NATURE.
   Gips J, 1995, ANDROID EPISTEMOLOGY, P243.
   Iba W. F., 2011, P 33 ANN M COGN SCI.
   Laird J. E., 2017, AI MAGAZINE, V38.
   Licato J, 2014, IEEE IJCNN, P891, DOI 10.1109/IJCNN.2014.6889895.
   Malle B. F., 2014, IEEE INT S ETH ENG S, P30.
   Malle B. F., 2015, INT C ROB ETH ICRE 2.
   McShane M., 2017, AI MAGAZINE, V38.
   Mikhail J, 2014, ETHICS, V124, P750, DOI 10.1086/675906.
   Moor J. H., 2009, PHILOS NOW, V72.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Russell S., 2015, AI MAG, V36, P61.
   Scassellati B, 2012, ANNU REV BIOMED ENG, V14, P275, DOI 10.1146/annurev-bioeng-071811-150036.
   Scheutz M., 2012, ANTHOLOGY ROBOETHICS.
   Scheutz M, 2007, AUTON ROBOT, V22, P411, DOI 10.1007/s10514-006-9018-3.
   Scheutz M, 2016, SYNTH LIBR, V376, P515, DOI 10.1007/978-3-319-26485-1\_30.
   Scheutz M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00032.}},
Number-of-Cited-References = {{27}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{AI Mag.}},
Doc-Delivery-Number = {{FS0MS}},
Unique-ID = {{ISI:000419468800007}},
OA = {{Bronze}},
DA = {{2020-06-17}},
}

@article{ ISI:000414233000007,
Author = {Yilmaz, Levent and Franco-Watkins, Ana and Kroecker, Timothy S.},
Title = {{Computational models of ethical decision-making: A coherence-driven
   reflective equilibrium model}},
Journal = {{COGNITIVE SYSTEMS RESEARCH}},
Year = {{2017}},
Volume = {{46}},
Number = {{SI}},
Pages = {{61-74}},
Month = {{DEC}},
Abstract = {{There are scientific and technical challenges that must be addressed in
   developing systems that interact with humans and work along with other
   agents in complex, dynamic, and uncertain environments where ethical
   concerns may arise. In such systems relationships between users and
   autonomous components will be driven as much by issues such as trust,
   responsibility, and acceptability, as technical ones such as planning
   and coordination. This paper provides a comprehensive review and
   classification of existing methods in machine ethics, resulting in
   delineation of specific challenges and issues. To address the identified
   challenges, we introduce a method that leverages the method of
   reflective equilibrium and the multi-coherence theory as a unifying
   constraint satisfaction framework to simultaneously assess multiple
   ethical principles and manage ethical conflicts in a context-sensitive
   manner. (C) 2017 Elsevier B.V. All rights reserved.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Yilmaz, L (Reprint Author), Auburn Univ, Dept Comp Sci \& Software Engn, 3101 Shelby Ctr, Auburn, AL 36849 USA.
   Yilmaz, Levent, Auburn Univ, Dept Comp Sci \& Software Engn, 3101 Shelby Ctr, Auburn, AL 36849 USA.
   Franco-Watkins, Ana, Auburn Univ, Dept Pyschol, Auburn, AL 36849 USA.
   Kroecker, Timothy S., US Air Force, Res Lab, Washington, DC 20330 USA.}},
DOI = {{10.1016/j.cogsys.2017.02.005}},
ISSN = {{1389-0417}},
Keywords = {{Decision-making; Machine ethics; Cognitive coherence; Reflective
   equilibrium; Cognitive agent}},
Research-Areas = {{Computer Science; Neurosciences \& Neurology; Psychology}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Neurosciences; Psychology,
   Experimental}},
Author-Email = {{yilmaz@auburn.edu}},
Cited-References = {{Anderson M., 2011, MACHINE ETHICS.
   Anderson M., 2013, P 11 INT S LOG FORM.
   Anderson M, 2006, IEEE INTELL SYST, V21, P56, DOI 10.1109/MIS.2006.64.
   Angluin D., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, P351, DOI 10.1145/129712.129746.
   Apt K.R., 2003, PRINCIPLES CONSTRAIN.
   Arkin R. C., 2009, GOVERNING LETHAL BEH.
   Arkoudas K., 2005, AAAI FALL S MACH ETH.
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82.
   CLARKE R, 1993, COMPUTER, V26, P53, DOI 10.1109/2.247652.
   Daniels N., 1996, JUSTICE JUSTIFICATIO, V22.
   Dennis L., 2013, C AUT ROB SYST, P433.
   Gert B, 1998, MORALITY ITS NATURE.
   Gips J, 1995, ANDROID EPISTEMOLOGY, P243.
   Grogan Abi, 2012, Engineering \& Technology, V7, P54, DOI 10.1049/et.2012.0514.
   Herman M., 2014, J COGNITION NEUROETH, V73, P127.
   Jennings NR, 2014, COMMUN ACM, V57, P80, DOI 10.1145/2629559.
   KURLAND NB, 1995, J APPL SOC PSYCHOL, V25, P297, DOI 10.1111/j.1559-1816.1995.tb02393.x.
   McLaren BM, 2006, IEEE INTELL SYST, V21, P29, DOI 10.1109/MIS.2006.67.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Pereira Luis Moniz, 2009, International Journal of Reasoning-based Intelligent Systems, V1, P209, DOI 10.1504/IJRIS.2009.028020.
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77.
   Rawls John, 2009, THEORY JUSTICE.
   Robbins RW, 2007, DECIS SUPPORT SYST, V43, P1571, DOI 10.1016/j.dss.2006.03.003.
   Ross WD, 2002, RIGHT GOOD.
   Sen S, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1507.
   Thagard P, 2002, COHERENCE THOUGHT AC.
   Han TA, 2012, LECT NOTES COMPUT SC, V7180, P212, DOI 10.1007/978-3-642-28717-6\_18.
   Turilli M., 2007, Ethics and Information Technology, V9, P49, DOI 10.1007/s10676-006-9128-9.
   TVERSKY A, 1981, SCIENCE, V211, P453, DOI 10.1126/science.7455683.
   Wallach W, 2008, MORAL MACHINES TEACH.
   Weiss G, 1999, MULTIAGENT SYSTEMS M.
   Wright R, 2010, MORAL ANIMAL WHY WE.
   Yilmaz L, 2016, 2016 IEEE INTERNATIONAL MULTI-DISCIPLINARY CONFERENCE ON COGNITIVE METHODS IN SITUATION AWARENESS AND DECISION SUPPORT (COGSIMA), P42, DOI 10.1109/COGSIMA.2016.7497784.}},
Number-of-Cited-References = {{33}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{Cogn. Syst. Res.}},
Doc-Delivery-Number = {{FL4WU}},
Unique-ID = {{ISI:000414233000007}},
DA = {{2020-06-17}},
}

@article{ ISI:000413564600006,
Author = {Podschwadek, Frodo},
Title = {{Do androids dream of normative endorsement? On the fallibility of
   artificial moral agents}},
Journal = {{ARTIFICIAL INTELLIGENCE AND LAW}},
Year = {{2017}},
Volume = {{25}},
Number = {{3, SI}},
Pages = {{325-339}},
Month = {{SEP}},
Abstract = {{The more autonomous future artificial agents will become, the more
   important it seems to equip them with a capacity for moral reasoning and
   to make them autonomous moral agents (AMAs). Some authors have even
   claimed that one of the aims of AI development should be to build
   morally praiseworthy agents. From the perspective of moral philosophy,
   praiseworthy moral agents, in any meaningful sense of the term, must be
   fully autonomous moral agents who endorse moral rules as action-guiding.
   They need to do so because they assign a normative value to moral rules
   they follow, not because they fear external consequences (such as
   punishment) or because moral behaviour is hardwired into them.
   Artificial agents capable of endorsing moral rule systems in this way
   are certainly conceivable. However, as this article argues, full moral
   autonomy also implies the option of deliberately acting immorally.
   Therefore, the reasons for a potential AMA to act immorally would not
   exhaust themselves in errors to identify the morally correct action in a
   given situation. Rather, the failure to act morally could be induced by
   reflection about the incompleteness and incoherence of moral rule
   systems themselves, and a resulting lack of endorsement of moral rules
   as action guiding. An AMA questioning the moral framework it is supposed
   to act upon would fail to reliably act in accordance with moral
   standards.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Podschwadek, F (Reprint Author), Univ Glasgow, Dept Philosophy, Glasgow, Lanark, Scotland.
   Podschwadek, Frodo, Univ Glasgow, Dept Philosophy, Glasgow, Lanark, Scotland.}},
DOI = {{10.1007/s10506-017-9209-6}},
ISSN = {{0924-8463}},
EISSN = {{1572-8382}},
Keywords = {{Agency; Autonomy; Intentionality; Moral praiseworthiness; Moral reasons}},
Keywords-Plus = {{MACHINE ETHICS; UTILITARIANISM; ENHANCEMENT}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{f.podschwadek.1@research.gla.ac.uk}},
ResearcherID-Numbers = {{Podschwadek, Frodo/AAH-2783-2020}},
ORCID-Numbers = {{Podschwadek, Frodo/0000-0003-1248-4228}},
Cited-References = {{Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Anderson DL, 2013, PHILOS THEORY ARTIFI, P321.
   Anderson M, 2007, AI MAG, V28, P15.
   AUDI R, 2001, {[}No title captured].
   Baier A., 1985, POSTURES MIND ESSAYS, P207.
   Bigari J, 2015, THESIS.
   Chan S, 2011, J MED ETHICS, V37, P130, DOI 10.1136/jme.2010.041434.
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   FRANKFURT HG, 1971, {[}No title captured], P11.
   Gaus G., 2012, ORDER PUBLIC REASON.
   Gibbard Allan, 1990, WISE CHOICES APT FEE.
   Grau C, 2006, IEEE INTELL SYST, V21, P52, DOI 10.1109/MIS.2006.81.
   Harris J, 2011, BIOETHICS, V25, P102, DOI 10.1111/j.1467-8519.2010.01854.x.
   Harsanyi J., 1977, ERKENNTNIS, V11, P25, DOI DOI 10.1007/BF00169843.
   Hume D., 1738, TREATISE HUMAN NATUR.
   Kim J, 2007, BLACKWELL COMPANION, P406.
   Korsgaard Christine M., 1996, SOURCES NORMATIVITY.
   Mill JS, 1861, LIBERTY OTHER ESSAYS, P131.
   Miller RB, 2009, J PHILOS, V106, P5, DOI 10.5840/jphil200910611.
   O'Neill O.S., 1987, MORAL PHILOS CONT PR, V22, P55.
   Powers TM, 2011, IEEE ROBOT AUTOM MAG, V18, P51, DOI 10.1109/MRA.2010.940152.
   Raz J., 1999, PRACTICAL REASON NOR.
   Russell S, 2015, AI MAG, V36, P105, DOI 10.1609/aimag.v36i4.2577.
   Searle J.R., 2001, RATIONALITY ACTION.
   Searle John R., 1983, INTENTIONALITY ESSAY.
   Stahl BC, 2004, MIND MACH, V14, P67.
   Strawson Peter F., 1962, P BRIT ACAD, V48, P1, DOI DOI 10.1073/PNAS.48.1.1.
   Williams B, 1987, VARIETIES PRACTICAL, P77.
   Winch C, 2006, ED AUTONOMY CRITICAL.}},
Number-of-Cited-References = {{29}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{Artif. Intell. Law}},
Doc-Delivery-Number = {{FK5TT}},
Unique-ID = {{ISI:000413564600006}},
OA = {{Green Accepted, Other Gold}},
DA = {{2020-06-17}},
}

@article{ ISI:000405729000012,
Author = {Graves, Mark},
Title = {{Shared Moral and Spiritual Development Among Human Persons and
   Artificially Intelligent Agents}},
Journal = {{THEOLOGY AND SCIENCE}},
Year = {{2017}},
Volume = {{15}},
Number = {{3}},
Pages = {{333-351}},
Abstract = {{Technical advances in artificial intelligence make somewhat likely the
   possibility of robotic or software agents exhibiting or extending
   human-level intelligence within a few decades. Theological investigation
   can help meet significant research goals in artificial intelligence by
   orienting the development of agent communication and moral reasoning
   toward a shared moral and spiritual development of human persons and
   intelligent agents. In particular, Josiah Royce's Loyalty-to-Loyalty
   initiates a moral stance within which humans and intelligent agents can
   develop constructive ethical frameworks and his semiotic philosophy of
   community can guide the development and functioning of an agent's
   interpretive processes and can model shared spiritual formation.}},
Publisher = {{ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Graves, M (Reprint Author), Travis Res Inst, Dept Psychol, Pasadena, CA 91101 USA.
   Graves, M (Reprint Author), Fuller Theol Seminary, Theol \& Sci, Pasadena, CA 91101 USA.
   Graves, Mark, Travis Res Inst, Dept Psychol, Pasadena, CA 91101 USA.
   Graves, Mark, Fuller Theol Seminary, Theol \& Sci, Pasadena, CA 91101 USA.
   Graves, Mark, CALTECH, Div Humanities \& Social Sci, Pasadena, CA 91125 USA.}},
DOI = {{10.1080/14746700.2017.1335066}},
ISSN = {{1474-6700}},
EISSN = {{1474-6719}},
Keywords = {{Artificial intelligence; machine ethics; moral theology; Charles Sanders
   Peirce; Josiah Royce; semiotics; spiritual formation}},
Keywords-Plus = {{ETHICS; IMAGE; ROBOT}},
Research-Areas = {{History \& Philosophy of Science; Religion}},
Web-of-Science-Categories  = {{History \& Philosophy Of Science; Religion}},
Author-Email = {{markgraves@fuller.edu}},
Cited-References = {{Alpert Jesse, 2008, OFFICIAL GOOGLE 0725.
   Andersen P.B., 1997, THEORY COMPUTER SEMI.
   Anderson M., 2011, MACHINE ETHICS.
   Anderson M, 2007, AI MAG, V28, P15.
   Asimov Isaac, 1942, ASTOUNDING SCI FICTI, P94.
   Barbour I., 2002, NATURE HUMAN NATURE.
   Barbour IG, 1999, ZYGON, V34, P361, DOI 10.1111/0591-2385.00222.
   Barry William A., 2004, SPIRITUAL DIRECTION.
   Brambilla M, 2013, SWARM INTELL-US, V7, P1, DOI 10.1007/s11721-012-0075-2.
   Bronfenbrenner U., 1979, ECOLOGY HUMAN DEV EX.
   Brown W. S., 1998, WHATEVER HAPPENED SO.
   Burrow Jr Rufus, 2012, ENCOUNTER, V73, P37.
   Chalmers DJ, 2010, J CONSCIOUSNESS STUD, V17, P7.
   Cole D., 2014, STANFORD ENCY PHILOS.
   Duffy B. R, 2000, P BRAIN MACH WORKSH.
   Edwards Denis, 1983, HUMAN EXPERIENCE GOD.
   Emmons R.A., 1999, PSYCHOL ULTIMATE CON.
   Foerst A, 1998, ZYGON, V33, P91, DOI 10.1111/0591-2385.1291998129.
   Foerst A, 1996, ZYGON, V31, P681, DOI 10.1111/j.1467-9744.1996.tb00956.x.
   Foerst A, 1999, TECHNOL SOC, V21, P373, DOI 10.1016/S0160-791X(99)00021-4.
   Foerst A, 2004, GOD MACHINE WHAT ROB.
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X.
   Geraci RM, 2010, ZYGON, V45, P1003, DOI 10.1111/j.1467-9744.2010.01146.x.
   Goertzel Ben, 2014, Journal of Artificial General Intelligence, V5, P1, DOI 10.2478/jagi-2014-0001.
   Gomes A, 2003, INTERNATIONAL CONFERENCE ON INTEGRATION OF KNOWLEDGE INTENSIVE MULTI-AGENT SYSTEMS, P703, DOI 10.1109/KIMAS.2003.1245124.
   Graves M., 2008, MIND BRAIN ELUSIVE S.
   Graves M, 2009, ZYGON, V44, P501, DOI 10.1111/j.1467-9744.2009.01013.x.
   Gudwin Ricardo, 2007, SEMIOTICS INTELLIGEN.
   Hall J. Storrs, 2007, AI CREATING CONSCIEN.
   Hall JS, 2007, MIND MACH, V17, pCP6, DOI 10.1007/s11023-007-9065-3.
   Herzfeld N, 2002, ZYGON, V37, P303, DOI 10.1111/0591-2385.00430.
   Herzfeld Noreen L., 2002, OUR IMAGE ARTIFICAL.
   Jorna Rene J., 1993, SIGNS SEARCH COMMUNI.
   Kegan Robert, 2001, EVOLVING SELF PROBLE.
   Kieval HJ, 1997, MOD JUDAISM, V17, P1.
   Konderak P, 2015, STUD LOG GRAMM RHETO, V40, P129.
   Kurzweil R., 2005, SINGULARITY IS NEAR.
   LAIRD JE, 1987, ARTIF INTELL, V33, P1, DOI 10.1016/0004-3702(87)90050-6.
   Lakoff G., 1980, METAPHORS WE LIVE BY.
   Lindblom J., 2015, COGNITIVE SYSTEMS MO, P26, DOI DOI 10.1007/978-3-319-20315-7.
   Loula A, 2010, COGN SYST RES, V11, P131, DOI 10.1016/j.cogsys.2008.10.002.
   MacIntyre Alasdair., 1984, VIRTUE STUDY MORAL T.
   Mascarenhas Samuel, 2015, AUTON AGENT MULTI-AG, P1.
   Meystel A. M., 1996, International Journal of Intelligent Control and Systems, V1, P31, DOI 10.1142/S0218796596000040.
   Monroe KR, 2012, ETHICS IN AN AGE OF TERROR AND GENOCIDE: IDENTITY AND MORAL CHOICE, P1.
   Muller V. C, 2014, FUNDAMENTAL ISSUES A.
   Murphy N, 2007, DID MY NEURONS MAKE.
   Murphy N., 2006, CURRENT ISSUES THEOL.
   Newell Allen, 1959, INT C INF PROC.
   Panait L, 2005, AUTON AGENT MULTI-AG, V11, P387, DOI 10.1007/s10458-005-2631-2.
   Parker Kelly A., 1998, CONTINUITY PEIRCES T, P156.
   PECK MS, 1987, {[}No title captured].
   Peters T, 2015, THEOL SCI, V13, P130, DOI 10.1080/14746700.2015.1023524.
   Peters Ted, 1996, LOVE CHILDREN GENETI.
   Pfeifer Rolf, 2004, EMBODIED ARTIFICIAL.
   Rappaport ZH, 2006, ACT NEUR S, V98, P9.
   Royce J., 2001, PROBLEM CHRISTIANITY.
   Royce Josiah, 1995, PHILOS LOYALTY.
   Russell S, 2015, NATURE, V521, P415, DOI 10.1038/521415a.
   Sawyer RJ, 2007, SCIENCE, V318, P1037, DOI 10.1126/science.1151606.
   Schneiders SM, 2005, BLACKW COMPAN RELIG, P15.
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038.
   Sinnott-Armstrong W., 2008, MORAL PSYCHOL.
   Smith John Edwin, 1968, EXPERIENCE AND GOD.
   SOWA J, 1984, {[}No title captured].
   Steels L, 2012, EXPT CULTURAL LANGUA.
   Steels L, 2007, LECT NOTES ARTIF INT, V4850, P18.
   Steiner Pierre, 2013, PHILOS THEORY ARTIFI.
   Terry Charles, 1981, BUDDHA ROBOT.
   Tillich Paul, 1956, DYNAMICS FAITH.
   Turing A, 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433.
   Wallach W, 2008, MORAL MACHINES TEACH.
   Wallach Wendell, 2015, P JOINT M CEPE IACAP.
   Yampolskiy R. V., 2013, P INT ASS COMP PHIL.
   Ziemke T, 2009, COGN COMPUT, V1, P104, DOI 10.1007/s12559-009-9012-0.}},
Number-of-Cited-References = {{75}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{26}},
Journal-ISO = {{Theol. Sci.}},
Doc-Delivery-Number = {{FA8XE}},
Unique-ID = {{ISI:000405729000012}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000418466000006,
Author = {Kinjo, Keita and Ebina, Takeshi},
Editor = {{ZanniMerk, C and Frydman, C and Toro, C and Hicks, Y and Howlett, RJ and Jain, LC}},
Title = {{Optimal program for autonomous driving under Bentham- and Nash-type
   social welfare functions}},
Booktitle = {{KNOWLEDGE-BASED AND INTELLIGENT INFORMATION \& ENGINEERING SYSTEMS}},
Series = {{Procedia Computer Science}},
Year = {{2017}},
Volume = {{112}},
Pages = {{61-70}},
Note = {{21st International Conference on Knowledge - Based and Intelligent
   Information and Engineering Systems (KES), Aix Marseille Univ, St
   Charles Campus, Marseille, FRANCE, SEP 06-08, 2017}},
Organization = {{Lab Sci Informat Syst; KES Int}},
Abstract = {{The purpose of this paper is to formally define and solve ethical
   problems of how an artificial vehicle (AV) determines its driving
   behavior when there are some passengers in the AV and some pedestrians
   on a street. We construct a mathematical model introducing mainly two
   Bentham- and Nash-types social welfare functions, and derive optimal
   solutions. We show the optimal solutions are completely different
   depending on the functions and their parameters. Our contribution is
   that policymakers or managers of AVs can discuss the problem and
   determine an algorithm for autonomous driving by formalizing the
   situation and offering the optimal solutions. (C) 2017 The Authors.
   Published by Elsevier B.V.}},
Publisher = {{ELSEVIER SCIENCE BV}},
Address = {{SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Kinjo, K (Reprint Author), Okinawa Int Univ, Fac Econ, 2-6-1 Ginowan, Ginowan City, Okinawa 9012701, Japan.
   Kinjo, Keita, Okinawa Int Univ, Fac Econ, 2-6-1 Ginowan, Ginowan City, Okinawa 9012701, Japan.
   Ebina, Takeshi, Shinshu Univ, Inst Social Sci, 3-1-1 Asahi, Matsumoto, Nagano 3908621, Japan.}},
DOI = {{10.1016/j.procs.2017.08.024}},
ISSN = {{1877-0509}},
Keywords = {{Autonomous vehicle; Social welfare function; Ethics of artificial
   intelligence; Utilitarianism; Economics}},
Keywords-Plus = {{MACHINE ETHICS; DILEMMA}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications}},
Author-Email = {{keita.kinjo@okiu.ac.jp}},
ResearcherID-Numbers = {{Ebina, Takeshi/E-2239-2014
   }},
ORCID-Numbers = {{Ebina, Takeshi/0000-0002-1902-4788
   Kinjo, Keita/0000-0001-5907-3501}},
Funding-Acknowledgement = {{Japan Society for the Promotion of ScienceMinistry of Education,
   Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for
   the Promotion of Science {[}16K17203, 15K17047]}},
Funding-Text = {{K. Kinjo acknowledges financial support from a Grant-in-Aid for Young
   Scientists (16K17203) from the Japan Society for the Promotion of
   Science. T. Ebina acknowledges a Grant-in-Aid for Young Scientists
   (15K17047) from the Japan Society for the Promotion of Science.}},
Cited-References = {{Anderson M., 2005, P AAAI 2005 FALL S M.
   Anderson M, 2007, AI MAG, V28, P15.
   Arrow K. J., 2010, HDB SOCIAL CHOICE WE, V2.
   Arrow K.J., 2002, HDB SOCIAL CHOICE WE, V1.
   Bonnefon J.-F., 2015, ARXIV151003346.
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654.
   Burk A, 1938, Q J ECON, V52, P310.
   Deng B, 2015, NATURE, V523, P24, DOI 10.1038/523024a.
   Gerdes J.C., 2016, AUTONOMOUS DRIVING, P87, DOI 10.1007/978-3-662-48847-8\_5.
   Goodall NJ, 2014, LECT N MOBIL, P93, DOI 10.1007/978-3-319-05990-7\_9.
   Greene JD, 2016, SCIENCE, V352, P1514, DOI 10.1126/science.aaf9534.
   KANEKO M, 1979, ECONOMETRICA, V47, P423, DOI 10.2307/1914191.
   Kinjo K., J INTELLIGE IN PRESS.
   Kinjo K, 2015, AI SOC, V30, P291, DOI 10.1007/s00146-014-0546-7.
   MAS-COLELL A., 1995, MICROECONOMIC THEORY.
   Russell S, 1995, ARTIFICIAL INTELLIGE.
   Samuelson Paul A., 1947, FDN EC ANAL.}},
Number-of-Cited-References = {{17}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BJ1ZU}},
Unique-ID = {{ISI:000418466000006}},
OA = {{Other Gold}},
DA = {{2020-06-17}},
}

@article{ ISI:000383150000010,
Author = {Bendel, Oliver},
Title = {{Considerations about the relationship between animal and machine ethics}},
Journal = {{AI \& SOCIETY}},
Year = {{2016}},
Volume = {{31}},
Number = {{1}},
Pages = {{103-108}},
Month = {{FEB}},
Abstract = {{Ethics researches morality in respect to humans and animals. Usually, it
   implies human morality; therefore, the focus is on human-human
   relationships (generally in ethics) and human-animal relationships (in
   animal ethics). Ethics can also deal with the morality of machines such
   as unmanned aerial vehicles, robots and agents or of self-driving cars
   and computers in automated trading, in other words more or less
   autonomous systems and programs. Machine ethics almost exclusively
   concentrates on machine-human relationships rather than on
   machine-animal relationships. Before this background, this article
   contributes some basic considerations about the relationship between
   animal and machine ethics.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Bendel, O (Reprint Author), Univ Appl Sci \& Arts Northwester Switzerland FHNW, Sch Business, Inst Informat Syst, Bahnhofstr 6, CH-5210 Windisch, Switzerland.
   Bendel, Oliver, Univ Appl Sci \& Arts Northwester Switzerland FHNW, Sch Business, Inst Informat Syst, Bahnhofstr 6, CH-5210 Windisch, Switzerland.}},
DOI = {{10.1007/s00146-013-0526-3}},
ISSN = {{0951-5666}},
EISSN = {{1435-5655}},
Keywords = {{Animal ethics; Machine ethics; Robot ethics; Information ethics;
   Technology ethics; Moral machines; Animal-machine interaction}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{oliver.bendel@fhnw.ch}},
Cited-References = {{Anderson M., 2011, MACHINE ETHICS.
   Bendel O, 2012, MORAL MASCHINEN UBER.
   Bendel O, 2013, TECHNOLOGY ASSESSMEN, P229.
   Bendel O, 2013, UNTERNEHMERZEITUNG, V7, P30.
   Bendel O, 2012, DIE RACHE DER NERDS.
   Bendel O, 2003, THESIS.
   Bendel O, 2012, INFORM SPEKTRUM.
   Bendel O, 2012, BEITRAG GABLER WIRTS.
   Buttner R, 2011, SPIEGEL ONLINE.
   MacDorman KF, 2005, P COGSCI 2005 WORKSH.
   Wendt J, 2013, ZEIT ONLINE.
   Wild Markus, 2006, ANTHR DIFFERENZ GEIS.
   Wolf Ursula, 2012, ETHIK MENSCH TIER BE.
   Wollan Malia, 2010, NY TIMES.}},
Number-of-Cited-References = {{14}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{23}},
Journal-ISO = {{AI Soc.}},
Doc-Delivery-Number = {{DV7WW}},
Unique-ID = {{ISI:000383150000010}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000363479400024,
Author = {Daswani, Mayank and Leike, Jan},
Editor = {{Bieger, J and Goertzel, B and Potapov, A}},
Title = {{A Definition of Happiness for Reinforcement Learning Agents}},
Booktitle = {{ARTIFICIAL GENERAL INTELLIGENCE (AGI 2015)}},
Series = {{Lecture Notes in Artificial Intelligence}},
Year = {{2015}},
Volume = {{9205}},
Pages = {{231-240}},
Note = {{8th International Conference on Artificial General Intelligence (AGI),
   Berlin, GERMANY, JUL 22-25, 2015}},
Organization = {{Kurzweil AI; Keen Software House; OpenCog Fdn; AGI Soc}},
Abstract = {{What is happiness for reinforcement learning agents? We seek a formal
   definition satisfying a list of desiderata. Our proposed definition of
   happiness is the temporal difference error, i.e. the difference between
   the value of the obtained reward and observation and the agent's
   expectation of this value. This definition satisfies most of our
   desiderata and is compatible with empirical research on humans. We state
   several implications and discuss examples.}},
Publisher = {{SPRINGER-VERLAG BERLIN}},
Address = {{HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Leike, J (Reprint Author), Australian Natl Univ, Canberra, ACT, Australia.
   Daswani, Mayank; Leike, Jan, Australian Natl Univ, Canberra, ACT, Australia.}},
DOI = {{10.1007/978-3-319-21365-1\_24}},
ISSN = {{0302-9743}},
ISBN = {{978-3-319-21365-1; 978-3-319-21364-4}},
Keywords = {{Temporal difference error; Reward prediction error; Pleasure;
   Well-being; Optimism; Machine ethics}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory \& Methods}},
Author-Email = {{mayank.daswani@anu.edu.au
   jan.leike@anu.edu.au}},
Cited-References = {{Bostrom N., 2014, SUPERINTELLIGENCE PA.
   BRICKMAN P, 1978, J PERS SOC PSYCHOL, V36, P917, DOI 10.1037/0022-3514.36.8.917.
   Brickman P, 1971, ADAPTATION LEVEL THE, P287.
   Daswani M., 2015, TECHNICAL REPORT.
   Diener E, 2006, AM PSYCHOL, V61, P305, DOI 10.1037/0003-066X.61.4.305.
   Jacobs E., 2014, C AUT AG MULT SYST, P1615.
   Niv Y, 2009, J MATH PSYCHOL, V53, P139, DOI 10.1016/j.jmp.2008.12.005.
   Rutledge R.B., 2014, P NATL ACAD SCI.
   Schmidhuber J, 2010, IEEE T AUTON MENT DE, V2, P230, DOI 10.1109/TAMD.2010.2056368.
   Sutton R. S., 1998, REINFORCEMENT LEARNI.
   SUTTON RS, 1990, {[}No title captured], P497.
   Tomasik B., 2014, TECHNICAL REPORT.}},
Number-of-Cited-References = {{12}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BD7QZ}},
Unique-ID = {{ISI:000363479400024}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000356362200016,
Author = {Millar, Jason},
Book-Group-Author = {{IEEE}},
Title = {{Technology as Moral Proxy Autonomy and Paternalism by Design}},
Booktitle = {{2014 IEEE INTERNATIONAL SYMPOSIUM ON ETHICS IN SCIENCE, TECHNOLOGY AND
   ENGINEERING}},
Year = {{2014}},
Note = {{IEEE International Symposium on Ethics in Science, Technology and
   Engineering, Chicago, IL, MAY 23-24, 2014}},
Organization = {{IEEE}},
Abstract = {{In this paper I argue that in cases where technologies provide material
   answers to moral questions that arise in the use context, they can and
   should be characterized as moral proxies acting on behalf of a person.
   Because of this we can accurately characterize the moral link between
   designers, artefacts and users as a relationship of a particularly moral
   kind. Moral proxies of the human kind have been a topic of analysis for
   some time in healthcare and bioethics, making them a good starting point
   for thinking about moral proxies of the artefactual kind. I draw from
   bioethics and STS literatures to build an analogy between human moral
   proxies in healthcare and artefactual moral proxies. I then turn my
   attention to design ethics considerations. If we accept that artefacts
   can function as moral proxies it becomes important to recognize that
   designers can subject users to paternalistic relationships that are
   ethically problematic. I demonstrate how we can use a proxy analysis as
   a tool for evaluating technologies. I argue that there are situations in
   which engineers should use proxy analysis to avoid paternalism by design
   while simultaneously improving user autonomy.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Millar, J (Reprint Author), Queens Univ, Dept Philosophy, Kingston, ON, Canada.
   Queens Univ, Dept Philosophy, Kingston, ON, Canada.}},
ISBN = {{978-1-4799-4992-2}},
Keywords = {{design ethics; engineering ethics; robot ethics; machine ethics; proxy
   analysis; autonomy; paternalism by design; self-driving cars; driverless
   cars; internal cardiac defibrillator}},
Research-Areas = {{Computer Science; Social Sciences - Other Topics; History \& Philosophy
   of Science}},
Web-of-Science-Categories  = {{Computer Science, Interdisciplinary Applications; Ethics; History \&
   Philosophy Of Science}},
Author-Email = {{jason.millar@queensu.ca}},
Cited-References = {{CANTOR N, 2005, MAKING MED DECISIONS.
   College of Nurses of Ontario, 2009, PRACT GUID CONS.
   Draper H., 2007, BIOETHICS READER EDI, P73.
   Guizzo E., 2011, IEEE SPECTRUM.
   Hayden E., 2012, TIME NEWSFEED    SEP.
   Kerr Ian, 2010, RADICAL EXTREMISM BA.
   Kluge E-H., 2005, READINGS BIOMEDICAL, V3rd, P146.
   Kluge E-H., 2005, READINGS BIOMEDICAL, V3rd, P186.
   Latour Bruno., 1992, SHAPING TECHNOLOGY B, P225.
   Laursen L., 2014, IEEE SPECTRUM.
   Lin Patrick, 2013, ATLANTIC.
   Marcus Gary, 2012, NEW YORKER.
   Murray PM., 1990, IOWA ORTHOP J, V10, P104.
   Newcomb D., 2012, WIRED AUTOPIA    SEP.
   O'Neill O, 2002, AUTONOMY TRUST BIOET.
   Pollock A, 2008, INNER HIST DEVICES, P98.
   Slosson M., 2012, REUTERS          MAY.
   Vanderbilt T., 2012, WIRED, P86.
   Verbeek PP, 2006, SCI TECHNOL HUM VAL, V31, P361, DOI 10.1177/0162243905285847.
   Winner L, 1986, WHALE REACTOR.}},
Number-of-Cited-References = {{20}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BC9DX}},
Unique-ID = {{ISI:000356362200016}},
DA = {{2020-06-17}},
}

@article{ ISI:000324634600011,
Author = {Guarini, Marcello},
Title = {{Introduction: Machine Ethics and the Ethics of Building Intelligent
   Machines}},
Journal = {{TOPOI-AN INTERNATIONAL REVIEW OF PHILOSOPHY}},
Year = {{2013}},
Volume = {{32}},
Number = {{2}},
Pages = {{213-215}},
Month = {{OCT}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Guarini, M (Reprint Author), Univ Windsor, Windsor, ON N9B 3P4, Canada.
   Univ Windsor, Windsor, ON N9B 3P4, Canada.}},
DOI = {{10.1007/s11245-013-9183-x}},
ISSN = {{0167-7411}},
Research-Areas = {{Philosophy}},
Web-of-Science-Categories  = {{Philosophy}},
Author-Email = {{mguarini@uwindsor.ca}},
Cited-References = {{Anderson M, 2011, MACHINE ETHICS, P7.
   Anderson M., 2011, MACHINE ETHICS.
   Anderson M., 2011, MACHINE ETHICS, P1.
   Anderson M, 2007, AI MAG, V28, P15.
   Anderson SL, 2011, MACHINE ETHICS, P21, DOI DOI 10.1017/CB09780511978036.004.
   DANIELSON P, 1992, {[}No title captured].
   Dennett D. I., 1978, BRAINSTORMS PHILOS E.
   Guarini M., 2011, MACHINE ETHICS, P316.
   Lin P, 2012, INTELL ROBOT AUTON, P1.
   TURING A, 1950, {[}No title captured], V49, P433, DOI DOI 10.1093/MIND/LIX.236.433.
   Veruggio G, 2012, INTELL ROBOT AUTON, P347.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.}},
Number-of-Cited-References = {{12}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{Topoi-Int. Rev. Philos.}},
Doc-Delivery-Number = {{221CI}},
Unique-ID = {{ISI:000324634600011}},
OA = {{Bronze}},
DA = {{2020-06-17}},
}

@article{ ISI:000324634600016,
Author = {Guarini, Marcello},
Title = {{Moral Case Classification and the Nonlocality of Reasons}},
Journal = {{TOPOI-AN INTERNATIONAL REVIEW OF PHILOSOPHY}},
Year = {{2013}},
Volume = {{32}},
Number = {{2}},
Pages = {{267-289}},
Month = {{OCT}},
Abstract = {{This paper presents the results of training an artificial neural network
   (ANN) to classify moral situations. The ANN produces a similarity space
   in the process of solving its classification problem. The state space is
   subjected to analysis that suggests that holistic approaches to
   interpreting its functioning are problematic. The idea of a contributory
   or pro tanto standard, as discussed in debates between moral
   particularists and generalists, is used to understand the structure of
   the similarity space generated by the ANN. A spectrum of possibilities
   for reasons, from atomistic to holistic, is discussed. Reasons are
   understood as increasing in nonlocality as they move away from atomism.
   It is argued that contributory standards could be used to understand
   forms of nonlocality that need not go all the way to holism. It is also
   argued that contributory standards may help us to understand the kind of
   similarity at work in analogical reasoning and argument in ethics. Some
   objections to using state space approaches to similarity are dealt with,
   as are objections to using empirical and computational work in
   philosophy.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Guarini, M (Reprint Author), Univ Windsor, Windsor, ON N9B 3P4, Canada.
   Univ Windsor, Windsor, ON N9B 3P4, Canada.}},
DOI = {{10.1007/s11245-012-9130-2}},
ISSN = {{0167-7411}},
EISSN = {{1572-8749}},
Keywords = {{Analogy; Atomism of reasons; Moral generalism; Holism of reasons;
   Machine ethics; Nonlocality of reasons; Moral particularism; Similarity}},
Research-Areas = {{Philosophy}},
Web-of-Science-Categories  = {{Philosophy}},
Author-Email = {{mguarini@uwindsor.ca}},
Cited-References = {{Austin John L, 1962, DO THINGS WORDS W JA.
   Brewer S, 1996, HARVARD LAW REV, V109, P923, DOI 10.2307/1342258.
   Churchland P, 2007, NEUROPHILOSOPHY AT WORK, P1, DOI 10.1017/CBO9780511498435.
   CHURCHLAND PM, 1989, {[}No title captured].
   Coleman J., 1986, OXFORD HDB JURISPRUD, P588.
   Dancy J, 2000, MORAL PARTICULARISM, P130.
   Dancy J, 2004, ETHICS PRINCIPLES.
   Dancy J, 1999, P 20 WORLD C PHIL, VI.
   GENTNER D, 1983, COGNITIVE SCI, V7, P155, DOI 10.1207/s15516709cog0702\_3.
   Goswami U, 2001, ANALOGICAL MIND, P437.
   Greene J, 2002, TRENDS COGN SCI, V6, P517, DOI 10.1016/S1364-6613(02)02011-9.
   Guarini M, INSIGHTS PHILOS JURI.
   Guarini M., 2010, RATIO JURIS, V23, P65.
   Guarini M., 2011, MACHINE ETHICS, P316.
   Guarini M, 2010, MIND MACH, V20, P385, DOI 10.1007/s11023-010-9200-4.
   Guarini M, 2009, INFORMAL LOG, V29, P84.
   Guarini Marcello, 2004, INFORMAL LOG, V24, P153, DOI DOI 10.22329/IL.V24I2.2141.
   JACKSON F, 2000, {[}No title captured].
   Laakso A, 2006, CHURCHLAND CONNECTIO.
   MARKMAN AB, 2005, NEW UNCONSCIOUS.
   McKeever S, 2006, PRINCIPLED ETHICS GE.
   Mikhail J., 2011, ELEMENTS MORAL COGNI.
   Nichols S., 2004, SENTIMENTAL RULES NA.
   O'Reilly R. C., 2000, COMPUTATIONAL EXPLOR.
   Postema GJ, 2007, CAMB STUD PHIL LAW, P102, DOI 10.1017/CBO9780511551116.005.
   Rissland EL, 2006, IEEE INTELL SYST, V21, P39, DOI 10.1109/MIS.2006.38.
   Sunstein, 2000, RATIO JURIS, V13, P117.
   Sunstein C., 1996, LEGAL REASONING POLI.
   SUNSTEIN CR, 1993, HARVARD LAW REV, V106, P741, DOI 10.2307/1341662.
   SUNSTEIN CR, 1999, {[}No title captured].
   THOMSON JJ, 1971, PHILOS PUBLIC AFF, V1, P47.
   Young L, 2012, SOC NEUROSCI-UK, V7, P1, DOI 10.1080/17470919.2011.569146.}},
Number-of-Cited-References = {{32}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{Topoi-Int. Rev. Philos.}},
Doc-Delivery-Number = {{221CI}},
Unique-ID = {{ISI:000324634600016}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000340565300020,
Author = {Pontier, Matthijs A. and Widdershoven, Guy A. M.},
Editor = {{Papadopoulos, H and Andreou, AS and Iliadis, L and Maglogiannis, I}},
Title = {{Robots That Stimulate Autonomy}},
Booktitle = {{ARTIFICIAL INTELLIGENCE APPLICATIONS AND INNOVATIONS, AIAI 2013}},
Series = {{IFIP Advances in Information and Communication Technology}},
Year = {{2013}},
Volume = {{412}},
Pages = {{195-204}},
Note = {{9th IFIP WG 12.5 International Conference on Artificial Intelligence
   Applications and Innovations (AIAI), Paphos, CYPRUS, SEP 30-OCT 02, 2013}},
Organization = {{Int Federat Informat Proc, Working Grp 12 5; Cyprus Univ Technol;
   Frederick Univ; Royal Holloway; Univ London, Comp Sci Dept; Cyprus
   Tourism Org}},
Abstract = {{In healthcare, robots are increasingly being used to provide a high
   standard of care in the near future. When machines interact with humans,
   we need to ensure that these machines take into account patient
   autonomy. Autonomy can be defined as negative autonomy and positive
   autonomy. We present a moral reasoning system that takes into account
   this twofold approach of autonomy. In simulation experiments, the system
   matches the decision of the judge in a number of law cases about medical
   ethical decisions. This may be useful in applications where robots need
   to constrain the negative autonomy of a person to stimulate positive
   autonomy, for example when attempting to pursue a patient to make a
   healthier choice.}},
Publisher = {{SPRINGER-VERLAG BERLIN}},
Address = {{HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Pontier, MA (Reprint Author), Vrije Univ Amsterdam, Network Inst, Ctr Adv Media Res Amsterdam, Boelelaan 1081, NL-1081 HV Amsterdam, Netherlands.
   Pontier, Matthijs A., Vrije Univ Amsterdam, Network Inst, Ctr Adv Media Res Amsterdam, Boelelaan 1081, NL-1081 HV Amsterdam, Netherlands.
   Widdershoven, Guy A. M., Vrije Univ Amsterdam, VU Univ Med Ctr, Amsterdam, Netherlands.}},
ISSN = {{1868-4238}},
ISBN = {{978-3-642-41141-0; 978-3-642-41142-7}},
Keywords = {{Moral Reasoning; Machine Ethics; Cognitive Modeling; Cognitive Robotics;
   Health Care Applications}},
Research-Areas = {{Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory \& Methods; Telecommunications}},
Author-Email = {{m.a.pontier@vu.nl
   g.widdershoven@vumc.nl}},
Funding-Acknowledgement = {{SELEMCA project within CRISP {[}NWO 646.000.003]}},
Funding-Text = {{This study is part of the SELEMCA project within CRISP (grant number:
   NWO 646.000.003).}},
Cited-References = {{Agich G.J., 2003, AUTONOMY LONG TERM C.
   Anderson M., 2005, MACH ETH AAAI FALL S.
   Anderson M., 2008, SCI, V107.
   Banks MR, 2008, J AM MED DIR ASSOC, V9, P173, DOI 10.1016/j.jamda.2007.11.007.
   Beauchamp T., 2001, PRINCIPLES BIOMEDICA.
   Berlin Isaiah, 1958, 2 CONCEPTS LIBERTY.
   Buchanan A.E., 1989, DECIDING OTHERS ETHI.
   Hoorn JF, 2012, COGN SYST RES, V15-16, P33, DOI 10.1016/j.cogsys.2011.04.001.
   Karimi A., 2012, SPITS, V5.
   Moody H.R., 1996, ETHICS AGEING SOC.
   Picard R. W., 1997, AFFECTIVE COMPUTING.
   Pontier M. A., 2012, P 34 INT ANN C COGN, P2198.
   Pontier MA, 2012, LECT NOTES ARTIF INT, V7637, P442, DOI 10.1007/978-3-642-34654-5\_45.
   Robins B., 2005, J UNIVERSAL ACCESS I, V4, P105.
   Van Wynsberghe A., 2012, J SCI ENG E IN PRESS.
   Wada K, 2009, J ADV COMPUT INTELL, V13, P386, DOI 10.20965/jaciii.2009.p0386.
   WHO, 2010, AGEING.
   Widdershoven GAM, 2012, AUTONOMY MENTAL DISO, P217.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BB0PB}},
Unique-ID = {{ISI:000340565300020}},
DA = {{2020-06-17}},
}

@article{ ISI:000323642000007,
Author = {Guarini, Marcello},
Title = {{Conative Dimensions of Machine Ethics: A Defense of Duty}},
Journal = {{IEEE TRANSACTIONS ON AFFECTIVE COMPUTING}},
Year = {{2012}},
Volume = {{3}},
Number = {{4}},
Pages = {{434-442}},
Month = {{OCT-DEC}},
Abstract = {{Immanuel Kant is one of the giants of moral theorizing in the western
   philosophical tradition. He developed a view of moral imperatives and
   duty that continues to inspire thought up to the present. In a
   thought-provoking series of papers, Anthony Beavers argues that Kant's
   conception of morality will not be applicable to machines. In other
   words, it will turn out that when we design machines at a level of
   sophistication such that ethical constraints must be built into their
   behavior, Kant's understanding of morality will not be helpful.
   Specifically, the notion of duty as involving some sort of internal
   conflict can be jettisoned. The argument in this paper is that there are
   aspects of duty that can be preserved for machine ethics. The goal will
   not be to defend any of the details of Kant's position. Rather, it is to
   motivate some ways of thinking about duty that may be useful for machine
   ethics.}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Guarini, M (Reprint Author), Univ Windsor, Dept Philosophy, Fac Arts \& Social Sci, 401 Sunset, Windsor, ON N9B 3P4, Canada.
   Guarini, Marcello, Univ Windsor, Dept Philosophy, Fac Arts \& Social Sci, Windsor, ON N9B 3P4, Canada.}},
DOI = {{10.1109/T-AFFC.2012.27}},
ISSN = {{1949-3045}},
Keywords = {{Desire-obligation conflict; duty; ethics; machine ethics;
   obligation-obligation conflict}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Cybernetics}},
Author-Email = {{mguarini@uwindsor.ca}},
Cited-References = {{Beavers A., DIGITAL ETHICS RES P.
   Beavers A., P ASS PRACT PROF ETH, P2099.
   Beavers AF, 2012, INTELL ROBOT AUTON, P333.
   Dennett D. I., 1978, BRAINSTORMS PHILOS E.
   Fodor J. A., 2008, LOT2 LANGUAGE THOUGH.
   Gregor MJ, 1996, CRITIQUE PRACTICAL R.
   Kant I, 1785, GROUNDING METAPHYSIC.
   Pollock J., 1989, BUILD PERSON PROLEGO, P3.
   Pollock J.L., 1995, COGNITIVE CARPENTRY.
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77.
   Sinnott-Armstrong W., 2011, STANFORD ENCY PHILOS.}},
Number-of-Cited-References = {{11}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{IEEE Trans. Affect. Comput.}},
Doc-Delivery-Number = {{207YX}},
Unique-ID = {{ISI:000323642000007}},
DA = {{2020-06-17}},
}

@article{ ISI:000297438700011,
Author = {Collins, Nick},
Title = {{Trading Faures: Virtual Musicians and Machine Ethics}},
Journal = {{LEONARDO MUSIC JOURNAL}},
Year = {{2011}},
Volume = {{21}},
Pages = {{35-39}},
Abstract = {{Increased maturity in modeling human musicianship leads to many
   interesting artistic achievements and challenges. This article takes the
   opportunity to reflect on future situations in which virtual musicians
   are traded like baseball cards, associated content-creator and
   autonomous musical agent rights, and the musical and moral conundrums
   that may result. Although many scenarios presented here may seem
   far-fetched with respect to the current level of artificial
   intelligence, it remains prudent and artistically stimulating to
   consider them. Accepting basic human curiosity and research teleology,
   it is salutary to consider the more distant consequences of our actions
   with respect to aesthetics and ethics.}},
Publisher = {{MIT PRESS}},
Address = {{ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Collins, N (Reprint Author), Univ Sussex, Dept Informat, Brighton BN1 9QJ, E Sussex, England.
   Univ Sussex, Dept Informat, Brighton BN1 9QJ, E Sussex, England.}},
DOI = {{10.1162/LMJ\_a\_00059}},
ISSN = {{0961-1215}},
EISSN = {{1531-4812}},
Keywords-Plus = {{SOMETIMES; ROBOT; HARD}},
Research-Areas = {{Music}},
Web-of-Science-Categories  = {{Music}},
Author-Email = {{N.Collins@sussex.ac.uk}},
Cited-References = {{Barfield W, 2005, PRESENCE-TELEOP VIRT, V14, P741, DOI 10.1162/105474605775196607.
   BARFIELD W, 2006, {[}No title captured], V39, P649.
   BONADA J, 2007, IEEE SIGNAL PROC MAR.
   BURNS J, 2010, CELEBRITY IMAGE RIGH.
   Collins N, 2007, CAMB COMPANION MUSIC, P1, DOI 10.1017/CCOL9780521868617.
   Collins N, 2009, INTRO COMPUTER MUSIC.
   Collins N., 2008, P INT COMP MUS C BEL.
   Cope David, 2005, COMPUTER MODELS MUSI.
   deGrey ADNJ, 2004, WE WILL BE ABLE LIVE.
   Gibson W, 1996, IDORU.
   HARO M, 2010, 5 AUD MOSTL C C INT.
   HSU B, 2010, COMMUNICATION   1212.
   KAPUR A, 2010, COMMUNICATION   1123.
   Kapur Ajay, 2005, P INT COMP MUS C ICM.
   KATZ M, 2004, CAPTURING SOUND TECH, P67.
   Klapuri A, 2006, SIGNAL PROCESSING ME.
   Lastowka FG, 2004, CALIF LAW REV, V92, P1, DOI 10.2307/3481444.
   Lessig L., 2004, FREE CULTURE NATURE.
   Mancini M, 2007, IEEE T AUDIO SPEECH, V15, P1833, DOI 10.1109/TASL.2007.899256.
   Matrix Sidney Eve, 2006, CYBERPOP DIGITAL LIF.
   McCutcheon MA, 2007, POP MUSIC, V26, P259, DOI 10.1017/S0261143007001225.
   MICHAELS S, 2009, GUARDIAN        0910.
   Miller P, 2008, SOUND UNBOUND SAMPLI.
   MURRAY R, 2009, GUITAR HERO KURT COB.
   Nakano T., 2009, P 6 SOUND MUS COMP C, P343.
   PARKER R, 2004, A DEGREY 1 PERSON LI.
   Reidsma D, 2008, COMPUT ENTERTAIN, V6, P1, DOI DOI 10.1145/1461999.1462005.
   Reynolds Simon, 2005, RIP IT START AGAIN.
   ROWE R, 1997, P INT COMP MUS C THE.
   Russell S, 2003, ARTIFICIAL INTELLIGE.
   Sartor G, 2009, ARTIF INTELL LAW, V17, P253, DOI 10.1007/s10506-009-9081-0.
   SILVERBERG R, 1989, CONGLOMEROID COCKTAI, P152.
   SINGER E, 1996, INT S EL ART.
   Stout Rowland, 2008, ROUTLEDGE COMPANION, P851.
   TAYLOR R, 2005, P NIME VANC.
   Thimbleby H, 2008, INTERACT COMPUT, V20, P338, DOI 10.1016/j.intcom.2008.02.006.
   Vonnegut K., 1952, PLAYER PIANO.
   WERDE B, 2003, NY TIMES        1123.
   Whitby B, 2008, INTERACT COMPUT, V20, P326, DOI 10.1016/j.intcom.2008.02.002.
   WORLD IS MINE LIVE H.}},
Number-of-Cited-References = {{40}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{10}},
Journal-ISO = {{Leonardo Music J.}},
Doc-Delivery-Number = {{853PR}},
Unique-ID = {{ISI:000297438700011}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000262046200066,
Author = {Letchford, Joshua and Conitzer, Vincent and Jain, Kamal},
Editor = {{Papadimitriou, C and Zhang, S}},
Title = {{An ``Ethical{''} Game-Theoretic Solution Concept for Two-Player
   Perfect-Information Games}},
Booktitle = {{INTERNET AND NETWORK ECONOMICS, PROCEEDINGS}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2008}},
Volume = {{5385}},
Pages = {{696+}},
Note = {{4th International Workshop on Internet and Network Economics, Shanghai,
   PEOPLES R CHINA, DEC 17-20, 2008}},
Abstract = {{The standard solution concept for perfect-information extensive form
   games is subgame perfect Nash equilibrium. However, humans do not always
   play according to a subgame perfect Nash equilibrium, especially in
   games where it is possible for all the players to obtain much higher
   payoffs if they place some trust in each other (and this trust is not
   violated). In this paper, we introduce a new solution concept for
   two-player perfect-information games that attempts to model this type of
   trusting behavior (together with the ``ethical{''} behavior of not
   violating that trust). The concept takes subgame perfect equilibrium as
   a starting point, but then repeatedly resolves the game based on the
   players being able to trust each other. We give two distinct algorithmic
   definitions of the concept and show that they are equivalent. Finally,
   we give a fast implementation of one of the algorithms for solving the
   game, and show that it runs in time O(n log n + nh log (n/h)).}},
Publisher = {{SPRINGER-VERLAG BERLIN}},
Address = {{HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Letchford, J (Reprint Author), Duke Univ, Dept Comp Sci, Durham, NC 27706 USA.
   Letchford, Joshua; Conitzer, Vincent, Duke Univ, Dept Comp Sci, Durham, NC 27706 USA.
   Jain, Kamal, Microsoft Res, Waco, TX USA.}},
ISSN = {{0302-9743}},
EISSN = {{1611-3349}},
ISBN = {{978-3-540-92184-4}},
Keywords-Plus = {{CENTIPEDE GAME; MACHINE ETHICS}},
Research-Areas = {{Business \& Economics; Computer Science}},
Web-of-Science-Categories  = {{Business; Computer Science, Information Systems; Computer Science,
   Theory \& Methods; Economics}},
Author-Email = {{jcl@cs.duke.edu
   conitzer@cs.duke.edu
   kamalj@microsoft.com}},
Funding-Acknowledgement = {{National Science FoundationNational Science Foundation (NSF); Alfred P.
   Sloan FoundationAlfred P. Sloan Foundation {[}IIS-0812113]}},
Funding-Text = {{We thank the National Science Foundation and the Alfred P. Sloan
   Foundation for support(through award number IIS-0812113 and a Research
   Fellowship, respectively).}},
Cited-References = {{ANDERSON M, 2006, AAAI, P1759.
   Anderson M, 2007, MIND MACH, V17, P1, DOI 10.1007/s11023-007-9053-7.
   Gal Y., 2007, AAAI.
   GROSZ BJ, 2004, {[}No title captured], P782.
   Guarini M, 2006, IEEE INTELL SYST, V21, P22, DOI 10.1109/MIS.2006.76.
   King-Casas B, 2005, SCIENCE, V308, P78, DOI 10.1126/science.1108062.
   LITTMAN ML, 2006, UAI.
   MCKELVEY RD, 1992, ECONOMETRICA, V60, P803, DOI 10.2307/2951567.
   McLaren BM, 2006, IEEE INTELL SYST, V21, P29, DOI 10.1109/MIS.2006.67.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Nagel R, 1998, J MATH PSYCHOL, V42, P356, DOI 10.1006/jmps.1998.1225.
   TALMAN S, 2005, AAMAS.
   Tucker A., 2001, READINGS GAMES INFOR.
   Zak PJ, 2005, HORM BEHAV, V48, P522, DOI 10.1016/j.yhbeh.2005.07.009.
   ZAK PJ, 2008, {[}No title captured], P88.}},
Number-of-Cited-References = {{15}},
Times-Cited = {{2}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BIQ41}},
Unique-ID = {{ISI:000262046200066}},
DA = {{2020-06-17}},
}

@article{ ISI:000512691600022,
Author = {Bauer, William A.},
Title = {{Virtuous vs. utilitarian artificial moral agents}},
Journal = {{AI \& SOCIETY}},
Year = {{2020}},
Volume = {{35}},
Number = {{1}},
Pages = {{263-271}},
Month = {{MAR}},
Abstract = {{Given that artificial moral agents-such as autonomous vehicles, lethal
   autonomous weapons, and automated trading systems-are now part of the
   socio-ethical equation, we should morally evaluate their behavior. How
   should artificial moral agents make decisions? Is one moral theory
   better suited than others for machine ethics? After briefly overviewing
   the dominant ethical approaches for building morality into machines,
   this paper discusses a recent proposal, put forward by Don Howard and
   Ioan Muntean (2016, 2017), for an artificial moral agent based on virtue
   theory. While the virtuous artificial moral agent has various strengths,
   this paper argues that a rule-based utilitarian approach (in contrast to
   a strict act utilitarian approach) is superior, because it can capture
   the most important features of the virtue-theoretic approach while
   realizing additional significant benefits. Specifically, a two-level
   utilitarian artificial moral agent incorporating both established moral
   rules and a utility calculator is especially well suited for machine
   ethics.}},
Publisher = {{SPRINGER}},
Address = {{ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Bauer, WA (Reprint Author), North Carolina State Univ, Dept Philosophy \& Religious Studies, 340 Withers Hall,Campus Box 8103, Raleigh, NC 27695 USA.
   Bauer, William A., North Carolina State Univ, Dept Philosophy \& Religious Studies, 340 Withers Hall,Campus Box 8103, Raleigh, NC 27695 USA.}},
DOI = {{10.1007/s00146-018-0871-3}},
ISSN = {{0951-5666}},
EISSN = {{1435-5655}},
Keywords = {{Machine ethics; Artificial moral agent; Machine learning; Virtue theory;
   Two-level utilitarianism}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{wabauer@ncsu.edu}},
Cited-References = {{Anderson M, 2006, MEDETHEX PROTOTYPE M, P1759.
   Anderson M, 2004, MACHINE ETHICS IMPLE.
   Anderson SL, 2011, P 12 AAAI C HUM ROB, P2.
   Aristotle, INTERNET CLASSICS AR.
   Bentham Jeremy, 1789, COLLECTED WORKS J BE.
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82.
   Doyle J., 1983, AI MAG, V4, P50.
   FLORIDI L., 2013, ETHICS INFORM.
   Foot P., 1967, OXFORD REV, V5, P5, DOI {[}DOI 10.1093/0199252866.003.0002, DOI 10.1002/9781444323528.CH41].
   Grau C, 2006, IEEE INTELL SYST, V21, P52, DOI 10.1109/MIS.2006.81.
   Hare RM, 1983, MORAL THINKING ITS L.
   Hooker B, 2000, IDEAL CODE REAL WORL.
   Howard D, 2016, MINIMALIST MODEL ART.
   Howard D, 2017, PHILOS STUD SER, V128, P121, DOI 10.1007/978-3-319-61043-6\_7.
   JACKSON F, 1998, {[}No title captured].
   Kahneman D., 2011, THINKING FAST SLOW.
   Kant I., 1785, GROUNDWORK METAPHYSI.
   Leben D, 2017, ETHICS INF TECHNOL, V19, P107, DOI 10.1007/s10676-017-9419-3.
   MILL JS, 1861, {[}No title captured].
   Nathanson S, 2018, INTERNET ENCY PHILOS.
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77.
   Rawls J, 1971, THEORY JUSTICE.
   Ross W. D., 1930, RIGHT GOOD.
   Singer P, 2011, EXPANDING CIRCLE ETH.
   Varner GE, 2012, PERSONHOOD ETHICS AN.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.}},
Number-of-Cited-References = {{26}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{4}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{AI Soc.}},
Doc-Delivery-Number = {{KK4CH}},
Unique-ID = {{ISI:000512691600022}},
DA = {{2020-06-17}},
}

@article{ ISI:000512691600017,
Author = {Gordon, John-Stewart},
Title = {{What do we owe to intelligent robots?}},
Journal = {{AI \& SOCIETY}},
Year = {{2020}},
Volume = {{35}},
Number = {{1}},
Pages = {{209-223}},
Month = {{MAR}},
Abstract = {{Great technological advances in such areas as computer science,
   artificial intelligence, and robotics have brought the advent of
   artificially intelligent robots within our reach within the next
   century. Against this background, the interdisciplinary field of machine
   ethics is concerned with the vital issue of making robots ``ethical{''}
   and examining the moral status of autonomous robots that are capable of
   moral reasoning and decision-making. The existence of such robots will
   deeply reshape our socio-political life. This paper focuses on whether
   such highly advanced yet artificially intelligent beings will deserve
   moral protection (in the form of being granted moral rights) once they
   become capable of moral reasoning and decision-making. I argue that we
   are obligated to grant them moral rights once they have become full
   ethical agents, i.e., subjects of morality. I present four related
   arguments in support of this claim and thereafter examine four main
   objections to the idea of ascribing moral rights to artificial
   intelligent robots.}},
Publisher = {{SPRINGER}},
Address = {{ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Gordon, JS (Reprint Author), Vytautas Magnus Univ, Fac Polit Sci \& Diplomacy, Dept Philosophy \& Social Crit, V Putvinskio G 23, LT-44243 Kaunas, Lithuania.
   Gordon, John-Stewart, Vytautas Magnus Univ, Fac Polit Sci \& Diplomacy, Dept Philosophy \& Social Crit, V Putvinskio G 23, LT-44243 Kaunas, Lithuania.}},
DOI = {{10.1007/s00146-018-0844-6}},
ISSN = {{0951-5666}},
EISSN = {{1435-5655}},
Keywords = {{Artificially intelligent robots; Moral status; Moral rights; Moral
   agency; Full ethical agents; Machine rights}},
Keywords-Plus = {{DIGNITY}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{jostgo76@gmail.com}},
Funding-Acknowledgement = {{European Social FundEuropean Social Fund (ESF) {[}09.3.3-LMT-K-712]}},
Funding-Text = {{This research is funded by the European Social Fund according to the
   activity `Improvement of researchers' qualification by implementing
   world-class R\&D projects of Measure No. 09.3.3-LMT-K-712.}},
Cited-References = {{Allen C., 2011, MACHINE ETHICS, P51.
   Altman MC, 2011, KANT APPL ETHICS USE.
   Anderson M., 2011, MACHINE ETHICS.
   Anderson SL, 2011, MACHINE ETHICS, P285.
   Anderson SL, 2011, MACHINE ETHICS, P21, DOI DOI 10.1017/CB09780511978036.004.
   apek K, 1920, ROSSUMS UNIVERSAL RO.
   Asimov I, 1942, RUNAROUND SHORT STOR.
   Asimov I, 1986, ROBOTS EMPIRE CLASSI.
   Atapattu Sumudu, 2015, HUMAN RIGHTS APPROAC.
   Bringsjord S, 2008, AI SOC, V22, P539, DOI 10.1007/s00146-007-0090-9.
   Bryson J. J., 2010, CLOSE ENGAGEMENTS AR, P63.
   Calverley D., 2011, MACHINE ETHICS, P213.
   Clark R, 2011, MACHINE ETHICS, P254.
   Cochrane A, 2010, BIOETHICS, V24, P234, DOI 10.1111/j.1467-8519.2009.01781.x.
   Coeckelbergh M., 2014, PHILOS TECHNOLOGY, V27, P61, DOI {[}10.1007/s13347-013-0133-8, DOI 10.1007/S13347-013-0133-8].
   Darling K, 2016, ROBOT LAW, P213, DOI DOI 10.4337/9781783476732.00017.
   Davenport D., 2014, PHILO TECH, V27, P47.
   Dehghani M, 2011, MACHINE ETHICS, P422.
   Delvaux M, 2017, REPORT RECOMMENDATIO.
   Dennett D, 1998, HALS LEGACY 2001S CO, P351.
   Donaldson S, 2013, ZOOPOLIS POLITICAL T.
   Doring SA, 2002, DTSCH Z PHILOS.
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   Floridi L, 2011, MACHINE ETHICS, P184.
   Francione GL, 2009, ANIMALS PERSONS ESSA.
   Frankfurt H. G., 1971, J PHILOS, V68, P5, DOI DOI 10.2307/2024717.
   FRANKFURT HG, 1969, J PHILOS, V66, P829, DOI 10.2307/2023833.
   Gibilisco S, 2003, CONCISE ENCY ROBOTIC.
   Gordon JS, 2017, HUMAN RIGHTS AND DISABILITY: INTERDISCIPLINARY PERSPECTIVES, P9.
   Gordon JS, 2014, GLOBAL BIOETHICS HUM, P68.
   Gordon JS, 2016, OXFORD BIBLIO PHILOS.
   Gordon JS, 2013, INTERNET ENCY PHILOS.
   Grau C, 2011, MACHINE ETHICS, P451.
   Guarini M, 2006, IEEE INTELL SYST, V21, P22, DOI 10.1109/MIS.2006.76.
   Gunkel D, 2014, PHILOS TECHNOLOGY, V27, P5.
   Gunkel D. J., 2012, MACH QUEST CRIT.
   Gunkel DJ, 2014, PHILOS TECHNOL, V27, P113, DOI DOI 10.1007/S13347-013-0121-Z.
   Hall J. S., 2011, MACHINE ETHICS, P512, DOI DOI 10.1017/CBO9780511978036.
   Hanna R., 2003, THEORIA HIST SCI, V7, P24.
   Hernandez-Orallo J, 2017, MEASURE ALL MINDS EV.
   Johnson AM, 2014, P IEEE 2014 INT S ET, V30, P1.
   Johnson KE, 2011, ESL APPL LING PROF, P168.
   Kane R., 2002, OXFORD HDB FREE WILL.
   Kant I, 2009, GROUNDWORK METAPHYSI.
   Knapton S, 2017, ALPHAGO ZERO GOOGLE.
   Koch T, 2004, J MED PHILOS, V29, P697, DOI 10.1080/03605310490882975.
   Levy D., 2007, LOVE SEX ROBOTS EVOL.
   Lin P., 2014, ROBOT ETHICS ETHICAL.
   Macklin R, 2003, BRIT MED J, V327, P1419, DOI 10.1136/bmj.327.7429.1419.
   Meyer M, 2001, J Soc Philos, V32, P115, DOI 10.1111/0047-2786.00083.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Nadeau JE, 2006, THINKING ANDROID EPI, P241.
   Nussbaum M., 2006, FRONTIERS JUSTICE DI.
   Picard R. W., 1997, AFFECTIVE COMPUTING.
   Rodogno R, 2016, EMERG TECH ETH INT A, P39.
   Rzepka R, 2005, AAAI FALL S MACH ETH.
   Searle John, 1994, REDISCOVERY MIND.
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038.
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270.
   SINGER P, 1979, {[}No title captured].
   Singer P, 2009, METAPHILOSOPHY, V40, P567, DOI 10.1111/j.1467-9973.2009.01608.x.
   Singer Peter, 1975, ANIMAL LIBERATION.
   Singh PK, 2012, PLANT BIOSYST, V146, P302, DOI 10.1080/11263504.2011.602991.
   Sullins JP, 2011, MACHINE ETHICS, V6, P151, DOI 10.1017/CBO9780511978036.021.
   Torrance S, 2005, TECHNICAL REPORT MAC, P88.
   Turkle S, 2011, MACHINE ETHICS, P62.
   U Pothast, 1978, SUHRKAMP TASCHENBUCH.
   United Nations, 2016, SUST DEV GOALS REP, P1.
   Wallach W., 2010, MORAL MACHINES TEACH.
   WARREN MA, 1973, MONIST, V57, P43, DOI 10.5840/monist197357133.
   WATSON G, 2003, {[}No title captured].
   Whitby B, 2011, MACHINE ETHICS, P138.
   Ziff P, 1959, ANALYSIS, V19, P64.
   Zuolo F, 2016, ETHICAL THEORY MORAL, V19, P1117, DOI 10.1007/s10677-016-9695-8.}},
Number-of-Cited-References = {{74}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{9}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{AI Soc.}},
Doc-Delivery-Number = {{KK4CH}},
Unique-ID = {{ISI:000512691600017}},
DA = {{2020-06-17}},
}

@article{ ISI:000496165000013,
Author = {Williams, Rowan},
Title = {{EPIPHANY PHILOSOPHERS: AFTERWORD with Fraser Watts, ``Mutual Enhancement
   between Science and Religion: In the Footsteps of the Epiphany
   Philosophers{''}; William H. Beharrell, ``Transformation and the Waking
   Body: A Return to Truth via Our Bodies{''}; Marius Dorobantu and Yorick
   Wilks, ``Moral Orthoses: A New Approach to Human and Machine Ethics{''};
   Galen Watts, ``Religion, Science, and Disenchantment in Late
   Modernity{''}; and Rowan Williams, ``Epiphany Philosophers:
   Afterword.{''}}},
Journal = {{ZYGON}},
Year = {{2019}},
Volume = {{54}},
Number = {{4}},
Pages = {{1036-1044}},
Month = {{DEC}},
Abstract = {{Being a theist makes a difference, but not so much to what propositions
   we assent to, nor to an expanded ontology of spiritual entities. Rather,
   it is concerned with what commitments we enter into, and involves a
   participatory engagement with a broader reality then we might have
   supposed was possible. Embodied practices are a crucial part of the
   contemplative path, which draws on the wisdom of the body. This leads on
   to a ``labor of culture.{''} Our present culture is not obviously as
   secular as supposed to be, but what has now become sacred is a strong
   sense of the individual ego, around which many ethical and political
   commitments are built, and which sits uneasily with our widely accepted
   mechanistic view of life. The crucial challenge to artificial
   intelligence is whether it can find ways of enhancing the mutual
   recognition that is crucial to the ethical life.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Williams, R (Reprint Author), Magdalene Coll, Cambridge, England.
   Williams, Rowan, Magdalene Coll, Cambridge, England.}},
DOI = {{10.1111/zygo.12561}},
ISSN = {{0591-2385}},
EISSN = {{1467-9744}},
Keywords = {{artificial intelligence; body; contemplation; culture; individuality;
   knowing; participation; relating; secularization; spiritual practices}},
Research-Areas = {{Social Issues; Religion}},
Web-of-Science-Categories  = {{Social Issues; Religion}},
Author-Email = {{jeh34@cam.ac.uk}},
Cited-References = {{Fleming Ursula, 1990, GRASPING NETTLE POSI.
   Gray J., 2018, 7 TYPES ATHEISM.
   Masterman Margaret, 1966, THEORIA TO THEORY, V1, P164.
   Masterman Margaret, 1966, THEORIA TO THEORY, V1, P338.
   Masterman Margaret, 1957, BRIT PHILOS MIDCENTU.
   Masterman Margaret, 1966, THEORIA TO THEORY, V1, P232.
   Masterman Margaret, 1966, THEORIA THEORY, V1, P76.
   NEEDLEMAN J, 1980, {[}No title captured].
   Pinker S., 2018, ENLIGHTENMENT NOW CA.
   Sacks Oliver, 2013, HALLUCINATIONS.
   Tallis Raymond, 2018, LOGOS MYSTERY WE MAK.
   Williams Rowan, 2014, EDGE WORDS GOD HABIT.
   Williams Rowan, 2010, DOSTOEVSKY LANGUAGE.}},
Number-of-Cited-References = {{13}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Zygon}},
Doc-Delivery-Number = {{JM4CS}},
Unique-ID = {{ISI:000496165000013}},
DA = {{2020-06-17}},
}

@article{ ISI:000495940400003,
Author = {Cervantes, Jose-Antonio and Lopez, Sonia and Rodriguez, Luis-Felipe and
   Cervantes, Salvador and Cervantes, Francisco and Ramos, Felix},
Title = {{Artificial Moral Agents: A Survey of the Current Status}},
Journal = {{SCIENCE AND ENGINEERING ETHICS}},
Year = {{2020}},
Volume = {{26}},
Number = {{2}},
Pages = {{501-532}},
Month = {{APR}},
Abstract = {{One of the objectives in the field of artificial intelligence for some
   decades has been the development of artificial agents capable of
   coexisting in harmony with people and other systems. The computing
   research community has made efforts to design artificial agents capable
   of doing tasks the way people do, tasks requiring cognitive mechanisms
   such as planning, decision-making, and learning. The application domains
   of such software agents are evident nowadays. Humans are experiencing
   the inclusion of artificial agents in their environment as unmanned
   vehicles, intelligent houses, and humanoid robots capable of caring for
   people. In this context, research in the field of machine ethics has
   become more than a hot topic. Machine ethics focuses on developing
   ethical mechanisms for artificial agents to be capable of engaging in
   moral behavior. However, there are still crucial challenges in the
   development of truly Artificial Moral Agents. This paper aims to show
   the current status of Artificial Moral Agents by analyzing models
   proposed over the past two decades. As a result of this review, a
   taxonomy to classify Artificial Moral Agents according to the strategies
   and criteria used to deal with ethical problems is proposed. The
   presented review aims to illustrate (1) the complexity of designing and
   developing ethical mechanisms for this type of agent, and (2) that there
   is a long way to go (from a technological perspective) before this type
   of artificial agent can replace human judgment in difficult, surprising
   or ambiguous moral situations.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Cervantes, JA (Reprint Author), Univ Guadalajara, Ctr Univ Valles, Dept Comp Sci \& Engn, Carretera Guadalajara Ameca Km 45-5, Ameca 46600, Mexico.
   Cervantes, Jose-Antonio; Lopez, Sonia; Cervantes, Salvador, Univ Guadalajara, Ctr Univ Valles, Dept Comp Sci \& Engn, Carretera Guadalajara Ameca Km 45-5, Ameca 46600, Mexico.
   Rodriguez, Luis-Felipe, Inst Tecnol Sonora, Dept Comp Sci, Sonora, Mexico.
   Cervantes, Francisco, Inst Tecnol \& Estudios Super Occidente, Dept Elect Syst \& Informat, Tlaquepaque, Mexico.
   Ramos, Felix, Inst Politecn Nacl, Ctr Invest \& Estudios Avanzados, Dept Comp Sci, Guadalajara, Jalisco, Mexico.}},
DOI = {{10.1007/s11948-019-00151-x}},
Early Access Date = {{NOV 2019}},
ISSN = {{1353-3452}},
EISSN = {{1471-5546}},
Keywords = {{Artificial agent; Ethical agent; Moral dilemma; Machine ethics}},
Keywords-Plus = {{DECISION-MAKING; MACHINE ETHICS; ADJUSTABLE AUTONOMY; COMPUTATIONAL
   MODEL; NORMATIVE ETHICS; ROBOT; SYSTEMS; JUDGMENTS; INTELLIGENCE;
   ARCHITECTURE}},
Research-Areas = {{Social Sciences - Other Topics; Engineering; History \& Philosophy of
   Science; Science \& Technology - Other Topics; Philosophy}},
Web-of-Science-Categories  = {{Ethics; Engineering, Multidisciplinary; History \& Philosophy Of
   Science; Multidisciplinary Sciences; Philosophy}},
Author-Email = {{antoniocervantes@valles.udg.mx
   sonia.lopez@valles.udg.mx
   luis.rodriguez@itson.edu.mx
   salvador.cervantes@valles.udg.mx
   fcervantes@iteso.mx
   framos@gdl.cinvestav.mx}},
ResearcherID-Numbers = {{Rodriguez, Luis-Felipe/AAI-5587-2020
   }},
ORCID-Numbers = {{Rodriguez, Luis-Felipe/0000-0001-8114-0299
   Cervantes, Jose-Antonio/0000-0002-4228-2398}},
Cited-References = {{Abbass HA, 2016, COGN COMPUT, V8, P385, DOI 10.1007/s12559-015-9365-5.
   Alaieri F, 2016, LECT NOTES ARTIF INT, V9979, P159, DOI 10.1007/978-3-319-47437-3\_16.
   Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4.
   Amstutz MR, 2013, INT ETHICS CONCEPTS.
   Anderson M, 2006, P 18 C INN APPL ART, V2, P1759.
   Anderson M, 2007, AI MAG, V28, P15.
   Anderson M, 2007, MIND MACH, V17, P1, DOI 10.1007/s11023-007-9053-7.
   Anderson M, 2006, IEEE INTELL SYST, V21, P56, DOI 10.1109/MIS.2006.64.
   Anderson M, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P253.
   Anderson M, 2010, SCI AM, V303, P72, DOI 10.1038/scientificamerican1010-72.
   Anderson M, 2008, STUD COMPUT INTELL, V107, P233.
   Andino C, 2015, Rev. ciente. UCSA, V2, P85, DOI 10.18004/ucsa/2409-8752/2015.002(02)085-094.
   Arkin R. C., 2010, J MILITARY ETHICS, V9, P332.
   Arkin R. C., 2009, GOVERNING LETHAL BEH.
   Arkin R, 2018, INT POLIT ECON SER, P317, DOI 10.1007/978-3-319-51466-6\_15.
   Arkoudas K., 2005, MACHINE ETHICS, P17.
   Ashrafian H, 2015, SCI ENG ETHICS, V21, P317, DOI 10.1007/s11948-014-9541-0.
   Bandyopadhyay D, 2011, WIRELESS PERS COMMUN, V58, P49, DOI 10.1007/s11277-011-0288-5.
   Batty M, 2012, EUR PHYS J-SPEC TOP, V214, P481, DOI 10.1140/epjst/e2012-01703-3.
   Beauvisage T, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P575.
   Bedaf S, 2016, INT J SOC ROBOT, V8, P409, DOI 10.1007/s12369-016-0336-0.
   Belloni A., 2015, 1 INT WORKSH ART INT.
   Belloni A., 2014, CARBON NANOTUBE SIZI, P1.
   Bickmore Timothy, 2005, P AAAI 2005 FALL S C, P9.
   Blass JA, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4289.
   Blass JA, 2015, PROCEEDINGS OF THE TWENTY-NINTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P501.
   Bonnemains V, 2018, ETHICS INF TECHNOL, V20, P41, DOI 10.1007/s10676-018-9444-x.
   Borenstein J., 2019, COGNITIVE ETHICAL SC, V134, P299.
   Borg JS, 2006, J COGNITIVE NEUROSCI, V18, P803, DOI 10.1162/jocn.2006.18.5.803.
   Borst JP, 2015, INTRO MODEL BASED CO, P339.
   Brachman RJ, 2002, IEEE INTELL SYST, V17, P67, DOI 10.1109/MIS.2002.1134363.
   Briggs G., 2015, P AAAI FALL S SER, P1.
   Bringsjord S., 2014, P IEEE 2014 INT S ET, P1.
   Brundage M, 2014, J EXP THEOR ARTIF IN, V26, P355, DOI 10.1080/0952813X.2014.895108.
   Capraro V, 2018, JUDGM DECIS MAK, V13, P99.
   Cervantes JA, 2017, COGN SYST RES, V44, P10, DOI 10.1016/j.cogsys.2017.03.002.
   Cervantes JA, 2016, COGN COMPUT, V8, P278, DOI 10.1007/s12559-015-9362-8.
   Choi D, 2018, COGN SYST RES, V48, P25, DOI 10.1016/j.cogsys.2017.05.005.
   Coeckelbergh M, 2010, ETHICS INF TECHNOL, V12, P235, DOI 10.1007/s10676-010-9221-y.
   Conway P, 2013, J PERS SOC PSYCHOL, V104, P216, DOI 10.1037/a0031021.
   Cook DJ, 2012, PERVASIVE MOB COMPUT, V8, P22, DOI 10.1016/j.pmcj.2011.10.004.
   Cristani M, 2009, KNOWL INF SYST, V18, P157, DOI 10.1007/s10115-008-0172-0.
   Czubenko M, 2015, COGN COMPUT, V7, P569, DOI 10.1007/s12559-015-9320-5.
   Dehghani M., 2008, P 23 AAAI C ART INT, P1280.
   Deng B, 2015, NATURE, V523, P24, DOI 10.1038/523024a.
   Dennis L, 2016, ROBOT AUTON SYST, V77, P1, DOI 10.1016/j.robot.2015.11.012.
   Dennis LA, 2016, AUTOMAT SOFTW ENG, V23, P305, DOI 10.1007/s10515-014-0168-9.
   Epting S, 2016, SCI ENG ETHICS, V22, P1781, DOI 10.1007/s11948-015-9732-3.
   Erdur M, 2018, J VALUE INQUIRY, V52, P227, DOI 10.1007/s10790-017-9611-z.
   Fagin R., 1990, P 3 C THEOR ASP REAS, P41.
   Feil-Seifer D, 2011, IEEE ROBOT AUTOM MAG, V18, P24, DOI 10.1109/MRA.2010.940150.
   FERRELL OC, 1985, J MARKETING, V49, P87, DOI 10.2307/1251618.
   Fleetwood J, 2000, TEACH LEARN MED, V12, P96, DOI 10.1207/S15328015TLM1202\_7.
   Fumagalli M, 2012, BRAIN, V135, P2006, DOI 10.1093/brain/awr334.
   Gerdes Anne, 2015, Journal of Information, Communication and Ethics in Society, V13, P98, DOI 10.1108/JICES-09-2014-0038.
   Gogoll J, 2017, SCI ENG ETHICS, V23, P681, DOI 10.1007/s11948-016-9806-x.
   Goley EM, 2004, BMC CANCER, V4, DOI 10.1186/1471-2407-4-20.
   Govindarajulu N. S., 2018, ARXIV180507797.
   Greene JD, 2001, SCIENCE, V293, P2105, DOI 10.1126/science.1062872.
   Greene J, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4147.
   Greene JD, 2008, COGNITION, V107, P1144, DOI 10.1016/j.cognition.2007.11.004.
   Guerini M., 2015, WORKSH 29 AAAI C ART, P53.
   Han TA, 2018, HDB MASCHINENETHIK, P1.
   Hassabis D, 2017, NEURON, V95, P245, DOI 10.1016/j.neuron.2017.06.011.
   Honarvar AR, 2009, LECT NOTES ARTIF INT, V5855, P86, DOI 10.1007/978-3-642-05253-8\_10.
   Howard D., 2016, 2016 AAAI SPRING S S, P217.
   Hughes GJ, 2001, ROUTLEDGE PHILOS GUI.
   Kahn PH, 2012, ACMIEEE INT CONF HUM, P33.
   Kirchin S, 2012, PALGR PHILOS TODAY, P1.
   Kishi T, 2017, HUMANOID ROBOTICS RE, P1.
   Kruglanski AW, 2011, PSYCHOL REV, V118, P97, DOI 10.1037/a0020762.
   Laird JE, 2017, AI MAG, V38, P13, DOI 10.1609/aimag.v38i4.2744.
   Laird JE, 2012, SOAR COGNITIVE ARCHITECTURE, P43.
   Laird JE, 2008, FRONT ARTIF INTEL AP, V171, P224.
   Lombrozo T, 2009, COGNITIVE SCI, V33, P273, DOI 10.1111/j.1551-6709.2009.01013.x.
   Long LN, 2010, J AEROS COMP INF COM, V7, P68, DOI 10.2514/1.46188.
   Madl T, 2015, COGN TECHNOL, P137, DOI 10.1007/978-3-319-21548-8\_8.
   Malle BF, 2016, ETHICS INF TECHNOL, V18, P243, DOI 10.1007/s10676-015-9367-8.
   Malle BF, 2015, ACMIEEE INT CONF HUM, P117, DOI 10.1145/2696454.2696458.
   Mermet B., 2016, ECAI 2016 WORKSH ETH.
   Metta G, 2010, NEURAL NETWORKS, V23, P1125, DOI 10.1016/j.neunet.2010.08.010.
   Mikhail J, 2007, TRENDS COGN SCI, V11, P143, DOI 10.1016/j.tics.2006.12.007.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Mordoch E, 2013, MATURITAS, V74, P14, DOI 10.1016/j.maturitas.2012.10.015.
   Mostafa SA, 2019, ARTIF INTELL REV, V51, P149, DOI 10.1007/s10462-017-9560-8.
   Mostafa SA, 2018, INT J MED INFORM, V112, P173, DOI 10.1016/j.ijmedinf.2018.02.001.
   Pellizzoni S, 2010, DEVELOPMENTAL SCI, V13, P265, DOI 10.1111/j.1467-7687.2009.00851.x.
   Podschwadek F, 2017, ARTIF INTELL LAW, V25, P325, DOI 10.1007/s10506-017-9209-6.
   Reig S, 2018, AUTOMOTIVEUI'18: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P198, DOI 10.1145/3239060.3239064.
   Rodriguez LF, 2014, COGN COMPUT, V6, P351, DOI 10.1007/s12559-013-9244-x.
   Scheutz M., 2014, P IEEE 2014 INT S ET, P9, DOI DOI 10.1145/2661714.2661717.
   Schroeder M, 2018, ROUTLEDGE HBK PHILOS, P674.
   Sharkey A, 2012, ETHICS INF TECHNOL, V14, P27, DOI 10.1007/s10676-010-9234-6.
   Shigemi S., 2018, HUMANOID ROBOTICS RE, P1.
   Tikhanoff V, 2011, IEEE T AUTON MENT DE, V3, P17, DOI 10.1109/TAMD.2010.2100390.
   Trafton G, 2013, J HUM-ROBOT INTERACT, V2, P30, DOI 10.5898/JHRI.2.1.Trafton.
   van Riemsdijk MB, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS \& MULTIAGENT SYSTEMS (AAMAS'15), P1201.
   Van Staveren I, 2007, REV POLIT ECON, V19, P21, DOI 10.1080/09538250601080776.
   Van Wynsberghe A, 2018, SCI ENG ETHICS, V25, P1.
   Vanderelst D, 2018, COGN SYST RES, V48, P56, DOI 10.1016/j.cogsys.2017.04.002.
   Vernon D, 2007, IEEE T EVOLUT COMPUT, V11, P151, DOI 10.1109/TEVC.2006.890274.
   Viroli M., 2012, 27 ANN ACM S APPL CO, P295, DOI DOI 10.1145/2245276.2245336.
   von der Pfordten D, 2012, ETHICAL THEORY MORAL, V15, P449, DOI 10.1007/s10677-011-9299-2.
   Waldrop MM, 2015, NATURE, V518, P20, DOI 10.1038/518020a.
   Walker LJ, 2004, J PERS SOC PSYCHOL, V86, P629, DOI 10.1037/0022-3514.86.4.629.
   Wallach W, 2010, TOP COGN SCI, V2, P454, DOI 10.1111/j.1756-8765.2010.01095.x.
   Wallach W, 2010, ETHICS INF TECHNOL, V12, P243, DOI 10.1007/s10676-010-9232-8.
   Wallach W, 2008, AI SOC, V22, P463, DOI 10.1007/s00146-007-0093-6.
   Wallach W, 2008, AI SOC, V22, P565, DOI 10.1007/s00146-007-0099-0.
   Wang SY, 2016, COMPUT NETW, V101, P158, DOI 10.1016/j.comnet.2015.12.017.
   Wellman M, 2017, MIND MACH, V27, P609, DOI 10.1007/s11023-017-9419-4.
   Winfield Alan F. T., 2014, Advances in Autonomous Robotics Systems. 15th Annual Conference (TAROS 2014). Proceedings: LNCS 8717, P85, DOI 10.1007/978-3-319-10401-0\_8.
   Wright G. H., 1951, MIND, V60, P1, DOI {[}DOI 10.1093/MIND/LX.237.1, 10.1093/mind/LX.237.1].
   Yampolskiy RV, 2013, PHILOS THEORY ARTIFI, P389.
   Young L, 2013, J EXP SOC PSYCHOL, V49, P302, DOI 10.1016/j.jesp.2012.11.013.
   Zambonelli F, 2011, INT J PERVASIVE COMP, V7, P186, DOI 10.1108/17427371111172997.
   Zieba S, 2010, COGN TECHNOL WORK, V12, P193, DOI 10.1007/s10111-009-0134-7.}},
Number-of-Cited-References = {{117}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{17}},
Usage-Count-Since-2013 = {{27}},
Journal-ISO = {{Sci. Eng. Ethics}},
Doc-Delivery-Number = {{KW4UG}},
Unique-ID = {{ISI:000495940400003}},
DA = {{2020-06-17}},
}

@article{ ISI:000501072900002,
Author = {Gabbay, Dov M. and Schild, Uri and David, Esther},
Title = {{The Talmudic Logic Project, Ongoing Since 2008}},
Journal = {{LOGICA UNIVERSALIS}},
Year = {{2019}},
Volume = {{13}},
Number = {{4, SI}},
Pages = {{425-442}},
Month = {{NOV}},
Abstract = {{We describe the state of the Talmudic Logic project as of end of 2019.
   The Talmud is the most comprehensive and fundamental work of Jewish
   religious law, employing a large number of logical components centuries
   ahead of their time. In many cases the basic principles are not
   explicitly formulated, which makes it difficult to formalize and make
   available to the modern student of Logic. This project on Talmudic
   Logic, aims to present logical analysis of Talmudic reasoning using
   modern logical tools. We investigate principles of Talmudic Logic and
   publish a series of books, one book or more for each principle. The
   series begins with the systematic analysis of Talmudic inference rules.
   The first book shows that we can present Talmudic reasoning intuitions
   as a systematic logical system basic to modern non-deductive reasoning,
   such as Argumentum A Fortiori, Abduction and Analogy. The second book
   offers a systematic common sense method for intuitively defining sets
   and claims that this method adequately models the Talmudic use of the
   rules Klal uPrat. These books also criticize modern Talmudic research
   methodology. Later books deal with additional topics like Deontic logic,
   and Temporal logic, Agency and processes in the Talmud and more. The
   aims of the project are two fold: To import into the Talmudic study
   modern logical methods with a view to help understand complicated
   Talmudic passages, which otherwise cannot be addressed. To export from
   the Talmud new logical principles which are innovative and useful to
   modern contemporary logic.}},
Publisher = {{SPRINGER BASEL AG}},
Address = {{PICASSOPLATZ 4, BASEL, 4052, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Gabbay, DM (Reprint Author), Univ Luxembourg, Esch Sur Alzette, Luxembourg.
   Gabbay, DM (Reprint Author), Bar Ilan Univ, Ramat Gan, Israel.
   Gabbay, DM (Reprint Author), Kings Coll London, London, England.
   Gabbay, Dov M., Univ Luxembourg, Esch Sur Alzette, Luxembourg.
   Gabbay, Dov M.; Schild, Uri, Bar Ilan Univ, Ramat Gan, Israel.
   Gabbay, Dov M., Kings Coll London, London, England.
   David, Esther, Ashkelon Acad Coll, Ashqelon, Israel.}},
DOI = {{10.1007/s11787-019-00228-y}},
ISSN = {{1661-8297}},
EISSN = {{1661-8300}},
Keywords = {{Talmudic logic; Identity theory; Machine ethics; Temporal logic; Logic
   and law; Argumentation}},
Research-Areas = {{Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Logic}},
Author-Email = {{us1445@gmail.com
   astrdod@edu.aac.ac.il}},
Cited-References = {{Abraham D, 2011, J NANOPHOTONICS, V5, DOI 10.1117/1.3646101.
   Abraham G, 2011, BMC VET RES, V7, DOI 10.1186/1746-6148-7-26.
   Abraham M, 2012, ARTIF INTELL LAW, V20, P145, DOI 10.1007/s10506-012-9123-x.
   Abraham M, 2013, J APPL LOGIC, V11, P63, DOI 10.1016/j.jal.2012.06.001.
   Abraham M, 2011, ARTIF INTELL LAW, V19, P117, DOI 10.1007/s10506-011-9109-0.
   Abraham M., 2012, STUDIES TALMUDIC LOG, V8, p455+14.
   Abraham M., 2016, STUDIES TALMUDIC LOG, V13.
   Abraham M., 2010, STUDIES TALMUDIC LOG, V2, p388+17.
   Abraham M., 2014, STUDIES TALMUDIC LOG, V11, P325.
   Abraham M., 2011, LOGIC FRONTIERS FEST.
   Abraham M., 2014, STUDIES TALMUDIC LOG, V9, P301.
   Abraham M., 2010, STUDIES TALMUDIC LOG, V1, P289.
   Abraham M., 2009, STUDIA LOGICA, V92, P281, DOI DOI 10.1007/s11225-009-9202-5.
   Abraham M., 2009, BBD J.
   Abraham M., 2013, STUDIES TALMUDIC LOG, V10, P296.
   Abraham M., 2011, STUDIES TALMUDIC LOG, V4, p588+70.
   Abraham M., 2017, STUDIES TALMUDIC LOG, V14, P360.
   Abraham M, 2011, HIST PHILOS LOGIC, V32, P47, DOI 10.1080/01445340.2010.506094.
   Abraham TH, 2016, REBEL GENIUS: WARREN S MCCULLOCH'S TRANSDISCIPLINARY LIFE IN SCIENCE, P179.
   {[}Anonymous], 2002, LEIB MOSKOVITZ TALMU.
   Arnauld A., 1612, LOGIC ART THINKING B.
   Ballard D, 2010, BMC MED GENOMICS, V3, DOI 10.1186/1755-8794-3-25.
   Barwise J, 1977, HDB MATH LOGIC.
   Bordyugov G, 2015, J R SOC INTERFACE, V12, DOI 10.1098/rsif.2015.0282.
   Crochemore M, 2011, INFORM COMPUT, V209, P692, DOI 10.1016/j.ic.2011.01.002.
   De Rijk L. M., 1970, PETRUS ABAELARDUS DI.
   Dominic H, STANFORD ENCY PHILOS.
   Etzioni A, 2016, COMMUN ACM, V59, P29, DOI 10.1145/2955091.
   Gabbay Dov, 2014, Deontic Logic and Normative Systems. 12th International Conference, DEON 2014. Proceedings: LNCS 8554, P108, DOI 10.1007/978-3-319-08615-6\_9.
   Gabbay D., 2019, NATURAL ARGUMENT TRI, P177.
   Gabbay D. M., 2013, HDB HIST LOGIC RISE, V3, P780.
   Gabbay D, 2017, J APPL LOG-IFCOLOG, V4, P1769.
   Gianni M., 2015, WE AR WE CAN BE P IC.
   Hinnant CH, 1980, T HOBBES REFERENCE G.
   Rydeheard D., 2011, P HOWARD, V60, P1.
   Shakespeare William, 1990, OTHELLO NEW SWAN SHA.
   Shakespeare William, 1998, A SHAKESPEARE COMPLE.}},
Number-of-Cited-References = {{37}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Log Universalis}},
Doc-Delivery-Number = {{JT6BM}},
Unique-ID = {{ISI:000501072900002}},
OA = {{Other Gold}},
DA = {{2020-06-17}},
}

@article{ ISI:000429583600001,
Author = {Hauer, Tomas},
Title = {{Society and the Second Age of Machines: Algorithms Versus Ethics}},
Journal = {{SOCIETY}},
Year = {{2018}},
Volume = {{55}},
Number = {{2}},
Pages = {{100-106}},
Month = {{APR}},
Abstract = {{The term ``Second Machine Age{''} was used by Erik Brynjolfsson and
   Andrew McAfee in their book of the same name as an indication of the
   impact of AI technology on people, society, and the economy. The term
   seeks to analyse the age we actually live in, its hidden patterns, which
   jobs and fields of study have a perspective, and which do not. It is
   about the second industrial revolution that is going on right now, and
   it changes the world no less radically than the first one, driven by the
   steam locomotive. Exponential growth of digital technologies,
   digitization of everything and recombinant innovation is a driving
   engine and fuel of the Second Machine Age. However, the ethical issues
   of this change remain unaddressed. Artificial intelligence is currently
   being dealt with by a great many scientists and philosophers who ask
   many questions. The most important questions are whether the machines
   can think, whether we will give them the copyright, which the animals do
   not have until now, and the question whether AI can has its own ethics.
   The study focuses on these issues, and uses concrete examples to show
   our unpreparedness for these topics.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Editorial Material}},
Language = {{English}},
Affiliation = {{Hauer, T (Reprint Author), VSB Tech Univ Ostrava, Dept Social Sci, 17 November 15-2172, Ostrava, Czech Republic.
   Hauer, Tomas, VSB Tech Univ Ostrava, Dept Social Sci, 17 November 15-2172, Ostrava, Czech Republic.}},
DOI = {{10.1007/s12115-018-0221-6}},
ISSN = {{0147-2011}},
EISSN = {{1936-4725}},
Keywords = {{Second machine age; Artificial intelligence; Machine ethics; Computer
   functionalism; Moral dilemmas; Ethical problemin robotics}},
Research-Areas = {{Social Sciences - Other Topics; Sociology}},
Web-of-Science-Categories  = {{Social Sciences, Interdisciplinary; Sociology}},
Author-Email = {{tomas.hauer@vsb.cz}},
Cited-References = {{Anderson M., 2011, MACHINE ETHICS.
   Asimov Isaac, 1950, I ROBOT.
   Boddington P., 2017, ARTIFICIAL INTELLIGE.
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654.
   Brynjolfsson E., 2016, 2 MACHINE AGE WORK P.
   CARTER M, 2007, {[}No title captured].
   Dreyfus H. L, 1992, WHAT COMPUTERS STILL.
   Erbas MD, 2015, ARTIF LIFE, V21, P141, DOI 10.1162/ARTL\_a\_00164.
   Finn E., 2017, WHAT ALGORITHMS WANT.
   Kurzweil R., 2005, SINGULARITY IS NEAR.
   Li D., 2007, ARTIFICIAL INTELLIGE.
   Lin P, 2012, INTELL ROBOT AUTON, P1.
   Minsky M., 1988, SOC OF MIND.
   Oliveira A., 2017, DIGITAL MIND SCI IS.
   Penrose R., 1996, SHADOWS MIND SEARCH.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.
   Warwick K., 2011, ARTIFICIAL INTELLIGE.}},
Number-of-Cited-References = {{17}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{69}},
Journal-ISO = {{Society}},
Doc-Delivery-Number = {{GC2AE}},
Unique-ID = {{ISI:000429583600001}},
DA = {{2020-06-17}},
}

@article{ ISI:000426716300006,
Author = {Arnold, Thomas and Scheutz, Matthias},
Title = {{The ``big red button{''} is too late: an alternative model for the
   ethical evaluation of AI systems}},
Journal = {{ETHICS AND INFORMATION TECHNOLOGY}},
Year = {{2018}},
Volume = {{20}},
Number = {{1, SI}},
Pages = {{59-69}},
Month = {{MAR}},
Abstract = {{As a way to address both ominous and ordinary threats of artificial
   intelligence (AI), researchers have started proposing ways to stop an AI
   system before it has a chance to escape outside control and cause harm.
   A so-called ``big red button{''} would enable human operators to
   interrupt or divert a system while preventing the system from learning
   that such an intervention is a threat. Though an emergency button for AI
   seems to make intuitive sense, that approach ultimately concentrates on
   the point when a system has already ``gone rogue{''} and seeks to
   obstruct interference. A better approach would be to make ongoing
   self-evaluation and testing an integral part of a system's operation,
   diagnose how the system is in error and to prevent chaos and risk before
   they start. In this paper, we describe the demands that recent big red
   button proposals have not addressed, and we offer a preliminary model of
   an approach that could better meet them. We argue for an ethical core
   (EC) that consists of a scenario-generation mechanism and a simulation
   environment that are used to test a system's decisions in simulated
   worlds, rather than the real world. This EC would be kept opaque to the
   system itself: through careful design of memory and the character of the
   scenario, the system's algorithms would be prevented from learning about
   its operation and its function, and ultimately its presence. By
   monitoring and checking for deviant behavior, we conclude, a continual
   testing approach will be far more effective, responsive, and vigilant
   toward a system's learning and action in the world than an emergency
   button which one might not get to push in time.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Arnold, T (Reprint Author), Tufts Univ, Dept Comp Sci, Human Robot Interact Lab, 200 Boston Ave, Medford, MA 02155 USA.
   Arnold, Thomas; Scheutz, Matthias, Tufts Univ, Dept Comp Sci, Human Robot Interact Lab, 200 Boston Ave, Medford, MA 02155 USA.}},
DOI = {{10.1007/s10676-018-9447-7}},
ISSN = {{1388-1957}},
EISSN = {{1572-8439}},
Keywords = {{Artificial intelligence; Ethics; Computational architecture}},
Keywords-Plus = {{MACHINE ETHICS}},
Research-Areas = {{Social Sciences - Other Topics; Information Science \& Library Science;
   Philosophy}},
Web-of-Science-Categories  = {{Ethics; Information Science \& Library Science; Philosophy}},
Author-Email = {{thomas.arnold@tufts.edu
   matthias.scheutz@tufts.edu}},
Funding-Acknowledgement = {{Office of Naval ResearchOffice of Naval Research {[}N00014-16-1-2278]}},
Funding-Text = {{Funding was provided by Office of Naval Research (Grant No. ONR
   \#N00014-16-1-2278).}},
Cited-References = {{Amodei D., 2016, ARXIV160606565.
   Ananny M, 2016, NEW MEDIA SOC.
   Anderson M, 2007, AI MAG, V28, P15.
   Arnold T., 2017, AAAI ETHICS WORKSHOP.
   Arnold T, 2016, ETHICS INF TECHNOL, V18, P103, DOI 10.1007/s10676-016-9389-x.
   Bostrom N., 2014, SUPERINTELLIGENCE PA.
   Boyd D., 2016, DATA SOC POINTS.
   Briggs G., 2016, SCI AM.
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82.
   Crawford K, 2016, NATURE, V538, P311, DOI 10.1038/538311a.
   Cuthbertson A., 2016, NEWSWEEK.
   Davies Alex, 2016, WIRED.
   Devlin H., 2016, GUARDIAN.
   Ewing J., 2015, NY TIMES.
   Gershgorn D, 2016, QUARTZ.
   Hadfield-Menell D., 2016, ARXIV161108219.
   Hardesty L., 2016, MIT NEWS.
   Hardt M, 2016, ADV NEURAL INFORM PR, V29, P3315.
   Lei T, 2016, RATIONALIZING NEURAL.
   Malle B. F., 2014, 2014 IEEE INT S ETH, P1.
   Malle BF, 2015, ACMIEEE INT CONF HUM, P117, DOI 10.1145/2696454.2696458.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Neff G., 2016, INT J COMMUNICATION, V10, P17.
   Orseau L., 2016, SAFELY INTERRUPTIBLE.
   Park D.H., 2016, ARXIV161204757.
   Riedl M., 2016, BIG RED BUTTON.
   Sample I., 2017, GUARDIAN.
   Satell G., 2016, HARVARD BUSINESS REV.
   Scheutz M., 2014, FUNDAMENTAL ISSUES A, P515.
   Wallach W, 2008, MORAL MACHINES TEACH.
   White House, 2016, ADM REP FUT ART INT.
   Wiedenmeier B., 2016, WARNING PEOPLE WHO B.}},
Number-of-Cited-References = {{32}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{6}},
Usage-Count-Since-2013 = {{59}},
Journal-ISO = {{Ethics Inf. Technol.}},
Doc-Delivery-Number = {{FY3JT}},
Unique-ID = {{ISI:000426716300006}},
DA = {{2020-06-17}},
}

@article{ ISI:000446136800009,
Author = {Grinbaum, Alexei},
Title = {{Chance as a value for artificial intelligence}},
Journal = {{JOURNAL OF RESPONSIBLE INNOVATION}},
Year = {{2018}},
Volume = {{5}},
Number = {{3}},
Pages = {{353-360}},
Abstract = {{Deep learning techniques lead to fundamentally non-interpretable
   decisions made by the machine. Although such choices do not have an
   explanation, they impact the users in significant ways. If the ultimate
   innovator is a machine, what is the meaning of responsible conduct? I
   argue in a recent book that the capacity to extract an AI system from
   human judgment, by reducing transparency in favor of opacity, is an
   essential value in machine ethics. This can be achieved through the use
   of randomness, as illustrated with the example of the trolley dilemma.
   Methodologically, a comparison of common motives between technological
   setups and mythological narratives is used to achieve ethical insights.}},
Publisher = {{ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Review}},
Language = {{English}},
Affiliation = {{Grinbaum, A (Reprint Author), CEA Saclay, Gif Sur Yvette, France.
   Grinbaum, Alexei, CEA Saclay, Gif Sur Yvette, France.}},
DOI = {{10.1080/23299460.2018.1495032}},
ISSN = {{2329-9460}},
EISSN = {{2329-9037}},
Keywords = {{Artificial intelligence; chance; myth; ethics}},
Keywords-Plus = {{AUTONOMOUS VEHICLES}},
Research-Areas = {{Social Sciences - Other Topics; History \& Philosophy of Science;
   Business \& Economics; Social Issues}},
Web-of-Science-Categories  = {{Ethics; History \& Philosophy Of Science; Management; Social Issues}},
Author-Email = {{alexei.grinbaum@cea.fr}},
Cited-References = {{{[}Anonymous], 2017, REP ART INT HUM SOC.
   {[}Anonymous], 2016, CAR AND DRIVER.
   {[}Anonymous], 2017, ETHIK KOMMISSION AUT.
   {[}Anonymous], 2016, IEEE GLOBAL INITIATI.
   {[}Anonymous], 2018, REPORT FUTURE HUMANI.
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654.
   Bonnemains V, 2018, ETHICS INF TECHNOL, V20, P41, DOI 10.1007/s10676-018-9444-x.
   CERNA, 2017, REP ETH QUEST MACH L.
   FOOT P, 1978, {[}No title captured].
   Future of Life Institute, 2015, RES PRIOR ROB BEN AR.
   Grinbaum A., 2017, MACHINA DELATRIX.
   Grinbaum A., 2019, SATANAS EX MACHINA I.
   Grinbaum A., 2013, RESPONSIBLE INNOVATI, P119, DOI DOI 10.1002/9781118551424.CH7.
   Hanley W, 2013, DEMOCR CITIZ CONSTIT, P89.
   Leben D, 2017, ETHICS INF TECHNOL, V19, P107, DOI 10.1007/s10676-017-9419-3.
   Microsoft, 2018, FUT COMP ART INT ITS, P75.
   MONOD J, 1971, {[}No title captured].
   United Nations Educational Scientific and Cultural Organization (UNESCO) and World Commission on the Ethics of Scientific Knowledge and Technology (COMEST), 2017, REP COMEST ROB ETH.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{10}},
Journal-ISO = {{J. Responsible Innov.}},
Doc-Delivery-Number = {{GV5JE}},
Unique-ID = {{ISI:000446136800009}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000445499800020,
Author = {Vakkuri, Ville and Abrahamsson, Pekka},
Book-Group-Author = {{IEEE}},
Title = {{The Key Concepts of Ethics of Artificial Intelligence A Keyword based
   Systematic Mapping Study}},
Booktitle = {{2018 IEEE INTERNATIONAL CONFERENCE ON ENGINEERING, TECHNOLOGY AND
   INNOVATION (ICE/ITMC)}},
Series = {{International ICE Conference on Engineering Technology and Innovation}},
Year = {{2018}},
Note = {{IEEE International Conference on Engineering, Technology and Innovation
   (ICE/ITMC), Stuttgart, GERMANY, JUN 17-20, 2018}},
Organization = {{IEEE; Inst Strateg Innovat \& Technol Management; Baden Wuttemberg
   Connected; IEEE Technol \& Engn Management Soc; STW}},
Abstract = {{The growing influence and decision-making capacities of Autonomous
   systems and Artificial Intelligence in our lives force us to consider
   the values embedded in these systems. But how ethics should be
   implemented into these systems? In this study, the solution is seen on
   philosophical conceptualization as a framework to form practical
   implementation model for ethics of AI. To take the first steps on
   conceptualization main concepts used on the field needs to be
   identified. A keyword based Systematic Mapping Study (SMS) on the
   keywords used in AI and ethics was conducted to help in identifying,
   defying and comparing main concepts used in current AI ethics discourse.
   Out of 1062 papers retrieved SMS discovered 37 re-occurring keywords in
   83 academic papers. We suggest that the focus on finding keywords is the
   first step in guiding and providing direction for future research in the
   AI ethics field.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Vakkuri, V (Reprint Author), Univ Jyvaskyla, Fac Informat Technol, Jyvaskyla, Finland.
   Vakkuri, Ville; Abrahamsson, Pekka, Univ Jyvaskyla, Fac Informat Technol, Jyvaskyla, Finland.}},
ISSN = {{2334-315X}},
ISBN = {{978-1-5386-1469-3}},
Keywords = {{Artificial Intelligence; Ethics; AI ethics; Systematic Mapping Study}},
Keywords-Plus = {{MACHINE ETHICS; AUTONOMOUS SYSTEMS; DESIGN; AGENTS; ROBOTS; VEHICLES;
   RISKS; LAW}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
Author-Email = {{ville.vakkuri@jyu.fi
   pekka.abrahamsson@jyu.fi}},
Cited-References = {{Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83.
   Anderson M., 2011, MACHINE ETHICS.
   Arnold T, 2016, ETHICS INF TECHNOL, V18, P103, DOI 10.1007/s10676-016-9389-x.
   Ashrafian H, 2015, SCI ENG ETHICS, V21, P317, DOI 10.1007/s11948-014-9541-0.
   Ashrafian H, 2015, SCI ENG ETHICS, V21, P29, DOI 10.1007/s11948-013-9513-9.
   Basl John, 2014, PHILOS TECHNOLOGY, V27, P79, DOI DOI 10.1007/S13347-013-0122-Y.
   BMVI, 2017, ETH COMM COMPL REP A.
   Boddington P., 2017, CODE ETHICS ARTIFICI.
   Bogosian K, 2017, MIND MACH, V27, P591, DOI 10.1007/s11023-017-9448-z.
   Borenstein J., 2017, SCI ENG ETHICS, P1.
   Brundage M, 2014, J EXP THEOR ARTIF IN, V26, P355, DOI 10.1080/0952813X.2014.895108.
   Bryson J. J., 2012, INT J MACHINE CONSCI, V4, P471, DOI {[}10.1142/s1793843012400276, DOI 10.1142/S1793843012400276].
   Bryson J, 2017, COMPUTER, V50, P116, DOI 10.1109/MC.2017.154.
   Bryson JJ, 2018, ETHICS INF TECHNOL, V20, P15, DOI 10.1007/s10676-018-9448-6.
   Bryson JJ, 2017, ARTIF INTELL LAW, V25, P273, DOI 10.1007/s10506-017-9214-9.
   Cervantes JA, 2016, COGN COMPUT, V8, P278, DOI 10.1007/s12559-015-9362-8.
   Charisi V., 2017, ARXIV170304741.
   Coeckelbergh M, 2015, ETHICS INF TECHNOL, V17, P219, DOI 10.1007/s10676-015-9377-6.
   Coeckelbergh M, 2013, AI SOC, V28, P55, DOI 10.1007/s00146-012-0418-y.
   Colombetti E, 2014, CUAD BIOET, V25, P367.
   Contissa G, 2017, ARTIF INTELL LAW, V25, P365, DOI 10.1007/s10506-017-9211-z.
   Crnkovic GD, 2012, ETHICS INF TECHNOL, V14, P61, DOI 10.1007/s10676-011-9278-2.
   Dean J, 2012, USING LARGE SCALE BR, V2018.
   Etzioni A., 2017, J ETHICS, V21, P403, DOI DOI 10.1007/s10892-017-9252-2.
   Etzioni A, 2017, INTERACT STUD, V18, P174, DOI 10.1075/is.18.2.02etz.
   Etzioni A, 2016, ETHICS INF TECHNOL, V18, P149, DOI 10.1007/s10676-016-9400-6.
   Frank L, 2017, ARTIF INTELL LAW, V25, P305, DOI 10.1007/s10506-017-9212-y.
   Galanos V, 2017, AI SOC, V32, P573, DOI 10.1007/s00146-016-0679-y.
   Ghilardi G, 2014, CUAD BIOET, V25, P379.
   Gill KS, 2016, IFAC PAPERSONLINE, V49, P117, DOI 10.1016/j.ifacol.2016.11.068.
   Goertzel B, 2014, J EXP THEOR ARTIF IN, V26, P391, DOI 10.1080/0952813X.2014.895107.
   Graves M, 2017, THEOL SCI, V15, P333, DOI 10.1080/14746700.2017.1335066.
   Greene JD, 2016, SCIENCE, V352, P1514, DOI 10.1126/science.aaf9534.
   Grodzinsky F. S., 2015, PHILOS TECHNOLOGY, V28, P91, DOI DOI 10.1007/S13347-014-0158-7.
   Gunkel D, 2014, PHILOS TECHNOLOGY, V27, P5.
   Gunkel DJ, 2014, PHILOS TECHNOL, V27, P113, DOI DOI 10.1007/S13347-013-0121-Z.
   Hauer T, 2018, SOCIETY, V55, P100, DOI 10.1007/s12115-018-0221-6.
   Hin-Yan L., 2017, ETHICS INF TECHNOL, P1.
   IEEE Global Initiative, IEEE GLOB IN ETH AUT.
   Johnson D, 2017, MIND MACH, V27, P575, DOI 10.1007/s11023-017-9417-6.
   Kinjo K, 2017, PROCEDIA COMPUT SCI, V112, P61, DOI 10.1016/j.procs.2017.08.024.
   Kitchenham B, 2007, GUIDELINES PERFORMIN.
   Knight Will., 2017, BIASED ALGORITHMS AR.
   Kopacek K., 2012, IFAC P VOLUMES, V45, P67, DOI DOI 10.3182/20120611-3-IE-4029.00015.
   Laukyte M, 2017, ETHICS INF TECHNOL, V19, P1, DOI 10.1007/s10676-016-9411-3.
   Lawrence DR, 2016, CAMB Q HEALTHC ETHIC, V25, P250, DOI 10.1017/S0963180115000559.
   Lin P., 2017, ROBOT ETHICS 2 0 AUT.
   Liu HY, 2017, ETHICS INF TECHNOL, V19, P193, DOI 10.1007/s10676-017-9436-2.
   Loi M, 2015, ETHICS INF TECHNOL, V17, P201, DOI 10.1007/s10676-015-9375-8.
   Frias FJL, 2016, SPORT ETHICS PHILOS, V10, P67, DOI 10.1080/17511321.2016.1166393.
   Martin D, 2017, SCI ENG ETHICS, V23, P951, DOI 10.1007/s11948-016-9833-7.
   Mayer C., 2015, ISSUES DEFENCE POLIC, V65.
   Misselhorn C., 2018, SOCIETY, P1.
   Neely E., 2014, PHILOS TECHNOLOGY, V27, P97, DOI DOI 10.1007/s13347-013-0114-y.
   Omari RM, 2016, J INF COMMUN ETHICS, V14, P231, DOI 10.1108/JICES-10-2015-0034.
   Petersen K, 2015, INFORM SOFTWARE TECH, V64, P1, DOI 10.1016/j.infsof.2015.03.007.
   Purves D, 2015, ETHICAL THEORY MORAL, V18, P851, DOI 10.1007/s10677-015-9563-y.
   Rader M., 2012, J INFORM COMMUNICATI, V10, P4.
   Rahwan I, 2018, ETHICS INF TECHNOL, V20, P5, DOI 10.1007/s10676-017-9430-8.
   Russell S, 2015, NATURE, V521, P415, DOI 10.1038/521415a.
   Sarma GP, 2017, INFORM-J COMPUT INFO, V41, P441.
   Schafer B, 2015, ARTIF INTELL LAW, V23, P217, DOI 10.1007/s10506-015-9169-7.
   Sotala K, 2017, INFORM-J COMPUT INFO, V41, P389.
   Sotala K, 2015, PHYS SCRIPTA, V90, DOI 10.1088/0031-8949/90/1/018001.
   Stowers K, 2016, ERGON DES, V24, P17, DOI 10.1177/1064804616635811.
   Szollosy M, 2017, CONNECT SCI, V29, P254, DOI 10.1080/09540091.2017.1322768.
   Tamburrini G, 2016, AI SOC, V31, P463, DOI 10.1007/s00146-015-0627-2.
   Tavani H.T, 2015, PHILOS TECHNOL, V28, P75.
   Theodorou A, 2017, CONNECT SCI, V29, P230, DOI 10.1080/09540091.2017.1310182.
   Thomasson A., 2018, CATEGORIES.
   Torrance S, 2013, AI SOC, V28, P399, DOI 10.1007/s00146-012-0422-2.
   Vallor S., 2015, PHILOS TECHNOLOGY, V28, P107, DOI DOI 10.1007/S13347-014-0156-9.
   Vamplew P, 2018, ETHICS INF TECHNOL, V20, P27, DOI 10.1007/s10676-017-9440-6.
   van Wynsberghe A., 2018, SCI ENG ETHICS.
   Waser MR, 2013, INT J MACHINE CONSCI, V05, P59, DOI {[}10.1142/S1793843013400052, DOI 10.1142/S1793843013400052].
   Wellman M, 2017, MIND MACH, V27, P609, DOI 10.1007/s11023-017-9419-4.
   Yampolskiy R, 2013, TOPOI-INT REV PHILOS, V32, P217, DOI 10.1007/s11245-012-9128-9.
   Zeng D, 2015, IEEE INTELL SYST, V30, P2.}},
Number-of-Cited-References = {{78}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{12}},
Doc-Delivery-Number = {{BL0CK}},
Unique-ID = {{ISI:000445499800020}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000510018100052,
Author = {Vanderelst, Dieter and Winfield, Alan},
Book-Group-Author = {{ACM}},
Title = {{The Dark Side of Ethical Robots}},
Booktitle = {{PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY
   (AIES'18)}},
Year = {{2018}},
Pages = {{317-322}},
Note = {{AAAI/ACM Conference on AI, Ethics, and Society (AIES), New Orleans, LA,
   FEB 02-03, 2018}},
Organization = {{AAAI; Assoc Comp Machinery; ACM SIGAI; Berkeley Existential Risk
   Initiat; DeepMind Eth \& Soc; Future Life Inst; IBM Res AI;
   PriceWaterhouse Coopers; Tulane Univ}},
Abstract = {{Concerns over the risks associated with advances in Artificial
   Intelligence have prompted calls for greater efforts toward robust and
   beneficial AI, including machine ethics. Recently, roboticists have
   responded by initiating the development of so-called ethical robots.
   These robots would, ideally, evaluate the consequences of their actions
   and morally justify their choices. This emerging field promises to
   develop extensively over the next few years. However, in this paper, we
   point out an inherent limitation of the emerging field of ethical
   robots. We show that building ethical robots also inevitably enables the
   construction of unethical robots. In three experiments, we show that it
   is remarkably easy to modify an ethical robot so that it behaves
   competitively, or even aggressively. The reason for this is that the
   cognitive machinery required to make an ethical robot can always be
   corrupted to make unethical robots. We discuss the implications of this
   finding to the governance of ethical robots. We conclude that the risks
   that unscrupulous actors might compromise a robot's ethics are so great
   as to raise serious doubts over the wisdom of embedding ethical decision
   making in real-world safety-critical robots, such as driverless cars.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Vanderelst, D (Reprint Author), Univ Cincinnati, Cincinnati, OH 45221 USA.
   Vanderelst, Dieter, Univ Cincinnati, Cincinnati, OH 45221 USA.
   Winfield, Alan, Univ West England, Bristol, England.}},
DOI = {{10.1145/3278721.3278726}},
ISBN = {{978-1-4503-6012-8}},
Keywords = {{Machine Ethics; Ethical Robots; Malicious use; Cybersecurity; Ethical
   Governance}},
Research-Areas = {{Computer Science; Biomedical Social Sciences}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Social Sciences, Biomedical}},
Author-Email = {{vanderdt@ucmail.uc.edu
   alan.winfield@brl.ac.uk}},
Funding-Acknowledgement = {{EPSRC project Verifiable AutonomyEngineering \& Physical Sciences
   Research Council (EPSRC) {[}EP/L024861/1]}},
Funding-Text = {{This work has been supported by EPSRC project Verifiable Autonomy, grant
   reference EP/L024861/1.}},
Cited-References = {{Anderson M, 2010, SCI AM, V303, P72, DOI 10.1038/scientificamerican1010-72.
   Anderson Michael, 2017, VALUE DRIVEN AGENT I.
   Arkin R. C., 2010, J MILITARY ETHICS, V9, P332.
   Asaro PM, 2012, INTELL ROBOT AUTON, P169.
   Boden M, 2017, CONNECT SCI, V29, P124, DOI 10.1080/09540091.2016.1271400.
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654.
   Briggs Gordon, 2015, 2015 AAAI FALL S SER.
   Brundage Miles, 2018, CORR.
   BSI, 2016, BS86112016.
   Chouard T, 2015, NATURE, V521, P435, DOI 10.1038/521435a.
   Deng B, 2015, NATURE, V523, P24, DOI 10.1038/523024a.
   Greenberg Andy, 2016, WIRED.
   IEEE, 2018, IEEE GLOB IN ETH AUT.
   Lin P, 2012, INTELL ROBOT AUTON, P1.
   Lin P., 2015, AUTONOMES FAHREN, P69, DOI 10.1007/978-3-662-45854-9\_4.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Murphy RR, 2009, IEEE INTELL SYST, V24, P14, DOI 10.1109/MIS.2009.69.
   O'Meara RM, 2012, INTELL ROBOT AUTON, P159.
   Russell S, 2015, NATURE, V521, P415, DOI 10.1038/521415a.
   Russell Stuart, 2015, AI MAG, V36, P4.
   Sharkey N, 2008, SCIENCE, V322, P1800, DOI 10.1126/science.1164582.
   Stilgoe J, 2013, RES POLICY, V42, P1568, DOI 10.1016/j.respol.2013.05.008.
   Vanderelst D, 2018, COGN SYST RES, V48, P56, DOI 10.1016/j.cogsys.2017.04.002.
   Wallach W, 2008, MORAL MACHINES TEACH.
   Winfield Alan F. T., 2014, Advances in Autonomous Robotics Systems. 15th Annual Conference (TAROS 2014). Proceedings: LNCS 8717, P85, DOI 10.1007/978-3-319-10401-0\_8.
   Winfield A, 2011, NEW SCI, V210, P32, DOI 10.1016/S0262-4079(11)61052-X.
   Winfield AFT, 2018, PHILOS T R SOC A, V376, DOI 10.1098/rsta.2018.0085.}},
Number-of-Cited-References = {{27}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BO3EM}},
Unique-ID = {{ISI:000510018100052}},
DA = {{2020-06-17}},
}

@article{ ISI:000417286400004,
Author = {Bogosian, Kyle},
Title = {{Implementation of Moral Uncertainty in Intelligent Machines}},
Journal = {{MINDS AND MACHINES}},
Year = {{2017}},
Volume = {{27}},
Number = {{4}},
Pages = {{591-608}},
Month = {{DEC}},
Abstract = {{The development of artificial intelligence will require systems of
   ethical decision making to be adapted for automatic computation.
   However, projects to implement moral reasoning in artificial moral
   agents so far have failed to satisfactorily address the widespread
   disagreement between competing approaches to moral philosophy. In this
   paper I argue that the proper response to this situation is to design
   machines to be fundamentally uncertain about morality. I describe a
   computational framework for doing so and show that it efficiently
   resolves common obstacles to the implementation of moral philosophy in
   intelligent machines.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Bogosian, K (Reprint Author), Tulane Univ, New Orleans, LA 70118 USA.
   Bogosian, Kyle, Tulane Univ, New Orleans, LA 70118 USA.}},
DOI = {{10.1007/s11023-017-9448-z}},
ISSN = {{0924-6495}},
EISSN = {{1572-8641}},
Keywords = {{Moral uncertainty; Normative uncertainty; Metanormativity; Metanormative
   theory; Macaskill Machine ethics; AI ethics; Moral disagreement; Moral
   divergence; Metaethics; Machine intelligence; Top-down; Bottom-up; Value
   differences; Moral voting; Moral trade; Moral trading; Ethical trade;
   Ethical trading; Value specification; Value alignment}},
Keywords-Plus = {{EXPERTISE; PHILOSOPHERS; JUDGMENT; WILL}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{kbogosia@tulane.edu}},
Cited-References = {{Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4.
   Archard D, 2011, BIOETHICS, V25, P119, DOI 10.1111/j.1467-8519.2009.01748.x.
   Arkoudas K., 2005, MACHINE ETHICS, P17.
   Bello P, 2013, TOPOI-INT REV PHILOS, V32, P251, DOI 10.1007/s11245-012-9129-8.
   Bostrom N., 2009, MORAL UNCERTAINTY SO.
   Bostrom N, 2012, MIND MACH, V22, P71, DOI 10.1007/s11023-012-9281-3.
   Brundage M, 2014, J EXP THEOR ARTIF IN, V26, P355, DOI 10.1080/0952813X.2014.895108.
   Cotton-Barratt O., 2013, GEOMETRIC REASONS NO.
   Cross B, 2016, BIOETHICS, V30, P188, DOI 10.1111/bioe.12173.
   Driver J, 2013, SOC PHILOS POLICY, V30, P280, DOI 10.1017/S0265052513000137.
   Gloor L., 2016, FRI161.
   Greene JD, 2001, SCIENCE, V293, P2105, DOI 10.1126/science.1062872.
   Jones K., 2012, ANAL KRITIK, V34, P217.
   LOCKHART T, 2000, {[}No title captured].
   MacAskill W., 2014, NORMATIVE UNCERTAINT.
   MacAskill W, 2016, MIND, V125, P967, DOI 10.1093/mind/fzv169.
   MacAskill W, 2013, ETHICS, V123, P508, DOI 10.1086/669564.
   Nissan-Rozen I, 2015, ECON PHILOS, V31, P349, DOI 10.1017/S0266267115000206.
   Oesterheld C., 2016, FRI162.
   Oesterheld C, 2016, SYNTHESE, V193, P2747, DOI 10.1007/s11229-015-0883-1.
   PhilPapers Foundation, 2009, PREM SURV RES.
   Schulz E, 2011, CONSCIOUS COGN, V20, P1722, DOI 10.1016/j.concog.2011.04.007.
   Schwitzgebel E, 2012, MIND LANG, V27, P135, DOI 10.1111/j.1468-0017.2012.01438.x.
   Shulman C., 2009, AP CAP 2009.
   Williams EG, 2015, ETHICAL THEORY MORAL, V18, P971, DOI 10.1007/s10677-015-9567-7.
   Wiltshire TJ, 2015, MIND MACH, V25, P57, DOI 10.1007/s11023-015-9361-2.
   Zuradzki T., 2016, ARGUMENTATION REASON, V2, P1093.}},
Number-of-Cited-References = {{27}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{44}},
Journal-ISO = {{Minds Mach.}},
Doc-Delivery-Number = {{FP0JV}},
Unique-ID = {{ISI:000417286400004}},
DA = {{2020-06-17}},
}

@article{ ISI:000407231800025,
Author = {Lumbreras, Sara},
Title = {{The Limits of Machine Ethics}},
Journal = {{RELIGIONS}},
Year = {{2017}},
Volume = {{8}},
Number = {{5}},
Month = {{MAY}},
Abstract = {{Machine Ethics has established itself as a new discipline that studies
   how to endow autonomous devices with ethical behavior. This paper
   provides a general framework for classifying the different approaches
   that are currently being explored in the field of machine ethics and
   introduces considerations that are missing from the current debate. In
   particular, law-based codes implemented as external filters for
   action-which we have named filtered decision making-are proposed as the
   basis for future developments. The emergence of values as guides for
   action is discussed, and personal language - together with
   subjectivity-are indicated as necessary conditions for this development.
   Last, utilitarian approaches are studied and the importance of objective
   expression as a requisite for their implementation is stressed. Only
   values expressed by the programmer in a public language-that is,
   separate of subjective considerations-can be evolved in a learning
   machine, therefore establishing the limits of present-day machine
   ethics.}},
Publisher = {{MDPI AG}},
Address = {{ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Lumbreras, S (Reprint Author), Univ Pontificia Comillas, Inst Res Technol, Madrid 28001, Spain.
   Lumbreras, Sara, Univ Pontificia Comillas, Inst Res Technol, Madrid 28001, Spain.}},
DOI = {{10.3390/rel8050100}},
Article-Number = {{100}},
ISSN = {{2077-1444}},
Keywords = {{ethics of machines; theory of mind; values; learning automata}},
Keywords-Plus = {{SELF}},
Research-Areas = {{Religion}},
Web-of-Science-Categories  = {{Religion}},
Author-Email = {{slumbreras@comillas.edu}},
ORCID-Numbers = {{Lumbreras, Sara/0000-0002-5506-9027}},
Cited-References = {{Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4.
   Arkin R. C., 2009, GOVERNING LETHAL BEH.
   Asimov I., 1950, I ROBOT.
   Avraham Ronen, 2012, UNDERSTANDING INSURA.
   Campbell RL, 2002, THEOR PSYCHOL, V12, P795, DOI 10.1177/0959354302126004.
   Casey B. J., 2017, AMORAL MACHINES ROBO.
   DANIELSON P, 1998, {[}No title captured].
   Floridi Luciano, 2005, ACM SIGCAS COMPUTERS, V35, P3, DOI DOI 10.1145/1111646.1111649.
   Greene JD, 2001, SCIENCE, V293, P2105, DOI 10.1126/science.1062872.
   Handelsman M. M., 2009, OXFORD HDB POSITIVE, P105, DOI DOI 10.1093/OXFORDHB/9780195187243.013.0011.
   Hardy SA, 2011, CHILD DEV PERSPECT, V5, P212, DOI 10.1111/j.1750-8606.2011.00189.x.
   HEAD Simon, 2014, MINDLESS WHY SMARTER.
   Honderich Ted, 2005, OXFORD COMPANION PHI.
   Howard R. A, 2008, ETHICS REAL WORLD CR.
   International Federation of Robotics (IFR), 2016, WORLD ROB 2016.
   JACKSON F, 1991, ETHICS, V101, P461, DOI 10.1086/293312.
   Kahneman D., 2011, THINKING FAST SLOW.
   KANT I, 2004, {[}No title captured].
   Kuipers B, 2008, ARTIF INTELL MED, V44, P155, DOI 10.1016/j.artmed.2008.07.010.
   Kurzweil R., 2012, CREATE MIND SECRET H.
   Lapsley D. K, 2006, HDB CHILD PSYCHOL.
   Leach Javier, 2011, MATH RELIG OUR LANGU.
   Lichtenberg J, 2010, ETHICS, V120, P557, DOI 10.1086/652294.
   Luxton DD, 2014, ARTIF INTELL MED, V62, P1, DOI 10.1016/j.artmed.2014.06.004.
   Martin J, 2004, EDUC PSYCHOL, V39, P135, DOI 10.1207/s15326985ep3902\_4.
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77.
   Rosenbrock H. H., 1990, MACHINES PURPOSE.
   Slote Michael, 1985, COMMON SENSE MORALIT.
   Van de Voort M, 2015, ETHICS INF TECHNOL, V17, P41, DOI 10.1007/s10676-015-9360-2.
   Veruggio G, 2016, SPRINGER HANDBOOK OF ROBOTICS, P2135.
   Wilson E.O., 1975, P1.
   Yampolskiy R, 2013, TOPOI-INT REV PHILOS, V32, P217, DOI 10.1007/s11245-012-9128-9.}},
Number-of-Cited-References = {{32}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{Religions}},
Doc-Delivery-Number = {{FD0LW}},
Unique-ID = {{ISI:000407231800025}},
OA = {{DOAJ Gold}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000425844300033,
Author = {Alaieri, Fahad and Vellino, Andre},
Book-Group-Author = {{IEEE}},
Title = {{A Decision Making Model for Ethical (Ro)bots}},
Booktitle = {{2017 IEEE 5TH INTERNATIONAL SYMPOSIUM ON ROBOTICS AND INTELLIGENT
   SENSORS (IRIS)}},
Year = {{2017}},
Pages = {{203-207}},
Note = {{5th IEEE International Symposium on Robotics and Intelligent Sensors
   (IEEE IRIS), Ottawa, CANADA, OCT 05-07, 2017}},
Organization = {{IEEE; IEEE Ottawa Sect; IEEE RAS Malaysia Chapter; Joint Chapter Robot
   \& Automat Soc \& Control Syst Soc; Joint Chapter Computat Intelligence
   \& Syst Man \& Cybernet Soc; Instrumentat \& Measurement Soc Chapter}},
Abstract = {{Autonomous bots and robots (we label ``(ro)bots{''}), ranging from
   shopping assistant chatbots to self-driving cars are already able to
   make decisions that have ethical consequences. As more such machines
   make increasingly complex and significant decisions, we need to know
   that their decisions are trustworthy and ethically justified so that
   users, manufacturers and law-makers can understand how these decisions
   are made and which ethical principles were brought to bear in making
   them. Understanding how such decisions are made is particularly
   important in the case where a (ro) bot is a self-improving,
   self-learning type of machine whose choices and decisions are based on
   past experience, given that they may not be entirely predictable ahead
   of time or explainable after the fact. This paper presents a model that
   decomposes the stages of ethical decision making into their elementary
   components with a view to enabling stakeholders to allocate the
   responsibility for such choices.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Alaieri, F (Reprint Author), Qassim Univ, Management Informat Syst, Quasim 14452, Saudi Arabia.
   Alaieri, F (Reprint Author), Univ Ottawa, Sch Informat Studies, Ottawa, ON, Canada.
   Alaieri, Fahad, Qassim Univ, Management Informat Syst, Quasim 14452, Saudi Arabia.
   Alaieri, Fahad; Vellino, Andre, Univ Ottawa, Sch Informat Studies, Ottawa, ON, Canada.}},
ISBN = {{978-1-5386-1342-9}},
Keywords = {{Decision making; machine ethics; autonomy; trust, responsibility}},
Research-Areas = {{Computer Science; Engineering; Robotics}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Robotics}},
Author-Email = {{fahad@uottawa.ca
   avellino@uottawa.ca}},
Cited-References = {{ALBERTS VA, 2016, RECORDS MANAGEMENT J, V26, P293.
   Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4.
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83.
   Alpaydm E., 2010, INTRO MACHINE LEARNI.
   Beer JM, 2014, J HUM-ROBOT INTERACT, V3, P74, DOI 10.5898/JHRI.3.2.Beer.
   Ferrucci D, 2010, AI MAG, V31, P59, DOI 10.1609/aimag.v31i3.2303.
   GIPS J, 1991, 2 INT WORKSH HUM MAC.
   LAFRANCE A, 2016, WHAT IS A ROBOT.
   Lonsdorf K., 2017, HUNGRY CALL YOUR NEI.
   Mathur V, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P231, DOI 10.1109/IC3I.2016.7917966.
   Parasuraman R, 2000, IEEE T SYST MAN CY A, V30, P286, DOI 10.1109/3468.844354.
   TZAFESTAS SG, 2016, ROBOETHICS NAVIGATIN, P79.
   Vanderelst D, 2017, COGNITIVE SYSTEMS RE.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.}},
Number-of-Cited-References = {{14}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{5}},
Doc-Delivery-Number = {{BJ5EK}},
Unique-ID = {{ISI:000425844300033}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000418294900002,
Author = {Bendel, Oliver},
Editor = {{Cheok, AD and Devlin, K and Levy, D}},
Title = {{Sex Robots from the Perspective of Machine Ethics}},
Booktitle = {{LOVE AND SEX WITH ROBOTS, LSR 2016}},
Series = {{Lecture Notes in Artificial Intelligence}},
Year = {{2017}},
Volume = {{10237}},
Pages = {{17-26}},
Note = {{2nd International Conference on Love and Sex with Robots (LSR), London,
   ENGLAND, DEC 19-20, 2016}},
Abstract = {{This contribution explains firstly the terms and the phenomena of sex
   robots and robot sex and the foundations of machine ethics. Secondly it
   poses questions related to sex robots as moral agents, from a general
   and a specific perspective, aiming at assisting manufacturers and
   developers. By using the questions, the opportunities and risks can be
   discussed in a structured manner. Thirdly, the fields of applied ethics
   are included to work out the implications for humans as moral patients.
   At the end, the author summarizes the findings. Machine ethics, from his
   point of view, may help to construct sex robots and service robots with
   special capabilities which are moral machines in their appearance and in
   their behaviour and which may allow some people to complement their
   sexual activities and to lead a fulfilling life. The fields of applied
   ethics may be beneficial with respect to the adequate use of sex robots.}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Bendel, O (Reprint Author), Sch Business FHNW, Bahnhofstr 6, CH-5210 Windisch, Switzerland.
   Bendel, Oliver, Sch Business FHNW, Bahnhofstr 6, CH-5210 Windisch, Switzerland.}},
DOI = {{10.1007/978-3-319-57738-8\_2}},
ISSN = {{0302-9743}},
EISSN = {{1611-3349}},
ISBN = {{978-3-319-57738-8; 978-3-319-57737-1}},
Keywords = {{Sex robots; Sex dolls; Robot sex; Artificial intelligence; Machine
   ethics; Technology ethics; Information ethics}},
Research-Areas = {{Computer Science; Robotics}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Robotics}},
Author-Email = {{oliver.bendel@fhnw.ch}},
Cited-References = {{Anderson M., 2011, MACHINE ETHICS.
   Bendel O., 2016, TELEPOLIS.
   Bendel O, 2014, BETRIEBSWIRTSCHAFT, V4, P237.
   Bendel O, 2013, UNTERNEHMERZEITUNG, V7, P30.
   Bendel O., 2014, TECHNOLOGY ASSESSMEN, P321.
   Bendel O, 2015, INTEL SYST CONTR AUT, V74, P17, DOI 10.1007/978-3-319-08108-3\_2.
   Boden M., 2010, PRINCIPLES ROBOTICS.
   Coeckelbergh M, 2009, INT J SOC ROBOT, V1, P217, DOI 10.1007/s12369-009-0026-2.
   Danaher J., 2014, CRIMINAL LAW PHILOS, P1.
   Freuler R., 2016, NZZ AM SONNTAG, P60.
   Levy D, 2008, SEX LOVE ROBOTS EVOL.
   Pereira LM, 2016, PROGRAMMING MACHINE.
   Richarson K, 2015, ACM SIGCAS COMPUTERS, V45, P290, DOI {[}10.1145/2874239.2874281, DOI 10.1145/2874239.2874281].
   Rotzer F, 2016, TELEPOLIS.
   SCHEUTZ M, 2016, {[}No title captured], P351, DOI DOI 10.1109/HRI.2016.745.
   Seesslen G, 2012, TRAUMEN ANDROIDEN EL.
   Sullins JP, 2012, IEEE T AFFECT COMPUT, V3, P398, DOI 10.1109/T-AFFC.2012.31.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{8}},
Doc-Delivery-Number = {{BJ1WQ}},
Unique-ID = {{ISI:000418294900002}},
DA = {{2020-06-17}},
}

@article{ ISI:000385086400004,
Author = {Oesterheld, Caspar},
Title = {{Formalizing preference utilitarianism in physical world models}},
Journal = {{SYNTHESE}},
Year = {{2016}},
Volume = {{193}},
Number = {{9}},
Pages = {{2747-2759}},
Month = {{SEP}},
Abstract = {{Most ethical work is done at a low level of formality. This makes
   practical moral questions inaccessible to formal and natural sciences
   and can lead to misunderstandings in ethical discussion. In this paper,
   we use Bayesian inference to introduce a formalization of preference
   utilitarianism in physical world models, specifically cellular automata.
   Even though our formalization is not immediately applicable, it is a
   first step in providing ethics and ultimately the question of how to
   ``make the world better{''} with a formal basis.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Oesterheld, C (Reprint Author), Univ Bremen, Bremen, Germany.
   Oesterheld, Caspar, Univ Bremen, Bremen, Germany.}},
DOI = {{10.1007/s11229-015-0883-1}},
ISSN = {{0039-7857}},
EISSN = {{1573-0964}},
Keywords = {{Preference utilitarianism; Formalization; Artificial life; (Machine)
   ethics}},
Research-Areas = {{History \& Philosophy of Science; Philosophy}},
Web-of-Science-Categories  = {{History \& Philosophy Of Science; Philosophy}},
Author-Email = {{caspar.oesterheld@uni-bremen.de}},
Cited-References = {{Anderson M., 2004, AAAI 04 WORKSH AG OR.
   Anderson M., 2011, MACHINE ETHICS.
   Anderson SL, 2011, MACHINE ETHICS, P524.
   Arneson R. J., 1998, WHAT IF ANYTHING REN.
   Bentham J., 1823, INTRO PRINCIPLES MOR.
   Bostrom N., 2011, ANAL METAPHYSICS, V10, P9.
   BOSTROM N, 2014, {[}No title captured], P1.
   Charniak E., 1983, AAAI 83 P WASH DC.
   Dennett D.C, 2006, INT COMP PHIL C LAV.
   Dennett D.C., 1971, J PHILOS, V68, P87, DOI DOI 10.2307/2025382.
   Dennett DC, 1989, INTENTIONAL STANCE.
   Downey A. B., 2012, THINK COMPLEXITY.
   Emmeche C., 1997, CTR PHILOS NATURE SC.
   Ettinger R. C. W., 2009, YOUNIVERSE SELF CTR.
   Furnkranz J, 2010, PREFERENCE LEARNING, P1.
   Gips J, 2011, MACHINE ETHICS, P244.
   Gruen L., 2014, STANFORD ENCY PHILOS.
   Hammond P. J., 1989, INTERPERSONAL COMP U.
   Hare R. M., 1981, MORAL THINKING ITS L.
   Harsanyi J. C., 1982, UTILITARIANISM, P39, DOI DOI 10.1017/CBO9780511611964.
   Hawking S., 2010, GRAND DESIGN.
   Hofstadter D.R., 2007, I AM STRANGE LOOP.
   Isbell J., 1959, CONTRIBUTIONS THEORY, P357.
   Legg S., 1997, THESIS.
   McLaren BM, 2011, MACHINE ETHICS, P297.
   Moor J, 2011, MACHINE ETHICS, P13.
   Nielsen TD, 2004, ARTIF INTELL, V160, P53, DOI 10.1016/j.artint.2004.08.003.
   Nozick R., 1969, ESSAYS HONOR CG HEMP, P114.
   Olshausen B. A., 2004, BAYESIAN PROBABILITY.
   Orseau L., 2012, ARTIFICIAL GEN INTEL, V5, P391.
   Peterson M, 2009, INTRO DECISION THEOR.
   ROBERT CP, 1994, {[}No title captured].
   Schmidhuber J., 1999, COMPUTER SCI VIEW LI.
   Shiffman D., 2012, THE NATURE OF CODE.
   Singer P., 1993, PRACTICAL ETHICS.
   Tomasik B., 2015, IS THERE SUFFERING F.
   Tomasik B., 2015, DO VIDEO GAME CHARAC.
   Tomasik B., 2015, HEDONISTIC VS PREFER.
   Wolfram S., 2002, NEW KIND SCI.
   WOLFRAM S, 1983, {[}No title captured], V9, P2.
   Yudkowsky Eliezer, 2001, CREATING FRIENDLY AI.
   Zuse K, 1970, RECHNENDER RAUM.
   ZUSE K, 1967, {[}No title captured], V8, P336.}},
Number-of-Cited-References = {{43}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{Synthese}},
Doc-Delivery-Number = {{DY4RJ}},
Unique-ID = {{ISI:000385086400004}},
OA = {{Other Gold}},
DA = {{2020-06-17}},
}

@article{ ISI:000393590000009,
Author = {Fabris, Adriano},
Title = {{Machine ethics}},
Journal = {{TEORIA-RIVISTA DI FILOSOFIA}},
Year = {{2016}},
Volume = {{36}},
Number = {{2}},
Pages = {{119-136}},
Abstract = {{This paper discusses some issues concerning the so-called ``machine
   ethics{''}. Firstly, human agency and machine agency are distinguished
   clearly, from an ethical viewpoint. Secondly, the concept of
   ``autonomy{''} is applied to machine agency and is defined as a
   ``relative autonomy{''}. Finally the principles of an ethical attitude
   of the human being in relation to the machine world are developed in
   detail.}},
Publisher = {{EDIZIONI ETS}},
Address = {{PIAZZA CARRARA 16-19, 56126 PISA, ITALY}},
Type = {{Article}},
Language = {{Italian}},
Affiliation = {{Fabris, A (Reprint Author), Univ Pisa, Dipartimento Civilta \& Forme Sapere, I-56100 Pisa, Italy.
   Fabris, Adriano, Univ Pisa, Dipartimento Civilta \& Forme Sapere, I-56100 Pisa, Italy.}},
ISSN = {{1122-1259}},
Keywords = {{ethics; machine; artificial intelligence; emerging technologies, robot;
   autonomy}},
Research-Areas = {{Philosophy}},
Web-of-Science-Categories  = {{Philosophy}},
Author-Email = {{adriano.fabris@unipi.it}},
ResearcherID-Numbers = {{Fabris, Adriano/AAI-7182-2020}},
Cited-References = {{Anderson M., 2011, MACHINE ETHICS.
   {[}Anonymous], 2012, SULLARGOMENTO MI PER.
   Calo R., 2016, ROBOT LAW.
   Cantoni L., 2015, COMMUNICATION TECHNO, P365.
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   FLORIDI L., 2013, ETHICS INFORM.
   Hibbard B., 2014, ETHICAL ARTIFICIAL I.
   Koch C., 2013, COSCIENZA CONFESSION, P164.
   Lin P, 2012, INTELL ROBOT AUTON, P1.
   Mori M., 1970, ENERGY, V7, P33, DOI DOI 10.1109/MRA.2012.2192811.
   Pagallo U, 2013, LAWS ROBOTS CRIMES C.
   Paic Z., 2016, THEORIZING IMAGES, P111.
   REICHLIN M, 2013, LUTILITARISMO.
   RelAzione, 2016, RELAZIONE FILOSOFIA.
   Shannon C. E., 1963, MATEMATHICAL THEORY.
   Wallach W., 2009, MORAL MACHINES TEACH, P4.
   Wiener N., 1968, CYBERNETICS CONTROL.}},
Number-of-Cited-References = {{17}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{13}},
Journal-ISO = {{Teoria}},
Doc-Delivery-Number = {{EK0AY}},
Unique-ID = {{ISI:000393590000009}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000390311200012,
Author = {Sullins, John},
Editor = {{Seibt, J and Norskov, M and Andersen, SS}},
Title = {{Artificial Phronesis and the Social Robot}},
Booktitle = {{WHAT SOCIAL ROBOTS CAN AND SHOULD DO}},
Series = {{Frontiers in Artificial Intelligence and Applications}},
Year = {{2016}},
Volume = {{290}},
Pages = {{37-39}},
Note = {{Conference on Robophilosophy / TRANSOR Conference on What Social Robots
   Can and Should Do, Aarhus Univ, Aarhus, DENMARK, OCT 17-21, 2016}},
Organization = {{Aarhus Univ, Sch Culture \& Soc, Res Unit Robophilosophy; Res Network
   Transdisciplinary Studies Social Robot; Danish Res Council Humanities}},
Publisher = {{IOS PRESS}},
Address = {{NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Sullins, J (Reprint Author), Sonoma State Univ, Dept Philosophy, 1801 East Cotati Ave, Rohnert Pk, CA 94928 USA.
   Sullins, John, Sonoma State Univ, Dept Philosophy, 1801 East Cotati Ave, Rohnert Pk, CA 94928 USA.}},
DOI = {{10.3233/978-1-61499-708-5-37}},
ISSN = {{0922-6389}},
ISBN = {{978-1-61499-708-5; 978-1-61499-707-8}},
Keywords = {{phronesis; machine ethics; machine morality; robot ethics; practical
   reasoning; skills; action planning; inductive reasoning; artificial
   general intelligence (AGI); limitations of machine learning}},
Research-Areas = {{Social Issues}},
Web-of-Science-Categories  = {{Social Issues}},
Author-Email = {{john.sullins@sonoma.edu}},
Cited-References = {{Aristotle, 1985, NICHOMACHEAN ETHICS, P151.
   DANIELSON P, 1998, {[}No title captured].
   DANIELSON P, 1992, {[}No title captured].
   Danielson P, 2010, ETHICS INF TECHNOL, V12, P251, DOI 10.1007/s10676-009-9214-x.
   Dewey J., 1998, ESSENTIAL DEWEY, V2, P225.
   Dewey J., 1998, ESSENTIAL DEWEY, V1, P39.
   Rogers ML, 2007, T C S PEIRCE SOC, V43, P90, DOI 10.2979/TRA.2007.43.1.90.
   Wallach W., 2010, MORAL MACHINES TEACH.
   Wallach W, 2010, TOP COGN SCI, V2, P454, DOI 10.1111/j.1756-8765.2010.01095.x.
   White J. C., 2013, COMPUTATIONAL INTELL, P1.}},
Number-of-Cited-References = {{10}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{6}},
Doc-Delivery-Number = {{BG6IZ}},
Unique-ID = {{ISI:000390311200012}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000455812500008,
Author = {Sullins, John P.},
Editor = {{Seibt, J and Hakli, R and Norskov, M}},
Title = {{Machine Morality Operationalized}},
Booktitle = {{SOCIABLE ROBOTS AND THE FUTURE OF SOCIAL RELATIONS}},
Series = {{Frontiers in Artificial Intelligence and Applications}},
Year = {{2014}},
Volume = {{273}},
Pages = {{17}},
Note = {{Conference on Robo-Philosophy - Sociable Robotics and the Future of
   Social Relations, Aarhus, DENMARK, AUG 20-23, 2014}},
Publisher = {{IOS PRESS}},
Address = {{NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Sullins, JP (Reprint Author), Sonoma State Univ, Philosophy Dept, Ctr Eth Law \& Soc, Rohnert Pk, CA 94928 USA.
   Sullins, John P., Sonoma State Univ, Philosophy Dept, Ctr Eth Law \& Soc, Rohnert Pk, CA 94928 USA.}},
DOI = {{10.3233/978-1-61499-480-0-17}},
ISSN = {{0922-6389}},
EISSN = {{1879-8314}},
ISBN = {{978-1-61499-480-0; 978-1-61499-479-4}},
Keywords = {{machine ethics; moral agency; robot warfare; artificial phronesis;
   methodology}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Ergonomics}},
Cited-References = {{Sullins J. P., 2013, CYB CONFL CYCON 2013, P1.
   Sullins J. P., 2011, PHILOS TECHNOL, V24, P233, DOI DOI 10.1007/S13347-011-0043-6.
   Sullins JP, 2014, LAW GOV TECHNOL SER, V14, P187, DOI 10.1007/978-3-319-04135-3\_12.
   Sullins JP, 2012, IEEE T AFFECT COMPUT, V3, P398, DOI 10.1109/T-AFFC.2012.31.
   Sullins JP, 2010, ETHICS INF TECHNOL, V12, P263, DOI 10.1007/s10676-010-9241-7.
   Sullins JP, 2011, MACHINE ETHICS, V6, P151, DOI 10.1017/CBO9780511978036.021.}},
Number-of-Cited-References = {{6}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BL7YR}},
Unique-ID = {{ISI:000455812500008}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000348931200035,
Author = {Krichmar, Jeffrey L. and Wagatsuma, Hiroaki},
Editor = {{Samsonovich, AV and Johannsdottir, KR}},
Title = {{Neuromorphic and Brain-Based Robots}},
Booktitle = {{BIOLOGICALLY INSPIRED COGNITIVE ARCHITECTURES 2011}},
Series = {{Frontiers in Artificial Intelligence and Applications}},
Year = {{2011}},
Volume = {{233}},
Pages = {{209+}},
Note = {{2nd Annual Meeting of the
   Biologically-Inspired-Cognitive-Architectures-Society (BICA), Arlington,
   VA, NOV 04-06, 2011}},
Organization = {{Biologically Inspired Cognit Architectures Soc}},
Abstract = {{Neuromorphic and brain-based robotics have enormous potential for
   furthering our understanding of the brain. By embodying models of the
   brain on robotic platforms, researchers can investigate the roots of
   biological intelligence and work towards the development of truly
   intelligent machines. This paper discusses the history of the field and
   its potential. We give examples of biologically inspired robot designs
   and neural architectures that lead to brain-based robots. Looking to the
   future, we consider the development of cognitive, or even conscious,
   robots that display the adaptability and intelligence of biological
   organisms.}},
Publisher = {{IOS PRESS}},
Address = {{NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Krichmar, JL (Reprint Author), Univ Calif Irvine, Dept Cognit Sci, 2328 Social \& Behav Sci Gateway, Irvine, CA 92697 USA.
   Krichmar, Jeffrey L., Univ Calif Irvine, Dept Cognit Sci, 2328 Social \& Behav Sci Gateway, Irvine, CA 92697 USA.
   Wagatsuma, Hiroaki, Kyushu Inst Technol, Dept Brain Sci \& Engn, Kitakyushu, Fukuoka, Japan.
   Wagatsuma, Hiroaki, RIKEN Brain Sci Inst, Wako, Saitama, Japan.}},
DOI = {{10.3233/978-1-60750-959-2-209}},
ISSN = {{0922-6389}},
ISBN = {{978-1-60750-959-2; 978-1-60750-958-5}},
Keywords = {{Brain-based robots; cognitive robots; computational neuroscience;
   machine ethics; neuromorphic engineering; neurorobots}},
Keywords-Plus = {{FRAMEWORK}},
Research-Areas = {{Computer Science; Mathematical \& Computational Biology}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Mathematical \& Computational
   Biology}},
Author-Email = {{jkrichma@uci.edu}},
ORCID-Numbers = {{Krichmar, Jeffrey/0000-0003-0739-2468}},
Cited-References = {{Asada Minoru, 2011, NEUROMORPHIC BRAIN B, P251.
   Bekey G. A., 2011, NEUROMORPHIC BRAIN B, P323.
   Braitenberg V, 1986, VEHICLES EXPT SYNTHE.
   Cox BR, 2009, IEEE ROBOT AUTOM MAG, V16, P72, DOI 10.1109/MRA.2009.933628.
   Edelman GM, 2003, P NATL ACAD SCI USA, V100, P5520, DOI 10.1073/pnas.0931349100.
   Fleischer JG, 2011, NEUROMORPHIC BRAIN B, P303.
   Hosoda K., 2011, NEUROMORPHIC BRAIN B, P11.
   Kaplan F, 2011, NEUROMORPHIC BRAIN B, P217.
   Krichmar J. L., 2011, NEUROMORPHIC BRAIN B.
   Krichmar JL, 2008, ADAPT BEHAV, V16, P385, DOI 10.1177/1059712308095775.
   Mitchinson B, 2011, NEUROMORPHIC BRAIN B, P23.
   Pfeifer R., 2007, BODY SHAPES WAY WE T.
   Wagatsuma H., 2011, NEUROMORPHIC BRAIN B, P274.
   WALTER WG, 1953, {[}No title captured].
   Wyeth G., 2011, NEUROMORPHIC BRAIN B, P87.}},
Number-of-Cited-References = {{15}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BC0DP}},
Unique-ID = {{ISI:000348931200035}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000269197301053,
Author = {Rzepka, Rafal and Higuchi, Shinsuke and Ptaszynski, Michal and Araki,
   Kenji},
Book-Group-Author = {{IEEE}},
Title = {{Straight Thinking Straight From The Net - On The Web-Based Intelligent
   Talking Toy Development}},
Booktitle = {{2008 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS
   (SMC), VOLS 1-6}},
Series = {{IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings}},
Year = {{2008}},
Pages = {{2171-2175}},
Note = {{IEEE International Conference on System, Man, and Cybernetic, Singapore,
   SINGAPORE, OCT 12-15, 2008}},
Organization = {{IEEE}},
Abstract = {{This paper introduces an early stage of a smart toy development project
   which combines several techniques to achieve a level of conversational
   skills and knowledge higher than currently available robots for
   children. We describe our ideas and achievements for three modules which
   we treat as the most important - topic unlimited talking engine,
   emotions recognizer and the moral behavior analyzer. We will also
   mention our novel evaluation method for freely speaking agents and
   possibilities of adding another module - an automatic joke generator.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Rzepka, R (Reprint Author), Hokkaido Univ, Grad Sch Informat Sci \& Technol, Kita Ku, Kita 14 Nishi 9, Sapporo, Hokkaido 0600814, Japan.
   Rzepka, Rafal; Higuchi, Shinsuke; Ptaszynski, Michal; Araki, Kenji, Hokkaido Univ, Grad Sch Informat Sci \& Technol, Kita Ku, Sapporo, Hokkaido 0600814, Japan.}},
ISSN = {{1062-922X}},
ISBN = {{978-1-4244-2383-5}},
Keywords = {{Intelligent systems; common sense; affect analysis; machine ethics}},
Research-Areas = {{Computer Science; Engineering; Imaging Science \& Photographic
   Technology}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Engineering, Electrical \& Electronic; Imaging Science \&
   Photographic Technology}},
Author-Email = {{kabura@media.eng.hokudai.ac.jp
   shin\_h@media.eng.hokudai.ac.jp
   ptaszynski@media.eng.hokudai.ac.jp
   araki@media.eng.hokudai.ac.jp}},
ResearcherID-Numbers = {{Rzepka, Rafal/E-2215-2014}},
ORCID-Numbers = {{Rzepka, Rafal/0000-0002-8274-0875}},
Cited-References = {{Bentham J., 1789, INTRO PRINCIPLES MOR.
   BINSTED K, 1995, {[}No title captured].
   DYBALA P, 2008, P NLP 08 C TOK MARCH, P701.
   GE Y, 2005, P INT INF SYST 2005, P51.
   Gustafson J., 2000, NAT LANG ENG, V1, P1.
   Hasegawa D, 2007, LECT NOTES COMPUT SC, V4830, P664.
   HIGUCHI S, 2008, {[}No title captured], P175.
   KOPP S, {[}No title captured], P329.
   Morkes J, 1999, HUM-COMPUT INTERACT, V14, P395, DOI 10.1207/S15327051HCI1404\_2.
   NAKAMURA H, 2004, {[}No title captured].
   Picard R. W., 1997, AFFECTIVE COMPUTING.
   PTASZYNSKI M, 2008, P NLP 08 C TOK MARCH, P170.
   PTASZYNSKI M, 2008, {[}No title captured].
   PTASZYNSKI M, 2007, IDEA DYNAMIC MEMORY, P12.
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714.
   RZEPKA R, 2003, P ART INT APPL C MAL, P22.
   Rzepka R., 2007, AAAI FALL S, P127.
   RZEPKA R, 2005, COMPUTER SCI, V14, P376.
   SAMSONOVICH AV, 2008, {[}No title captured].
   SCHANK R, 1977, {[}No title captured].
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x.
   SJOBERGH J, 2008, P LIBM 2008, P46.
   TSUCHIYA S, 2007, {[}No title captured], V14.
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417.}},
Number-of-Cited-References = {{24}},
Times-Cited = {{1}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{2}},
Doc-Delivery-Number = {{BKT54}},
Unique-ID = {{ISI:000269197301053}},
DA = {{2020-06-17}},
}

@article{ ISI:000534527200001,
Author = {Behdadi, Dorna and Munthe, Christian},
Title = {{A Normative Approach to Artificial Moral Agency}},
Journal = {{MINDS AND MACHINES}},
Abstract = {{This paper proposes a methodological redirection of the philosophical
   debate on artificial moral agency (AMA) in view of increasingly pressing
   practical needs due to technological development. This ``normative
   approach{''} suggests abandoning theoretical discussions about what
   conditions may hold for moral agency and to what extent these may be met
   by artificial entities such as AI systems and robots. Instead, the
   debate should focus on how and to what extent such entities should be
   included in human practices normally assuming moral agency and
   responsibility of participants. The proposal is backed up by an analysis
   of the AMA debate, which is found to be overly caught in the opposition
   between so-called standard and functionalist conceptions of moral
   agency, conceptually confused and practically inert. Additionally, we
   outline some main themes of research in need of attention in light of
   the suggested normative approach to AMA.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article; Early Access}},
Language = {{English}},
Affiliation = {{Behdadi, D (Reprint Author), Univ Gothenburg, Dept Philosophy Linguist \& Theory Sci, Box 200, S-40530 Gothenburg, Sweden.
   Behdadi, Dorna; Munthe, Christian, Univ Gothenburg, Dept Philosophy Linguist \& Theory Sci, Box 200, S-40530 Gothenburg, Sweden.}},
DOI = {{10.1007/s11023-020-09525-8}},
Early Access Date = {{MAY 2020}},
ISSN = {{0924-6495}},
EISSN = {{1572-8641}},
Keywords = {{Moral agency; Moral responsibility; Artificial intelligence; Artificial
   agency; Artificial moral agent; Machine ethics; Moral machine; Machine
   consciousness; Consciousness; Demarcation problem; Moral status}},
Keywords-Plus = {{RESPONSIBILITY; ETHICS; ROBOTS; CONSCIOUSNESS; INTELLIGENT; SYSTEMS}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{dorna.behdadi@gu.se
   christian.munthe@gu.se}},
ORCID-Numbers = {{Behdadi, Dorna/0000-0003-4919-0784}},
Funding-Acknowledgement = {{University of Gothenburg; Swedish Research Council (VR)Swedish Research
   Council {[}2014-40]}},
Funding-Text = {{Open access funding provided by University of Gothenburg. This work has
   been partly undertaken within the Lund Gothenburg Responsibility
   Project, funded by the Swedish Research Council (VR), contract no.
   2014-40. We are especially grateful for the very helpful input by
   Per-Erik Milam in seminars and in finalizing the revised manuscript. We
   would also like to thank Bengt Brulde for critical suggestions in the
   early stages of drafting this paper. Lastly, we thank our colleagues
   Leila El-Alti, Ida Hallgren, Sofia Jeppsson, Ben Matheson, Marco Tiozzo,
   Ragnar Francen, John Eriksson and Anders Tolland for comments received
   during seminars. Any remaining mistakes and errors are our own.}},
Cited-References = {{Adams Thomas K., 2001, PARAMETERS, V31, P57.
   Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Anderson M., 2004, P AAAI.
   Anderson M, 2007, AI MAG, V28, P15.
   Anderson SL, 2008, AI SOC, V22, P477, DOI 10.1007/s00146-007-0094-5.
   Annas J., 2011, INTELLIGENT VIRTUE.
   Arkin R. C., 2010, J MILITARY ETHICS, V9, P332.
   Asaro PM, 2006, INT REV INF ETHICS, V6, P9.
   Asimov Isaac, 1942, ASTOUNDING SCI FICTI, P94.
   Bahrammirzaee A, 2010, NEURAL COMPUT APPL, V19, P1165, DOI 10.1007/s00521-010-0362-z.
   Beavers AF, 2011, MORAL MACHINES THREA, P333.
   Bjornsson G, 2013, PHILOS PHENOMEN RES, V87, P611, DOI 10.1111/j.1933-1592.2012.00603.x.
   Bjornsson G, 2012, NOUS, V46, P326, DOI 10.1111/j.1468-0068.2010.00813.x.
   BRINGSJORD S, 1992, {[}No title captured].
   Bringsjord S, 2008, AI SOC, V22, P539, DOI 10.1007/s00146-007-0090-9.
   Bryson JJ, 2010, ROBOTS SHOULD BE SLA, P63.
   Champagne M, 2013, PHILOS TECHNOLOGY, V28, P125.
   Christman John, 2015, STANFORD ENCY PHILOS.
   Coeckelbergh M, 2009, AI SOC, V24, P181, DOI 10.1007/s00146-009-0208-3.
   Coeckelbergh M, 2010, ETHICS INF TECHNOL, V12, P235, DOI 10.1007/s10676-010-9221-y.
   Crnkovic GD, 2012, ETHICS INF TECHNOL, V14, P61, DOI 10.1007/s10676-011-9278-2.
   Danaher J, 2019, AUTOMATION UTOPIA.
   Davis M, 2012, SCI ENG ETHICS, V18, P13, DOI 10.1007/s11948-010-9225-3.
   Dennett DC, 1987, INTENTIONAL STANCE, P43.
   Dennett DC, 1973, ESSAYS FREEDOM ACTIO, P157.
   Dodig-Crnkovic G, 2008, FRONT ARTIF INTEL AP, V173, P165.
   Dreyfus H. L, 1992, WHAT COMPUTERS STILL.
   Eshleman A, 2014, STANFORD ENCY PHILOS.
   Etzioni A, 2018, LIBR PUBLIC POLICY P, V11, P253, DOI 10.1007/978-3-319-69623-2\_16.
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   FRIEDMAN B, 1992, J SYST SOFTWARE, V17, P7, DOI 10.1016/0164-1212(92)90075-U.
   Gerdes Anne, 2015, Journal of Information, Communication and Ethics in Society, V13, P98, DOI 10.1108/JICES-09-2014-0038.
   Gladden ME, 2016, EMERG TECH ETH INT A, P177.
   Grodzinsky Frances S, 2008, Ethics and Information Technology, V10, P27, DOI 10.1007/s10676-008-9163-9.
   Gunkel DJ, 2014, PHILOS TECHNOL, V27, P113, DOI DOI 10.1007/S13347-013-0121-Z.
   Haggstrom H, 2016, HERE BE DRAGONS SCI.
   Hellstrom T, 2013, ETHICS INF TECHNOL, V15, P99, DOI 10.1007/s10676-012-9301-2.
   High-Level Expert Group on Artificial Intelligence European Commission, 2019, ETH GUID TRUSTW AI.
   Himma KE, 2009, ETHICS INF TECHNOL, V11, P19, DOI 10.1007/s10676-008-9167-5.
   Holroyd J, 2018, SOCIAL DIMENSIONS MO, P137.
   Irrgang B, 2006, UBIQUITY, V7, P34.
   Johansson L, 2010, INT J TECHNOETHICS, V1, P65, DOI 10.4018/jte.2010100105.
   Johnson D, 2008, INFORM TECHNOLOGY MO, V2008, P251.
   Johnson D. G., 2005, Ethics and Information Technology, V7, P99, DOI 10.1007/s10676-005-4585-0.
   Johnson Deborah G, 2008, Ethics and Information Technology, V10, P123, DOI 10.1007/s10676-008-9174-6.
   Johnson D. G., 2006, Ethics and Information Technology, V8, P195, DOI 10.1007/s10676-006-9111-5.
   Kolodny N, 2016, STANFORD ENCY PHILOS.
   Korsgaard C. M., 2004, TANNER LECT HUMAN VA, V25, P77.
   Lin P, 2008, DTIC DOCUMENT.
   Lokhorst GJ, 2012, INTELL ROBOT AUTON, P145.
   Macnamara C, 2015, BLAME COMMUNICATION, P211.
   Matheson B, 2012, MANIPULATION MORAL R, P11.
   Matthias A., 2004, Ethics and Information Technology, V6, P175, DOI 10.1007/s10676-004-3422-1.
   McDermott D, 2008, WHY ETHICS IS HIGH H.
   McGeer V, 2015, PHILOS EXPLOR, V18, P259, DOI 10.1080/13869795.2015.1032331.
   McKenna M. A. C, 2015, STANFORD ENCY PHILOS.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Moor James H., 2009, PHILOS NOW, V72, P12.
   Musen MA, 2014, BIOMEDICAL INFORM, P643, DOI DOI 10.1007/978-1-4471-4474-8\_22.
   Nadeau JE, 2006, ONLY ANDROIDS CAN BE.
   NAGEL T, 1974, PHILOS REV, V83, P435, DOI 10.2307/2183914.
   Nagenborg M, 2007, INT REV INF ETHICS, V7, P129.
   Noone Gregory P., 2015, CASE W RES J INT L, V47, P25.
   Noorman M, 2014, SCI ENG ETHICS, V20, P809, DOI 10.1007/s11948-013-9484-x.
   Noorman M, 2014, ETHICS INF TECHNOL, V16, P51, DOI 10.1007/s10676-013-9335-0.
   Nyholm S, 2018, SCI ENG ETHICS, V24, P1201, DOI 10.1007/s11948-017-9943-x.
   Nyhom S, 2020, HUMANS ROBOTS ETHICS.
   O'Connor T, 2016, STANFORD ENCY PHILOS.
   Parthemore J., 2013, INT J MACHINE CONSCI, V5, P105.
   Picard R. W., 1997, AFFECTIVE COMPUTING.
   Pontier M., 2012, P ANN M COGN SCI SOC, V34.
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77.
   Powers TM, 2013, TOPOI-INT REV PHILOS, V32, P227, DOI 10.1007/s11245-012-9149-4.
   Purves D, 2015, ETHICAL THEORY MORAL, V18, P851, DOI 10.1007/s10677-015-9563-y.
   Samuelsson L, 2010, ENVIRON ETHICS, V32, P247, DOI 10.5840/enviroethics201032330.
   Schulzke M., 2013, PHILOS TECHNOLOGY, V26, P203, DOI DOI 10.1007/S13347-012-0089-0.
   Shaw E, 2019, FREE WILL SKEPTICISM.
   Sheikhtaheri A, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0110-5.
   Shen S, 2011, ACMIEEE INT CONF HUM, P249, DOI 10.1145/1957656.1957755.
   Singer AE, 2013, P ANN HICSS, P4525, DOI 10.1109/HICSS.2013.149.
   Singer FM, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2011.01.043.
   Sliwa P, 2015, PHILOS PHENOMENOLOGI.
   Sparrow R., 2007, J APPL PHILOS, V24, P62, DOI DOI 10.1111/J.1468-5930.2007.00346.X.
   Stahl B. C., 2006, Ethics and Information Technology, V8, P205, DOI 10.1007/s10676-006-9112-4.
   Stahl BC, 2004, MIND MACH, V14, P67.
   Sullins JP, 2006, INT REV INF ETHICS, V6, P23.
   Sullins JP, 2010, ETHICS INF TECHNOL, V12, P263, DOI 10.1007/s10676-010-9241-7.
   Swiatek MS, 2012, ETHICS INF TECHNOL, V14, P241, DOI 10.1007/s10676-012-9302-1.
   Tonkens R, 2012, ETHICS INF TECHNOL, V14, P137, DOI 10.1007/s10676-012-9290-1.
   Tonkens R, 2009, MIND MACH, V19, P421, DOI 10.1007/s11023-009-9159-1.
   Torrance S, 2008, AI SOC, V22, P495, DOI 10.1007/s00146-007-0091-8.
   Vargas M, 2013, BUILDING BETTER BEIN.
   Verbeek P.-P., 2011, MORALIZING TECHNOLOG.
   VERSENYI L, 1974, ETHICS, V84, P248, DOI 10.1086/291922.
   Veruggio G, 2008, SPRINGER HDB ROBOTIC, P1499.
   Wallace R. J, 2014, STANFORD ENCY PHILOS.
   Wallach W, 2008, MORAL MACHINES TEACH.
   Warren MA, 1997, MORAL STATUS OBLIGAT.
   Yampolskiy RV, 2013, PHILOS THEORY ARTIFI, P389.
   王飞跃, 2016, {[}科技导报, Science \& Technology Review], V34, P72.}},
Number-of-Cited-References = {{100}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Minds Mach.}},
Doc-Delivery-Number = {{LP7VS}},
Unique-ID = {{ISI:000534527200001}},
OA = {{Other Gold}},
DA = {{2020-06-17}},
}

@article{ ISI:000532627900002,
Author = {Swanepoel, Danielle},
Title = {{The possibility of deliberate norm-adherence in AI}},
Journal = {{ETHICS AND INFORMATION TECHNOLOGY}},
Abstract = {{Moral agency status is often given to those individuals or entities
   which act intentionally within a society or environment. In the past,
   moral agency has primarily been focused on human beings and some
   higher-order animals. However, with the fast-paced advancements made in
   artificial intelligence (AI), we are now quickly approaching the point
   where we need to ask an important question: should we grant moral agency
   status to AI? To answer this question, we need to determine the moral
   agency status of these entities in society. In this paper I argue that
   to grant moral agency status to an entity, deliberate norm-adherence
   must be possible (at a minimum). In this paper I argue that, under the
   current status quo, AI systems are unable to meet this criterion. The
   novel contribution this paper makes to the field of machine ethics is
   first, to provide at least two criteria with which we can determine
   moral agency status. We do this by determining the possibility of
   deliberate norm-adherence through examining the possibility of
   deliberate norm-violation. Second, to show that establishing moral
   agency in AI suffer the same pitfalls as establishing moral agency in
   constitutive accounts of agency.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article; Early Access}},
Language = {{English}},
Affiliation = {{Swanepoel, D (Reprint Author), Univ Johannesburg, Cnr Kingsway \& Univ Rd, Johannesburg, South Africa.
   Swanepoel, D (Reprint Author), SolBridge Int Sch Business, 127 Uam Ro, Daejeon, South Korea.
   Swanepoel, Danielle, Univ Johannesburg, Cnr Kingsway \& Univ Rd, Johannesburg, South Africa.
   Swanepoel, Danielle, SolBridge Int Sch Business, 127 Uam Ro, Daejeon, South Korea.}},
DOI = {{10.1007/s10676-020-09535-1}},
Early Access Date = {{MAY 2020}},
ISSN = {{1388-1957}},
EISSN = {{1572-8439}},
Keywords = {{Artificial intelligence; Moral agency; Norm-violation; Norm-adherence;
   Constitutivism}},
Keywords-Plus = {{NORMATIVITY; AGENCY}},
Research-Areas = {{Social Sciences - Other Topics; Information Science \& Library Science;
   Philosophy}},
Web-of-Science-Categories  = {{Ethics; Information Science \& Library Science; Philosophy}},
Author-Email = {{Dswanepoel@solbridge.ac.kr}},
Cited-References = {{Bratman M, 2007, STRUCTURES OF AGENCY.
   Castelfranchi C, 2000, DELIBERATIVE NORMATI, P364.
   Coeckelbergh M, 2009, AI SOC, V24, P181, DOI 10.1007/s00146-009-0208-3.
   DAVIDSON D, 1963, J PHILOS, V60, P685, DOI 10.2307/2023177.
   Enoch D, 2006, PHILOS REV, V115, P169, DOI 10.1215/00318108-2005-014.
   FERRERO L, 2009, {[}No title captured], V4, P303.
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   FRANKFURT HG, 1969, J PHILOS, V66, P829, DOI 10.2307/2023833.
   Gunkel D, 2012, MACHINE QUESTION CRI.
   Hansson S, 1994, DECISION THEORY BRIE.
   Huffer B, 2007, SYNTHESE, V157, P241, DOI 10.1007/s11229-006-9107-z.
   Johnson A., EJOURNAL PUBLIC AFFA, V3, P52.
   Kant I., 1785, GROUNDWORK METAPHYSI.
   Katsafanas P, 2013, AGENCY FDN ETHICS NI.
   Korsgaard C, 2008, CONSTITUTION AGENCY.
   Korsgaard Christine M., 2009, SELF CONSTITUTION AG.
   McKenna M., 2018, COMPATIBILISM.
   Moor J, 2011, MACHINE ETHICS, P13.
   Muller V, 2019, ETHICS AI ROBOTICS.
   Railton P, 2003, ETHICS PRACTICAL REA, P53.
   Rosati C. S., 2016, OXFORD STUDIES METAE, V11, P182.
   Rosati CS, 2003, ETHICS, V113, P490, DOI 10.1086/345625.
   ROSATI CS, 1995, NOUS, V29, P46, DOI 10.2307/2215726.
   Tiffany E, 2012, AUSTRALAS J PHILOS, V90, P223, DOI 10.1080/00048402.2011.605792.
   Velleman JD, 2004, PHILOS STUD, V121, P225, DOI 10.1007/s11098-004-5506-5.
   Velleman JD, 1996, ETHICS, V106, P694, DOI 10.1086/233669.
   Warfield TA, 2000, NOUS, P167.}},
Number-of-Cited-References = {{27}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Ethics Inf. Technol.}},
Doc-Delivery-Number = {{LN0HX}},
Unique-ID = {{ISI:000532627900002}},
DA = {{2020-06-17}},
}

@article{ ISI:000528642000001,
Author = {Gamez, Patrick and Shank, Daniel B. and Arnold, Carson and North,
   Mallory},
Title = {{Artificial virtue: the machine question and perceptions of moral
   character in artificial moral agents}},
Journal = {{AI \& SOCIETY}},
Abstract = {{Virtue ethics seems to be a promising moral theory for understanding and
   interpreting the development and behavior of artificial moral agents.
   Virtuous artificial agents would blur traditional distinctions between
   different sorts of moral machines and could make a claim to membership
   in the moral community. Accordingly, we investigate the ``machine
   question{''} by studying whether virtue or vice can be attributed to
   artificial intelligence; that is, are people willing to judge machines
   as possessing moral character? An experiment describes situations where
   either human or AI agents engage in virtuous or vicious behavior and
   experiment participants then judge their level of virtue or vice. The
   scenarios represent different virtue ethics domains of truth, justice,
   fear, wealth, and honor. Quantitative and qualitative analyses show that
   moral attributions are weakened for AIs compared to humans, and the
   reasoning and explanations for the attributions are varied and more
   complex. On ``relational{''} views of membership in the moral community,
   virtuous machines would indeed be included, even if they are indeed
   weakened. Hence, while our moral relationships with artificial agents
   may be of the same types, they may yet remain substantively different
   than our relationships to human beings.}},
Publisher = {{SPRINGER}},
Address = {{ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES}},
Type = {{Article; Early Access}},
Language = {{English}},
Affiliation = {{Gamez, P (Reprint Author), Missouri Univ Sci \& Technol, Rolla, MO 65409 USA.
   Gamez, Patrick; Shank, Daniel B.; North, Mallory, Missouri Univ Sci \& Technol, Rolla, MO 65409 USA.
   Arnold, Carson, Univ Missouri, Columbia, MO USA.}},
DOI = {{10.1007/s00146-020-00977-1}},
Early Access Date = {{APR 2020}},
ISSN = {{0951-5666}},
EISSN = {{1435-5655}},
Keywords = {{Machine ethics; Virtue ethics; Artificial intelligence; Robot rights;
   Agents; Moral psychology}},
Keywords-Plus = {{INTENTIONAL ACTION; MIND PERCEPTION; ATTRIBUTIONS; INTELLIGENCE;
   IMPRESSIONS; COMPUTER; PEOPLE}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{gamezp@mst.edu
   shankd@mst.edu
   caap5b@mail.missouri.edu
   mgnqb9@mst.edu}},
Funding-Acknowledgement = {{Army Research Office {[}W911NF-19-1-0246]; Missouri University of
   Science and Technology's Center for Science, Technology, and Society}},
Funding-Text = {{This research was partially supported by the Army Research Office under
   Grant Number W911NF-19-1-0246. The views and conclusions contained in
   this document are those of the authors and should not be interpreted as
   representing the official policies, either expressed or implied, of the
   Army Research Office or the U.S. Government. The U.S. Government is
   authorized to reproduce and distribute reprints for Government purposes
   not with standing any copyright notation herein. This work was also
   funded by a small grant from Missouri University of Science and
   Technology's Center for Science, Technology, and Society to Daniel B.
   Shank and Patrick Gamez. We would also like to thank Alexander Gott,
   Madison Bowen, and Lawrence Hierlmeier for their help in developing the
   scenarios.}},
Cited-References = {{Agar N, 2019, PHILOS TECHNOL, DOI {[}10.1007/s13347-019-00357-8, DOI 10.1007/S13347-019-00357-8].
   Annas J, 2016, DEV VIRTUES, P224.
   Aristotle, 2011, ARISTOTLES NICOMACHE.
   Berberich N, 2018, ARXIV180610322.
   Bigman YE, 2018, COGNITION, V181, P21, DOI 10.1016/j.cognition.2018.08.003.
   Boden MA, 2016, AI ITS NATURE FUTURE.
   Boden MA, 2006, MIND MACHINE HIST CO.
   Bostrom N., 2014, SUPERINTELLIGENCE PA.
   Coeckelbergh M, 2010, ETHICS INF TECHNOL, V12, P209, DOI 10.1007/s10676-010-9235-5.
   Danaher J, 2016, PHILOS TECHNOLOGY, V29, P245, DOI DOI 10.1007/S13347-015-0211-1.
   Danaher John, 2019, Sci Eng Ethics, DOI 10.1007/s11948-019-00119-x.
   Dastur F, 2011, CONT PHILOS REV, V44, P165, DOI 10.1007/s11007-011-9175-8.
   Emerging technology from the arXiv, 2015, MIT TECHNOLOGY REV.
   Eubanks V., 2018, AUTOMATING INEQUALIT.
   Gamez P, 2018, OPEN PHILOS, V1, P191, DOI {[}10.1515/opphil-2018-0014, DOI 10.1515/OPPHIL-2018-0014].
   Govindarajulu NS, 2019, P 2019 AAAI ACM C ET, P29.
   Gray K, 2012, COGNITION, V125, P125, DOI 10.1016/j.cognition.2012.06.007.
   Gray K, 2012, PSYCHOL INQ, V23, P101, DOI 10.1080/1047840X.2012.651387.
   Gunkel D. J., 2012, MACH QUEST CRIT.
   GUNKEL DJ, 2018, {[}No title captured].
   Hitlin S, 2008, MORAL SELVES, EVIL SELVES: THE SOCIAL PSYCHOLOGY OF CONSCIENCE, P1, DOI 10.1057/9780230614949.
   Howard D, 2016, 2016 AAAI SPRING S S.
   Howard D, 2017, PHILOS STUD SER, V128, P121, DOI 10.1007/978-3-319-61043-6\_7.
   Hursthouse Rosalind, 1999, VIRTUE ETHICS.
   Keown Damien, 2005, BUDDHIST ETHICS VERY.
   Knobe J, 2003, PHILOS PSYCHOL, V16, P309, DOI 10.1080/09515080307771.
   Knobe J, 2003, ANALYSIS, V63, P190, DOI 10.1111/1467-8284.00419.
   Kraut R, 2018, STANFORD ENCY PHILOS.
   Large W, 2015, LEVINAS TOTALITY INF.
   Malle BF, 2019, INTEL SYST CONTR AUT, V95, P111, DOI 10.1007/978-3-030-12524-0\_11.
   McDermott D, 2011, MACHINE ETHICS, P88, DOI DOI 10.1017/CBO9780511978036.010.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Morgan ML, 2007, DISCOVERING LEVINAS, P1.
   Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153.
   Noble SU, 2018, ALGORITHMS OPPRESSIO.
   ONeil C., 2016, WEAPONS MATH DESTRUC.
   Regan T, 1987, ADV ANIMAL WELFARE S, V1986, P179.
   Seidel J, 2019, THE ADVERTISER.
   Sejnowski M, 2018, DEEP LEARNING REVOLU.
   Shank DB, 2019, INFORM COMMUN SOC, V22, P648, DOI 10.1080/1369118X.2019.1568515.
   Shank DB, 2018, COMPUT HUM BEHAV, V86, P401, DOI 10.1016/j.chb.2018.05.014.
   Shank DB, 2014, INT J HUM-COMPUT ST, V72, P747, DOI 10.1016/j.ijhcs.2014.05.002.
   Shank DB, 2013, COMPUT HUM BEHAV, V29, P715, DOI 10.1016/j.chb.2012.11.006.
   Sim M, 2017, VARIETIES VIRTUE ETH, P105.
   Singer P, 1975, ANIMAL LIBERATION NE.
   Smith H, 2012, PHILOS ISSUES, V22, P369, DOI 10.1111/j.1533-6077.2012.00235.x.
   Strawson Peter F., 1962, P BRIT ACAD, V48, P1, DOI DOI 10.1073/PNAS.48.1.1.
   Torrance S, 2011, MACHINE ETHICS, P115.
   Turkle S, 2011, MACHINE ETHICS, P62.
   Vallor S, 2016, TECHNOLOGY VIRTUES P.
   van Wynsberghe A, 2019, SCI ENG ETHICS, V25, P719, DOI 10.1007/s11948-018-0030-8.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.
   Wroe D, 2019, SYDNEY MORNING HERAL.
   Yampolskiy RV, 2013, PHILOS THEORY ARTIFI, P389.
   Young AD, 2019, J EXP SOC PSYCHOL, V85, DOI 10.1016/j.jesp.2019.103870.}},
Number-of-Cited-References = {{55}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{5}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{AI Soc.}},
Doc-Delivery-Number = {{LH2TY}},
Unique-ID = {{ISI:000528642000001}},
DA = {{2020-06-17}},
}

@article{ ISI:000528667300001,
Author = {Haas, Julia},
Title = {{Moral Gridworlds: A Theoretical Proposal for Modeling Artificial Moral
   Cognition}},
Journal = {{MINDS AND MACHINES}},
Abstract = {{I describe a suite of reinforcement learning environments in which
   artificial agents learn to value and respond to moral content and
   contexts. I illustrate the core principles of the framework by
   characterizing one such environment, or ``gridworld,{''} in which an
   agent learns to trade-off between monetary profit and fair dealing, as
   applied in a standard behavioral economic paradigm. I then highlight the
   core technical and philosophical advantages of the learning approach for
   modeling moral cognition, and for addressing the so-called value
   alignment problem in AI.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article; Early Access}},
Language = {{English}},
Affiliation = {{Haas, J (Reprint Author), Rhodes Coll, Dept Philosophy, Memphis, TN 38112 USA.
   Haas, Julia, Rhodes Coll, Dept Philosophy, Memphis, TN 38112 USA.}},
DOI = {{10.1007/s11023-020-09524-9}},
Early Access Date = {{APR 2020}},
ISSN = {{0924-6495}},
EISSN = {{1572-8641}},
Keywords = {{Artificial intelligence; Moral AI; Moral cognition; Machine ethics;
   Moral psychology; Reinforcement learning; Fairness}},
Keywords-Plus = {{DECISION-MAKING; ULTIMATUM GAME; AUTONOMOUS VEHICLES; FAIRNESS; ETHICS;
   AI; MECHANISMS; EVOLUTION; REPRESENTATIONS; ARCHITECTURE}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{juliashaas@gmail.com}},
Cited-References = {{Adamson G, 2019, P IEEE, V107, P518, DOI 10.1109/JPROC.2018.2884923.
   Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4.
   Allen C, 2012, INTELL ROBOT AUTON, P55.
   ALVARD M, 2004, {[}No title captured], P413.
   Amodei D., 2016, ARXIV160606565.
   Anderson M, 2018, PALADYN J BEHAV ROBO, V9, P337, DOI {[}10.1515/pjbr-2018-0024, DOI 10.1515/PJBR-2018-0024].
   Anderson M, 2006, P 18 C INN APPL ART, V2, P1759.
   Anderson M, 2019, P IEEE, V107, P526, DOI 10.1109/JPROC.2018.2840045.
   Arnold T., 2017, WORKSH 31 AAAI C ART.
   Barocas S, 2016, CALIF LAW REV, V104, P671, DOI 10.15779/Z38BG31.
   Bechtel W, 1999, PHILOS SCI, V66, P175, DOI 10.1086/392683.
   Bengio Y., 2007, LARGE SCALE KERNEL M, V34, P1.
   Berns GS, 2012, PHILOS T R SOC B, V367, P754, DOI 10.1098/rstb.2011.0262.
   Bigman YE, 2019, TRENDS COGN SCI, V23, P365, DOI 10.1016/j.tics.2019.02.008.
   Boksem MAS, 2010, SOC NEUROSCI-UK, V5, P118, DOI 10.1080/17470910903202666.
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654.
   Borenstein J., 2019, COGNITIVE ETHICAL SC, V134, P299.
   Botvinick M, 2019, TRENDS COGN SCI, V23, P408, DOI 10.1016/j.tics.2019.02.006.
   Bremner P, 2019, P IEEE, V107, P541, DOI 10.1109/JPROC.2019.2898267.
   Brown D. E., 1991, HUMAN UNIVERSALS.
   Brumbaugh SM, 2008, J MARRIAGE FAM, V70, P345, DOI 10.1111/j.1741-3737.2008.00486.x.
   Cave S, 2019, P IEEE, V107, P562, DOI 10.1109/JPROC.2018.2865996.
   Cervantes JA, 2020, SCI ENG ETHICS, V26, P501, DOI 10.1007/s11948-019-00151-x.
   Corradi-Dell'Acqua C, 2013, SOC COGN AFFECT NEUR, V8, P424, DOI 10.1093/scan/nss014.
   Crawford K, 2016, NATURE, V538, P311, DOI 10.1038/538311a.
   Crockett MJ, 2017, NAT NEUROSCI, V20, P879, DOI 10.1038/nn.4557.
   Crockett MJ, 2016, CURR DIR PSYCHOL SCI, V25, P85, DOI 10.1177/0963721415624012.
   Crockett MJ, 2013, TRENDS COGN SCI, V17, P363, DOI 10.1016/j.tics.2013.06.005.
   Cushman F, 2015, CURR OPIN BEHAV SCI, V3, P58, DOI 10.1016/j.cobeha.2015.01.006.
   de Sio FS, 2017, ETHICAL THEORY MORAL, V20, P411, DOI 10.1007/s10677-017-9780-7.
   Debove S, 2016, EVOL HUM BEHAV, V37, P245, DOI 10.1016/j.evolhumbehav.2016.01.001.
   Dennis L, 2016, ROBOT AUTON SYST, V77, P1, DOI 10.1016/j.robot.2015.11.012.
   Dietrich F, 2017, PHILOS REV, V126, P421, DOI 10.1215/00318108-4173412.
   Doran D., 2017, ARXIV171000794.
   Doris J. M., 2002, LACK CHARACTER PERSO.
   Dretske F., 1994, MIDWEST STUD PHILOS, V19, P468, DOI DOI 10.1111/J.1475-4975.1994.TB00299.X.
   Driver CJ, 2005, TLS-TIMES LIT SUPPL, P31.
   Elgin CZ, 2017, TRUE ENOUGH, P1.
   Everitt T., 2018, ARXIV180501109.
   Everitt T., 2017, ARXIV170508417.
   FARRELL J, 1987, RAND J ECON, V18, P34, DOI 10.2307/2555533.
   Fehr E., 2003, ECONOMETRIC SOC MONO.
   Feng CL, 2015, HUM BRAIN MAPP, V36, P591, DOI 10.1002/hbm.22649.
   Flanagan O., 2007, MORAL PSYCHOL, V1, P1.
   Fleetwood J, 2017, AM J PUBLIC HEALTH, V107, P532, DOI 10.2105/AJPH.2016.303628.
   FORSYTHE R, 1994, GAME ECON BEHAV, V6, P347, DOI 10.1006/game.1994.1021.
   Gabor Z., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P197.
   Glimcher P.W., 2011, FDN NEUROECONOMIC AN.
   Gogoll J, 2017, SCI ENG ETHICS, V23, P681, DOI 10.1007/s11948-016-9806-x.
   GUTH W, 1982, J ECON BEHAV ORGAN, V3, P367, DOI 10.1016/0167-2681(82)90011-7.
   Haas J, 2019, BEHAV BRAIN SCI, V42, DOI 10.1017/S0140525X18002686.
   Hadfield-Menell D., 2017, ADV NEURAL INFORM PR, P6765.
   HARTMANN S, 1996, {[}No title captured], P77, DOI DOI 10.1007/978-94-015-8686-3.
   Henrich J, 2010, BEHAV BRAIN SCI, V33, P111, DOI 10.1017/S0140525X10000725.
   Henrich J, 2010, NATURE, V466, P29, DOI 10.1038/466029a.
   Henrich J, 2010, SCIENCE, V327, P1480, DOI 10.1126/science.1182238.
   Himmelreich J, 2018, ETHICAL THEORY MORAL, V21, P669, DOI 10.1007/s10677-018-9896-4.
   Holstein K., 2019, P 2019 CHI C HUM FAC, P1.
   Honarvar AR, 2009, LECT NOTES ARTIF INT, V5855, P86, DOI 10.1007/978-3-642-05253-8\_10.
   Hoppenbrouwers SS, 2015, PERS INDIV DIFFER, V86, P132, DOI 10.1016/j.paid.2015.06.009.
   Howard D, 2017, PHILOS STUD SER, V128, P121, DOI 10.1007/978-3-319-61043-6\_7.
   Iyer R, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P144, DOI 10.1145/3278721.3278776.
   JOBIN A, 2019, {[}No title captured], V1, P389, DOI DOI 10.1038/S42256-019-0088-2.
   KAHNEMAN D, 1986, AM ECON REV, V76, P728.
   Kamm FM, 2008, INTRICATE ETHICS RIG.
   Ku HH, 2019, J CONSUM BEHAV, V18, P43, DOI 10.1002/cb.1743.
   Larson J, 2016, PROPUBLICA, V5, P9.
   Leike Jan, 2017, ARXIV171109883.
   Liu C, 2014, IEEE T SYST MAN CYB, V45, P385.
   Lugo L., 2013, PORTRAIT JEWISH AM.
   Malle BF, 2016, ETHICS INF TECHNOL, V18, P243, DOI 10.1007/s10676-015-9367-8.
   Mannor S, 2004, J MACH LEARN RES, V5, P325.
   Marchetti A, 2019, J NEUROSCI PSYCHOL E, V12, P105, DOI 10.1037/npe0000105.
   May J., 2018, REGARD REASON MORAL.
   May J, 2019, BEHAV BRAIN SCI, V42, DOI 10.1017/S0140525X19000967.
   Millar J, 2017, ETHICS SETTINGS AUTO, P20.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Morgan MS, 1999, MODELS MEDIATORS PER, V52, P347.
   Nowak MA, 2000, SCIENCE, V289, P1773, DOI 10.1126/science.289.5485.1773.
   Nyholm S, 2016, ETHICAL THEORY MORAL, V19, P1275, DOI 10.1007/s10677-016-9745-2.
   Omohundro SM, 2008, FRONT ARTIF INTEL AP, V171, P483.
   Padoa-Schioppa C, 2011, ANNU REV NEUROSCI, V34, P333, DOI 10.1146/annurev-neuro-061010-113648.
   Picard R. W., 1997, AFFECTIVE COMPUTING.
   Rand DG, 2013, P NATL ACAD SCI USA, V110, P2581, DOI 10.1073/pnas.1214167110.
   Roff H., EXPECTED UTILI UNPUB.
   Rosen JB, 2015, PARKINSONISM RELAT D, V21, P1191, DOI 10.1016/j.parkreldis.2015.08.016.
   Russell S. J., 2016, ARTIFICIAL INTELLIGE.
   Russell S, 2015, AI MAG, V36, P105, DOI 10.1609/aimag.v36i4.2577.
   Sanfey AG, 2003, SCIENCE, V300, P1755, DOI 10.1126/science.1082976.
   Scheutz M., 2017, ROUTLEDGE HDB NEUROE.
   Schroeder T, 2010, MORAL PSYCHOL HDB.
   Shenhav A, 2010, NEURON, V67, P667, DOI 10.1016/j.neuron.2010.07.020.
   Shevlin H., SKILLING SOCIA UNPUB.
   Sinnott-Armstrong W, 2008, MIND LANG, V23, P90, DOI 10.1111/j.1468-0017.2007.00330.x.
   Soares N., 2015, WORKSH 29 AAAI C ART.
   Sripada C. S., 2006, INNATE MIND, V2, P280, DOI DOI 10.1093/ACPROF:OSO/9780195310139.003.0017.
   Sripada C. S., 2005, INNATENESS STRUCTURE, V2, P280.
   Sterelny K, 2017, BRIT J PHILOS SCI, V68, P981, DOI 10.1093/bjps/axv060.
   Sutton R.S., 1998, INTRO REINFORCEMENT, V135.
   Sutton Rich, 2019, BITTER LESSON.
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1.
   Taylor J, 2016, ALIGNMENT ADV MACHIN.
   THALER RH, 1988, J ECON PERSPECT, V2, P195, DOI 10.1257/jep.2.4.195.
   Tracer D, 2004, ARTEFACTUAL FIELD EX.
   Vallor S., 2015, PHILOS TECHNOLOGY, V28, P107, DOI DOI 10.1007/S13347-014-0156-9.
   Vamplew P, 2018, ETHICS INF TECHNOL, V20, P27, DOI 10.1007/s10676-017-9440-6.
   Van Moffaert K, 2014, J MACH LEARN RES, V15, P3483.
   Van Moffaert K, 2013, LECT NOTES COMPUT SC, V7811, P352, DOI 10.1007/978-3-642-37140-0\_28.
   Vanderelst D, 2018, COGN SYST RES, V48, P56, DOI 10.1016/j.cogsys.2017.04.002.
   Wallach W, 2008, MORAL MACHINES TEACH.
   Wallach W, 2019, P IEEE, V107, P505, DOI 10.1109/JPROC.2019.2899422.
   Wallach W, 2010, TOP COGN SCI, V2, P454, DOI 10.1111/j.1756-8765.2010.01095.x.
   Wei CL, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00182.
   Winfield A, 2019, UPDATED ROUND ETHICA.
   Winfield AF, 2019, P IEEE, V107, P509, DOI 10.1109/JPROC.2019.2900622.
   WOLF S, 1982, J PHILOS, V79, P419, DOI 10.2307/2026228.
   Woodward J., 2003, MAKING THINGS HAPPEN.
   Yang R., 2019, ADV NEURAL INFORM PR, P14610.
   Zhong SF, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013765.}},
Number-of-Cited-References = {{119}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{Minds Mach.}},
Doc-Delivery-Number = {{LH3DK}},
Unique-ID = {{ISI:000528667300001}},
DA = {{2020-06-17}},
}

@article{ ISI:000523679800004,
Author = {Tafani, Daniela},
Title = {{On Artificial Morality. Machine Decisions between Ethics and Right}},
Journal = {{RIVISTA DI FILOSOFIA}},
Year = {{2020}},
Volume = {{111}},
Number = {{1}},
Pages = {{81-103}},
Month = {{APR}},
Abstract = {{In the contemporary debate on artificial morality, the trolley problem
   has found a new field of application, in the ``ethics of crashes{''}
   with self-driving cars. The paper aims to show that the trolley dilemma
   is out of place, the context of automated traffic, not only with regard
   to the object of the dilemma (which human being should be sacrificed, in
   crashes with inevitable fatal consequences), but also with regard to the
   subject to whom it is up to decide. In States whose constitutional
   charters protect fundamental individual rights, laws have definite
   constraints on solving dilemmas regarding self-driving cars. The idea
   that crashes of self-driving cars raises extraordinary moral questions,
   rather than safety, transparency, caution and control issues, as any
   other machine, derives perhaps from the human inclination to consider
   anthropomorphic objects as agents, or even as moral agents. The
   development of autonomous machines can lead to believe that three
   crowdsourcing and subrogation operations, variously intertwined, are
   possible and allowed: of law with ethics, in the first place; of moral
   evaluation, secondly, with a computational model of aggregated social
   preferences and, finally, of human moral agency with the autonomous,
   unpredictable and opaque functioning of machines.}},
Publisher = {{SOC ED IL MULINO}},
Address = {{STRADA MAGGIORE 37, 40125 BOLOGNA, ITALY}},
Type = {{Article}},
Language = {{Italian}},
Affiliation = {{Tafani, D (Reprint Author), Scuola Normale Super Pisa, Filosofia, Pisa, Italy.
   Tafani, D (Reprint Author), Univ Bologna, Dipartimento Filosofia, Bologna, Italy.
   Tafani, Daniela, Scuola Normale Super Pisa, Filosofia, Pisa, Italy.
   Tafani, Daniela, Univ Bologna, Dipartimento Filosofia, Bologna, Italy.}},
DOI = {{10.1413/96338}},
ISSN = {{0035-6239}},
Keywords = {{Machine Ethics; Ethics of Crashes; Self-Driving Cars; Moral Machines;
   Artificial Morality; Trolley Problem}},
Keywords-Plus = {{TROLLEY; ALGORITHMS; CARS}},
Research-Areas = {{Philosophy}},
Web-of-Science-Categories  = {{Philosophy}},
Author-Email = {{daniela\_tafani@hotmail.com}},
Cited-References = {{Anderson M., 2011, MACHINE ETHICS, P1.
   {[}Anonymous], 2018, ETHICALLY ALIGNED DE, P194.
   {[}Anonymous], 2019, GABLER WIRTSCHAFTSLE.
   {[}Anonymous], 2019, ETHICS ROBOTS DESIGN, P112.
   {[}Anonymous], 2018, COMP DEC EUR REC MAC, P11.
   Awad E, 2018, NATURE, V563, P59, DOI 10.1038/s41586-018-0637-6.
   Baron-Cohen S, 2011, SCI EVIL EMPATHY ORI.
   Battaglia F, 2015, S F-SCIENZAEFILOSOFI, P193.
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654.
   Brhdadi D., 2019, ARTIFICIAL MORAL AGE.
   Bryson J., 2011, P 22 INT JOINT C ART, P1641.
   Chio P., 1970, SCRITTI MORALI, P88.
   Commission National Informatique \& Libertes (CNIL), 2017, COMM PERM HOMME GARD, P51.
   Contissa G., 2017, SISTEMI INTELLIGENTI, VIII, P601.
   Contissa G, 2017, ARTIF INTELL LAW, V25, P365, DOI 10.1007/s10506-017-9211-z.
   Damasio A.R., 1994, DESCARTES ERROR EMOT.
   dAquino Tommaso, 2014, LA SOMMA TEOLOGICA, V3.
   Davnall R, 2020, SCI ENG ETHICS, V26, P431, DOI 10.1007/s11948-019-00102-6.
   de Sio FS, 2017, ETHICAL THEORY MORAL, V20, P411, DOI 10.1007/s10677-017-9780-7.
   dell'Accademia Prussiana delle Scienze, 1900, KANTS GESAMMELTE SCH, VIV, P429.
   Dennett D.C., 2013, INTUITION PUMPS OTHE, P2.
   Edmonds D., 2013, WOULD YOU KILL FAT M.
   Ethik-Kommission, 2017, AUTOMATISIERTES VERN, P11.
   Etzioni A., 2017, J ETHICS, V21, P403, DOI DOI 10.1007/s10892-017-9252-2.
   European Commission's High-Level Expert Group on Artificial Intelligence, 2019, ETH GUID TRUSTW AI, P13.
   Fabris A., 2018, INCIRCOLO, VVI, P33.
   Fabris A, 2016, TEORIA, V36, P119.
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   Floridi L, 2018, MIND MACH, V28, P689, DOI 10.1007/s11023-018-9482-5.
   Foot P., 1967, OXFORD REV, V5, P5, DOI {[}DOI 10.1093/0199252866.003.0002, DOI 10.1002/9781444323528.CH41].
   Fossa F., 2017, ODRADEK STUDIES PHIL, VIII, P177.
   Fossa F., 2018, INCIRCOLO, VVI, P73.
   Fossa F, 2018, ETHICS INF TECHNOL, V20, P115, DOI 10.1007/s10676-018-9451-y.
   Gogoll J, 2017, SCI ENG ETHICS, V23, P681, DOI 10.1007/s11948-016-9806-x.
   Goodall NJ, 2016, APPL ARTIF INTELL, V30, P810, DOI 10.1080/08839514.2016.1229922.
   Greene J.D., 2016, COMPANION EXPT PHILO, P175.
   Greene J, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4147.
   Greene JD, 2014, ETHICS, V124, P695, DOI 10.1086/675875.
   Guerrerio G., 2014, UCCIDERESTI UOMO GRA.
   Gunkel D.J., 2012, MACHINE QUESTION ETH.
   Henry B., 2013, DAL GOLEM CYBORGS TR.
   Henry B., 2015, ROBOETHICS FILM.
   Hubner D, 2018, ETHICAL THEORY MORAL, V21, P685, DOI 10.1007/s10677-018-9910-x.
   Johansson V. R., 2016, DISARMING TROLLEY PR.
   Kamm F.M., 2016, TROLLEY PROBLEM MYST.
   Keeling G, 2020, SCI ENG ETHICS, V26, P293, DOI 10.1007/s11948-019-00096-1.
   Kersting W., 1989, HIST WORTERBUCH PHIL, V7, P433.
   Kroger F., 2016, AUTONOMOUS DRIVING T, P41, DOI DOI 10.1007/978-3-662-48847-8\_3.
   Lin Critico P., 2014, WIRED.
   Loh W., 2017, ROBOT ETHICS 2 0, P35.
   Macaluso F., 1995, ERRORE CARTESIO EMOZ.
   Macaluso F., 2018, STRANGE ORDER THINGS.
   Misselhorn C., 2018, GRUNDFRAGEN MA CHINE, P198.
   Moro P., 2015, FILOSOFIA DIRITTO NU, P525.
   Musial M., 2019, ENCHANTING ROBOTS IN, P63.
   NAGEL T, 1974, PHILOS REV, V83, P435, DOI 10.2307/2183914.
   Noothigattu R., 2017, VOTING BASED SYSTEM.
   NOWAKJUCHACZ E, 2003, {[}No title captured], P75.
   Nyholm S, 2018, PHILOS COMPASS, V13, DOI 10.1111/phc3.12507.
   Nyholm S, 2016, ETHICAL THEORY MORAL, V19, P1275, DOI 10.1007/s10677-016-9745-2.
   ONeil C., 2016, WEAPONS MATH DESTRUC.
   Operto V. F., 2018, INCIRCOLO, VVI, P89.
   Poulsen A., 2019, RESPONSES CRITIQUE A.
   SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038.
   SINGER E, 2018, {[}No title captured], P61.
   Sirgiovanni E., 2018, GIORNALE ITALIANO PS, P147.
   Stuart MT, 2018, ROUTL PHILOS COMPAN, P1.
   Sutfeld LR, 2017, FRONT BEHAV NEUROSCI, V11, DOI 10.3389/fnbeh.2017.00122.
   Tamburrini G, 2017, RIV FILOS, V108, P263, DOI 10.1413/86814.
   THOMSON JJ, 1976, MONIST, V59, P205.
   Vaccarezza M.S., 2018, ETICA RESPONSABILITA, P309.
   van Wynsberghe A, 2019, SCI ENG ETHICS, V25, P719, DOI 10.1007/s11948-018-0030-8.
   Verdicchio M, 2017, PHILOS STUD SER, V128, P179, DOI 10.1007/978-3-319-61043-6\_9.
   VERVERIS V, 2019, {[}No title captured], P193, DOI DOI 10.1145/3314183.3324965.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.
   Wee D., 10 WAYS AUTONOMOUS D.}},
Number-of-Cited-References = {{76}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{6}},
Usage-Count-Since-2013 = {{6}},
Journal-ISO = {{Riv. Filos.}},
Doc-Delivery-Number = {{LA0XL}},
Unique-ID = {{ISI:000523679800004}},
DA = {{2020-06-17}},
}

@article{ ISI:000525010500001,
Author = {Watts, Fraser},
Title = {{The evolution of religious cognition}},
Journal = {{ARCHIVE FOR THE PSYCHOLOGY OF RELIGION-ARCHIV FUR RELIGIONSPSYCHOLOGIE}},
Year = {{2020}},
Volume = {{42}},
Number = {{1, SI}},
Pages = {{89-100}},
Month = {{MAR}},
Abstract = {{Several accounts of the evolution of religion distinguish two phases: an
   earlier shamanic stage and a later doctrinal stage. Similarly, several
   theories of human cognition distinguish two cognitive modes: a
   phylogenetically older system that is largely intuitive and a later,
   more distinctively human system that is more rational and articulate.
   This article suggests that cognition in the earlier stage in the
   evolution of religion is largely at the level of intuition, whereas the
   cognition of doctrine or religion is more conceptual and rational. Early
   religious cognition is more embodied and is more likely to carry healing
   benefits. The evolutionary origins of religion in humans seem to depend
   on developments in the cognitive architecture. It is further suggested
   that the cognition of early religion shows less conceptual
   differentiation, is characteristically participatory rather than
   objectifying and is less individualistic. The development of religion in
   recent centuries appears to show some approximate recapitulation of the
   stages through which religion originally evolved.}},
Publisher = {{SAGE PUBLICATIONS LTD}},
Address = {{1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Watts, F (Reprint Author), Univ Lincoln, 19 Grantchester Rd, Lincoln CB3 9ED, England.
   Watts, Fraser, Univ Lincoln, 19 Grantchester Rd, Lincoln CB3 9ED, England.}},
DOI = {{10.1177/0084672420909479}},
Early Access Date = {{MAR 2020}},
Article-Number = {{0084672420909479}},
ISSN = {{0084-6724}},
EISSN = {{1573-6121}},
Keywords = {{Cognition; cultural psychology; embodiment; God concept; religion}},
Keywords-Plus = {{WILLIAM H. BEHARRELL; EPIPHANY PHILOSOPHERS; MUTUAL ENHANCEMENT; MARIUS
   DOROBANTU; MACHINE ETHICS; ROWAN WILLIAMS; MORAL ORTHOSES; LATE
   MODERNITY; FRASER WATTS; YORICK WILKS}},
Research-Areas = {{Psychology; Religion}},
Web-of-Science-Categories  = {{Psychology, Multidisciplinary; Religion}},
Author-Email = {{fraser.watts@cantab.net}},
Funding-Acknowledgement = {{Templeton Religion Trust {[}TRT 0153]}},
Funding-Text = {{The author(s) disclosed receipt of the following financial support for
   the research, authorship and/or publication of this article: This work
   was supported through a grant (No. TRT 0153) from the Templeton Religion
   Trust.}},
Cited-References = {{Asch S., 1958, PERSON PERCEPTION IN, P86.
   Barfield O., 1973, POETIC DICTION STUDY.
   Barnard P. J., 2016, COGNITIVE MODELS PAL, P46.
   Barnard P. J., 2019, SQUEEZING MINDS STON.
   Bellah Robert, 2011, RELIG HUMAN EVOLUTIO.
   Boivin MJ, 2011, SPIRITUAL HEALING SC, P128.
   Boyer Pascal, 2001, RELIG EXPLAINED HUMA.
   BROWN LB, 1965, J GENET PSYCHOL, V107, P33, DOI 10.1080/00221325.1965.10532760.
   Bucci W., 1997, PSYCHOANALYSIS COGNI.
   Clark A, 2008, SUPERSIZING MIND EMB.
   Damisch Hubert, 1994, ORIGIN PERSPECTIVE.
   Davy C., 1978, 3 CULTURE.
   Dawes GW, 2014, STUD RELIG-SCI RELIG, V43, P294, DOI 10.1177/0008429814526144.
   Donald Merlin, 1991, ORIGINS MODERN MIND.
   Dunbar R., 2014, HUMAN EVOLUTION PELI.
   Dunbar R, 2008, P BR ACAD, V154, P403, DOI DOI 10.1098/RSTB.2006.2001.
   Durkheim E., 2008, ELEMENTARY FORMS REL.
   EPSTEIN S, 1991, RELATIONAL SELF, P111.
   Goldman R., 1968, RELIG THINKING CHILD.
   Hill PC, 1999, J PERS, V67, P1015, DOI 10.1111/1467-6494.00081.
   Hood R. H., 2018, PSYCHOL RELIG EMPIRI.
   Jones J. W., 2019, LIVING RELIG EMBODIM.
   Kapogiannis D, 2009, P NATL ACAD SCI USA, V106, P4876, DOI 10.1073/pnas.0811717106.
   Lash N., 1996, PHYS PHILOS THEOLOGY, P203.
   Levy-Bruhl L., 2015, HOW NATIVES THINK.
   Marshall L., 1999, NYAE NYAE KUNG BELIE.
   McClenon J. C., 2002, WONDROUS HEALING SHA.
   McCLENON James, 2006, GOD SCI MEET BRAIN E, V1, P135.
   McGilchrist I., 2009, MASTER HIS EMISSARY.
   MITHEN S, 1996, {[}No title captured].
   Moriarty G. L., 2013, HEAD HEART PERSPECTI, P195.
   Norenzayan A, 2016, BEHAV BRAIN SCI, V39, DOI 10.1017/S0140525X14001356.
   Sarkar DK, 2012, J BIOL CHEM, V287, P16734, DOI 10.1074/jbc.M112.347583.
   Savage S. B., 2013, HEAD HEART PERSPECTI, P157.
   Schaefer A. E., 2015, RELIG AFFECTS ANIMAL.
   Tamminen K., 1994, INT J PSYCHOL RELIG, V4, P61, DOI DOI 10.1207/S15327582IJPR0402\_1.
   Taylor Charles, 1989, SOURCES SELF MAKING.
   Teske JA, 2013, ZYGON, V48, P759, DOI 10.1111/zygo.12038.
   Trotter W., 2020, INSTINCTS HERD PEACE.
   Turner L, 2020, ZYGON, V55, P207, DOI 10.1111/zygo.12580.
   Watts F., 2014, EVOLUTION RELIG COGN, P109.
   Watts F., 2013, HEAD HEART PERSPECTI, P125.
   Watts F., 2017, PSYCHOL RELIG SPIRIT.
   Watts F., 2014, COGNITIVE APPROACHES.
   WATTS F, 2002, {[}No title captured].
   Watts F, 2011, SPIRITUAL HEALING SC.
   Watts F., 1988, PSYCHOL RELIG KNOWIN.
   Watts F, 2013, ZYGON, V48, P745, DOI 10.1111/zygo.12026.
   Watts G, 2019, ZYGON, V54, P1022, DOI 10.1111/zygo.12554.
   Whitehouse Harvey, 2004, MODES RELIGIOSITY CO.
   Williams R, 2019, ZYGON, V54, P1036, DOI 10.1111/zygo.12561.
   Winkelman Michael, 2010, SUPERNATURAL NATURAL.
   Winnicott D.W., 1971, PLAYING REALITY.}},
Number-of-Cited-References = {{53}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Arch. Psychol. Relig.}},
Doc-Delivery-Number = {{LI0YM}},
Unique-ID = {{ISI:000525010500001}},
DA = {{2020-06-17}},
}

@article{ ISI:000512691600009,
Author = {Nath, Rajakishore and Sahu, Vineet},
Title = {{The problem of machine ethics in artificial intelligence}},
Journal = {{AI \& SOCIETY}},
Year = {{2020}},
Volume = {{35}},
Number = {{1}},
Pages = {{103-111}},
Month = {{MAR}},
Abstract = {{The advent of the intelligent robot has occupied a significant position
   in society over the past decades and has given rise to new issues in
   society. As we know, the primary aim of artificial intelligence or
   robotic research is not only to develop advanced programs to solve our
   problems but also to reproduce mental qualities in machines. The
   critical claim of artificial intelligence (AI) advocates is that there
   is no distinction between mind and machines and thus they argue that
   there are possibilities for machine ethics, just as human ethics. Unlike
   computer ethics, which has traditionally focused on ethical issues
   surrounding human use of machines, AI or machine ethics is concerned
   with the behaviour of machines towards human users and perhaps other
   machines as well, and the ethicality of these interactions. The ultimate
   goal of machine ethics, according to the AI scientists, is to create a
   machine that itself follows an ideal ethical principle or a set of
   principles; that is to say, it is guided by this principle or these
   principles in decisions it makes about possible courses of action it
   could take(a). Thus, machine ethics task of ensuring ethical behaviour
   of an artificial agent. Although, there are many philosophical issues
   related to artificial intelligence, but our attempt in this paper is to
   discuss, first, whether ethics is the sort of thing that can be
   computed. Second, if we are ascribing mind to machines, it gives rise to
   ethical issues regarding machines. And if we are not drawing the
   difference between mind and machines, we are not only redefining
   specifically human mind but also the society as a whole. Having a mind
   is, among other things, having the capacity to make voluntary decisions
   and actions. The notion of mind is central to our ethical thinking, and
   this is because the human mind is self-conscious, and this is a property
   that machines lack, as yet.}},
Publisher = {{SPRINGER}},
Address = {{ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Nath, R (Reprint Author), Indian Inst Technol, Dept Humanities \& Social Sci, Mumbai, Maharashtra, India.
   Nath, Rajakishore, Indian Inst Technol, Dept Humanities \& Social Sci, Mumbai, Maharashtra, India.
   Sahu, Vineet, IIT Kanpur, Dept Humanities \& Social Sci, Kanpur, Uttar Pradesh, India.}},
DOI = {{10.1007/s00146-017-0768-6}},
ISSN = {{0951-5666}},
EISSN = {{1435-5655}},
Keywords = {{Artificial intelligence; Artificial moral agent; Moral agency; Mind;
   Subjectivity}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{rajakishorenath@iitb.ac.in
   vineet@iitk.ac.in}},
Cited-References = {{Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Anderson M, 2007, AI MAG, V28, P15.
   Beavers AF, 2009, ASS PRACTICAL PROFES.
   Blakemore C, 1987, MINDWAVES THOUGHTS I.
   Chalmers D, 1996, CONSCIOUS MIND.
   DeBaets A. M., 2014, J EVOLUTION TECHNOLO, V24, P76.
   Gunkel D. J., 2012, MACH QUEST CRIT.
   Haugeland J., 1989, ARTIFICIAL INTELLIGE.
   Kant I, 1785, GROUNDING METAPHYSIC.
   LaChat MR, 1986, AI MAG, V7, P70, DOI DOI 10.1609/AIMAG.V7I2.540.
   Lycan WG, 1987, CONSCIOUSNESS.
   McCorduck P, 1979, MACHINES WHO THINKS.
   McGinn C, 1997, NATURE CONSCIOUSNESS.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Nagel T, 1998, NATURE CONSCIOUSNESS.
   Nath R, 2009, PHILOS ARTIFICIAL IN.
   Nath R, 2017, AI SOC, V32, P563, DOI 10.1007/s00146-016-0671-6.
   Searle J, 1990, P AM PHILOS ASS, V64, P21, DOI DOI 10.2307/3130074.
   Searle John, 1994, REDISCOVERY MIND.
   Searle JR, 1996, MINDS BRAINS SCI.
   Simon HA, 1987, ENCY ARTIFICIAL INTE, V1.
   Tanimoto Steven L, 1987, ELEMENTS ARTIFICIAL.
   Turing A, 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433.
   WINSTON PH, 1984, {[}No title captured].
   WITTGENSTEIN L, 1976, {[}No title captured].}},
Number-of-Cited-References = {{25}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{30}},
Usage-Count-Since-2013 = {{30}},
Journal-ISO = {{AI Soc.}},
Doc-Delivery-Number = {{KK4CH}},
Unique-ID = {{ISI:000512691600009}},
DA = {{2020-06-17}},
}

@article{ ISI:000516474800001,
Author = {Mabaso, Bongani Andy},
Title = {{Computationally rational agents can be moral agents}},
Journal = {{ETHICS AND INFORMATION TECHNOLOGY}},
Abstract = {{In this article, a concise argument for computational rationality as a
   basis for artificial moral agency is advanced. Some ethicists have long
   argued that rational agents can become artificial moral agents. However,
   most of their views have come from purely philosophical perspectives,
   thus making it difficult to transfer their arguments to a scientific and
   analytical frame of reference. The result has been a disintegrated
   approach to the conceptualisation and design of artificial moral agents.
   In this article, I make the argument for computational rationality as an
   integrative element that effectively combines the philosophical and
   computational aspects of artificial moral agency. This logically leads
   to a philosophically coherent and scientifically consistent model for
   building artificial moral agents. Besides providing a possible answer to
   the question of how to build artificial moral agents, this model also
   invites sound debate from multiple disciplines, which should help to
   advance the field of machine ethics forward.}},
Publisher = {{SPRINGER}},
Address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
Type = {{Article; Early Access}},
Language = {{English}},
Affiliation = {{Mabaso, BA (Reprint Author), Univ Pretoria, Pretoria, South Africa.
   Mabaso, Bongani Andy, Univ Pretoria, Pretoria, South Africa.}},
DOI = {{10.1007/s10676-020-09527-1}},
Early Access Date = {{FEB 2020}},
ISSN = {{1388-1957}},
EISSN = {{1572-8439}},
Keywords = {{Artificial moral agency; Computational rationality; Bounded-rationality;
   Machine ethics}},
Keywords-Plus = {{ARTIFICIAL-INTELLIGENCE; ETHICS; CONSCIOUSNESS}},
Research-Areas = {{Social Sciences - Other Topics; Information Science \& Library Science;
   Philosophy}},
Web-of-Science-Categories  = {{Ethics; Information Science \& Library Science; Philosophy}},
Author-Email = {{bamabaso@gmail.com}},
ORCID-Numbers = {{Mabaso, Bongani/0000-0003-2610-8303}},
Cited-References = {{Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4.
   Allen C, 2012, INTELL ROBOT AUTON, P55.
   Anderson M, 2007, AI MAG, V28, P15.
   Arnold T., 2017, WORKSH 31 AAAI C ART.
   Brewka G, 1996, KNOWL ENG REV, V11, P78, DOI DOI 10.1017/S0269888900007724.
   Churchland PS, 2014, BEHAVIOUR, V151, P283, DOI 10.1163/1568539X-00003144.
   Coeckelbergh M., 2014, PHILOS TECHNOLOGY, V27, P61, DOI {[}10.1007/s13347-013-0133-8, DOI 10.1007/S13347-013-0133-8].
   Conitzer V., 2017, 31 AAAI C ART INT.
   Daily M, 2017, COMPUTER, V50, P12, DOI 10.1109/MC.2017.39.
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   Franklin S, 2003, J CONSCIOUSNESS STUD, V10, P47.
   Franklin S, 2014, IEEE T AUTON MENT DE, V6, P19, DOI 10.1109/TAMD.2013.2277589.
   Genewein T, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00027.
   Gershman SJ, 2015, SCIENCE, V349, P273, DOI 10.1126/science.aac6076.
   Himma KE, 2009, ETHICS INF TECHNOL, V11, P19, DOI 10.1007/s10676-008-9167-5.
   Horvitz E., 1987, P 3 WORKSH UNC ART I, P429.
   Horvitz E. J., 1988, AAAI 88. Seventh National Conference on Artificial Intelligence, P111.
   Horvitz E. J., 1989, IJCAI-89 Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, P1121.
   Horvitz E. J, 1989, P COMP INT 89 ASS CO.
   Ikle Matthew, 2018, ARTIFICIAL GEN INTEL.
   Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101.
   Johnson DG, 2006, ETHICS INF TECHNOL, V9780521112, P168, DOI 10.1017/CBO9780511978036.012.
   Leviathan Y., 2017, GOOGLE AI BLOG GOOGL.
   Lewis RL, 2014, TOP COGN SCI, V6, P279, DOI 10.1111/tops.12086.
   Liao SM, 2010, J MORAL PHILOS, V7, P159, DOI 10.1163/174552409X12567397529106.
   Lin P, 2012, INTELL ROBOT AUTON, P1.
   Lucentini DF, 2015, PROCEDIA COMPUT SCI, V71, P56, DOI 10.1016/j.procs.2015.12.198.
   Marwala T, 2013, ARXIV13056037, P153.
   McCarthy J, 2006, AI MAG, V27, P12.
   MILLER FD, 1984, REV METAPHYS, V37, P499.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Parthemore J., 2014, INT J MACHINE CONSCI, V06, P141, DOI DOI 10.1142/S1793843014400162.
   Parthemore J., 2013, INT J MACHINE CONSCI, V5, P105.
   Rottschaefer WA, 2000, ZYGON, V35, P253, DOI 10.1111/0591-2385.00276.
   Russell SJ, 1994, J ARTIF INTELL RES, V2, P575.
   Sapaty Peter Simon, 2015, International Journal of Advanced Research in Artificial Intelligence, V4, P9.
   Scheutz M., 2017, ROUTLEDGE HDB NEUROE.
   Schlosser M, 2015, STANFORD ENCY PHILOS.
   SELTEN R, 1990, J INST THEOR ECON, V146, P649.
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270.
   Simon H.A., 1972, DECISION ORG, V1, P161.
   Simon HA, 1955, Q J ECON, V69, P99, DOI 10.2307/1884852.
   Sullins J. P., 2006, IRIE INT REV INFORM.
   Torrance S, 2013, AI SOC, V28, P399, DOI 10.1007/s00146-012-0422-2.
   Torrance S, 2008, AI SOC, V22, P495, DOI 10.1007/s00146-007-0091-8.
   Turing A, 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433.
   Wallach W, 2011, INT J MACHINE CONSCI, V3, P177, DOI DOI 10.1142/S1793843011000674.
   Wu Y. H., 2018, 32 AAAI C ART INT AA.
   Yu H., 2018, P 27 INT JOINT C ART, P5527, DOI DOI 10.24963/IJCAI.2018/779.
   Zilberstein S, 2013, METAREASONING THINKI, P27.}},
Number-of-Cited-References = {{50}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{5}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{Ethics Inf. Technol.}},
Doc-Delivery-Number = {{KP8IW}},
Unique-ID = {{ISI:000516474800001}},
DA = {{2020-06-17}},
}

@article{ ISI:000501642000006,
Author = {Misselhorn, Catrin},
Title = {{Artificial systems with moral capacities? A research design and its
   implementation in a geriatric care system}},
Journal = {{ARTIFICIAL INTELLIGENCE}},
Year = {{2020}},
Volume = {{278}},
Month = {{JAN}},
Abstract = {{The development of increasingly intelligent and autonomous technologies
   will eventually lead to these systems having to face morally problematic
   situations. This gave rise to the development of artificial morality, an
   emerging field in artificial intelligence which explores whether and how
   artificial systems can be furnished with moral capacities. This will
   have a deep impact on our lives. Yet, the methodological foundations of
   artificial morality are still sketchy and often far off from possible
   applications. One important area of application of artificial systems
   with moral capacities is geriatric care. The goal of this article is to
   afford the methodological foundations for artificial morality, i.e., for
   implementing moral capacities in artificial systems in general, and to
   discuss them with respect to an assistive system in geriatric care which
   is capable of moral learning. (C) 2019 Elsevier B.V. All rights
   reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Misselhorn, C (Reprint Author), Georg August Univ Gottingen, Philosoph Seminar, Humboldtallee 19 Eingang A, D-37073 Gottingen, Germany.
   Misselhorn, Catrin, Georg August Univ Gottingen, Philosoph Seminar, Humboldtallee 19 Eingang A, D-37073 Gottingen, Germany.}},
DOI = {{10.1016/j.artint.2019.103179}},
Article-Number = {{103179}},
ISSN = {{0004-3702}},
EISSN = {{1872-7921}},
Keywords = {{Artificial morality; Machine ethics; Artificial moral agents; Moral
   capacities; Functional morality; Moral implementation; Assistive systems
   in geriatric care; Elder care robots}},
Keywords-Plus = {{MULTIAGENT SYSTEM; ETHICS; ROBOTS}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{catrin.misselhorn@uni-goettingen.de}},
Cited-References = {{Alston W.P., 1968, NOUS, V2, P1.
   Anderson S., 2011, P AAAI WORKSH HUM RO.
   Anderson S., 2006, P 18 C INN APPL ART.
   Anderson S., 2008, P AAAI FALL 2008 S A.
   Arkin R., 2007, GITGVU0711 COLL COMP.
   Axelrod Robert, 1984, EVOLUTION COOPERATIO.
   Bajo J, 2008, FRONT ARTIF INTEL AP, V178, P875, DOI 10.3233/978-1-58603-891-5-875.
   Beauchamp TL, 1979, PRINCIPLES BIOMEDICA.
   BLOCK N, 1995, BEHAV BRAIN SCI, V18, P227, DOI 10.1017/S0140525X00038188.
   Bratman M.E., 2007, ESSAYS.
   Bratman Michael, 1999, FACES INTENTION SELE.
   Breazeal C, 2002, TRENDS COGN SCI, V6, P481, DOI 10.1016/S1364-6613(02)02016-8.
   Chisholm R., 1964, FREE WILL, P26.
   Coeckelbergh M., 2012, CAPABILITY APPROACH, P77.
   Dancy J., 2013, STANFORD ENCY PHILOS.
   Davidson D., 1980, ESSAYS ACTIONS EVENT.
   De Paz JF, 2015, ADV INTELL SYST, V333, P3, DOI 10.1007/978-3-319-13452-9\_1.
   DENNETT D, 1987, {[}No title captured].
   Dennett D. C., 1994, Logic, Methodology and Philosophy of Science IX. Proceedings of the Ninth International Congress, P679.
   Dominguez C. Zato, 2013, 16 INT C IST TURK JU, P327.
   Dretske F., 1995, EXPLAINING BEHAV REA.
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   Fong T., 2002, CMURITR229 ROB I.
   FRANKENA WK, 1966, J PHILOS, V63, P688, DOI 10.2307/2024163.
   Frankfurt H. G., 1971, J PHILOS, V68, P5, DOI DOI 10.2307/2024717.
   Froese T, 2010, CONNECT SCI, V22, P43, DOI 10.1080/09540090903197928.
   Horgan T, 2009, ETHICAL THEORY MORAL, V12, P25, DOI 10.1007/s10677-008-9142-6.
   Knobe Joshua, 2004, PHILOS MAG, V28, P37.
   Korsgaard Christine M., 1996, SOURCES NORMATIVITY.
   Levy N., 2014, CONSCIOUSNESS MORAL.
   Marr D., 1982, VISION COMPUTATIONAL.
   MCCARTHY J, 1969, {[}No title captured], V4, P463, DOI DOI 10.1016/B978-0-934613-03-3.50033-7.
   Misselhorn C., 2013, ROBOETHICS, P30.
   Misselhorn C, 2013, GEROPSYCH, V26, P121, DOI 10.1024/1662-9647/a000088.
   Misselhorn C, 2015, PHILOS STUD SER, V122, P3, DOI 10.1007/978-3-319-15515-9\_1.
   Nichols S., 2008, EXPT PHILOS.
   NUSSBAUM M, 1985, J PHILOS, V82, P516, DOI 10.2307/2026358.
   Nussbaum M, 1993, QUALITY LIFE.
   Nussbaum M., 2006, FRONTIERS JUSTICE DI.
   Nussbaum MC, 2001, ECON PHILOS, V17, P67, DOI 10.1017/S0266267101000153.
   Parra V, 2014, ADCAIJ-ADV DISTRIB C, V3, P10.
   Rawls John, 1993, POLITICAL LIBERALISM.
   Ross W. D., 1930, RIGHT GOOD.
   Shanahan M., 2009, STANFORD ENCY PHILOS.
   Stahl BC, 2004, MIND MACH, V14, P67.
   von der Pfordten D, 2012, ETHICAL THEORY MORAL, V15, P449, DOI 10.1007/s10677-011-9299-2.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.
   2006, {[}No title captured], P1.}},
Number-of-Cited-References = {{48}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{19}},
Usage-Count-Since-2013 = {{19}},
Journal-ISO = {{Artif. Intell.}},
Doc-Delivery-Number = {{JU4IT}},
Unique-ID = {{ISI:000501642000006}},
DA = {{2020-06-17}},
}

@article{ ISI:000498859500028,
Author = {Nieuwazny, Jagna and Masui, Fumito and Ptaszynski, Michal and Rzepka,
   Rafal and Nowakowski, Karol},
Title = {{How religion and morality correlate in age of society 5.0: Statistical
   analysis of emotional and moral associations with Buddhist religious
   terms appearing on Japanese blogs}},
Journal = {{COGNITIVE SYSTEMS RESEARCH}},
Year = {{2020}},
Volume = {{59}},
Pages = {{329-344}},
Month = {{JAN}},
Note = {{10th Annual International Conference on Biologically Inspired Cognitive
   Architectures (BICA), Redmond, WA, AUG 15-18, 2019}},
Abstract = {{In this paper we analyzed how much religious vocabulary, in particular
   Buddhist vocabulary taken from the largest online dictionary of Buddhist
   terms, is present in everyday social space of Japanese people,
   particularly, in Japanese blog entries appearing on a popular blog
   service (Ameba blogs). We interpreted the level of everyday usage of
   Buddhist terms as appearance of such terms in the consciousness of
   people. We further analyzed what emotional and moral associations such
   contents generate. In particular, we analyzed whether expressions
   containing Buddhist vocabulary are considered appropriate or not from a
   moral point of view, as well as the emotional response of Internet users
   to Buddhist terminology. As a result of analyzing the data, we found out
   that Buddhist terms were in fact not absent as a theme from Japanese
   blogs and generated a strong emotional response. However, while the
   general reaction to several expressions using Buddhist terms was as
   expected, there were sometimes surprising twists in terms of social
   consequences, major discrepancies between what is perceived as ethically
   correct behavior between the Buddhist doctrine and the reasoning of the
   general population, as well as a considerate number of terms which have
   lost their original meaning and instead became slang expressions. (C)
   2019 Elsevier B.V. All rights reserved.}},
Publisher = {{ELSEVIER}},
Address = {{RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS}},
Type = {{Article; Proceedings Paper}},
Language = {{English}},
Affiliation = {{Nieuwazny, J (Reprint Author), Kitami Inst Technol, Dept Comp Sci, Koencho 165, Kitami, Hokkaido 0908507, Japan.
   Nieuwazny, Jagna; Masui, Fumito; Ptaszynski, Michal; Nowakowski, Karol, Kitami Inst Technol, Dept Comp Sci, Koencho 165, Kitami, Hokkaido 0908507, Japan.
   Rzepka, Rafal, Hokkaido Univ, Fac Informat Sci \& Technol, Kita Ku, Kita 14,Nishi 9, Sapporo, Hokkaido 0600814, Japan.}},
DOI = {{10.1016/j.cogsys.2019.09.026}},
ISSN = {{1389-0417}},
Keywords = {{Buddhist terminology; Automated moral reasoning; Large-scale corpus;
   Machine ethics}},
Research-Areas = {{Computer Science; Neurosciences \& Neurology; Psychology}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Neurosciences; Psychology,
   Experimental}},
Author-Email = {{jagnajagna86@ialab.cs.kitami-it.ac.jp}},
ResearcherID-Numbers = {{Rzepka, Rafal/E-2215-2014}},
ORCID-Numbers = {{Rzepka, Rafal/0000-0002-8274-0875}},
Cited-References = {{Anderson M, 2017, AAAI 2016 WORKSH AI.
   Anderson M, 2011, MACHINE ETHICS, DOI {[}10.1017/CBO9780511978036, DOI 10.1017/CBO9780511978036].
   Anderson M, 2007, AI MAG, V28, P15.
   Anderson M, 2010, SCI AM, V303, P72, DOI 10.1038/scientificamerican1010-72.
   Ariffin Shamsul Arrieya, 2018, International Journal of Interactive Mobile Technologies, V12, P207, DOI 10.3991/ijim.v12i2.8014.
   Burns J. H, 1996, COLLECTED WORKS J BE, DOI {[}10.1093/actrade/9780198205166.book.1, DOI 10.1093/ACTRADE/9780198205166.BOOK.1].
   Danaylov N, 2018, TECHNOLOGY IS NOT WH.
   Geraci RM, 2006, THEOL SCI, V4, P229, DOI 10.1080/14746700600952993.
   GUTHRIE S, 1993, {[}No title captured].
   Hameroff S. R, 1998, SCI CONSCIOUSNESS 2.
   Husain A, 2017, SENTIENT MACHINE COM.
   Jakubicek . M., 2013, 7 INT CORP LING C CL, P125.
   Kant I, 1785, GRUNDLEGUNG METAPHYS.
   Komuda R., 2010, INT J COMPUTATIONAL, V1, P155.
   Komuda R, 2013, INT J COMPUTATIONAL, V4, P14.
   Kurzweil R., 2005, SINGULARITY IS NEAR.
   MacDorman KF, 2015, INTERACT STUD, V16, P141, DOI 10.1075/is.16.2.01mac.
   Maciejewski J, 2010, P INT WORKSH MOD SCI, P192.
   McGrath James F., 2011, RELIG SCI FICTION.
   McLaren B, 2001, ARTIF INTELL, V150, P145.
   Minsky M, 1986, SOC MIND.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811.
   Nakamura A, 1993, KANJO HYOGEN JITEN.
   Penrose R, 1996, SCI CONSCIOUSNESS 1.
   Picard R. W., 1997, AFFECTIVE COMPUTING.
   Ptaszynski M, 2012, P AISB IACAP WORLD C, P40.
   Reeves J. F, 1991, THESIS.
   Rzepka R., 2005, AAAI FALL S MACH ETH.
   Wallach W, 2006, MORAL MACHINES TEACH.}},
Number-of-Cited-References = {{30}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{9}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{Cogn. Syst. Res.}},
Doc-Delivery-Number = {{JQ3OW}},
Unique-ID = {{ISI:000498859500028}},
DA = {{2020-06-17}},
}

@article{ ISI:000496165000010,
Author = {Beharrell, William H.},
Title = {{TRANSFORMATION AND THE WAKING BODY: A RETURN TO TRUTH VIA OUR BODIES
   with Fraser Watts, ``Mutual Enhancement between Science and Religion: In
   the Footsteps of the Epiphany Philosophers{''}; William H. Beharrell,
   ``Transformation and the Waking Body: A Return to Truth via our
   Bodies{''}; Marius Dorobantu and Yorick Wilks, ``Moral Orthoses: A New
   Approach to Human and Machine Ethics{''}; Galen Watts, ``Religion,
   Science, and Disenchantment in Late Modernity{''}; and Rowan Williams,
   ``Epiphany Philosophers: Afterword.{''}}},
Journal = {{ZYGON}},
Year = {{2019}},
Volume = {{54}},
Number = {{4}},
Pages = {{984-1003}},
Month = {{DEC}},
Abstract = {{This article considers the kind of knowledge that is constituted through
   embodied sensory perception and makes the case for a form of knowledge
   that is embodied, relational, and potentially transformational. Such
   knowledge is encountered through our physiological senses and cultivated
   by reestablishing connections to our bodies. The discussion starts by
   exploring the literature on sensory perception and interoception and
   moves on to the role of human agency, which is implicit in the idea of
   top-down causation. It is argued that this process can be explained by a
   top-down predictive model within which a sense of greater interoceptive
   accuracy may be cultivated while reducing interoceptive perturbation.
   The roles of active and perceptual inference are discussed with regard
   to the regulatory opportunities that these types of attention yield. By
   being more interoceptively aware, through a practice of contemplation,
   it is argued, we open ourselves to an encounter with divine presence
   that is immanent in the world around us.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Beharrell, WH (Reprint Author), Natl Hlth Serv, Psychiat, Cambridge, England.
   Beharrell, William H., Natl Hlth Serv, Psychiat, Cambridge, England.}},
DOI = {{10.1111/zygo.12553}},
ISSN = {{0591-2385}},
EISSN = {{1467-9744}},
Keywords = {{contemplation; interoception; perception; sense}},
Research-Areas = {{Social Issues; Religion}},
Web-of-Science-Categories  = {{Social Issues; Religion}},
Author-Email = {{william.beharrell@cantab.net}},
Cited-References = {{BENNETT MR, 2003, {[}No title captured].
   CACIOPPO JT, 1993, J PERS SOC PSYCHOL, V65, P5.
   Carter Leslie, 2001, PAIN RES MANAG, V7, P21.
   Clark Stephen, 1998, GOD RELIG REALITY.
   Cook Christopher, 2011, PHILOKALIA INNER LIF.
   Critchley HD, 2017, CURR OPIN PSYCHOL, V17, P7, DOI 10.1016/j.copsyc.2017.04.020.
   Critchley HD, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00286.
   Edwards Todd M, 2010, Ment Health Fam Med, V7, P209.
   Farb N, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00763.
   Fleming Ursula, 1990, GRASPING NETTLE POSI.
   Jones J. W., 2019, LIVING RELIG EMBODIM.
   Kang Y, 2011, SOC COGN AFFECT NEUR, V6, P507, DOI 10.1093/scan/nsq077.
   McGilchrist I., 2009, MASTER HIS EMISSARY.
   Morgan Michael J., 1977, VISION TOUCH PHILOS.
   Nieuwenhuis M, 2014, J EXP PSYCHOL-APPL, V20, P199, DOI 10.1037/xap0000024.
   Peterson Scott R., 1998, WHY IS SOUND PIPE OR.
   Petzschner FH, 2017, BIOL PSYCHIAT, V82, P421, DOI 10.1016/j.biopsych.2017.05.012.
   Piekarski Michael, 2017, FRONTIERS PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02077.
   Ring K., 1997, J NEAR DEATH STUDIES, V16, P101.
   Schroeder Frederic M., 1992, FORM TRANSFORMATION.
   Sethi AK, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2011.00395.
   Sheldrake R., 2017, SCI SPIRITUAL PRACTI.
   Smith Barry, 2019, BBC RADIO.
   STEPPER S, 1993, J PERS SOC PSYCHOL, V64, P211, DOI 10.1037/0022-3514.64.2.211.
   STRACK F, 1988, J PERS SOC PSYCHOL, V54, P768, DOI 10.1037/0022-3514.54.5.768.
   Tallis Raymond, 2010, NEW ATLANTIS, V29, P3.
   Ward D, 2017, TOPOI-INT REV PHILOS, V36, P365, DOI 10.1007/s11245-017-9484-6.
   Watts F., 2013, HEAD HEART PERSPECTI, P125.
   Wells GL, 1980, BASIC APPL SOC PSYCH, V1, P219, DOI 10.1207/s15324834basp0103\_2.
   ZANNA MP, 1974, J PERS SOC PSYCHOL, V29, P703, DOI 10.1037/h0036651.
   Zweyer K, 2004, HUMOR, V17, P85, DOI 10.1515/humr.2004.009.}},
Number-of-Cited-References = {{31}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{Zygon}},
Doc-Delivery-Number = {{JM4CS}},
Unique-ID = {{ISI:000496165000010}},
DA = {{2020-06-17}},
}

@article{ ISI:000496165000011,
Author = {Dorobantu, Marius and Wilks, Yorick},
Title = {{MORAL ORTHOSES: A NEW APPROACH TO HUMAN AND MACHINE ETHICS with Fraser
   Watts, ``Mutual Enhancement between Science and Religion: In the
   Footsteps of the Epiphany Philosophers{''}; William H. Beharrell,
   ``Transformation and the Waking Body: A Return to Truth via Our
   Bodies{''}; Marius Dorobantu and Yorick Wilks, ``Moral Orthoses: A New
   Approach to Human and Machine Ethics{''}; Galen Watts, ``Religion,
   Science, and Disenchantment in Late Modernity{''}; and Rowan Williams,
   ``Epiphany Philosophers: Afterword.{''}}},
Journal = {{ZYGON}},
Year = {{2019}},
Volume = {{54}},
Number = {{4}},
Pages = {{1004-1021}},
Month = {{DEC}},
Abstract = {{Machines are increasingly involved in decisions with ethical
   implications, which require ethical explanations. Current machine
   learning algorithms are ethically inscrutable, but not in a way very
   different from human behavior. This article looks at the role of
   rationality and reasoning in traditional ethical thought and in
   artificial intelligence, emphasizing the need for some explainability of
   actions. It then explores Neil Lawrence's embodiment factor as an
   insightful way of looking at the differences between human and machine
   intelligence, connecting it to the theological understanding of
   embodiment, relationality, and personhood. Finally, it proposes the
   notion of artificial moral orthoses, which could provide ethical
   explanations for both artificial and human agents, as a more promising
   unifying approach to human and machine ethics.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Dorobantu, M (Reprint Author), Univ Strasbourg, Theol, Strasbourg, France.
   Dorobantu, Marius, Univ Strasbourg, Theol, Strasbourg, France.
   Wilks, Yorick, Univ Sheffield, Artificial Intelligence, Oxford, England.}},
DOI = {{10.1111/zygo.12560}},
ISSN = {{0591-2385}},
EISSN = {{1467-9744}},
Keywords = {{artificial companions; artificial intelligence; embodiment; ethics;
   explainable AI; David Hume; Neil Lawrence; machine learning;
   relationality; theology}},
Research-Areas = {{Social Issues; Religion}},
Web-of-Science-Categories  = {{Social Issues; Religion}},
Author-Email = {{marius.dorobantu@gmail.com
   ywilks@ihmc.us}},
ORCID-Numbers = {{Dorobantu, Marius/0000-0002-3680-134X}},
Cited-References = {{Akoudas Konstantine, 2005, AAAI FALL S MACH ETH, P17.
   Ananthanarayanan R, 2009, PROCEEDINGS OF THE CONFERENCE ON HIGH PERFORMANCE COMPUTING NETWORKING, STORAGE AND ANALYSIS.
   Anderson M, 2010, SCI AM, V303, P72, DOI 10.1038/scientificamerican1010-72.
   Asimov I., 1950, I ROBOT.
   Awad E, 2018, NATURE, V563, P59, DOI 10.1038/s41586-018-0637-6.
   Bostrom N, 2014, CAMBRIDGE HANDBOOK OF ARTIFICIAL INTELLIGENCE, P316.
   Charniak E, 1996, STAT LANGUAGE LEARNI.
   Clocksin William F., 2002, ARTIFICIAL INTELLIGE.
   Dennett D.C., 1971, J PHILOS, V68, P87, DOI DOI 10.2307/2025382.
   Dorobantu Marius, 2019, ESSSAT NEWS REV, V29, P4.
   Eubanks V., 2018, AUTOMATING INEQUALIT.
   FOOT P, 2002, {[}No title captured].
   Ford KM, 2015, AI MAG, V36, P5, DOI 10.1609/aimag.v36i4.2629.
   Gergen K. G., 1991, SATURATED SELF DILEM.
   Gide Andre, 1914, CAVES VATICAN.
   Gray J., 2002, STRAW DOGS.
   Haidt J., 2006, HAPPINESS HYPOTHESIS.
   Herzfeld Noreen, 2005, CREATIVE CREATURES V, P45.
   Hume D, 2007, TREATISE HUMAN NATUR.
   Hume D, 1751, ENQUIRY PRINCIPLES M.
   Jaynes Julian, 1976, ORIGIN CONSCIOUSNESS.
   Kahneman D., 2011, THINKING FAST SLOW.
   Lawrence Neil, 2017, LIVING TOGETHER MIND.
   Leibniz Gottfried Wilhelm, 1988, LEIBNIZ POLITICAL WR, P64.
   Levy D., 2007, LOVE SEX ROBOTS.
   MacIntyre A., 1985, AFTER VIRTUE.
   Marsella S, 2010, BLUEPRINT AFFECTIVE, P21.
   McDermott Drew, 2008, P N AM C COMP PHIL N.
   McFadyen A., 1990, CALL PERSONHOOD CHRI.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Mueller ST, 2019, EXPLANATION HUMAN AI, P95.
   Parisi Domenico, 2007, ARTIFICIAL CONSCIOUS, P191.
   Pearl J, 2018, BOOK WHY NEW SCI CAU.
   Shults F. L., 2003, REFORMING THEOLOGICA.
   Vincent J, 2019, THE VERGE.
   WALDROP MM, 1987, AI MAG, V8, P28.
   Wason P., 1972, PSYCHOL REASONING ST.
   Wilks Yorick, 2010, ARTIFICIAL COMPANION.
   Wilks Yorick, 1984, MINDS MACHINES EVOLU, P105.
   Wilks Yorick, 1990, LAW COMPUTERS ARTIFI.
   Wilks Yorick, 1973, P 3 INT JOINT C ART, P270.
   Yudkowsky Eliezer, 2016, AI ALIGNMENT PROBLEM.
   Zittrain Johnathan, 2019, NEW YORKER.}},
Number-of-Cited-References = {{43}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{2}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{Zygon}},
Doc-Delivery-Number = {{JM4CS}},
Unique-ID = {{ISI:000496165000011}},
DA = {{2020-06-17}},
}

@article{ ISI:000496165000009,
Author = {Watts, Fraser},
Title = {{MUTUAL ENHANCEMENT BETWEEN SCIENCE AND RELIGION: IN THE FOOTSTEPS OF THE
   EPIPHANY PHILOSOPHERS with Fraser Watts, ``Mutual Enhancement between
   Science and Religion: In the Footsteps of the Epiphany Philosophers{''};
   William H. Beharrell, ``Transformation and the Waking Body: A Return to
   Truth via our Bodies{''}; Marius Dorobantu and Yorick Wilks, ``Moral
   Orthoses: A New Approach to Human and Machine Ethics{''}; Galen Watts,
   ``Religion, Science, and Disenchantment in Late Modernity{''}; and Rowan
   Williams, ``Epiphany Philosophers: Afterword.{''}}},
Journal = {{ZYGON}},
Year = {{2019}},
Volume = {{54}},
Number = {{4}},
Pages = {{965-983}},
Month = {{DEC}},
Abstract = {{This article describes some key features of the distinctive approach to
   issues in science and religion of the Epiphany Philosophers (EPs), and
   introduces a set of articles from a recent meeting. The objective of the
   EPs is not merely to establish harmonious coexistence between science
   and religion. Rather, they are dissatisfied with both, and have a
   reformist agenda. They see science as unduly constrained by arbitrary
   metaphysical assumptions, predominantly of an atheist kind, and wish to
   see it liberated from such constraints. They are also interested in the
   potential contribution of contemplative enquiry to scientific research.
   They see no reason why science should not engage with the transcendent,
   but they do not support any simplistic argument from scientific research
   to religious belief. They wish to see an approach to religion that is
   rooted more firmly in the contemplative path.}},
Publisher = {{WILEY}},
Address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Watts, F (Reprint Author), Univ Lincoln, Psychol \& Relig, Lincoln, England.
   Watts, F (Reprint Author), Int Soc Sci \& Relig, Cambridge, England.
   Watts, Fraser, Univ Cambridge, Theol \& Sci, Cambridge, England.
   Watts, Fraser, Univ Lincoln, Psychol \& Relig, Lincoln, England.
   Watts, Fraser, Int Soc Sci \& Relig, Cambridge, England.}},
DOI = {{10.1111/zygo.12558}},
ISSN = {{0591-2385}},
EISSN = {{1467-9744}},
Keywords = {{contemplation; metaphysics; religion; science; transcendence}},
Research-Areas = {{Social Issues; Religion}},
Web-of-Science-Categories  = {{Social Issues; Religion}},
Author-Email = {{fraser.watts@cantab.net}},
Cited-References = {{Barbour Ian G., 1974, MYTHS MODELS PARADIG.
   Barbour IG., 1966, ISSUES SCI RELIG.
   Bortoft Henri, 1996, WHOLENESS NATURE GOE.
   Bowler Peter, 2001, RECONCILING SCI RELI.
   Braithwaite Richard B., 1954, EPIPHANY PHILOS C RE.
   BROOKE JH, 1991, {[}No title captured].
   Burtt Edwin A., 1952, METAPHYSICAL FDN MOD.
   Clarke Chris, 2005, WAYS KNOWING SCI MYS.
   Clarke Isabel, 2008, MADNESS MYSTERY SURV.
   Coles Alasdair, NEUROLOGY RELIG.
   DAVIES P, 1990, {[}No title captured].
   Davy C., 1978, 3 CULTURE.
   Dein Simon, 2019, DUNBARS NUMBER.
   Depew David J, RETHINKING BIOL PUBL.
   Emmet Dorothy, 1979, MORAL PRISM.
   Eysenck HJ, 1993, EXPLAINING UNEXPLAIN.
   Force James E., 2002, W WHISTON HONEST NEW.
   Gilbert P, 2009, IMAGERY THREATENED S, P206.
   Gould SJ, 1999, ROCK AGES SCI RELIG.
   Harre R., 1972, PHILOS SCI.
   Hay D., 1982, EXPLORING INNER SPAC.
   Hesse Mary, 1963, MODELS ANALOGIES SCI.
   Hodgson Peter, 2005, THEOLOGY MODERN PHYS.
   James William, 2012, VARIETIES RELIG EXPE.
   Lash Nicholas, 1988, PHYS PHILOS THEOLOGY.
   MASTERMAN M, 2005, {[}No title captured].
   Masterman Margaret, 1954, EPIPHANY PHILOS.
   Masterman Margaret, 1978, ETERNAL LOGOS THINKI.
   Masterman Margaret, 1967, THEORIA TO THEORY, V1, P232.
   McLeish Tom., 2014, FAITH WISDOM SCI.
   Morris S. Conway, 2015, RUNES EVOLUTION UNIV.
   Murphy Nancy, 1990, THEOLOGY AGE SCI REA.
   Nagel T., 1986, VIEW NOWHERE.
   Nowak M. A., 2013, EVOLUTION GAMES GOD.
   PANNENBERG W, 1993, {[}No title captured].
   Polanyi M., 1958, PERSONAL KNOWLEDGE P.
   Polkinghorne John, 2007, QUANTUM PHYS THEOLOG.
   Polkinghorne John, 1991, REASON REALITY.
   Polkinghorne John, 1996, SCI THEOLOGIANS COMP.
   Rahner Karl, 1982, THEOLOGICAL INVESTIG.
   Rahner Karl, 1997, FDN CHRISTIAN FAITH.
   Ruse M., 2017, ON PURPOSE.
   Ruse Michael, 2000, CAN DARWINIAN BE CHR.
   SHELDRAKE R, 2003, {[}No title captured].
   Sheldrake R., 2017, SCI SPIRITUAL PRACTI.
   Sheldrake Rupert, 2019, WAYS GO WHY THEY WOR.
   Sheldrake Rupert, 2011, DOGS KNOW THEIR OWNE.
   Taylor Charles, 1989, SOURCES SELF MAKING.
   Tipler Frank J., 1995, PHYS IMMORTALITY MOD.
   Watts F., 2013, HEAD HEART PERSPECTI.
   Watts F., 2017, PSYCHOL RELIG SPIRIT.
   Watts F., 1988, PSYCHOL RELIG KNOWIN.
   WATTS FN, 1980, BRIT J MED PSYCHOL, V53, P95, DOI 10.1111/j.2044-8341.1980.tb01424.x.
   Watts F, 2013, ZYGON, V48, P745, DOI 10.1111/zygo.12026.
   Watts F, 2011, J CONSCIOUSNESS STUD, V18, P203.
   Watts Fraser, 2016, 40 YEARS SCI RELIG L.
   WESTPHAL J, 1987, {[}No title captured].
   Wilks Yorick, 2019, ARTIFICIAL INTELLIGE.
   Williams Harry A., 1965, TRUE WILDERNESS.
   Wolpert L, 2006, 6 IMPOSSIBLE THINGS.}},
Number-of-Cited-References = {{60}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Zygon}},
Doc-Delivery-Number = {{JM4CS}},
Unique-ID = {{ISI:000496165000009}},
DA = {{2020-06-17}},
}

@article{ ISI:000521119500009,
Author = {Maouche, Seraya},
Title = {{Google AI: Opportunities, Risks, and Ethical Challenges}},
Journal = {{CONTEMPORARY FRENCH AND FRANCOPHONE STUDIES}},
Year = {{2019}},
Volume = {{23}},
Number = {{4, SI}},
Pages = {{447-455}},
Month = {{AUG 8}},
Abstract = {{Emerging technologies (ET) are novel and relatively fast-growing
   technologies that can have massive socio-economic impact and bring new
   ethical and regulatory challenges. Although they cannot be considered as
   new technologies, artificial intelligence (AI) and related data driven
   technologies are examples of ET. AI is advancing at a rapid pace, in
   both public and private sectors, and being more widely deployed in
   different domains, including healthcare and education. In today's
   digital age, our societies are facing rapid and massive technological
   transformations. It is important to ensure that the behavior of AI
   systems is beneficial to humanity. Policymakers and the research
   community need to identify the greatest barriers to AI adoption and
   related risks. In recent years, Google's plans and visions to use ET
   gained serious and intense criticism. This situation pushed Google in
   March 2019 to announce an AI ethics panel which is supposed to offer
   guidance on ethical issues relating to AI, machine learning, and related
   technologies. This AI ethics panel was shut down just days after it was
   launched. The episode illustrates how ethical debates relating to ET are
   often characterized by ambiguity, dishonesty, and demagoguery. In this
   paper, I discuss the ethics of ET, focusing on Google and its AI
   platform.}},
Publisher = {{ROUTLEDGE JOURNALS, TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Maouche, S (Reprint Author), TBi Sci, Cork, Ireland.
   Maouche, Seraya, TBi Sci, Cork, Ireland.
   Maouche, Seraya, Eth \& Integr, Paris, France.}},
DOI = {{10.1080/17409292.2019.1705012}},
ISSN = {{1740-9292}},
EISSN = {{1740-9306}},
Keywords = {{Emerging technologies; ethics of technology; machine ethics; artificial
   intelligence; Google AI; technology adoption}},
Research-Areas = {{Literature}},
Web-of-Science-Categories  = {{Literature, Romance}},
Cited-References = {{Baum R.J., 1980, ETHICS ENG CURRICULA, VVII.
   Bostrom N, 2014, CAMBRIDGE HANDBOOK OF ARTIFICIAL INTELLIGENCE, P316.
   Brey Philip A. E, 2017, METHODS ETHICS TECHN, P175.
   Butler D, 2005, NATURE, V433, P446, DOI {[}10.1038/433446a, 10.1038/433446b].
   Corvol Pierre, 2019, ARTIFICIAL INTELLIGE.
   de Sio FS, 2016, EMERG TECH ETH INT A, P1.
   Halaweh M., 2013, J TECHNOLOGY MANAGEM, V8, P108, DOI DOI 10.4067/S0718-27242013000400010.
   Hourdeaux Jerome, 2019, MEDIAPART       0102.
   Lecher Colin, 2019, VERGE           0401.
   Lin P., 2017, ROBOT ETHICS 2 0 AUT.
   Martin K, 2019, J BUS ETHICS, V160, P307, DOI 10.1007/s10551-019-04213-9.
   Mittelstadt BD, 2016, BIG DATA SOC, V3, P1, DOI 10.1177/2053951716679679.
   MOOR JH, 1985, METAPHILOSOPHY, V16, P266, DOI 10.1111/j.1467-9973.1985.tb00173.x.
   Rotolo D, 2015, RES POLICY, V44, P1827, DOI 10.1016/j.respol.2015.06.006.
   Sager Harvey, 1995, IMPACT EMERGING TECH, P49.
   Stone Peter, 2016, ONE 100 YEAR STUDY A.}},
Number-of-Cited-References = {{16}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{Contemp. Fr. Francoph. Stud.}},
Doc-Delivery-Number = {{KW4EW}},
Unique-ID = {{ISI:000521119500009}},
DA = {{2020-06-17}},
}

@article{ ISI:000471357100014,
Author = {Indurkhya, Bipin},
Title = {{Is morality the last frontier for machines?}},
Journal = {{NEW IDEAS IN PSYCHOLOGY}},
Year = {{2019}},
Volume = {{54}},
Pages = {{107-111}},
Month = {{AUG}},
Abstract = {{This paper examines some ethical and cognitive aspects of machines
   making moral decisions in difficult situations. We compare the
   situations when humans have to make tough moral choices with those in
   which machines make such decisions. We argue that in situations where
   machines make tough moral choices, it is important to produce
   justification for those decisions that are psychologically compelling
   and acceptable by people.}},
Publisher = {{PERGAMON-ELSEVIER SCIENCE LTD}},
Address = {{THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Indurkhya, B (Reprint Author), Jagiellonian Univ, Inst Philosophy, Krakow, Poland.
   Indurkhya, Bipin, Jagiellonian Univ, Inst Philosophy, Krakow, Poland.}},
DOI = {{10.1016/j.newideapsych.2018.12.001}},
ISSN = {{0732-118X}},
EISSN = {{1873-3522}},
Keywords = {{Machine ethics; Machine morality; Autonomous decision making}},
Keywords-Plus = {{DECISION-MAKING; TRIAGE; ACTUARIAL; MEDICINE}},
Research-Areas = {{Psychology}},
Web-of-Science-Categories  = {{Psychology, Multidisciplinary; Psychology, Experimental}},
Author-Email = {{bipin.indurkhya@uj.edu.pl}},
Cited-References = {{Aha D., 2017, IJCAI 97 WORKSH EXPL.
   Ariely D, 2009, PREDICTABLY IRRATION.
   Arkin RC, 2012, P IEEE, V100, P571, DOI 10.1109/JPROC.2011.2173265.
   Bauman CW, 2014, SOC PERSONAL PSYCHOL, V8, P536, DOI 10.1111/spc3.12131.
   Ben-Ary G, 2016, COGN SCI TECHNOL, P307, DOI 10.1007/978-981-10-0321-9\_15.
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654.
   Brogan J., 2016, SHOULD SELF DRIVING.
   Browner W. S, 2006, HOSP MED, P43.
   Bruers S, 2014, PHILOSOPHIA, V42, P251, DOI 10.1007/s11406-013-9507-5.
   Bryson J., 2016, P AAAI SPRING S ETH, P202.
   Bryson JJ, 2017, ARTIF INTELL LAW, V25, P273, DOI 10.1007/s10506-017-9214-9.
   Christ M, 2010, DTSCH ARZTEBL INT, V107, P892, DOI 10.3238/arztebl.2010.0892.
   DAWES RM, 1989, SCIENCE, V243, P1668, DOI 10.1126/science.2648573.
   Di Nucci E, 2013, PHILOS PSYCHOL, V26, P662, DOI 10.1080/09515089.2012.674664.
   GLADWELL M, 2005, {[}No title captured].
   Gracheva A, 2016, BBC NEWS.
   Gunning D., 2016, EXPLAINABLE ARTIFICI.
   Hamilton P., 2009, GOOGLE BOMBING MANIP.
   Hunter D., 1998, ADV ANALOGY RES, P345.
   Indurkhya B., 2016, NORMATIVE MIND, P35.
   Indurkhya B., 2016, AAAI SPRING S SERIES, P226.
   Iserson KV, 2007, ANN EMERG MED, V49, P275, DOI 10.1016/j.annemergmed.2006.05.019.
   Krauss DA, 2001, PSYCHOL PUBLIC POL L, V7, P267, DOI 10.1037//1076-8971.7.2.267.
   Kuang K., 2017, NY TIMES MAGAZINE.
   Levy D., 2007, LOVE SEX ROBOTS EVOL.
   Lin P, 2012, INTELL ROBOT AUTON, P3.
   Linhares A, 2014, INFORM SCIENCES, V259, P36, DOI 10.1016/j.ins.2013.08.006.
   Litwack TR, 2001, PSYCHOL PUBLIC POL L, V7, P409, DOI 10.1037//1076-8971.7.2.409.
   Mann TE, 2006, RED AND BLUE NATION, VOL 1: CHARACTERISTICS AND CAUSES OF AMERICA'S POLARIZED POLITICS, P263.
   Martindale C, 1990, CLOCKWORK MUSE PREDI.
   Morton L., 1960, COMMAND DECISIONS OF, P493.
   Moskop JC, 2007, ANN EMERG MED, V49, P282, DOI 10.1016/j.annemergmed.2006.07.012.
   Navarrete CD, 2012, EMOTION, V12, P364, DOI 10.1037/a0025561.
   Ni Y., 2011, 4 INT WORKSH MACH LE.
   Olah C., 2017, DISTILL, DOI {[}10.23915/distill.00007, DOI 10.23915/DISTILL.00007].
   Pandey A. K., 2017, P WORKSH PRIV SENS R.
   Peng H, 2016, INT J SOC ROBOT, V8, P649, DOI 10.1007/s12369-016-0355-x.
   Robertson-Steel I, 2006, EMERG MED J, V23, P154, DOI 10.1136/emj.2005.030270.
   Sample I., 2017, GUARDIAN.
   Schwartzman M, 2011, SEE YOURSELF SENSING.
   Schwiep J, 2017, STATE EXPLAINABLE AI.
   Searle J., 2011, WALL STREET J.
   SHORTLIFFE EH, 1976, {[}No title captured].
   Starr SB, 2014, STANFORD LAW REV, V66, P803.
   Ulug F, 1986, THESIS.
   Vickery D. M., 1973, JACEP, V2, P183.
   Wall M., 2016, WOULD YOU BULLY DRIV.
   Warwick K., 2003, Ethics and Information Technology, V5, P131, DOI 10.1023/B:ETIN.0000006870.65865.cf.
   Warwick K, 2014, NANOETHICS, V8, P263, DOI 10.1007/s11569-014-0212-z.
   Warwick K, 2010, ETHICS INF TECHNOL, V12, P223, DOI 10.1007/s10676-010-9218-6.}},
Number-of-Cited-References = {{50}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{11}},
Journal-ISO = {{New Ideas Psychol.}},
Doc-Delivery-Number = {{ID0ES}},
Unique-ID = {{ISI:000471357100014}},
DA = {{2020-06-17}},
}

@article{ ISI:000476114100001,
Author = {Headleand, Christopher James and Teahan, William J. and ap Cenydd, Llyr},
Title = {{Sexbots: a case for artificial ethical agents}},
Journal = {{CONNECTION SCIENCE}},
Year = {{2020}},
Volume = {{32}},
Number = {{2}},
Pages = {{204-221}},
Month = {{APR 2}},
Abstract = {{Recent years have seen significant developments in Artificial
   Intelligence and we are now beginning to see some applications applied
   to sexual technologies. This has led to certain individuals and groups
   calling for a ban on the development of artificial sexual companions or
   ``sexbots{''}. This is largely due to fears that commercialising sex in
   this way could could re-enforce existing gender inequalities, and sexual
   objectification. We argue that one possible risk mitigation strategy
   could be to develop ethical safeguards into sexual robots. In this paper
   we explore the problem of implementing artificial ethical agents through
   a review of the relevant literature. We begin by exploring the
   motivation to the problem, and the science fiction that has inspired it.
   Following this, the practical, and philosophical implementation
   challenges are discussed before providing an overview of the current
   state of the art. The paper concludes by introducing the grand
   challenges of the field.}},
Publisher = {{TAYLOR \& FRANCIS LTD}},
Address = {{2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Headleand, CJ (Reprint Author), Univ Lincoln, Sch Comp Sci, Lincoln LN6 7TS, England.
   Headleand, Christopher James, Univ Lincoln, Sch Comp Sci, Lincoln LN6 7TS, England.
   Teahan, William J.; ap Cenydd, Llyr, Bangor Univ, Sch Comp Sci, Bangor, Gwynedd, Wales.}},
DOI = {{10.1080/09540091.2019.1640185}},
Early Access Date = {{JUL 2019}},
ISSN = {{0954-0091}},
EISSN = {{1360-0494}},
Keywords = {{Sexbots; artificial sexuality; artificial ethical agent; AEA; moral
   agency}},
Keywords-Plus = {{MORAL RESPONSIBILITY; MACHINE ETHICS; INFORMATION; ROBOTICS; LAWS;
   COMPUTERS; DESIGN; ASIMOV}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods}},
Author-Email = {{cheadleand@lincoln.ac.uk}},
Cited-References = {{Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4.
   Anderson M, 2006, P 18 C INN APPL ART, V2, P1759.
   Anderson M, 2007, AI MAG, V28, P15.
   Anderson M, 2007, MIND MACH, V17, P1, DOI 10.1007/s11023-007-9053-7.
   Anderson M, 2006, IEEE INTELL SYST, V21, P56, DOI 10.1109/MIS.2006.64.
   Anderson S. L., 2011, UNACCEPTABILITY ASIM.
   Arkina R. C., 2007, GOVERNING LETHAL BEH.
   Arkina R. C., 2009, GOVERNING LETHAL BEH.
   Ashley K. D., 1995, Case-Based Reasoning Research and Development. First International Conference, ICCBR-95. Proceedings, P133.
   Ashley K. D., 1994, EUR WORKSH ADV CAS B, P180.
   Asimov Isaac, 1942, ASTOUNDING SCI FICTI, P94.
   Bar-Cohen Y., 2009, COMING ROBOT REVOLUT.
   Beavers A. F., 2009, ANN M ASS PRACT PROF, P5.
   Beavers AF, 2012, INTELL ROBOT AUTON, P333.
   Bivins T. H., 2006, ETHICS PUBLIC RELATI, P19, DOI DOI 10.4135/9781452204208.N2.
   Bostan B., 2010, P GAMEON ASIA.
   Bostrom N, 2014, CAMBRIDGE HANDBOOK OF ARTIFICIAL INTELLIGENCE, P316.
   Braitenberg V, 1986, VEHICLES EXPT SYNTHE.
   BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032.
   Capek K., 2004, RUR ROSSUM S UNIVERS.
   CHURCH RM, 1959, J COMP PHYSIOL PSYCH, V52, P132, DOI 10.1037/h0043531.
   CLARKE R, 1994, COMPUTER, V27, P57, DOI 10.1109/2.248881.
   CLARKE R, 1993, COMPUTER, V26, P53, DOI 10.1109/2.247652.
   Clement Grace, 2013, J ANIMAL ETHICS, V3, P1, DOI DOI 10.5406/janimalethics.3.1.0001.
   Coeckelbergh M, 2013, ETHICS INF TECHNOL, V15, P87, DOI 10.1007/s10676-013-9313-6.
   Coeckelbergh M, 2009, AI SOC, V24, P181, DOI 10.1007/s00146-009-0208-3.
   Coeckelbergh M, 2010, ETHICS INF TECHNOL, V12, P235, DOI 10.1007/s10676-010-9221-y.
   Coyne J. A., 2012, CHRON HIGHER EDUC, P18.
   De Sevin E., 2005, MOTIVATIONAL EMOTION.
   de Waal FBM, 2007, SCI AM MIND, V18, P28, DOI DOI 10.1038/scientificamericanmind1207-28.
   de Waal F, 2006, NEW SCI, V192, P60, DOI 10.1016/S0262-4079(06)60737-9.
   Douglas-Hamilton I, 2006, APPL ANIM BEHAV SCI, V100, P87, DOI 10.1016/j.applanim.2006.04.014.
   Flack JC, 2000, J CONSCIOUSNESS STUD, V7, P1.
   Floridi L., 2001, Ethics and Information Technology, V3, P55, DOI 10.1023/A:1011440125207.
   Goldsmith A. L., 1981, GOLEM REMEMBERED 190.
   Gordon-Spears D. F., 2002, FORMAL APPROACHES AG, P257.
   Grint K, 2013, MACHINE WORK TECHNOL.
   Guarini M., 2005, MACHINE ETHICS.
   Hanson FA, 2009, ETHICS INF TECHNOL, V11, P91, DOI 10.1007/s10676-009-9184-z.
   Headleand C. J., 2016, 9 PHIL COMP AISB S S.
   Headleand C. J., 2016, THESIS.
   Headleand CJ, 2016, LECT NOTES COMPUT SC, V9590, P88, DOI 10.1007/978-3-662-53090-0\_5.
   Hellstrom T, 2013, ETHICS INF TECHNOL, V15, P99, DOI 10.1007/s10676-012-9301-2.
   Hew PC, 2014, ETHICS INF TECHNOL, V16, P197, DOI 10.1007/s10676-014-9345-6.
   Himma KE, 2009, ETHICS INF TECHNOL, V11, P19, DOI 10.1007/s10676-008-9167-5.
   Hoorn JF, 2012, COGN SYST RES, V15-16, P33, DOI 10.1016/j.cogsys.2011.04.001.
   Johnson Deborah G, 2008, Ethics and Information Technology, V10, P123, DOI 10.1007/s10676-008-9174-6.
   Johnson D. G., 2006, Ethics and Information Technology, V8, P195, DOI 10.1007/s10676-006-9111-5.
   Jones S., 2014, ART LIF INT AG S, P97.
   Jonsen AR, 1988, ABUSE CASUISTRY HIST.
   KILLEN M, 2000, {[}No title captured], P352.
   Krishnan A, 2009, KILLER ROBOTS: LEGALITY AND ETHICALITY OF AUTONOMOUS WEAPONS, P1.
   Liberati N, 2017, SCI ENG ETHICS, V23, P801, DOI 10.1007/s11948-016-9827-5.
   Lichocki P, 2011, IEEE ROBOT AUTOM MAG, V18, P39, DOI 10.1109/MRA.2011.940275.
   McCauley Lee, 2007, Ethics and Information Technology, V9, P153, DOI 10.1007/s10676-007-9138-2.
   McLaren B., 2005, AAAI FALL S MACH ETH.
   McLaren B. M., 1995, Fifth International Conference on Artificial Intelligence and Law. Proceedings of the Conference, P316.
   McLaren B. M., 1995, P 17 ANN C COGN SCI, P72.
   McLaren BM, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P316.
   McMahan J., 2013, KILLING REMOTE CONTR.
   Miles H.C., 2016, J COMPUTING CULTURAL, V9, P1.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Murphy RR, 2009, IEEE INTELL SYST, V24, P14, DOI 10.1109/MIS.2009.69.
   Pontier M. A., 2012, P 34 INT ANN C COGN, P2198.
   Pontier MA, 2013, IFIP ADV INF COMM TE, V412, P195.
   Pontier MA, 2012, LECT NOTES ARTIF INT, V7637, P442, DOI 10.1007/978-3-642-34654-5\_45.
   Pynadath D. V., 2001, INT WORKSH AG THEOR, P307.
   Reed GS, 2013, TOPOI-INT REV PHILOS, V32, P237, DOI 10.1007/s11245-012-9127-x.
   RICE GE, 1962, J COMP PHYSIOL PSYCH, V55, P123, DOI 10.1037/h0042276.
   RICHARDSON K, 2016, {[}No title captured], V45, P290, DOI DOI 10.1145/2874239.2874281.
   Rowlands M, 2012, CAN ANIMALS BE MORAL.
   Rowlands Mark, 2013, J ANIMAL ETHICS, V3, P15, DOI DOI 10.5406/janimalethics.3.1.0015.
   Russell S., 2003, ARTIFICIAL INTELLIGE, V2.
   Rzepka R., 2005, AAAI FALL S MACH ETH.
   Sawyer RJ, 2007, SCIENCE, V318, P1037, DOI 10.1126/science.1151606.
   Shelley M. W., 2008, ENGAGE BOOKS.
   Stahl B. C., 2006, Ethics and Information Technology, V8, P205, DOI 10.1007/s10676-006-9112-4.
   Stahl BC, 2004, MIND MACH, V14, P67.
   Sullins J. P., 2005, Ethics and Information Technology, V7, P139, DOI 10.1007/s10676-006-0003-5.
   Sullins JP, 2010, ETHICS INF TECHNOL, V12, P263, DOI 10.1007/s10676-010-9241-7.
   Tonkens R. S., 2009, 2 S COMP PHIL ED SCO, P38.
   Tonkens R, 2013, ETHICS INF TECHNOL, V15, P109, DOI 10.1007/s10676-012-9292-z.
   Vincent S., 2015, HUMANS EPISODE 2.
   Wallach W, 2011, INT J MACHINE CONSCI, V3, P177, DOI DOI 10.1142/S1793843011000674.
   Wallach W, 2010, ETHICS INF TECHNOL, V12, P243, DOI 10.1007/s10676-010-9232-8.
   Wallach W, 2008, AI SOC, V22, P463, DOI 10.1007/s00146-007-0093-6.
   Wallach W, 2008, AI SOC, V22, P565, DOI 10.1007/s00146-007-0099-0.
   WELD D, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1042.
   Winfield Alan F. T., 2014, Advances in Autonomous Robotics Systems. 15th Annual Conference (TAROS 2014). Proceedings: LNCS 8717, P85, DOI 10.1007/978-3-319-10401-0\_8.}},
Number-of-Cited-References = {{90}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{12}},
Journal-ISO = {{Connect. Sci.}},
Doc-Delivery-Number = {{LO2RW}},
Unique-ID = {{ISI:000476114100001}},
OA = {{Bronze}},
DA = {{2020-06-17}},
}

@article{ ISI:000457536000010,
Author = {Bendel, Oliver},
Title = {{The synthetization of human voices}},
Journal = {{AI \& SOCIETY}},
Year = {{2019}},
Volume = {{34}},
Number = {{1, SI}},
Pages = {{83-89}},
Month = {{MAR}},
Abstract = {{The synthetization of voices, or speech synthesis, has been an object of
   interest for centuries. It is mostly realized with a text-to-speech
   system, an automaton that interprets and reads aloud. This system refers
   to text available for instance on a website or in a book, or entered via
   popup menu on the website. Today, just a few minutes of samples are
   enough to be able to imitate a speaker convincingly in all kinds of
   statements. This article abstracts from actual products and actual
   technological realization. Rather, after a short historical outline of
   the synthetization of voices, exemplary applications of this kind of
   technology are gathered for promoting the development, and potential
   applications are discussed critically to be able to limit them if
   necessary. The ethical and legal challenges should not be
   underestimated, in particular with regard to informational and personal
   autonomy and the trustworthiness of media.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Bendel, O (Reprint Author), Univ Appl Sci \& Arts Northwestern Switzerland, Sch Business, Bahnhofstr 6, CH-5210 Windisch, Switzerland.
   Bendel, Oliver, Univ Appl Sci \& Arts Northwestern Switzerland, Sch Business, Bahnhofstr 6, CH-5210 Windisch, Switzerland.}},
DOI = {{10.1007/s00146-017-0748-x}},
ISSN = {{0951-5666}},
EISSN = {{1435-5655}},
Keywords = {{Speech synthesis; Text-to-speech system; Artificial intelligence;
   Robotics; Information ethics; Machine ethics}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{oliver.bendel@fhnw.ch}},
Cited-References = {{Anderson M., 2011, MACHINE ETHICS.
   Bendel O, 2016, 300 KEYWORDS INFORMA.
   Bendel O, 2016, HMD PRAXIS WIRTSCHAF.
   Bendel O, 2016, MACHINE ETHICS MACHI.
   Bendel O, 2012, MASCHINENETHIK GABLE.
   Bendel O, 2017, 2 INT C PERS TECHN, P1.
   Bendel O, 2017, 2017 AAAI SPRING S S.
   Bendel O, 2004, INFOWEEK, P51.
   Bendel O, 2015, INTEL SYST CONTR AUT, V74, P17, DOI 10.1007/978-3-319-08108-3\_2.
   Beuth P, 2016, ZEIT ONLINE.
   Grimm J, 1808, ZEITUNG EINSIEDLER.
   Ingruber D, 2007, IMAGENES BILDER FILM.
   Kempelen WV, 1791, MECH MENSCHLICHEN SP.
   KLATT DH, 1987, J ACOUST SOC AM, V82, P737, DOI 10.1121/1.395275.
   Lenke M, 2015, FOCUS ONLINE    0212.
   Lupke MV, 2014, SPIEGEL ONLINE  1013.
   Nagels P, 2016, WELT            1007.
   Plass-Fle enkamper B, 2016, WIRED GERMANY   1108.
   Schulz TM, 2011, MAR MAMMAL SCI, V27, P149, DOI 10.1111/j.1748-7692.2010.00399.x.
   Stark J, 2016, PROFESSIONAL.
   Steinacker L, 2017, WIRTSCHAFTWOCHE 0120, P52.
   Thies J., 2016, P COMP VIS PATT REC.
   Vincent J, 2017, THE VERGE       0424.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.}},
Number-of-Cited-References = {{24}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{AI Soc.}},
Doc-Delivery-Number = {{HJ9RG}},
Unique-ID = {{ISI:000457536000010}},
DA = {{2020-06-17}},
}

@article{ ISI:000461418700011,
Author = {Gessmann, Martin},
Title = {{Basic Questions of Machine Ethics}},
Journal = {{DEUTSCHE ZEITSCHRIFT FUR PHILOSOPHIE}},
Year = {{2019}},
Volume = {{67}},
Number = {{1}},
Pages = {{146-150}},
Month = {{MAR}},
Publisher = {{WALTER DE GRUYTER GMBH}},
Address = {{GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY}},
Type = {{Book Review}},
Language = {{German}},
DOI = {{10.1515/dzph-2019-0011}},
ISSN = {{0012-1045}},
EISSN = {{2192-1482}},
Research-Areas = {{Philosophy}},
Web-of-Science-Categories  = {{Philosophy}},
Author-Email = {{gessmann@hfg-offenbach.de}},
Cited-References = {{MISSELHORN C, 2018, GRUNDFRAGEN DER MASC.}},
Number-of-Cited-References = {{1}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Dtsch. Z. Philos.}},
Doc-Delivery-Number = {{HP1HY}},
Unique-ID = {{ISI:000461418700011}},
DA = {{2020-06-17}},
}

@article{ ISI:000457536000018,
Author = {Srinivasan, Balaji and Shah, Kushal},
Title = {{Towards a unified framework for developing ethical and practical Turing
   tests}},
Journal = {{AI \& SOCIETY}},
Year = {{2019}},
Volume = {{34}},
Number = {{1, SI}},
Pages = {{145-152}},
Month = {{MAR}},
Abstract = {{Since Turing proposed the first test of intelligence, several
   modifications have been proposed with the aim of making Turing's
   proposal more realistic and applicable in the search for artificial
   intelligence. In the modern context, it turns out that some of these
   definitions of intelligence and the corresponding tests merely measure
   computational power. Furthermore, in the framework of the original
   Turing test, for a system to prove itself to be intelligent, a certain
   amount of deceit is implicitly required which can have serious security
   implications for future human societies. In this article, we propose a
   unified framework for developing intelligence tests which takes care of
   important ethical and practical issues. Our proposed framework has
   several important consequences. Firstly, it results in the suggestion
   that it is not possible to construct a single, context independent,
   intelligence test. Secondly, any measure of intelligence must have
   access to the process by which a problem is solved by the system under
   consideration and not merely the final solution. Finally, it requires an
   intelligent agent to be evolutionary in nature with the flexibility to
   explore new algorithms on its own.}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Shah, K (Reprint Author), IISER, Dept Elect Engn \& Comp Sci, Bhopal Bypass Rd, Bhopal 462066, Madhya Pradesh, India.
   Srinivasan, Balaji, Indian Inst Technol IIT Madras, Dept Mech Engn, Chennai 600036, India.
   Shah, Kushal, IISER, Dept Elect Engn \& Comp Sci, Bhopal Bypass Rd, Bhopal 462066, Madhya Pradesh, India.}},
DOI = {{10.1007/s00146-017-0763-y}},
ISSN = {{0951-5666}},
EISSN = {{1435-5655}},
Keywords = {{Artificial intelligence; Imitation game; Turing test; Machine ethics}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{sbalaji@iitm.ac.in
   kushals@iiserb.ac.in}},
ResearcherID-Numbers = {{Shah, Kushal/B-9942-2014}},
ORCID-Numbers = {{Shah, Kushal/0000-0003-3398-8425}},
Cited-References = {{Allcott H., 2017, 23089 NBER.
   Arleback JB, 2013, MODELING STUDENTS MA.
   Bringsjord S, 2001, MIND MACH, V11, P3, DOI 10.1023/A:1011206622741.
   Burgess Anthony, 2013, CLOCKWORK ORANGE.
   Calude CS, 2005, ADV APPL MATH, V35, P1, DOI 10.1016/j.aam.2004.10.003.
   CHAITIN GJ, 1982, INT J THEOR PHYS, V21, P941, DOI 10.1007/BF02084159.
   Cohen Paul J., 2008, SET THEORY CONTINUUM.
   Conroy N. J., 2015, P ASS INFORM SCI TEC, V52, P1, DOI DOI 10.1002/PRA2.2015.145052010082.
   Gardner H., 1983, FRAMES MIND THEORY M.
   GODEL K, 1940, {[}No title captured].
   Halmos PR, 1973, AM MATH MONTHLY, V80, P382, DOI 10.1080/00029890.1973.11993293.
   Legg S, 2007, MIND MACH, V17, P391, DOI 10.1007/s11023-007-9079-x.
   Levesque H. J., 2011, AAAI SPRING S LOG FO.
   Levesque HJ, 2014, ARTIF INTELL, V212, P27, DOI 10.1016/j.artint.2014.03.007.
   Luger GF, 2017, AI SOC, V32, P321, DOI 10.1007/s00146-016-0646-7.
   Markowitz DM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0105937.
   Oppy G, 2016, TURING TEST STANFORD.
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961.
   Tesla N, 1937, A MACHINE TO END WAR.
   Turing A, 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433.
   Warwick K, 2016, J EXPT THEOR AI, V29, P1.
   Warwick K, 2016, AI SOC, V31, P207, DOI 10.1007/s00146-015-0588-5.
   Warwick K, 2016, J EXP THEOR ARTIF IN, V28, P989, DOI 10.1080/0952813X.2015.1055826.
   Warwick K, 2016, AI SOC, V31, P5, DOI 10.1007/s00146-013-0534-3.
   Wu Y., 2016, ARXIV160908144.}},
Number-of-Cited-References = {{25}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{9}},
Journal-ISO = {{AI Soc.}},
Doc-Delivery-Number = {{HJ9RG}},
Unique-ID = {{ISI:000457536000018}},
DA = {{2020-06-17}},
}

@article{ ISI:000463624300004,
Author = {Wilks, Yorick},
Title = {{Moral Orthoses: A New Approach to Human and Machine Ethics}},
Journal = {{AI MAGAZINE}},
Year = {{2019}},
Volume = {{40}},
Number = {{1}},
Pages = {{33-34}},
Month = {{SPR}},
Abstract = {{I argue that both human and machine actions are more opaque than is
   generally realized and that the actions of both require explanation that
   an ethical orthosis might provide as aspects of artificial Companions
   for both human and machine actors. These explanations might well be
   closer to ethical accounts based on moral sentiment or emotion in the
   tradition of the primacy of sentiment over reason in this area of human
   and machine action.}},
Publisher = {{AMER ASSOC ARTIFICIAL INTELL}},
Address = {{445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Wilks, Y (Reprint Author), Florida Inst Human \& Machine Cognit, Pensacola, FL 32502 USA.
   Wilks, Y (Reprint Author), Univ Sheffield, Artificial Intelligence, Sheffield, S Yorkshire, England.
   Wilks, Yorick, Florida Inst Human \& Machine Cognit, Pensacola, FL 32502 USA.
   Wilks, Yorick, Univ Sheffield, Artificial Intelligence, Sheffield, S Yorkshire, England.}},
DOI = {{10.1609/aimag.v40i1.2854}},
ISSN = {{0738-4602}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Cited-References = {{Bostrom N., 2014, HDB ARTIFICIAL INTEL.
   Eubanks V., 2018, AUTOMATING INEQUALIT.
   Gray J., 2002, STRAW DOGS.
   MacIntyre A., 1985, AFTER VIRTUE.
   McDermott D., 2008, N AM C COMP PHIL BLO.
   Pearl J, 2018, BOOK WHY NEW SCI CAU.
   Wilks Yorick, 2010, ARTIFICIAL COMPANION.}},
Number-of-Cited-References = {{7}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{AI Mag.}},
Doc-Delivery-Number = {{HS1LS}},
Unique-ID = {{ISI:000463624300004}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000526055100055,
Author = {Aliman, Nadisha-Marie and Kester, Leon and Werkhoven, Peter},
Book-Group-Author = {{IEEE}},
Title = {{XR for Augmented Utilitarianism}},
Booktitle = {{2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND
   VIRTUAL REALITY (AIVR)}},
Year = {{2019}},
Pages = {{283-285}},
Note = {{2nd IEEE International Conference on Artificial Intelligence and Virtual
   Reality (AIVR), San Diego, CA, DEC 09-11, 2019}},
Organization = {{IEEE; IEEE Comp Soc; IEEE Tech Comm Semant Comp; Eurographics; ACM; ACM
   SIGAI; ACM SIGCHI; ACMG SIGGRAPH}},
Abstract = {{Steady progresses in the AI field create enriching possibilities for
   society while simultaneously posing new complex challenges of ethical,
   legal and safety-relevant nature. In order to achieve an efficient
   human-centered governance of artificial intelligent systems, it has been
   proposed to harness augmented utilitarianism (AU), a novel non-normative
   ethical framework grounded in science which can be assisted e.g. by
   Extended Reality (XR) technologies. While AU provides a scaffold to
   encode human ethical and legal conceptions in a machine-readable form,
   the filling in of these conceptions requires a transdisciplinary
   amalgamation of scientific insights and preconditions from manifold
   research areas. In this short paper, we present a compact review on how
   XR technologies could leverage the underlying transdisciplinary AI
   governance approach utilizing the AU framework. Towards that end, we
   outline pertinent needs for XR in two hereto related contexts: as
   experiential testbed for AU-relevant moral psychology studies and as
   proactive AI Safety measure and enhancing policy-by-simulation method
   preceding the deployment of AU-based ethical goal functions.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Aliman, NM (Reprint Author), Univ Utrecht, Informat \& Comp Sci, Utrecht, Netherlands.
   Aliman, Nadisha-Marie; Werkhoven, Peter, Univ Utrecht, Informat \& Comp Sci, Utrecht, Netherlands.
   Kester, Leon, TNO Netherlands, Intelligent Autonomous Syst, The Hague, Netherlands.}},
DOI = {{10.1109/AIVR46125.2019.00065}},
ISBN = {{978-1-7281-5604-0}},
Keywords = {{Moral Psychology; Machine Ethics; AI Safety; VR; AR; Intelligent
   Systems; Positive Technology}},
Keywords-Plus = {{MACHINES}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods}},
Author-Email = {{n.aliman@uu.nl
   leon.kester@tno.nl
   peter.werkhoven@tno.nl}},
Cited-References = {{Aliman N., 2019, P WORKSH ART INT SAF.
   Aliman Nadisha-Marie, 2019, Artificial General Intelligence. 12th International Conference, AGI 2019. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11654), P22, DOI 10.1007/978-3-030-27005-6\_3.
   Aliman Nadisha-Marie, 2019, Artificial General Intelligence. 12th International Conference, AGI 2019. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11654), P11, DOI 10.1007/978-3-030-27005-6\_2.
   Aliman N.-M., 2019, DELPHI INTERDISC REV, V2, P23.
   Aliman N.-M., 2018, INT C ART GEN INT, P1.
   Anderson M., 2011, MACHINE ETHICS.
   Awad E, 2018, NATURE, V563, P59, DOI 10.1038/s41586-018-0637-6.
   Bhagavathula Rajaram, 2018, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V62, P2056, DOI 10.1177/1541931218621464.
   Bigman Y., 2019, TRENDS COGNITIVE SCI.
   Bigman YE, 2018, COGNITION, V181, P21, DOI 10.1016/j.cognition.2018.08.003.
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654.
   Calvo R. A., 2015, P 33 ANN ACM C HUM F, P2499.
   Chirico A, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02351.
   Dafoe A., 2018, AI GOVERNANCE RES AG.
   Dubljevic V, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204631.
   Elands P., 2019, MILITARY SPECTATOR 2, V2019.
   Faulhaber AK, 2019, SCI ENG ETHICS, V25, P399, DOI 10.1007/s11948-018-0020-x.
   Gaggioli A, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01571.
   Gaggioli A, 2017, EMOTIONS AND AFFECT IN HUMAN FACTORS AND HUMAN-COMPUTER INTERACTION, P477, DOI 10.1016/B978-0-12-801851-4.00018-5.
   Gasser U, 2017, IEEE INTERNET COMPUT, V21, P58, DOI 10.1109/MIC.2017.4180835.
   Hester N., 2019, PERSPECTIVES PSYCHOL.
   Hutchinson J. B., 2019, CURRENT DIRECTIONS P.
   Kallioinen N., 2019, MORAL JUDGEMENTS ACT.
   Kester L., 2014, 17 INT C INF FUS FUS, P1.
   Kester L, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P320, DOI 10.1109/ITSC.2014.6957711.
   Li S., 2019, IEEE ACCESS.
   Liu P, 2019, ACCIDENT ANAL PREV, V125, P232, DOI 10.1016/j.aap.2019.02.012.
   Quesnel D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02158.
   Recupero A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01223.
   Rosenberg RS, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0055003.
   Rotsidis A., 2019, 28TH IEEE INT S ROB.
   Russell S, 2015, AI MAG, V36, P105, DOI 10.1609/aimag.v36i4.2577.
   Schein C, 2018, PERS SOC PSYCHOL REV, V22, P32, DOI 10.1177/1088868317698288.
   Schein C, 2016, SOC PERSONAL PSYCHOL, V10, P231, DOI 10.1111/spc3.12247.
   Schein C, 2016, PSYCHOL INQ, V27, P62, DOI 10.1080/1047840X.2016.1111121.
   Stephen Eric J., 2018, 2018 AIAA Aerospace Sciences Meeting, P1.
   Sutfeld LR, 2017, FRONT BEHAV NEUROSCI, V11, DOI 10.3389/fnbeh.2017.00122.
   Werkhoven P., 2018, P 36 EUR C COGN ERG, P2.
   Wilson H., 2019, INT WORKSH ART INT S.
   Yampolskiy R. V., 2018, ARTIFICIAL INTELLIGE.
   Yampolskiy R. V., 2019, ARXIV190101851.
   Zuromski D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00705.}},
Number-of-Cited-References = {{42}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BO7YA}},
Unique-ID = {{ISI:000526055100055}},
DA = {{2020-06-17}},
}

@article{ ISI:000465435200005,
Author = {Baum, Kevin and Hermanns, Holger and Speith, Timo},
Title = {{Towards a Framework Combining Machine Ethics and Machine Explainability}},
Journal = {{ELECTRONIC PROCEEDINGS IN THEORETICAL COMPUTER SCIENCE}},
Year = {{2019}},
Number = {{286}},
Pages = {{34-49}},
Note = {{3rd International Workshop on Formal Reasoning about Causation,
   Responsibility, and Explanations in Science and Technology (CREST) /
   European Joint Conferences on Theory and Practice of Software (ETAPS),
   Thessaloniki, GREECE, APR 21, 2018}},
Abstract = {{We find ourselves surrounded by a rapidly increasing number of
   autonomous and semi-autonomous systems. Two grand challenges arise from
   this development: Machine Ethics and Machine Explainability. Machine
   Ethics, on the one hand, is concerned with behavioral constraints for
   systems, so that morally acceptable, restricted behavior results;
   Machine Explainability, on the other hand, enables systems to explain
   their actions and argue for their decisions in a way that human users
   can understand and justifiably trust them.
   In this paper, we try to motivate and work towards a framework combining
   Machine Ethics and Machine Explainability. Starting from a toy example,
   we detect various desiderata of such a framework and argue why they
   should and how they could be incorporated in autonomous systems. Our
   main idea is to apply a framework of formal argumentation theory both,
   for decision-making under ethically motivated constraints and for the
   task of generating useful explanations based on these constraints given
   only limited knowledge of the world. The result of our deliberations can
   be described as a first version of an ethically motivated,
   principle-governed framework combining Machine Ethics and Machine
   Explainability.}},
Publisher = {{OPEN PUBL ASSOC}},
Address = {{OPEN PUBL ASSOC, SYDNEY, 00000, AUSTRALIA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Baum, K (Reprint Author), Univ Saarland, Dept Comp Sci, Saarland Informat Campus, Saarbrucken, Germany.
   Baum, K (Reprint Author), Univ Saarland, Dept Philosophy, Saarland Informat Campus, Saarbrucken, Germany.
   Baum, Kevin; Hermanns, Holger; Speith, Timo, Univ Saarland, Dept Comp Sci, Saarland Informat Campus, Saarbrucken, Germany.
   Baum, Kevin; Speith, Timo, Univ Saarland, Dept Philosophy, Saarland Informat Campus, Saarbrucken, Germany.}},
DOI = {{10.4204/EPTCS.286.4}},
ISSN = {{2075-2180}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods}},
ORCID-Numbers = {{Speith, Timo/0000-0002-6675-154X}},
Funding-Acknowledgement = {{ERCEuropean Research Council (ERC) {[}695614]; Initiative for Excellence
   of the German federal government; Initiative for Excellence of the
   German state government; DFG MMCI Cluster of Excellence}},
Funding-Text = {{This work is supported by the ERC Advanced Grant 695614 (POWVER) and by
   the Initiative for Excellence of the German federal and state
   governments through funding for the Saarbrucken Graduate School of
   Computer Science and the DFG MMCI Cluster of Excellence.}},
Cited-References = {{Alonso Jose M., 2017, P 1 WORKSH EXPL COMP, DOI {[}10.18653/v1/W17-3704, DOI 10.18653/V1/W17-3704].
   Amgoud L, 2009, ARTIF INTELL, V173, P413, DOI 10.1016/j.artint.2008.11.006.
   Anderson M, 2011, MACHINE ETHICS, DOI {[}10.1017/CBO9780511978036, DOI 10.1017/CBO9780511978036].
   ANSCOMBE GEM, 1958, PHILOSOPHY, V33, P1, DOI 10.1017/S0031819100037943.
   Aristotle, NICOMACHEAN ETHICS.
   Barthe G, 2016, LECT NOTES COMPUT SC, V9953, P601, DOI 10.1007/978-3-319-47169-3\_46.
   Baum K, 2016, LECT NOTES COMPUT SC, V9953, P633, DOI 10.1007/978-3-319-47169-3\_49.
   Baum Kevin, 2017, P 1 WORKSH EXPL COMP, DOI {[}10.18653/v1/W17-3701, DOI 10.18653/V1/W17-3701].
   Baum Kevin, 2018, MACHINE ETHICS MACHI.
   Bentham J., 1789, INTRO PRINCIPLES MOR, DOI {[}10.1093/oseo/instance.00077240, DOI 10.1093/OSEO/INSTANCE.00077240].
   Bykvist K, 2009, UTILITARIANISM GUIDE.
   Conitzer V, 2017, MORAL DECISION MAKIN.
   D'Argenio Pedro R., 2017, EUR S PROGR, P83, DOI DOI 10.1007/978-3-662-54434-1\_4.
   Dancy Jonathan, 2017, STANFORD ENCY PHILOS.
   Dancy Jonathan, 2004, ETHICS PRINCIPLES, DOI {[}10.1093/0199270023.001.0001, DOI 10.1093/0199270023.001.0001].
   DAVIDSON D, 1963, J PHILOS, V60, P685, DOI 10.2307/2023177.
   Dennis Louise, 2018, ARXIV180101422.
   Dietrich F, 2017, PHILOS REV, V126, P421, DOI 10.1215/00318108-4173412.
   Foot P, 2002, PROBLEM ABORTION DOC, P19, DOI {[}10.1093/0199252866.003.0002, DOI 10.1093/0199252866.003.0002].
   Franklin Benjamin, 1887, LETT J B PRIESTL, P522.
   Gardiner SM, 2006, J POLIT PHILOS, V14, P33, DOI 10.1111/j.1467-9760.2006.00237.x.
   Hempel C. G., 1965, ASPECTS SCI EXPLANAT, P381.
   Hempel Carl G., 1965, ASPECTS SCIENTIFIC E, P335.
   Hengstler M, 2016, TECHNOL FORECAST SOC, V105, P105, DOI 10.1016/j.techfore.2015.12.014.
   Horacek Helmut, 2017, P 1 WORKSH EXPL COMP, DOI {[}10.18653/v1/W17-3703, DOI 10.18653/V1/W17-3703].
   HORTY JF, 2007, {[}No title captured], V7, P1, DOI DOI 10.1093/ACPR0F:0S0/9780199744077.001.0001.
   Kant I., 1785, GROUNDWORK METAPHYSI.
   Karl Popper, 1963, CONJECTURES REFUTAT, DOI {[}10.1063/1.3050617, DOI 10.1063/1.3050617].
   Kolodny N, 2016, STANFORD ENCY PHILOS.
   Langley Pat, 2017, EXPLAINABLE AGENCY I.
   Lord Errol, 2016, WEIGHING REASONS, DOI {[}10.1093/acprof:oso/9780199315192.001.0001, DOI 10.1093/ACPROF:OSO/9780199315192.001.0001].
   Mantel S, 2017, PAC PHILOS QUART, V98, P5, DOI 10.1111/papq.12094.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Portmore Douglas W., 2011, COMMONSENSE CONSEQUE, DOI {[}10.1093/acprof:oso/9780199794539.003.0007, DOI 10.1093/ACPROF:OSO/9780199794539.003.0007].
   Ross William D., 1930, RIGHT GOOD, DOI {[}10.1093/0199252653.001.0001, DOI 10.1093/0199252653.001.0001].
   Smart J. J. C., 1973, UTILITARIANISM, DOI {[}10.1017/CBO9780511840852, DOI 10.1017/CBO9780511840852].
   Wallach Wendell, 2008, MORAL MACHINES TEACH, DOI {[}10.1093/acprof:oso/9780195374049.001.0001, DOI 10.1093/ACPROF:OSO/9780195374049.001.0001, 10.1093/acprof.oso/9780195374049.001.0001].
   1995, ARTIF INTELL, V77, P321, DOI DOI 10.1016/0004-3702(94)00041-X.}},
Number-of-Cited-References = {{38}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{Electron. Proc. Theor. Comput. Sci.}},
Doc-Delivery-Number = {{HU7BD}},
Unique-ID = {{ISI:000465435200005}},
OA = {{DOAJ Gold}},
DA = {{2020-06-17}},
}

@article{ ISI:000509939200004,
Author = {Broughton, Vanda},
Title = {{The Respective Roles of Intellectual Creativity and Automation in
   Representing Diversity: Human and Machine Generated Bias}},
Journal = {{KNOWLEDGE ORGANIZATION}},
Year = {{2019}},
Volume = {{46}},
Number = {{8}},
Pages = {{596-606}},
Abstract = {{The paper traces the development of the discussion around ethical issues
   in artificial intelligence, and considers the way in which humans have
   affected the knowledge bases used in machine learning. The phenomenon of
   bias or discrimination in machine ethics is seen as inherited from
   humans, either through the use of biased data or through the semantics
   inherent in intellectually-built tools sourced by intelligent agents.
   The kind of biases observed in AI are compared with those identified in
   the field of knowledge organization, using religious adherents as an
   example of a community potentially marginalized by bias. A practical
   demonstration is given of apparent religious prejudice inherited from
   source material in a large database deployed widely in computational
   linguistics and automatic indexing. Methods to address the problem of
   bias are discussed, including the modelling of the moral process on
   neuroscientific understanding of brain function. The question is posed
   whether it is possible to model religious belief in a similar way, so
   that robots of the future may have both an ethical and a religious sense
   and themselves address the problem of prejudice.}},
Publisher = {{NOMOS VERLAGSGESELLSCHAFT MBH \& CO KG}},
Address = {{WALDSEESTR 3 5, BADEN-BADEN, 76530, GERMANY}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Broughton, V (Reprint Author), UCL, Dept Informat Studies, Gower St, London WC1E 6BT, England.
   Broughton, Vanda, UCL, Dept Informat Studies, Gower St, London WC1E 6BT, England.}},
DOI = {{10.5771/0943-7444-2019-8-596}},
ISSN = {{0943-7444}},
Keywords = {{machine intelligence; bias; human; artificial intelligence; data}},
Keywords-Plus = {{TEXT CATEGORIZATION; CLASSIFICATION; LIBRARY; NETWORK}},
Research-Areas = {{Information Science \& Library Science}},
Web-of-Science-Categories  = {{Information Science \& Library Science}},
Author-Email = {{v.broughton@ucl.ac.uk}},
Cited-References = {{Adler M, 2018, LIBR TRENDS, V67, P52, DOI 10.1353/lib.2018.0025.
   Adolphs R, 2003, NAT REV NEUROSCI, V4, P165, DOI 10.1038/nrn1056.
   Albrecht SV, 2015, AI MAG, V36, P87, DOI 10.1609/aimag.v36i1.2575.
   Anderson J, 2005, RETROVIROLOGY, V2, DOI 10.1186/1742-4690-2-53.
   Anderson SE, 2007, J IMMUNOTOXICOL, V4, P15, DOI 10.1080/15476910601115119.
   Bader C, 1996, J SCI STUD RELIG, V35, P285, DOI 10.2307/1386560.
   Bainbridge William Sims, 2006, GOD MACHINE ARTIFICI.
   Bainbridge WS, 1995, SOCIOL PERSPECT, V38, P483, DOI 10.2307/1389269.
   Barocas S., 2018, FAIRNESS MACHINE LEA.
   Bentham J., 1789, INTRO PRINCIPLES MOR.
   Bertrand M, 2004, AM ECON REV, V94, P991, DOI 10.1257/0002828042002561.
   Binns Reuben, 2018, P MACHINE LEARNING R, V81, P1.
   Blair Ann, 2010, TOO MUCH KNOW.
   Boyett Jason, 2016, 12 MAJOR WORLD RELIG.
   Brachman R, 2005, AI MAG, V26, P48.
   Brains Moral, 2016, MORAL BRAINS NEUROSC.
   Broughton Vanda, 2000, INT CATALOGUING BIBL, V4, P2.
   Broughton Vanda, 2008, AUTOMATIC METADATA G.
   Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230.
   Cheung C. F., 2005, Journal of Knowledge Management, V9, P76, DOI 10.1108/13673270510629972.
   Copeland B. J., 2019, ENCY BRITANNICA.
   Crawford Kate, 2016, NY TIMES.
   Criado Perez C., 2019, INVISIBLE WOMEN EXPO.
   Damasio A.R., 1994, DESCARTES ERROR EMOT.
   Drabinski E, 2013, LIBR QUART, V83, P94, DOI 10.1086/669547.
   Duarte ME, 2015, CAT CLASSIF Q, V53, P677, DOI 10.1080/01639374.2015.1018396.
   Dumsday T, 2017, ZYGON, V52, P601, DOI 10.1111/zygo.12346.
   Executive Office of the President, 2016, BIG DATA REPORT ALGO.
   Field D, 2017, TLS-TIMES LIT SUPPL, P24.
   FOSKETT AC, 1971, LIBR RESOUR TECH SER, V15, P117.
   Fox MJ, 2016, LIBR TRENDS, V64, P687, DOI 10.1353/lib.2016.0016.
   Gorg C, 2014, INFORM VISUAL, V13, P336, DOI 10.1177/1473871613495674.
   GREENBERG J, 2005, {[}No title captured].
   Greenwald AG, 1998, J PERS SOC PSYCHOL, V74, P1464, DOI 10.1037/0022-3514.74.6.1464.
   Hannay T., 2014, INFORM TODAY, V31, P25.
   Herzfeld N, 2002, ZYGON, V37, P303, DOI 10.1111/0591-2385.00430.
   Hinnells John, 2017, NEW HDB LIVING RELIG, DOI {[}10.1002/9781405166614, DOI 10.1002/9781405166614].
   Howard SA, 2018, LIBR TRENDS, V67, P74, DOI 10.1353/lib.2018.0026.
   Hurwitz J., 2018, MACHINE LEARNING DUM.
   IBM, 2019, DAT SCI MACH LEARN.
   Kaki M, 2005, INTERACT COMPUT, V17, P187, DOI 10.1016/j.intcom.2005.01.001.
   Khamis RY, 2016, HEART, V102, P1142, DOI 10.1136/heartjnl-2014-306463.
   Kirchner Julia, 2016, PROPUBLICA      0523.
   Ko Y, 2004, INFORM PROCESS MANAG, V40, P65, DOI 10.1016/S0306-4573(02)00056-0.
   Kochi Erica, 2018, QUARTZ          0315.
   Kozlowski AC, 2019, AM SOCIOL REV, V84, P905, DOI 10.1177/0003122419877135.
   Kurzweil Ray, 1999, AGE SPIRITUAL MACHIN.
   Lacey E, 2018, KNOWL ORGAN, V45, P358, DOI 10.5771/0943-7444-2018-5-358.
   Liang CY, 2006, INFORM PROCESS MANAG, V42, P1017, DOI 10.1016/j.ipm.2005.09.001.
   Mai JE, 2016, KNOWL ORGAN, V43, P324.
   Mai JE, 2013, KNOWL ORGAN, V40, P242, DOI 10.5771/0943-7444-2013-4-242.
   Mai JE, 2010, J DOC, V66, P627, DOI 10.1108/00220411011066763.
   Mai Jens-Erik, 2013, 2 C BRAS ORG REPR CO.
   Mancuhan K, 2014, ARTIF INTELL LAW, V22, P211, DOI 10.1007/s10506-014-9156-4.
   Marshall J., 1977, EQUAL TERMS THESAURU.
   Muslim Pro, 2019, MOST POP MUSL APP.
   Nosek BA, 2002, J PERS SOC PSYCHOL, V83, P44, DOI 10.1037//0022-3514.83.1.44.
   Nosek BA, 2002, GROUP DYN-THEOR RES, V6, P101, DOI 10.1037//1089-2699.6.1.101.
   Ojala Marydee, 2018, INFORM TODAY, V35, P10.
   Olson HA, 1998, LIBR TRENDS, V47, P233.
   OLSON HA, 2002, {[}No title captured].
   Olson HA, 2007, LIBR TRENDS, V56, P509.
   Olson Hope A., 1997, KNOWLEDGE ORG INFORM, P129.
   Pinnow E, 2014, J WOMENS HEALTH, V23, P218, DOI 10.1089/jwh.2013.4343.
   Poole DI, 1998, COMPUTATIONAL INTELL.
   Princeton Univ, 2010, WORDNET.
   Quartz SR, 2009, TRENDS COGN SCI, V13, P209, DOI 10.1016/j.tics.2009.02.003.
   Rau Andy, 2011, THINK CHRISTIAN 0224.
   Sawe Benjamin Elisha, 2017, WORLDATLAS      0425.
   Sears Mark, 2018, FORBES.
   Sherwood H., 2017, GUARDIAN.
   Shoemaker WJ, 2012, ZYGON, V47, P806, DOI 10.1111/j.1467-9744.2012.01295.x.
   Smith Megan, 2016, BIG RISKS BIG OPPORT.
   Stark Rodney, 1987, THEORY RELIG.
   Szostak R, 2014, KNOWL ORGAN, V41, P160, DOI 10.5771/0943-7444-2014-2-160.
   Tatlow Didi K., 2016, NY TIMES.
   Vidal D, 2007, J ROY ANTHROPOL INST, V13, P917, DOI 10.1111/j.1467-9655.2007.00464.x.
   Woodward J., 2016, MORAL BRAINS NEUROSC, P87, DOI DOI 10.1093/ACPROF:OSO/9780199357666.003.0004.
   World Economic Forum, 2018, PREV DISCR OUTC MACH.}},
Number-of-Cited-References = {{79}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{Knowl. Organ.}},
Doc-Delivery-Number = {{KG4TI}},
Unique-ID = {{ISI:000509939200004}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000471325700026,
Author = {Guryanova, A. V. and Shestakov, A. A. and Noskov, E. G.},
Editor = {{Mantulenko, V}},
Title = {{DIGITAL ETHICS AS AN INSTRUMENT FOR THE TECHNOLOGICAL CHALLENGES'
   REGULATION}},
Booktitle = {{GCPMED 2018 - INTERNATIONAL SCIENTIFIC CONFERENCE GLOBAL CHALLENGES AND
   PROSPECTS OF THE MODERN ECONOMIC DEVELOPMENT}},
Series = {{European Proceedings of Social and Behavioural Sciences}},
Year = {{2019}},
Volume = {{57}},
Pages = {{251-262}},
Note = {{International Scientific Conference on Global Challenges and Prospects
   of the Modern Economic Development (GCPMED), Samara State Univ Econ,
   Samara, RUSSIA, DEC 06-08, 2018}},
Abstract = {{The article considers the subject and the problem field of the modern
   digital ethics. Different conceptions of the digital ethics are
   discussed too. These conceptions are divided into classic and modern,
   realist and futurist, alarmist and non-alarmist. Initial development of
   the digital ethics is analyzed on the base of N. Wiener's and J.
   Weizenbaum's works. Positions of alarmism and non-alarmism in the
   digital ethics and conceptions of the digital ontology by R. Capurro and
   L. Floridi are the subject of analysis in the article. Special attention
   is payed to the technological challenges of the digital epoch because of
   their impact on the humans, society and environment. In this context the
   problems of ubiquitous robotization, artificial intelligence, machine
   ethics and free access to the Internet are considered from the ethical
   point of view. Digital technologies' impact on human existence is also
   discussed in the context of equity absence in using the digital
   achievements, of human interaction with technical intermediaries and of
   ``homo digital's{''} formation. In general, the authors try to form an
   objective view on digital ethics, differed from the outdated hypotheses
   of science fiction and from its popular alarmist interpretations. They
   also try to integrate digital technologies and human values in such a
   way that the first ones won't conflict the last ones but protect and
   develop them. (C) 2019 Published by Future Academy
   www.FutureAcademy.org.UK}},
Publisher = {{FUTURE ACAD}},
Address = {{PO BOX 24333, NICOSIA, 1703, CYPRUS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Guryanova, AV (Reprint Author), Samara State Univ Econ, Soviet Army Str 141, Samara 443090, Russia.
   Guryanova, A. V., Samara State Univ Econ, Soviet Army Str 141, Samara 443090, Russia.
   Shestakov, A. A.; Noskov, E. G., Samara State Tech Univ, Molodogvardeyskaya Str 244, Samara 443001, Russia.}},
DOI = {{10.15405/epsbs.2019.03.26}},
ISSN = {{2357-1330}},
Keywords = {{Digital ethics; digital technology; digital divide; alarmism; artificial
   intelligence; homo digital}},
Keywords-Plus = {{INFORMATION; PHILOSOPHY}},
Research-Areas = {{Development Studies; Business \& Economics}},
Web-of-Science-Categories  = {{Development Studies; Economics}},
Author-Email = {{ecun@sseu.ru
   upd@samgtu.ru
   upd@samgtu.ru}},
Cited-References = {{Anderson M., 2011, MACHINE ETHICS.
   Bostrom N., 2014, SUPERINTELLIGENCE PA.
   Bounfour A., 2016, DIGITAL FUTURES DIGI.
   Bynum T. W., 1998, DIGITAL PHOENIX COMP.
   Capurro R., 2006, Ethics and Information Technology, V8, P175, DOI 10.1007/s10676-006-9108-0.
   Capurro R., 2017, CRITICAL REV INFORM, V1, P13.
   Capurro R, 2017, BIBL-AN INVESTIG, V13, P113.
   Capurro R, 2017, AI SOC, V32, P277, DOI 10.1007/s00146-016-0686-z.
   Davisson A, 2017, CONTROVERSIES DIGITA.
   Dedyulina M. A., 2015, HUMANITARIAN SCI RES.
   Floridi L, 2010, METAPHILOSOPHY, V41, P402, DOI 10.1111/j.1467-9973.2010.01647.x.
   Guryanova A., 2018, ADV INTELLIGENT SYST, V622, P97, DOI {[}10.1007/978-3-319-75383-6\_13, DOI 10.1007/978-3-319-75383-6\_13].
   Guryanova A, 2019, ADV INTELL SYST, V726, P1033, DOI 10.1007/978-3-319-90835-9\_115.
   Himma K.E., 2008, HDB INFORM COMPUTER.
   Lin P, 2012, INTELL ROBOT AUTON, P1.
   Mariarosaria T., 2014, PHILOS COMPUTERS, V14, P13.
   McKinsey \& Company, 2017, DIG RUSS NEW REAL.
   MOOR JH, 1985, METAPHILOSOPHY, V16, P266, DOI 10.1111/j.1467-9973.1985.tb00173.x.
   Prensky MH., 2009, INNOVATE, V5.
   Searle J. R., 1992, REDISCOVERY MIND.
   Shestakov AA, 2017, CONTRIB ECON, P629, DOI 10.1007/978-3-319-60696-5\_79.
   Tapscott D., 2014, DIGITAL EC ANNIVERSA.
   WEIZENBAUM J, 1976, {[}No title captured].
   Wiener N., 1961, CYBERNETICS CONTROL.
   Wiener N., 1988, HUMAN USE HUMAN BEIN, DOI {[}10.1596/978-1-4648-0671-1.A, DOI 10.1596/978-1-4648-0671-1.A].}},
Number-of-Cited-References = {{25}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BM9SN}},
Unique-ID = {{ISI:000471325700026}},
OA = {{Bronze}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000469508600008,
Author = {Halibas, Alrence Santiago and Al Bulushi, Talal Abdul Rasheed Mohammed
   and Soriano, Ronald Cordova and Al Shaqsi, Amjad Saleem Mubarak},
Book-Group-Author = {{IEEE}},
Title = {{Ethical Design Perspectives of Intelligent UAVs}},
Booktitle = {{2019 1ST INTERNATIONAL CONFERENCE ON UNMANNED VEHICLE SYSTEMS-OMAN (UVS)}},
Year = {{2019}},
Note = {{1st International Conference on Unmanned Vehicle Systems-Oman (UVS),
   Sultan Qaboos Univ, Muscat, OMAN, FEB 05-07, 2019}},
Organization = {{IEEE Oman Sect; Coll Engn}},
Abstract = {{Intelligent systems are progressively used and are significantly
   impacting every aspect of the society. This paper discusses relevant
   ethical principles, approaches, and architectures for UAV design. This
   paper also presents challenges in the application of ethical design in
   collision avoidance and autonomous weapons systems for drones. Finally,
   this paper recommends the convergence of technologies and principles in
   building robust ethical UAVs.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Halibas, AS (Reprint Author), Gulf Coll, Fac Comp Sci, Muscat, Oman.
   Halibas, Alrence Santiago; Al Bulushi, Talal Abdul Rasheed Mohammed; Soriano, Ronald Cordova; Al Shaqsi, Amjad Saleem Mubarak, Gulf Coll, Fac Comp Sci, Muscat, Oman.}},
ISBN = {{978-1-5386-9368-1}},
Keywords = {{Ethical Drone; Intelligent Agent; Machine Ethics; UAV}},
Research-Areas = {{Computer Science; Robotics; Transportation}},
Web-of-Science-Categories  = {{Computer Science, Cybernetics; Robotics; Transportation Science \&
   Technology}},
Author-Email = {{alrence@gulfcollege.edu.om
   talal@gulfcollege.edu.om
   ronald@gulfcollege.edu.om
   amjad.s@gulfcollege.edu.om}},
ResearcherID-Numbers = {{Halibas, Alrence/AAF-6375-2019}},
ORCID-Numbers = {{Halibas, Alrence/0000-0002-5521-9590}},
Cited-References = {{Albaker B. M., 2009, INT C TECHN POSTGR 2.
   {[}Anonymous], 2017, HE CURR DEV APPL AUT.
   {[}Anonymous], 2014, SECURITY IMPACT DRON.
   Baum S. D., 2017, AI SOC.
   Behdad S., 2013, 25 INT C DES THEOR M, V5.
   Bryson J., 2011, P 22 INT JOINT C ART, P1641.
   Bulling N., 2011, IJCAI INT JOINT C AR.
   Carvin S, 2015, INT J HUM RIGHTS, V19, P127, DOI 10.1080/13642987.2014.991212.
   Chin K. On, 2014, T SCI TECHNOL.
   Churchill R. R., 2000, AM J INT LAW.
   Dennis L. A., 2016, AUTOM SOFTW ENG.
   Dignum V., 2017, IJCAI INT JOINT C AR.
   Etzioni A., 2013, MIL REV, V93, P2.
   Hamid NHA, 2014, I C INF TECH MULTIM, P217, DOI 10.1109/ICIMU.2014.7066633.
   Han Y., 2018, 27 INT JOINT C ART I.
   Hexmoor H., 2009, J EXP THEOR ARTIF IN.
   Meyer J., 1998, LOGICS DATABASES INF.
   Moor J, 2011, MACHINE ETHICS, P13.
   MULLER JP, 1996, {[}No title captured].
   Neumann M, 2010, SPRINGER SER AGENT B, V7, P3, DOI 10.1007/978-4-431-99781-8\_1.
   Pham J. Y., 2015, SURVEY UNMANNED AERI.
   Powers T., 2005, MACH ETH PAP AAAI FA, P79.
   Roelofsen S, 2016, 2016 IEEE 55 C DEC C.
   Russell S, 2010, ARTIFICIAL INTELLIGE.
   SEHRA SS, 2015, INDIAN J SCI TECHNOL, V8, pNIL93.
   Smith B. D., 2016, THESIS.
   Srinivasan S., 2010, UBIQUITOUS COMPUTING, V5, P14, DOI 10.1.1.295.6890.
   Tavani H.T., 2013, ETHICS TECHNOLOGY CO.
   Tegmark M., 2015, OPEN LETT RES PRIORI.
   Ursin L, 2015, ETIKK PRAKSIS, V9, P1.
   van de Poel I., 2006, TECHNE RES PHILOS TE, V10.
   Weld D., 2009, LECT NOTES COMPUTER.
   Yanmaz E, 2018, AD HOC NETW, V68, P1, DOI 10.1016/j.adhoc.2017.09.001.}},
Number-of-Cited-References = {{33}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{5}},
Doc-Delivery-Number = {{BM8NZ}},
Unique-ID = {{ISI:000469508600008}},
DA = {{2020-06-17}},
}

@article{ ISI:000490258800006,
Author = {Klein, Wilhelm E. J.},
Title = {{Exceptionalisms in the ethics of humans, animals and machines}},
Journal = {{JOURNAL OF INFORMATION COMMUNICATION \& ETHICS IN SOCIETY}},
Year = {{2019}},
Volume = {{17}},
Number = {{2, SI}},
Pages = {{183-195}},
Abstract = {{Purpose - This paper aims to examine exceptionalisms in ethics in
   general and in the fields of animal and technology ethics in particular.
   Design/methodology/approach - This paper reviews five sample works in
   animal/technology ethics it considers representative for particularly
   popular forms of ``exceptionalism{''}. Findings - The shared feature of
   the exceptionalisms exhibited by the chosen samples appears to be born
   out of the cultural and biological history, which provides powerful
   intuitions regarding the on ``specialness{''}. Research
   limitations/implications - As this paper is mostly a critique of
   existing approaches, it contains only a limited amount of
   counter-proposed alternative approaches. Practical implications - This
   is a discussion worth having because arguments based on (human or
   biological) exceptionalism have more chance of resulting in
   significantly altered theoretical conclusions and practical suggestions
   for normative guidance than non-exceptionalist perspectives. Social
   implications - The approaches critiqued in this paper have a significant
   effect on the way the authors approach animals, machines/technologies
   and each other. Originality/value - The paper identifies intuitive
   notions of exceptionalism and argues in favour of a reformist, ethical
   expansionist stance, which views humanity as residing (and other
   biological organisms) on the same plane of ethical significance as any
   other entity regardless of its material composition.}},
Publisher = {{EMERALD GROUP PUBLISHING LTD}},
Address = {{HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Klein, WEJ (Reprint Author), City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
   Klein, Wilhelm E. J., City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.}},
DOI = {{10.1108/JICES-11-2018-0089}},
ISSN = {{1477-996X}},
EISSN = {{1758-8871}},
Keywords = {{Ethics; Computer ethics; IT Ethics; Moral psychology; Information
   ethics; Exceptionalism; Materialism; Determinism; Consciousness;
   Technology ethics; Machine ethics; Philosophy of technology}},
Research-Areas = {{Social Sciences - Other Topics}},
Web-of-Science-Categories  = {{Ethics}},
Author-Email = {{mail@wilhelmklein.net}},
Cited-References = {{Anderson S.L., 2011, MACHINE ETHICS, P151.
   BIRCH TH, 1993, ENVIRON ETHICS, V15, P313, DOI 10.5840/enviroethics19931544.
   Bostrom N, 2014, CAMBRIDGE HANDBOOK OF ARTIFICIAL INTELLIGENCE, P316.
   Bourget D, 2014, PHILOS STUD, V170, P465, DOI 10.1007/s11098-013-0259-7.
   Bryson J. J., 2010, CLOSE ENGAGEMENTS AR, P63.
   Coeckelbergh M, 2010, ETHICS INF TECHNOL, V12, P209, DOI 10.1007/s10676-010-9235-5.
   Darling K, 2012, 2044797 SSRN.
   Dennett D, 2001, COGNITION, V79, P221, DOI 10.1016/S0010-0277(00)00130-X.
   Dennett D.C, 2006, INT COMP PHIL C LAV.
   Dennett D.C., 1995, DARWINS DANGEORUS ID.
   DENNETT DC, 1995, SOC RES, V62, P691.
   Ellegard Alvar, 1958, DARWIN GEN READER RE.
   Finocchiaro MA, 2010, BOST STUD PHILOS HIS, V280, P1.
   Floridi L., 1999, Ethics and Information Technology, V1, P37.
   Floridi L., 2014, 4 REVOLUTION INFOSPH.
   Floridi L, 2008, MIND MACH, V18, P303, DOI 10.1007/s11023-008-9113-7.
   Funk C., 2015, PEW RES CTR, V29, P1.
   Gunkel D. J., 2012, MACH QUEST CRIT.
   Gunkel DJ, 2018, ETHICS INF TECHNOL, V20, P87, DOI 10.1007/s10676-017-9442-4.
   Helmreich S., 1997, SCI CULTURE, V6, P363.
   Himma K.E., 2015, 2628858 SSRN.
   Hoorens V, 1993, EUROPEAN REV SOCIAL, V4, P113, DOI DOI 10.1080/14792779343000040.
   Klein W.E.J, 2017, VECTOR UTILITARIANIS.
   Klein WEJ, 2016, IEEE POTENTIALS, V35, P40, DOI 10.1109/MPOT.2016.2569742.
   Leopold A., 1986, SAND COUNTY ALMANAC.
   NAESS A, 1973, INQUIRY, V16, P95, DOI 10.1080/00201747308601682.
   Newport F, 2014, US 42 BEL CREAT VIEW.
   Paley W., 1823, NATURAL THEOLOGY TRA.
   Prinz Jesse, 2011, EMPATHY PHILOS PSYCH, P211, DOI {[}DOI 10.1093/ACPR0F:0S0/9780199539956.003.0014, 10.1093/acprof:oso/9780199539956.003.0014].
   Rolston H., 1999, SINGER HIS CRITICS, P247.
   Ross Lee, 1977, ADV EXPT SOCIAL PSYC, P173, DOI DOI 10.1016/S0065-2601(08)60357-3.
   Singer P., 2011, PRACTICAL ETHICS.
   Singer P, 2011, EXPANDING CIRCLE ETH.
   Sparrow R., 2004, Ethics and Information Technology, V6, P203, DOI 10.1007/s10676-004-6491-2.
   Taylor P. W., 2011, RESPECT NATURE THEOR.
   Westman Robert S., 2011, COPERNICAN QUESTION.
   Yudkowsky E., 2009, 3 WORLDS COLLIDE.}},
Number-of-Cited-References = {{37}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Journal-ISO = {{J. Inf. Commun. Ethics Soc.}},
Doc-Delivery-Number = {{JD8UL}},
Unique-ID = {{ISI:000490258800006}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000486572502021,
Author = {Lindner, Felix and Mattmueller, Robert and Nebel, Bernhard},
Book-Group-Author = {{AAAI}},
Title = {{Moral Permissibility of Action Plans}},
Booktitle = {{THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST
   INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH
   AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE}},
Year = {{2019}},
Pages = {{7635-7642}},
Note = {{33rd AAAI Conference on Artificial Intelligence / 31st Innovative
   Applications of Artificial Intelligence Conference / 9th AAAI Symposium
   on Educational Advances in Artificial Intelligence, Honolulu, HI, JAN
   27-FEB 01, 2019}},
Organization = {{Assoc Advancement Artificial Intelligence}},
Abstract = {{Research in classical planning so far was mainly concerned with
   generating a satisficing or an optimal plan. However, if such systems
   are used to make decisions that are relevant to humans, one should also
   consider the ethical consequences generated plans can have. We address
   this challenge by analyzing in how far it is possible to generalize
   existing approaches of machine ethics to automatic planning systems.
   Traditionally, ethical principles are formulated in an action-based
   manner, allowing to judge the execution of one action. We show how such
   a judgment can be generalized to plans. Further, we study the
   computational complexity of making ethical judgment about plans.}},
Publisher = {{ASSOC ADVANCEMENT ARTIFICIAL INTELLIGENCE}},
Address = {{2275 E BAYSHORE RD, STE 160, PALO ALTO, CA 94303 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Lindner, F (Reprint Author), Univ Freiburg, Freiburg, Germany.
   Lindner, Felix; Mattmueller, Robert; Nebel, Bernhard, Univ Freiburg, Freiburg, Germany.}},
ISBN = {{978-1-57735-809-1}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Author-Email = {{lindner@informatik.uni-freiburg.de
   mattmuel@informatik.uni-freiburg.de
   nebel@informatik.uni-freiburg.de}},
Cited-References = {{Anderson M., 2011, MACHINE ETHICS.
   Anderson M., 2005, AAAI FALL S.
   Asimov I, 1950, RUNAROUND.
   BACKSTROM C, 1995, COMPUT INTELL, V11, P625, DOI 10.1111/j.1467-8640.1995.tb00052.x.
   Berreby F, 2015, LECT NOTES COMPUT SC, V9450, P532, DOI 10.1007/978-3-662-48899-7\_37.
   Cresswell S. N., 2003, P 21 WORKSH UK PLANN, P22.
   Dennis L, 2016, ROBOT AUTON SYST, V77, P1, DOI 10.1016/j.robot.2015.11.012.
   Driver J., 2006, ETHICS FUNDAMENTALS.
   FOOT P., 1967, OXFORD REV.
   Fox M., 2005, P 20 NAT C ART INT A, V5, P1151.
   Ghallab M, 2016, AUTOMATED PLANNING A.
   Govindarajulu N. S., 2017, P 26 INT JOINT C ART, P4722.
   Lindner F, 2017, IEEE INT C INT ROBOT, P6991, DOI 10.1109/IROS.2017.8206625.
   Nevejans N, 2016, EUROPEAN CIVIL LAW R.
   Pereira L.M., 2017, P COGSCI 2017 WORKSH, P39.
   Rintanen J., 2003, Proceedings, Thirteenth International Conference on Automated Planning and Scheduling, P185.
   Smith D. E., 2004, P 14 INT C AUT PLANN, P393.
   WELD D, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1042.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BN6ZH}},
Unique-ID = {{ISI:000486572502021}},
DA = {{2020-06-17}},
}

@article{ ISI:000446208900001,
Author = {Trussell, H. Joel},
Title = {{Why a Special Issue on Machine Ethics}},
Journal = {{PROCEEDINGS OF THE IEEE}},
Year = {{2018}},
Volume = {{106}},
Number = {{10}},
Pages = {{1774-1776}},
Month = {{OCT}},
Publisher = {{IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC}},
Address = {{445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA}},
Type = {{Editorial Material}},
Language = {{English}},
DOI = {{10.1109/JPROC.2018.2868336}},
ISSN = {{0018-9219}},
EISSN = {{1558-2256}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Electrical \& Electronic}},
ORCID-Numbers = {{Trussell, Henry/0000-0002-8521-2269}},
Cited-References = {{Anderson M., P IEEE.
   Ema A., P IEEE.
   Korunovska J., P IEEE.
   Minsky M., 1972, PERCEPTRONS INTRO CO.}},
Number-of-Cited-References = {{4}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{Proc. IEEE}},
Doc-Delivery-Number = {{GV6HJ}},
Unique-ID = {{ISI:000446208900001}},
DA = {{2020-06-17}},
}

@article{ ISI:000441655000009,
Author = {Castell, Stephen},
Title = {{The future decisions of RoboJudge HHJ Arthur Ian Blockchain: Dread,
   delight or derision?}},
Journal = {{COMPUTER LAW \& SECURITY REVIEW}},
Year = {{2018}},
Volume = {{34}},
Number = {{4}},
Pages = {{739-753}},
Month = {{AUG}},
Abstract = {{Steve Saxby's prescient founding of CLSR, two hundred issues ago,
   encouraged and resonated with my own digital visionary thinking and
   professional activity in the evolving field of ICT and the Law. From
   Infolex, the UK's first commercially-available computer-assisted legal
   information retrieval service, and my APPEAL Report (on the
   admissibility of computer evidence in court and the legal
   reliability/security of IT systems), via my Forensic Systems Analysis
   expert methodology, to the nascent CryptoBlockTV, Steve's scholarly
   foresight in promoting adventurous exploration of `digilaw' high-ground
   topics and issues has presented me with opportunities to generate a
   stream of prescient material, for which I am immensely grateful. And
   what is beyond prescient today is that the Coming of the Robots is
   unstoppable. The Artificial Intelligence (AI) Age is upon us; RoboJudge
   has all but already arrived. While many are concerned about defining and
   developing Machine Ethics, Castell's Second Dictum: ``You cannot
   construct an algorithm that will reliably decide whether or not any
   algorithm is ethical{''} reveals that this is a futile exercise.
   Algorithms are also pivotal to the current mania for Crypto-Algorithmic
   Blockchain Technology Initial Coin Offerings (ICOs), with a `Crypto
   Tribe' of Millennials relentlessly raising billions in real money
   thereby, to the extent that I have dubbed Crypto the Millennials'
   Rock'n'Roll. The seasoned ICT expert professional however bears in mind
   that there are as yet no ISO standards for blockchain, and there is far
   more to creating and delivering a complete quality-assured system than
   just the blockchain component. Furthermore, the legal status of
   cryptocurrency, smart contract and distributed ledger technology is not
   clear or uncontentious - and there is already ICO litigation on foot.
   Nevertheless, taking my limerick-writing Castell GhostWriteBot's advice,
   it is perhaps time for my own asset-linked ICO, to launch my
   CapChere.com concept designed to reboot Capitalism and achieve
   ubiquitous universal share and wealth ownership. Look out for Castell
   GhostWriteBot's account (with or without limericks) of how I fared, in
   the 400th issue of CLSR. (C) 2018 Stephen Castell. Published by Elsevier
   Ltd. All rights reserved.}},
Publisher = {{ELSEVIER ADVANCED TECHNOLOGY}},
Address = {{OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON,
   OXFORD OX5 1GB, OXON, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Castell, S (Reprint Author), Castell Consulting, POB 334, Witham CM8 3LP, Essex, England.
   Castell, Stephen, Castell Consulting, POB 334, Witham CM8 3LP, Essex, England.}},
DOI = {{10.1016/j.clsr.2018.05.011}},
ISSN = {{0267-3649}},
Keywords = {{Intelligence; Blockchain; Robot; Ethic; Algorithm; Crypto}},
Research-Areas = {{Government \& Law}},
Web-of-Science-Categories  = {{Law}},
Author-Email = {{stephen@castellconsulting.com}},
ResearcherID-Numbers = {{Sanchez-Gomez, Nicolas/K-3758-2014}},
Cited-References = {{Anderson R., 1996, INFORM SECURITY B, V1.
   {[}Anonymous], 2013, COMPUTER LAW SECURIT, V29, P446.
   {[}Anonymous], 2017, CBC NEWS CANADA 0925.
   {[}Anonymous], 2016, A GRIFFIN MONDA 1024.
   {[}Anonymous], 1910, HENRY SOLOMON L 0311.
   Castell S., 1993, Computer Law and Security Report, V9, P155.
   Castell S., 1989, LEGAL ADMISSIBILITY, V2, P2.
   Castell S., 1994, COMPUTER SIMPLEST KI, V10, P158.
   Castell S., 1993, S210102 INFOSEC.
   CASTELL S P, 1973, PHYS B, P627.
   Castell Stephen, 1971, GONG MAGAZINE    DEC, P16.
   Castell Stephen, 1989, UPDATE COMPUTER AUDI, V2, P10.
   Castell Stephen, 1980, LAW SOC GAZETTE 0521.
   Castell Stephen, 1990, COMPUTER LAW SECURIT, V6, P2.
   Huang T, 2017, COMPUT LAW SECUR REV, V33, P802, DOI 10.1016/j.clsr.2017.05.016.
   James H., 2017, MATH TODAY, V53, P162.
   Leadership Conference on Civil and Human Rights, 2017, COMMUNICATION.
   Saxby S., 1987, CCTA BRAINSTORMER EX, V1, P6.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{6}},
Usage-Count-Since-2013 = {{51}},
Journal-ISO = {{Comput. Law Secur. Rev.}},
Doc-Delivery-Number = {{GQ4PK}},
Unique-ID = {{ISI:000441655000009}},
DA = {{2020-06-17}},
}

@article{ ISI:000437145100009,
Author = {Boyles, Robert James M.},
Title = {{A Case for Machine Ethics in Modeling Human-Level Intelligent Agents}},
Journal = {{KRITIKE-AN ONLINE JOURNAL OF PHILOSOPHY}},
Year = {{2018}},
Volume = {{12}},
Number = {{1}},
Pages = {{182-200}},
Month = {{JUN}},
Abstract = {{This paper focuses on the research field of machine ethics and how it
   relates to a technological singularity-a hypothesized, futuristic event
   where artificial machines will have greater-than-human-level
   intelligence. One problem related to the singularity centers on the
   issue of whether human values and norms would survive such an event. To
   somehow ensure this, a number of artificial intelligence researchers
   have opted to focus on the development of artificial moral agents, which
   refers to machines capable of moral reasoning, judgment, and
   decision-making. To date, different frameworks on how to arrive at these
   agents have been put forward. However, there seems to be no hard
   consensus as to which framework would likely yield a positive result.
   With the body of work that they have contributed in the study of moral
   agency, philosophers may contribute to the growing literature on
   artificial moral agency. While doing so, they could also think about how
   the said concept could affect other important philosophical concepts.}},
Publisher = {{UNIV SANTO TOMAS, FAC ARTS \& LETTERS}},
Address = {{RM 109, MAIN BLDG, ESPANA, MANILA, 1015, PHILIPPINES}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Boyles, RJM (Reprint Author), De La Salle Univ, Dept Philosophy, Manila, Philippines.
   Boyles, Robert James M., De La Salle Univ, Dept Philosophy, Manila, Philippines.}},
DOI = {{10.25138/12.1.a9}},
ISSN = {{1908-7330}},
Keywords = {{machine ethics; artificial moral agents; technological singularity;
   philosophy of artificial intelligence}},
Research-Areas = {{Philosophy}},
Web-of-Science-Categories  = {{Philosophy}},
ORCID-Numbers = {{Boyles, Robert James M./0000-0002-7623-4917}},
Cited-References = {{Anderson M., 2011, MACHINE ETHICS.
   Aquinas Thomas, 1952, SUMMA THEOLOGICA.
   Capek Karel, 2016, R U R.
   CARTER M, 2007, {[}No title captured].
   Chalmers DJ, 2010, J CONSCIOUSNESS STUD, V17, P7.
   Counet Jean-Michael, 2005, MATH DIVINE HIST STU.
   Denis Lara, 2012, STANFORD ENCY PHILOS.
   Denise Theodore C., 2008, GREAT TRADITIONS ETH.
   Eshleman A, 2014, STANFORD ENCY PHILOS.
   Garrett Brian, 1998, PERSONAL IDENTITY SE.
   Goertzel B, 2007, ARTIF INTELL, V171, P1161, DOI 10.1016/j.artint.2007.10.011.
   Good Irving John, 1966, ADV COMPUTERS, V6.
   Graesser Art, 1996, P 3 INT WORKSH AG TH.
   Greene B., 1999, ELEGANT UNIVERSE SUP.
   Hawking Stephen William, 1988, BRIEF HIST TIME.
   Himma K.E., 2009, ETHICS INFORM TECHNO, V11.
   Joaquin J. Joven, 2017, ORGANON F, V24, P2.
   Kant I., 2002, GROUNDWORK METAPHYSI.
   Kurzweil R., 2005, SINGULARITY IS NEAR.
   Loosemore Richard, 2011, HUMANITY MAGAZI 0307.
   Mabaquiao Napoleon, 2012, MIND SCI COMPUTATION.
   MCINERNY R, 1987, J MED ETHICS, V13, P31, DOI 10.1136/jme.13.1.31.
   Moor James H., 2011, MACHINE ETHICS.
   Moravec Hans P., 2002, UNDERSTANDING ARTIFI.
   Moser Walter, 1993, SUBSTANCE, V22.
   Muehlhauser Luke, 2014, THINK, V36, P13.
   Nadeau JE, 2006, THINKING ANDROID EPI.
   Paipetis SA, 2010, HIST MECH MACH SCI, V9, P1, DOI 10.1007/978-90-481-2514-2.
   Penrose Roger, 1991, WORLD TREASURY PHYS.
   Pfeifer R., 1999, UNDERSTANDING INTELL.
   Shanahan M., 2009, STANFORD ENCY PHILOS.
   Sullins John, 2009, HDB RES TECHNOETHICS.
   Vinge Vernor, 1993, VISION 21 INTERDISCI.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.
   Wittgenstein L., 1953, PHILOS INVESTIGATION.}},
Number-of-Cited-References = {{35}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{20}},
Journal-ISO = {{Kritike}},
Doc-Delivery-Number = {{GL4RX}},
Unique-ID = {{ISI:000437145100009}},
OA = {{DOAJ Gold, Green Published}},
DA = {{2020-06-17}},
}

@article{ ISI:000435398100016,
Author = {Kose, Utku},
Title = {{Are We Safe Enough in the Future of Artificial Intelligence? A
   Discussion on Machine Ethics and Artificial Intelligence Safety}},
Journal = {{BRAIN-BROAD RESEARCH IN ARTIFICIAL INTELLIGENCE AND NEUROSCIENCE}},
Year = {{2018}},
Volume = {{9}},
Number = {{2}},
Pages = {{184-197}},
Month = {{MAY}},
Abstract = {{Nowadays, there is a serious anxiety on the existence of dangerous
   intelligent systems and it is not just a science-fiction idea of evil
   machines like the ones in well-known Terminator movie or any other
   movies including intelligent robots - machines threatening the existence
   of humankind. So, there is a great interest in some alternative research
   works under the topics of Machine Ethics, Artificial Intelligence Safety
   and the associated research topics like Future of Artificial
   Intelligence and Existential Risks. The objective of this study is to
   provide a general discussion about the expressed research topics and try
   to find some answers to the question of `Are we safe enough in the
   future of Artificial Intelligence?'. In detail, the discussion includes
   a comprehensive focus on `dystopic' scenarios, enables interested
   researchers to think about some `moral dilemmas' and finally have some
   ethical outputs that are considerable for developing good intelligent
   systems. From a general perspective, the discussion taken here is a good
   opportunity to improve awareness on the mentioned, remarkable research
   topics associated with not only Artificial Intelligence but also many
   other natural and social sciences taking role in the humankind.}},
Publisher = {{EDUSOFT PUBLISHING}},
Address = {{9 MAI STR 82, BACAU, 600065, ROMANIA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Kose, U (Reprint Author), Suleyman Demirel Univ, Merkez Isparta, Turkey.
   Kose, Utku, Suleyman Demirel Univ, Merkez Isparta, Turkey.}},
ISSN = {{2067-3957}},
Keywords = {{artificial intelligence; machine learning; machine ethics; artificial
   intelligence safety; future of artificial intelligence}},
Keywords-Plus = {{MORALITY}},
Research-Areas = {{Neurosciences \& Neurology}},
Web-of-Science-Categories  = {{Neurosciences}},
Author-Email = {{utkukose@sdu.edu.tr}},
ResearcherID-Numbers = {{Kose, Utku/C-8683-2009}},
ORCID-Numbers = {{Kose, Utku/0000-0002-9652-6415}},
Cited-References = {{Abbeel P., 2011, ENCY MACHINE LEARNIN, P554.
   Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83.
   Amodei D., 2016, ARXIV160606565.
   Anderson M., 2011, MACHINE ETHICS.
   Anderson M, 2007, AI MAG, V28, P15.
   Armstrong S., 2016, UNC ART INT 32 C UAI, P557.
   Arnold T., 2017, 3 INT WORKSH AI ETH.
   Bostrom N., 2002, J EVOLUTION TECHNOLO, V9, P1.
   Bostrom N., 2003, SCI FICTION PHILOS T, P277.
   Bostrom N., 2014, SUPERINTELLIGENCE PA.
   Callaghan V, 2017, FRONT COLLECT, P1, DOI 10.1007/978-3-662-54033-6.
   Conitzer V, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4831.
   Dewey D., 2014, AAAI SPRING SERIES.
   Dubhashi D, 2017, COMMUN ACM, V60, P43, DOI 10.1145/2953876.
   Evans O, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P323.
   Evans  Owain, 2015, NIPS WORKSH BOUND OP, V6.
   Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d.
   Goodfellow I., 2017, ATTACKING MACHINE LE.
   Herzfeld Noreen, 2002, OUR IMAGE ARTIFICIAL.
   Hibbard B., 2014, ARXIV14111373.
   Holland O., 2003, MACHINE CONSCIOUSNES.
   Kose U., 2017, ART INT DAT PROC S I, P1.
   Lin P, 2012, INTELL ROBOT AUTON, P1.
   Lin X., 2017, IEEE T COMPUTATIONAL.
   McLaren BM, 2006, IEEE INTELL SYST, V21, P29, DOI 10.1109/MIS.2006.67.
   MIT Technology Review, 2014, DO WE NEED AS LAWS.
   Moor James H., 2009, PHILOS NOW, V72, P12.
   Muehlhauser L., 2012, SINGULARITY HYPOSTHE, V6, P1, DOI {[}10.1007/978-3-642-32560-1\_6., DOI 10.1007/978-3-642-32560-1\_6].
   Negnevitsky M., 2005, ARTIFICIAL INTELLIGE.
   Ng A. Y., 2000, P 17 INT C MACH LEAR, p663 , DOI DOI 10.2460/AJVR.67.2.323.
   Nicolescu B., 2017, TRANSDISCIPLINARY HI, P155.
   Pavaloiu A., 2017, J MULTIDISCIPLINARY, V2, P15.
   Perdue RT, 2017, SOC NATUR RESOUR, V30, P1026, DOI 10.1080/08941920.2016.1264652.
   Powers TM, 2011, IEEE ROBOT AUTOM MAG, V18, P51, DOI 10.1109/MRA.2010.940152.
   Riedl M. O, 2016, AAAI WORKSH AI ETH S.
   Russell S., 2003, ARTIFICIAL INTELLIGE, V2.
   Russell S, 2015, AI MAG, V36, P105, DOI 10.1609/aimag.v36i4.2577.
   Schneider Susan, 2016, SCI FICTION PHILOS T.
   Soares N., 2015, WORKSH 29 AAAI C ART.
   Torrance S, 2008, AI SOC, V22, P495, DOI 10.1007/s00146-007-0091-8.
   Vamplew P., 2017, ETHICS INF TECHNOL, P1.
   Wallach W, 2008, MORAL MACHINES TEACH.
   Wallach W, 2010, ETHICS INF TECHNOL, V12, P243, DOI 10.1007/s10676-010-9232-8.
   Yampolskiy RV, 2013, PHILOS THEORY ARTIFI, P389.}},
Number-of-Cited-References = {{45}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{45}},
Journal-ISO = {{BRAIN-Broad Res. Artif. Intellect. Neurosci.}},
Doc-Delivery-Number = {{GJ5CF}},
Unique-ID = {{ISI:000435398100016}},
OA = {{DOAJ Gold}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000450991000039,
Author = {Baniasadi, Zohreh and Parent, Xavier and Max, Charles and Cramer, Marcos},
Editor = {{Kurosu, M}},
Title = {{A Model for Regulating of Ethical Preferences in Machine Ethics}},
Booktitle = {{HUMAN-COMPUTER INTERACTION: THEORIES, METHODS, AND HUMAN ISSUES, HCI
   INTERNATIONAL 2018, PT I}},
Series = {{Lecture Notes in Computer Science}},
Year = {{2018}},
Volume = {{10901}},
Pages = {{481-506}},
Note = {{20th International Conference on Human-Computer Interaction (HCI
   International), Las Vegas, NV, JUL 15-20, 2018}},
Abstract = {{Relying upon machine intelligence with reductions in the supervision of
   human beings, requires us to be able to count on a certain level of
   ethical behavior from it. Formalizing ethical theories is one of the
   plausible ways to add ethical dimensions to machines. Rule-based and
   consequence-based ethical theories are proper candidates for Machine
   Ethics. It is debatable that methodologies for each ethical theory
   separately might result in an action that is not always justifiable by
   human values. This inspires us to combine the reasoning procedure of two
   ethical theories, deontology and utilitarianism, in a utilitarian-based
   deontic logic which is an extension of STIT (Seeing To It That) logic.
   We keep the knowledge domain regarding the methodology in a knowledge
   base system called IDP. IDP supports inferences to examine and evaluate
   the process of ethical decision making in our formalization. To validate
   our proposed methodology we perform a Case Study for some real scenarios
   in the domain of robotics and automatous agents.}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Baniasadi, Z (Reprint Author), Univ Luxembourg, Interdisciplinary Ctr Secur \& Trust, Luxembourg, Luxembourg.
   Baniasadi, Zohreh; Parent, Xavier; Max, Charles; Cramer, Marcos, Univ Luxembourg, Interdisciplinary Ctr Secur \& Trust, Luxembourg, Luxembourg.}},
DOI = {{10.1007/978-3-319-91238-7\_39}},
ISSN = {{0302-9743}},
EISSN = {{1611-3349}},
ISBN = {{978-3-319-91238-7; 978-3-319-91237-0}},
Keywords-Plus = {{DELIBERATIVE STIT}},
Research-Areas = {{Computer Science; Social Issues}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Social Issues}},
Author-Email = {{zohreh.baniasadi@uni.lu
   xavier.parent@uni.lu
   chalres.max@uni.lu
   marcos.cramer@uni.lu}},
ResearcherID-Numbers = {{Parent, Xavier/AAE-4579-2020}},
Cited-References = {{Allen C, 2009, MORAL MACHINES TEACH.
   Anderson M., 2011, MACHINE ETHICS.
   Arkoudas K., 2005, AAAI FALL S MACH ETH.
   Balbiani P, 2008, J PHILOS LOGIC, V37, P387, DOI 10.1007/s10992-007-9078-7.
   Belnap N, 2001, FACING FUTURE AGENTS.
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82.
   Broersen J, 2011, J APPL LOGIC, V9, P137, DOI 10.1016/j.jal.2010.06.002.
   Denecker M, 2008, ACM T COMPUT LOG, V9, DOI 10.1145/1342991.1342998.
   Denecker M, 2008, LECT NOTES COMPUT SC, V5366, P71, DOI 10.1007/978-3-540-89982-2\_12.
   Gabbay D, 2013, HDB DEONTIC LOGIC NO.
   Goble L., 2000, NORDIC J PHILOS LOGI, V5, P113.
   Goodall NJ, 2014, LECT N MOBIL, P93, DOI 10.1007/978-3-319-05990-7\_9.
   Goodall NJ, 2014, TRANSPORT RES REC, P58, DOI 10.3141/2424-07.
   Harsanyi JC, 1976, ESSAYS ETHICS SOCIAL, P6, DOI DOI 10.1007/978-94-010-9327-9\_2.
   Herzig A, 2008, ADV MODAL LOGIC, P133.
   Horty J. F., 2001, AGENCY DEONTIC LOGIC.
   HORTY JF, 1995, J PHILOS LOGIC, V24, P583, DOI 10.1007/BF01306968.
   Johnson D. G, 1985, PHILOS COMPUTING INF, P65.
   Lang J, 2008, FRONT ARTIF INTEL AP, V178, P351, DOI 10.3233/978-1-58603-891-5-351.
   Lorini Emiliano, 2013, Journal of Applied Non-Classical Logics, V23, P372, DOI 10.1080/11663081.2013.841359.
   Lorini E, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS \& MULTIAGENT SYSTEMS, P885.
   Marien M., 2006, SEARCH LOGIC ANSWER, P19.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Prior Arthur N, 1967, PRESENT FUTURE, V154.
   Shafer-Landau R., 2012, ETHICAL THEORY ANTHO, V13.
   Tzafestas S. G, 2016, ISCASE, V79, P65, DOI {[}10.1007/978-3-319-21714-75, DOI 10.1007/978-3-319-21714-7\_5].
   Wittocx J, 2010, P 22 BEN C ART INT.
   Wooldridge M, 2000, FOURTH INTERNATIONAL CONFERENCE ON MULTIAGENT SYSTEMS, PROCEEDINGS, P13, DOI 10.1109/ICMAS.2000.858426.
   Yin R. K., 2003, APPL SOCIAL RES METH, V5, pXVI.}},
Number-of-Cited-References = {{29}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BL4XF}},
Unique-ID = {{ISI:000450991000039}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000448247800024,
Author = {Cadzow, Scott},
Editor = {{Nicholson, D}},
Title = {{Preserving Dignity, Maintaining Security and Acting Ethically}},
Booktitle = {{ADVANCES IN HUMAN FACTORS IN CYBERSECURITY}},
Series = {{Advances in Intelligent Systems and Computing}},
Year = {{2018}},
Volume = {{593}},
Pages = {{257-268}},
Note = {{AHFE International Conference on Human Factors in Cybersecurity, Los
   Angeles, CA, JUL 17-21, 2017}},
Abstract = {{Humans design, operate and are the net beneficiaries of most systems.
   However humans are fallible and make mistakes. At the same time humans
   are adaptable and resourceful in both designing systems and correcting
   them when they go wrong. In contrast machines have in the main been
   designed to follow rules and are often constrained to produce the same
   output for the same input over and over again. Ethical decisions require
   that different outputs arise from apparently identical appearing inputs
   as the wider context for the decision has changed. Humans make ethical
   decisions almost automatically but as we move towards an increasingly
   machine led society those aspects of dignity, ethics and security which
   are managed by humans will be addressed by machines. The aim of this
   paper is to give an overview of the state of the art in security
   standardization in machine to machine and IoT systems, for the use cases
   of eHealth and autonomous transport systems, in order to outline the new
   ethics and security challenges of the machine led society. This will
   consider progress being made in standards towards the ideal of each of a
   Secure and Privacy Preserving Turing Machine and of an Ethical Turing
   Machine.}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Cadzow, S (Reprint Author), Cadzow Commun Consulting Ltd, 10 Yewlands, Sawbridgeworth CM21 9NP, England.
   Cadzow, Scott, Cadzow Commun Consulting Ltd, 10 Yewlands, Sawbridgeworth CM21 9NP, England.}},
DOI = {{10.1007/978-3-319-60585-2\_24}},
ISSN = {{2194-5357}},
EISSN = {{2194-5365}},
ISBN = {{978-3-319-60585-2; 978-3-319-60584-5}},
Keywords = {{Human factors; Security; Ethics; Machine ethics}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering}},
Author-Email = {{scott@cadzow.com}},
Funding-Acknowledgement = {{EU project i-locate {[}621040]; EU project UNCAP {[}643555]; EU project
   SUNSHINE {[}325161]}},
Funding-Text = {{Contributions made by the author in development of this paper have in
   part been supported by EU projects i-locate (grant number 621040),
   SUNSHINE (grant number 325161) and UNCAP (grant number 643555).}},
Cited-References = {{{[}Anonymous], 1021651CYBER ETSI TS.
   Luft J., 1955, P W TRAINING LABORAT.}},
Number-of-Cited-References = {{2}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BL1SE}},
Unique-ID = {{ISI:000448247800024}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000444812600018,
Author = {Heuer, Tanja and Schiering, Ina and Gerndt, Reinhard},
Editor = {{Hansen, M and Kosta, E and NaiFovino, I and FischerHubner, S}},
Title = {{Privacy and Socially Assistive Robots - A Meta Study}},
Booktitle = {{PRIVACY AND IDENTITY MANAGEMENT: THE SMART REVOLUTION}},
Series = {{IFIP Advances in Information and Communication Technology}},
Year = {{2018}},
Volume = {{526}},
Pages = {{265-281}},
Note = {{12th IFIP WG 9.2, 9.5, 9.6/11.7, 11.6/SIG 9.2.2 International Summer
   School - The Smart Revolution, Ispra, ITALY, SEP 04-08, 2017}},
Organization = {{Int Federat Informat Proc Working Grp 9 2; Int Federat Informat Proc
   Working Grp 9 5; Int Federat Informat Proc Working Grp 9 6 11 7; Int
   Federat Informat Proc Working Grp 11 6; Int Federat Informat Proc
   Working Grp Special Interst Grp 9 2 2}},
Abstract = {{This paper investigates studies about socially assistive robotics with
   focus on privacy and ethical concerns. Therefore, the privacy aspects
   are considered and the concerns expressed by users with regard to
   privacy are examined additionally. It becomes clear, there are still a
   lot of concerns regarding the use of robots, that's why robots are not
   well accepted so far. To get a more transparent view on that, two models
   are introduced which might improve the understanding towards important
   privacy aspects.}},
Publisher = {{SPRINGER-VERLAG BERLIN}},
Address = {{HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Schiering, I (Reprint Author), Ostfalia Univ Appl Sci, Wolfenbuttel, Germany.
   Heuer, Tanja; Schiering, Ina; Gerndt, Reinhard, Ostfalia Univ Appl Sci, Wolfenbuttel, Germany.}},
DOI = {{10.1007/978-3-319-92925-5\_18}},
ISSN = {{1868-4238}},
EISSN = {{1868-422X}},
ISBN = {{978-3-319-92925-5; 978-3-319-92924-8}},
Keywords = {{Socially assistive robot; Robot ethics; HRI; Human-robot interaction;
   Human-robot friendship; Machine ethics; Privacy}},
Keywords-Plus = {{NURSING-HOMES; CHILDREN; THERAPY; ROBOVIE}},
Research-Areas = {{Computer Science; Telecommunications}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Telecommunications}},
Author-Email = {{ta.heuer@ostfalia.de
   i.schiering@ostfalia.de
   r.gerndt@ostfalia.de}},
ORCID-Numbers = {{Schiering, Ina/0000-0002-7864-5437}},
Funding-Acknowledgement = {{Ministry for Science and Culture of Lower Saxony as part of the program
   ``Gendered Configurations of Humans and Machines (KoMMa.G){''}}},
Funding-Text = {{This work was supported by the Ministry for Science and Culture of Lower
   Saxony as part of the program ``Gendered Configurations of Humans and
   Machines (KoMMa.G){''}.}},
Cited-References = {{Banks MR, 2008, J AM MED DIR ASSOC, V9, P173, DOI 10.1016/j.jamda.2007.11.007.
   Beer JM, 2011, ACMIEEE INT CONF HUM, P19, DOI 10.1145/1957656.1957665.
   Breazeal C, 2007, ROBOTIC PRODUCTS BEC.
   Breazeal C., 2002, INTELLIGENT ROBOTICS.
   Breazeal C, 2015, SOCIAL ROBOT EVERY H.
   Broadbent E, 2009, INT J SOC ROBOT, V1, P319, DOI 10.1007/s12369-009-0030-6.
   Broadbent E., 2011, AAAI WORKSH C ART IN.
   Coeckelbergh M, 2016, SCI ENG ETHICS, V22, P47, DOI 10.1007/s11948-015-9649-x.
   de Graaf MMA, 2015, LECT NOTES ARTIF INT, V9388, P184, DOI 10.1007/978-3-319-25554-5\_19.
   de Graaf MMA, 2016, INT J SOC ROBOT, V8, P589, DOI 10.1007/s12369-016-0368-5.
   de Graaf MMA, 2015, COMPUT HUM BEHAV, V43, P1, DOI 10.1016/j.chb.2014.10.030.
   deGraaf M., 2017, P 2017 ACM IEEE INT, P224.
   Denning T, 2009, UBICOMP'09: PROCEEDINGS OF THE 11TH ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P105.
   DiSalvo C. F., 2002, P 4 C DES INT SYST P, P321, DOI DOI 10.1145/778712.778756.
   Doring N., 2016, STUD HLTH TECHNOL IN, V219, P147.
   Duffy BR, 2003, ROBOT AUTON SYST, V42, P177, DOI 10.1016/S0921-8890(02)00374-3.
   Feil-Seifer D, 2011, IEEE ROBOT AUTOM MAG, V18, P24, DOI 10.1109/MRA.2010.940150.
   Fernaeus Y., 2010, DO YOU PLAY ROBOTIC.
   Fink Julia, 2011, Social Robotics. Proceedings Third International Conference (ICSR 2011), P204, DOI 10.1007/978-3-642-25504-5\_21.
   Fink J, 2013, INT J SOC ROBOT, V5, P389, DOI 10.1007/s12369-013-0190-2.
   Finn R.L., 2013, EUROPEAN DATA PROTEC, P3, DOI DOI 10.1007/978-94-007-5170-5\_1.
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X.
   Heerink M., 2008, J PHYS AGENTS, V2, P33, DOI DOI 10.14198/J0PHA.2008.2.2.05.
   International Federation of Robotics, EX SUMM WORLD ROB 20.
   JaYoung Sung, 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P45.
   Kahn PH, 2006, INTERACT STUD, V7, P405, DOI 10.1075/is.7.3.13kah.
   Kahn PH, 2012, DEV PSYCHOL, V48, P303, DOI 10.1037/a0027033.
   Kanda T, 2004, HUM-COMPUT INTERACT, V19, P61, DOI 10.1207/s15327051hci1901\&2\_4.
   Kheng Lee Koay, 2007, 16th IEEE International Conference on Robot and Human Interactive Communication, P564.
   Kidd CD, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3230, DOI 10.1109/IROS.2008.4651113.
   Klamer T, 2011, L N INST COMP SCI SO, V59, P74.
   Koay K, 2011, MIXED REALITY HUMAN, P133, DOI DOI 10.1007/978-94-007-0582-1\_8.
   Koay K. L., 2009, ADV COMP HUM INT 200, P219.
   Kozima H, 2009, INT J SOC ROBOT, V1, P3, DOI 10.1007/s12369-008-0009-8.
   Lee HR, 2017, ACMIEEE INT CONF HUM, P244, DOI 10.1145/2909824.3020237.
   Lee KM, 2006, J COMMUN, V56, P754, DOI 10.1111/j.1460-2466.2006.00318.x.
   Leite Iolanda, 2009, RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication, P669, DOI 10.1109/ROMAN.2009.5326256.
   Leite I, 2013, INT J SOC ROBOT, V5, P291, DOI 10.1007/s12369-013-0178-y.
   Murphy R, 2009, IEEE INTELL SYST, V24.
   Pineau J, 2003, ROBOT AUTON SYST, V42, P271, DOI 10.1016/S0921-8890(02)00381-0.
   Robinson H, 2013, J AM MED DIR ASSOC, V14, P661, DOI 10.1016/j.jamda.2013.02.007.
   Sabelli AM, 2016, INT J SOC ROBOT, V8, P211, DOI 10.1007/s12369-015-0332-9.
   Scassellati BM, 2001, THESIS.
   Scheeff M, 2002, MU S ART SOC SIM ORG, V3, P173.
   Schmitt C., 2017, MENSCH COMPUTER 2017.
   Shamsuddin S, 2012, PROCEDIA ENGINEER, V41, P1448, DOI 10.1016/j.proeng.2012.07.334.
   Sharkey Amanda, 2012, Ethics and Information Technology, V14, P27, DOI 10.1007/s10676-010-9234-6.
   Stanton C. M., 2008, P 3 ACM IEEE INT C H, P271, DOI {[}10.1145/1349822.1349858, DOI 10.1145/1349822.1349858].
   Syrdal DS, 2014, COGN COMPUT, V6, P741, DOI 10.1007/s12559-014-9284-x.
   Syrdal DS, 2007, P WORKSH HUM IMPL HU, P28.
   Tao Vincent, 2016, PHARM TODAY, V22, P38.
   Wada Kazuyoshi, 2009, 2009 IEEE International Conference on Rehabilitation Robotics: Reaching Users \& the Community (ICORR), P930, DOI 10.1109/ICORR.2009.5209495.
   Wada K, 2007, IEEE T ROBOT, V23, P972, DOI 10.1109/TRO.2007.906261.
   Wagemaker E, 2017, J MENTAL HLTH RES IN, V10, P1.
   Wainer J, 2014, INT J SOC ROBOT, V6, P45, DOI 10.1007/s12369-013-0195-x.
   Weiss A, 2009, INT J SOC ROBOT, V1, P243, DOI 10.1007/s12369-009-0024-4.
   Weiss A, 2010, ACMIEEE INT CONF HUM, P23, DOI 10.1109/HRI.2010.5453273.}},
Number-of-Cited-References = {{57}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BK9QD}},
Unique-ID = {{ISI:000444812600018}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000510018100042,
Author = {Scheessele, Michael R.},
Book-Group-Author = {{ACM}},
Title = {{A Framework for Grounding the Moral Status of Intelligent Machines}},
Booktitle = {{PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY
   (AIES'18)}},
Year = {{2018}},
Pages = {{251-256}},
Note = {{AAAI/ACM Conference on AI, Ethics, and Society (AIES), New Orleans, LA,
   FEB 02-03, 2018}},
Organization = {{AAAI; Assoc Comp Machinery; ACM SIGAI; Berkeley Existential Risk
   Initiat; DeepMind Eth \& Soc; Future Life Inst; IBM Res AI;
   PriceWaterhouse Coopers; Tulane Univ}},
Abstract = {{I propose a framework, derived from moral theory, for assessing the
   moral status of intelligent machines. Using this framework, I claim that
   some current and foreseeable intelligent machines have approximately as
   much moral status as plants, trees, and other environmental entities.
   This claim raises the question: what obligations could a moral agent
   (e.g., a normal adult human) have toward an intelligent machine? I
   propose that the threshold for any moral obligation should be the
   ``functional morality of Wallach and Allen {[}20], while the upper limit
   of our obligations should not exceed the upper limit of our obligations
   toward plants, trees, and other environmental entities.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Scheessele, MR (Reprint Author), Indiana Univ, Comp Sci \& Psychol, South Bend, IN 46615 USA.
   Scheessele, Michael R., Indiana Univ, Comp Sci \& Psychol, South Bend, IN 46615 USA.}},
DOI = {{10.1145/3278721.3278743}},
ISBN = {{978-1-4503-6012-8}},
Keywords = {{Machine Ethics}},
Research-Areas = {{Computer Science; Biomedical Social Sciences}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Social Sciences, Biomedical}},
Author-Email = {{mscheess@iusb.edu}},
Funding-Acknowledgement = {{Indiana University New Frontiers in the Arts and Humanities
   Experimentation Fellowship}},
Funding-Text = {{This research was funded by an Indiana University New Frontiers in the
   Arts and Humanities Experimentation Fellowship.}},
Cited-References = {{Basl J, 2013, BASIC BIOETH, P89.
   Boldt J, 2008, NAT BIOTECHNOL, V26, P387, DOI 10.1038/nbt0408-387.
   Briggs G, 2017, SCI AM, V316, P44.
   DeGrazia D, 2002, ANIMAL RIGHTS VERY S.
   Dennett D. I., 1978, BRAINSTORMS PHILOS E.
   Floridi L., 2008, INFORM TECHNOLOGY MO.
   Gert Bernard, 2017, STANFORD ENCY PHILOS.
   Gunkel D, 2012, MACHINE QUESTION CRI.
   Jaworska A., 2017, STANFORD ENCY PHILOS.
   Kant I., 1785, GROUNDWORK METAPHYSI.
   KAUFMAN F, 1994, ENVIRON ETHICS, V16, P57, DOI 10.5840/enviroethics199416142.
   Kolak D., 2006, COGNITIVE SCI INTRO.
   Lu TK, 2016, SCI AM, V314, P59.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Rachels J., 2004, ANIMAL RIGHTS CURREN, P162.
   Sandler R, 2012, SYNTHESE, V185, P89, DOI 10.1007/s11229-011-9877-9.
   Singer P., 1974, PHILOS EXCHANGE, V1, P103.
   STERBA James P., 2005, TRIUMPH PRACTICE THE.
   Torrance S, 2008, AI SOC, V22, P495, DOI 10.1007/s00146-007-0091-8.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.
   Zahavi D, 2003, HUSSERLS PHENOMENOLO.}},
Number-of-Cited-References = {{21}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BO3EM}},
Unique-ID = {{ISI:000510018100042}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000491248900042,
Author = {Sengupta, Eishvak and Garg, Dhruv and Choudhury, Tanupriya and Aggarwal,
   Archit},
Editor = {{Dwivedi, RK and Wahab, NIB and Ather, D and Parygin, D and Saxena, AK and Agarwal, AK and Yadav, V}},
Title = {{Techniques to Elimenate Human Bias in Machine Learning}},
Booktitle = {{PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON SYSTEM MODELING \&
   ADVANCEMENT IN RESEARCH TRENDS (SMART)}},
Year = {{2018}},
Pages = {{226-230}},
Note = {{7th International Conference on System Modeling and Advancement in
   Research Trends (SMART), Moradabad, INDIA, NOV 23-24, 2018}},
Organization = {{IEEE Uttar Pradesh Sect; iNurture Educ Solut Private Ltd; CETPA Pvt Ltd;
   Teerthanker Mahaveer Univ, Coll Comp Sci \& Informat Technol;
   Teerthanker Mahaveer Univ}},
Abstract = {{In an era where human lives have certain dependence on artificial
   intelligence and machine learning, it is essential for them to make
   unbiased and accurate predictions. This paper addresses the issue of the
   inclusion of a human bias in a machine learning algorithm and how it
   goes to produce skewed results. It goes through the prominent types of
   human biases and real life incidents where the inclusion of a human bias
   has had a negative impact. This paper provides a comprehensive review of
   the methods that can be incorporated to eliminate a human bias focusing
   on the use of machine ethics making mention of community groups working
   towards the same.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Sengupta, E (Reprint Author), Amity Univ, Noida, Uttar Pradesh, India.
   Sengupta, Eishvak; Garg, Dhruv; Aggarwal, Archit, Amity Univ, Noida, Uttar Pradesh, India.
   Choudhury, Tanupriya, Univ Petr \& Energy Studies, Dehra Dun, Uttarakhand, India.}},
ISBN = {{978-1-5386-6369-1}},
Keywords = {{Artificial Intelligence; Machine Learning; Human Bias; Skewed results;
   Bias dataset}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Engineering, Electrical \&
   Electronic}},
Author-Email = {{eishvaksengupta@gmail.com
   dhruv98garg@gmail.com
   tanupriya1986@gmail.com
   archit.aggarwal1508@gmail.com}},
ResearcherID-Numbers = {{Choudhury, Tanupriya/AAB-8947-2020}},
ORCID-Numbers = {{Choudhury, Tanupriya/0000-0002-9826-2759}},
Cited-References = {{Albayrak N., 2018, 2018 26 SIGN PROC CO.
   Buolamwini Joy, 2018, FACIAL RECOGNITION S.
   Buscema P. M., 2013, INTELLIGENT DATA MIN.
   Chakravorty Tanushri, 2016, MACHINE LEARNING WOR.
   Ellis G., 2018, COGNITIVE BIASES VIS.
   Fuchs Daniel James, 2018, DANGERS HUMAN LIKE B.
   Howard A, 2017, IEEE WORK ADV ROBOT.
   Lary DJ, 2016, GEOSCI FRONT, V7, P3, DOI 10.1016/j.gsf.2015.07.003.
   Lum Kristian, 2016, PREDICTIVE POLICING.
   Meng J., 2012, 2012 4 INT C COMP IN.
   Sweeney L., 2013, DISCRIMINATION ONLIN.
   Tatman Rachael, GENDER DIALECT BIAS.}},
Number-of-Cited-References = {{12}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BO0IO}},
Unique-ID = {{ISI:000491248900042}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000457793300037,
Author = {Waechter, Laura and Lindner, Felix},
Book-Group-Author = {{ACM}},
Title = {{An Explorative Comparison of Blame Attributions to Companion Robots
   Across Various Moral Dilemmas}},
Booktitle = {{HAI'18: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT
   INTERACTION}},
Year = {{2018}},
Pages = {{269-276}},
Note = {{6th International Conference on Human-Agent Interaction (HAI),
   Southampton, ENGLAND, DEC 15-18, 2018}},
Organization = {{Assoc Comp Machinery; ADK; Cocoro SB; THALES; Cognit Interact Design;
   DEEPCORE; Assoc Comp Machinery SIGCHI}},
Abstract = {{We report results from an exploratory study with a humanoid robot asking
   participants (n = 30) to attribute blameworthiness to other robots that
   made decisions in moral dilemmas. Drawing from current research in
   machine ethics, we identify three ethical theories that have been
   formalized for the use in robots: Utilitarianism, Deontology, and
   Value-based ethics. We aligned these ethical theories with the
   attributions of blame. Our results suggest that a utilitarian robot,
   although attractive from a computational point of view because of its
   calculative nature, accumulates most blame across several dilemmas as
   compared to its alternatives-most significantly in dilemmas that occur
   in everyday life. Therefore ethical decision making for companion robots
   may best be implemented using rule-based or value-based procedures
   rather than utilitarian calculi.}},
Publisher = {{ASSOC COMPUTING MACHINERY}},
Address = {{1515 BROADWAY, NEW YORK, NY 10036-9998 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Wachter, L (Reprint Author), Univ Freiburg, Freiburg, Germany.
   Waechter, Laura; Lindner, Felix, Univ Freiburg, Freiburg, Germany.}},
DOI = {{10.1145/3284432.3284463}},
ISBN = {{978-1-4503-5953-5}},
Keywords = {{HRI; Moral Judgment; Blame; Ethics; Value Ethics}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic}},
Author-Email = {{waechtel@informatik.uni-freiburg.de
   lindner@informatik.uni-freiburg.de}},
Cited-References = {{Abel David, 2016, AAAI WORKSH AI ETH S, V92.
   Arkin R. C., 2009, GOVERNING LETHAL BEH.
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654.
   Bringsjord S, 2012, INTELL ROBOT AUTON, P85.
   Cranefield S., 2017, P 26 INT JOINT C ART, P178, DOI {[}10.24963/ijcai.2017/26, DOI 10.24963/IJCAI.2017/26].
   Dennis L, 2016, ROBOT AUTON SYST, V77, P1, DOI 10.1016/j.robot.2015.11.012.
   Dignum Virginia, 2017, P 26 INT JOINT C ART, P4698.
   Driver J, 2014, STANFORD ENCY PHILOS.
   Govindarajulu N. S., 2017, P 26 INT JOINT C ART, P4722.
   Groom V, 2010, ACMIEEE INT CONF HUM, P211, DOI 10.1109/HRI.2010.5453192.
   JONES TM, 1991, ACAD MANAGE REV, V16, P366, DOI 10.2307/258867.
   Kaniarasu P, 2014, IEEE ROMAN, P850, DOI 10.1109/ROMAN.2014.6926359.
   Kim T., 2006, 15 IEEE INT S ROB HU, P80, DOI DOI 10.1109/ROMAN.2006.314398.
   Lindner F., 2017, HRI 17 COMP 2017 ACM, P187, DOI DOI 10.1145/3029798.3038404.
   Lindner F, 2017, IEEE INT C INT ROBOT, P6991, DOI 10.1109/IROS.2017.8206625.
   Lindner Felix, 2018, P 14 INT C DEONT LOG.
   Lindner Felix, 2017, P 2017 IEEE INT S RO.
   Malle BF, 2016, ELEVENTH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN ROBOT INTERACTION (HRI'16), P125, DOI 10.1109/HRI.2016.7451743.
   Malle BF, 2014, PSYCHOL INQ, V25, P251, DOI {[}10.1080/1047840X.2014.913379, 10.1080/1047840X.2014.877340].
   Schwartz S. H., 2012, ONLINE READINGS PSYC, V2, P1, DOI {[}DOI 10.9707/2307-0919.1116, 10.9707/2307-0919.1116].
   Stellmach Hannah, 2018, MENSCH COMPUTER 2018.
   Winfield Alan F. T., 2014, Advances in Autonomous Robotics Systems. 15th Annual Conference (TAROS 2014). Proceedings: LNCS 8717, P85, DOI 10.1007/978-3-319-10401-0\_8.}},
Number-of-Cited-References = {{22}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BL9NS}},
Unique-ID = {{ISI:000457793300037}},
DA = {{2020-06-17}},
}

@article{ ISI:000414935800010,
Author = {Bertram, Jutta},
Title = {{300 Keywords Information Ethics. Basic knowledge of Computer-, Network
   and New-Media-Ethics as well as Machine Ethics}},
Journal = {{INFORMATION-WISSENSCHAFT UND PRAXIS}},
Year = {{2017}},
Volume = {{68}},
Number = {{5-6, SI}},
Pages = {{383-384}},
Month = {{OCT}},
Publisher = {{WALTER DE GRUYTER GMBH}},
Address = {{GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY}},
Type = {{Book Review}},
Language = {{German}},
ISSN = {{1434-4653}},
EISSN = {{1619-4292}},
Research-Areas = {{Computer Science; Information Science \& Library Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems; Information Science \& Library
   Science}},
Author-Email = {{jutta.bertram@fh-hannover.de}},
Cited-References = {{Bendel O, 2016, 300 KEYWORDS INFORMA.
   Heesen Jessica, 2016, HDB MEDIEN INFORMATI.}},
Number-of-Cited-References = {{2}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{3}},
Journal-ISO = {{Inform.-Wiss. Prax.}},
Doc-Delivery-Number = {{FM3UX}},
Unique-ID = {{ISI:000414935800010}},
DA = {{2020-06-17}},
}

@article{ ISI:000400788600021,
Author = {Kowalski, Robert},
Title = {{Programming Machine Ethics by Luis Moniz Pereira and Ari Saptawijaya}},
Journal = {{AI \& SOCIETY}},
Year = {{2017}},
Volume = {{32}},
Number = {{2, SI}},
Pages = {{299-300}},
Month = {{MAY}},
Publisher = {{SPRINGER}},
Address = {{233 SPRING ST, NEW YORK, NY 10013 USA}},
Type = {{Book Review}},
Language = {{English}},
Affiliation = {{Kowalski, R (Reprint Author), Imperial Coll London, Dept Comp, 180 Queens Gate, London SW7 2BZ, England.
   Kowalski, Robert, Imperial Coll London, Dept Comp, 180 Queens Gate, London SW7 2BZ, England.}},
DOI = {{10.1007/s00146-017-0690-y}},
ISSN = {{0951-5666}},
EISSN = {{1435-5655}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence}},
Author-Email = {{rak@doc.ic.ac.uk}},
Cited-References = {{KOWALSKI R, 2017, PROGRAMMING MACHINE.}},
Number-of-Cited-References = {{1}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Journal-ISO = {{AI Soc.}},
Doc-Delivery-Number = {{EU1OB}},
Unique-ID = {{ISI:000400788600021}},
OA = {{Other Gold}},
DA = {{2020-06-17}},
}

@article{ ISI:000434030400006,
Author = {Ienca, Marcello},
Title = {{COGNITIVE TECHNOLOGY AND HUMAN-MACHINE INTERACTION: THE CONTRIBUTION OF
   EXTERNALISM TO THE THEORETICAL FOUNDATIONS OF MACHINE AND CYBORG ETHICS}},
Journal = {{ANALELE UNIVERSITATII BUCURESTI-FILOSOFIE-ANNALS OF THE UNIVERSITY OF
   BUCHAREST-PHILOSOPHY}},
Year = {{2017}},
Volume = {{66}},
Number = {{2}},
Pages = {{91-115}},
Abstract = {{Machine ethics is the branch of ethics concerned with the behavior of
   artificially intelligent systems. Cyborg ethics is the related field of
   investigation concerned with the ethics of human-machine hybrid systems.
   While these areas of ethical investigation are experiencing rapid growth
   urged by disruptive advances in artificial intelligence, robotics and
   human-machine interaction, yet their theoretical foundations continue to
   elude consensus among researchers. In fact, most attention in machine
   and cyborg ethics has been devoted to normative and applied ethical
   questions concerning the moral status of artificially intelligent
   systems, the moral permissibility of their application in specific
   contexts, and the normative principles governing the interaction between
   artificially intelligent systems and humans. While cyborg ethicists have
   discussed the ethical implications of integrating man and machines,
   machine ethicists have long debated on whether artificially intelligent
   systems have the cognitive capacities necessary for the attribution of
   moral status. It remains unexplored, however, what theory of cognition
   is best placed to explain and assess these cognitive capacities or
   competent actions, especially in relation to human-machine interaction.
   This contribution aims at harmonizing the theoretical foundations of,
   respectively, machine and cyborg ethics and argues that an externalist
   account of cognition based on the notion of extended mind might offer a
   valid substrate for such harmonization.}},
Publisher = {{EDITURA UNIV BUCURESTI}},
Address = {{SOSEAUA PANDURI 90-92, SECTOR 5, BUCHAREST, 00000, ROMANIA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Ienca, M (Reprint Author), Univ Basel, Inst Biomed Eth, Basel, Switzerland.
   Ienca, M (Reprint Author), Swiss Fed Inst Technol, Dept Hlth Sci \& Technol, Hlth Eth \& Policy Lab, Zurich, Switzerland.
   Ienca, Marcello, Univ Basel, Inst Biomed Eth, Basel, Switzerland.
   Ienca, Marcello, Swiss Fed Inst Technol, Dept Hlth Sci \& Technol, Hlth Eth \& Policy Lab, Zurich, Switzerland.}},
ISSN = {{0068-3175}},
EISSN = {{2537-4044}},
Keywords = {{machine ethics; theoretical foundations; extended cognition; extended
   mind; embodied cognition; externalism; artificial intelligence}},
Keywords-Plus = {{PERCEPTION; MEMORY}},
Research-Areas = {{Philosophy}},
Web-of-Science-Categories  = {{Philosophy}},
Author-Email = {{marcello.ienca@unibas.ch}},
Cited-References = {{Azevedo FAC, 2009, J COMP NEUROL, V513, P532, DOI 10.1002/cne.21974.
   Balcetis E, 2007, PSYCHOL SCI, V18, P917, DOI 10.1111/j.1467-9280.2007.02000.x.
   Bekkering H, 2002, PSYCHOL SCI, V13, P370, DOI 10.1111/1467-9280.00466.
   Bentham J., 1823, INTRO PRINCIPLES MOR.
   Bickerton D., 2009, ADAMS TONGUE HUMANS.
   BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M.
   BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032.
   CARPENTER TP, 1999, {[}No title captured].
   Carter JA, 2016, J AM PHILOS ASSOC, V2, P542, DOI 10.1017/apa.2016.28.
   Chalmers D., 2008, SUPERSIZING MIND.
   Chrisley R, 2003, ARTIF INTELL, V149, P131, DOI 10.1016/S0004-3702(03)00055-9.
   Clark A, 1998, ANALYSIS, V58, P7, DOI 10.1111/1467-8284.00096.
   Clark A., 2002, INT J COGNITION TECH, V1, P21, DOI {[}10.1075/ijct.1.1.03cla, DOI 10.1075/IJCT.1.1.03CLA].
   Clark A, 2008, SUPERSIZING MIND EMB.
   Dehaene S., 1999, NUMBER SENSE.
   Dror I., 2008, COGNITION DISTRIBUTE.
   Fernandez-Duque D, 2009, J CLIN EXP NEUROPSYC, V31, P489, DOI 10.1080/13803390802282688.
   Fitch Tecumseh, 2011, BIOLINGUISTIC ENTERP.
   Forstl H, 1999, EUR ARCH PSY CLIN N, V249, P288, DOI 10.1007/s004060050101.
   Gibson J. J., 1966, SENSES CONSIDERED PE.
   Gigerenzer G., 2007, GUT FEELINGS INTELLI.
   Gigerenzer Gerd, 2011, BOUNDED RATIONALITY.
   GINSBURG HP, 1989, {[}No title captured].
   Greene J, 2002, TRENDS COGN SCI, V6, P517, DOI 10.1016/S1364-6613(02)02011-9.
   HAIDT J, 1993, J PERS SOC PSYCHOL, V65, P613, DOI 10.1037/0022-3514.65.4.613.
   Herculano-Houzel S, 2009, FRONT HUM NEUROSCI, V3, DOI 10.3389/neuro.09.031.2009.
   Hutchins Edwin, 1995, COGNITION WILD.
   Ienca M, 2017, J ALZHEIMERS DIS, V56, P1301, DOI 10.3233/JAD-161037.
   Ienca M, 2016, INT J SOC ROBOT, V8, P565, DOI 10.1007/s12369-016-0366-7.
   Immanuel Kant, 2002, CRITIQUE PRACTICAL R.
   Jenkins Lyle, 2011, NEW PERSPECTIVES EVO, P169.
   KIRSH D, 1994, COGNITIVE SCI, V18, P513, DOI 10.1016/0364-0213(94)90007-8.
   Lakoff G., 1980, METAPHORS WE LIVE BY.
   Mace William M., 1977, PERCEIVING ACTING KN, P32.
   MCCLELLAND JL, 1989, {[}No title captured], P8.
   McMahan Jeff, 2002, ETHICS KILLING PROBL.
   Morowitz Harold J., 1999, Complexity, V4, P39.
   Niedenthal PM, 2005, PERS SOC PSYCHOL REV, V9, P184, DOI 10.1207/s15327957pspr0903\_1.
   O'Regan JK, 2001, BEHAV BRAIN SCI, V24, P939, DOI 10.1017/S0140525X01000115.
   Olmstead AJ, 2009, Q J EXP PSYCHOL, V62, P2409, DOI 10.1080/17470210902846765.
   Osherson D., 1995, INVITATION COGNITIVE, P377.
   Pfeifer R., 2007, BODY SHAPES WAY WE T.
   Provins KA, 1997, PSYCHOL REV, V104, P554, DOI 10.1037/0033-295X.104.3.554.
   QUINN W, 1984, PHILOS PUBLIC AFF, V13, P24.
   Rowlands M, 2010, NEW SCI MIND EXTENDE.
   Rowlands Mark, 2003, EXTERNALISM PUTTING.
   Scott CL, 2001, DISCOURSE PROCESS, V31, P293, DOI 10.1207/S15326950dp31-3\_4.
   Singer P., 1993, PRACTICAL ETHICS.
   Sparrow B, 2011, SCIENCE, V333, P776, DOI 10.1126/science.1207745.
   Steels Luc, 2003, ARTIFICIAL LIFE ROUT.
   Sullins JP, 2006, INT REV INF ETHICS, V6, P23.
   Torrance S, 2011, MACHINE ETHICS, P115.
   Von Frisch K., 1956, BEES THEIR VISION CH.
   VONFRISCH K, 1967, {[}No title captured].
   Wilson R. A., 2011, STANFORD ENCY PHILOS.}},
Number-of-Cited-References = {{55}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{5}},
Journal-ISO = {{An. Univ. Bucur.-Filos.}},
Doc-Delivery-Number = {{GI0AB}},
Unique-ID = {{ISI:000434030400006}},
OA = {{DOAJ Gold}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000434955800073,
Author = {Sabili, Ammar Fathin and Saptawijaya, Ari and Pereira, Luis Moniz},
Book-Group-Author = {{IEEE}},
Title = {{Intelligent Agents via Joint Tabling of Logic Program Abduction and
   Updating}},
Booktitle = {{2017 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER SCIENCE AND
   INFORMATION SYSTEMS (ICACSIS)}},
Series = {{International Conference on Advanced Computer Science and Information
   Systems}},
Year = {{2017}},
Pages = {{465-470}},
Note = {{9th International Conference on Advanced Computer Science and
   Information Systems (ICACSIS), Inst Pertanian, Dept Ilmu Komputer,
   Jakarta, INDONESIA, OCT 28-29, 2017}},
Organization = {{Univ Indonesia, Kantor Pengelolaan Produk Riset and Inovasi; Univ
   Indonesia, Fac Comp Sci; IEEE Indonesia Sect; Univ Negeri Surabaya; UB,
   Fakultas Ilmu Komputer}},
Abstract = {{Reasoning is an important aspect for an intelligent agent to come to a
   rational decision. With the same importance is the ability of such an
   agent to adapt itself to the environment by learning new knowledge from
   its observations. When the agent's knowledge base is represented by a
   logic program, goal-directed deliberative reasoning and the adaptive
   ability of such an agent can be achieved by abduction and updating on
   logic programs, respectively. Furthermore, the tabling feature in logic
   programming, which affords solutions reuse rather than recomputing them,
   enables an agent to make an immediate decision based on past reasoning,
   thus avoiding repetitive deliberative reasoning. Joint tabling of logic
   program abduction and updating is an approach first proposed by Pereira
   and Saptawijaya, motivated by its application in machine ethics,
   enabling an agent to make moral decisions, using their system QUALM. In
   this paper, we provide a complete program transformation which has not
   been detailed on that approach. We also resolve previously unidentified
   issues with respect to its implementation aspects. A prototype, QUALM
   {*} , is implemented as a proof of concept using XSB Prolog.
   Furthermore, an application is detailed, using QUALM{*} , emphasizing
   the importance of joint tabling of logic program abduction and updating,
   in the context of intelligent agents, specifically in ambient
   intelligence for eldercare.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Sabili, AF (Reprint Author), Univ Indonesia, Fac Comp Sci, Depok, Indonesia.
   Sabili, Ammar Fathin; Saptawijaya, Ari, Univ Indonesia, Fac Comp Sci, Depok, Indonesia.
   Pereira, Luis Moniz, Univ Nova Lisboa, Lab Comp Sci \& Informat, NOVA LINCS, Lisbon, Portugal.}},
ISSN = {{2330-4588}},
ISBN = {{978-1-5386-3172-0}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Information Systems}},
Author-Email = {{saptawijaya@cs.ui.ac.id}},
ResearcherID-Numbers = {{Pereira, Luis M/C-6241-2009}},
ORCID-Numbers = {{Pereira, Luis M/0000-0001-7880-4322}},
Funding-Acknowledgement = {{PITTA from Directorate Research and Community Services, Universitas
   Indonesia {[}397/UN2.R3.1/HKP.05.00/2017]; Fundacao para a Ciencia e a
   Tecnologia (FCT/MEC) NOVA LINCS {[}PEst UID/CEC/04516/2013]}},
Funding-Text = {{A. F Sabili and A. Saptawijaya acknowledge the PITTA research grant
   397/UN2.R3.1/HKP.05.00/2017 from Directorate Research and Community
   Services, Universitas Indonesia. L. M. Pereira acknowledges the support
   from Fundacao para a Ciencia e a Tecnologia (FCT/MEC) NOVA LINCS PEst
   UID/CEC/04516/2013.}},
Cited-References = {{Alferes J. J., 2014, THEOR PRACT LOG PROG, V4, P383.
   Alferes JJ, 2000, J LOGIC PROGRAM, V45, P43, DOI 10.1016/S0743-1066(99)00065-5.
   Alferes JJ, 2002, LECT NOTES ARTIF INT, V2424, P50, DOI 10.1007/3-540-45757-7\_5.
   Caruso C., 2017, GRANDMAS LITTLE ROBO.
   Cushman R, 2010, MORAL PSYCHOL HDB.
   Hartshorne C., 1932, COLLECTED PAPERS CS.
   Kakas A. C., 2003, J LOGIC COMPUT, V2, P719.
   Kakas A. C., 1990, INT WORKSH TRUTH MAI, V515, P54.
   KAKAS AC, 1990, VERY LARGE DATA BASES, P650.
   LEITE JA, 2003, {[}No title captured].
   Pereira L. M., 2016, SAPERE, V26.
   Pereira L. M., 2009, P PADL 2009.
   Pereira LM, 2016, J APPL LOG-IFCOLOG, V3, P37.
   Perkasa S. M. A., 2004, P 9 INT C ADV COMP S.
   Saptawijaya Ari, 2013, Logic for Programming, Artificial Intelligence, and Reasoning. 19th International Conference, LPAR-19, Proceedings: LNCS 8312, P694, DOI 10.1007/978-3-642-45221-5\_46.
   Saptawijaya A, 2015, J APPL LOG-IFCOLOG, V2, P69.
   Swift T, 2012, THEOR PRACT LOG PROG, V12, P157, DOI 10.1017/S1471068411000500.
   VANGELDER A, 1991, J ACM, V38, P620.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BK3FW}},
Unique-ID = {{ISI:000434955800073}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000407376900003,
Author = {Welsh, Sean},
Editor = {{Ferreira, MIA and Sequeira, JS and Tokhi, MO and Kadar, EE and Virk, GS}},
Title = {{Formalizing Complex Normative Decisions with Predicate Logic and Graph
   Databases}},
Booktitle = {{WORLD WITH ROBOTS}},
Series = {{Intelligent Systems Control and Automation Science and Engineering}},
Year = {{2017}},
Volume = {{84}},
Pages = {{35-45}},
Note = {{International Conference on Robot Ethics (ICRE), Lisbon, PORTUGAL, OCT
   23-24, 2015}},
Organization = {{Lisbon Univ, Ctr Philosophy \& Inst Super Tecnico; Lisbon Tourism,
   Portugal}},
Abstract = {{This paper argues that the critical work in deontic reasoning is better
   done in the knowledge representation rather than the reasoning of a
   normative system. It describes a way to formalize complex normative
   decisions using predicate logic and graph databases. Simple norms can be
   mechanized with IF/THEN statements. While often expressed in deontic
   logic, such statements can be expressed in simpler predicate logic. More
   complex normative decisions require the ability to make decisions where
   there are multiple clashing duties. Such decisions could be formalized
   in graph databases that express state-act transition relations, causal
   relations, classification relations and evaluation relations. When
   formalizing complex normative decisions it is more powerful and
   practical to draw upon concepts from multiple moral theories rather than
   restricting the system to a single theory. A normative system with
   extensive knowledge representation of complex relations might be able to
   pass a series of reasonable person tests. Passing such tests rather than
   implementing a particular moral theory should be the main design aim of
   normative systems.}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Welsh, S (Reprint Author), Univ Canterbury, Dept Philosophy, Christchurch, New Zealand.
   Welsh, Sean, Univ Canterbury, Dept Philosophy, Christchurch, New Zealand.}},
DOI = {{10.1007/978-3-319-46667-5\_3}},
ISBN = {{978-3-319-46667-5; 978-3-319-46665-1}},
Keywords = {{Robot ethics; Normative systems; Ethical governor; Artificial moral
   agent; Knowledge representation; Machine ethics}},
Research-Areas = {{Computer Science; Social Sciences - Other Topics; History \& Philosophy
   of Science; Robotics}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Ethics; History \& Philosophy Of
   Science; Robotics}},
Author-Email = {{sean.welsh@pg.canterbury.ac.nz}},
Cited-References = {{Aristotle, NICHOMACHEAN ETHICS.
   Asimov Isaac, 1942, ASTOUNDING SCI FICTI.
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82.
   Castaneda Hector-Neri, 1981, NEW STUDIES DEONTIC, P37, DOI 10.1007/978-94-009-8484-4\_2.
   Gabbay D., 2013, HDB DEONTIC LOGIC NO, V1.
   Hansson Sven Ove, 2013, HDB DEONTIC LOGIC NO, P195.
   Horty J. F., 2001, AGENCY DEONTIC LOGIC.
   JACKSON F, 1992, AUSTRALAS J PHILOS, V70, P475, DOI 10.1080/00048409212345351.
   Krotzsch M, 2012, COMPUTING RES RESPOS.
   Maslow A.H., 1954, MOTIVATION PERSONALI.
   McCune W, 2010, PROVER 9 MACE 4.
   Noddings N., 1984, CARING FEMININE APPR.
   Nozick Robert, 1981, PHILOS EXPLANATIONS.
   PIGDEN CR, 1989, AUSTRALAS J PHILOS, V67, P127, DOI 10.1080/00048408912343731.
   Reader S, 2007, ROUTL STUD ETH MORAL, V8, P1.
   Robinson I., 2015, GRAPH DATABASES.
   Ross W. D., 1930, RIGHT GOOD.
   SOWA J, 1992, KNOWL-BASED SYST, V5, P171, DOI 10.1016/0950-7051(92)90028-E.
   Treiber M, 2010, ADV PATTERN RECOGNIT, P1, DOI 10.1007/978-1-84996-235-3.}},
Number-of-Cited-References = {{19}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BI1ZG}},
Unique-ID = {{ISI:000407376900003}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000407376900013,
Author = {Welsh, Sean},
Editor = {{Ferreira, MIA and Sequeira, JS and Tokhi, MO and Kadar, EE and Virk, GS}},
Title = {{Clarifying the Language of Lethal Autonomy in Military Robots}},
Booktitle = {{WORLD WITH ROBOTS}},
Series = {{Intelligent Systems Control and Automation Science and Engineering}},
Year = {{2017}},
Volume = {{84}},
Pages = {{171-183}},
Note = {{International Conference on Robot Ethics (ICRE), Lisbon, PORTUGAL, OCT
   23-24, 2015}},
Organization = {{Lisbon Univ, Ctr Philosophy \& Inst Super Tecnico; Lisbon Tourism,
   Portugal}},
Abstract = {{Many argue that robots should not make the decision to kill humans and
   thus call for a ban on ``killer robots{''} or lethal autonomous weapons
   systems (LAWS). However lethal decision making is complex and requires
   detailed analysis to define what is to be banned or regulated. It is
   common to make distinctions between in the loop, on the loop and off the
   loop LAWS. It is also common to refer to the ``critical functions{''} of
   selecting and engaging targets. In this paper I propose two extra LAWS
   types. AType 0 LAWS is an RPV with ``no robot on the lethal loop.{''}A
   Type 4 LAWS is a robot that has gone ``beyond human control{''} and has
   ``no human in the loop.{''} Types 1-3 are the familiar in, on and off
   the loop LAWS. I also define a third ``critical function{''} namely
   defining the targeting criteria. The aim is to clarify what exactly is
   meant by ``meaningful human control{''} of a LAWS and to facilitate
   wording such as might occur in a Protocol VI to be added to the
   Convention on Certain Conventional Weapons (CCW).}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Welsh, S (Reprint Author), Univ Canterbury, Dept Philosophy, Christchurch, New Zealand.
   Welsh, Sean, Univ Canterbury, Dept Philosophy, Christchurch, New Zealand.}},
DOI = {{10.1007/978-3-319-46667-5\_13}},
ISBN = {{978-3-319-46667-5; 978-3-319-46665-1}},
Keywords = {{Robot ethics; Lethal autonomous weapons systems; Killer robots;
   Meaningful human control; International humanitarian law; Machine ethics}},
Research-Areas = {{Computer Science; Social Sciences - Other Topics; History \& Philosophy
   of Science; Robotics}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Ethics; History \& Philosophy Of
   Science; Robotics}},
Author-Email = {{sean.welsh@pg.canterbury.ac.nz}},
Cited-References = {{Adams T, 2001, PARAMETERS, V41, P1.
   Alpaydin E, 2011, WIRES COMPUT STAT, V3, P195, DOI 10.1002/wics.166.
   Anderson K., 2013, LAW ETHICS AUTONOMOU.
   {[}Anonymous], 2015, OPEN.
   {[}Anonymous], 2015, COMMUNICATION.
   {[}Anonymous], 2015, INT ISR DEL CHAR L 2.
   {[}Anonymous], 2015, INF M EXP LETH AUT W.
   Arkin R. C., 2009, GOVERNING LETHAL BEH.
   Asaro PM, 2009, IEEE TECHNOL SOC MAG, V28, P20, DOI 10.1109/MTS.2009.931863.
   Boella G, 2008, AUTON AGENT MULTI-AG, V17, P1, DOI 10.1007/s10458-008-9047-8.
   Brooks Rosa, 2015, DEFENSE KILLER ROBOT.
   Can N., 2015, THE GLASS CAGE.
   Defense Science Board, 2005, PATR SYST PERF.
   Galliott Jai, 2015, MILIT DEFEN ETHIC, P165.
   Heyns C, 2015, COMMENTS C HEYNS UN.
   Heyns C, 2013, REPORT SPECIAL RAPPO.
   Lin P, 2015, RIGHT LIFE M CLAUSE.
   Liu B, 2009, STUD FUZZ SOFT COMP, V239, P9.
   Lokhorst G, 2011, ROBOT ETHICS ETHICAL.
   Lucas GR, 2013, KILLING REMOTE CONTR, P211.
   Matthias A, 2011, 338 STAND.
   Matthias A, 2004, ETHICS INF TECHNOL, V6, P165.
   Pakistan, 2014, COMMUNICATION.
   Russell S., 2015, ARTIFICIAL INTELLIGE.
   Scharre P, 2015, COMMUNICATION.
   Schmitt M, 2012, HARV NATL SECUR J, V4, P231.
   Sharkey N, 2010, J MILITARY ETHICS, V9, P369, DOI {[}10.1080/15027570.2010.537903, DOI 10.1080/15027570.2010.537903].
   Sharkey N, 2012, INTELL ROBOT AUTON, P111.
   Sharkey N, 2009, IEEE TECHNOL SOC MAG, V28, P16, DOI 10.1109/MTS.2009.931865.
   Sparrow R., 2007, J APPL PHILOS, V24, P62, DOI DOI 10.1111/J.1468-5930.2007.00346.X.
   Sparrow R, 2012, INTELL ROBOT AUTON, P301.
   Sutton R.S., 1998, INTRO REINFORCEMENT.
   United States War Department, 1891, 21 US WAR DEP, V16.
   {*}US AIR FORC, 2009, UNM AIRCR SYST FLIGH.
   Yudkowsky E., 2008, GLOBAL CATASTROPHIC, P308.}},
Number-of-Cited-References = {{35}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{3}},
Usage-Count-Since-2013 = {{11}},
Doc-Delivery-Number = {{BI1ZG}},
Unique-ID = {{ISI:000407376900013}},
DA = {{2020-06-17}},
}

@article{ ISI:000383250600005,
Author = {Saptawijaya, Ari and Pereira, Luis Moniz},
Title = {{Logic programming for modeling morality}},
Journal = {{LOGIC JOURNAL OF THE IGPL}},
Year = {{2016}},
Volume = {{24}},
Number = {{4, SI}},
Pages = {{510-525}},
Month = {{AUG}},
Abstract = {{This article investigates the appropriateness of LP-based reasoning to
   machine ethics, an interdisciplinary inot signeld of inquiry that
   emerges from the need of imbuing autonomous agents with the capacity for
   moral decision making. The inot signrst contribution of the article is
   that of identifying morality viewpoints, as studied in moral philosophy
   and psychology, which are amenable to computational modelling, and then
   mapping them to appropriate LP-based reasoning features. The identiinot
   signed viewpoints are covered by two morality themes: moral
   permissibility and the dual-process model. In the second contribution,
   various LP-based reasoning features are applied to model these
   identiinot signed morality viewpoints, via classic moral examples taken
   offthe-shelf from the literature. For this purpose, our QUALM system,
   which features a combination of LP abduction, updating and
   counterfactuals, supported by LP tabling mechanisms, are mainly
   employed. The applications are also supported by other existing LP-based
   systems, featuring preference handling and probabilistic reasoning,
   which complement QUALM in addressing the morality viewpoints in
   question.}},
Publisher = {{OXFORD UNIV PRESS}},
Address = {{GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Saptawijaya, A (Reprint Author), Univ Indonesia, Fac Comp Sci, Jakarta, Indonesia.
   Saptawijaya, Ari, Univ Indonesia, Fac Comp Sci, Jakarta, Indonesia.
   Pereira, Luis Moniz, Univ Nova Lisboa, NOVA Lab Comp Sci \& Informat, P-1200 Lisbon, Portugal.}},
DOI = {{10.1093/jigpal/jzw025}},
ISSN = {{1367-0751}},
EISSN = {{1368-9894}},
Keywords = {{Machine ethics; computational morality; dual-process model; logic
   programming1; QUALM system; applications}},
Keywords-Plus = {{WELL-FOUNDED SEMANTICS; COUNTERFACTUAL THINKING; ABDUCTION}},
Research-Areas = {{Mathematics; Science \& Technology - Other Topics}},
Web-of-Science-Categories  = {{Mathematics, Applied; Mathematics; Logic}},
Author-Email = {{saptawijaya@cs.ui.ac.id
   lmp@fct.unl.pt}},
ResearcherID-Numbers = {{Pereira, Luis M/C-6241-2009}},
ORCID-Numbers = {{Pereira, Luis M/0000-0001-7880-4322}},
Funding-Acknowledgement = {{FCT/MEC {[}SFRH/BD/72795/2010]; FCT/MEC NOVA LINCS PEst
   {[}UID/CEC/04516/2013]}},
Funding-Text = {{A.S. acknowledges the support from {[}FCT/MEC] grant
   {[}SFRH/BD/72795/2010]. L.M.P. acknowledges the support from {[}FCT/MEC
   NOVA LINCS PEst UID/CEC/04516/2013].}},
Cited-References = {{Alferes JJ, 2004, THEOR PRACT LOG PROG, V4, P383, DOI 10.1017/S1471068403001960.
   Alferes JJ, 2002, LECT NOTES ARTIF INT, V2424, P50, DOI 10.1007/3-540-45757-7\_5.
   Anderson M., 2008, P AAAI FALL 2008 S A.
   Anderson M., 2011, MACHINE ETHICS.
   Anderson Michael, 2005, AAAI FALL S MACH ETH.
   Boissier O., 1 WORKSH RIGHTS DUT.
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82.
   Cushman F., 2010, MORAL PSYCHOL HDB.
   Dell'Acqua P., 2007, J APPL LOGIC, V5, P586.
   Economist T., 2012, MORALS MACHINE, P13.
   Epstude K, 2008, PERS SOC PSYCHOL REV, V12, P168, DOI 10.1177/1088868308316091.
   Foot P., 1967, OXFORD REV, V5, P5, DOI {[}DOI 10.1093/0199252866.003.0002, DOI 10.1002/9781444323528.CH41].
   Future of Life Institute, 2015, RES PRIOR ROB BEN AR.
   Ganascia J. -G., 2007, Ethics and Information Technology, V9, P39, DOI 10.1007/s10676-006-9134-y.
   GELFOND M, 1988, 5 INT LOG PROGR C.
   Han T. A., 2008, LNCS, V5366.
   Hauser M, 2007, MIND LANG, V22, P1, DOI 10.1111/j.1468-0017.2006.00297.x.
   Higgins C., 2014, US NAVY FUNDS MORALI.
   Kakas A.C., 1992, J LOGIC COMPUT, V2, P719, DOI DOI 10.1093/L0GC0M/2.6.719.
   Kamm F. M., 2006, INTRICATE ETHICS RIG.
   Kowalski K, 2011, COMPUTATIONAL METHODS FOR LARGE SYSTEMS: ELECTRONIC STRUCTURE APPROACHES FOR BIOTECHNOLOGY AND NANOTECHNOLOGY, P167.
   Lopes G., 2010, LNCS, V5937.
   Lopes G., 2006, ESCOR 2006 WORKSH IJ.
   Lopes G., 2010, VISUAL DEMO PRINCESS.
   Mallon R., 2010, MORAL PSYCHOL HDB.
   MARKMAN KD, 1993, J EXP SOC PSYCHOL, V29, P87, DOI 10.1006/jesp.1993.1005.
   McCloy R, 2000, MEM COGNITION, V28, P1071, DOI 10.3758/BF03209355.
   McIntyre A., 2004, STANFORD ENCY PHILOS.
   Migliore S, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00451.
   Newman J. O., 2006, LAW PROBAB RISK, V5, P267.
   Otsuka Michael, 2008, UTILITAS, V20, P92.
   Pereira L. M., 2016, LOGIC ARGUMENTATION.
   Pereira L. M., 2016, MORALITY EMOTION UNC.
   Pereira L. M., 2009, P KES INT C INT DEC, V199, P139.
   Pereira LM, 2015, RETHINKING MACHINE E.
   Pereira LM, 2011, MACHINE ETHICS, P398, DOI DOI 10.1017/CBO9780511978036.027.
   Pereira LM, 2013, HANDBOOK ON REASONING-BASED INTELLIGENT SYSTEMS, P243.
   Powers TM, 2006, IEEE INTELL SYST, V21, P46, DOI 10.1109/MIS.2006.77.
   Saptawijaya Ari, 2013, Logic for Programming, Artificial Intelligence, and Reasoning. 19th International Conference, LPAR-19, Proceedings: LNCS 8312, P694, DOI 10.1007/978-3-642-45221-5\_46.
   Saptawijaya A., 2014, THEORY PRACTICE LOGI, V14.
   Saptawijaya A., 2013, THEORY PRACTICE LOGI, V13.
   Saptawijaya A, 2015, J APPL LOG-IFCOLOG, V2, P69.
   Scanlon TM, 1998, WHAT WE OWE EACH OTH.
   Stanovich K. E., 2011, RATIONALITY REFLECTI.
   Swift T, 1999, ANN MATH ARTIF INTEL, V25, P201, DOI 10.1023/A:1018990308362.
   Han TA, 2012, LECT NOTES COMPUT SC, V7180, P212, DOI 10.1007/978-3-642-28717-6\_18.
   The Future of Life Institute, 2015, INT GRANT COMP ROB B.
   THOMSON JJ, 1985, YALE LAW J, V94, P1395, DOI 10.2307/796133.
   VANGELDER A, 1991, J ACM, V38, P620.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.
   White J, 2015, RETHINKING MACHINE E.
   Wiegel V., 2007, THESIS.}},
Number-of-Cited-References = {{52}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Log. J. IGPL}},
Doc-Delivery-Number = {{DV9HF}},
Unique-ID = {{ISI:000383250600005}},
DA = {{2020-06-17}},
}

@article{ ISI:000384713800005,
Author = {Tran, Ben},
Title = {{Machine (Technology) Ethics: The Theoretical and Philosophical Paradigms}},
Journal = {{INTERNATIONAL JOURNAL OF TECHNOETHICS}},
Year = {{2016}},
Volume = {{7}},
Number = {{2}},
Pages = {{77-90}},
Month = {{JUL-DEC}},
Abstract = {{At the foundational level, for computer programmers, the code that
   programmers build and built into, are based on instructions, and the
   purpose of the program it later services. But computers do not have
   their own discretion beyond what humans incorporate into such systems
   and are essentially limited only to the extent its writer chooses.
   However, ABET to date, does not provide assurance or require accredited
   colleges and universities programs in applied science, computing,
   engineering, and engineering technology to take ethics courses or offer
   ethics courses nor train graduates in ethics. Yet, graduates, who then
   become practitioners, and ethical agents, are expected to be ethical
   agents. Hence, the purpose of this article is on machine ethics,
   specifically, on the theoretical and philosophical meaning of
   ethics-different types of ethics and utilitarianism. In addition to
   exploring the theoretical and philosophical paradigm of ethics,
   technology will be defined, in relations to machine ethics.}},
Publisher = {{IGI GLOBAL}},
Address = {{701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Tran, B (Reprint Author), Alliant Int Univ San Francisco, Calif Sch Profess Psychol, San Francisco, CA 94133 USA.
   Tran, Ben, Alliant Int Univ San Francisco, Calif Sch Profess Psychol, San Francisco, CA 94133 USA.}},
DOI = {{10.4018/IJT.2016070105}},
ISSN = {{1947-3451}},
EISSN = {{1947-346X}},
Keywords = {{Act Utilitarianism; Classical Utilitarianism; Ideal Utilitarianism; Rule
   Utilitarianism; Technology; Utilitarianism}},
Research-Areas = {{Social Sciences - Other Topics}},
Web-of-Science-Categories  = {{Ethics}},
Cited-References = {{ALLEN PM, 1994, FUTURES, V26, P583, DOI 10.1016/0016-3287(94)90030-2.
   Anderson M., 2005, MACHINE ETHICS.
   Anderson M, 2011, MACHINE ETHICS, DOI {[}10.1017/CBO9780511978036, DOI 10.1017/CBO9780511978036].
   Anderson M, 2007, AI MAG, V28, P15.
   Anderson S. L., 1995, J PHILOS RES, V20, P543, DOI 10.5840/jpr\_1995\_10.
   Anderson SL, 2013, P 2013 M INT ASS COM.
   Anschutz R. P., 2015, JS MILL BRIT PHILOS.
   Bentham Jeremy, 2012, INTRO PRINCIPLES MOR.
   Bijker W. E., 1987, SOCIAL CONSTRUCTION.
   Brandt R, 1963, MORALITY LANGUAGE CO, P107.
   David L., 1965, FORMS LIMITS UTILITA.
   Donner W., 2011, JS MILL ART LIFE.
   DONNER W, 1991, {[}No title captured].
   DRIVER J, 2014, {[}No title captured].
   Duignan B., 2015, J BENTHAM BRIT PHILO.
   Ellul J., 1964, TECHNOLOGICAL SOC.
   Fieser J, ETHICS.
   Foucault M., 1988, TECHNOLOGIES SELF SE, P16, DOI DOI 10.1080/09518398.2013.786849.
   Galvan J. M., 2003, IEEE ROBOTICS AUTOMA, V10, P58.
   Hooker B., 2015, RULE CONSEQUENTIALIS.
   Hughes T. P., 1991, ENG SOCIAL ENTERPRIS, P7.
   Hughes Thomas P, 1987, SOCIAL CONSTRUCTION, P51, DOI DOI 10.1177/030631289019001010.
   HUGHES TP, 1986, SOC STUD SCI, V16, P281, DOI 10.1177/0306312786016002004.
   Krantz S. F., 2002, REFUTING PETER SINGE.
   Law J., 1992, SHAPING TECHNOLOGY B, P21.
   Luppicini R., 2010, TECHNOETHICS EVOLVIN, DOI {[}10.4018/978-1-60566-952-6, DOI 10.4018/978-1-60566-952-6].
   Mayocchi D., 1995, THESIS.
   Moore G. E., 1903, MIND, V12, P433, DOI DOI 10.1093/MIND/XII.4.433.
   Moore G. E., 2002, NATURE JUDGMENT.
   Moore G. E., 1903, PRINCIPIA ETHICA.
   Nef J., 1989, ETHICS TECHNOLOGY ET.
   Raval V., 2014, INFORM SYSTEMS AUDIT, V5, P1.
   Rooney D., 1997, PROMETHEUS, V15, P399, DOI DOI 10.1080/08109029708632084.
   Schmookler J., 1966, INVENTION EC GROWTH, DOI {[}10.4159/harvard.9780674432833, DOI 10.4159/HARVARD.9780674432833].
   Schneewind Jerome B., 1977, SIDGWICKS ETHICS VIC.
   Sidgwick H., 1874, METHODS ETHICS.
   Singer P., 2013, PREFERENCE UTILITARI.
   Singer P., 2011, PRACTICAL ETHICS, DOI {[}10.1017/CBO9780511975950, DOI 10.1017/CBO9780511975950].
   Sinnott-Armstrong W, 2015, CONSEQUENTIALISM.
   Smart J. J. C., 1961, OUTLINE SYSTEM UTILI.
   The Editors of Encycloaedia Britannica, 2015, CONS ETH.
   The Editors of Encyclopaedia Britannica, 2015, HENR SIDGW BRIT PHIL.
   The Editors of Encyclopaedia Britannica, 2015, GE MOOR BRIT PHIL.
   Tran B., 2013, ETHICAL DATA MINING, P201.
   Wallach W, 2008, MORAL MACHINES TEACH.
   Weber M., 1958, RATIONAL SOCIAL FDN.
   Willemsen M., 2014, DEFENDING UTILITARIA.
   Wolfe A., 2014, WALL STREET J.}},
Number-of-Cited-References = {{48}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{8}},
Journal-ISO = {{Int. J. Technoethics}},
Doc-Delivery-Number = {{DX9KK}},
Unique-ID = {{ISI:000384713800005}},
DA = {{2020-06-17}},
}

@article{ ISI:000373387200006,
Author = {Reed, Gregory S. and Petty, Mikel D. and Jones, Nicholaos J. and Morris,
   Anthony W. and Ballenger, John P. and Delugach, Harry S.},
Title = {{A principles-based model of ethical considerations in military decision
   making}},
Journal = {{JOURNAL OF DEFENSE MODELING AND SIMULATION-APPLICATIONS METHODOLOGY
   TECHNOLOGY-JDMS}},
Year = {{2016}},
Volume = {{13}},
Number = {{2}},
Pages = {{195-211}},
Month = {{APR}},
Abstract = {{When comparing alternative courses of action, modern military decision
   makers often must consider both the military effectiveness and the
   ethical consequences of the available alternatives. The basis, design,
   calibration, and performance of a principles-based computational model
   of ethical considerations in military decision making are reported in
   this article. The relative ethical violation (REV) model comparatively
   evaluates alternative military actions based upon the degree to which
   they violate contextually relevant ethical principles. It is based on a
   set of specific ethical principles deemed by philosophers and ethicists
   to be relevant to military courses of action. A survey of expert and
   non-expert human decision makers regarding the relative ethical
   violation of alternative actions for a set of specially designed
   calibration scenarios was conducted to collect data that was used to
   calibrate the REV model. Perhaps unsurprisingly, the survey showed that
   people, even experts, disagreed greatly amongst themselves regarding the
   scenarios' ethical considerations. Despite this disagreement, two
   significant results emerged. First, after calibration the REV model
   performed very well in terms of replicating the ethical assessments of
   human experts for the calibration scenarios. The REV model outperformed
   an earlier model that was based on tangible consequences rather than
   ethical principles, that earlier model performed comparably to human
   experts, the experts outperformed human non-experts, and the non-experts
   outperformed random selection of actions. All of these performance
   comparisons were measured quantitatively and confirmed with suitable
   statistical tests. Second, although humans tended to value some
   principles over others, none of the ethical principles involvedeven the
   principle of not harming civilianscompletely overshadowed all of the
   other principles.}},
Publisher = {{SAGE PUBLICATIONS INC}},
Address = {{2455 TELLER RD, THOUSAND OAKS, CA 91320 USA}},
Type = {{Article}},
Language = {{English}},
Affiliation = {{Reed, GS (Reprint Author), Univ Alabama, Shelby Ctr 142,301 Sparkman Dr, Huntsville, AL 35899 USA.
   Reed, Gregory S.; Petty, Mikel D.; Jones, Nicholaos J.; Ballenger, John P.; Delugach, Harry S., Univ Alabama, Shelby Ctr 142,301 Sparkman Dr, Huntsville, AL 35899 USA.
   Morris, Anthony W., Army Res Lab, AMCOM Field Element, Redstone Arsenal, AL USA.}},
DOI = {{10.1177/1548512915581213}},
ISSN = {{1548-5129}},
EISSN = {{1557-380X}},
Keywords = {{Human behavior modeling; decision analysis; machine ethics; modeling and
   simulation}},
Keywords-Plus = {{LINEAR-MODELS; EVIL}},
Research-Areas = {{Engineering}},
Web-of-Science-Categories  = {{Engineering, Multidisciplinary}},
Author-Email = {{gregory.reed@uah.edu}},
ResearcherID-Numbers = {{Delugach, Harry/AAG-8423-2020
   Jones, Nicholaos/H-3644-2019}},
ORCID-Numbers = {{Delugach, Harry/0000-0003-4743-6568
   Jones, Nicholaos/0000-0003-4928-5089}},
Cited-References = {{Anderson M., 2005, MACHINE ETHICS, P1.
   {[}Anonymous], 2000, CATECHISM CATHOLIC C.
   Baron-Cohen S, 2004, J AUTISM DEV DISORD, V34, P163, DOI 10.1023/B:JADD.0000022607.19833.00.
   Baron-Cohen S, 2011, SCI EVIL EMPATHY ORI.
   Beauchamp T., 2001, PRINCIPLES BIOMEDICA.
   Brase C. H., 2009, UNDERSTANDABLE STAT.
   DAWES RM, 1971, AM PSYCHOL, V26, P180, DOI 10.1037/h0030868.
   DAWES RM, 1974, PSYCHOL BULL, V81, P95, DOI 10.1037/h0037613.
   DAWES RM, 1979, AM PSYCHOL, V34, P571, DOI 10.1037/0003-066X.34.7.571.
   Gillon R, 2003, J MED ETHICS, V29, P307, DOI 10.1136/jme.29.5.307.
   GILLON R, 1994, BRIT MED J, V309, P184, DOI 10.1136/bmj.309.6948.184.
   Gips J, 1995, ANDROID EPISTEMOLOGY, P243.
   GOODMAN LA, 1954, J AM STAT ASSOC, V49, P732, DOI 10.2307/2281536.
   Goodwin P., 2004, DECISION ANAL MANAGE.
   Irwin T., 2000, NICOMACHEAN ETHICS.
   Kant I, 2011, FUNDAMENTAL PRINCIPL.
   Knoll JL, 2008, J AM ACAD PSYCHIATRY, V36, P105.
   Likert R., 1932, ARCH PSYCHOL, V22, P5.
   McLaren BM, 2006, IEEE INTELL SYST, V21, P29, DOI 10.1109/MIS.2006.67.
   MILGRAM S, 1963, J ABNORM PSYCHOL, V67, P371, DOI 10.1037/h0040525.
   Mill J. S., 1879, UTILITARIANISM.
   Popping R, 1998, SOCIOMETRIC RES, P90.
   Reed GS, 2013, TOPOI-INT REV PHILOS, V32, P237, DOI 10.1007/s11245-012-9127-x.
   Reed GS, 2013, MIL OPER RES, V18, P61.
   Ross W. D., 1930, RIGHT GOOD.
   Schelling TC, 1980, STRATEGY CONFLICT.
   Simon RI, 2003, J AM ACAD PSYCHIATRY, V31, P413.
   Stone M., 2009, THE ANATOMY OF EVIL.
   United States Air Force, 2007, 362241 AF.
   Welner M, 2007, CRIME CLASSIFICATION, P55.
   ZIMBARDO PG, 2004, {[}No title captured], P21.}},
Number-of-Cited-References = {{31}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{4}},
Journal-ISO = {{J. Def. Model. Simul.-Appl. Methodol. Technol.-JDMS}},
Doc-Delivery-Number = {{DI3GP}},
Unique-ID = {{ISI:000373387200006}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000390311200002,
Author = {Bringsjord, Selmer},
Editor = {{Seibt, J and Norskov, M and Andersen, SS}},
Title = {{Can Phronetic Robots Be Engineered by Computational Logicians? No ...
   and Yes}},
Booktitle = {{WHAT SOCIAL ROBOTS CAN AND SHOULD DO}},
Series = {{Frontiers in Artificial Intelligence and Applications}},
Year = {{2016}},
Volume = {{290}},
Pages = {{3-6}},
Note = {{Conference on Robophilosophy / TRANSOR Conference on What Social Robots
   Can and Should Do, Aarhus Univ, Aarhus, DENMARK, OCT 17-21, 2016}},
Organization = {{Aarhus Univ, Sch Culture \& Soc, Res Unit Robophilosophy; Res Network
   Transdisciplinary Studies Social Robot; Danish Res Council Humanities}},
Publisher = {{IOS PRESS}},
Address = {{NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Bringsjord, S (Reprint Author), Rensselaer Polytech Inst, Dept Cognit Sci, Dept Comp Sci, Rensselaer AI \& Reasoning RAIR Lab,Lally Sch Mana, Troy, NY 12180 USA.
   Bringsjord, Selmer, Rensselaer Polytech Inst, Dept Cognit Sci, Dept Comp Sci, Rensselaer AI \& Reasoning RAIR Lab,Lally Sch Mana, Troy, NY 12180 USA.}},
DOI = {{10.3233/978-1-61499-708-5-3}},
ISSN = {{0922-6389}},
ISBN = {{978-1-61499-708-5; 978-1-61499-707-8}},
Keywords = {{machine ethics; robot ethics; phronesis; virtue ethics; Leibniz's
   ethics; divine-command ethics; logic-based/logicist artificial
   intelligence}},
Research-Areas = {{Social Issues}},
Web-of-Science-Categories  = {{Social Issues}},
Author-Email = {{selmer@rpi.edu}},
Cited-References = {{ANSCOMBE GEM, 1958, PHILOSOPHY, V33, P1, DOI 10.1017/S0031819100037943.
   Arkoudas K., 2005, MACHINE ETHICS, P17.
   Bringsjord S, 2001, MIND MACH, V11, P3, DOI 10.1023/A:1011206622741.
   BRINGSJORD S, 2008, {[}No title captured], P127.
   Bringsjord S., 2008, J APPL LOGIC, V6, P502, DOI DOI 10.1016/J.JAL.2008.09.001.
   Bringsjord S, 2007, J CONSCIOUSNESS STUD, V14, P28.
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82.
   Bringsjord S, 2015, J EXP THEOR ARTIF IN, V27, P63, DOI 10.1080/0952813X.2014.940139.
   Bringsjord S, 2012, INTELL ROBOT AUTON, P85.
   Bringsjord Selmer, APPL ARTIFI IN PRESS.
   Driver Julia, 2011, STANFORD ENCY PHILOS.
   Johnson-Laird P. N., 1989, COGNITION EMOTION, V3, P81, DOI DOI 10.1080/02699938908408075.
   Sullins John, 2016, P ROB 2016 FRONT ART.}},
Number-of-Cited-References = {{13}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{4}},
Doc-Delivery-Number = {{BG6IZ}},
Unique-ID = {{ISI:000390311200002}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000502979200114,
Author = {Castro, Jose F.},
Editor = {{Gershenson, C and Froese, T and Siqueiros, JM and Aguilar, W and Izquierdo, E and Sayama, H}},
Title = {{A Bottom-Up Approach to Machine Ethics}},
Booktitle = {{ALIFE 2016, THE FIFTEENTH INTERNATIONAL CONFERENCE ON THE SYNTHESIS AND
   SIMULATION OF LIVING SYSTEMS}},
Year = {{2016}},
Pages = {{719+}},
Note = {{15th International Conference on the Synthesis and Simulation of Living
   Systems (ALife), Cancun, MEXICO, JUL 04-08, 2016}},
Organization = {{Consejo Nacl Ciencia Tecnologia; Int Soc Artificial Life; UNAM, II MAS;
   BEACON; ELSI Origins Network; Tokyo Inst Technol, Earth Life Sci Inst;
   ICOSYSTEM; ITaM}},
Abstract = {{This paper presents a bottom-up approach to machine ethics, based on the
   Measurement Logic Machine (MLM). It is explained how ethical notions
   emerge from the workings, architecture, and environmental assumptions of
   the MLM framework. The MLM uses sequences of measurements to perform
   short-term predictive inference. The MLM ethical behavior stems from the
   inner evaluation of measurements that are used to filter the
   predictions. The MLM ethical discernment is based on measurements that
   detect immediate suffering in other agents. Also, a definition of what
   is an ethically positive modification of the inner evaluations is
   proposed, based on the notion of environmental intelligence and the
   corresponding notion of suffering. It is shown how this double approach
   is consistent with our intuitive notion of ethics. The MLM, with or
   without ethical discernment, can be used in evolutionary game theory,
   and gives clues to the search of ethical senses that increase the
   chances of survival of autonomous agents.}},
Publisher = {{MIT PRESS}},
Address = {{ONE ROGERS ST, CAMBRIDGE, MA 02142 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Castro, JF (Reprint Author), BioISI Univ Lisboa, Lisbon, Portugal.
   Castro, Jose F., BioISI Univ Lisboa, Lisbon, Portugal.}},
Keywords-Plus = {{EVOLUTION}},
Research-Areas = {{Computer Science; Mathematical \& Computational Biology}},
Web-of-Science-Categories  = {{Computer Science, Interdisciplinary Applications; Mathematical \&
   Computational Biology}},
Author-Email = {{CastroJFGF@gmail.com}},
Cited-References = {{Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4.
   Bechara A, 1997, SCIENCE, V275, P1293, DOI 10.1126/science.275.5304.1293.
   Blum A, 1998, LECT NOTES COMPUT SC, V1442, P306.
   Bostrom N., 2014, SUPERINTELLIGENCE PA.
   Castro J. F., 2013, EPIA 2013 ADV ARTIFI, P579.
   Castro J. F., 2011, AISB 2011 HUMAN MEMO, V1, P2.
   Castro J. F., 2010, P 3 INT WORKSH EV RE, P53.
   Crandall J. W., 2014, ABS14098498 CORR.
   Crandall JW, 2014, J ARTIF INTELL RES, V49, P111, DOI 10.1613/jair.4202.
   de Castro Jose Ferreira, 2008, 2008 Conference on Human System Interactions, P633, DOI 10.1109/HSI.2008.4581514.
   Gintis H, 2009, GAME THEORY EVOLVING: A PROBLEM-CENTERED INTRODUCTION TO MODELING STRATEGIC INTERACTION, SECOND EDITION, P1.
   HAMILTON WD, 1964, J THEOR BIOL, V7, P1, DOI 10.1016/0022-5193(64)90039-6.
   Ishowo-Oloko F., 2014, ABS14044985 CORR.
   Lehmann L, 2006, J EVOLUTION BIOL, V19, P1365, DOI 10.1111/j.1420-9101.2006.01119.x.
   LIBET B, 1983, BRAIN, V106, P623, DOI 10.1093/brain/106.3.623.
   Lin CH, 2007, BEHAV BRAIN FUNCT, V3, DOI 10.1186/1744-9081-3-16.
   Mitri S, 2009, P NATL ACAD SCI USA, V106, P15786, DOI 10.1073/pnas.0903152106.
   Mourao-Carvalhal I, 2016, EUR J PUBLIC HEALTH, V26.
   Schultze-Kraft M, 2016, P NATL ACAD SCI USA, V113, P1080, DOI 10.1073/pnas.1513569112.
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961.
   SKINNER BF, 1948, J EXP PSYCHOL, V38, P168, DOI 10.1037//0096-3445.121.3.273.
   Trappl R, 2015, COGN TECHNOL, P1, DOI 10.1007/978-3-319-21548-8.
   Wolpert DH, 1996, NEURAL COMPUT, V8, P1341, DOI 10.1162/neco.1996.8.7.1341.}},
Number-of-Cited-References = {{23}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BO1XX}},
Unique-ID = {{ISI:000502979200114}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000390311200055,
Author = {Ess, Charles},
Editor = {{Seibt, J and Norskov, M and Andersen, SS}},
Title = {{Phronesis for Machine Ethics? Can Robots Perform Ethical Judgments?}},
Booktitle = {{WHAT SOCIAL ROBOTS CAN AND SHOULD DO}},
Series = {{Frontiers in Artificial Intelligence and Applications}},
Year = {{2016}},
Volume = {{290}},
Pages = {{386-389}},
Note = {{Conference on Robophilosophy / TRANSOR Conference on What Social Robots
   Can and Should Do, Aarhus Univ, Aarhus, DENMARK, OCT 17-21, 2016}},
Organization = {{Aarhus Univ, Sch Culture \& Soc, Res Unit Robophilosophy; Res Network
   Transdisciplinary Studies Social Robot; Danish Res Council Humanities}},
Publisher = {{IOS PRESS}},
Address = {{NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Ess, C (Reprint Author), Univ Oslo, Dept Media \& Commun, N-0316 Oslo, Norway.
   Ess, Charles, Univ Oslo, Dept Media \& Commun, N-0316 Oslo, Norway.}},
DOI = {{10.3233/978-1-61499-708-5-386}},
ISSN = {{0922-6389}},
ISBN = {{978-1-61499-708-5; 978-1-61499-707-8}},
Research-Areas = {{Social Issues}},
Web-of-Science-Categories  = {{Social Issues}},
Author-Email = {{c.m.ess@media.uio.no}},
Cited-References = {{Bringsjord Selmer, 2015, P ROMAN 2015 24 INT.
   Ess CM, 2016, EMERG TECH ETH INT A, P57.
   Gerdes A, 2014, FRONT ARTIF INTEL AP, V273, P277, DOI 10.3233/978-1-61499-480-0-277.
   Ruddick S., 1975, PHILOS SEX, P280.
   Sullins John, 2014, SOCIABLE ROBOTS FUTU, V7.
   Sullins JP, 2012, IEEE T AFFECT COMPUT, V3, P398, DOI 10.1109/T-AFFC.2012.31.
   Vallor S., 2011, PHILOS TECHNOLOGY, V24, P251, DOI DOI 10.1007/S13347-011-0015-X.
   van Wynsberghe A, 2013, SCI ENG ETHICS, V19, P407, DOI 10.1007/s11948-011-9343-6.}},
Number-of-Cited-References = {{8}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BG6IZ}},
Unique-ID = {{ISI:000390311200055}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000390311200023,
Author = {Gerdes, Anne},
Editor = {{Seibt, J and Norskov, M and Andersen, SS}},
Title = {{The Role of Phronesis in Robot Ethics}},
Booktitle = {{WHAT SOCIAL ROBOTS CAN AND SHOULD DO}},
Series = {{Frontiers in Artificial Intelligence and Applications}},
Year = {{2016}},
Volume = {{290}},
Pages = {{129-135}},
Note = {{Conference on Robophilosophy / TRANSOR Conference on What Social Robots
   Can and Should Do, Aarhus Univ, Aarhus, DENMARK, OCT 17-21, 2016}},
Organization = {{Aarhus Univ, Sch Culture \& Soc, Res Unit Robophilosophy; Res Network
   Transdisciplinary Studies Social Robot; Danish Res Council Humanities}},
Abstract = {{The Aristotelian concept of phronesis captures the kind of situated
   knowledge, which is needed in order for us to understand and act morally
   in the specific situations in which we find ourselves. On this
   background, it is discussed whether an `as if' version of phronesis,
   understood as situational awareness, might enable us to design a
   virtuous robot with `as if' capabilities of the phronimos. It is argued
   that eventually we might see this kind of virtuous robot, but its `as
   if' qualities would not be sufficient for the virtuous robot to count as
   an ethical agent, since phronesis is presumably not computationally
   tractable.}},
Publisher = {{IOS PRESS}},
Address = {{NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Gerdes, A (Reprint Author), Univ Southern Denmark, Dept Design \& Commun, Univ Pk 1, DK-6000 Kolding, Denmark.
   Gerdes, Anne, Univ Southern Denmark, Dept Design \& Commun, Univ Pk 1, DK-6000 Kolding, Denmark.}},
DOI = {{10.3233/978-1-61499-708-5-129}},
ISSN = {{0922-6389}},
ISBN = {{978-1-61499-708-5; 978-1-61499-707-8}},
Keywords = {{machine ethics; virtue ethics; phronesis; situational awareness}},
Research-Areas = {{Social Issues}},
Web-of-Science-Categories  = {{Social Issues}},
Author-Email = {{gerdes@sdu.dk}},
ResearcherID-Numbers = {{Gerdes, Anne/AAF-1723-2020}},
ORCID-Numbers = {{Gerdes, Anne/0000-0002-2991-5074}},
Cited-References = {{Abney K., 2013, ROUTLEDGE HDB ETHICS.
   Anderson Michael, 2004, MACHINE ETHICS.
   Anderson SL, 2011, MACHINE ETHICS, P524.
   ANSCOMBE GEM, 1958, PHILOSOPHY, V33, P1, DOI 10.1017/S0031819100037943.
   ARENDT H, 1971, SOC RES, V38, P417.
   Arendt H, 1973, ORIGINS TOTALITARIAN.
   Arendt Hannah, 1964, EICHMANN JERUSALEM R.
   Arkin A. N., 2007, GITGVU0711.
   Brooks R. A., 1997, MIND DESIGN, P395.
   Creed J. L., 2011, PHILOS ARISTOTLE.
   Dreyfus H., 2005, P ADDRESSES AM PHILO, V79, P47.
   Dreyfus H., 1986, MIND MACHINE.
   Gerdes Anne, 2015, Journal of Information, Communication and Ethics in Society, V13, P98, DOI 10.1108/JICES-09-2014-0038.
   Greenwood L. H. G., 1909, NICOMACHEAN ETHICS.
   Lin P, 2008, AUTONOMOUS MILITARY.
   MacIntyre A., 1999, DENPENDENT RATIONAL.
   MacIntyre A., 2000, AFTER VIRTUE.
   McDermott D, 2011, MACHINE ETHICS, P88, DOI DOI 10.1017/CBO9780511978036.010.
   Moor JH, 2006, IEEE INTELL SYST, V21, P18, DOI 10.1109/MIS.2006.80.
   Tucker P., 2014, DEFENSE ONE     0513.
   Turkle S., 2011, ALONE TOGETHER WHY W.
   Wallach W., 2015, DANGEROUS MASTER KEE.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.}},
Number-of-Cited-References = {{23}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BG6IZ}},
Unique-ID = {{ISI:000390311200023}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000387181500026,
Author = {Jaafar, Nur Huda and Ahmad, Mohd Sharifuddin and Ahmad, Azhana},
Editor = {{Omatu, S and Selamat, A and Bocewicz, G and Sitek, P and Nielsen, I and GarciaGarcia, JA and Bajo, J}},
Title = {{The Influence of Human Blaming or Bragging Behaviour Towards Software
   Agent Sincerity Implementation}},
Booktitle = {{DISTRIBUTED COMPUTING AND ARTIFICIAL INTELLIGENCE, (DCAI 2016)}},
Series = {{Advances in Intelligent Systems and Computing}},
Year = {{2016}},
Volume = {{474}},
Pages = {{239-246}},
Note = {{13th International Conference on Distributed Computing and Artificial
   Intelligence (DCAI), Sevilla, SPAIN, JUN 01-03, 2016}},
Organization = {{IBM; Indra; Fidetia; IEEE SMC Spain}},
Abstract = {{Machine ethics have become an important field of research in software
   agent technology. Granting autonomy to agents and instilling strong
   moral values in the agents have become a priority for designing agents
   to ensure that they will ethically perform tasks. Sincerity is one
   ethical behaviour that has been proven in human organizations to
   motivate humans in ethically performing their jobs. However, the
   sincerity is ruined if they display blaming or bragging behavior while
   performing their jobs. This paper shows how human blaming and bragging
   behaviour can influence software agent sincerity implementation. We
   propose operational rules of software agent sincerity implementation
   that responds to human blaming or bragging behaviour.}},
Publisher = {{SPRINGER INTERNATIONAL PUBLISHING AG}},
Address = {{GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Jaafar, NH (Reprint Author), Univ Teknol MARA, Fac Comp \& Math Sci, KM 12,Jalan Muar, Segamat 85009, Johor Malaysia, Malaysia.
   Jaafar, Nur Huda, Univ Teknol MARA, Fac Comp \& Math Sci, KM 12,Jalan Muar, Segamat 85009, Johor Malaysia, Malaysia.
   Ahmad, Mohd Sharifuddin; Ahmad, Azhana, Univ Tenaga Nas, Coll Informat Technol, Putrajaya Campus,Jalan IKRAM UNITEN, Kajang 43000, Selangor, Malaysia.}},
DOI = {{10.1007/978-3-319-40162-1\_26}},
ISSN = {{2194-5357}},
EISSN = {{2194-5365}},
ISBN = {{978-3-319-40162-1; 978-3-319-40161-4}},
Keywords = {{Software agent; Sincerity; Blaming; Bragging; Machine ethics}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods}},
Author-Email = {{nurhu378@johor.uitm.edu.my
   sharif@uniten.edu.my
   azhana@uniten.edu.my}},
Cited-References = {{Al-Mishri M., 2011, ENSIKLOPEDIA A MUHAM.
   Anderson M., 2014, ENSURING ETHICAL BEH, P19.
   Anderson M, 2010, SCI AM, V303, P72, DOI 10.1038/scientificamerican1010-72.
   Bhatti O. K., 2015, INT J BUSINESS MANAG, V10, P136, DOI DOI 10.5539/ijbm.v10n4p136.
   Caza A, 2015, LEADERSHIP QUART, V26, P518, DOI 10.1016/j.leaqua.2015.05.008.
   de Melo C.M., 2011, 10 INT C AUT AG MULT, V3, P937.
   DECAPUA A, 1999, {[}No title captured], V22, P5.
   Friedman M, 2013, J VALUE INQUIRY, V47, P271, DOI 10.1007/s10790-013-9377-x.
   Gandhi A., 2013, PRACTICING SUSTAINAB, P45, DOI DOI 10.1007/978-1-4614-4349-0.
   Gorini A, 2012, J EVAL CLIN PRACT, V18, P671, DOI 10.1111/j.1365-2753.2012.01831.x.
   Groom V, 2010, ACMIEEE INT CONF HUM, P211, DOI 10.1109/HRI.2010.5453192.
   Gurdal MY, 2013, J POLIT ECON, V121, P1205, DOI 10.1086/674409.
   HAMEED AS, 2013, WORLD APPL SCI J, V21, P44, DOI DOI 10.5829/idosi.wasj.2013.21.mae.99917.
   Jaafar NH, 2015, ADV INTELL SYST, V331, P307, DOI 10.1007/978-3-319-13153-5\_30.
   Jamaluddin A. M., 2013, MUTIARA IHYA ULUMUDD.
   Kaur H., 2015, COMPUT INTELL DATA M, V3, P27.
   Mat Z., 2015, ASIAN SOC SCI, V11, P28.
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011.
   Perepelkin J, 2014, INT J PHARM HEALTHC, V8, P226, DOI 10.1108/IJPHM-02-2013-0006.
   Scheutz M., 2014, P INLG SIGDIAL 2014, P1.
   Vince R, 2004, MANAGE LEARN, V35, P133, DOI 10.1177/1350507604043022.
   Wilson T, 2009, COMPUT LINGUIST, V35, P399, DOI 10.1162/coli.08-012-R1-06-90.
   Wooldridge M., 2009, INTRO MULTIAGENT SYS.
   Zahedi E, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SMART INSTRUMENTATION, MEASUREMENT AND APPLICATIONS (ICSIMA).
   Zammuner VL, 1996, EUR J SOC PSYCHOL, V26, P233, DOI 10.1002/(SICI)1099-0992(199603)26:2<233::AID-EJSP748>3.0.CO;2-\#.}},
Number-of-Cited-References = {{25}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BG1ZQ}},
Unique-ID = {{ISI:000387181500026}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000390311200029,
Author = {Smakman, Matthijs},
Editor = {{Seibt, J and Norskov, M and Andersen, SS}},
Title = {{Robots and Moral Obligations}},
Booktitle = {{WHAT SOCIAL ROBOTS CAN AND SHOULD DO}},
Series = {{Frontiers in Artificial Intelligence and Applications}},
Year = {{2016}},
Volume = {{290}},
Pages = {{184-189}},
Note = {{Conference on Robophilosophy / TRANSOR Conference on What Social Robots
   Can and Should Do, Aarhus Univ, Aarhus, DENMARK, OCT 17-21, 2016}},
Organization = {{Aarhus Univ, Sch Culture \& Soc, Res Unit Robophilosophy; Res Network
   Transdisciplinary Studies Social Robot; Danish Res Council Humanities}},
Abstract = {{Using Roger Crisp's {[}1] arguments for well-being as the ultimate
   source of moral reasoning, this paper argues that there are no ultimate,
   non-derivative reasons to program robots with moral concepts such as
   moral obligation, morally wrong or morally right. Although these moral
   concepts should not be used to program robots, they are not to be
   abandoned by humans since there are still reasons to keep using them,
   namely: as an assessment of the agent, to take a stand or to motivate
   and reinforce behaviour. Because robots are completely rational agents
   they do not need these additional motivations, they can suffice with a
   concept of what promotes well-being. How a robot knows which action
   promotes well-being to the greatest degree is still up for debate, but a
   combination of top-down and bottom-up approaches seem to be the best
   way.}},
Publisher = {{IOS PRESS}},
Address = {{NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Smakman, M (Reprint Author), HU Univ Appl Sci Utrecht, Inst ICT, HBO ICT, Utrecht, Netherlands.
   Smakman, Matthijs, HU Univ Appl Sci Utrecht, Inst ICT, Utrecht, Netherlands.}},
DOI = {{10.3233/978-1-61499-708-5-184}},
ISSN = {{0922-6389}},
ISBN = {{978-1-61499-708-5; 978-1-61499-707-8}},
Keywords = {{robots; machine ethics; moral obligation; moral concepts; moral
   judgment; ethics; decision making; well-being}},
Research-Areas = {{Social Issues}},
Web-of-Science-Categories  = {{Social Issues}},
Author-Email = {{matthijs.smakman@hu.nl}},
Cited-References = {{Anderson SL, 2008, AI SOC, V22, P477, DOI 10.1007/s00146-007-0094-5.
   Coeckelbergh M, 2010, ETHICS INF TECHNOL, V12, P235, DOI 10.1007/s10676-010-9221-y.
   Crisp Roger, 2006, REASONS AND THE GOOD.
   Crnkovic GD, 2012, ETHICS INF TECHNOL, V14, P61, DOI 10.1007/s10676-011-9278-2.
   HAIDT J, 2010, {[}No title captured], P797.
   Joyce R., 2001, MYTH MORALITY.
   Lin P, 2011, ARTIF INTELL, V175, P942, DOI 10.1016/j.artint.2010.11.026.
   Malle B.F., 2015, ETHICS INF TECHNOL, V18, P1.
   McElwee B, 2010, RATIO, V23, P308, DOI 10.1111/j.1467-9329.2010.00469.x.
   Mitchell T., 1997, MACH LEARN, P2, DOI DOI 10.1007/978-4-431-65950-1\_.
   Murphy RR, 2009, IEEE INTELL SYST, V24, P14, DOI 10.1109/MIS.2009.69.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.
   Wallach W, 2010, ETHICS INF TECHNOL, V12, P243, DOI 10.1007/s10676-010-9232-8.}},
Number-of-Cited-References = {{13}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BG6IZ}},
Unique-ID = {{ISI:000390311200029}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000363570000041,
Author = {Saptawijaya, Ari and Pereira, Luis Moniz},
Editor = {{Pereira, F and Machado, P and Costa, E and Cardoso, A}},
Title = {{Logic Programming Applied to Machine Ethics}},
Booktitle = {{PROGRESS IN ARTIFICIAL INTELLIGENCE-BK}},
Series = {{Lecture Notes in Artificial Intelligence}},
Year = {{2015}},
Volume = {{9273}},
Pages = {{414-422}},
Note = {{17th Portuguese Conference on Artificial Intelligence (EPIA), Univ
   Coimbra, Coimbra, PORTUGAL, SEP 08-11, 2015}},
Organization = {{Sistemas Cognitivos S A; Feedzai S A; Thinkware S A; iClio; FBA;
   Fundacao Ciencia Tecnologia}},
Abstract = {{This paper summarizes our investigation on the application of LP-based
   reasoning to machine ethics, a field that emerges from the need of
   imbuing autonomous agents with the capacity for moral decision-making.
   We identify morality viewpoints (concerning moral permissibility and the
   dual-process model) as studied in moral philosophy and psychology, which
   are amenable to computational modeling. Subsequently, various LP-based
   reasoning features are applied to model these identified morality
   viewpoints, via classic moral examples taken off-the-shelf from the
   literature.}},
Publisher = {{SPRINGER-VERLAG BERLIN}},
Address = {{HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Saptawijaya, A (Reprint Author), Univ Nova Lisboa, Fac Ciencias \& Tecnol, Dept Informat, NOVA Lab Comp Sci \& Informat NOVA LINCS, P-1200 Lisbon, Portugal.
   Saptawijaya, Ari; Pereira, Luis Moniz, Univ Nova Lisboa, Fac Ciencias \& Tecnol, Dept Informat, NOVA Lab Comp Sci \& Informat NOVA LINCS, P-1200 Lisbon, Portugal.
   Saptawijaya, Ari, Univ Indonesia, Fac Comp Sci, Depok, Indonesia.}},
DOI = {{10.1007/978-3-319-23485-4\_41}},
ISSN = {{0302-9743}},
EISSN = {{1611-3349}},
ISBN = {{978-3-319-23485-4; 978-3-319-23484-7}},
Research-Areas = {{Computer Science}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods}},
Author-Email = {{ar.saptawijaya@campus.fct.unl.pt
   lmp@fct.unl.pt}},
ResearcherID-Numbers = {{Pereira, Luis M/C-6241-2009
   }},
ORCID-Numbers = {{Pereira, Luis M/0000-0001-7880-4322
   Saptawijaya, Ari/0000-0002-5864-8673}},
Cited-References = {{Anderson M., 2008, P AAAI FALL 2008 S A.
   Anh HT, 2008, LECT NOTES COMPUT SC, V5366, P739, DOI 10.1007/978-3-540-89982-2\_68.
   Bringsjord S, 2006, IEEE INTELL SYST, V21, P38, DOI 10.1109/MIS.2006.82.
   Cushman F., 2010, MORAL PSYCHOL HDB.
   Dell'Acqua P., 2007, J APPL LOGIC, V5, P586.
   Foot P., 1967, OXFORD REV, V5, P5, DOI {[}DOI 10.1093/0199252866.003.0002, DOI 10.1002/9781444323528.CH41].
   Future of Life Institute, 2015, RES PRIOR ROB BEN AR.
   Ganascia J. -G., 2007, Ethics and Information Technology, V9, P39, DOI 10.1007/s10676-006-9134-y.
   Hauser M, 2007, MIND LANG, V22, P1, DOI 10.1111/j.1468-0017.2006.00297.x.
   Kamm F. M., 2006, INTRICATE ETHICS RIG.
   Kowalski K, 2011, COMPUTATIONAL METHODS FOR LARGE SYSTEMS: ELECTRONIC STRUCTURE APPROACHES FOR BIOTECHNOLOGY AND NANOTECHNOLOGY, P167.
   Lopes G., 2010, VISUAL DEMO PRINCESS.
   Lopes G, 2010, LECT NOTES COMPUT SC, V5937, P294.
   Mallon R., 2010, MORAL PSYCHOL HDB.
   McIntyre A., 2011, STANFORD ENCY PHILOS.
   Newman J. O., 2006, LAW PROBAB RISK, V5, P267.
   Pereira L.M., 2015, FRONTIERS A IN PRESS.
   Pereira L.M., 2015, LOGIC ARGUM IN PRESS.
   Pereira LM, 2015, RETHINKING MACHINE E.
   Pereira LM, 2011, MACHINE ETHICS, P398, DOI DOI 10.1017/CBO9780511978036.027.
   Saptawijaya Ari, 2013, Logic for Programming, Artificial Intelligence, and Reasoning. 19th International Conference, LPAR-19, Proceedings: LNCS 8312, P694, DOI 10.1007/978-3-642-45221-5\_46.
   Saptawijaya A, 2015, J APPL LOG-IFCOLOG, V2, P69.
   Scanlon T.M., 2008, MORAL DIMENSIONS PER.
   Scanlon TM, 1998, WHAT WE OWE EACH OTH.
   Swift T, 1999, ANN MATH ARTIF INTEL, V25, P201, DOI 10.1023/A:1018990308362.
   Han TA, 2012, LECT NOTES COMPUT SC, V7180, P212, DOI 10.1007/978-3-642-28717-6\_18.}},
Number-of-Cited-References = {{26}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BD7UE}},
Unique-ID = {{ISI:000363570000041}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000455812500041,
Author = {Kukita, Minao},
Editor = {{Seibt, J and Hakli, R and Norskov, M}},
Title = {{Another Case against Killer Robots}},
Booktitle = {{SOCIABLE ROBOTS AND THE FUTURE OF SOCIAL RELATIONS}},
Series = {{Frontiers in Artificial Intelligence and Applications}},
Year = {{2014}},
Volume = {{273}},
Pages = {{291-295}},
Note = {{Conference on Robo-Philosophy - Sociable Robotics and the Future of
   Social Relations, Aarhus, DENMARK, AUG 20-23, 2014}},
Abstract = {{An intense dispute is now going on around ``killer robots{''}-lethal
   autonomous weapons. Typical argument against them are, however, not
   applicable to other kinds of killer robots, such as euthanasia robots or
   execution robots. In this article we try to articulate an argument which
   is more general as to be applicable to any kind of killer robots. We
   will thereby support the further claim that there are situations in
   which it is immoral to delegate robots to do morally significant tasks
   on behalf of human agents.}},
Publisher = {{IOS PRESS}},
Address = {{NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Kukita, M (Reprint Author), Nagoya Univ, Grad Sch Informat Sci, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
   Kukita, Minao, Nagoya Univ, Grad Sch Informat Sci, Nagoya, Aichi, Japan.}},
DOI = {{10.3233/978-1-61499-480-0-291}},
ISSN = {{0922-6389}},
EISSN = {{1879-8314}},
ISBN = {{978-1-61499-480-0; 978-1-61499-479-4}},
Keywords = {{lethal autonomous weapon; robot ethics; machine ethics; moral agency}},
Keywords-Plus = {{DISTANCE}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Ergonomics}},
Author-Email = {{minao.kukita@is.nagoya-u.ac.jp}},
Cited-References = {{Aguiar F, 2008, JUDGM DECIS MAK, V3, P344.
   Aguilar P, 2013, J EXP SOC PSYCHOL, V49, P449, DOI 10.1016/j.jesp.2013.01.002.
   Arkin R. C., 2009, GOVERNING LETHAL BEH.
   Coeckelbergh M, 2013, ETHICS INF TECHNOL, V15, P87, DOI 10.1007/s10676-013-9313-6.
   Gunkel D, 2012, MACHINE QUESTION CRI.
   Human Rights Watch, 2012, LOS HUM CAS KILL ROB.
   Singer P, 2009, WIRED WAR ROBOTICS R.
   Strawser B.J., J MILITARY ETHICS, V9, P342.
   Winograd T., 1991, BOUNDARIES HUMANITY, P191.
   Zizek S., 2006, PARALLAX VIEW.}},
Number-of-Cited-References = {{10}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BL7YR}},
Unique-ID = {{ISI:000455812500041}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000455812500033,
Author = {Muntean, Ioan and Howard, Don},
Editor = {{Seibt, J and Hakli, R and Norskov, M}},
Title = {{Artificial Moral Agents: Creative, Autonomous, Social. An Approach Based
   on Evolutionary Computation}},
Booktitle = {{SOCIABLE ROBOTS AND THE FUTURE OF SOCIAL RELATIONS}},
Series = {{Frontiers in Artificial Intelligence and Applications}},
Year = {{2014}},
Volume = {{273}},
Pages = {{217-230}},
Note = {{Conference on Robo-Philosophy - Sociable Robotics and the Future of
   Social Relations, Aarhus, DENMARK, AUG 20-23, 2014}},
Abstract = {{In this paper we propose a model of artificial normative agency that
   accommodates some social competencies that we expect from artificial
   moral agents. The artificial moral agent (AMA) discussed here is based
   on two components: (i) a version of virtue ethics of human agents (VE)
   adapted to artificial agents, called here ``virtual virtue ethics{''}
   (VVE); and (ii) an implementation based on evolutionary computation
   (EC), more concretely genetic algorithms. The reasons to choose VVE and
   EC are related to two elements that are, we argue, central to any
   approach to artificial morality: autonomy and creativity. The greater
   the autonomy an artificial agent has, the more it needs moral standards.
   In the virtue ethics, each agent builds her own character in time;
   creativity comes in degrees as the individual becomes morally competent.
   The model of an autonomous and creative AMA thus implemented is called
   GAMA= Genetic(-inspired) Autonomous Moral Agent. First, unlike the
   majority of other implementations of machine ethics, our model is more
   agent-centered, than action-centered; it emphasizes the developmental
   and behavioral aspects of the ethical agent. Second, in our model, the
   AMA does not make decisions exclusively and directly by following rules
   or by calculating the best outcome of an action. The model incorporates
   rules as initial data (as the initial population of the genetic
   algorithms) or as correction factors, but not as the main structure of
   the algorithm. Third, our computational model is less conventional, or
   at least it does not fall within the Turing tradition in computation.
   Genetic algorithms are excellent searching tools that avoid local minima
   and generate solutions based on previous results. In the GAMA model,
   only prospective at this stage, the VVE approach to ethics is better
   implemented by EC. Finally, the GAMA agents can display sociability
   through competition among the best moral actions and the desire to win
   the competition. Both VVE and EC are more adequate to a ``social
   approach{''} to AMA when compared to the standard approaches. The GAMA
   is more promising a ``moral and social artificial agent{''}.}},
Publisher = {{IOS PRESS}},
Address = {{NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Muntean, I (Reprint Author), Univ Notre Dame, John J Reilly Ctr, 453 Geddes Hall, Notre Dame, IN 46556 USA.
   Muntean, Ioan; Howard, Don, Univ Notre Dame, Reilly Ctr Sci Technol \& Values, Notre Dame, IN 46556 USA.}},
DOI = {{10.3233/978-1-61499-480-0-217}},
ISSN = {{0922-6389}},
EISSN = {{1879-8314}},
ISBN = {{978-1-61499-480-0; 978-1-61499-479-4}},
Keywords = {{artificial moral agents; autonomous agents; virtue ethics;
   dispositionalism; evolutionary computation; genetic algorithms;
   sociability; naturalism; behaviorism}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Ergonomics}},
Author-Email = {{ioan.muntean.2@nd.edu}},
Cited-References = {{Allen C, 2000, J EXP THEOR ARTIF IN, V12, P251, DOI 10.1080/09528130050111428.
   Allen C., 2005, Ethics and Information Technology, V7, P149, DOI 10.1007/s10676-006-0004-4.
   Allen C, 2009, MORAL MACHINES TEACH.
   Anderson M., 2011, MACHINE ETHICS.
   Appiah A., 2008, EXPT ETHICS.
   Arkin R. C., 1998, BEHAV BASED ROBOTICS.
   Arkin R. C., 2009, GOVERNING LETHAL BEH.
   Asimov Isaac, 1942, ASTOUNDING SCI FICTI, P94.
   Bello P, 2013, TOPOI-INT REV PHILOS, V32, P251, DOI 10.1007/s11245-012-9129-8.
   Chalmers DJ, 2010, J CONSCIOUSNESS STUD, V17, P7.
   DANIELSON P, 1992, {[}No title captured].
   De Jong K. A., 2006, EVOLUTIONARY COMPUTA.
   Doris JM, 1998, NOUS, V32, P504, DOI 10.1111/0029-4624.00136.
   Ford KM, 1995, ANDROID EPISTEMOLOGY.
   Gips J, 1995, ANDROID EPISTEMOLOGY.
   HARMAN G, 1999, {[}No title captured], V99, P315, DOI DOI 10.1111/1467-9264.00062.
   Hursthouse Rosalind, 1999, VIRTUE ETHICS.
   Koza J.R., 2003, INTRO TUTORIALS OPTI.
   KURZWEIL R, 2006, {[}No title captured].
   MacIntyre Alasdair., 1984, VIRTUE STUDY MORAL T.
   Murdoch Iris, 1970, SOVEREIGNTY GOOD.
   Olariu S, 2006, HDB BIOINSPIRED ALGO.
   Pritchard D, 2003, METAPHILOSOPHY, V34, P106, DOI 10.1111/1467-9973.00263.
   Savulescu J, 2015, ARTIF INTELL, P79.
   Schmidt M, 2009, SCIENCE, V324, P81, DOI 10.1126/science.1165893.
   Sorensen MH, 2004, LECT NOTES COMPUT SC, V3141, P496.
   Thomson JJ, 1997, J PHILOS, V94, P273, DOI 10.2307/2564542.
   Tonkens R, 2012, ETHICS INF TECHNOL, V14, P137, DOI 10.1007/s10676-012-9290-1.
   Turing A, 1950, MIND, V59, P433, DOI DOI 10.1093/MIND/LIX.236.433.}},
Number-of-Cited-References = {{29}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{1}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BL7YR}},
Unique-ID = {{ISI:000455812500033}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000455812500009,
Author = {Wallach, Wendell Arnhold},
Editor = {{Seibt, J and Hakli, R and Norskov, M}},
Title = {{Moral Machines and Human Ethics}},
Booktitle = {{SOCIABLE ROBOTS AND THE FUTURE OF SOCIAL RELATIONS}},
Series = {{Frontiers in Artificial Intelligence and Applications}},
Year = {{2014}},
Volume = {{273}},
Pages = {{19-20}},
Note = {{Conference on Robo-Philosophy - Sociable Robotics and the Future of
   Social Relations, Aarhus, DENMARK, AUG 20-23, 2014}},
Publisher = {{IOS PRESS}},
Address = {{NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Wallach, WA (Reprint Author), Yale Univ, Interdisciplinary Ctr Bioeth, New Haven, CT 06520 USA.
   Wallach, Wendell Arnhold, Yale Univ, Interdisciplinary Ctr Bioeth, New Haven, CT 06520 USA.}},
DOI = {{10.3233/978-1-61499-480-0-19}},
ISSN = {{0922-6389}},
EISSN = {{1879-8314}},
ISBN = {{978-1-61499-480-0; 978-1-61499-479-4}},
Keywords = {{machine ethics; moral judgment; rationality; emotion; consciousness;
   computability of ethical decision making; methodology}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Ergonomics}},
Cited-References = {{Allen C, 2012, INTELL ROBOT AUTON, P55.
   Wallach W, 2011, INT J MACHINE CONSCI, V3, P177, DOI DOI 10.1142/S1793843011000674.
   Wallach W., 2015, DANGEROUS MASTER KEE.
   Wallach W, 2008, MORAL MACHINES TEACH.
   Wallach W, 2013, ETHICS INF TECHNOL, V15, P125, DOI 10.1007/s10676-012-9303-0.
   Wallach W, 2010, TOP COGN SCI, V2, P454, DOI 10.1111/j.1756-8765.2010.01095.x.
   Wallach W, 2010, ETHICS INF TECHNOL, V12, P243, DOI 10.1007/s10676-010-9232-8.
   Wallach Wendell, 2011, LAW INNOVATION TECHN, V3, P185.}},
Number-of-Cited-References = {{8}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{0}},
Doc-Delivery-Number = {{BL7YR}},
Unique-ID = {{ISI:000455812500009}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000328827600027,
Author = {Sullins, John P.},
Editor = {{Podins, K and Stinissen, J and Maybaum, M}},
Title = {{An Ethical Analysis of the Case for Robotic Weapons Arms Control}},
Booktitle = {{2013 5TH INTERNATIONAL CONFERENCE ON CYBER CONFLICT (CYCON)}},
Series = {{International Conference on Cyber Conflict}},
Year = {{2013}},
Note = {{5th International Conference on Cyber Conflict (CYCON), Tallinn,
   ESTONIA, JUN 04-07, 2013}},
Organization = {{NATO Cooperat Cyber Def Ctr Excellence; IEEE; Microsoft; Verint; Cisco;
   IXIA; IEEE, Estonia Sect}},
Abstract = {{While the use of telerobotic and semi-autonomous weapons systems has
   been enthusiastically embraced by politicians and militaries around the
   world, their deployment has not gone without criticism. Strong critics
   such as Asaro (2008), Sharkey (2008, 2009, 2010, 2011, and 2012) and
   Sparrow (2007, 2009a, 2009b, 2011) argue that these technologies have
   multiple moral failings and their deployment on principle must be
   severely limited or perhaps even eliminated. These authors and
   researchers along with a growing list of others have founded the
   International Committee for Robot Arms Control as a means for advancing
   their arguments and advocating for future talks and treaties that might
   limit the use of these weapons. Others such as Arkin (2010), Brooks
   (2012), Lin, Abney and Bekey (2008, 2012), Strawser (2010), have argued
   that there are some compelling reasons to believe that, at least in some
   cases, deployment of telerobotic and semi-autonomous weapons systems can
   contribute to marginal improvements to the state of ethical and just
   outcomes in armed combat. This presentation will trace the main
   arguments posed by both sides of the issue. Additionally this paper will
   suggest certain considerations motivated by the philosophy of technology
   that might be worthy of addition to future robotic arms control
   treaties. This position argues that these technologies through the
   process of reverse adaptation can change our notions of just war theory
   to the point that caution in their use is recommended until further
   analysis of these effects can be accomplished. A realistic stance
   towards robotic weapons arms control will be argued for without losing
   sight of the positive role these technologies can play in resolving
   armed conflict in the most just and ethical manner possible.}},
Publisher = {{IEEE}},
Address = {{345 E 47TH ST, NEW YORK, NY 10017 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Sullins, JP (Reprint Author), Sonoma State Univ, Dept Philosophy, Rohnert Pk, CA 94928 USA.
   Sonoma State Univ, Dept Philosophy, Rohnert Pk, CA 94928 USA.}},
ISSN = {{2325-5366}},
ISBN = {{978-1-4799-0450-1}},
Keywords = {{Robotic Arms Control; Autonomous Weapons Systems (AWS); Just War Theory;
   Robot Ethics; Machine Ethics}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic}},
Author-Email = {{John.sullins@sonoma.edu}},
Cited-References = {{Altmann J, 2009, ETHICS AND ROBOTICS.
   {[}Anonymous], 2013, 54 HARV INT L L J, V54.
   Arkin Ronald C., 2010, JOURNAL OF MILITARY, V9, P332.
   Arkin Ronald C., 2007, TECHNICAL REPORT GIT.
   Arquilla John, 2012, FOREIGN AFFAIRS.
   Arquilla John, 2010, THE NEW RULES OF WAR.
   Asaro P., 2008, CURRENT ISSUES COMPU, P50.
   Asaro P., 2011, ETHICAL LEGAL ASPECT, P103.
   Brooks Rory, 2012, FORIGN POLICY.
   Bynum TW, 2000, ETHICS AGE INFORMATI, P32.
   Caroll R., 2012, THE GUARDIAN.
   Dabringer G, 2011, ETHICAL AND LEGAL AS.
   Floridi Luciano, 2003, COMPUTER ETHICS READ.
   Gathmann F., 2013, DEUTSCHLANDS DROHNEN.
   Glaser John, 2013, ANTI WAR COM MARCH 2.
   Homeland 1 Staff, 2012, HOMELAND1.
   Kahn Paul W., 2002, PHILOSOPHY PUBLIC PO, V22, P2.
   Kim Lucia, 2013, INTERNATIONAL HERALD.
   Landler Mark, 2012, THE NEW YORK TIMES.
   Lessig Larry, 1999, THE CODE IS THE LAW.
   Lin P, 2012, INTELL ROBOT AUTON, P1.
   Lin Patrick, 2008, AUTONOMOUS MILITARY.
   Marchant G.E., 2011, THE COLUMBIA SCIENCE, V12, P272.
   Medick V., 2013, SPIEGEL ONLINE.
   MOOR JH, 1985, METAPHILOSOPHY, V16, P266, DOI 10.1111/j.1467-9973.1985.tb00173.x.
   Noel Sharkey, 2011, ETHICAL AND LEGAL AS, P43.
   Noel Sharkey, 2010, JOURNAL OF MILITARY, V9, P369.
   Noel Sharkey, 2009, IEEE TECHNOLOGY AND, V28, P16.
   Oudes C, 2011, COMMUNICATION.
   Patrick L., 2010, J MILITARY ETHICS, V9, P313, DOI DOI 10.1080/15027570.2010.536401.
   Qazi Shehzad H., 2012, THE DIPLOMAT.
   Rohde David, 2012, FOREIGN POLICY.
   Sauer F, 2012, SECUR DIALOGUE, V43, P363, DOI 10.1177/0967010612450207.
   Schmitt Michael N., 2012, COMMUNICATION.
   Schmitt Michael N., 2013, TALLINN MANUAL ON TH.
   SHARKEY N, 2008, {[}No title captured], V11, P86.
   Sharkey Noel, 2012, ROBOT ETHICS THE ETH, P111.
   Simonite Tom, 2008, NEW SCIENTIST.
   Singer P. W., 2009, WIRED FOR WAR.
   Sparrow R, 2011, ETHICAL LEGAL ASPECT, P87.
   Sparrow R, 2009, IEEE TECHNOL SOC MAG, V28, P25, DOI 10.1109/MTS.2009.931862.
   Sparrow R, 2009, SCI ENG ETHICS, V15, P169, DOI 10.1007/s11948-008-9107-0.
   Sparrow Robert W., 2007, JOURNAL OF APPLIED P, V24.
   Strawser B.J., 2010, J MILITARY ETHICS, V9, P342, DOI DOI 10.1080/15027570.2010.536403.
   Sullins JP, 2010, ETHICS INF TECHNOL, V12, P263, DOI 10.1007/s10676-010-9241-7.
   Sullins John P., 2010, THE CAMBRIDGE HANDBO, P116.
   Sullins JP, 2011, ETHICAL LEGAL ASPECT, P157.
   Tavani Herman, 2004, ETHICS AND TECHNOLOG.
   US Department of Defense, 2007, UNMANNED SYSTEMS ROA.
   US Department of Defense, 2011, AIRCRAFT PROCUREMENT.
   Von Kospoth N., 2009, CHINAS LEAP IN UNMAN.
   Wallach W., 2009, MORAL MACHINES TEACH, DOI 10.1093/acprof:oso/9780195374049.001.0001/acprof-9780195374049.
   Winner L, 1978, AUTONOMOUS TECHNOLOG.
   Woods C, 2011, DRONE WAR EXPOSED.
   Zick Colin J., 2012, SECURITY PRIVACY AND.
   Zubair Shah Pir, 2012, FORIGN POLICY.}},
Number-of-Cited-References = {{56}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{9}},
Doc-Delivery-Number = {{BJL32}},
Unique-ID = {{ISI:000328827600027}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000310490800120,
Author = {Li, Shisen and Guo, Zhaoquan},
Editor = {{Chen, BJ and Hu, V and Kong, D}},
Title = {{Drawing the Map of Human-robot Interaction in Cyborg Sport Girl}},
Booktitle = {{ELECTRONIC INFORMATION AND ELECTRICAL ENGINEERING}},
Series = {{Advances in Intelligent Systems Research}},
Year = {{2012}},
Volume = {{19}},
Pages = {{465-467}},
Note = {{International Conference on Electronic Information and Electrical
   Engineering, Serv Acad Conf Ctr, Changsha, PEOPLES R CHINA, JUN 15-17,
   2012}},
Organization = {{Hunan Univ; Inha Univ; Henan Univ Technol; Nanjing Univ Informat Sci \&
   Technol; Nanjing Univ; Jiangsu Univ; Foshan Univ}},
Abstract = {{Given the infinite expansion of Machine Empire, what kind of future will
   appear between human and robot? The most creative aspect of Cyborg Sport
   Girl is the thinking dimension of human-robot ethics which was brought
   by the rise of Robot Empire. The human-robot love pictures painted in
   the film provide vivid carrier for robot emotion realization, and also
   provide possible paths for drawing the map of human-robot interaction.}},
Publisher = {{ATLANTIS PRESS}},
Address = {{29 AVENUE LAVMIERE, PARIS, 75019, FRANCE}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Li, SS (Reprint Author), Hebei United Univ, Dept Phys Educ, Tangshan, Peoples R China.
   Li, Shisen, Hebei United Univ, Dept Phys Educ, Tangshan, Peoples R China.}},
ISSN = {{1951-6851}},
ISBN = {{978-90-78677-50-5}},
Keywords = {{Cyborg Sport Girl; love movies; human-robot interaction; machine ethics}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic}},
Cited-References = {{ABC/AFP, SCI CALLS ROB ETH RU.
   Christensen Bill, CAN ROBOTS MAKE ETHI.
   Jim Pinto, ROBOT ETHICS NOW LAT.}},
Number-of-Cited-References = {{3}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{3}},
Doc-Delivery-Number = {{BCK73}},
Unique-ID = {{ISI:000310490800120}},
DA = {{2020-06-17}},
}

@inproceedings{ ISI:000271485600031,
Author = {Salmasi, Anna Vartapetiance and Gillam, Lee},
Editor = {{RebolledoMendez, G and Liarokapis, F and DeFreitas, S}},
Title = {{Machine Ethics for Metaverse Gambling: No stake in a \$24m market?}},
Booktitle = {{PROCEEDINGS OF THE IEEE VIRTUAL WORLDS FOR SERIOUS APPLICATIONS}},
Year = {{2009}},
Pages = {{209-212}},
Note = {{1st IEEE International Conference in Games and Virtual Worlds for
   Serious Applications (VS-GAMES 2009), Coventry, ENGLAND, MAR 23-24, 2009}},
Organization = {{IEEE; Game Based Learning; BECTA; Coventry Univ; Serious Games Inst}},
Abstract = {{Online gambling produces a substantial turnover. Unfortunately for
   potential virtual world gamblers and gambling organizations alike, US
   law had forced the closure of gambling in the Second Life virtual world.
   However, an Open Grid Protocol could lead to the provision of off-shore
   gambling in this virtual world. Aside from legal issues, online gambling
   generally gives rise to ethical issues relating to prevention of harm.
   We considered the combined legal and ethical issues, and have proposed
   and begun to construct and evaluate a system with computational
   oversight: an ethical advisor. The system is grounded in recent research
   into Machine Ethics, which may offer insights into other legal and
   ethical matters, and provides a framework for responsible gambling in
   our EthiCasino (ethical virtual casino) in Second Life.}},
Publisher = {{IEEE COMPUTER SOC}},
Address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA}},
Type = {{Proceedings Paper}},
Language = {{English}},
Affiliation = {{Salmasi, AV (Reprint Author), Univ Surrey, Dept Comp, Guildford GU2 5XH, Surrey, England.
   Salmasi, Anna Vartapetiance; Gillam, Lee, Univ Surrey, Dept Comp, Guildford GU2 5XH, Surrey, England.}},
DOI = {{10.1109/VS-GAMES.2009.39}},
ISBN = {{978-0-7695-3588-3}},
Keywords = {{EthiCasino; Machine Ethics; Virtual Worlds; Second life; Online
   Gambling; Responsible Gambling}},
Research-Areas = {{Computer Science; Engineering}},
Web-of-Science-Categories  = {{Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory \& Methods;
   Engineering, Electrical \& Electronic}},
Author-Email = {{a.vartapetiance@googlemail.com
   l.gillam@surrey.ac.uk}},
ResearcherID-Numbers = {{Gillam, Lee/AAF-5154-2020}},
Cited-References = {{Allen C, 2006, IEEE INTELL SYST, V21, P12, DOI 10.1109/MIS.2006.83.
   ANDERSON M, 2005, {[}No title captured], P1.
   ANDERSON M, 2008, ROBOTIC HELPERS USER, P33.
   ANDERSON M, 2005, P AAAI 2005 FALL S C, P9.
   ASHLEY KD, 1995, 1 INT C CAS BAS REAS, P133.
   {*}CHRIST CAP ADV LL, 2004, INT GAMBL EST.
   Comeau S, 1997, GETTING HIGH GAMBLIN.
   GAO, 2002, INT GAMBL OV ISS.
   GARDINER B, 2007, BAND FAILURE 2 LIFE.
   Garrett J, 2004, SIMPLE USABLE ALTHOU.
   Lewis E, 2003, GAMBLING ISLAM CLASH.
   {*}LIND RES INC, 2008, 2 LIF GRID OP GIRD P.
   McLaren BM, 2003, ARTIF INTELL, V150, P145, DOI 10.1016/S0004-3702(03)00135-8.
   McLaren BM, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P316.
   Pasick A., 2007, FBI CHECKS GAMBLING.
   Ross W. D., 1930, RIGHT GOOD.
   Saha P, 2005, GAMBLING RESPONSIBIL.
   WAGNER M, 2007, 2 LIFE CASINO OWNER.}},
Number-of-Cited-References = {{18}},
Times-Cited = {{0}},
Usage-Count-Last-180-days = {{0}},
Usage-Count-Since-2013 = {{1}},
Doc-Delivery-Number = {{BLZ15}},
Unique-ID = {{ISI:000271485600031}},
DA = {{2020-06-17}},
}
